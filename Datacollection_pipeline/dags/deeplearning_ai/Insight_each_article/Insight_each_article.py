import pandas as pd
import os
from dotenv import load_dotenv
from pymongo import MongoClient
from datetime import datetime
from dateutil.relativedelta import relativedelta
from nltk.tokenize import word_tokenize
import nltk
from langchain_google_genai import ChatGoogleGenerativeAI

from langfuse import Langfuse
from langfuse.langchain import CallbackHandler


load_dotenv() 
lf = Langfuse()        # hoáº·c lf = get_client()
handler = CallbackHandler() 
# nltk.download("punkt")
import tiktoken
class InsightSummarizer:
    def __init__(self, mongo_uri, source_db_name, collections, insight_db_name="deeplearning_ai_insight"):
        self.client = MongoClient(mongo_uri)
        self.source_db = self.client[source_db_name]  # Database chá»©a dá»¯ liá»‡u gá»‘c
        self.insight_db = self.client[insight_db_name]  # Database chá»©a insights
        self.collections = collections

    def count_tokens(self, text):
        if not isinstance(text, str):
            return 0
        encoding = tiktoken.get_encoding("cl100k_base")
        return len(encoding.encode(text))

    def filter_summaries_last_k_months(self, k=1, reference_date=None):
        if reference_date is None:
            reference_date = datetime.utcnow()

        start_date = reference_date - relativedelta(months=k)
        all_data = []

        for col in self.collections:
            collection = self.source_db[col]  # Láº¥y tá»« source database
            query = {
                "publish_date": {
                    "$gte": start_date,
                    "$lte": reference_date
                }
            }
            projection = {"summary": 1, "title": 1, "publish_date": 1, "_id": 0}
            results = list(collection.find(query, projection))

            for item in results:
                item["collection"] = col
                item["tokens"] = self.count_tokens(item.get("summary", ""))
                all_data.append(item)

        df = pd.DataFrame(all_data)
        return df.sort_values(by="publish_date")

    def generate_llm_prompt(self, df, k=1, max_tokens=100_000):
        """
        GhÃ©p cÃ¡c summary thÃ nh má»™t prompt dÃ i Ä‘á»ƒ gá»­i vÃ o LLM
        """
        if df.empty:
            return "KhÃ´ng cÃ³ dá»¯ liá»‡u summary trong khoáº£ng thá»i gian Ä‘Ã£ chá»n."
    
        content_blocks = []
        token_total = 0
    
        for _, row in df.iterrows():
            block = f"- ({row['collection']}, {row['publish_date'].date()}): {row['summary']}"
            block_tokens = row["tokens"]
    
            if token_total + block_tokens > max_tokens:
                break
    
            content_blocks.append(block)
            token_total += block_tokens
    
        prompt = (
            f"Báº¡n lÃ  má»™t trá»£ lÃ½ AI Ä‘ang theo dÃµi cÃ¡c bÃ i viáº¿t trong lÄ©nh vá»±c nÃ y. "
            f"DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c Ä‘oáº¡n tÃ³m táº¯t tá»« cÃ¡c bÃ i viáº¿t Ä‘Æ°á»£c xuáº¥t báº£n trong {k} thÃ¡ng gáº§n Ä‘Ã¢y:\n\n"
            + "\n".join(content_blocks)
            + "\n\nDá»±a vÃ o cÃ¡c thÃ´ng tin trÃªn, hÃ£y viáº¿t má»™t báº£n tÃ³m táº¯t tá»± nhiÃªn, sÃºc tÃ­ch vÃ  cÃ³ ngá»¯ Ä‘iá»‡u giá»‘ng nhÆ° má»™t phÃ³ng viÃªn hoáº·c biÃªn táº­p viÃªn chuyÃªn má»¥c cÃ´ng nghá»‡ Ä‘ang tá»•ng káº¿t cÃ¡c sá»± kiá»‡n ná»•i báº­t. "
            "Chá»‰ táº­p trung vÃ o nhá»¯ng Ä‘iá»ƒm Ä‘Ã¡ng chÃº Ã½, trÃ¡nh liá»‡t kÃª dÃ i dÃ²ng. "
            "HÃ£y káº¿t thÃºc báº±ng 1â€“2 cÃ¢u tá»•ng káº¿t cÃ´ Ä‘á»ng xu hÆ°á»›ng chÃ­nh."
        )

        return prompt

    def summarize_last_k_months(self, k=1, max_tokens=100_000, return_df=False):
        df = self.filter_summaries_last_k_months(k)
        prompt = self.generate_llm_prompt(df, k=k, max_tokens=max_tokens)
        return (prompt, df) if return_df else prompt

    def call_gemini_summary(self, prompt, model="gemini-2.0-flash", temperature=0.4):
        genai = ChatGoogleGenerativeAI(
            model=model,
            google_api_key="AIzaSyBKX9Qe8lC8Iqma3LDia_NM0LFCaz7GBt0",
            temperature=temperature,
            callbacks      = [handler],
            name = "monthly summary insight"
        )

        response = genai.invoke(prompt)
        return response.content

    def generate_prompt_for_collection(self, df, k=1, max_tokens=100_000):
        if df.empty:
            return None

        content_blocks = []
        token_total = 0

        for _, row in df.iterrows():
            block = f"- ({row['publish_date'].date()}): {row['summary']}"
            block_tokens = row["tokens"]

            if token_total + block_tokens > max_tokens:
                break

            content_blocks.append(block)
            token_total += block_tokens

        prompt = (
            f"DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c Ä‘oáº¡n tÃ³m táº¯t tá»« cÃ¡c bÃ i viáº¿t Ä‘Æ°á»£c xuáº¥t báº£n trong {k} thÃ¡ng gáº§n Ä‘Ã¢y:\n\n"
            + "\n".join(content_blocks)
            + "\n\nHÃ£y viáº¿t má»™t Ä‘oáº¡n tá»•ng káº¿t ngáº¯n gá»n, khÃ¡ch quan vÃ  rÃµ rÃ ng. "
            "Táº­p trung vÃ o cÃ¡c diá»…n biáº¿n ná»•i báº­t, xu hÆ°á»›ng chÃ­nh vÃ  báº¥t ká»³ thay Ä‘á»•i Ä‘Ã¡ng chÃº Ã½ nÃ o. "
            "KhÃ´ng cáº§n má»Ÿ Ä‘áº§u hoa má»¹ hay trÃ¬nh bÃ y theo kiá»ƒu phÃ³ng viÃªn, chá»‰ cáº§n ná»™i dung insight rÃµ vÃ  Ä‘áº§y Ä‘á»§, cÃ´ Ä‘á»ng trong má»™t Ä‘oáº¡n duy nháº¥t."
        )

        return prompt
    
    def generate_markmap_from_text(self, text, model="gemini-2.0-flash-lite", temperature=0.3):
        prompt = f"""
    TÃ´i sáº½ Ä‘Æ°a báº¡n má»™t Ä‘oáº¡n vÄƒn báº£n tá»•ng há»£p tin tá»©c cÃ´ng nghá»‡. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  chuyá»ƒn ná»™i dung nÃ y sang dáº¡ng **Markdown mindmap** Ä‘á»ƒ cÃ³ thá»ƒ sá»­ dá»¥ng vá»›i thÆ° viá»‡n [Markmap](https://markmap.js.org/).

    â— Tráº£ vá» chá»‰ pháº§n ná»™i dung markdown há»£p lá»‡ (KHÃ”NG bao gá»“m dÃ²ng ```markdown hoáº·c ```), KHÃ”NG thÃªm giáº£i thÃ­ch.

    ÄÃ¢y lÃ  ná»™i dung:

    {text}
    """
        genai = ChatGoogleGenerativeAI(
            model=model,
            google_api_key="AIzaSyBKX9Qe8lC8Iqma3LDia_NM0LFCaz7GBt0",
            temperature=temperature
        )

        response = genai.invoke(prompt)
        content = response.content.strip()

        if content.startswith("```markdown"):
            content = content.removeprefix("```markdown").strip()
        if content.startswith("```"):
            content = content.removeprefix("```").strip()
        if content.endswith("```"):
            content = content.removesuffix("```").strip()

        # âœ… ThÃªm frontmatter YAML cho markmap
        prefix = "---\nmarkmap:\n  initialExpandLevel: 999\n  colorFreezeLevel: 2\n---\n\n"
        return prefix + content



    def summarize_each_collection(self, k=1, max_tokens=100_000, return_prompt_only=False):
        from collections import defaultdict
        collection_insights = {}

        reference_date = datetime.utcnow()
        start_date = reference_date - relativedelta(months=k)

        for col in self.collections:
            collection = self.source_db[col]  # Láº¥y tá»« source database
            query = {
                "publish_date": {"$gte": start_date, "$lte": reference_date}
            }
            projection = {"summary": 1, "title": 1, "publish_date": 1, "_id": 0}
            results = list(collection.find(query, projection))

            if not results:
                continue

            for item in results:
                item["tokens"] = self.count_tokens(item.get("summary", ""))

            df = pd.DataFrame(results).sort_values(by="publish_date")
            prompt = self.generate_prompt_for_collection(df, k=k, max_tokens=max_tokens)

            if not prompt:
                continue

            if return_prompt_only:
                collection_insights[col] = prompt
            else:
                response = self.call_gemini_summary(prompt)
                markmap_md = self.generate_markmap_from_text(response)

                collection_insights[col] = {
                    "insight": response,
                    "markmap": markmap_md
                }


        return collection_insights

    def generate_month_year_string(self, reference_date=None):
        """Táº¡o string month-year format YYYY-MM"""
        if reference_date is None:
            reference_date = datetime.utcnow()
        return reference_date.strftime("%Y-%m")

    def save_insights_to_db(self, k=1, max_tokens=1000, reference_date=None):
        """
        Sinh insight cho tá»«ng collection vÃ  lÆ°u vÃ o database riÃªng biá»‡t
        Má»—i collection sáº½ cÃ³ collection name giá»‘ng vá»›i tÃªn collection gá»‘c
        """
        if reference_date is None:
            reference_date = datetime.utcnow()
        
        month_year = self.generate_month_year_string(reference_date)
        insights = self.summarize_each_collection(k=k, max_tokens=max_tokens, return_prompt_only=False)
        
        saved_count = 0
        
        for collection_name, insight_content in insights.items():
            # Sá»­ dá»¥ng tÃªn collection gá»‘c
            insight_collection = self.insight_db[collection_name]
            
            # Táº¡o document ID theo Ä‘á»‹nh dáº¡ng month_year
            document_id = month_year
            
            insight_doc = {
                "_id": document_id,
                "source_collection": collection_name,
                "month": month_year,
                "insight": insight_content["insight"],
                "markmap": insight_content["markmap"],
                "generated_at": datetime.utcnow(),
                "period_months": k,
                "max_tokens_used": max_tokens
            }
            
            try:
                # Sá»­ dá»¥ng upsert Ä‘á»ƒ trÃ¡nh lá»—i duplicate key
                insight_collection.update_one(
                    {"_id": document_id},
                    {"$set": insight_doc},
                    upsert=True
                )
                saved_count += 1
                print(f"âœ… ÄÃ£ lÆ°u insight cho collection '{collection_name}' (ID: {document_id})")
                
            except Exception as e:
                print(f"âŒ Lá»—i khi lÆ°u insight cho collection '{collection_name}': {e}")
        
        print(f"\nğŸ“Š Tá»•ng káº¿t: ÄÃ£ lÆ°u thÃ nh cÃ´ng {saved_count}/{len(insights)} insights vÃ o database '{self.insight_db.name}'")
        return saved_count

    def get_insights_by_month(self, month_year=None, source_collection=None):
        """
        Láº¥y insights theo thÃ¡ng, cÃ³ thá»ƒ lá»c theo source collection cá»¥ thá»ƒ
        """
        if month_year is None:
            month_year = self.generate_month_year_string()
        
        results = {}
        collections_to_check = [source_collection] if source_collection else self.collections
        
        for col in collections_to_check:
            insight_collection = self.insight_db[col]
            
            try:
                doc = insight_collection.find_one({"_id": month_year})
                if doc:
                    results[col] = doc
            except Exception as e:
                print(f"âš ï¸ Lá»—i khi láº¥y insight tá»« collection '{col}': {e}")
        
        return results

    def get_insights_by_collection(self, collection_name, limit=5):
        """
        Láº¥y insights theo collection (má»›i nháº¥t trÆ°á»›c)
        """
        insight_collection = self.insight_db[collection_name]
        
        try:
            results = list(insight_collection.find().sort("generated_at", -1).limit(limit))
            return results
        except Exception as e:
            print(f"âš ï¸ Lá»—i khi láº¥y insights tá»« collection '{collection_name}': {e}")
            return []

    def delete_insights_by_month(self, month_year, source_collection=None):
        """
        XÃ³a insights cá»§a má»™t thÃ¡ng cá»¥ thá»ƒ, cÃ³ thá»ƒ chá»‰ Ä‘á»‹nh collection cá»¥ thá»ƒ
        """
        deleted_total = 0
        collections_to_delete = [source_collection] if source_collection else self.collections
        
        for col in collections_to_delete:
            insight_collection = self.insight_db[col]
            
            try:
                result = insight_collection.delete_one({"_id": month_year})
                if result.deleted_count > 0:
                    deleted_total += result.deleted_count
                    print(f"ğŸ—‘ï¸ ÄÃ£ xÃ³a insight thÃ¡ng {month_year} tá»« collection '{col}'")
            except Exception as e:
                print(f"âš ï¸ Lá»—i khi xÃ³a insight tá»« collection '{col}': {e}")
        
        print(f"ğŸ—‘ï¸ Tá»•ng cá»™ng Ä‘Ã£ xÃ³a {deleted_total} insights cá»§a thÃ¡ng {month_year}")
        return deleted_total

    def list_all_insight_collections(self):
        """
        Liá»‡t kÃª táº¥t cáº£ collections insight cÃ³ trong database
        """
        collections = self.insight_db.list_collection_names()
        # Lá»c chá»‰ nhá»¯ng collection náº±m trong danh sÃ¡ch collections Ä‘á»‹nh nghÄ©a
        insight_collections = [col for col in collections if col in self.collections]
        return insight_collections

    def get_database_stats(self):
        """
        Thá»‘ng kÃª thÃ´ng tin vá» insight database
        """
        stats = {
            "database_name": self.insight_db.name,
            "collections": {},
            "total_insights": 0
        }
        
        insight_collections = self.list_all_insight_collections()
        
        for col_name in insight_collections:
            collection = self.insight_db[col_name]
            count = collection.count_documents({})
            stats["collections"][col_name] = count
            stats["total_insights"] += count
        
        return stats
