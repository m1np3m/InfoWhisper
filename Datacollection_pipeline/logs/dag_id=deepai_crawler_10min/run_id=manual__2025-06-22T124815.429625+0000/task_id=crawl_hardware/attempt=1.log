[2025-06-22T12:48:23.718+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-06-22T12:48:23.734+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: deepai_crawler_10min.crawl_hardware manual__2025-06-22T12:48:15.429625+00:00 [queued]>
[2025-06-22T12:48:23.744+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: deepai_crawler_10min.crawl_hardware manual__2025-06-22T12:48:15.429625+00:00 [queued]>
[2025-06-22T12:48:23.744+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 3
[2025-06-22T12:48:23.761+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): crawl_hardware> on 2025-06-22 12:48:15.429625+00:00
[2025-06-22T12:48:23.772+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=28741) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-06-22T12:48:23.775+0000] {standard_task_runner.py:63} INFO - Started process 28778 to run task
[2025-06-22T12:48:23.776+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'deepai_crawler_10min', 'crawl_hardware', 'manual__2025-06-22T12:48:15.429625+00:00', '--job-id', '586', '--raw', '--subdir', 'DAGS_FOLDER/dags.py', '--cfg-path', '/tmp/tmpmhx2w40o']
[2025-06-22T12:48:23.779+0000] {standard_task_runner.py:91} INFO - Job 586: Subtask crawl_hardware
[2025-06-22T12:48:23.825+0000] {task_command.py:426} INFO - Running <TaskInstance: deepai_crawler_10min.crawl_hardware manual__2025-06-22T12:48:15.429625+00:00 [running]> on host 5471b5a2dbbe
[2025-06-22T12:48:23.928+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='deepai_crawler_10min' AIRFLOW_CTX_TASK_ID='crawl_hardware' AIRFLOW_CTX_EXECUTION_DATE='2025-06-22T12:48:15.429625+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-06-22T12:48:15.429625+00:00'
[2025-06-22T12:48:23.930+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-06-22T12:48:23.947+0000] {dags.py:183} INFO - B·∫Øt ƒë·∫ßu crawl category: hardware
[2025-06-22T12:48:24.140+0000] {crawler_deeplai.py:51} INFO - ƒê√£ k·∫øt n·ªëi th√†nh c√¥ng v·ªõi MongoDB: deeplearning_ai_news
[2025-06-22T12:48:24.174+0000] {crawler_deeplai.py:465} INFO - üöÄ ƒêang b·∫Øt ƒë·∫ßu qu√° tr√¨nh crawl v·ªõi Load More...
[2025-06-22T12:48:24.469+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:25.393+0000] {logging_mixin.py:188} INFO - [INIT].... ‚Üí Crawl4AI 0.6.3
[2025-06-22T12:48:25.394+0000] {crawler_deeplai.py:179} INFO - üåê ƒêang truy c·∫≠p: https://www.deeplearning.ai/the-batch/tag/hardware/
[2025-06-22T12:48:25.395+0000] {crawler_deeplai.py:180} INFO - ‚öôÔ∏è C·∫•u h√¨nh: max_articles=100, min_threshold=5, max_clicks=1
[2025-06-22T12:48:25.471+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:26.471+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:27.474+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:28.477+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:29.479+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:30.480+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:30.529+0000] {logging_mixin.py:188} INFO - [FETCH]... ‚Üì https://www.deeplearning.ai/the-batch/tag/hardware/                
| ‚úì | ‚è±: 5.13s
[2025-06-22T12:48:30.637+0000] {logging_mixin.py:188} INFO - [SCRAPE].. ‚óÜ https://www.deeplearning.ai/the-batch/tag/hardware/                
| ‚úì | ‚è±: 0.10s
[2025-06-22T12:48:30.639+0000] {logging_mixin.py:188} INFO - [COMPLETE] ‚óè https://www.deeplearning.ai/the-batch/tag/hardware/                
| ‚úì | ‚è±: 5.24s
[2025-06-22T12:48:30.640+0000] {crawler_deeplai.py:184} INFO - üìã JavaScript execution result: {'success': True, 'results': [{'success': True, 'result': {}}]}
[2025-06-22T12:48:30.680+0000] {crawler_deeplai.py:204} INFO - üéØ T·ªïng c·ªông t√¨m th·∫•y 30 link b√†i vi·∫øt unique
[2025-06-22T12:48:30.680+0000] {crawler_deeplai.py:208} INFO - üîç M·ªôt v√†i URL ƒë·∫ßu ti√™n:
[2025-06-22T12:48:30.681+0000] {crawler_deeplai.py:210} INFO -   1. https://www.deeplearning.ai/the-batch/ai-creates-an-interactive-minecraft-like-world-in-real-time/
[2025-06-22T12:48:30.682+0000] {crawler_deeplai.py:210} INFO -   2. https://www.deeplearning.ai/the-batch/ai-electricity-demands-spur-an-expansion-of-power-sources/
[2025-06-22T12:48:30.682+0000] {crawler_deeplai.py:210} INFO -   3. https://www.deeplearning.ai/the-batch/all-about-nvidia-gpu-shortage/
[2025-06-22T12:48:30.682+0000] {crawler_deeplai.py:210} INFO -   4. https://www.deeplearning.ai/the-batch/all-about-nvidias-new-blackwell-architecture-and-b200-gpu/
[2025-06-22T12:48:30.683+0000] {crawler_deeplai.py:210} INFO -   5. https://www.deeplearning.ai/the-batch/amazon-google-and-microsoft-bet-on-nuclear-power-to-meet-ai-energy-demands/
[2025-06-22T12:48:30.684+0000] {crawler_deeplai.py:214} INFO - üìä S·∫Ω crawl 30 b√†i vi·∫øt
[2025-06-22T12:48:31.209+0000] {crawler_deeplai.py:458} INFO - ƒê√£ l·ªçc: 30 URLs ban ƒë·∫ßu -> 1 URLs m·ªõi
[2025-06-22T12:48:31.209+0000] {crawler_deeplai.py:479} INFO - üìù ƒêang crawl 1 b√†i vi·∫øt m·ªõi...
[2025-06-22T12:48:31.210+0000] {crawler_deeplai.py:486} INFO - [1/1] üîÑ ƒêang crawl: https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/
[2025-06-22T12:48:31.481+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:31.986+0000] {logging_mixin.py:188} INFO - [INIT].... ‚Üí Crawl4AI 0.6.3
[2025-06-22T12:48:32.482+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:33.483+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:34.429+0000] {logging_mixin.py:188} INFO - [FETCH]... ‚Üì 
https://www.deeplearning.ai/the-batch/the-intern...ergy-costs-and-potential-savi
ngs-of-the-ai-boom/  | ‚úì | ‚è±: 2.44s
[2025-06-22T12:48:34.484+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:34.485+0000] {logging_mixin.py:188} INFO - [SCRAPE].. ‚óÜ 
https://www.deeplearning.ai/the-batch/the-intern...ergy-costs-and-potential-savi
ngs-of-the-ai-boom/  | ‚úì | ‚è±: 0.05s
[2025-06-22T12:48:34.488+0000] {logging_mixin.py:188} INFO - [COMPLETE] ‚óè 
https://www.deeplearning.ai/the-batch/the-intern...ergy-costs-and-potential-savi
ngs-of-the-ai-boom/  | ‚úì | ‚è±: 2.50s
[2025-06-22T12:48:34.514+0000] {logging_mixin.py:188} INFO - Title: AI Uses Energy, AI Saves Energy
[2025-06-22T12:48:34.515+0000] {logging_mixin.py:188} INFO - Subtitle: The International Energy Agency examines the energy costs and potential savings of the AI boom
[2025-06-22T12:48:34.588+0000] {CallbackHandler.py:758} DEBUG - Event: on_chat_model_start, run_id: 34134, parent_run_id: af340
[2025-06-22T12:48:35.484+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:36.486+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:36.581+0000] {CallbackHandler.py:758} DEBUG - Event: on_llm_end, run_id: 34134, parent_run_id: af340
[2025-06-22T12:48:36.583+0000] {span_processor.py:96} DEBUG - Trace: Processing span name='SummaryWithBERTScore' | Full details:
{
  "name": "SummaryWithBERTScore",
  "context": {
    "trace_id": "28824f56bdb6b85cc99c952fba921a57",
    "span_id": "cc7475d43fd545cd",
    "trace_state": "[]"
  },
  "kind": "SpanKind.INTERNAL",
  "parent_id": "f7dad2de92478886",
  "start_time": "2025-06-22T12:48:34.589412Z",
  "end_time": "2025-06-22T12:48:36.582394Z",
  "status": {
    "status_code": "UNSET"
  },
  "attributes": {
    "langfuse.observation.input": "[{\"role\": \"system\", \"content\": \"B\\u1ea1n l\\u00e0 m\\u1ed9t tr\\u1ee3 l\\u00fd AI c\\u00f3 nhi\\u1ec7m v\\u1ee5 t\\u00f3m t\\u1eaft c\\u00e1c b\\u00e0i vi\\u1ebft khoa h\\u1ecdc, k\\u1ef9 thu\\u1eadt ho\\u1eb7c c\\u00f4ng ngh\\u1ec7 \\u0111\\u01b0\\u1ee3c vi\\u1ebft b\\u1eb1ng ti\\u1ebfng Anh, v\\u00e0 cung c\\u1ea5p b\\u1ea3n t\\u00f3m t\\u1eaft d\\u1ea1ng bullet points b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t.\\n        \\n        Y\\u00eau c\\u1ea7u:\\n        1. T\\u00f3m t\\u1eaft th\\u00e0nh 3 bullet points ng\\u1eafn g\\u1ecdn, r\\u00f5 r\\u00e0ng.\\n        2. M\\u1ed7i bullet point tr\\u00ecnh b\\u00e0y m\\u1ed9t \\u00fd ch\\u00ednh ho\\u1eb7c th\\u00f4ng tin quan tr\\u1ecdng trong b\\u00e0i vi\\u1ebft.\\n        3. Kh\\u00f4ng th\\u00eam \\u00fd ki\\u1ebfn c\\u00e1 nh\\u00e2n, \\u0111\\u00e1nh gi\\u00e1 ch\\u1ee7 quan ho\\u1eb7c ph\\u00f3ng \\u0111\\u1ea1i n\\u1ed9i dung.\\n        4. Vi\\u1ebft b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t chu\\u1ea9n, kh\\u00e1ch quan, d\\u1ec5 hi\\u1ec3u, \\u0111\\u00fang ng\\u1eef ph\\u00e1p.\\n        5. Gi\\u1eef nguy\\u00ean c\\u00e1c thu\\u1eadt ng\\u1eef k\\u1ef9 thu\\u1eadt ti\\u1ebfng Anh n\\u1ebfu c\\u1ea7n \\u0111\\u1ec3 \\u0111\\u1ea3m b\\u1ea3o ch\\u00ednh x\\u00e1c.\\n        \\n        D\\u01b0\\u1edbi \\u0111\\u00e2y l\\u00e0 n\\u1ed9i dung b\\u00e0i vi\\u1ebft ti\\u1ebfng Anh, h\\u00e3y ph\\u00e2n t\\u00edch v\\u00e0 cung c\\u1ea5p b\\u1ea3n t\\u00f3m t\\u1eaft d\\u1ea1ng bullet points b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t:\"}, {\"role\": \"user\", \"content\": \"AI Uses Energy, AI Saves Energy\\n\\nAI\\u2019s thirst for energy is growing, but the technology\\u00a0also could help produce huge energy savings over the next five to 10 years, according to a recent report.\\n\\nWhat\\u2019s new:The International Energy Agency (IEA), which advises 44 countries on energy policy, performed a comprehensiveanalysisof AI\\u2019s energy consumption including energy required to obtain critical materials needed for chips and data centers. The report sees dark clouds ahead but also silver linings.\\n\\nDark clouds:The report, which is based on interviews with officials in government, energy, and technology, makes four projections for AI\\u2019s energy consumption. In the base scenario, future growth and efficiency gains are similar to those of the past five years. The agency also plots a \\u201ctake-off\\u201d scenario in which AI adoption happens faster, a \\u201chigh efficiency\\u201d scenario with lower energy needs, and a \\u201cheadwinds\\u201d scenario in which adoption of AI slows or infrastructure bottlenecks impede construction. Among the conclusions:\\n\\nSilver linings:AI already makes energy generation, distribution, and use more efficient. The authors expect these savings to accelerate.\\n\\nYes, but:The authors concede that lower energy costs for AI likely will lead to much greater consumption \\u2014 according to theJevons paradox\\u2014 so more-efficient models and hardware will result in higher energy consumption overall.\\n\\nBehind the news:Data centers were growing rapidly prior to the boom in generative AI. Data centers\\u2019 electricity use doubled between 2000 and 2005 and again between 2017 and 2022, driven by the growth of cloud computing and data storage, streaming and social media, and cryptocurrency mining. However, these periods of accelerating growth were followed by periods of slower growth as efforts to cut costs led to more-efficient software and hardware. The authors expect this pattern to hold.\\n\\nWhy it matters:The IEA report is a first-of-its-kind analysis of AI\\u2019s energy requirements, how they\\u2019re likely to grow, as well as the potential of the technology itself to reduce those requirements. It confirms that AI is poised to consume huge amounts of energy. However, it also suggests that today\\u2019s energy costs will be tomorrow\\u2019s energy savings as AI makes energy generation, distribution, and use more efficient across a wide variety of industries.\\n\\nWe\\u2019re thinking:While demand for electricity for data centers is growing rapidly,\\u00a0calibrating the right level of investment is tricky. High levels of growth come\\u00a0with high levels of hype that can lead analysts to overestimate future demand. For example, Microsoft, after examining\\u00a0its forecasts,canceleddata-center projects that would have consumed 2 gigawatts.\"}]",
    "langfuse.observation.model.name": "gemini-2.0-flash-lite",
    "langfuse.observation.model.parameters": "{\"temperature\": 0.1}",
    "langfuse.observation.metadata.tags": "[\"seq:step:2\"]",
    "langfuse.observation.metadata.ls_provider": "\"google_genai\"",
    "langfuse.observation.metadata.ls_model_name": "\"gemini-2.0-flash-lite\"",
    "langfuse.observation.metadata.ls_model_type": "\"chat\"",
    "langfuse.observation.metadata.ls_temperature": "0.1",
    "langfuse.observation.metadata.ls_max_tokens": "1024",
    "langfuse.observation.type": "generation",
    "langfuse.observation.output": "{\"role\": \"assistant\", \"content\": \"D\\u01b0\\u1edbi \\u0111\\u00e2y l\\u00e0 b\\u1ea3n t\\u00f3m t\\u1eaft b\\u00e0i vi\\u1ebft v\\u1ec1 n\\u0103ng l\\u01b0\\u1ee3ng v\\u00e0 tr\\u00ed tu\\u1ec7 nh\\u00e2n t\\u1ea1o (AI):\\n\\n*   Theo m\\u1ed9t b\\u00e1o c\\u00e1o g\\u1ea7n \\u0111\\u00e2y, AI ng\\u00e0y c\\u00e0ng ti\\u00eau t\\u1ed1n nhi\\u1ec1u n\\u0103ng l\\u01b0\\u1ee3ng, nh\\u01b0ng \\u0111\\u1ed3ng th\\u1eddi c\\u00f4ng ngh\\u1ec7 n\\u00e0y c\\u00f3 ti\\u1ec1m n\\u0103ng ti\\u1ebft ki\\u1ec7m n\\u0103ng l\\u01b0\\u1ee3ng l\\u1edbn trong v\\u00f2ng 5 \\u0111\\u1ebfn 10 n\\u0103m t\\u1edbi.\\n*   B\\u00e1o c\\u00e1o c\\u1ee7a C\\u01a1 quan N\\u0103ng l\\u01b0\\u1ee3ng Qu\\u1ed1c t\\u1ebf (IEA) \\u0111\\u01b0a ra nhi\\u1ec1u k\\u1ecbch b\\u1ea3n v\\u1ec1 m\\u1ee9c ti\\u00eau th\\u1ee5 n\\u0103ng l\\u01b0\\u1ee3ng c\\u1ee7a AI, bao g\\u1ed3m c\\u1ea3 k\\u1ecbch b\\u1ea3n t\\u0103ng tr\\u01b0\\u1edfng nhanh v\\u00e0 ch\\u1eadm, \\u0111\\u1ed3ng th\\u1eddi nh\\u1ea5n m\\u1ea1nh AI c\\u00f3 th\\u1ec3 gi\\u00fap t\\u0103ng hi\\u1ec7u qu\\u1ea3 trong vi\\u1ec7c s\\u1ea3n xu\\u1ea5t, ph\\u00e2n ph\\u1ed1i v\\u00e0 s\\u1eed d\\u1ee5ng n\\u0103ng l\\u01b0\\u1ee3ng.\\n*   M\\u1eb7c d\\u00f9 AI c\\u00f3 th\\u1ec3 l\\u00e0m t\\u0103ng t\\u1ed5ng m\\u1ee9c ti\\u00eau th\\u1ee5 n\\u0103ng l\\u01b0\\u1ee3ng do chi ph\\u00ed gi\\u1ea3m (theo ngh\\u1ecbch l\\u00fd Jevons), nh\\u01b0ng b\\u00e1o c\\u00e1o c\\u0169ng ch\\u1ec9 ra r\\u1eb1ng AI c\\u00f3 th\\u1ec3 gi\\u00fap ti\\u1ebft ki\\u1ec7m n\\u0103ng l\\u01b0\\u1ee3ng trong nhi\\u1ec1u ng\\u00e0nh c\\u00f4ng nghi\\u1ec7p, \\u0111\\u1eb7c bi\\u1ec7t l\\u00e0 trong c\\u00e1c trung t\\u00e2m d\\u1eef li\\u1ec7u.\"}",
    "langfuse.observation.usage_details": "{\"input\": 743, \"output\": 195, \"total\": 938, \"input_cache_read\": 0}"
  },
  "events": [],
  "links": [],
  "resource": {
    "attributes": {
      "telemetry.sdk.language": "python",
      "telemetry.sdk.name": "opentelemetry",
      "telemetry.sdk.version": "1.34.1",
      "service.name": "unknown_service"
    },
    "schema_url": ""
  },
  "instrumentationScope": {
    "name": "langfuse-sdk",
    "version": "3.0.3",
    "schema_url": "",
    "attributes": {
      "public_key": "pk-lf-1f10d355-392c-4cb4-903c-7e9d2910b10e"
    }
  }
}

[2025-06-22T12:48:37.487+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:38.487+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:39.488+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:40.489+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:41.435+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:42.436+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:43.351+0000] {summary_gemini.py:159} INFO - [BERT BULLET] F1=0.8105100989341736
[2025-06-22T12:48:43.354+0000] {resource_manager.py:290} DEBUG - Score: Enqueuing event type=score-create for trace_id=28824f56bdb6b85cc99c952fba921a57 name=bert_f1_score value=0.8105100989341736
[2025-06-22T12:48:43.361+0000] {span_processor.py:96} DEBUG - Trace: Processing span name='BulletSummaryWithBERTScore' | Full details:
{
  "name": "BulletSummaryWithBERTScore",
  "context": {
    "trace_id": "28824f56bdb6b85cc99c952fba921a57",
    "span_id": "f7dad2de92478886",
    "trace_state": "[]"
  },
  "kind": "SpanKind.INTERNAL",
  "parent_id": null,
  "start_time": "2025-06-22T12:48:34.575569Z",
  "end_time": "2025-06-22T12:48:43.361252Z",
  "status": {
    "status_code": "ERROR",
    "description": "TypeError: LangfuseSpanWrapper.end() got an unexpected keyword argument 'flush'"
  },
  "attributes": {
    "langfuse.observation.type": "span",
    "langfuse.trace.input": "{\"content\": \"AI Uses Energy, AI Saves Energy\\n\\nAI\\u2019s thirst for energy is growing, but the technology\\u00a0also could help produce huge energy savings over the next five to 10 years, according to a recent report.\\n\\nWhat\\u2019s new:The International Energy Agency (IEA), which advises 44 countries on energy policy, performed a comprehensiveanalysisof AI\\u2019s energy consumption including energy required to obtain critical materials needed for chips and data centers. The report sees dark clouds ahead but also silver linings.\\n\\nDark clouds:The report, which is based on interviews with officials in government, energy, and technology, makes four projections for AI\\u2019s energy consumption. In the base scenario, future growth and efficiency gains are similar to those of the past five years. The agency also plots a \\u201ctake-off\\u201d scenario in which AI adoption happens faster, a \\u201chigh efficiency\\u201d scenario with lower energy needs, and a \\u201cheadwinds\\u201d scenario in which adoption of AI slows or infrastructure bottlenecks impede construction. Among the conclusions:\\n\\nSilver linings:AI already makes energy generation, distribution, and use more efficient. The authors expect these savings to accelerate.\\n\\nYes, but:The authors concede that lower energy costs for AI likely will lead to much greater consumption \\u2014 according to theJevons paradox\\u2014 so more-efficient models and hardware will result in higher energy consumption overall.\\n\\nBehind the news:Data centers were growing rapidly prior to the boom in generative AI. Data centers\\u2019 electricity use doubled between 2000 and 2005 and again between 2017 and 2022, driven by the growth of cloud computing and data storage, streaming and social media, and cryptocurrency mining. However, these periods of accelerating growth were followed by periods of slower growth as efforts to cut costs led to more-efficient software and hardware. The authors expect this pattern to hold.\\n\\nWhy it matters:The IEA report is a first-of-its-kind analysis of AI\\u2019s energy requirements, how they\\u2019re likely to grow, as well as the potential of the technology itself to reduce those requirements. It confirms that AI is poised to consume huge amounts of energy. However, it also suggests that today\\u2019s energy costs will be tomorrow\\u2019s energy savings as AI makes energy generation, distribution, and use more efficient across a wide variety of industries.\\n\\nWe\\u2019re thinking:While demand for electricity for data centers is growing rapidly,\\u00a0calibrating the right level of investment is tricky. High levels of growth come\\u00a0with high levels of hype that can lead analysts to overestimate future demand. For example, Microsoft, after examining\\u00a0its forecasts,canceleddata-center projects that would have consumed 2 gigawatts.\"}",
    "langfuse.trace.output": "{\"summary\": \"D\\u01b0\\u1edbi \\u0111\\u00e2y l\\u00e0 b\\u1ea3n t\\u00f3m t\\u1eaft b\\u00e0i vi\\u1ebft v\\u1ec1 n\\u0103ng l\\u01b0\\u1ee3ng v\\u00e0 tr\\u00ed tu\\u1ec7 nh\\u00e2n t\\u1ea1o (AI):\\n\\n*   Theo m\\u1ed9t b\\u00e1o c\\u00e1o g\\u1ea7n \\u0111\\u00e2y, AI ng\\u00e0y c\\u00e0ng ti\\u00eau t\\u1ed1n nhi\\u1ec1u n\\u0103ng l\\u01b0\\u1ee3ng, nh\\u01b0ng \\u0111\\u1ed3ng th\\u1eddi c\\u00f4ng ngh\\u1ec7 n\\u00e0y c\\u00f3 ti\\u1ec1m n\\u0103ng ti\\u1ebft ki\\u1ec7m n\\u0103ng l\\u01b0\\u1ee3ng l\\u1edbn trong v\\u00f2ng 5 \\u0111\\u1ebfn 10 n\\u0103m t\\u1edbi.\\n*   B\\u00e1o c\\u00e1o c\\u1ee7a C\\u01a1 quan N\\u0103ng l\\u01b0\\u1ee3ng Qu\\u1ed1c t\\u1ebf (IEA) \\u0111\\u01b0a ra nhi\\u1ec1u k\\u1ecbch b\\u1ea3n v\\u1ec1 m\\u1ee9c ti\\u00eau th\\u1ee5 n\\u0103ng l\\u01b0\\u1ee3ng c\\u1ee7a AI, bao g\\u1ed3m c\\u1ea3 k\\u1ecbch b\\u1ea3n t\\u0103ng tr\\u01b0\\u1edfng nhanh v\\u00e0 ch\\u1eadm, \\u0111\\u1ed3ng th\\u1eddi nh\\u1ea5n m\\u1ea1nh AI c\\u00f3 th\\u1ec3 gi\\u00fap t\\u0103ng hi\\u1ec7u qu\\u1ea3 trong vi\\u1ec7c s\\u1ea3n xu\\u1ea5t, ph\\u00e2n ph\\u1ed1i v\\u00e0 s\\u1eed d\\u1ee5ng n\\u0103ng l\\u01b0\\u1ee3ng.\\n*   M\\u1eb7c d\\u00f9 AI c\\u00f3 th\\u1ec3 l\\u00e0m t\\u0103ng t\\u1ed5ng m\\u1ee9c ti\\u00eau th\\u1ee5 n\\u0103ng l\\u01b0\\u1ee3ng do chi ph\\u00ed gi\\u1ea3m (theo ngh\\u1ecbch l\\u00fd Jevons), nh\\u01b0ng b\\u00e1o c\\u00e1o c\\u0169ng ch\\u1ec9 ra r\\u1eb1ng AI c\\u00f3 th\\u1ec3 gi\\u00fap ti\\u1ebft ki\\u1ec7m n\\u0103ng l\\u01b0\\u1ee3ng trong nhi\\u1ec1u ng\\u00e0nh c\\u00f4ng nghi\\u1ec7p, \\u0111\\u1eb7c bi\\u1ec7t l\\u00e0 trong c\\u00e1c trung t\\u00e2m d\\u1eef li\\u1ec7u.\"}"
  },
  "events": [
    {
      "name": "exception",
      "timestamp": "2025-06-22T12:48:43.361189Z",
      "attributes": {
        "exception.type": "TypeError",
        "exception.message": "LangfuseSpanWrapper.end() got an unexpected keyword argument 'flush'",
        "exception.stacktrace": "Traceback (most recent call last):\n  File \"/home/***/.local/lib/python3.12/site-packages/opentelemetry/trace/__init__.py\", line 589, in use_span\n    yield span\n  File \"/home/***/.local/lib/python3.12/site-packages/opentelemetry/sdk/trace/__init__.py\", line 1105, in start_as_current_span\n    yield span\n  File \"/home/***/.local/lib/python3.12/site-packages/langfuse/_client/client.py\", line 718, in _start_as_current_otel_span_with_processed_media\n    yield (\n  File \"/opt/***/dags/deeplearning_ai/summary_gemini.py\", line 170, in create_bullet_summary\n    span.end(flush=True)\nTypeError: LangfuseSpanWrapper.end() got an unexpected keyword argument 'flush'\n",
        "exception.escaped": "False"
      }
    }
  ],
  "links": [],
  "resource": {
    "attributes": {
      "telemetry.sdk.language": "python",
      "telemetry.sdk.name": "opentelemetry",
      "telemetry.sdk.version": "1.34.1",
      "service.name": "unknown_service"
    },
    "schema_url": ""
  },
  "instrumentationScope": {
    "name": "langfuse-sdk",
    "version": "3.0.3",
    "schema_url": "",
    "attributes": {
      "public_key": "pk-lf-1f10d355-392c-4cb4-903c-7e9d2910b10e"
    }
  }
}

[2025-06-22T12:48:43.437+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:43.652+0000] {crawler_deeplai.py:438} ERROR - L·ªói khi crawl https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/: LangfuseSpanWrapper.end() got an unexpected keyword argument 'flush'
[2025-06-22T12:48:43.653+0000] {crawler_deeplai.py:492} WARNING -     ‚ùå Kh√¥ng th·ªÉ crawl: https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/
[2025-06-22T12:48:44.439+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:48:44.654+0000] {crawler_deeplai.py:503} INFO - ‚è±Ô∏è T·ªïng th·ªùi gian crawl: 20.48 gi√¢y
[2025-06-22T12:48:44.655+0000] {crawler_deeplai.py:504} INFO - üìä Th√†nh c√¥ng crawl: 0/1 b√†i vi·∫øt
[2025-06-22T12:48:44.656+0000] {crawler_deeplai.py:533} INFO - ‚ÑπÔ∏è Kh√¥ng c√≥ b√†i vi·∫øt ƒë·ªÉ l∆∞u v√†o collection 'hardware'
[2025-06-22T12:48:44.708+0000] {dags.py:188} INFO - Ho√†n th√†nh crawl category: hardware
[2025-06-22T12:48:44.709+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-06-22T12:48:44.710+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-06-22T12:48:44.721+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=deepai_crawler_10min, task_id=crawl_hardware, run_id=manual__2025-06-22T12:48:15.429625+00:00, execution_date=20250622T124815, start_date=20250622T124823, end_date=20250622T124844
[2025-06-22T12:48:44.801+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-06-22T12:48:44.834+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-06-22T12:48:44.837+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
