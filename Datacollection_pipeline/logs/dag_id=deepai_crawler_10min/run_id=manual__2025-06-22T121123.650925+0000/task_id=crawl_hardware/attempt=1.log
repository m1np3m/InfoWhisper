[2025-06-22T12:11:32.581+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-06-22T12:11:32.596+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: deepai_crawler_10min.crawl_hardware manual__2025-06-22T12:11:23.650925+00:00 [queued]>
[2025-06-22T12:11:32.605+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: deepai_crawler_10min.crawl_hardware manual__2025-06-22T12:11:23.650925+00:00 [queued]>
[2025-06-22T12:11:32.606+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 3
[2025-06-22T12:11:32.621+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): crawl_hardware> on 2025-06-22 12:11:23.650925+00:00
[2025-06-22T12:11:32.631+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=20839) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-06-22T12:11:32.633+0000] {standard_task_runner.py:63} INFO - Started process 21020 to run task
[2025-06-22T12:11:32.634+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'deepai_crawler_10min', 'crawl_hardware', 'manual__2025-06-22T12:11:23.650925+00:00', '--job-id', '545', '--raw', '--subdir', 'DAGS_FOLDER/dags.py', '--cfg-path', '/tmp/tmpgmtp8yk7']
[2025-06-22T12:11:32.637+0000] {standard_task_runner.py:91} INFO - Job 545: Subtask crawl_hardware
[2025-06-22T12:11:32.679+0000] {task_command.py:426} INFO - Running <TaskInstance: deepai_crawler_10min.crawl_hardware manual__2025-06-22T12:11:23.650925+00:00 [running]> on host 5471b5a2dbbe
[2025-06-22T12:11:32.773+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='deepai_crawler_10min' AIRFLOW_CTX_TASK_ID='crawl_hardware' AIRFLOW_CTX_EXECUTION_DATE='2025-06-22T12:11:23.650925+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-06-22T12:11:23.650925+00:00'
[2025-06-22T12:11:32.775+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-06-22T12:11:32.789+0000] {dags.py:183} INFO - B·∫Øt ƒë·∫ßu crawl category: hardware
[2025-06-22T12:11:32.902+0000] {crawler_deeplai.py:51} INFO - ƒê√£ k·∫øt n·ªëi th√†nh c√¥ng v·ªõi MongoDB: deeplearning_ai_news
[2025-06-22T12:11:32.931+0000] {crawler_deeplai.py:465} INFO - üöÄ ƒêang b·∫Øt ƒë·∫ßu qu√° tr√¨nh crawl v·ªõi Load More...
[2025-06-22T12:11:33.355+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:11:33.679+0000] {logging_mixin.py:188} INFO - [INIT].... ‚Üí Crawl4AI 0.6.3
[2025-06-22T12:11:33.681+0000] {crawler_deeplai.py:179} INFO - üåê ƒêang truy c·∫≠p: https://www.deeplearning.ai/the-batch/tag/hardware/
[2025-06-22T12:11:33.681+0000] {crawler_deeplai.py:180} INFO - ‚öôÔ∏è C·∫•u h√¨nh: max_articles=100, min_threshold=5, max_clicks=1
[2025-06-22T12:11:34.356+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:11:35.357+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:11:36.358+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:11:37.082+0000] {logging_mixin.py:188} INFO - [FETCH]... ‚Üì https://www.deeplearning.ai/the-batch/tag/hardware/                
| ‚úì | ‚è±: 3.40s
[2025-06-22T12:11:37.203+0000] {logging_mixin.py:188} INFO - [SCRAPE].. ‚óÜ https://www.deeplearning.ai/the-batch/tag/hardware/                
| ‚úì | ‚è±: 0.12s
[2025-06-22T12:11:37.206+0000] {logging_mixin.py:188} INFO - [COMPLETE] ‚óè https://www.deeplearning.ai/the-batch/tag/hardware/                
| ‚úì | ‚è±: 3.52s
[2025-06-22T12:11:37.207+0000] {crawler_deeplai.py:184} INFO - üìã JavaScript execution result: {'success': True, 'results': [{'success': True, 'result': {}}]}
[2025-06-22T12:11:37.251+0000] {crawler_deeplai.py:204} INFO - üéØ T·ªïng c·ªông t√¨m th·∫•y 30 link b√†i vi·∫øt unique
[2025-06-22T12:11:37.252+0000] {crawler_deeplai.py:208} INFO - üîç M·ªôt v√†i URL ƒë·∫ßu ti√™n:
[2025-06-22T12:11:37.253+0000] {crawler_deeplai.py:210} INFO -   1. https://www.deeplearning.ai/the-batch/ai-creates-an-interactive-minecraft-like-world-in-real-time/
[2025-06-22T12:11:37.253+0000] {crawler_deeplai.py:210} INFO -   2. https://www.deeplearning.ai/the-batch/ai-electricity-demands-spur-an-expansion-of-power-sources/
[2025-06-22T12:11:37.254+0000] {crawler_deeplai.py:210} INFO -   3. https://www.deeplearning.ai/the-batch/all-about-nvidia-gpu-shortage/
[2025-06-22T12:11:37.254+0000] {crawler_deeplai.py:210} INFO -   4. https://www.deeplearning.ai/the-batch/all-about-nvidias-new-blackwell-architecture-and-b200-gpu/
[2025-06-22T12:11:37.255+0000] {crawler_deeplai.py:210} INFO -   5. https://www.deeplearning.ai/the-batch/amazon-google-and-microsoft-bet-on-nuclear-power-to-meet-ai-energy-demands/
[2025-06-22T12:11:37.255+0000] {crawler_deeplai.py:214} INFO - üìä S·∫Ω crawl 30 b√†i vi·∫øt
[2025-06-22T12:11:37.359+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:11:37.837+0000] {crawler_deeplai.py:458} INFO - ƒê√£ l·ªçc: 30 URLs ban ƒë·∫ßu -> 1 URLs m·ªõi
[2025-06-22T12:11:37.837+0000] {crawler_deeplai.py:479} INFO - üìù ƒêang crawl 1 b√†i vi·∫øt m·ªõi...
[2025-06-22T12:11:37.838+0000] {crawler_deeplai.py:486} INFO - [1/1] üîÑ ƒêang crawl: https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/
[2025-06-22T12:11:38.360+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:11:38.511+0000] {logging_mixin.py:188} INFO - [INIT].... ‚Üí Crawl4AI 0.6.3
[2025-06-22T12:11:39.360+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:11:39.883+0000] {logging_mixin.py:188} INFO - [FETCH]... ‚Üì 
https://www.deeplearning.ai/the-batch/the-intern...ergy-costs-and-potential-savi
ngs-of-the-ai-boom/  | ‚úì | ‚è±: 1.37s
[2025-06-22T12:11:39.972+0000] {logging_mixin.py:188} INFO - [SCRAPE].. ‚óÜ 
https://www.deeplearning.ai/the-batch/the-intern...ergy-costs-and-potential-savi
ngs-of-the-ai-boom/  | ‚úì | ‚è±: 0.09s
[2025-06-22T12:11:39.977+0000] {logging_mixin.py:188} INFO - [COMPLETE] ‚óè 
https://www.deeplearning.ai/the-batch/the-intern...ergy-costs-and-potential-savi
ngs-of-the-ai-boom/  | ‚úì | ‚è±: 1.46s
[2025-06-22T12:11:40.006+0000] {logging_mixin.py:188} INFO - Title: AI Uses Energy, AI Saves Energy
[2025-06-22T12:11:40.006+0000] {logging_mixin.py:188} INFO - Subtitle: The International Energy Agency examines the energy costs and potential savings of the AI boom
[2025-06-22T12:11:40.078+0000] {summary_gemini.py:155} ERROR - L·ªói bullet LLM (l·∫ßn 3/2): 'Langfuse' object has no attribute 'observation'
[2025-06-22T12:11:40.090+0000] {span_processor.py:96} DEBUG - Trace: Processing span name='BulletSummaryWithBERTScore' | Full details:
{
  "name": "BulletSummaryWithBERTScore",
  "context": {
    "trace_id": "bd4f0046c05f28fa14aa85c04dc4e647",
    "span_id": "9deb930c688ed35d",
    "trace_state": "[]"
  },
  "kind": "SpanKind.INTERNAL",
  "parent_id": null,
  "start_time": "2025-06-22T12:11:40.077940Z",
  "end_time": "2025-06-22T12:11:40.089391Z",
  "status": {
    "status_code": "ERROR",
    "description": "TypeError: LangfuseSpanWrapper.update_trace() got an unexpected keyword argument 'error'"
  },
  "attributes": {
    "langfuse.observation.type": "span",
    "langfuse.trace.input": "{\"content\": \"AI Uses Energy, AI Saves Energy\\n\\nAI\\u2019s thirst for energy is growing, but the technology\\u00a0also could help produce huge energy savings over the next five to 10 years, according to a recent report.\\n\\nWhat\\u2019s new:The International Energy Agency (IEA), which advises 44 countries on energy policy, performed a comprehensiveanalysisof AI\\u2019s energy consumption including energy required to obtain critical materials needed for chips and data centers. The report sees dark clouds ahead but also silver linings.\\n\\nDark clouds:The report, which is based on interviews with officials in government, energy, and technology, makes four projections for AI\\u2019s energy consumption. In the base scenario, future growth and efficiency gains are similar to those of the past five years. The agency also plots a \\u201ctake-off\\u201d scenario in which AI adoption happens faster, a \\u201chigh efficiency\\u201d scenario with lower energy needs, and a \\u201cheadwinds\\u201d scenario in which adoption of AI slows or infrastructure bottlenecks impede construction. Among the conclusions:\\n\\nSilver linings:AI already makes energy generation, distribution, and use more efficient. The authors expect these savings to accelerate.\\n\\nYes, but:The authors concede that lower energy costs for AI likely will lead to much greater consumption \\u2014 according to theJevons paradox\\u2014 so more-efficient models and hardware will result in higher energy consumption overall.\\n\\nBehind the news:Data centers were growing rapidly prior to the boom in generative AI. Data centers\\u2019 electricity use doubled between 2000 and 2005 and again between 2017 and 2022, driven by the growth of cloud computing and data storage, streaming and social media, and cryptocurrency mining. However, these periods of accelerating growth were followed by periods of slower growth as efforts to cut costs led to more-efficient software and hardware. The authors expect this pattern to hold.\\n\\nWhy it matters:The IEA report is a first-of-its-kind analysis of AI\\u2019s energy requirements, how they\\u2019re likely to grow, as well as the potential of the technology itself to reduce those requirements. It confirms that AI is poised to consume huge amounts of energy. However, it also suggests that today\\u2019s energy costs will be tomorrow\\u2019s energy savings as AI makes energy generation, distribution, and use more efficient across a wide variety of industries.\\n\\nWe\\u2019re thinking:While demand for electricity for data centers is growing rapidly,\\u00a0calibrating the right level of investment is tricky. High levels of growth come\\u00a0with high levels of hype that can lead analysts to overestimate future demand. For example, Microsoft, after examining\\u00a0its forecasts,canceleddata-center projects that would have consumed 2 gigawatts.\"}"
  },
  "events": [
    {
      "name": "exception",
      "timestamp": "2025-06-22T12:11:40.089301Z",
      "attributes": {
        "exception.type": "TypeError",
        "exception.message": "LangfuseSpanWrapper.update_trace() got an unexpected keyword argument 'error'",
        "exception.stacktrace": "Traceback (most recent call last):\n  File \"/opt/***/dags/deeplearning_ai/summary_gemini.py\", line 139, in create_bullet_summary\n    with self.lf.observation(\n         ^^^^^^^^^^^^^^^^^^^\nAttributeError: 'Langfuse' object has no attribute 'observation'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/***/.local/lib/python3.12/site-packages/opentelemetry/trace/__init__.py\", line 589, in use_span\n    yield span\n  File \"/home/***/.local/lib/python3.12/site-packages/opentelemetry/sdk/trace/__init__.py\", line 1105, in start_as_current_span\n    yield span\n  File \"/home/***/.local/lib/python3.12/site-packages/langfuse/_client/client.py\", line 718, in _start_as_current_otel_span_with_processed_media\n    yield (\n  File \"/opt/***/dags/deeplearning_ai/summary_gemini.py\", line 157, in create_bullet_summary\n    span.update_trace(error={\"message\": str(e)})\nTypeError: LangfuseSpanWrapper.update_trace() got an unexpected keyword argument 'error'\n",
        "exception.escaped": "False"
      }
    }
  ],
  "links": [],
  "resource": {
    "attributes": {
      "telemetry.sdk.language": "python",
      "telemetry.sdk.name": "opentelemetry",
      "telemetry.sdk.version": "1.34.1",
      "service.name": "unknown_service"
    },
    "schema_url": ""
  },
  "instrumentationScope": {
    "name": "langfuse-sdk",
    "version": "3.0.3",
    "schema_url": "",
    "attributes": {
      "public_key": "pk-lf-1f10d355-392c-4cb4-903c-7e9d2910b10e"
    }
  }
}

[2025-06-22T12:11:40.278+0000] {crawler_deeplai.py:438} ERROR - L·ªói khi crawl https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/: LangfuseSpanWrapper.update_trace() got an unexpected keyword argument 'error'
[2025-06-22T12:11:40.279+0000] {crawler_deeplai.py:492} WARNING -     ‚ùå Kh√¥ng th·ªÉ crawl: https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/
[2025-06-22T12:11:40.361+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:11:41.280+0000] {crawler_deeplai.py:503} INFO - ‚è±Ô∏è T·ªïng th·ªùi gian crawl: 8.35 gi√¢y
[2025-06-22T12:11:41.280+0000] {crawler_deeplai.py:504} INFO - üìä Th√†nh c√¥ng crawl: 0/1 b√†i vi·∫øt
[2025-06-22T12:11:41.281+0000] {crawler_deeplai.py:533} INFO - ‚ÑπÔ∏è Kh√¥ng c√≥ b√†i vi·∫øt ƒë·ªÉ l∆∞u v√†o collection 'hardware'
[2025-06-22T12:11:41.339+0000] {resource_manager.py:361} DEBUG - Successfully flushed OTEL tracer provider
[2025-06-22T12:11:41.340+0000] {resource_manager.py:364} DEBUG - Successfully flushed score ingestion queue
[2025-06-22T12:11:41.340+0000] {resource_manager.py:367} DEBUG - Successfully flushed media upload queue
[2025-06-22T12:11:41.362+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:11:42.341+0000] {dags.py:188} INFO - Ho√†n th√†nh crawl category: hardware
[2025-06-22T12:11:42.343+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-06-22T12:11:42.343+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-06-22T12:11:42.358+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=deepai_crawler_10min, task_id=crawl_hardware, run_id=manual__2025-06-22T12:11:23.650925+00:00, execution_date=20250622T121123, start_date=20250622T121132, end_date=20250622T121142
[2025-06-22T12:11:42.363+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T12:11:42.439+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-06-22T12:11:42.464+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-06-22T12:11:42.467+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
