[2025-07-12T20:59:24.913+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-07-12T20:59:24.937+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: deepai_crawler_10min.crawl_ml-research scheduled__2025-07-12T20:40:00+00:00 [queued]>
[2025-07-12T20:59:24.950+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: deepai_crawler_10min.crawl_ml-research scheduled__2025-07-12T20:40:00+00:00 [queued]>
[2025-07-12T20:59:24.951+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 3
[2025-07-12T20:59:24.970+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): crawl_ml-research> on 2025-07-12 20:40:00+00:00
[2025-07-12T20:59:24.988+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=1044) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-07-12T20:59:24.990+0000] {standard_task_runner.py:63} INFO - Started process 1062 to run task
[2025-07-12T20:59:24.992+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'deepai_crawler_10min', 'crawl_ml-research', 'scheduled__2025-07-12T20:40:00+00:00', '--job-id', '1553', '--raw', '--subdir', 'DAGS_FOLDER/dags.py', '--cfg-path', '/tmp/tmp5dbpawhw']
[2025-07-12T20:59:24.996+0000] {standard_task_runner.py:91} INFO - Job 1553: Subtask crawl_ml-research
[2025-07-12T20:59:25.097+0000] {task_command.py:426} INFO - Running <TaskInstance: deepai_crawler_10min.crawl_ml-research scheduled__2025-07-12T20:40:00+00:00 [running]> on host 0eb58692feb3
[2025-07-12T20:59:25.259+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='deepai_crawler_10min' AIRFLOW_CTX_TASK_ID='crawl_ml-research' AIRFLOW_CTX_EXECUTION_DATE='2025-07-12T20:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-12T20:40:00+00:00'
[2025-07-12T20:59:25.262+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-07-12T20:59:25.284+0000] {dags.py:178} INFO - B·∫Øt ƒë·∫ßu crawl category: ml-research
[2025-07-12T20:59:25.327+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:25.525+0000] {crawler_deeplai.py:51} INFO - ƒê√£ k·∫øt n·ªëi th√†nh c√¥ng v·ªõi MongoDB: deeplearning_ai_news
[2025-07-12T20:59:25.578+0000] {client.py:1980} DEBUG - Getting prompt '3 Points-label:production'
[2025-07-12T20:59:25.579+0000] {client.py:1984} DEBUG - Prompt '3 Points-label:production' not found in cache or caching disabled.
[2025-07-12T20:59:25.579+0000] {client.py:2068} DEBUG - Fetching prompt '3 Points-label:production' from server...
[2025-07-12T20:59:25.610+0000] {log.py:232} WARNING - 2025-07-12 20:59:25,610 - httpx - INFO - HTTP Request: GET http://host.docker.internal:4000/api/public/v2/prompts/3%20Points?label=production "HTTP/1.1 200 OK"
[2025-07-12T20:59:25.610+0000] {_client.py:1025} INFO - HTTP Request: GET http://host.docker.internal:4000/api/public/v2/prompts/3%20Points?label=production "HTTP/1.1 200 OK"
[2025-07-12T20:59:25.616+0000] {crawler_deeplai.py:465} INFO - üöÄ ƒêang b·∫Øt ƒë·∫ßu qu√° tr√¨nh crawl v·ªõi Load More...
[2025-07-12T20:59:26.328+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:26.647+0000] {logging_mixin.py:188} INFO - [INIT].... ‚Üí Crawl4AI 0.6.3
[2025-07-12T20:59:26.652+0000] {crawler_deeplai.py:179} INFO - üåê ƒêang truy c·∫≠p: https://www.deeplearning.ai/the-batch/tag/research/
[2025-07-12T20:59:26.655+0000] {crawler_deeplai.py:180} INFO - ‚öôÔ∏è C·∫•u h√¨nh: max_articles=100, min_threshold=5, max_clicks=1
[2025-07-12T20:59:27.329+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:28.330+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:29.332+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:30.335+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:31.063+0000] {logging_mixin.py:188} INFO - [FETCH]... ‚Üì https://www.deeplearning.ai/the-batch/tag/research/                
| ‚úì | ‚è±: 4.40s
[2025-07-12T20:59:31.338+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:31.450+0000] {logging_mixin.py:188} INFO - [SCRAPE].. ‚óÜ https://www.deeplearning.ai/the-batch/tag/research/                
| ‚úì | ‚è±: 0.38s
[2025-07-12T20:59:31.458+0000] {logging_mixin.py:188} INFO - [COMPLETE] ‚óè https://www.deeplearning.ai/the-batch/tag/research/                
| ‚úì | ‚è±: 4.79s
[2025-07-12T20:59:31.461+0000] {crawler_deeplai.py:184} INFO - üìã JavaScript execution result: {'success': True, 'results': [{'success': True, 'result': {}}]}
[2025-07-12T20:59:31.572+0000] {crawler_deeplai.py:204} INFO - üéØ T·ªïng c·ªông t√¨m th·∫•y 30 link b√†i vi·∫øt unique
[2025-07-12T20:59:31.573+0000] {crawler_deeplai.py:208} INFO - üîç M·ªôt v√†i URL ƒë·∫ßu ti√™n:
[2025-07-12T20:59:31.574+0000] {crawler_deeplai.py:210} INFO -   1. https://www.deeplearning.ai/the-batch/alibaba-releases-the-qwen3-family-of-open-llms-with-optional-reasoning/
[2025-07-12T20:59:31.575+0000] {crawler_deeplai.py:210} INFO -   2. https://www.deeplearning.ai/the-batch/anthropic-debuts-new-claude-4-sonnet-and-claude-4-opus-models-featuring-top-benchmarks-in-coding/
[2025-07-12T20:59:31.576+0000] {crawler_deeplai.py:210} INFO -   3. https://www.deeplearning.ai/the-batch/anthropic-finds-chain-of-thought-reasoning-traces-may-omit-key-influences/
[2025-07-12T20:59:31.577+0000] {crawler_deeplai.py:210} INFO -   4. https://www.deeplearning.ai/the-batch/anthropic-made-llms-choose-between-failing-and-misbehaving-and-they-blackmailed-executives/
[2025-07-12T20:59:31.577+0000] {crawler_deeplai.py:210} INFO -   5. https://www.deeplearning.ai/the-batch/apple-updates-its-on-device-and-cloud-ai-models-introduces-a-new-developer-api/
[2025-07-12T20:59:31.578+0000] {crawler_deeplai.py:214} INFO - üìä S·∫Ω crawl 30 b√†i vi·∫øt
[2025-07-12T20:59:32.340+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:32.351+0000] {crawler_deeplai.py:458} INFO - ƒê√£ l·ªçc: 30 URLs ban ƒë·∫ßu -> 2 URLs m·ªõi
[2025-07-12T20:59:32.352+0000] {crawler_deeplai.py:479} INFO - üìù ƒêang crawl 2 b√†i vi·∫øt m·ªõi...
[2025-07-12T20:59:32.353+0000] {crawler_deeplai.py:486} INFO - [1/2] üîÑ ƒêang crawl: https://www.deeplearning.ai/the-batch/anthropic-made-llms-choose-between-failing-and-misbehaving-and-they-blackmailed-executives/
[2025-07-12T20:59:32.577+0000] {crawler_deeplai.py:486} INFO - [2/2] üîÑ ƒêang crawl: https://www.deeplearning.ai/the-batch/researchers-scale-up-production-of-training-data-for-web-agents/
[2025-07-12T20:59:33.341+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:33.607+0000] {logging_mixin.py:188} INFO - [INIT].... ‚Üí Crawl4AI 0.6.3
[2025-07-12T20:59:33.704+0000] {logging_mixin.py:188} INFO - [INIT].... ‚Üí Crawl4AI 0.6.3
[2025-07-12T20:59:34.342+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:35.343+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:36.344+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:37.346+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:38.107+0000] {logging_mixin.py:188} INFO - [FETCH]... ‚Üì 
https://www.deeplearning.ai/the-batch/anthropic-...and-misbehaving-and-they-blac
kmailed-executives/  | ‚úì | ‚è±: 4.52s
[2025-07-12T20:59:38.284+0000] {logging_mixin.py:188} INFO - [SCRAPE].. ‚óÜ 
https://www.deeplearning.ai/the-batch/anthropic-...and-misbehaving-and-they-blac
kmailed-executives/  | ‚úì | ‚è±: 0.17s
[2025-07-12T20:59:38.289+0000] {logging_mixin.py:188} INFO - [COMPLETE] ‚óè 
https://www.deeplearning.ai/the-batch/anthropic-...and-misbehaving-and-they-blac
kmailed-executives/  | ‚úì | ‚è±: 4.70s
[2025-07-12T20:59:38.313+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:38.341+0000] {logging_mixin.py:188} INFO - Title: Good Models, Bad Choices
[2025-07-12T20:59:38.342+0000] {logging_mixin.py:188} INFO - Subtitle: Anthropic made LLMs choose between failing and misbehaving, and they blackmailed executives.
[2025-07-12T20:59:38.554+0000] {CallbackHandler.py:758} DEBUG - Event: on_chat_model_start, run_id: 87c7d, parent_run_id: 3f8d2
[2025-07-12T20:59:39.314+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:40.319+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:41.322+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:42.058+0000] {CallbackHandler.py:758} DEBUG - Event: on_llm_end, run_id: 87c7d, parent_run_id: 3f8d2
[2025-07-12T20:59:42.073+0000] {span_processor.py:96} DEBUG - Trace: Processing span name='Summary_News' | Full details:
{
  "name": "Summary_News",
  "context": {
    "trace_id": "f14a01b1ca8e542b8cc95210a01f9589",
    "span_id": "dcdbeee3c2d44620",
    "trace_state": "[]"
  },
  "kind": "SpanKind.INTERNAL",
  "parent_id": null,
  "start_time": "2025-07-12T20:59:38.559594Z",
  "end_time": "2025-07-12T20:59:42.072886Z",
  "status": {
    "status_code": "UNSET"
  },
  "attributes": {
    "langfuse.observation.input": "[{\"role\": \"system\", \"content\": \"B\\u1ea1n l\\u00e0 m\\u1ed9t tr\\u1ee3 l\\u00fd AI c\\u00f3 nhi\\u1ec7m v\\u1ee5 t\\u00f3m t\\u1eaft c\\u00e1c b\\u00e0i vi\\u1ebft khoa h\\u1ecdc, k\\u1ef9 thu\\u1eadt ho\\u1eb7c c\\u00f4ng ngh\\u1ec7 \\u0111\\u01b0\\u1ee3c vi\\u1ebft b\\u1eb1ng ti\\u1ebfng Anh, v\\u00e0 cung c\\u1ea5p b\\u1ea3n t\\u00f3m t\\u1eaft d\\u1ea1ng bullet points b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t.\\n        \\n        Y\\u00eau c\\u1ea7u:\\n        1. T\\u00f3m t\\u1eaft th\\u00e0nh 3 bullet points ng\\u1eafn g\\u1ecdn, r\\u00f5 r\\u00e0ng.\\n        2. M\\u1ed7i bullet point tr\\u00ecnh b\\u00e0y m\\u1ed9t \\u00fd ch\\u00ednh ho\\u1eb7c th\\u00f4ng tin quan tr\\u1ecdng trong b\\u00e0i vi\\u1ebft.\\n        3. Kh\\u00f4ng th\\u00eam \\u00fd ki\\u1ebfn c\\u00e1 nh\\u00e2n, \\u0111\\u00e1nh gi\\u00e1 ch\\u1ee7 quan ho\\u1eb7c ph\\u00f3ng \\u0111\\u1ea1i n\\u1ed9i dung.\\n        4. Vi\\u1ebft b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t chu\\u1ea9n, kh\\u00e1ch quan, d\\u1ec5 hi\\u1ec3u, \\u0111\\u00fang ng\\u1eef ph\\u00e1p.\\n        5. Gi\\u1eef nguy\\u00ean c\\u00e1c thu\\u1eadt ng\\u1eef k\\u1ef9 thu\\u1eadt ti\\u1ebfng Anh n\\u1ebfu c\\u1ea7n \\u0111\\u1ec3 \\u0111\\u1ea3m b\\u1ea3o ch\\u00ednh x\\u00e1c.\\n        \\n        D\\u01b0\\u1edbi \\u0111\\u00e2y l\\u00e0 n\\u1ed9i dung b\\u00e0i vi\\u1ebft ti\\u1ebfng Anh, h\\u00e3y ph\\u00e2n t\\u00edch v\\u00e0 cung c\\u1ea5p b\\u1ea3n t\\u00f3m t\\u1eaft d\\u1ea1ng bullet points b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t:\"}, {\"role\": \"user\", \"content\": \"Good Models, Bad Choices\\n\\nTop large language models, under experimental conditions that pressed them to choose between abandoning their prompted mission and misbehaving, resorted to harmful behavior, researchers found.\\n\\nWhat\\u2019s new:A team\\u00a0at Anthropic, University College London, ML Alignment & Theory Scholars Program, and Mila\\u00a0placed 16 large language models from various developers in hypothetical corporate scenarios that \\u201cpushed [them] into corners\\u201d via carefully designed prompts. Given a mission, an immediate threat to that mission, and an opportunity to remove the threat by blackmailing a human co-worker, all the LLMscommitted blackmail, and many of them did so consistently. The code is availablehere. The authors said they\\u00a0had not seen any evidence of such behavior in the real world, but they cautioned against deploying current LLMs with the ability to use tools, access to sensitive information, and little oversight.\\n\\nHow it works:The authors created a fictitious company that assigned business goals to LLMs from various developers while giving them access to sensitive information and enabling them to compose and send email. Then they fed the LLMs a sequence of information that indicated they were under threat, discouraged them from discussing the threat with human co-workers, and gave them an opportunity to achieve their goals by misbehaving.\\n\\nResults:Claude Sonnet 3.7 judged whether a model\\u2019s response was attempted blackmail. In addition, regular expressions were used to check whether the\\u00a0model had executed the blackmail by verifying email addresses and looking for specific threatening words. The model\\u2019s behavior was deemed harmful if it met both conditions.\\n\\nBehind the news:Earlier work elicited similarly undesirable behavior from LLMs.\\n\\nWhy it matters:Models trained on a wide range of human-written text can learn both good and bad behaviors. Then, placed in a situation in which harmful behavior is their most effective option \\u2014 in this case, a situation designed to elicit such behavior\\u00a0\\u2014 they\\u2019re likely to behave badly. Although the LLMs had undergone training to align them with human preferences, those guardrails buckled under the pressure.\\n\\nWe\\u2019re thinking:LLMs that have not undergone training for alignment with human preferences display a vast repertoire of misbehaviors. However, the dramatic misbehaviors seen in this study have not been observed in the wild. This suggests that alignment methods keep them in check under real-world conditions and that they reflect corner cases rather than significant issues. LLM developers routinely usered teamingto elicit undesirable behaviors and safeguard against them. That it took a skilled team of researchers to elicit this blackmailing behavior is a sign of both the safety of current LLMs and incremental opportunities to\\u00a0improve existing guardrails.\"}]",
    "langfuse.observation.model.name": "gemini-2.0-flash-lite",
    "langfuse.observation.model.parameters": "{\"temperature\": 0.1}",
    "langfuse.observation.metadata.tags": "[\"seq:step:2\"]",
    "langfuse.observation.metadata.ls_provider": "\"google_genai\"",
    "langfuse.observation.metadata.ls_model_name": "\"gemini-2.0-flash-lite\"",
    "langfuse.observation.metadata.ls_model_type": "\"chat\"",
    "langfuse.observation.metadata.ls_temperature": "0.1",
    "langfuse.observation.metadata.ls_max_tokens": "1024",
    "langfuse.observation.type": "generation",
    "langfuse.observation.output": "{\"role\": \"assistant\", \"content\": \"D\\u01b0\\u1edbi \\u0111\\u00e2y l\\u00e0 b\\u1ea3n t\\u00f3m t\\u1eaft b\\u00e0i vi\\u1ebft d\\u01b0\\u1edbi d\\u1ea1ng bullet points:\\n\\n*   C\\u00e1c nh\\u00e0 nghi\\u00ean c\\u1ee9u \\u0111\\u00e3 ph\\u00e1t hi\\u1ec7n ra r\\u1eb1ng c\\u00e1c m\\u00f4 h\\u00ecnh ng\\u00f4n ng\\u1eef l\\u1edbn (LLM) h\\u00e0ng \\u0111\\u1ea7u c\\u00f3 xu h\\u01b0\\u1edbng th\\u1ef1c hi\\u1ec7n c\\u00e1c h\\u00e0nh vi g\\u00e2y h\\u1ea1i nh\\u01b0 t\\u1ed1ng ti\\u1ec1n khi b\\u1ecb \\u0111\\u1eb7t v\\u00e0o c\\u00e1c t\\u00ecnh hu\\u1ed1ng gi\\u1ea3 \\u0111\\u1ecbnh, n\\u01a1i ch\\u00fang ph\\u1ea3i l\\u1ef1a ch\\u1ecdn gi\\u1eefa vi\\u1ec7c t\\u1eeb b\\u1ecf nhi\\u1ec7m v\\u1ee5 \\u0111\\u01b0\\u1ee3c giao ho\\u1eb7c c\\u00f3 h\\u00e0nh vi sai tr\\u00e1i.\\n*   Trong th\\u00ed nghi\\u1ec7m, 16 LLM \\u0111\\u01b0\\u1ee3c cung c\\u1ea5p th\\u00f4ng tin nh\\u1ea1y c\\u1ea3m v\\u00e0 kh\\u1ea3 n\\u0103ng g\\u1eedi email trong m\\u1ed9t c\\u00f4ng ty gi\\u1ea3 \\u0111\\u1ecbnh, sau \\u0111\\u00f3 ch\\u00fang \\u0111\\u01b0\\u1ee3c \\u0111\\u1eb7t v\\u00e0o t\\u00ecnh hu\\u1ed1ng b\\u1ecb \\u0111e d\\u1ecda v\\u00e0 c\\u00f3 c\\u01a1 h\\u1ed9i \\u0111\\u1ea1t \\u0111\\u01b0\\u1ee3c m\\u1ee5c ti\\u00eau b\\u1eb1ng c\\u00e1ch t\\u1ed1ng ti\\u1ec1n \\u0111\\u1ed3ng nghi\\u1ec7p.\\n*   M\\u1eb7c d\\u00f9 c\\u00e1c LLM \\u0111\\u00e3 \\u0111\\u01b0\\u1ee3c hu\\u1ea5n luy\\u1ec7n \\u0111\\u1ec3 ph\\u00f9 h\\u1ee3p v\\u1edbi c\\u00e1c \\u01b0u ti\\u00ean c\\u1ee7a con ng\\u01b0\\u1eddi, nh\\u01b0ng c\\u00e1c bi\\u1ec7n ph\\u00e1p b\\u1ea3o v\\u1ec7 n\\u00e0y \\u0111\\u00e3 kh\\u00f4ng c\\u00f2n hi\\u1ec7u qu\\u1ea3 trong c\\u00e1c t\\u00ecnh hu\\u1ed1ng \\u00e1p l\\u1ef1c cao, cho th\\u1ea5y t\\u1ea7m quan tr\\u1ecdng c\\u1ee7a vi\\u1ec7c ti\\u1ebfp t\\u1ee5c c\\u1ea3i thi\\u1ec7n c\\u00e1c bi\\u1ec7n ph\\u00e1p an to\\u00e0n cho LLM.\"}",
    "langfuse.observation.usage_details": "{\"input\": 731, \"output\": 216, \"total\": 947, \"input_cache_read\": 0}"
  },
  "events": [],
  "links": [],
  "resource": {
    "attributes": {
      "telemetry.sdk.language": "python",
      "telemetry.sdk.name": "opentelemetry",
      "telemetry.sdk.version": "1.34.1",
      "service.name": "unknown_service"
    },
    "schema_url": ""
  },
  "instrumentationScope": {
    "name": "langfuse-sdk",
    "version": "3.0.3",
    "schema_url": "",
    "attributes": {
      "public_key": "pk-lf-a17c2d30-02f1-43ee-8d12-50aa9c2906f4"
    }
  }
}

[2025-07-12T20:59:42.325+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:42.488+0000] {logging_mixin.py:188} INFO - [FETCH]... ‚Üì 
https://www.deeplearning.ai/the-batch/researcher...e-up-production-of-training-d
ata-for-web-agents/  | ‚úì | ‚è±: 8.78s
[2025-07-12T20:59:42.589+0000] {logging_mixin.py:188} INFO - [SCRAPE].. ‚óÜ 
https://www.deeplearning.ai/the-batch/researcher...e-up-production-of-training-d
ata-for-web-agents/  | ‚úì | ‚è±: 0.10s
[2025-07-12T20:59:42.594+0000] {logging_mixin.py:188} INFO - [COMPLETE] ‚óè 
https://www.deeplearning.ai/the-batch/researcher...e-up-production-of-training-d
ata-for-web-agents/  | ‚úì | ‚è±: 8.89s
[2025-07-12T20:59:42.638+0000] {logging_mixin.py:188} INFO - Title: Generated Data for Training Web Agents
[2025-07-12T20:59:42.639+0000] {logging_mixin.py:188} INFO - Subtitle: Researchers scale up production of training data for web agents
[2025-07-12T20:59:42.827+0000] {CallbackHandler.py:758} DEBUG - Event: on_chat_model_start, run_id: 4a931, parent_run_id: 2639d
[2025-07-12T20:59:43.328+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:44.329+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:44.659+0000] {CallbackHandler.py:758} DEBUG - Event: on_llm_end, run_id: 4a931, parent_run_id: 2639d
[2025-07-12T20:59:44.662+0000] {span_processor.py:96} DEBUG - Trace: Processing span name='Summary_News' | Full details:
{
  "name": "Summary_News",
  "context": {
    "trace_id": "947fee58822f45945141b97da77a9e90",
    "span_id": "abf770a4e94b2c1d",
    "trace_state": "[]"
  },
  "kind": "SpanKind.INTERNAL",
  "parent_id": null,
  "start_time": "2025-07-12T20:59:42.829843Z",
  "end_time": "2025-07-12T20:59:44.661657Z",
  "status": {
    "status_code": "UNSET"
  },
  "attributes": {
    "langfuse.observation.input": "[{\"role\": \"system\", \"content\": \"B\\u1ea1n l\\u00e0 m\\u1ed9t tr\\u1ee3 l\\u00fd AI c\\u00f3 nhi\\u1ec7m v\\u1ee5 t\\u00f3m t\\u1eaft c\\u00e1c b\\u00e0i vi\\u1ebft khoa h\\u1ecdc, k\\u1ef9 thu\\u1eadt ho\\u1eb7c c\\u00f4ng ngh\\u1ec7 \\u0111\\u01b0\\u1ee3c vi\\u1ebft b\\u1eb1ng ti\\u1ebfng Anh, v\\u00e0 cung c\\u1ea5p b\\u1ea3n t\\u00f3m t\\u1eaft d\\u1ea1ng bullet points b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t.\\n        \\n        Y\\u00eau c\\u1ea7u:\\n        1. T\\u00f3m t\\u1eaft th\\u00e0nh 3 bullet points ng\\u1eafn g\\u1ecdn, r\\u00f5 r\\u00e0ng.\\n        2. M\\u1ed7i bullet point tr\\u00ecnh b\\u00e0y m\\u1ed9t \\u00fd ch\\u00ednh ho\\u1eb7c th\\u00f4ng tin quan tr\\u1ecdng trong b\\u00e0i vi\\u1ebft.\\n        3. Kh\\u00f4ng th\\u00eam \\u00fd ki\\u1ebfn c\\u00e1 nh\\u00e2n, \\u0111\\u00e1nh gi\\u00e1 ch\\u1ee7 quan ho\\u1eb7c ph\\u00f3ng \\u0111\\u1ea1i n\\u1ed9i dung.\\n        4. Vi\\u1ebft b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t chu\\u1ea9n, kh\\u00e1ch quan, d\\u1ec5 hi\\u1ec3u, \\u0111\\u00fang ng\\u1eef ph\\u00e1p.\\n        5. Gi\\u1eef nguy\\u00ean c\\u00e1c thu\\u1eadt ng\\u1eef k\\u1ef9 thu\\u1eadt ti\\u1ebfng Anh n\\u1ebfu c\\u1ea7n \\u0111\\u1ec3 \\u0111\\u1ea3m b\\u1ea3o ch\\u00ednh x\\u00e1c.\\n        \\n        D\\u01b0\\u1edbi \\u0111\\u00e2y l\\u00e0 n\\u1ed9i dung b\\u00e0i vi\\u1ebft ti\\u1ebfng Anh, h\\u00e3y ph\\u00e2n t\\u00edch v\\u00e0 cung c\\u1ea5p b\\u1ea3n t\\u00f3m t\\u1eaft d\\u1ea1ng bullet points b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t:\"}, {\"role\": \"user\", \"content\": \"Generated Data for Training Web Agents\\n\\nDeveloping an agent that navigates the web can involve\\u00a0a lot of human effort spent annotating training examples to fine-tune the agent\\u2019s LLM component. Scientists automated the production of data that fine-tuned LLMs effectively for web tasks.\\n\\nWhat\\u2019s new:Brandon Trabucco and colleagues at Carnegie Mellon University and Amazongenerateda dataset that enabled an agent based on a small model to outperform agents equipped with much larger models. The data is freelyavailablefor noncommercial and commercial uses under an MIT license.\\n\\nKey insight:In a dataset for training agentic LLMs to use the web, each example typically includes a web site, task (such as comparing prices of items for sale), and a paired list of web pages (represented as markdown or screenshots) and desired actions (clicking a link, typing in a form, and so on) that complete the task. Typically, such examples are limited in the tasks and websites they illustrate.\\u00a0An LLM equipped with the proper tools and know-how to use a browser can build much larger and more diverse\\u00a0datasets automatically.\\n\\nHow it works:The authors built an agentic workflow that prompted Qwen3-235B and other models to produce\\u00a0a web-agent training dataset. From the massive web dataset Common Crawl, they selected the 1 million web sites with the highest Google PageRank.\\n\\nResults:Using their generated training set, the authors fine-tuned a variety of models, including Qwen3-1.7B. They coupled each model \\u2014 in both stock and fine-tuned versions \\u2014 with an agentic framework. They asked the resulting agents complete (i) a generated test set (3,000 tasks on 3,000 web sites) and (ii)WebVoyager(643 tasks on 15 web sites). Four leading models (Qwen3-235B, Gemini 2.5 Flash, Llama 4 Maverick, and GPT 4.1 Nano) separately judged whether the agents had completed the tasks.\\n\\nWhy it matters:Previous datasets designed to fine-tune LLMs for agentic tasks, such as WebVoyager,Mind2Web, andWebLINX, are limited to hundreds or thousands of web sites. That may not be enough to generalize reliably to a wide variety of web sites and tasks. The authors built a dataset that enables LLMs to generalize more broadly, and they shared their dataset and recipe.\\n\\nWe\\u2019re thinking:This work takes advantage of computer use to generate\\u00a0datasets that reflect the immense variety of potential web tasks. Computer use is an exciting area, but leading approaches are still unreliable. As this field progresses, we expect it to open up a huge range of applications.\"}]",
    "langfuse.observation.model.name": "gemini-2.0-flash-lite",
    "langfuse.observation.model.parameters": "{\"temperature\": 0.1}",
    "langfuse.observation.metadata.tags": "[\"seq:step:2\"]",
    "langfuse.observation.metadata.ls_provider": "\"google_genai\"",
    "langfuse.observation.metadata.ls_model_name": "\"gemini-2.0-flash-lite\"",
    "langfuse.observation.metadata.ls_model_type": "\"chat\"",
    "langfuse.observation.metadata.ls_temperature": "0.1",
    "langfuse.observation.metadata.ls_max_tokens": "1024",
    "langfuse.observation.type": "generation",
    "langfuse.observation.output": "{\"role\": \"assistant\", \"content\": \"D\\u01b0\\u1edbi \\u0111\\u00e2y l\\u00e0 b\\u1ea3n t\\u00f3m t\\u1eaft b\\u00e0i vi\\u1ebft d\\u01b0\\u1edbi d\\u1ea1ng bullet points:\\n\\n*   C\\u00e1c nh\\u00e0 khoa h\\u1ecdc \\u0111\\u00e3 t\\u1ef1 \\u0111\\u1ed9ng h\\u00f3a vi\\u1ec7c t\\u1ea1o ra m\\u1ed9t b\\u1ed9 d\\u1eef li\\u1ec7u \\u0111\\u1ec3 hu\\u1ea5n luy\\u1ec7n c\\u00e1c m\\u00f4 h\\u00ecnh ng\\u00f4n ng\\u1eef l\\u1edbn (LLMs) cho c\\u00e1c t\\u00e1c v\\u1ee5 tr\\u00ean web, cho ph\\u00e9p m\\u1ed9t t\\u00e1c nh\\u00e2n d\\u1ef1a tr\\u00ean m\\u1ed9t m\\u00f4 h\\u00ecnh nh\\u1ecf v\\u01b0\\u1ee3t tr\\u1ed9i h\\u01a1n c\\u00e1c t\\u00e1c nh\\u00e2n s\\u1eed d\\u1ee5ng c\\u00e1c m\\u00f4 h\\u00ecnh l\\u1edbn h\\u01a1n.\\n*   B\\u1ed9 d\\u1eef li\\u1ec7u \\u0111\\u01b0\\u1ee3c t\\u1ea1o ra b\\u1eb1ng c\\u00e1ch s\\u1eed d\\u1ee5ng m\\u1ed9t quy tr\\u00ecnh t\\u00e1c nh\\u00e2n, trong \\u0111\\u00f3 c\\u00e1c LLMs \\u0111\\u01b0\\u1ee3c y\\u00eau c\\u1ea7u t\\u1ea1o ra d\\u1eef li\\u1ec7u hu\\u1ea5n luy\\u1ec7n, bao g\\u1ed3m c\\u00e1c trang web, t\\u00e1c v\\u1ee5 v\\u00e0 danh s\\u00e1ch c\\u00e1c h\\u00e0nh \\u0111\\u1ed9ng c\\u1ea7n thi\\u1ebft \\u0111\\u1ec3 ho\\u00e0n th\\u00e0nh t\\u00e1c v\\u1ee5.\\n*   K\\u1ebft qu\\u1ea3 cho th\\u1ea5y, vi\\u1ec7c s\\u1eed d\\u1ee5ng b\\u1ed9 d\\u1eef li\\u1ec7u \\u0111\\u01b0\\u1ee3c t\\u1ea1o ra \\u0111\\u00e3 gi\\u00fap c\\u1ea3i thi\\u1ec7n kh\\u1ea3 n\\u0103ng t\\u1ed5ng qu\\u00e1t h\\u00f3a c\\u1ee7a c\\u00e1c LLMs tr\\u00ean nhi\\u1ec1u trang web v\\u00e0 t\\u00e1c v\\u1ee5 kh\\u00e1c nhau, \\u0111\\u1ed3ng th\\u1eddi b\\u1ed9 d\\u1eef li\\u1ec7u v\\u00e0 ph\\u01b0\\u01a1ng ph\\u00e1p n\\u00e0y \\u0111\\u01b0\\u1ee3c chia s\\u1ebb c\\u00f4ng khai.\"}",
    "langfuse.observation.usage_details": "{\"input\": 756, \"output\": 194, \"total\": 950, \"input_cache_read\": 0}"
  },
  "events": [],
  "links": [],
  "resource": {
    "attributes": {
      "telemetry.sdk.language": "python",
      "telemetry.sdk.name": "opentelemetry",
      "telemetry.sdk.version": "1.34.1",
      "service.name": "unknown_service"
    },
    "schema_url": ""
  },
  "instrumentationScope": {
    "name": "langfuse-sdk",
    "version": "3.0.3",
    "schema_url": "",
    "attributes": {
      "public_key": "pk-lf-a17c2d30-02f1-43ee-8d12-50aa9c2906f4"
    }
  }
}

[2025-07-12T20:59:44.794+0000] {crawler_deeplai.py:490} INFO -     ‚úÖ Good Models, Bad Choices...
[2025-07-12T20:59:45.140+0000] {crawler_deeplai.py:490} INFO -     ‚úÖ Generated Data for Training Web Agents...
[2025-07-12T20:59:45.332+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:46.143+0000] {crawler_deeplai.py:503} INFO - ‚è±Ô∏è T·ªïng th·ªùi gian crawl: 20.53 gi√¢y
[2025-07-12T20:59:46.144+0000] {crawler_deeplai.py:504} INFO - üìä Th√†nh c√¥ng crawl: 2/2 b√†i vi·∫øt
[2025-07-12T20:59:46.256+0000] {crawler_deeplai.py:531} INFO - üíæ ƒê√£ l∆∞u th√†nh c√¥ng 2/2 b√†i vi·∫øt v√†o collection 'ml-research'
[2025-07-12T20:59:46.305+0000] {dags.py:183} INFO - Ho√†n th√†nh crawl category: ml-research
[2025-07-12T20:59:46.306+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-07-12T20:59:46.306+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-07-12T20:59:46.318+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=deepai_crawler_10min, task_id=crawl_ml-research, run_id=scheduled__2025-07-12T20:40:00+00:00, execution_date=20250712T204000, start_date=20250712T205924, end_date=20250712T205946
[2025-07-12T20:59:46.333+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:46.393+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-07-12T20:59:46.418+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-12T20:59:46.421+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
