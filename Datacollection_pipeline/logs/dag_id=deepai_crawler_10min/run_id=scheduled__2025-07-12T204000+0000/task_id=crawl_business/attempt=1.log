[2025-07-12T20:59:00.115+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-07-12T20:59:00.175+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: deepai_crawler_10min.crawl_business scheduled__2025-07-12T20:40:00+00:00 [queued]>
[2025-07-12T20:59:00.202+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: deepai_crawler_10min.crawl_business scheduled__2025-07-12T20:40:00+00:00 [queued]>
[2025-07-12T20:59:00.204+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 3
[2025-07-12T20:59:00.313+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): crawl_business> on 2025-07-12 20:40:00+00:00
[2025-07-12T20:59:00.352+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=752) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-07-12T20:59:00.371+0000] {standard_task_runner.py:63} INFO - Started process 759 to run task
[2025-07-12T20:59:00.363+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'deepai_crawler_10min', 'crawl_business', 'scheduled__2025-07-12T20:40:00+00:00', '--job-id', '1552', '--raw', '--subdir', 'DAGS_FOLDER/dags.py', '--cfg-path', '/tmp/tmphizsazgi']
[2025-07-12T20:59:00.375+0000] {standard_task_runner.py:91} INFO - Job 1552: Subtask crawl_business
[2025-07-12T20:59:00.581+0000] {task_command.py:426} INFO - Running <TaskInstance: deepai_crawler_10min.crawl_business scheduled__2025-07-12T20:40:00+00:00 [running]> on host 0eb58692feb3
[2025-07-12T20:59:00.645+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:01.106+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='deepai_crawler_10min' AIRFLOW_CTX_TASK_ID='crawl_business' AIRFLOW_CTX_EXECUTION_DATE='2025-07-12T20:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-12T20:40:00+00:00'
[2025-07-12T20:59:01.107+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-07-12T20:59:01.125+0000] {dags.py:178} INFO - B·∫Øt ƒë·∫ßu crawl category: business
[2025-07-12T20:59:01.520+0000] {crawler_deeplai.py:51} INFO - ƒê√£ k·∫øt n·ªëi th√†nh c√¥ng v·ªõi MongoDB: deeplearning_ai_news
[2025-07-12T20:59:01.597+0000] {client.py:1980} DEBUG - Getting prompt '3 Points-label:production'
[2025-07-12T20:59:01.598+0000] {client.py:1984} DEBUG - Prompt '3 Points-label:production' not found in cache or caching disabled.
[2025-07-12T20:59:01.599+0000] {client.py:2068} DEBUG - Fetching prompt '3 Points-label:production' from server...
[2025-07-12T20:59:01.647+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:01.878+0000] {log.py:232} WARNING - 2025-07-12 20:59:01,878 - httpx - INFO - HTTP Request: GET http://host.docker.internal:4000/api/public/v2/prompts/3%20Points?label=production "HTTP/1.1 200 OK"
[2025-07-12T20:59:01.878+0000] {_client.py:1025} INFO - HTTP Request: GET http://host.docker.internal:4000/api/public/v2/prompts/3%20Points?label=production "HTTP/1.1 200 OK"
[2025-07-12T20:59:01.885+0000] {crawler_deeplai.py:465} INFO - üöÄ ƒêang b·∫Øt ƒë·∫ßu qu√° tr√¨nh crawl v·ªõi Load More...
[2025-07-12T20:59:02.647+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:03.135+0000] {logging_mixin.py:188} INFO - [INIT].... ‚Üí Crawl4AI 0.6.3
[2025-07-12T20:59:03.152+0000] {crawler_deeplai.py:179} INFO - üåê ƒêang truy c·∫≠p: https://www.deeplearning.ai/the-batch/tag/business/
[2025-07-12T20:59:03.152+0000] {crawler_deeplai.py:180} INFO - ‚öôÔ∏è C·∫•u h√¨nh: max_articles=100, min_threshold=5, max_clicks=1
[2025-07-12T20:59:03.648+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:04.649+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:05.651+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:06.652+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:07.504+0000] {logging_mixin.py:188} INFO - [FETCH]... ‚Üì https://www.deeplearning.ai/the-batch/tag/business/                
| ‚úì | ‚è±: 4.35s
[2025-07-12T20:59:07.619+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:07.642+0000] {logging_mixin.py:188} INFO - [SCRAPE].. ‚óÜ https://www.deeplearning.ai/the-batch/tag/business/                
| ‚úì | ‚è±: 0.16s
[2025-07-12T20:59:07.645+0000] {logging_mixin.py:188} INFO - [COMPLETE] ‚óè https://www.deeplearning.ai/the-batch/tag/business/                
| ‚úì | ‚è±: 4.52s
[2025-07-12T20:59:07.646+0000] {crawler_deeplai.py:184} INFO - üìã JavaScript execution result: {'success': True, 'results': [{'success': True, 'result': {}}]}
[2025-07-12T20:59:07.705+0000] {crawler_deeplai.py:204} INFO - üéØ T·ªïng c·ªông t√¨m th·∫•y 30 link b√†i vi·∫øt unique
[2025-07-12T20:59:07.706+0000] {crawler_deeplai.py:208} INFO - üîç M·ªôt v√†i URL ƒë·∫ßu ti√™n:
[2025-07-12T20:59:07.706+0000] {crawler_deeplai.py:210} INFO -   1. https://www.deeplearning.ai/the-batch/ai-agents-and-infrastructure-dominate-cb-insights-top-100-ai-startups-list/
[2025-07-12T20:59:07.707+0000] {crawler_deeplai.py:210} INFO -   2. https://www.deeplearning.ai/the-batch/alexa-adds-generative-ai-and-agents-using-claude-and-other-models/
[2025-07-12T20:59:07.707+0000] {crawler_deeplai.py:210} INFO -   3. https://www.deeplearning.ai/the-batch/amazon-plans-to-spend-tens-of-billions-on-ai-infrastructure-with-project-rainier/
[2025-07-12T20:59:07.708+0000] {crawler_deeplai.py:210} INFO -   4. https://www.deeplearning.ai/the-batch/apple-updates-its-on-device-and-cloud-ai-models-introduces-a-new-developer-api/
[2025-07-12T20:59:07.708+0000] {crawler_deeplai.py:210} INFO -   5. https://www.deeplearning.ai/the-batch/claude-3-7-sonnet-introduces-hybrid-reasoning-and-extended-thinking/
[2025-07-12T20:59:07.709+0000] {crawler_deeplai.py:214} INFO - üìä S·∫Ω crawl 30 b√†i vi·∫øt
[2025-07-12T20:59:08.620+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:09.252+0000] {crawler_deeplai.py:458} INFO - ƒê√£ l·ªçc: 30 URLs ban ƒë·∫ßu -> 1 URLs m·ªõi
[2025-07-12T20:59:09.252+0000] {crawler_deeplai.py:479} INFO - üìù ƒêang crawl 1 b√†i vi·∫øt m·ªõi...
[2025-07-12T20:59:09.253+0000] {crawler_deeplai.py:486} INFO - [1/1] üîÑ ƒêang crawl: https://www.deeplearning.ai/the-batch/walmarts-element-platform-for-industrial-scale-ai-app-development-a-progress-report/
[2025-07-12T20:59:09.621+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:10.511+0000] {logging_mixin.py:188} INFO - [INIT].... ‚Üí Crawl4AI 0.6.3
[2025-07-12T20:59:10.622+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:11.623+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:12.624+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:13.627+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:13.714+0000] {logging_mixin.py:188} INFO - [FETCH]... ‚Üì 
https://www.deeplearning.ai/the-batch/walmarts-e...rial-scale-ai-app-development
-a-progress-report/  | ‚úì | ‚è±: 3.20s
[2025-07-12T20:59:13.823+0000] {logging_mixin.py:188} INFO - [SCRAPE].. ‚óÜ 
https://www.deeplearning.ai/the-batch/walmarts-e...rial-scale-ai-app-development
-a-progress-report/  | ‚úì | ‚è±: 0.10s
[2025-07-12T20:59:13.827+0000] {logging_mixin.py:188} INFO - [COMPLETE] ‚óè 
https://www.deeplearning.ai/the-batch/walmarts-e...rial-scale-ai-app-development
-a-progress-report/  | ‚úì | ‚è±: 3.31s
[2025-07-12T20:59:13.860+0000] {logging_mixin.py:188} INFO - Title: Inside Walmart‚Äôs AI App Factory
[2025-07-12T20:59:13.861+0000] {logging_mixin.py:188} INFO - Subtitle: Walmart‚Äôs Element platform for industrial-scale AI app development ‚Äî a progress report
[2025-07-12T20:59:13.972+0000] {CallbackHandler.py:758} DEBUG - Event: on_chat_model_start, run_id: 2fb60, parent_run_id: 6cb91
[2025-07-12T20:59:14.629+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:15.630+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:15.950+0000] {CallbackHandler.py:758} DEBUG - Event: on_llm_end, run_id: 2fb60, parent_run_id: 6cb91
[2025-07-12T20:59:15.953+0000] {span_processor.py:96} DEBUG - Trace: Processing span name='Summary_News' | Full details:
{
  "name": "Summary_News",
  "context": {
    "trace_id": "80387c63d9c1b528533937c7971bb5f5",
    "span_id": "1c90887b7b0b0ab2",
    "trace_state": "[]"
  },
  "kind": "SpanKind.INTERNAL",
  "parent_id": null,
  "start_time": "2025-07-12T20:59:13.973921Z",
  "end_time": "2025-07-12T20:59:15.952361Z",
  "status": {
    "status_code": "UNSET"
  },
  "attributes": {
    "langfuse.observation.input": "[{\"role\": \"system\", \"content\": \"B\\u1ea1n l\\u00e0 m\\u1ed9t tr\\u1ee3 l\\u00fd AI c\\u00f3 nhi\\u1ec7m v\\u1ee5 t\\u00f3m t\\u1eaft c\\u00e1c b\\u00e0i vi\\u1ebft khoa h\\u1ecdc, k\\u1ef9 thu\\u1eadt ho\\u1eb7c c\\u00f4ng ngh\\u1ec7 \\u0111\\u01b0\\u1ee3c vi\\u1ebft b\\u1eb1ng ti\\u1ebfng Anh, v\\u00e0 cung c\\u1ea5p b\\u1ea3n t\\u00f3m t\\u1eaft d\\u1ea1ng bullet points b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t.\\n        \\n        Y\\u00eau c\\u1ea7u:\\n        1. T\\u00f3m t\\u1eaft th\\u00e0nh 3 bullet points ng\\u1eafn g\\u1ecdn, r\\u00f5 r\\u00e0ng.\\n        2. M\\u1ed7i bullet point tr\\u00ecnh b\\u00e0y m\\u1ed9t \\u00fd ch\\u00ednh ho\\u1eb7c th\\u00f4ng tin quan tr\\u1ecdng trong b\\u00e0i vi\\u1ebft.\\n        3. Kh\\u00f4ng th\\u00eam \\u00fd ki\\u1ebfn c\\u00e1 nh\\u00e2n, \\u0111\\u00e1nh gi\\u00e1 ch\\u1ee7 quan ho\\u1eb7c ph\\u00f3ng \\u0111\\u1ea1i n\\u1ed9i dung.\\n        4. Vi\\u1ebft b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t chu\\u1ea9n, kh\\u00e1ch quan, d\\u1ec5 hi\\u1ec3u, \\u0111\\u00fang ng\\u1eef ph\\u00e1p.\\n        5. Gi\\u1eef nguy\\u00ean c\\u00e1c thu\\u1eadt ng\\u1eef k\\u1ef9 thu\\u1eadt ti\\u1ebfng Anh n\\u1ebfu c\\u1ea7n \\u0111\\u1ec3 \\u0111\\u1ea3m b\\u1ea3o ch\\u00ednh x\\u00e1c.\\n        \\n        D\\u01b0\\u1edbi \\u0111\\u00e2y l\\u00e0 n\\u1ed9i dung b\\u00e0i vi\\u1ebft ti\\u1ebfng Anh, h\\u00e3y ph\\u00e2n t\\u00edch v\\u00e0 cung c\\u1ea5p b\\u1ea3n t\\u00f3m t\\u1eaft d\\u1ea1ng bullet points b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t:\"}, {\"role\": \"user\", \"content\": \"Inside Walmart\\u2019s AI App Factory\\n\\nThe world\\u2019s biggest retailer by revenue revealed new details about its cloud- and model-agnostic AI application development platform.\\n\\nWhat\\u2019s new:Walmart\\u00a0Element is a wellspring of apps, built and managed internally, that serve retail store personnel. Company executivesdescribedthe system\\u2019s philosophy, architecture, and current generation of applications toVentureBeat.\\n\\nHow it works:Element enables an assembly-line approach to application development, in contrast to developing each app as a separate project.\\n\\nBehind the news:Walmart launched Element in 2022, emphasizing its vision of simplifying adoption of AI throughout the company. Early reportsoutlinedthe needs to centralize access to data, maintain independence with respect to cloud platforms, take advantage of technology as it evolved, and support the ability to scale up. They alsospecifiedthe system\\u2019s priorities: best-of-breed technology, speed and scale, cost efficiency, and governance.\\n\\nWhy it matters:Walmart \\u2014 not a tech company but a brick-and-mortar retailer \\u2014 recognized early both the benefits that AI could bring and the challenges of making it practical and productive. Rather than relying on external vendors, it built an development platform that remains in gear\\u00a0three years later. The system aggregates data generated by 240 million customers and 2 million store personnel, feeding\\u00a0applications that streamline operations among 100,000 suppliers, 150 distributors, and 10,000 retail venues in 19 countries.\\n\\nWe\\u2019re thinking:Walmart is a giant, and few other companies have the means (or need) to operate at this scale. Nonetheless, even companies an order of magnitude smaller by revenue might benefit from a similarly DIY approach to AI application development.\"}]",
    "langfuse.observation.model.name": "gemini-2.0-flash-lite",
    "langfuse.observation.model.parameters": "{\"temperature\": 0.1}",
    "langfuse.observation.metadata.tags": "[\"seq:step:2\"]",
    "langfuse.observation.metadata.ls_provider": "\"google_genai\"",
    "langfuse.observation.metadata.ls_model_name": "\"gemini-2.0-flash-lite\"",
    "langfuse.observation.metadata.ls_model_type": "\"chat\"",
    "langfuse.observation.metadata.ls_temperature": "0.1",
    "langfuse.observation.metadata.ls_max_tokens": "1024",
    "langfuse.observation.type": "generation",
    "langfuse.observation.output": "{\"role\": \"assistant\", \"content\": \"D\\u01b0\\u1edbi \\u0111\\u00e2y l\\u00e0 b\\u1ea3n t\\u00f3m t\\u1eaft b\\u00e0i vi\\u1ebft v\\u1ec1 n\\u1ec1n t\\u1ea3ng ph\\u00e1t tri\\u1ec3n \\u1ee9ng d\\u1ee5ng AI c\\u1ee7a Walmart:\\n\\n*   Walmart \\u0111\\u00e3 ti\\u1ebft l\\u1ed9 th\\u00f4ng tin chi ti\\u1ebft v\\u1ec1 Element, n\\u1ec1n t\\u1ea3ng ph\\u00e1t tri\\u1ec3n \\u1ee9ng d\\u1ee5ng AI n\\u1ed9i b\\u1ed9, ho\\u1ea1t \\u0111\\u1ed9ng \\u0111\\u1ed9c l\\u1eadp v\\u1edbi c\\u00e1c n\\u1ec1n t\\u1ea3ng \\u0111\\u00e1m m\\u00e2y v\\u00e0 m\\u00f4 h\\u00ecnh AI.\\n*   Element cho ph\\u00e9p ph\\u00e1t tri\\u1ec3n \\u1ee9ng d\\u1ee5ng theo quy tr\\u00ecnh, kh\\u00e1c v\\u1edbi c\\u00e1ch ph\\u00e1t tri\\u1ec3n t\\u1eebng \\u1ee9ng d\\u1ee5ng ri\\u00eang l\\u1ebb, nh\\u1eb1m \\u0111\\u01a1n gi\\u1ea3n h\\u00f3a vi\\u1ec7c \\u1ee9ng d\\u1ee5ng AI trong to\\u00e0n c\\u00f4ng ty.\\n*   N\\u1ec1n t\\u1ea3ng n\\u00e0y t\\u1ed5ng h\\u1ee3p d\\u1eef li\\u1ec7u t\\u1eeb 240 tri\\u1ec7u kh\\u00e1ch h\\u00e0ng v\\u00e0 2 tri\\u1ec7u nh\\u00e2n vi\\u00ean, h\\u1ed7 tr\\u1ee3 c\\u00e1c \\u1ee9ng d\\u1ee5ng gi\\u00fap t\\u1ed1i \\u01b0u h\\u00f3a ho\\u1ea1t \\u0111\\u1ed9ng v\\u1edbi 100.000 nh\\u00e0 cung c\\u1ea5p, 150 nh\\u00e0 ph\\u00e2n ph\\u1ed1i v\\u00e0 10.000 \\u0111\\u1ecba \\u0111i\\u1ec3m b\\u00e1n l\\u1ebb t\\u1ea1i 19 qu\\u1ed1c gia.\"}",
    "langfuse.observation.usage_details": "{\"input\": 553, \"output\": 179, \"total\": 732, \"input_cache_read\": 0}"
  },
  "events": [],
  "links": [],
  "resource": {
    "attributes": {
      "telemetry.sdk.language": "python",
      "telemetry.sdk.name": "opentelemetry",
      "telemetry.sdk.version": "1.34.1",
      "service.name": "unknown_service"
    },
    "schema_url": ""
  },
  "instrumentationScope": {
    "name": "langfuse-sdk",
    "version": "3.0.3",
    "schema_url": "",
    "attributes": {
      "public_key": "pk-lf-a17c2d30-02f1-43ee-8d12-50aa9c2906f4"
    }
  }
}

[2025-07-12T20:59:16.351+0000] {crawler_deeplai.py:490} INFO -     ‚úÖ Inside Walmart‚Äôs AI App Factory...
[2025-07-12T20:59:16.631+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:17.354+0000] {crawler_deeplai.py:503} INFO - ‚è±Ô∏è T·ªïng th·ªùi gian crawl: 15.47 gi√¢y
[2025-07-12T20:59:17.356+0000] {crawler_deeplai.py:504} INFO - üìä Th√†nh c√¥ng crawl: 1/1 b√†i vi·∫øt
[2025-07-12T20:59:17.416+0000] {crawler_deeplai.py:531} INFO - üíæ ƒê√£ l∆∞u th√†nh c√¥ng 1/1 b√†i vi·∫øt v√†o collection 'business'
[2025-07-12T20:59:17.466+0000] {dags.py:183} INFO - Ho√†n th√†nh crawl category: business
[2025-07-12T20:59:17.467+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-07-12T20:59:17.469+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-07-12T20:59:17.487+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=deepai_crawler_10min, task_id=crawl_business, run_id=scheduled__2025-07-12T20:40:00+00:00, execution_date=20250712T204000, start_date=20250712T205900, end_date=20250712T205917
[2025-07-12T20:59:17.606+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-07-12T20:59:17.635+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-07-12T20:59:17.678+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-12T20:59:17.683+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
