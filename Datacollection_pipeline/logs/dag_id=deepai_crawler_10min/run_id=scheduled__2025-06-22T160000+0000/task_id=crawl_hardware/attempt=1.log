[2025-06-22T16:10:08.741+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-06-22T16:10:08.758+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: deepai_crawler_10min.crawl_hardware scheduled__2025-06-22T16:00:00+00:00 [queued]>
[2025-06-22T16:10:08.766+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: deepai_crawler_10min.crawl_hardware scheduled__2025-06-22T16:00:00+00:00 [queued]>
[2025-06-22T16:10:08.767+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 3
[2025-06-22T16:10:08.783+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): crawl_hardware> on 2025-06-22 16:00:00+00:00
[2025-06-22T16:10:08.793+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=17239) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-06-22T16:10:08.796+0000] {standard_task_runner.py:63} INFO - Started process 17275 to run task
[2025-06-22T16:10:08.797+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'deepai_crawler_10min', 'crawl_hardware', 'scheduled__2025-06-22T16:00:00+00:00', '--job-id', '881', '--raw', '--subdir', 'DAGS_FOLDER/dags.py', '--cfg-path', '/tmp/tmp5kp47c_r']
[2025-06-22T16:10:08.801+0000] {standard_task_runner.py:91} INFO - Job 881: Subtask crawl_hardware
[2025-06-22T16:10:08.850+0000] {task_command.py:426} INFO - Running <TaskInstance: deepai_crawler_10min.crawl_hardware scheduled__2025-06-22T16:00:00+00:00 [running]> on host 5471b5a2dbbe
[2025-06-22T16:10:08.961+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='deepai_crawler_10min' AIRFLOW_CTX_TASK_ID='crawl_hardware' AIRFLOW_CTX_EXECUTION_DATE='2025-06-22T16:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-06-22T16:00:00+00:00'
[2025-06-22T16:10:08.962+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-06-22T16:10:08.982+0000] {dags.py:183} INFO - B·∫Øt ƒë·∫ßu crawl category: hardware
[2025-06-22T16:10:09.236+0000] {crawler_deeplai.py:51} INFO - ƒê√£ k·∫øt n·ªëi th√†nh c√¥ng v·ªõi MongoDB: deeplearning_ai_news
[2025-06-22T16:10:09.266+0000] {crawler_deeplai.py:465} INFO - üöÄ ƒêang b·∫Øt ƒë·∫ßu qu√° tr√¨nh crawl v·ªõi Load More...
[2025-06-22T16:10:09.513+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:10.046+0000] {logging_mixin.py:188} INFO - [INIT].... ‚Üí Crawl4AI 0.6.3
[2025-06-22T16:10:10.048+0000] {crawler_deeplai.py:179} INFO - üåê ƒêang truy c·∫≠p: https://www.deeplearning.ai/the-batch/tag/hardware/
[2025-06-22T16:10:10.049+0000] {crawler_deeplai.py:180} INFO - ‚öôÔ∏è C·∫•u h√¨nh: max_articles=100, min_threshold=5, max_clicks=1
[2025-06-22T16:10:10.514+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:11.515+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:12.516+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:13.516+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:13.836+0000] {logging_mixin.py:188} INFO - [FETCH]... ‚Üì https://www.deeplearning.ai/the-batch/tag/hardware/                
| ‚úì | ‚è±: 3.78s
[2025-06-22T16:10:13.937+0000] {logging_mixin.py:188} INFO - [SCRAPE].. ‚óÜ https://www.deeplearning.ai/the-batch/tag/hardware/                
| ‚úì | ‚è±: 0.10s
[2025-06-22T16:10:13.939+0000] {logging_mixin.py:188} INFO - [COMPLETE] ‚óè https://www.deeplearning.ai/the-batch/tag/hardware/                
| ‚úì | ‚è±: 3.89s
[2025-06-22T16:10:13.940+0000] {crawler_deeplai.py:184} INFO - üìã JavaScript execution result: {'success': True, 'results': [{'success': True, 'result': {}}]}
[2025-06-22T16:10:13.973+0000] {crawler_deeplai.py:204} INFO - üéØ T·ªïng c·ªông t√¨m th·∫•y 30 link b√†i vi·∫øt unique
[2025-06-22T16:10:13.974+0000] {crawler_deeplai.py:208} INFO - üîç M·ªôt v√†i URL ƒë·∫ßu ti√™n:
[2025-06-22T16:10:13.975+0000] {crawler_deeplai.py:210} INFO -   1. https://www.deeplearning.ai/the-batch/ai-creates-an-interactive-minecraft-like-world-in-real-time/
[2025-06-22T16:10:13.975+0000] {crawler_deeplai.py:210} INFO -   2. https://www.deeplearning.ai/the-batch/ai-electricity-demands-spur-an-expansion-of-power-sources/
[2025-06-22T16:10:13.976+0000] {crawler_deeplai.py:210} INFO -   3. https://www.deeplearning.ai/the-batch/all-about-nvidia-gpu-shortage/
[2025-06-22T16:10:13.976+0000] {crawler_deeplai.py:210} INFO -   4. https://www.deeplearning.ai/the-batch/all-about-nvidias-new-blackwell-architecture-and-b200-gpu/
[2025-06-22T16:10:13.976+0000] {crawler_deeplai.py:210} INFO -   5. https://www.deeplearning.ai/the-batch/amazon-google-and-microsoft-bet-on-nuclear-power-to-meet-ai-energy-demands/
[2025-06-22T16:10:13.977+0000] {crawler_deeplai.py:214} INFO - üìä S·∫Ω crawl 30 b√†i vi·∫øt
[2025-06-22T16:10:14.481+0000] {crawler_deeplai.py:458} INFO - ƒê√£ l·ªçc: 30 URLs ban ƒë·∫ßu -> 1 URLs m·ªõi
[2025-06-22T16:10:14.482+0000] {crawler_deeplai.py:479} INFO - üìù ƒêang crawl 1 b√†i vi·∫øt m·ªõi...
[2025-06-22T16:10:14.482+0000] {crawler_deeplai.py:486} INFO - [1/1] üîÑ ƒêang crawl: https://www.deeplearning.ai/the-batch/the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom/
[2025-06-22T16:10:14.517+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:15.145+0000] {logging_mixin.py:188} INFO - [INIT].... ‚Üí Crawl4AI 0.6.3
[2025-06-22T16:10:15.518+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:16.304+0000] {logging_mixin.py:188} INFO - [FETCH]... ‚Üì 
https://www.deeplearning.ai/the-batch/the-intern...ergy-costs-and-potential-savi
ngs-of-the-ai-boom/  | ‚úì | ‚è±: 1.24s
[2025-06-22T16:10:16.376+0000] {logging_mixin.py:188} INFO - [SCRAPE].. ‚óÜ 
https://www.deeplearning.ai/the-batch/the-intern...ergy-costs-and-potential-savi
ngs-of-the-ai-boom/  | ‚úì | ‚è±: 0.07s
[2025-06-22T16:10:16.378+0000] {logging_mixin.py:188} INFO - [COMPLETE] ‚óè 
https://www.deeplearning.ai/the-batch/the-intern...ergy-costs-and-potential-savi
ngs-of-the-ai-boom/  | ‚úì | ‚è±: 1.31s
[2025-06-22T16:10:16.405+0000] {logging_mixin.py:188} INFO - Title: AI Uses Energy, AI Saves Energy
[2025-06-22T16:10:16.406+0000] {logging_mixin.py:188} INFO - Subtitle: The International Energy Agency examines the energy costs and potential savings of the AI boom
[2025-06-22T16:10:16.437+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:16.481+0000] {CallbackHandler.py:758} DEBUG - Event: on_chat_model_start, run_id: cfac0, parent_run_id: 20bc2
[2025-06-22T16:10:17.438+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:18.438+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:19.253+0000] {CallbackHandler.py:758} DEBUG - Event: on_llm_end, run_id: cfac0, parent_run_id: 20bc2
[2025-06-22T16:10:19.255+0000] {span_processor.py:96} DEBUG - Trace: Processing span name='SummaryWithBERTScore' | Full details:
{
  "name": "SummaryWithBERTScore",
  "context": {
    "trace_id": "76ab30dc1b5b8aba1ee49345d995ba22",
    "span_id": "c4d62191d5d37d71",
    "trace_state": "[]"
  },
  "kind": "SpanKind.INTERNAL",
  "parent_id": "85ba3c588743452e",
  "start_time": "2025-06-22T16:10:16.482394Z",
  "end_time": "2025-06-22T16:10:19.254701Z",
  "status": {
    "status_code": "UNSET"
  },
  "attributes": {
    "langfuse.observation.input": "[{\"role\": \"system\", \"content\": \"B\\u1ea1n l\\u00e0 m\\u1ed9t tr\\u1ee3 l\\u00fd AI c\\u00f3 nhi\\u1ec7m v\\u1ee5 t\\u00f3m t\\u1eaft c\\u00e1c b\\u00e0i vi\\u1ebft khoa h\\u1ecdc, k\\u1ef9 thu\\u1eadt ho\\u1eb7c c\\u00f4ng ngh\\u1ec7 \\u0111\\u01b0\\u1ee3c vi\\u1ebft b\\u1eb1ng ti\\u1ebfng Anh, v\\u00e0 cung c\\u1ea5p b\\u1ea3n t\\u00f3m t\\u1eaft d\\u1ea1ng bullet points b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t.\\n        \\n        Y\\u00eau c\\u1ea7u:\\n        1. T\\u00f3m t\\u1eaft th\\u00e0nh 3 bullet points ng\\u1eafn g\\u1ecdn, r\\u00f5 r\\u00e0ng.\\n        2. M\\u1ed7i bullet point tr\\u00ecnh b\\u00e0y m\\u1ed9t \\u00fd ch\\u00ednh ho\\u1eb7c th\\u00f4ng tin quan tr\\u1ecdng trong b\\u00e0i vi\\u1ebft.\\n        3. Kh\\u00f4ng th\\u00eam \\u00fd ki\\u1ebfn c\\u00e1 nh\\u00e2n, \\u0111\\u00e1nh gi\\u00e1 ch\\u1ee7 quan ho\\u1eb7c ph\\u00f3ng \\u0111\\u1ea1i n\\u1ed9i dung.\\n        4. Vi\\u1ebft b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t chu\\u1ea9n, kh\\u00e1ch quan, d\\u1ec5 hi\\u1ec3u, \\u0111\\u00fang ng\\u1eef ph\\u00e1p.\\n        5. Gi\\u1eef nguy\\u00ean c\\u00e1c thu\\u1eadt ng\\u1eef k\\u1ef9 thu\\u1eadt ti\\u1ebfng Anh n\\u1ebfu c\\u1ea7n \\u0111\\u1ec3 \\u0111\\u1ea3m b\\u1ea3o ch\\u00ednh x\\u00e1c.\\n        \\n        D\\u01b0\\u1edbi \\u0111\\u00e2y l\\u00e0 n\\u1ed9i dung b\\u00e0i vi\\u1ebft ti\\u1ebfng Anh, h\\u00e3y ph\\u00e2n t\\u00edch v\\u00e0 cung c\\u1ea5p b\\u1ea3n t\\u00f3m t\\u1eaft d\\u1ea1ng bullet points b\\u1eb1ng ti\\u1ebfng Vi\\u1ec7t:\"}, {\"role\": \"user\", \"content\": \"AI Uses Energy, AI Saves Energy\\n\\nAI\\u2019s thirst for energy is growing, but the technology\\u00a0also could help produce huge energy savings over the next five to 10 years, according to a recent report.\\n\\nWhat\\u2019s new:The International Energy Agency (IEA), which advises 44 countries on energy policy, performed a comprehensiveanalysisof AI\\u2019s energy consumption including energy required to obtain critical materials needed for chips and data centers. The report sees dark clouds ahead but also silver linings.\\n\\nDark clouds:The report, which is based on interviews with officials in government, energy, and technology, makes four projections for AI\\u2019s energy consumption. In the base scenario, future growth and efficiency gains are similar to those of the past five years. The agency also plots a \\u201ctake-off\\u201d scenario in which AI adoption happens faster, a \\u201chigh efficiency\\u201d scenario with lower energy needs, and a \\u201cheadwinds\\u201d scenario in which adoption of AI slows or infrastructure bottlenecks impede construction. Among the conclusions:\\n\\nSilver linings:AI already makes energy generation, distribution, and use more efficient. The authors expect these savings to accelerate.\\n\\nYes, but:The authors concede that lower energy costs for AI likely will lead to much greater consumption \\u2014 according to theJevons paradox\\u2014 so more-efficient models and hardware will result in higher energy consumption overall.\\n\\nBehind the news:Data centers were growing rapidly prior to the boom in generative AI. Data centers\\u2019 electricity use doubled between 2000 and 2005 and again between 2017 and 2022, driven by the growth of cloud computing and data storage, streaming and social media, and cryptocurrency mining. However, these periods of accelerating growth were followed by periods of slower growth as efforts to cut costs led to more-efficient software and hardware. The authors expect this pattern to hold.\\n\\nWhy it matters:The IEA report is a first-of-its-kind analysis of AI\\u2019s energy requirements, how they\\u2019re likely to grow, as well as the potential of the technology itself to reduce those requirements. It confirms that AI is poised to consume huge amounts of energy. However, it also suggests that today\\u2019s energy costs will be tomorrow\\u2019s energy savings as AI makes energy generation, distribution, and use more efficient across a wide variety of industries.\\n\\nWe\\u2019re thinking:While demand for electricity for data centers is growing rapidly,\\u00a0calibrating the right level of investment is tricky. High levels of growth come\\u00a0with high levels of hype that can lead analysts to overestimate future demand. For example, Microsoft, after examining\\u00a0its forecasts,canceleddata-center projects that would have consumed 2 gigawatts.\"}]",
    "langfuse.observation.model.name": "gemini-2.0-flash-lite",
    "langfuse.observation.model.parameters": "{\"temperature\": 0.1}",
    "langfuse.observation.metadata.tags": "[\"seq:step:2\"]",
    "langfuse.observation.metadata.ls_provider": "\"google_genai\"",
    "langfuse.observation.metadata.ls_model_name": "\"gemini-2.0-flash-lite\"",
    "langfuse.observation.metadata.ls_model_type": "\"chat\"",
    "langfuse.observation.metadata.ls_temperature": "0.1",
    "langfuse.observation.metadata.ls_max_tokens": "1024",
    "langfuse.observation.type": "generation",
    "langfuse.observation.output": "{\"role\": \"assistant\", \"content\": \"D\\u01b0\\u1edbi \\u0111\\u00e2y l\\u00e0 b\\u1ea3n t\\u00f3m t\\u1eaft b\\u00e0i vi\\u1ebft d\\u01b0\\u1edbi d\\u1ea1ng bullet points:\\n\\n*   Theo b\\u00e1o c\\u00e1o g\\u1ea7n \\u0111\\u00e2y, AI ng\\u00e0y c\\u00e0ng ti\\u00eau th\\u1ee5 nhi\\u1ec1u n\\u0103ng l\\u01b0\\u1ee3ng, bao g\\u1ed3m c\\u1ea3 n\\u0103ng l\\u01b0\\u1ee3ng c\\u1ea7n thi\\u1ebft \\u0111\\u1ec3 s\\u1ea3n xu\\u1ea5t chip v\\u00e0 v\\u1eadn h\\u00e0nh c\\u00e1c trung t\\u00e2m d\\u1eef li\\u1ec7u.\\n*   AI c\\u00f3 ti\\u1ec1m n\\u0103ng ti\\u1ebft ki\\u1ec7m n\\u0103ng l\\u01b0\\u1ee3ng l\\u1edbn trong t\\u01b0\\u01a1ng lai th\\u00f4ng qua vi\\u1ec7c t\\u1ed1i \\u01b0u h\\u00f3a qu\\u00e1 tr\\u00ecnh s\\u1ea3n xu\\u1ea5t, ph\\u00e2n ph\\u1ed1i v\\u00e0 s\\u1eed d\\u1ee5ng n\\u0103ng l\\u01b0\\u1ee3ng.\\n*   B\\u00e1o c\\u00e1o nh\\u1ea5n m\\u1ea1nh s\\u1ef1 ph\\u1ee9c t\\u1ea1p c\\u1ee7a v\\u1ea5n \\u0111\\u1ec1, khi chi ph\\u00ed n\\u0103ng l\\u01b0\\u1ee3ng gi\\u1ea3m c\\u00f3 th\\u1ec3 d\\u1eabn \\u0111\\u1ebfn vi\\u1ec7c s\\u1eed d\\u1ee5ng AI nhi\\u1ec1u h\\u01a1n, t\\u1eeb \\u0111\\u00f3 l\\u00e0m t\\u0103ng t\\u1ed5ng l\\u01b0\\u1ee3ng \\u0111i\\u1ec7n ti\\u00eau th\\u1ee5.\"}",
    "langfuse.observation.usage_details": "{\"input\": 743, \"output\": 132, \"total\": 875, \"input_cache_read\": 0}"
  },
  "events": [],
  "links": [],
  "resource": {
    "attributes": {
      "telemetry.sdk.language": "python",
      "telemetry.sdk.name": "opentelemetry",
      "telemetry.sdk.version": "1.34.1",
      "service.name": "unknown_service"
    },
    "schema_url": ""
  },
  "instrumentationScope": {
    "name": "langfuse-sdk",
    "version": "3.0.3",
    "schema_url": "",
    "attributes": {
      "public_key": "pk-lf-1f10d355-392c-4cb4-903c-7e9d2910b10e"
    }
  }
}

[2025-06-22T16:10:19.439+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:20.440+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:21.440+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:22.442+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:23.442+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:24.443+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:24.584+0000] {summary_gemini.py:159} INFO - [BERT BULLET] F1=0.7976621985435486
[2025-06-22T16:10:24.586+0000] {resource_manager.py:290} DEBUG - Score: Enqueuing event type=score-create for trace_id=76ab30dc1b5b8aba1ee49345d995ba22 name=bert_f1_score value=0.7976621985435486
[2025-06-22T16:10:24.587+0000] {span_processor.py:96} DEBUG - Trace: Processing span name='BulletSummaryWithBERTScore' | Full details:
{
  "name": "BulletSummaryWithBERTScore",
  "context": {
    "trace_id": "76ab30dc1b5b8aba1ee49345d995ba22",
    "span_id": "85ba3c588743452e",
    "trace_state": "[]"
  },
  "kind": "SpanKind.INTERNAL",
  "parent_id": null,
  "start_time": "2025-06-22T16:10:16.468695Z",
  "end_time": "2025-06-22T16:10:24.587044Z",
  "status": {
    "status_code": "UNSET"
  },
  "attributes": {
    "langfuse.observation.type": "span",
    "langfuse.trace.input": "{\"content\": \"AI Uses Energy, AI Saves Energy\\n\\nAI\\u2019s thirst for energy is growing, but the technology\\u00a0also could help produce huge energy savings over the next five to 10 years, according to a recent report.\\n\\nWhat\\u2019s new:The International Energy Agency (IEA), which advises 44 countries on energy policy, performed a comprehensiveanalysisof AI\\u2019s energy consumption including energy required to obtain critical materials needed for chips and data centers. The report sees dark clouds ahead but also silver linings.\\n\\nDark clouds:The report, which is based on interviews with officials in government, energy, and technology, makes four projections for AI\\u2019s energy consumption. In the base scenario, future growth and efficiency gains are similar to those of the past five years. The agency also plots a \\u201ctake-off\\u201d scenario in which AI adoption happens faster, a \\u201chigh efficiency\\u201d scenario with lower energy needs, and a \\u201cheadwinds\\u201d scenario in which adoption of AI slows or infrastructure bottlenecks impede construction. Among the conclusions:\\n\\nSilver linings:AI already makes energy generation, distribution, and use more efficient. The authors expect these savings to accelerate.\\n\\nYes, but:The authors concede that lower energy costs for AI likely will lead to much greater consumption \\u2014 according to theJevons paradox\\u2014 so more-efficient models and hardware will result in higher energy consumption overall.\\n\\nBehind the news:Data centers were growing rapidly prior to the boom in generative AI. Data centers\\u2019 electricity use doubled between 2000 and 2005 and again between 2017 and 2022, driven by the growth of cloud computing and data storage, streaming and social media, and cryptocurrency mining. However, these periods of accelerating growth were followed by periods of slower growth as efforts to cut costs led to more-efficient software and hardware. The authors expect this pattern to hold.\\n\\nWhy it matters:The IEA report is a first-of-its-kind analysis of AI\\u2019s energy requirements, how they\\u2019re likely to grow, as well as the potential of the technology itself to reduce those requirements. It confirms that AI is poised to consume huge amounts of energy. However, it also suggests that today\\u2019s energy costs will be tomorrow\\u2019s energy savings as AI makes energy generation, distribution, and use more efficient across a wide variety of industries.\\n\\nWe\\u2019re thinking:While demand for electricity for data centers is growing rapidly,\\u00a0calibrating the right level of investment is tricky. High levels of growth come\\u00a0with high levels of hype that can lead analysts to overestimate future demand. For example, Microsoft, after examining\\u00a0its forecasts,canceleddata-center projects that would have consumed 2 gigawatts.\"}",
    "langfuse.trace.output": "{\"summary\": \"D\\u01b0\\u1edbi \\u0111\\u00e2y l\\u00e0 b\\u1ea3n t\\u00f3m t\\u1eaft b\\u00e0i vi\\u1ebft d\\u01b0\\u1edbi d\\u1ea1ng bullet points:\\n\\n*   Theo b\\u00e1o c\\u00e1o g\\u1ea7n \\u0111\\u00e2y, AI ng\\u00e0y c\\u00e0ng ti\\u00eau th\\u1ee5 nhi\\u1ec1u n\\u0103ng l\\u01b0\\u1ee3ng, bao g\\u1ed3m c\\u1ea3 n\\u0103ng l\\u01b0\\u1ee3ng c\\u1ea7n thi\\u1ebft \\u0111\\u1ec3 s\\u1ea3n xu\\u1ea5t chip v\\u00e0 v\\u1eadn h\\u00e0nh c\\u00e1c trung t\\u00e2m d\\u1eef li\\u1ec7u.\\n*   AI c\\u00f3 ti\\u1ec1m n\\u0103ng ti\\u1ebft ki\\u1ec7m n\\u0103ng l\\u01b0\\u1ee3ng l\\u1edbn trong t\\u01b0\\u01a1ng lai th\\u00f4ng qua vi\\u1ec7c t\\u1ed1i \\u01b0u h\\u00f3a qu\\u00e1 tr\\u00ecnh s\\u1ea3n xu\\u1ea5t, ph\\u00e2n ph\\u1ed1i v\\u00e0 s\\u1eed d\\u1ee5ng n\\u0103ng l\\u01b0\\u1ee3ng.\\n*   B\\u00e1o c\\u00e1o nh\\u1ea5n m\\u1ea1nh s\\u1ef1 ph\\u1ee9c t\\u1ea1p c\\u1ee7a v\\u1ea5n \\u0111\\u1ec1, khi chi ph\\u00ed n\\u0103ng l\\u01b0\\u1ee3ng gi\\u1ea3m c\\u00f3 th\\u1ec3 d\\u1eabn \\u0111\\u1ebfn vi\\u1ec7c s\\u1eed d\\u1ee5ng AI nhi\\u1ec1u h\\u01a1n, t\\u1eeb \\u0111\\u00f3 l\\u00e0m t\\u0103ng t\\u1ed5ng l\\u01b0\\u1ee3ng \\u0111i\\u1ec7n ti\\u00eau th\\u1ee5.\"}"
  },
  "events": [],
  "links": [],
  "resource": {
    "attributes": {
      "telemetry.sdk.language": "python",
      "telemetry.sdk.name": "opentelemetry",
      "telemetry.sdk.version": "1.34.1",
      "service.name": "unknown_service"
    },
    "schema_url": ""
  },
  "instrumentationScope": {
    "name": "langfuse-sdk",
    "version": "3.0.3",
    "schema_url": "",
    "attributes": {
      "public_key": "pk-lf-1f10d355-392c-4cb4-903c-7e9d2910b10e"
    }
  }
}

[2025-06-22T16:10:25.445+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:26.445+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:27.446+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:28.447+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:29.448+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:29.711+0000] {crawler_deeplai.py:490} INFO -     ‚úÖ AI Uses Energy, AI Saves Energy...
[2025-06-22T16:10:30.448+0000] {media_manager.py:52} DEBUG - Queue: Media upload queue is empty, waiting for new jobs
[2025-06-22T16:10:30.714+0000] {crawler_deeplai.py:503} INFO - ‚è±Ô∏è T·ªïng th·ªùi gian crawl: 21.45 gi√¢y
[2025-06-22T16:10:30.715+0000] {crawler_deeplai.py:504} INFO - üìä Th√†nh c√¥ng crawl: 1/1 b√†i vi·∫øt
[2025-06-22T16:10:30.774+0000] {crawler_deeplai.py:531} INFO - üíæ ƒê√£ l∆∞u th√†nh c√¥ng 1/1 b√†i vi·∫øt v√†o collection 'hardware'
[2025-06-22T16:10:30.826+0000] {dags.py:188} INFO - Ho√†n th√†nh crawl category: hardware
[2025-06-22T16:10:30.826+0000] {python.py:237} INFO - Done. Returned value was: None
[2025-06-22T16:10:30.827+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-06-22T16:10:30.834+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=deepai_crawler_10min, task_id=crawl_hardware, run_id=scheduled__2025-06-22T16:00:00+00:00, execution_date=20250622T160000, start_date=20250622T161008, end_date=20250622T161030
[2025-06-22T16:10:30.886+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-06-22T16:10:30.909+0000] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-06-22T16:10:30.912+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
