{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T21:22:35.472824Z",
     "iopub.status.busy": "2025-06-07T21:22:35.472466Z",
     "iopub.status.idle": "2025-06-07T21:23:55.467716Z",
     "shell.execute_reply": "2025-06-07T21:23:55.466420Z",
     "shell.execute_reply.started": "2025-06-07T21:22:35.472797Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting crawl4ai\n",
      "  Downloading crawl4ai-0.6.3-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: aiosqlite~=0.20 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (0.21.0)\n",
      "Requirement already satisfied: lxml~=5.3 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (5.3.1)\n",
      "Collecting litellm>=1.53.1 (from crawl4ai)\n",
      "  Downloading litellm-1.72.2-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.26.4)\n",
      "Collecting pillow~=10.4 (from crawl4ai)\n",
      "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting playwright>=1.49.0 (from crawl4ai)\n",
      "  Downloading playwright-1.52.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting python-dotenv~=1.0 (from crawl4ai)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: requests~=2.26 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4~=4.12 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (4.13.3)\n",
      "Collecting tf-playwright-stealth>=1.1.0 (from crawl4ai)\n",
      "  Downloading tf_playwright_stealth-1.1.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: xxhash~=3.4 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (3.5.0)\n",
      "Collecting rank-bm25~=0.2 (from crawl4ai)\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting aiofiles>=24.1.0 (from crawl4ai)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: colorama~=0.4 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (0.4.6)\n",
      "Requirement already satisfied: snowballstemmer~=2.2 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (2.2.0)\n",
      "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (2.11.4)\n",
      "Requirement already satisfied: pyOpenSSL>=24.3.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (25.0.0)\n",
      "Requirement already satisfied: psutil>=6.1.1 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (7.0.0)\n",
      "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (3.9.1)\n",
      "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (14.0.0)\n",
      "Collecting cssselect>=1.2.0 (from crawl4ai)\n",
      "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (0.28.1)\n",
      "Collecting fake-useragent>=2.0.3 (from crawl4ai)\n",
      "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (8.1.8)\n",
      "Requirement already satisfied: pyperclip>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.9.0)\n",
      "Requirement already satisfied: chardet>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (5.2.0)\n",
      "Requirement already satisfied: aiohttp>=3.11.11 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (3.11.18)\n",
      "Collecting brotli>=1.1.0 (from crawl4ai)\n",
      "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: humanize>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (1.20.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.11/dist-packages (from aiosqlite~=0.20->crawl4ai) (4.13.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4~=4.12->crawl4ai) (2.6)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->crawl4ai) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->crawl4ai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->crawl4ai) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->crawl4ai) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.2->crawl4ai) (0.14.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (8.7.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (1.70.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (0.9.0)\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (0.21.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->crawl4ai) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->crawl4ai) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->crawl4ai) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.0->crawl4ai) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.0->crawl4ai) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.0->crawl4ai) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.0->crawl4ai) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.0->crawl4ai) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.0->crawl4ai) (2.4.1)\n",
      "Collecting pyee<14,>=13 (from playwright>=1.49.0->crawl4ai)\n",
      "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from playwright>=1.49.0->crawl4ai) (3.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->crawl4ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->crawl4ai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->crawl4ai) (0.4.0)\n",
      "Requirement already satisfied: cryptography<45,>=41.0.5 in /usr/local/lib/python3.11/dist-packages (from pyOpenSSL>=24.3.0->crawl4ai) (44.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.26->crawl4ai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.26->crawl4ai) (2.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->crawl4ai) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->crawl4ai) (2.19.1)\n",
      "Collecting fake-http-header<0.4.0,>=0.3.5 (from tf-playwright-stealth>=1.1.0->crawl4ai)\n",
      "  Downloading fake_http_header-0.3.5-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (1.17.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.53.1->crawl4ai) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.53.1->crawl4ai) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.24.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->crawl4ai) (0.1.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm>=1.53.1->crawl4ai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm>=1.53.1->crawl4ai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm>=1.53.1->crawl4ai) (1.3.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.0->crawl4ai) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.0->crawl4ai) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.0->crawl4ai) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.26.0->crawl4ai) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm>=1.53.1->crawl4ai) (0.31.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (2.22)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (6.0.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (1.1.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.26.0->crawl4ai) (2024.2.0)\n",
      "Downloading crawl4ai-0.6.3-py3-none-any.whl (292 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
      "Downloading fake_useragent-2.2.0-py3-none-any.whl (161 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading litellm-1.72.2-py3-none-any.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading playwright-1.52.0-py3-none-manylinux1_x86_64.whl (45.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Downloading tf_playwright_stealth-1.1.2-py3-none-any.whl (33 kB)\n",
      "Downloading fake_http_header-0.3.5-py3-none-any.whl (14 kB)\n",
      "Downloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: brotli, python-dotenv, pyee, pillow, fake-useragent, fake-http-header, cssselect, aiofiles, playwright, tf-playwright-stealth, litellm, rank-bm25, crawl4ai\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "  Attempting uninstall: aiofiles\n",
      "    Found existing installation: aiofiles 22.1.0\n",
      "    Uninstalling aiofiles-22.1.0:\n",
      "      Successfully uninstalled aiofiles-22.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ypy-websocket 0.8.4 requires aiofiles<23,>=22.1.0, but you have aiofiles 24.1.0 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-24.1.0 brotli-1.1.0 crawl4ai-0.6.3 cssselect-1.3.0 fake-http-header-0.3.5 fake-useragent-2.2.0 litellm-1.72.2 pillow-10.4.0 playwright-1.52.0 pyee-13.0.0 python-dotenv-1.1.0 rank-bm25-0.2.2 tf-playwright-stealth-1.1.2\n",
      "Requirement already satisfied: crawl4ai in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
      "Requirement already satisfied: aiosqlite~=0.20 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (0.21.0)\n",
      "Requirement already satisfied: lxml~=5.3 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (5.3.1)\n",
      "Requirement already satisfied: litellm>=1.53.1 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.72.2)\n",
      "Requirement already satisfied: numpy<3,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.26.4)\n",
      "Requirement already satisfied: pillow~=10.4 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (10.4.0)\n",
      "Requirement already satisfied: playwright>=1.49.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.52.0)\n",
      "Requirement already satisfied: python-dotenv~=1.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.1.0)\n",
      "Requirement already satisfied: requests~=2.26 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4~=4.12 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (4.13.3)\n",
      "Requirement already satisfied: tf-playwright-stealth>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.1.2)\n",
      "Requirement already satisfied: xxhash~=3.4 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (3.5.0)\n",
      "Requirement already satisfied: rank-bm25~=0.2 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (0.2.2)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (24.1.0)\n",
      "Requirement already satisfied: colorama~=0.4 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (0.4.6)\n",
      "Requirement already satisfied: snowballstemmer~=2.2 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (2.2.0)\n",
      "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (2.11.4)\n",
      "Requirement already satisfied: pyOpenSSL>=24.3.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (25.0.0)\n",
      "Requirement already satisfied: psutil>=6.1.1 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (7.0.0)\n",
      "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (3.9.1)\n",
      "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (14.0.0)\n",
      "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (0.28.1)\n",
      "Requirement already satisfied: fake-useragent>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (8.1.8)\n",
      "Requirement already satisfied: pyperclip>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.9.0)\n",
      "Requirement already satisfied: chardet>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (5.2.0)\n",
      "Requirement already satisfied: aiohttp>=3.11.11 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (3.11.18)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.1.0)\n",
      "Requirement already satisfied: humanize>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (1.20.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.11/dist-packages (from aiosqlite~=0.20->crawl4ai) (4.13.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4~=4.12->crawl4ai) (2.6)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->crawl4ai) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->crawl4ai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->crawl4ai) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->crawl4ai) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.2->crawl4ai) (0.14.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (8.7.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (1.70.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (0.9.0)\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (0.21.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->crawl4ai) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->crawl4ai) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->crawl4ai) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.0->crawl4ai) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.0->crawl4ai) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.0->crawl4ai) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.0->crawl4ai) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.0->crawl4ai) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.0->crawl4ai) (2.4.1)\n",
      "Requirement already satisfied: pyee<14,>=13 in /usr/local/lib/python3.11/dist-packages (from playwright>=1.49.0->crawl4ai) (13.0.0)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from playwright>=1.49.0->crawl4ai) (3.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->crawl4ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->crawl4ai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->crawl4ai) (0.4.0)\n",
      "Requirement already satisfied: cryptography<45,>=41.0.5 in /usr/local/lib/python3.11/dist-packages (from pyOpenSSL>=24.3.0->crawl4ai) (44.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.26->crawl4ai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.26->crawl4ai) (2.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->crawl4ai) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->crawl4ai) (2.19.1)\n",
      "Requirement already satisfied: fake-http-header<0.4.0,>=0.3.5 in /usr/local/lib/python3.11/dist-packages (from tf-playwright-stealth>=1.1.0->crawl4ai) (0.3.5)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (1.17.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.53.1->crawl4ai) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.53.1->crawl4ai) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.24.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->crawl4ai) (0.1.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm>=1.53.1->crawl4ai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm>=1.53.1->crawl4ai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm>=1.53.1->crawl4ai) (1.3.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.0->crawl4ai) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.0->crawl4ai) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.0->crawl4ai) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.26.0->crawl4ai) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm>=1.53.1->crawl4ai) (0.31.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (2.22)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (6.0.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (1.1.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.26.0->crawl4ai) (2024.2.0)\n",
      "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Running post-installation setup\u001b[0m\u001b[36m...\u001b[0m\u001b[36m \u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Installing Playwright browsers\u001b[0m\u001b[36m...\u001b[0m\u001b[36m \u001b[0m\n",
      "Installing dependencies...\n",
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]                           \n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,765 kB]\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease                                              \n",
      "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]                                \n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]                             \n",
      "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
      "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,021 kB]    \n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]     \n",
      "Get:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]       \n",
      "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,984 kB]              \n",
      "Get:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]              \n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,295 kB]                \n",
      "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,246 kB]          \n",
      "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,476 kB]        \n",
      "Get:17 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.8 kB]   \n",
      "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,743 kB]                    \n",
      "Get:19 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [46.6 kB]\n",
      "Get:20 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [75.1 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,630 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,553 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
      "Fetched 32.4 MB in 3s (9,735 kB/s)                          \n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "fonts-liberation is already the newest version (1:1.07.4-11).\n",
      "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
      "libasound2 set to manually installed.\n",
      "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
      "libatk-bridge2.0-0 set to manually installed.\n",
      "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
      "libatk1.0-0 set to manually installed.\n",
      "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
      "libatspi2.0-0 set to manually installed.\n",
      "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
      "libcairo2 set to manually installed.\n",
      "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
      "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
      "libxcb1 set to manually installed.\n",
      "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
      "libxcomposite1 set to manually installed.\n",
      "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
      "libxdamage1 set to manually installed.\n",
      "libxext6 is already the newest version (2:1.3.4-1build1).\n",
      "libxfixes3 is already the newest version (1:6.0.0-1).\n",
      "libxfixes3 set to manually installed.\n",
      "libxkbcommon0 is already the newest version (1.4.0-1).\n",
      "libxkbcommon0 set to manually installed.\n",
      "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
      "libxrandr2 set to manually installed.\n",
      "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
      "libcups2 set to manually installed.\n",
      "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
      "libdbus-1-3 set to manually installed.\n",
      "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
      "libdrm2 set to manually installed.\n",
      "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.3).\n",
      "libfreetype6 set to manually installed.\n",
      "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
      "libgbm1 set to manually installed.\n",
      "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
      "libnspr4 set to manually installed.\n",
      "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
      "libnss3 set to manually installed.\n",
      "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
      "libpango-1.0-0 set to manually installed.\n",
      "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
      "libwayland-client0 set to manually installed.\n",
      "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
      "libx11-6 set to manually installed.\n",
      "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.14).\n",
      "The following additional packages will be installed:\n",
      "  libglib2.0-bin libglib2.0-dev libglib2.0-dev-bin\n",
      "Suggested packages:\n",
      "  libglib2.0-doc libxml2-utils\n",
      "Recommended packages:\n",
      "  fonts-ipafont-mincho fonts-tlwg-loma xdg-user-dirs\n",
      "The following NEW packages will be installed:\n",
      "  fonts-freefont-ttf fonts-ipafont-gothic fonts-noto-color-emoji fonts-tlwg-loma-otf fonts-unifont\n",
      "  fonts-wqy-zenhei xfonts-cyrillic xfonts-scalable\n",
      "The following packages will be upgraded:\n",
      "  libglib2.0-0 libglib2.0-bin libglib2.0-dev libglib2.0-dev-bin\n",
      "4 upgraded, 8 newly installed, 0 to remove and 177 not upgraded.\n",
      "Need to get 31.2 MB of archives.\n",
      "After this operation, 66.8 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-ipafont-gothic all 00303-21ubuntu1 [3,513 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-dev amd64 2.72.4-0ubuntu2.5 [1,743 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-dev-bin amd64 2.72.4-0ubuntu2.5 [116 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-bin amd64 2.72.4-0ubuntu2.5 [81.2 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libglib2.0-0 amd64 2.72.4-0ubuntu2.5 [1,466 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-freefont-ttf all 20120503-10build1 [2,388 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 fonts-noto-color-emoji all 2.047-0ubuntu0.22.04.1 [10.0 MB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-tlwg-loma-otf all 1:0.7.3-1 [107 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-unifont all 1:14.0.01-1 [3,551 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-wqy-zenhei all 0.9.45-8 [7,472 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy/universe amd64 xfonts-cyrillic all 1:1.0.5 [386 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-scalable all 1:1.0.3-1.2ubuntu1 [306 kB]\n",
      "Fetched 31.2 MB in 1s (25.4 MB/s)         \n",
      "Selecting previously unselected package fonts-ipafont-gothic.\n",
      "(Reading database ... 129184 files and directories currently installed.)\n",
      "Preparing to unpack .../00-fonts-ipafont-gothic_00303-21ubuntu1_all.deb ...\n",
      "Unpacking fonts-ipafont-gothic (00303-21ubuntu1) ...\n",
      "Preparing to unpack .../01-libglib2.0-dev_2.72.4-0ubuntu2.5_amd64.deb ...\n",
      "Unpacking libglib2.0-dev:amd64 (2.72.4-0ubuntu2.5) over (2.72.4-0ubuntu2.4) ...\n",
      "Preparing to unpack .../02-libglib2.0-dev-bin_2.72.4-0ubuntu2.5_amd64.deb ...\n",
      "Unpacking libglib2.0-dev-bin (2.72.4-0ubuntu2.5) over (2.72.4-0ubuntu2.4) ...\n",
      "Preparing to unpack .../03-libglib2.0-bin_2.72.4-0ubuntu2.5_amd64.deb ...\n",
      "Unpacking libglib2.0-bin (2.72.4-0ubuntu2.5) over (2.72.4-0ubuntu2.4) ...\n",
      "Preparing to unpack .../04-libglib2.0-0_2.72.4-0ubuntu2.5_amd64.deb ...\n",
      "Unpacking libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) over (2.72.4-0ubuntu2.4) ...\n",
      "Selecting previously unselected package fonts-freefont-ttf.\n",
      "Preparing to unpack .../05-fonts-freefont-ttf_20120503-10build1_all.deb ...\n",
      "Unpacking fonts-freefont-ttf (20120503-10build1) ...\n",
      "Selecting previously unselected package fonts-noto-color-emoji.\n",
      "Preparing to unpack .../06-fonts-noto-color-emoji_2.047-0ubuntu0.22.04.1_all.deb ...\n",
      "Unpacking fonts-noto-color-emoji (2.047-0ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package fonts-tlwg-loma-otf.\n",
      "Preparing to unpack .../07-fonts-tlwg-loma-otf_1%3a0.7.3-1_all.deb ...\n",
      "Unpacking fonts-tlwg-loma-otf (1:0.7.3-1) ...\n",
      "Selecting previously unselected package fonts-unifont.\n",
      "Preparing to unpack .../08-fonts-unifont_1%3a14.0.01-1_all.deb ...\n",
      "Unpacking fonts-unifont (1:14.0.01-1) ...\n",
      "Selecting previously unselected package fonts-wqy-zenhei.\n",
      "Preparing to unpack .../09-fonts-wqy-zenhei_0.9.45-8_all.deb ...\n",
      "Unpacking fonts-wqy-zenhei (0.9.45-8) ...\n",
      "Selecting previously unselected package xfonts-cyrillic.\n",
      "Preparing to unpack .../10-xfonts-cyrillic_1%3a1.0.5_all.deb ...\n",
      "Unpacking xfonts-cyrillic (1:1.0.5) ...\n",
      "Selecting previously unselected package xfonts-scalable.\n",
      "Preparing to unpack .../11-xfonts-scalable_1%3a1.0.3-1.2ubuntu1_all.deb ...\n",
      "Unpacking xfonts-scalable (1:1.0.3-1.2ubuntu1) ...\n",
      "Setting up fonts-noto-color-emoji (2.047-0ubuntu0.22.04.1) ...\n",
      "Setting up libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...\n",
      "Setting up fonts-wqy-zenhei (0.9.45-8) ...\n",
      "Setting up fonts-freefont-ttf (20120503-10build1) ...\n",
      "Setting up libglib2.0-bin (2.72.4-0ubuntu2.5) ...\n",
      "Setting up fonts-tlwg-loma-otf (1:0.7.3-1) ...\n",
      "Setting up fonts-ipafont-gothic (00303-21ubuntu1) ...\n",
      "update-alternatives: using /usr/share/fonts/opentype/ipafont-gothic/ipag.ttf to provide /usr/share/fonts/truetype/fonts-japanese-gothic.ttf (fonts-japanese-gothic.ttf) in auto mode\n",
      "Setting up xfonts-cyrillic (1:1.0.5) ...\n",
      "Setting up xfonts-scalable (1:1.0.3-1.2ubuntu1) ...\n",
      "Setting up fonts-unifont (1:14.0.01-1) ...\n",
      "Setting up libglib2.0-dev-bin (2.72.4-0ubuntu2.5) ...\n",
      "Setting up libglib2.0-dev:amd64 (2.72.4-0ubuntu2.5) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
      "Downloading Chromium 136.0.7103.25 (playwright build v1169)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1169/chromium-linux.zip\u001b[22m\n",
      "\u001b[1G167.7 MiB [                    ] 0% 0.0s\u001b[0K\u001b[1G167.7 MiB [                    ] 0% 11.5s\u001b[0K\u001b[1G167.7 MiB [                    ] 0% 5.4s\u001b[0K\u001b[1G167.7 MiB [                    ] 1% 3.2s\u001b[0K\u001b[1G167.7 MiB [                    ] 2% 2.7s\u001b[0K\u001b[1G167.7 MiB [=                   ] 3% 2.4s\u001b[0K\u001b[1G167.7 MiB [=                   ] 4% 2.2s\u001b[0K\u001b[1G167.7 MiB [=                   ] 5% 2.0s\u001b[0K\u001b[1G167.7 MiB [=                   ] 6% 2.1s\u001b[0K\u001b[1G167.7 MiB [=                   ] 6% 2.0s\u001b[0K\u001b[1G167.7 MiB [==                  ] 7% 2.0s\u001b[0K\u001b[1G167.7 MiB [==                  ] 8% 1.9s\u001b[0K\u001b[1G167.7 MiB [==                  ] 9% 1.9s\u001b[0K\u001b[1G167.7 MiB [==                  ] 9% 2.0s\u001b[0K\u001b[1G167.7 MiB [==                  ] 10% 2.0s\u001b[0K\u001b[1G167.7 MiB [==                  ] 11% 2.0s\u001b[0K\u001b[1G167.7 MiB [==                  ] 12% 1.9s\u001b[0K\u001b[1G167.7 MiB [===                 ] 13% 1.8s\u001b[0K\u001b[1G167.7 MiB [===                 ] 14% 1.8s\u001b[0K\u001b[1G167.7 MiB [===                 ] 16% 1.7s\u001b[0K\u001b[1G167.7 MiB [===                 ] 17% 1.6s\u001b[0K\u001b[1G167.7 MiB [====                ] 18% 1.5s\u001b[0K\u001b[1G167.7 MiB [====                ] 19% 1.5s\u001b[0K\u001b[1G167.7 MiB [====                ] 21% 1.5s\u001b[0K\u001b[1G167.7 MiB [====                ] 22% 1.4s\u001b[0K\u001b[1G167.7 MiB [=====               ] 22% 1.4s\u001b[0K\u001b[1G167.7 MiB [=====               ] 23% 1.4s\u001b[0K\u001b[1G167.7 MiB [=====               ] 24% 1.4s\u001b[0K\u001b[1G167.7 MiB [=====               ] 25% 1.4s\u001b[0K\u001b[1G167.7 MiB [=====               ] 26% 1.3s\u001b[0K\u001b[1G167.7 MiB [=====               ] 27% 1.3s\u001b[0K\u001b[1G167.7 MiB [=====               ] 27% 1.4s\u001b[0K\u001b[1G167.7 MiB [======              ] 27% 1.4s\u001b[0K\u001b[1G167.7 MiB [======              ] 28% 1.4s\u001b[0K\u001b[1G167.7 MiB [======              ] 29% 1.3s\u001b[0K\u001b[1G167.7 MiB [======              ] 31% 1.3s\u001b[0K\u001b[1G167.7 MiB [=======             ] 32% 1.2s\u001b[0K\u001b[1G167.7 MiB [=======             ] 33% 1.2s\u001b[0K\u001b[1G167.7 MiB [=======             ] 35% 1.2s\u001b[0K\u001b[1G167.7 MiB [=======             ] 36% 1.1s\u001b[0K\u001b[1G167.7 MiB [========            ] 37% 1.1s\u001b[0K\u001b[1G167.7 MiB [========            ] 39% 1.1s\u001b[0K\u001b[1G167.7 MiB [========            ] 40% 1.0s\u001b[0K\u001b[1G167.7 MiB [========            ] 41% 1.0s\u001b[0K\u001b[1G167.7 MiB [=========           ] 42% 1.0s\u001b[0K\u001b[1G167.7 MiB [=========           ] 44% 0.9s\u001b[0K\u001b[1G167.7 MiB [=========           ] 45% 0.9s\u001b[0K\u001b[1G167.7 MiB [=========           ] 46% 0.9s\u001b[0K\u001b[1G167.7 MiB [==========          ] 48% 0.9s\u001b[0K\u001b[1G167.7 MiB [==========          ] 49% 0.8s\u001b[0K\u001b[1G167.7 MiB [==========          ] 51% 0.8s\u001b[0K\u001b[1G167.7 MiB [===========         ] 52% 0.8s\u001b[0K\u001b[1G167.7 MiB [===========         ] 54% 0.7s\u001b[0K\u001b[1G167.7 MiB [===========         ] 55% 0.7s\u001b[0K\u001b[1G167.7 MiB [===========         ] 57% 0.7s\u001b[0K\u001b[1G167.7 MiB [============        ] 58% 0.6s\u001b[0K\u001b[1G167.7 MiB [============        ] 59% 0.6s\u001b[0K\u001b[1G167.7 MiB [============        ] 61% 0.6s\u001b[0K\u001b[1G167.7 MiB [=============       ] 62% 0.6s\u001b[0K\u001b[1G167.7 MiB [=============       ] 63% 0.6s\u001b[0K\u001b[1G167.7 MiB [=============       ] 64% 0.5s\u001b[0K\u001b[1G167.7 MiB [=============       ] 65% 0.5s\u001b[0K\u001b[1G167.7 MiB [=============       ] 66% 0.5s\u001b[0K\u001b[1G167.7 MiB [=============       ] 67% 0.5s\u001b[0K\u001b[1G167.7 MiB [==============      ] 68% 0.5s\u001b[0K\u001b[1G167.7 MiB [==============      ] 69% 0.5s\u001b[0K\u001b[1G167.7 MiB [==============      ] 71% 0.4s\u001b[0K\u001b[1G167.7 MiB [==============      ] 72% 0.4s\u001b[0K\u001b[1G167.7 MiB [===============     ] 73% 0.4s\u001b[0K\u001b[1G167.7 MiB [===============     ] 75% 0.4s\u001b[0K\u001b[1G167.7 MiB [===============     ] 76% 0.3s\u001b[0K\u001b[1G167.7 MiB [================    ] 78% 0.3s\u001b[0K\u001b[1G167.7 MiB [================    ] 79% 0.3s\u001b[0K\u001b[1G167.7 MiB [================    ] 81% 0.3s\u001b[0K\u001b[1G167.7 MiB [=================   ] 82% 0.3s\u001b[0K\u001b[1G167.7 MiB [=================   ] 84% 0.2s\u001b[0K\u001b[1G167.7 MiB [=================   ] 85% 0.2s\u001b[0K\u001b[1G167.7 MiB [=================   ] 87% 0.2s\u001b[0K\u001b[1G167.7 MiB [==================  ] 88% 0.2s\u001b[0K\u001b[1G167.7 MiB [==================  ] 89% 0.1s\u001b[0K\u001b[1G167.7 MiB [==================  ] 91% 0.1s\u001b[0K\u001b[1G167.7 MiB [=================== ] 92% 0.1s\u001b[0K\u001b[1G167.7 MiB [=================== ] 93% 0.1s\u001b[0K\u001b[1G167.7 MiB [=================== ] 95% 0.1s\u001b[0K\u001b[1G167.7 MiB [=================== ] 96% 0.0s\u001b[0K\u001b[1G167.7 MiB [====================] 97% 0.0s\u001b[0K\u001b[1G167.7 MiB [====================] 99% 0.0s\u001b[0K\u001b[1G167.7 MiB [====================] 100% 0.0s\u001b[0K\n",
      "Chromium 136.0.7103.25 (playwright build v1169) downloaded to /root/.cache/ms-playwright/chromium-1169\n",
      "Downloading FFMPEG playwright build v1011\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/ffmpeg/1011/ffmpeg-linux.zip\u001b[22m\n",
      "\u001b[1G2.3 MiB [                    ] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [==                  ] 8% 0.2s\u001b[0K\u001b[1G2.3 MiB [========            ] 38% 0.1s\u001b[0K\u001b[1G2.3 MiB [====================] 100% 0.0s\u001b[0K\n",
      "FFMPEG playwright build v1011 downloaded to /root/.cache/ms-playwright/ffmpeg-1011\n",
      "Downloading Chromium Headless Shell 136.0.7103.25 (playwright build v1169)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1169/chromium-headless-shell-linux.zip\u001b[22m\n",
      "\u001b[1G101.4 MiB [                    ] 0% 0.0s\u001b[0K\u001b[1G101.4 MiB [                    ] 0% 13.2s\u001b[0K\u001b[1G101.4 MiB [                    ] 0% 5.2s\u001b[0K\u001b[1G101.4 MiB [                    ] 1% 2.6s\u001b[0K\u001b[1G101.4 MiB [=                   ] 3% 2.0s\u001b[0K\u001b[1G101.4 MiB [=                   ] 4% 1.7s\u001b[0K\u001b[1G101.4 MiB [=                   ] 6% 1.5s\u001b[0K\u001b[1G101.4 MiB [==                  ] 7% 1.3s\u001b[0K\u001b[1G101.4 MiB [==                  ] 9% 1.3s\u001b[0K\u001b[1G101.4 MiB [==                  ] 11% 1.2s\u001b[0K\u001b[1G101.4 MiB [===                 ] 13% 1.1s\u001b[0K\u001b[1G101.4 MiB [===                 ] 15% 1.1s\u001b[0K\u001b[1G101.4 MiB [===                 ] 16% 1.0s\u001b[0K\u001b[1G101.4 MiB [====                ] 18% 1.0s\u001b[0K\u001b[1G101.4 MiB [====                ] 20% 0.9s\u001b[0K\u001b[1G101.4 MiB [====                ] 22% 0.9s\u001b[0K\u001b[1G101.4 MiB [=====               ] 23% 0.9s\u001b[0K\u001b[1G101.4 MiB [=====               ] 25% 0.8s\u001b[0K\u001b[1G101.4 MiB [=====               ] 27% 0.8s\u001b[0K\u001b[1G101.4 MiB [======              ] 29% 0.8s\u001b[0K\u001b[1G101.4 MiB [======              ] 32% 0.7s\u001b[0K\u001b[1G101.4 MiB [=======             ] 35% 0.7s\u001b[0K\u001b[1G101.4 MiB [=======             ] 37% 0.6s\u001b[0K\u001b[1G101.4 MiB [========            ] 39% 0.6s\u001b[0K\u001b[1G101.4 MiB [========            ] 41% 0.6s\u001b[0K\u001b[1G101.4 MiB [=========           ] 44% 0.5s\u001b[0K\u001b[1G101.4 MiB [=========           ] 47% 0.5s\u001b[0K\u001b[1G101.4 MiB [==========          ] 50% 0.5s\u001b[0K\u001b[1G101.4 MiB [===========         ] 52% 0.4s\u001b[0K\u001b[1G101.4 MiB [===========         ] 55% 0.4s\u001b[0K\u001b[1G101.4 MiB [============        ] 57% 0.4s\u001b[0K\u001b[1G101.4 MiB [============        ] 59% 0.4s\u001b[0K\u001b[1G101.4 MiB [============        ] 62% 0.3s\u001b[0K\u001b[1G101.4 MiB [=============       ] 64% 0.3s\u001b[0K\u001b[1G101.4 MiB [=============       ] 67% 0.3s\u001b[0K\u001b[1G101.4 MiB [==============      ] 69% 0.3s\u001b[0K\u001b[1G101.4 MiB [==============      ] 71% 0.2s\u001b[0K\u001b[1G101.4 MiB [===============     ] 73% 0.2s\u001b[0K\u001b[1G101.4 MiB [===============     ] 74% 0.2s\u001b[0K\u001b[1G101.4 MiB [===============     ] 77% 0.2s\u001b[0K\u001b[1G101.4 MiB [================    ] 79% 0.2s\u001b[0K\u001b[1G101.4 MiB [================    ] 81% 0.2s\u001b[0K\u001b[1G101.4 MiB [=================   ] 83% 0.1s\u001b[0K\u001b[1G101.4 MiB [=================   ] 86% 0.1s\u001b[0K\u001b[1G101.4 MiB [==================  ] 88% 0.1s\u001b[0K\u001b[1G101.4 MiB [==================  ] 90% 0.1s\u001b[0K\u001b[1G101.4 MiB [==================  ] 92% 0.1s\u001b[0K\u001b[1G101.4 MiB [=================== ] 94% 0.0s\u001b[0K\u001b[1G101.4 MiB [=================== ] 95% 0.0s\u001b[0K\u001b[1G101.4 MiB [=================== ] 97% 0.0s\u001b[0K\u001b[1G101.4 MiB [====================] 99% 0.0s\u001b[0K\u001b[1G101.4 MiB [====================] 100% 0.0s\u001b[0K\n",
      "Chromium Headless Shell 136.0.7103.25 (playwright build v1169) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1169\n",
      "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● Playwright installation completed successfully. \u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Starting database initialization\u001b[0m\u001b[36m...\u001b[0m\u001b[36m \u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[36mCOMPLETE\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m ● Database backup created at: \u001b[0m\u001b[36m/root/.crawl4ai/\u001b[0m\u001b[36mcrawl4ai.db.backup_20250607_212346\u001b[0m\u001b[36m \u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Starting database migration\u001b[0m\u001b[36m...\u001b[0m\u001b[36m \u001b[0m\n",
      "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● Migration completed. \u001b[0m\u001b[1;32m0\u001b[0m\u001b[32m records processed. \u001b[0m\n",
      "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● Database initialization completed successfully. \u001b[0m\n",
      "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● Post-installation setup completed! \u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Running Crawl4AI health check\u001b[0m\u001b[36m...\u001b[0m\u001b[36m \u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[36mTEST\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. ℹ Testing crawling capabilities\u001b[0m\u001b[36m...\u001b[0m\u001b[36m \u001b[0m\n",
      "\u001b[1;36m[\u001b[0m\u001b[36mEXPORT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m.. ℹ Exporting media \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mPDF/MHTML/screenshot\u001b[0m\u001b[1;36m)\u001b[0m\u001b[36m took \u001b[0m\u001b[1;36m1.\u001b[0m\u001b[36m76s \u001b[0m\n",
      "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ↓ \u001b[0m\u001b[4;32mhttps://crawl4ai.com\u001b[0m\u001b[32m                                                                   \u001b[0m\n",
      "\u001b[32m| \u001b[0m\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m3.\u001b[0m\u001b[32m93s \u001b[0m\n",
      "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ◆ \u001b[0m\u001b[4;32mhttps://crawl4ai.com\u001b[0m\u001b[32m                                                                   \u001b[0m\n",
      "\u001b[32m| \u001b[0m\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m10s \u001b[0m\n",
      "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● \u001b[0m\u001b[4;32mhttps://crawl4ai.com\u001b[0m\u001b[32m                                                                   \u001b[0m\n",
      "\u001b[32m| \u001b[0m\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m4.\u001b[0m\u001b[32m03s \u001b[0m\n",
      "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● ✅ Crawling test passed! \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install the package\n",
    "!pip install -U crawl4ai\n",
    "\n",
    "# For pre release versions\n",
    "!pip install crawl4ai --pre\n",
    "\n",
    "# Run post-installation setup\n",
    "!crawl4ai-setup\n",
    "\n",
    "# Verify your installation\n",
    "!crawl4ai-doctor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T12:08:56.334562Z",
     "iopub.status.busy": "2025-06-08T12:08:56.334064Z",
     "iopub.status.idle": "2025-06-08T12:09:05.801094Z",
     "shell.execute_reply": "2025-06-08T12:09:05.799795Z",
     "shell.execute_reply.started": "2025-06-08T12:08:56.334531Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.12.1)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
      "Collecting langchain_google_genai\n",
      "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.50)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.23)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain_google_genai)\n",
      "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.49 (from langchain)\n",
      "  Downloading langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.34.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.40.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (3.20.3)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.49->langchain)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.72.0rc1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.49.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain_google_genai-2.1.5-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.64-py3-none-any.whl (438 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: filetype, packaging, langsmith, langchain-core, google-ai-generativelanguage, langchain_google_genai\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.23\n",
      "    Uninstalling langsmith-0.3.23:\n",
      "      Successfully uninstalled langsmith-0.3.23\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.50\n",
      "    Uninstalling langchain-core-0.3.50:\n",
      "      Successfully uninstalled langchain-core-0.3.50\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
      "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-core-0.3.64 langchain_google_genai-2.1.5 langsmith-0.3.45 packaging-24.2\n"
     ]
    }
   ],
   "source": [
    "! pip install pymongo langchain langchain_google_genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing Code for new pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T18:43:27.237357Z",
     "iopub.status.busy": "2025-06-08T18:43:27.237054Z",
     "iopub.status.idle": "2025-06-08T18:45:00.214500Z",
     "shell.execute_reply": "2025-06-08T18:45:00.213402Z",
     "shell.execute_reply.started": "2025-06-08T18:43:27.237331Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qdrant-client\n",
      "  Downloading qdrant_client-1.14.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.2.0-py3-none-any.whl.metadata (941 bytes)\n",
      "Collecting langchain-qdrant\n",
      "  Downloading langchain_qdrant-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.12.1)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (1.72.0rc1)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (1.26.4)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (3.20.3)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.11.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.4.0)\n",
      "Collecting langchain-core<1.0.0,>=0.3.59 (from langchain-huggingface)\n",
      "  Downloading langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.51.3)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (3.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.31.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (1.1.0)\n",
      "Collecting langsmith<0.4,>=0.3.45 (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface)\n",
      "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.33)\n",
      "Collecting packaging>=20.9 (from huggingface-hub>=0.30.2->langchain-huggingface)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->qdrant-client) (2.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.15.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.59->langchain-huggingface) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (3.4.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->qdrant-client) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->qdrant-client) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21->qdrant-client) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21->qdrant-client) (2024.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.6.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21->qdrant-client) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
      "Downloading qdrant_client-1.14.2-py3-none-any.whl (327 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_huggingface-0.2.0-py3-none-any.whl (27 kB)\n",
      "Downloading langchain_qdrant-0.2.0-py3-none-any.whl (23 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading langchain_core-0.3.64-py3-none-any.whl (438 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-dotenv, portalocker, packaging, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, langsmith, langchain-core, qdrant-client, langchain-qdrant, langchain-huggingface\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.23\n",
      "    Uninstalling langsmith-0.3.23:\n",
      "      Successfully uninstalled langsmith-0.3.23\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.50\n",
      "    Uninstalling langchain-core-0.3.50:\n",
      "      Successfully uninstalled langchain-core-0.3.50\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-0.3.64 langchain-huggingface-0.2.0 langchain-qdrant-0.2.0 langsmith-0.3.45 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 packaging-24.2 portalocker-2.10.1 python-dotenv-1.1.0 qdrant-client-1.14.2\n"
     ]
    }
   ],
   "source": [
    "!pip install qdrant-client langchain-huggingface langchain-qdrant pymongo python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "SentenceTransformer(\"BAAI/bge-m3\")  # Lần đầu cần internet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T21:54:51.306871Z",
     "iopub.status.busy": "2025-06-08T21:54:51.306472Z",
     "iopub.status.idle": "2025-06-08T22:08:29.758909Z",
     "shell.execute_reply": "2025-06-08T22:08:29.757578Z",
     "shell.execute_reply.started": "2025-06-08T21:54:51.306845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import pymongo\n",
    "from pymongo.errors import PyMongoError\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from datetime import datetime\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "import uuid\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Thiết lập logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(\"KaggleIndexer\")\n",
    "\n",
    "# Kiểm tra và thiết lập GPU\n",
    "def setup_gpu():\n",
    "    \"\"\"Thiết lập GPU cho Kaggle\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        logger.info(f\"🚀 Sử dụng GPU: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "        \n",
    "        # Thiết lập memory management\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        \n",
    "        return device, \"cuda\"\n",
    "    else:\n",
    "        logger.warning(\"⚠️ Không tìm thấy GPU, sử dụng CPU\")\n",
    "        return torch.device(\"cpu\"), \"cpu\"\n",
    "\n",
    "# Thiết lập device\n",
    "DEVICE, DEVICE_TYPE = setup_gpu()\n",
    "\n",
    "class MongoToQdrantIndexer:\n",
    "    def __init__(self, \n",
    "                 mongo_uri=None,\n",
    "                 mongo_db_name=\"deeplearning_ai_news\",\n",
    "                 qdrant_endpoint=None,\n",
    "                 qdrant_api_key=None,\n",
    "                 qdrant_collection=\"news_embeddings\",\n",
    "                 vector_size=1024,\n",
    "                 chunk_size=500,\n",
    "                 chunk_overlap=50):\n",
    "        \n",
    "        # Cấu hình MongoDB\n",
    "        self.mongo_uri = mongo_uri or \"\"\n",
    "        self.mongo_db_name = mongo_db_name\n",
    "        \n",
    "        # Cấu hình Qdrant\n",
    "        self.qdrant_endpoint = qdrant_endpoint\n",
    "        self.qdrant_api_key = qdrant_api_key\n",
    "        self.qdrant_collection = qdrant_collection\n",
    "        self.vector_size = vector_size\n",
    "        \n",
    "        # Cấu hình chunking\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        \n",
    "        # Khởi tạo text splitter\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=self.chunk_size,\n",
    "            chunk_overlap=self.chunk_overlap,\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "        )\n",
    "        \n",
    "        # Khởi tạo embeddings model với GPU\n",
    "        logger.info(\"🔄 Đang tải model embedding...\")\n",
    "        \n",
    "        if DEVICE_TYPE == \"cuda\":\n",
    "            # Sử dụng SentenceTransformer trực tiếp để có control tốt hơn về GPU\n",
    "            self.embedding_model = SentenceTransformer(\"BAAI/bge-m3\", device=DEVICE)\n",
    "            \n",
    "            # Thiết lập model để sử dụng GPU hiệu quả\n",
    "            self.embedding_model.max_seq_length = 512  # Giới hạn sequence length\n",
    "            \n",
    "            # Wrapper cho HuggingFaceEmbeddings\n",
    "            self.embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=\"BAAI/bge-m3\",\n",
    "                model_kwargs={'device': DEVICE_TYPE},\n",
    "                encode_kwargs={'device': DEVICE_TYPE, 'batch_size': 32}  # Tăng batch size cho GPU\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"✅ Đã tải model embedding lên GPU\")\n",
    "        else:\n",
    "            # CPU fallback\n",
    "            self.embedding_model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "            self.embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=\"BAAI/bge-m3\",\n",
    "                encode_kwargs={'batch_size': 8}  # Batch size nhỏ hơn cho CPU\n",
    "            )\n",
    "            logger.info(\"✅ Đã tải model embedding (CPU)\")\n",
    "        \n",
    "        logger.info(\"✅ Hoàn thành tải model embedding\")\n",
    "        \n",
    "        # Khởi tạo kết nối\n",
    "        self._init_mongodb()\n",
    "        self._init_qdrant()\n",
    "    \n",
    "    def _init_mongodb(self):\n",
    "        \"\"\"Khởi tạo kết nối MongoDB\"\"\"\n",
    "        try:\n",
    "            self.mongo_client = pymongo.MongoClient(self.mongo_uri)\n",
    "            self.db = self.mongo_client[self.mongo_db_name]\n",
    "            # Test connection\n",
    "            self.mongo_client.admin.command('ping')\n",
    "            logger.info(\"Kết nối MongoDB thành công\")\n",
    "        except PyMongoError as e:\n",
    "            logger.error(f\"Lỗi kết nối MongoDB: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _init_qdrant(self):\n",
    "        \"\"\"Khởi tạo kết nối Qdrant và tạo collection\"\"\"\n",
    "        try:\n",
    "            self.qdrant_client = QdrantClient(\n",
    "                url=self.qdrant_endpoint,\n",
    "                api_key=self.qdrant_api_key,\n",
    "            )\n",
    "            \n",
    "            # Kiểm tra và tạo collection\n",
    "            collections = self.qdrant_client.get_collections()\n",
    "            collection_names = [collection.name for collection in collections.collections]\n",
    "            \n",
    "            if self.qdrant_collection not in collection_names:\n",
    "                self.qdrant_client.create_collection(\n",
    "                    collection_name=self.qdrant_collection,\n",
    "                    vectors_config=models.VectorParams(\n",
    "                        size=self.vector_size, \n",
    "                        distance=models.Distance.COSINE\n",
    "                    )\n",
    "                )\n",
    "                logger.info(f\"Đã tạo collection {self.qdrant_collection}\")\n",
    "            else:\n",
    "                logger.info(f\"Collection {self.qdrant_collection} đã tồn tại\")\n",
    "            \n",
    "            # Tạo index cho metadata\n",
    "            self._create_indexes()\n",
    "            \n",
    "            # Khởi tạo vector store\n",
    "            self.vector_store = QdrantVectorStore(\n",
    "                client=self.qdrant_client,\n",
    "                collection_name=self.qdrant_collection,\n",
    "                embedding=self.embeddings\n",
    "            )\n",
    "            \n",
    "            logger.info(\"Kết nối Qdrant thành công\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Lỗi kết nối Qdrant: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _create_indexes(self):\n",
    "        \"\"\"Tạo index cho các trường metadata\"\"\"\n",
    "        indexes = [\n",
    "            (\"metadata.document_id\", models.PayloadSchemaType.KEYWORD),\n",
    "            (\"metadata.url\", models.PayloadSchemaType.KEYWORD),\n",
    "            (\"metadata.chunk_id\", models.PayloadSchemaType.KEYWORD),\n",
    "            (\"metadata.category\", models.PayloadSchemaType.KEYWORD)\n",
    "        ]\n",
    "        \n",
    "        for field_name, field_type in indexes:\n",
    "            try:\n",
    "                self.qdrant_client.create_payload_index(\n",
    "                    collection_name=self.qdrant_collection,\n",
    "                    field_name=field_name,\n",
    "                    field_schema=field_type\n",
    "                )\n",
    "                logger.info(f\"Đã tạo index cho {field_name}\")\n",
    "            except Exception as e:\n",
    "                if \"already exists\" in str(e):\n",
    "                    logger.info(f\"Index cho {field_name} đã tồn tại\")\n",
    "                else:\n",
    "                    logger.warning(f\"Lỗi khi tạo index cho {field_name}: {e}\")\n",
    "    \n",
    "    def chunk_document(self, doc):\n",
    "        \"\"\"Chia nhỏ document thành chunks\"\"\"\n",
    "        content = doc.get('content', '')\n",
    "        if content == \"Không tìm thấy nội dung chi tiết\" or not content.strip():\n",
    "            title = doc.get('title', '')\n",
    "            description = doc.get('description', '')\n",
    "            content = f\"{title}\\n\\n{description}\"\n",
    "        \n",
    "        # Tạo LangChain Document với metadata\n",
    "        metadata = {\n",
    "            \"document_id\": str(doc.get('_id')),\n",
    "            \"title\": doc.get('title', ''),\n",
    "            \"author\": doc.get('author', 'Không có thông tin tác giả'),\n",
    "            \"category\": doc.get('category', ''),\n",
    "            \"url\": doc.get('url', ''),\n",
    "            \"publish_date\": doc.get('publish_date', ''),\n",
    "            \"description\": doc.get('description', ''),\n",
    "            \"tags\": doc.get('tags', []),\n",
    "            \"main_image\": doc.get('main_image', ''),\n",
    "            \"bullet_summary\": doc.get('bullet_summary', '')\n",
    "        }\n",
    "        \n",
    "        langchain_doc = Document(page_content=content, metadata=metadata)\n",
    "        chunks = self.text_splitter.split_documents([langchain_doc])\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def process_documents_batch(self, docs):\n",
    "        \"\"\"Xử lý một batch documents để tận dụng GPU hiệu quả\"\"\"\n",
    "        try:\n",
    "            all_chunks = []\n",
    "            all_ids = []\n",
    "            \n",
    "            # Chuẩn bị tất cả chunks từ batch\n",
    "            for doc in docs:\n",
    "                document_id = str(doc.get('_id'))\n",
    "                \n",
    "                # Xóa chunks cũ\n",
    "                try:\n",
    "                    self.qdrant_client.delete(\n",
    "                        collection_name=self.qdrant_collection,\n",
    "                        points_selector=models.FilterSelector(\n",
    "                            filter=models.Filter(\n",
    "                                must=[\n",
    "                                    models.FieldCondition(\n",
    "                                        key=\"metadata.document_id\",\n",
    "                                        match=models.MatchValue(value=document_id)\n",
    "                                    )\n",
    "                                ]\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Lỗi khi xóa chunks cũ cho {document_id}: {e}\")\n",
    "                \n",
    "                # Chia document thành chunks\n",
    "                chunks = self.chunk_document(doc)\n",
    "                if not chunks:\n",
    "                    continue\n",
    "                \n",
    "                # Thêm metadata cho mỗi chunk\n",
    "                for i, chunk in enumerate(chunks):\n",
    "                    chunk.metadata.update({\n",
    "                        \"document_id\": document_id,\n",
    "                        \"chunk_id\": f\"{document_id}_{i}\",\n",
    "                        \"chunk_index\": i,\n",
    "                        \"chunk_total\": len(chunks),\n",
    "                        \"chunk_content\": chunk.page_content,\n",
    "                        \"processed_at\": datetime.now().isoformat()\n",
    "                    })\n",
    "                \n",
    "                # Tạo IDs\n",
    "                chunk_ids = [str(uuid.uuid5(uuid.NAMESPACE_DNS, f\"{document_id}_{i}\")) \n",
    "                           for i in range(len(chunks))]\n",
    "                \n",
    "                all_chunks.extend(chunks)\n",
    "                all_ids.extend(chunk_ids)\n",
    "            \n",
    "            if not all_chunks:\n",
    "                return 0, len(docs)\n",
    "            \n",
    "            # Xử lý embedding theo batch lớn để tận dụng GPU\n",
    "            if DEVICE_TYPE == \"cuda\":\n",
    "                # Chia thành sub-batches để tránh OOM\n",
    "                batch_size = 64  # Có thể điều chỉnh tùy theo GPU memory\n",
    "                success_count = 0\n",
    "                \n",
    "                for i in range(0, len(all_chunks), batch_size):\n",
    "                    batch_chunks = all_chunks[i:i + batch_size]\n",
    "                    batch_ids = all_ids[i:i + batch_size]\n",
    "                    \n",
    "                    try:\n",
    "                        # Clear cache trước khi xử lý batch\n",
    "                        if DEVICE_TYPE == \"cuda\":\n",
    "                            torch.cuda.empty_cache()\n",
    "                        \n",
    "                        # Thêm vào vector store\n",
    "                        self.vector_store.add_documents(documents=batch_chunks, ids=batch_ids)\n",
    "                        success_count += len(batch_chunks)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Lỗi khi xử lý batch {i//batch_size + 1}: {e}\")\n",
    "                        # Thử xử lý từng chunk riêng lẻ\n",
    "                        for chunk, chunk_id in zip(batch_chunks, batch_ids):\n",
    "                            try:\n",
    "                                self.vector_store.add_documents(documents=[chunk], ids=[chunk_id])\n",
    "                                success_count += 1\n",
    "                            except Exception as e2:\n",
    "                                logger.error(f\"Lỗi chunk {chunk_id}: {e2}\")\n",
    "                \n",
    "                return success_count, len(docs) - success_count\n",
    "            else:\n",
    "                # CPU: xử lý toàn bộ batch\n",
    "                self.vector_store.add_documents(documents=all_chunks, ids=all_ids)\n",
    "                return len(docs), 0\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Lỗi khi xử lý batch: {e}\")\n",
    "            return 0, len(docs)\n",
    "    \n",
    "    def index_collection(self, collection_name, batch_size=20, limit=None):\n",
    "        \"\"\"Index toàn bộ collection từ MongoDB vào Qdrant với GPU optimization\"\"\"\n",
    "        logger.info(f\"🚀 Bắt đầu index collection: {collection_name}\")\n",
    "        \n",
    "        collection = self.db[collection_name]\n",
    "        \n",
    "        # Đếm tổng số documents\n",
    "        total_docs = collection.count_documents({})\n",
    "        if limit:\n",
    "            total_docs = min(total_docs, limit)\n",
    "        \n",
    "        logger.info(f\"📊 Tổng số documents cần xử lý: {total_docs}\")\n",
    "        \n",
    "        # Điều chỉnh batch size theo device\n",
    "        if DEVICE_TYPE == \"cuda\":\n",
    "            # GPU có thể xử lý batch lớn hơn\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "            if gpu_memory > 12:  # GPU > 12GB\n",
    "                batch_size = min(batch_size, 32)\n",
    "            else:  # GPU <= 12GB\n",
    "                batch_size = min(batch_size, 16)\n",
    "            logger.info(f\"🎯 Sử dụng batch size: {batch_size} (GPU)\")\n",
    "        else:\n",
    "            batch_size = min(batch_size, 8)  # CPU batch nhỏ hơn\n",
    "            logger.info(f\"🎯 Sử dụng batch size: {batch_size} (CPU)\")\n",
    "        \n",
    "        # Query documents\n",
    "        query = {}\n",
    "        cursor = collection.find(query).limit(limit) if limit else collection.find(query)\n",
    "        \n",
    "        success_count = 0\n",
    "        error_count = 0\n",
    "        batch = []\n",
    "        \n",
    "        # Xử lý với progress bar\n",
    "        with tqdm(total=total_docs, desc=\"🔄 Indexing documents\", \n",
    "                 unit=\"docs\", ncols=100) as pbar:\n",
    "            \n",
    "            for doc in cursor:\n",
    "                batch.append(doc)\n",
    "                \n",
    "                # Xử lý theo batch\n",
    "                if len(batch) >= batch_size:\n",
    "                    batch_success, batch_errors = self.process_documents_batch(batch)\n",
    "                    success_count += batch_success\n",
    "                    error_count += batch_errors\n",
    "                    \n",
    "                    # Cập nhật progress bar\n",
    "                    pbar.update(len(batch))\n",
    "                    pbar.set_postfix({\n",
    "                        'Success': success_count, \n",
    "                        'Errors': error_count,\n",
    "                        'GPU Memory': f\"{torch.cuda.memory_allocated()/1024**3:.1f}GB\" if DEVICE_TYPE == \"cuda\" else \"N/A\"\n",
    "                    })\n",
    "                    \n",
    "                    batch = []\n",
    "                    \n",
    "                    # GPU memory management\n",
    "                    if DEVICE_TYPE == \"cuda\":\n",
    "                        torch.cuda.empty_cache()\n",
    "                        time.sleep(0.1)  # Ngắn hơn cho GPU\n",
    "                    else:\n",
    "                        time.sleep(0.2)  # CPU cần nghỉ lâu hơn\n",
    "            \n",
    "            # Xử lý batch cuối cùng\n",
    "            if batch:\n",
    "                batch_success, batch_errors = self.process_documents_batch(batch)\n",
    "                success_count += batch_success\n",
    "                error_count += batch_errors\n",
    "                pbar.update(len(batch))\n",
    "        \n",
    "        # Final cleanup\n",
    "        if DEVICE_TYPE == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        logger.info(f\"✅ Hoàn thành indexing: {success_count} thành công, {error_count} lỗi\")\n",
    "        logger.info(f\"📈 Tỷ lệ thành công: {success_count/(success_count+error_count)*100:.1f}%\")\n",
    "        \n",
    "        return success_count, error_count\n",
    "    \n",
    "    def get_collection_stats(self):\n",
    "        \"\"\"Lấy thống kê về các collection trong MongoDB\"\"\"\n",
    "        collections = self.db.list_collection_names()\n",
    "        stats = {}\n",
    "        \n",
    "        for coll_name in collections:\n",
    "            count = self.db[coll_name].count_documents({})\n",
    "            stats[coll_name] = count\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def get_qdrant_stats(self):\n",
    "        \"\"\"Lấy thống kê về collection trong Qdrant\"\"\"\n",
    "        try:\n",
    "            collection_info = self.qdrant_client.get_collection(self.qdrant_collection)\n",
    "            return {\n",
    "                \"points_count\": collection_info.points_count,\n",
    "                \"vector_size\": collection_info.config.params.vectors.size,\n",
    "                \"indexed_fields\": collection_info.payload_schema\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Lỗi khi lấy stats Qdrant: {e}\")\n",
    "            return {}\n",
    "\n",
    "# Hàm chính để chạy indexing\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Hàm chính để chạy indexing với GPU optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🔥 KAGGLE MONGODB TO QDRANT INDEXER WITH GPU 🔥\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Hiển thị thông tin GPU\n",
    "    if DEVICE_TYPE == \"cuda\":\n",
    "        print(f\"🚀 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"💾 VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
    "        print(f\"🔧 CUDA Version: {torch.version.cuda}\")\n",
    "    else:\n",
    "        print(\"⚠️  Running on CPU (Consider enabling GPU in Kaggle)\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # CẤU HÌNH - Cập nhật thông tin của bạn tại đây\n",
    "    QDRANT_ENDPOINT = \"\"\n",
    "    QDRANT_API_KEY = \"\"\n",
    "    \n",
    "    # Khởi tạo indexer\n",
    "    indexer = MongoToQdrantIndexer(\n",
    "        qdrant_endpoint=QDRANT_ENDPOINT,\n",
    "        qdrant_api_key=QDRANT_API_KEY,\n",
    "        qdrant_collection=\"deeplearning_ai_news_embeddings\",\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    \n",
    "    # Xem thống kê MongoDB\n",
    "    print(\"\\n📊 THỐNG KÊ MONGODB\")\n",
    "    print(\"-\" * 30)\n",
    "    mongo_stats = indexer.get_collection_stats()\n",
    "    for coll, count in mongo_stats.items():\n",
    "        print(f\"📁 {coll}: {count:,} documents\")\n",
    "    \n",
    "    # Chọn collection để index\n",
    "    collection_to_index = \"data-points\"  # Thay bằng tên collection của bạn\n",
    "    \n",
    "    if collection_to_index not in mongo_stats:\n",
    "        print(f\"❌ Collection '{collection_to_index}' không tồn tại!\")\n",
    "        print(f\"✅ Các collection có sẵn: {list(mongo_stats.keys())}\")\n",
    "        return\n",
    "    \n",
    "    # Bắt đầu indexing\n",
    "    print(f\"\\n🚀 BẮT ĐẦU INDEXING: {collection_to_index}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Cấu hình cho GPU/CPU\n",
    "    if DEVICE_TYPE == \"cuda\":\n",
    "        batch_size = 24  # Batch lớn hơn cho GPU\n",
    "        limit = None     # Không giới hạn với GPU\n",
    "    else:\n",
    "        batch_size = 8   # Batch nhỏ hơn cho CPU\n",
    "        limit = None       # Giới hạn cho CPU\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    success, errors = indexer.index_collection(\n",
    "        collection_name=collection_to_index,\n",
    "        batch_size=batch_size,\n",
    "        limit=limit\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # Hiển thị kết quả\n",
    "    print(f\"\\n📈 KẾT QUẢ INDEXING\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"✅ Thành công: {success:,} documents\")\n",
    "    print(f\"❌ Lỗi: {errors:,} documents\")\n",
    "    print(f\"⏱️  Thời gian: {duration:.1f}s\")\n",
    "    print(f\"🚀 Tốc độ: {success/duration:.1f} docs/sec\")\n",
    "    \n",
    "    # Thống kê Qdrant\n",
    "    print(f\"\\n🎯 THỐNG KÊ QDRANT\")\n",
    "    print(\"-\" * 30)\n",
    "    qdrant_stats = indexer.get_qdrant_stats()\n",
    "    for key, value in qdrant_stats.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"📊 {key}: {value:,}\")\n",
    "        else:\n",
    "            print(f\"📊 {key}: {value}\")\n",
    "    \n",
    "    # Memory cleanup\n",
    "    if DEVICE_TYPE == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"\\n🧹 GPU Memory cleaned\")\n",
    "    \n",
    "    print(f\"\\n🎉 HOÀN THÀNH! 🎉\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T21:44:50.486832Z",
     "iopub.status.busy": "2025-06-08T21:44:50.486272Z",
     "iopub.status.idle": "2025-06-08T21:46:24.005667Z",
     "shell.execute_reply": "2025-06-08T21:46:24.003920Z",
     "shell.execute_reply.started": "2025-06-08T21:44:50.486800Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 KAGGLE MONGODB TO QDRANT INDEXER WITH GPU 🔥\n",
      "==================================================\n",
      "⚠️  Running on CPU (Consider enabling GPU in Kaggle)\n",
      "==================================================\n",
      "\n",
      "📊 THỐNG KÊ MONGODB\n",
      "------------------------------\n",
      "📁 science: 84 documents\n",
      "📁 data-points: 126 documents\n",
      "📁 hardware: 46 documents\n",
      "📁 ml-research: 455 documents\n",
      "📁 business: 223 documents\n",
      "📁 culture: 31 documents\n",
      "\n",
      "🚀 BẮT ĐẦU INDEXING: culture\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Indexing documents: 100%|█| 31/31 [01:18<00:00,  2.52s/docs, Success=24, Errors=0, GPU Memory=N/A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 KẾT QUẢ INDEXING\n",
      "------------------------------\n",
      "✅ Thành công: 31 documents\n",
      "❌ Lỗi: 0 documents\n",
      "⏱️  Thời gian: 78.3s\n",
      "🚀 Tốc độ: 0.4 docs/sec\n",
      "\n",
      "🎯 THỐNG KÊ QDRANT\n",
      "------------------------------\n",
      "📊 points_count: 6,250\n",
      "📊 vector_size: 1,024\n",
      "📊 indexed_fields: {'metadata.url': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=6250), 'metadata.chunk_id': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=6250), 'metadata.category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=6250), 'metadata.document_id': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=6250)}\n",
      "\n",
      "🎉 HOÀN THÀNH! 🎉\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Hàm chính để chạy indexing\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Hàm chính để chạy indexing với GPU optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🔥 KAGGLE MONGODB TO QDRANT INDEXER WITH GPU 🔥\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Hiển thị thông tin GPU\n",
    "    if DEVICE_TYPE == \"cuda\":\n",
    "        print(f\"🚀 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"💾 VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
    "        print(f\"🔧 CUDA Version: {torch.version.cuda}\")\n",
    "    else:\n",
    "        print(\"⚠️  Running on CPU (Consider enabling GPU in Kaggle)\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # CẤU HÌNH - Cập nhật thông tin của bạn tại đây\n",
    "    QDRANT_ENDPOINT = \"\"\n",
    "    QDRANT_API_KEY = \"\"\n",
    "    \n",
    "    # Khởi tạo indexer\n",
    "    indexer = MongoToQdrantIndexer(\n",
    "        qdrant_endpoint=QDRANT_ENDPOINT,\n",
    "        qdrant_api_key=QDRANT_API_KEY,\n",
    "        qdrant_collection=\"deeplearning_ai_news_embeddings\",\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    \n",
    "    # Xem thống kê MongoDB\n",
    "    print(\"\\n📊 THỐNG KÊ MONGODB\")\n",
    "    print(\"-\" * 30)\n",
    "    mongo_stats = indexer.get_collection_stats()\n",
    "    for coll, count in mongo_stats.items():\n",
    "        print(f\"📁 {coll}: {count:,} documents\")\n",
    "    \n",
    "    # Chọn collection để index\n",
    "    collection_to_index = \"culture\"  # Thay bằng tên collection của bạn\n",
    "    \n",
    "    if collection_to_index not in mongo_stats:\n",
    "        print(f\"❌ Collection '{collection_to_index}' không tồn tại!\")\n",
    "        print(f\"✅ Các collection có sẵn: {list(mongo_stats.keys())}\")\n",
    "        return\n",
    "    \n",
    "    # Bắt đầu indexing\n",
    "    print(f\"\\n🚀 BẮT ĐẦU INDEXING: {collection_to_index}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Cấu hình cho GPU/CPU\n",
    "    if DEVICE_TYPE == \"cuda\":\n",
    "        batch_size = 24  # Batch lớn hơn cho GPU\n",
    "        limit = None     # Không giới hạn với GPU\n",
    "    else:\n",
    "        batch_size = 8   # Batch nhỏ hơn cho CPU\n",
    "        limit = None       # Giới hạn cho CPU\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    success, errors = indexer.index_collection(\n",
    "        collection_name=collection_to_index,\n",
    "        batch_size=batch_size,\n",
    "        limit=limit\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # Hiển thị kết quả\n",
    "    print(f\"\\n📈 KẾT QUẢ INDEXING\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"✅ Thành công: {success:,} documents\")\n",
    "    print(f\"❌ Lỗi: {errors:,} documents\")\n",
    "    print(f\"⏱️  Thời gian: {duration:.1f}s\")\n",
    "    print(f\"🚀 Tốc độ: {success/duration:.1f} docs/sec\")\n",
    "    \n",
    "    # Thống kê Qdrant\n",
    "    print(f\"\\n🎯 THỐNG KÊ QDRANT\")\n",
    "    print(\"-\" * 30)\n",
    "    qdrant_stats = indexer.get_qdrant_stats()\n",
    "    for key, value in qdrant_stats.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"📊 {key}: {value:,}\")\n",
    "        else:\n",
    "            print(f\"📊 {key}: {value}\")\n",
    "    \n",
    "    # Memory cleanup\n",
    "    if DEVICE_TYPE == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"\\n🧹 GPU Memory cleaned\")\n",
    "    \n",
    "    print(f\"\\n🎉 HOÀN THÀNH! 🎉\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T21:46:24.008737Z",
     "iopub.status.busy": "2025-06-08T21:46:24.008392Z",
     "iopub.status.idle": "2025-06-08T21:50:07.826035Z",
     "shell.execute_reply": "2025-06-08T21:50:07.825062Z",
     "shell.execute_reply.started": "2025-06-08T21:46:24.008711Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 KAGGLE MONGODB TO QDRANT INDEXER WITH GPU 🔥\n",
      "==================================================\n",
      "⚠️  Running on CPU (Consider enabling GPU in Kaggle)\n",
      "==================================================\n",
      "\n",
      "📊 THỐNG KÊ MONGODB\n",
      "------------------------------\n",
      "📁 science: 84 documents\n",
      "📁 data-points: 126 documents\n",
      "📁 hardware: 46 documents\n",
      "📁 ml-research: 455 documents\n",
      "📁 business: 223 documents\n",
      "📁 culture: 31 documents\n",
      "\n",
      "🚀 BẮT ĐẦU INDEXING: science\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Indexing documents: 100%|█| 84/84 [03:31<00:00,  2.52s/docs, Success=80, Errors=0, GPU Memory=N/A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 KẾT QUẢ INDEXING\n",
      "------------------------------\n",
      "✅ Thành công: 84 documents\n",
      "❌ Lỗi: 0 documents\n",
      "⏱️  Thời gian: 211.6s\n",
      "🚀 Tốc độ: 0.4 docs/sec\n",
      "\n",
      "🎯 THỐNG KÊ QDRANT\n",
      "------------------------------\n",
      "📊 points_count: 6,634\n",
      "📊 vector_size: 1,024\n",
      "📊 indexed_fields: {'metadata.url': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=6634), 'metadata.document_id': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=6634), 'metadata.chunk_id': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=6634), 'metadata.category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=6634)}\n",
      "\n",
      "🎉 HOÀN THÀNH! 🎉\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Hàm chính để chạy indexing\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Hàm chính để chạy indexing với GPU optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🔥 KAGGLE MONGODB TO QDRANT INDEXER WITH GPU 🔥\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Hiển thị thông tin GPU\n",
    "    if DEVICE_TYPE == \"cuda\":\n",
    "        print(f\"🚀 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"💾 VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
    "        print(f\"🔧 CUDA Version: {torch.version.cuda}\")\n",
    "    else:\n",
    "        print(\"⚠️  Running on CPU (Consider enabling GPU in Kaggle)\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # CẤU HÌNH - Cập nhật thông tin của bạn tại đây\n",
    "    QDRANT_ENDPOINT = \"\"\n",
    "    QDRANT_API_KEY = \"\"\n",
    "    \n",
    "    # Khởi tạo indexer\n",
    "    indexer = MongoToQdrantIndexer(\n",
    "        qdrant_endpoint=QDRANT_ENDPOINT,\n",
    "        qdrant_api_key=QDRANT_API_KEY,\n",
    "        qdrant_collection=\"deeplearning_ai_news_embeddings\",\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    \n",
    "    # Xem thống kê MongoDB\n",
    "    print(\"\\n📊 THỐNG KÊ MONGODB\")\n",
    "    print(\"-\" * 30)\n",
    "    mongo_stats = indexer.get_collection_stats()\n",
    "    for coll, count in mongo_stats.items():\n",
    "        print(f\"📁 {coll}: {count:,} documents\")\n",
    "    \n",
    "    # Chọn collection để index\n",
    "    collection_to_index = \"science\"  # Thay bằng tên collection của bạn\n",
    "    \n",
    "    if collection_to_index not in mongo_stats:\n",
    "        print(f\"❌ Collection '{collection_to_index}' không tồn tại!\")\n",
    "        print(f\"✅ Các collection có sẵn: {list(mongo_stats.keys())}\")\n",
    "        return\n",
    "    \n",
    "    # Bắt đầu indexing\n",
    "    print(f\"\\n🚀 BẮT ĐẦU INDEXING: {collection_to_index}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Cấu hình cho GPU/CPU\n",
    "    if DEVICE_TYPE == \"cuda\":\n",
    "        batch_size = 24  # Batch lớn hơn cho GPU\n",
    "        limit = None     # Không giới hạn với GPU\n",
    "    else:\n",
    "        batch_size = 8   # Batch nhỏ hơn cho CPU\n",
    "        limit = None       # Giới hạn cho CPU\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    success, errors = indexer.index_collection(\n",
    "        collection_name=collection_to_index,\n",
    "        batch_size=batch_size,\n",
    "        limit=limit\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # Hiển thị kết quả\n",
    "    print(f\"\\n📈 KẾT QUẢ INDEXING\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"✅ Thành công: {success:,} documents\")\n",
    "    print(f\"❌ Lỗi: {errors:,} documents\")\n",
    "    print(f\"⏱️  Thời gian: {duration:.1f}s\")\n",
    "    print(f\"🚀 Tốc độ: {success/duration:.1f} docs/sec\")\n",
    "    \n",
    "    # Thống kê Qdrant\n",
    "    print(f\"\\n🎯 THỐNG KÊ QDRANT\")\n",
    "    print(\"-\" * 30)\n",
    "    qdrant_stats = indexer.get_qdrant_stats()\n",
    "    for key, value in qdrant_stats.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"📊 {key}: {value:,}\")\n",
    "        else:\n",
    "            print(f\"📊 {key}: {value}\")\n",
    "    \n",
    "    # Memory cleanup\n",
    "    if DEVICE_TYPE == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"\\n🧹 GPU Memory cleaned\")\n",
    "    \n",
    "    print(f\"\\n🎉 HOÀN THÀNH! 🎉\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T21:50:07.827328Z",
     "iopub.status.busy": "2025-06-08T21:50:07.827078Z",
     "iopub.status.idle": "2025-06-08T21:52:22.121127Z",
     "shell.execute_reply": "2025-06-08T21:52:22.119638Z",
     "shell.execute_reply.started": "2025-06-08T21:50:07.827308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 KAGGLE MONGODB TO QDRANT INDEXER WITH GPU 🔥\n",
      "==================================================\n",
      "⚠️  Running on CPU (Consider enabling GPU in Kaggle)\n",
      "==================================================\n",
      "\n",
      "📊 THỐNG KÊ MONGODB\n",
      "------------------------------\n",
      "📁 science: 84 documents\n",
      "📁 data-points: 126 documents\n",
      "📁 hardware: 46 documents\n",
      "📁 ml-research: 455 documents\n",
      "📁 business: 223 documents\n",
      "📁 culture: 31 documents\n",
      "\n",
      "🚀 BẮT ĐẦU INDEXING: hardware\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Indexing documents: 100%|█| 46/46 [02:00<00:00,  2.63s/docs, Success=40, Errors=0, GPU Memory=N/A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 KẾT QUẢ INDEXING\n",
      "------------------------------\n",
      "✅ Thành công: 46 documents\n",
      "❌ Lỗi: 0 documents\n",
      "⏱️  Thời gian: 121.1s\n",
      "🚀 Tốc độ: 0.4 docs/sec\n",
      "\n",
      "🎯 THỐNG KÊ QDRANT\n",
      "------------------------------\n",
      "📊 points_count: 6,789\n",
      "📊 vector_size: 1,024\n",
      "📊 indexed_fields: {'metadata.chunk_id': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=6789), 'metadata.document_id': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=6789), 'metadata.category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=6789), 'metadata.url': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=6789)}\n",
      "\n",
      "🎉 HOÀN THÀNH! 🎉\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Hàm chính để chạy indexing\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Hàm chính để chạy indexing với GPU optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🔥 KAGGLE MONGODB TO QDRANT INDEXER WITH GPU 🔥\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Hiển thị thông tin GPU\n",
    "    if DEVICE_TYPE == \"cuda\":\n",
    "        print(f\"🚀 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"💾 VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
    "        print(f\"🔧 CUDA Version: {torch.version.cuda}\")\n",
    "    else:\n",
    "        print(\"⚠️  Running on CPU (Consider enabling GPU in Kaggle)\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # CẤU HÌNH - Cập nhật thông tin của bạn tại đây\n",
    "    QDRANT_ENDPOINT = \"\"\n",
    "    QDRANT_API_KEY = \"\"\n",
    "    \n",
    "    # Khởi tạo indexer\n",
    "    indexer = MongoToQdrantIndexer(\n",
    "        qdrant_endpoint=QDRANT_ENDPOINT,\n",
    "        qdrant_api_key=QDRANT_API_KEY,\n",
    "        qdrant_collection=\"deeplearning_ai_news_embeddings\",\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    \n",
    "    # Xem thống kê MongoDB\n",
    "    print(\"\\n📊 THỐNG KÊ MONGODB\")\n",
    "    print(\"-\" * 30)\n",
    "    mongo_stats = indexer.get_collection_stats()\n",
    "    for coll, count in mongo_stats.items():\n",
    "        print(f\"📁 {coll}: {count:,} documents\")\n",
    "    \n",
    "    # Chọn collection để index\n",
    "    collection_to_index = \"hardware\"  # Thay bằng tên collection của bạn\n",
    "    \n",
    "    if collection_to_index not in mongo_stats:\n",
    "        print(f\"❌ Collection '{collection_to_index}' không tồn tại!\")\n",
    "        print(f\"✅ Các collection có sẵn: {list(mongo_stats.keys())}\")\n",
    "        return\n",
    "    \n",
    "    # Bắt đầu indexing\n",
    "    print(f\"\\n🚀 BẮT ĐẦU INDEXING: {collection_to_index}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Cấu hình cho GPU/CPU\n",
    "    if DEVICE_TYPE == \"cuda\":\n",
    "        batch_size = 24  # Batch lớn hơn cho GPU\n",
    "        limit = None     # Không giới hạn với GPU\n",
    "    else:\n",
    "        batch_size = 8   # Batch nhỏ hơn cho CPU\n",
    "        limit = None       # Giới hạn cho CPU\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    success, errors = indexer.index_collection(\n",
    "        collection_name=collection_to_index,\n",
    "        batch_size=batch_size,\n",
    "        limit=limit\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # Hiển thị kết quả\n",
    "    print(f\"\\n📈 KẾT QUẢ INDEXING\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"✅ Thành công: {success:,} documents\")\n",
    "    print(f\"❌ Lỗi: {errors:,} documents\")\n",
    "    print(f\"⏱️  Thời gian: {duration:.1f}s\")\n",
    "    print(f\"🚀 Tốc độ: {success/duration:.1f} docs/sec\")\n",
    "    \n",
    "    # Thống kê Qdrant\n",
    "    print(f\"\\n🎯 THỐNG KÊ QDRANT\")\n",
    "    print(\"-\" * 30)\n",
    "    qdrant_stats = indexer.get_qdrant_stats()\n",
    "    for key, value in qdrant_stats.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"📊 {key}: {value:,}\")\n",
    "        else:\n",
    "            print(f\"📊 {key}: {value}\")\n",
    "    \n",
    "    # Memory cleanup\n",
    "    if DEVICE_TYPE == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"\\n🧹 GPU Memory cleaned\")\n",
    "    \n",
    "    print(f\"\\n🎉 HOÀN THÀNH! 🎉\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7648899,
     "sourceId": 12166439,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7666620,
     "sourceId": 12172832,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
