{
  "all-about-the-hollywood-actors-and-studios-deal-on-generative-ai-usage-in-films-and-tv": {
    "title": "Actors Reach Accord on AI",
    "collection": "culture",
    "content": "The longest actors’ strike in Hollywood history ended as actors and studios reached an accord on the use of generative AI in making movies.\n\nWhat’s new: Film studios must seek an actor’s consent before using a generated likeness or performance and compensate the actor, according to anagreementbetween the trade union Screen Actors Guild-American Federation of Television and Radio Artists (SAG-AFTRA) and the Alliance of Motion Picture and Television Producers (TMPTP). The pact will remain in effect for three years, once it has been ratified by SAG-AFTRA members.\n\nHow it works:The agreement covers digital replicas of human actors, synthetic performers, and simulated performances created using AI and other technologies that may not be generally recognized as AI. The parties argued over terms with respect to AI until the very last day of their 118-day negotiation,accordingto SAG-AFTRA’s president. Among the provisions:\n\nBehind the news:The agreement followed a similar three-yeardealin September that ended the concurrent strike by Writers Guild of America.\n\nYes, but:The agreement covers on-screen actors. It does not cover voice or motion actors in video games or television animation. In September, SAG-AFTRAauthorizeda strike against a group of video game companies if negotiations, which are ongoing, stall. Negotiations over television animation are expected as well.\n\nWhy it matters:The actors’ agreement could set an international example for limits on AI in the performing arts, thanks to the U.S. film and television industry’s global reach. Entertainers’ unions in Europe and Canada arecontemplatingstrikes inspired by SAG-AFTRA’s, and they may seek similar agreements.\n\nWe’re thinking:As with the screenwriters’ contract, the agreement between actors and studios gives everyone three years to experiment with AI while respecting the consent, credit, and compensation of creative workers. We hope that shows made in this period provide ample evidence that such tools can yield wonderful productions that enlarge the market, and that the next agreement focuses more on growing the use of AI and dividing the winnings fairly among actors, studios, and technologists.",
    "qa": [
      {
        "question": "Thỏa thuận giữa SAG-AFTRA và AMPTP tập trung giải quyết vấn đề gì?",
        "options": {
          "A": "Mức lương tối thiểu cho diễn viên Hollywood.",
          "B": "Việc sử dụng trí tuệ nhân tạo (AI) trong sản xuất phim.",
          "C": "Quyền lợi của các nhà biên kịch trong ngành điện ảnh.",
          "D": "Điều kiện làm việc của diễn viên trên phim trường."
        },
        "answer": "B"
      },
      {
        "question": "Thời gian hiệu lực của thỏa thuận giữa SAG-AFTRA và AMPTP là bao lâu sau khi được phê chuẩn?",
        "options": {
          "A": "Vô thời hạn.",
          "B": "Ba năm.",
          "C": "Năm năm.",
          "D": "Mười năm."
        },
        "answer": "B"
      },
      {
        "question": "Theo thỏa thuận, điều gì phải được thực hiện trước khi studio sử dụng hình ảnh hoặc diễn xuất được tạo ra bởi AI của một diễn viên?",
        "options": {
          "A": "Thông báo cho công chúng.",
          "B": "Xin phép và bồi thường cho diễn viên.",
          "C": "Tham khảo ý kiến của các nhà làm phim khác.",
          "D": "Được sự chấp thuận của AMPTP."
        },
        "answer": "B"
      },
      {
        "question": "Thỏa thuận này không bao gồm những đối tượng diễn viên nào?",
        "options": {
          "A": "Diễn viên đóng vai chính.",
          "B": "Diễn viên lồng tiếng và diễn viên chuyển động trong trò chơi điện tử và phim hoạt hình truyền hình.",
          "C": "Diễn viên đóng vai quần chúng.",
          "D": "Diễn viên đóng vai phản diện."
        },
        "answer": "B"
      },
      {
        "question": "Cuộc đình công của diễn viên kéo dài bao lâu trước khi đạt được thỏa thuận?",
        "options": {
          "A": "90 ngày.",
          "B": "100 ngày.",
          "C": "118 ngày.",
          "D": "150 ngày."
        },
        "answer": "C"
      },
      {
        "question": "Thỏa thuận này có thể có tác động gì trên phạm vi quốc tế?",
        "options": {
          "A": "Tăng cường hợp tác giữa các studio phim trên toàn thế giới.",
          "B": "Đặt ra một hình mẫu quốc tế cho việc giới hạn AI trong nghệ thuật biểu diễn.",
          "C": "Thúc đẩy sự phát triển của công nghệ AI trong ngành giải trí.",
          "D": "Giảm thiểu sự cạnh tranh giữa các diễn viên quốc tế."
        },
        "answer": "B"
      },
      {
        "question": "Tổ chức nào đã đình công đồng thời với SAG-AFTRA và đạt được thỏa thuận trước đó?",
        "options": {
          "A": "Hiệp hội Đạo diễn Hoa Kỳ (DGA).",
          "B": "Hiệp hội Nhà sản xuất Phim và Truyền hình (AMPTP).",
          "C": "Hiệp hội Biên kịch Hoa Kỳ (WGA).",
          "D": "Hiệp hội Kỹ thuật viên Điện ảnh (IATSE)."
        },
        "answer": "C"
      },
      {
        "question": "SAG-AFTRA đã ủy quyền đình công chống lại nhóm công ty nào nếu đàm phán bị đình trệ?",
        "options": {
          "A": "Các công ty sản xuất phim độc lập.",
          "B": "Các công ty trò chơi điện tử.",
          "C": "Các công ty truyền hình.",
          "D": "Các công ty quảng cáo."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu dài hạn được kỳ vọng từ thỏa thuận này là gì?",
        "options": {
          "A": "Hạn chế hoàn toàn việc sử dụng AI trong ngành giải trí.",
          "B": "Tăng cường sự kiểm soát của các studio đối với diễn viên.",
          "C": "Phát triển việc sử dụng AI một cách công bằng, chia sẻ lợi nhuận giữa diễn viên, studio và nhà công nghệ.",
          "D": "Giảm chi phí sản xuất phim."
        },
        "answer": "C"
      },
      {
        "question": "Thuật ngữ nào được sử dụng để mô tả các diễn viên được tạo ra bằng AI trong thỏa thuận?",
        "options": {
          "A": "Diễn viên ảo.",
          "B": "Diễn viên kỹ thuật số.",
          "C": "Người biểu diễn tổng hợp.",
          "D": "Tất cả các đáp án trên."
        },
        "answer": "D"
      }
    ]
  },
  "ai-that-unites-us": {
    "title": "Audrey Tang",
    "collection": "culture",
    "content": "As we approach 2025, my greatest hope for AI is that it will enableprosocialplatforms that promote empathy, understanding, and collaboration rather than division.\n\nFor too long, the algorithms that drive social media have functioned like strip-mining machines, extracting attention while eroding trust and social cohesion. What remains are depleted online spaces, where empathy struggles to take root and collective problem-solving finds no fertile ground. AI can — and should — help us transcend these entrenched divides.\n\nTo achieve this, we must design AI systems that place prosocial values at their core. Instead of reinforcing fragmentation, recommendation algorithms can guide us toward “bridging content” that reveals common ground. They should clearly identify the communities a piece of content relates to — whether physical, religious, political, social, cultural, or professional — and illuminate the specific lines of division it seeks to mend.\n\nRealizing this vision requires a fundamental shift in what we optimize for. Instead of relying on pure engagement metrics, we should adopt values-driven indicators that prioritize constructive discourse and mutual understanding. For instance, we might spotlight “surprising validators,” or individuals and perspectives that productively challenge assumptions, thereby enriching our sense of what seemed irreconcilable. Researchers and developers should co-create new ranking and curation methods, embed them into widely used platforms, and rigorouslyassesstheir impact on democratic life.\n\nAt the same time, the AI community must embrace participatory, inclusive approaches to development and governance. Research onpluralistic alignmentstresses that AI systems emerge from and operate within complex social contexts, and including a wide range of voices helps guard against institutional blind spots. Tools likePolis, which can visualize stances and reveal hidden areas of consensus, already illustrate how complexity can be transformed into clarity. Such participatory methods ensure that AI reflects the priorities and values of the societies it serves, rather than amplifying the biases of the few.\n\nBy embracing these inclusive, democratic principles, AI can help us co-createdigital public squaresthat foster social cohesion rather than erode it. Embedding collective input at every stage — from how we build datasets to how we set governance policies — ensures that AI systems genuinely align with a spectrum of human values and serve as catalysts for common understanding.\n\nAudrey Tang is Taiwan’s Cyber Ambassador, former Minister of Digital Affairs, and co-author ofPlurality: The Future of Collaborative Technology and Democracy.",
    "qa": [
      {
        "question": "Theo tác giả, điều gì là hy vọng lớn nhất cho AI vào năm 2025?",
        "options": {
          "A": "AI sẽ thay thế hoàn toàn các nền tảng truyền thông xã hội hiện tại.",
          "B": "AI sẽ tạo ra các nền tảng vị xã hội thúc đẩy sự đồng cảm, thấu hiểu và hợp tác.",
          "C": "AI sẽ giúp các công ty truyền thông xã hội tăng lợi nhuận đáng kể.",
          "D": "AI sẽ giải quyết tất cả các vấn đề xã hội hiện tại."
        },
        "answer": "B"
      },
      {
        "question": "Tác giả ví các thuật toán truyền thông xã hội hiện tại như thế nào?",
        "options": {
          "A": "Những công cụ xây dựng cộng đồng vững mạnh.",
          "B": "Những cỗ máy khai thác mỏ, rút cạn sự chú ý và xói mòn lòng tin.",
          "C": "Những người bạn đồng hành đáng tin cậy trong việc giải quyết vấn đề.",
          "D": "Những hệ thống hỗ trợ đắc lực cho sự phát triển kinh tế."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, các thuật toán đề xuất nên hướng người dùng đến loại nội dung nào?",
        "options": {
          "A": "Nội dung gây tranh cãi để kích thích thảo luận.",
          "B": "Nội dung mang tính giải trí cao để thu hút sự chú ý.",
          "C": "Nội dung 'kết nối' giúp khám phá điểm chung.",
          "D": "Nội dung củng cố quan điểm cá nhân của người dùng."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề xuất thay thế các chỉ số tương tác thuần túy bằng loại chỉ số nào?",
        "options": {
          "A": "Các chỉ số đánh giá mức độ lan truyền của thông tin.",
          "B": "Các chỉ số dựa trên cảm xúc của người dùng.",
          "C": "Các chỉ số ưu tiên thảo luận mang tính xây dựng và sự thấu hiểu lẫn nhau.",
          "D": "Các chỉ số đo lường mức độ ảnh hưởng của người dùng."
        },
        "answer": "C"
      },
      {
        "question": "Trong bài viết, 'người xác nhận đáng ngạc nhiên' (surprising validators) được định nghĩa là gì?",
        "options": {
          "A": "Những người nổi tiếng bất ngờ ủng hộ một sản phẩm.",
          "B": "Những cá nhân và quan điểm thách thức các giả định một cách hiệu quả.",
          "C": "Những chuyên gia đưa ra những dự đoán gây sốc.",
          "D": "Những người dùng bất ngờ trở thành người có ảnh hưởng trên mạng xã hội."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu về 'sự liên kết đa nguyên' (pluralistic alignment) nhấn mạnh điều gì về hệ thống AI?",
        "options": {
          "A": "Hệ thống AI nên được phát triển bởi một nhóm nhỏ các chuyên gia hàng đầu.",
          "B": "Hệ thống AI nên hoạt động độc lập với bối cảnh xã hội.",
          "C": "Hệ thống AI nên được thiết kế để tối đa hóa lợi nhuận cho các nhà phát triển.",
          "D": "Hệ thống AI phát sinh và hoạt động trong bối cảnh xã hội phức tạp."
        },
        "answer": "D"
      },
      {
        "question": "Công cụ 'Polis' được đề cập trong bài viết có chức năng gì?",
        "options": {
          "A": "Tự động kiểm duyệt nội dung trên mạng xã hội.",
          "B": "Trực quan hóa các quan điểm và tiết lộ các lĩnh vực đồng thuận ẩn.",
          "C": "Tạo ra các nội dung tin tức giả mạo.",
          "D": "Phân tích dữ liệu người dùng để đưa ra các quảng cáo được nhắm mục tiêu."
        },
        "answer": "B"
      },
      {
        "question": "Theo tác giả, điều gì đảm bảo rằng AI thực sự phù hợp với một loạt các giá trị của con người?",
        "options": {
          "A": "Việc sử dụng các thuật toán phức tạp nhất.",
          "B": "Việc nhúng đầu vào tập thể ở mọi giai đoạn, từ xây dựng bộ dữ liệu đến thiết lập chính sách quản trị.",
          "C": "Việc tập trung vào tối đa hóa lợi nhuận cho các công ty công nghệ.",
          "D": "Việc tuân thủ nghiêm ngặt các quy định của chính phủ."
        },
        "answer": "B"
      },
      {
        "question": "Tác giả của bài viết là ai?",
        "options": {
          "A": "Một nhà nghiên cứu AI ẩn danh.",
          "B": "Một giám đốc điều hành của một công ty truyền thông xã hội lớn.",
          "C": "Audrey Tang, Cyber Ambassador của Đài Loan và cựu Bộ trưởng Bộ Các vấn đề Kỹ thuật số.",
          "D": "Một giáo sư đại học chuyên về đạo đức AI."
        },
        "answer": "C"
      },
      {
        "question": "Cuốn sách nào được tác giả đồng sáng tác?",
        "options": {
          "A": "The Future of Artificial Intelligence.",
          "B": "Democracy and the Digital Age.",
          "C": "Plurality: The Future of Collaborative Technology and Democracy.",
          "D": "AI for Social Good."
        },
        "answer": "C"
      }
    ]
  },
  "amazon-echo-uses-generative-ai-to-create-bedtime-stories": {
    "title": "How Alexa Says Goodnight",
    "collection": "culture",
    "content": "Too exhausted (or unimaginative) to tell your child a bedtime story? Amazon’s smart displays can spin bespoke tales on demand.What’s new:A feature called Create with Alexagenerateschildren’s stories complete with illustrations, music, and sound effects on the Amazon Echo Show device.\n\nHow it works:The screen presents a series of prompts that provide a setting (such as “space exploration” or “enchanted forest”), main character (such as an astronaut or an alien), principal color, and tone (such as “happy” or “mysterious”).\n\nBehind the news:Amazon is under pressure to revitalize its 10-year-old Echo line. The devices, which have been sold at a loss on the theory that they would spur purchases of other goods,lost$10 billion in 2022 alone, and the division responsible for the Alexa softwarefacessteep layoffs.Why it matters:AI models that generate text, images, video, and music are having abanner year. Alexa’s storytelling feature coordinates several generative models into a coherent whole. Whether it will spur sales is a tale for another time.We’re thinking:Once upon a time, there was a boy in a blue shirt who dreamed of changing the world with AI. . . .",
    "qa": [
      {
        "question": "Tính năng 'Create with Alexa' tạo ra những gì cho trẻ em?",
        "options": {
          "A": "Các bài hát ru ngủ với hiệu ứng âm thanh nhẹ nhàng.",
          "B": "Những câu chuyện được cá nhân hóa kèm hình ảnh, âm nhạc và hiệu ứng âm thanh.",
          "C": "Các trò chơi tương tác giúp trẻ phát triển trí tuệ.",
          "D": "Những đoạn phim hoạt hình ngắn với nội dung giáo dục."
        },
        "answer": "B"
      },
      {
        "question": "Người dùng cung cấp thông tin gì cho 'Create with Alexa' để tạo câu chuyện?",
        "options": {
          "A": "Tên nhân vật chính và sở thích của trẻ.",
          "B": "Bối cảnh, nhân vật chính, màu sắc chủ đạo và giọng điệu.",
          "C": "Thể loại truyện yêu thích và độ dài mong muốn.",
          "D": "Bài học đạo đức muốn truyền tải trong câu chuyện."
        },
        "answer": "B"
      },
      {
        "question": "Thiết bị nào của Amazon được đề cập đến trong bài viết có tính năng 'Create with Alexa'?",
        "options": {
          "A": "Amazon Kindle.",
          "B": "Amazon Fire Tablet.",
          "C": "Amazon Echo Show.",
          "D": "Amazon Echo Dot."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, lý do chính khiến Amazon chịu áp lực phải cải tiến dòng sản phẩm Echo là gì?",
        "options": {
          "A": "Sự cạnh tranh gay gắt từ các đối thủ trên thị trường.",
          "B": "Doanh số bán hàng giảm sút và thua lỗ lớn.",
          "C": "Phản hồi tiêu cực từ người dùng về chất lượng sản phẩm.",
          "D": "Chi phí sản xuất tăng cao."
        },
        "answer": "B"
      },
      {
        "question": "Trong năm 2022, bộ phận chịu trách nhiệm về phần mềm Alexa đã bị ảnh hưởng như thế nào?",
        "options": {
          "A": "Được đầu tư mạnh mẽ để phát triển các tính năng mới.",
          "B": "Phải đối mặt với tình trạng cắt giảm nhân sự sâu rộng.",
          "C": "Sáp nhập với một bộ phận khác để tăng hiệu quả hoạt động.",
          "D": "Được tách ra thành một công ty độc lập."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về các mô hình AI hiện nay?",
        "options": {
          "A": "Chúng đang dần thay thế con người trong nhiều lĩnh vực.",
          "B": "Chúng đang có một năm thành công trong việc tạo ra văn bản, hình ảnh, video và âm nhạc.",
          "C": "Chúng vẫn còn nhiều hạn chế và cần được cải thiện hơn nữa.",
          "D": "Chúng đang gây ra nhiều tranh cãi về vấn đề đạo đức."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng kể chuyện của Alexa phối hợp nhiều mô hình AI khác nhau để tạo ra điều gì?",
        "options": {
          "A": "Một câu chuyện có nội dung phức tạp và nhiều tầng ý nghĩa.",
          "B": "Một câu chuyện hoàn chỉnh và mạch lạc.",
          "C": "Một câu chuyện có khả năng tương tác cao với người dùng.",
          "D": "Một câu chuyện có thể tự động điều chỉnh theo phản ứng của người nghe."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến việc liệu tính năng kể chuyện của Alexa có thúc đẩy doanh số bán hàng hay không như thế nào?",
        "options": {
          "A": "Chắc chắn sẽ giúp tăng doanh số bán hàng đáng kể.",
          "B": "Vẫn còn là một ẩn số và cần thời gian để kiểm chứng.",
          "C": "Có thể sẽ không ảnh hưởng nhiều đến doanh số bán hàng.",
          "D": "Sẽ chỉ có tác động tích cực đến doanh số bán hàng trong ngắn hạn."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, Amazon đã bán các thiết bị Echo với mục đích gì?",
        "options": {
          "A": "Để tạo ra lợi nhuận trực tiếp từ việc bán thiết bị.",
          "B": "Để thúc đẩy việc mua các sản phẩm khác của Amazon.",
          "C": "Để cạnh tranh với các đối thủ trên thị trường thiết bị thông minh.",
          "D": "Để thu thập dữ liệu người dùng cho mục đích quảng cáo."
        },
        "answer": "B"
      },
      {
        "question": "Câu cuối cùng của bài viết gợi ý về điều gì?",
        "options": {
          "A": "Sự phát triển của trí tuệ nhân tạo sẽ mang lại nhiều lợi ích cho trẻ em.",
          "B": "Một cậu bé mơ ước thay đổi thế giới bằng AI.",
          "C": "Màu xanh là màu sắc yêu thích của nhiều trẻ em.",
          "D": "Những câu chuyện cổ tích luôn có một kết thúc tốt đẹp."
        },
        "answer": "B"
      }
    ]
  },
  "bridge-to-explainable-ai": {
    "title": "Bridge to Explainable AI",
    "collection": "culture",
    "content": "DeepMind’s AlphaGo famously dominated Go, a game in which players can see the state of play at all times. A new AI system demonstrated similar mastery of bridge, in which crucial information remains hidden.What’s new:NooK, built by Jean-Baptiste Fantun, Véronique Ventos, and colleagues at the French startup NukkAI, recently beat eight world champions at bridge — rather, a core aspect of the game.Rules of the game:Bridge is played by four players grouped into teams of two. Each player is dealt a hand of cards, after which the game is played in two phases:\n\nThis study focused on the play phase, pitting NooK and human champions against previous automated bridge-playing systems, none of which has proven superior to an excellent human player. Each deal had a preassigned bid and trump suit, and competitors played the same 800 deals, divided into sets of 10. The player with the highest average score in the most sets won.How it works:The developers didn’t reveal the mechanisms behind NooK, but we can offer a guess based on press reports and the company’sresearchpapers.\n\nResults:Pitted against the previous systems, NooK scored higher than the human champions in 67 out of 80 sets, or 83 percent of the time.Why it matters:Neural networks would be more useful in many situations if they were more interpretable; that is, if they could tell us why they classified a cat as a cat, or misclassified a cat as an iguana. This work’s approach offers one way to build more interpretable systems: a neurosymbolic hybrid that combines rules (symbolic AI, also known as good old-fashioned AI) describing various situations with neural networks trained to handle specific cases of each situation.We’re thinking:In bridge, bidding is a way to hint to your partner (and deceive your opponent) about what you have in your hand, and thus a vital strategic element. NooK is impressive as far as it goes, but mastering bids and teamwork lie ahead.",
    "qa": [
      {
        "question": "Hệ thống AI NooK được phát triển bởi tổ chức nào?",
        "options": {
          "A": "DeepMind",
          "B": "NukkAI",
          "C": "Google AI",
          "D": "Facebook AI Research"
        },
        "answer": "B"
      },
      {
        "question": "NooK đã đánh bại các nhà vô địch thế giới ở khía cạnh nào của trò chơi Bridge?",
        "options": {
          "A": "Toàn bộ trò chơi Bridge, bao gồm cả đấu thầu và chơi bài.",
          "B": "Giai đoạn chơi bài (play phase) sau khi đã có đấu thầu và chọn chất chủ.",
          "C": "Giai đoạn đấu thầu (bidding phase) để xác định chất chủ.",
          "D": "Chiến thuật phối hợp giữa các thành viên trong đội."
        },
        "answer": "B"
      },
      {
        "question": "Trong thử nghiệm, NooK và các đối thủ cạnh tranh đã chơi bao nhiêu ván bài (deals)?",
        "options": {
          "A": "100 ván",
          "B": "400 ván",
          "C": "80 ván",
          "D": "800 ván"
        },
        "answer": "D"
      },
      {
        "question": "Tỷ lệ số set mà NooK đạt điểm cao hơn các nhà vô địch Bridge là bao nhiêu?",
        "options": {
          "A": "50%",
          "B": "67%",
          "C": "83%",
          "D": "100%"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề xuất phương pháp nào để xây dựng các hệ thống mạng nơ-ron dễ giải thích hơn?",
        "options": {
          "A": "Sử dụng mạng nơ-ron sâu hơn với nhiều lớp ẩn.",
          "B": "Kết hợp trí tuệ nhân tạo tượng trưng (symbolic AI) với mạng nơ-ron.",
          "C": "Tăng cường dữ liệu huấn luyện cho mạng nơ-ron.",
          "D": "Sử dụng các thuật toán tối ưu hóa khác nhau để huấn luyện mạng nơ-ron."
        },
        "answer": "B"
      },
      {
        "question": "Điểm yếu nào của NooK được bài viết đề cập đến?",
        "options": {
          "A": "Khả năng chơi bài ngẫu nhiên.",
          "B": "Khả năng đấu thầu và phối hợp đồng đội.",
          "C": "Khả năng thích nghi với các chiến thuật mới.",
          "D": "Khả năng xử lý các ván bài phức tạp."
        },
        "answer": "B"
      },
      {
        "question": "AlphaGo nổi tiếng vì đã thống trị trò chơi nào?",
        "options": {
          "A": "Bridge",
          "B": "Cờ vua",
          "C": "Cờ vây (Go)",
          "D": "Poker"
        },
        "answer": "C"
      },
      {
        "question": "Đâu là đặc điểm khác biệt chính giữa trò chơi Cờ vây (Go) và Bridge được đề cập trong bài viết?",
        "options": {
          "A": "Cờ vây đòi hỏi nhiều tính toán hơn Bridge.",
          "B": "Bridge đòi hỏi nhiều kỹ năng xã hội hơn Cờ vây.",
          "C": "Trong Cờ vây, người chơi có thể thấy toàn bộ trạng thái ván cờ, trong khi Bridge có thông tin ẩn.",
          "D": "Cờ vây có luật chơi phức tạp hơn Bridge."
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu chính của giai đoạn đấu thầu (bidding) trong Bridge là gì?",
        "options": {
          "A": "Để xác định người chơi nào sẽ đi trước.",
          "B": "Để đánh lừa đối thủ và che giấu thông tin.",
          "C": "Để ra hiệu cho đồng đội về các lá bài mình có và xác định chất chủ.",
          "D": "Để tăng điểm số cho đội của mình."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, NooK đã chứng minh điều gì về khả năng của AI?",
        "options": {
          "A": "AI đã hoàn toàn vượt trội con người trong mọi khía cạnh của Bridge.",
          "B": "AI có thể đạt được trình độ cao trong các trò chơi có thông tin ẩn.",
          "C": "AI có thể dễ dàng giải thích lý do đưa ra quyết định của mình.",
          "D": "AI có thể thay thế hoàn toàn con người trong các trò chơi trí tuệ."
        },
        "answer": "B"
      }
    ]
  },
  "concert-venues-use-face-recognition-to-block-enemies": {
    "title": "Looking for Enemies",
    "collection": "culture",
    "content": "A major company is using face recognition to settle scores.\n\nWhat's new:MSG Entertainment, which operates large entertainment venues in several cities in the United States,usedface recognition to block its perceived enemies from attending events at New York’s Madison Square Garden and Radio City Music Hall,The New York Timesreported.\n\nWhat happened:MSG used the technology on at least two occasions to eject attorneys who work at law firms involved in litigation against the company.\n\nBehind the news:New York does not restrict use of face recognition by private companies.MSG venues haveusedthe technology since at least 2018 to compare attendees’ faces to a database of photographs and flag individuals the company considers undesirable. Prior to Conlon’s ejection, a judgeruledthat MSG has a right to deny entry to anyone who doesn’t hold a valid ticket; Conlon’s employer sued in a case that is ongoing.\n\nWhy it matters:Privacy advocates have longfearedthat face recognition could enable powerful interests to single out individuals for retribution. MSG’s use of the technology to target its perceived enemies certainly fits that description.\n\nWe're thinking:Face recognition is a flashpoint in AI, and rightly so. We need to protect privacy and fairness even as we improve safety and productivity. But outrage over such ill-considered uses of the technology could lead regulators to ban it despite its potential for good — for instance, by helping security personnel identify people who are legally barred from an area. Regulators who focus on face recognition should address ethical gray areas as well as outright abuses.",
    "qa": [
      {
        "question": "Công ty MSG Entertainment đã sử dụng công nghệ nhận diện khuôn mặt để làm gì?",
        "options": {
          "A": "Xác định khách hàng tiềm năng tại các sự kiện.",
          "B": "Ngăn chặn những người mà họ coi là 'kẻ thù' tham dự sự kiện.",
          "C": "Cải thiện trải nghiệm của khách hàng bằng cách cá nhân hóa dịch vụ.",
          "D": "Tăng cường an ninh bằng cách xác định tội phạm tiềm ẩn."
        },
        "answer": "B"
      },
      {
        "question": "Sự việc cụ thể nào đã được báo cáo liên quan đến việc MSG Entertainment sử dụng công nghệ nhận diện khuôn mặt?",
        "options": {
          "A": "Họ đã sử dụng nó để xác định những người vi phạm bản quyền tại các buổi hòa nhạc.",
          "B": "Họ đã sử dụng nó để trục xuất các luật sư làm việc cho các công ty luật đang kiện họ.",
          "C": "Họ đã sử dụng nó để theo dõi những người biểu tình bên ngoài các địa điểm tổ chức sự kiện.",
          "D": "Họ đã sử dụng nó để xác định những người có tiền án tiền sự và từ chối cho họ vào."
        },
        "answer": "B"
      },
      {
        "question": "Luật pháp New York quy định như thế nào về việc các công ty tư nhân sử dụng công nghệ nhận diện khuôn mặt?",
        "options": {
          "A": "Nó cấm hoàn toàn việc sử dụng công nghệ này.",
          "B": "Nó hạn chế việc sử dụng công nghệ này trong các khu vực công cộng.",
          "C": "Nó không hạn chế việc sử dụng công nghệ này.",
          "D": "Nó yêu cầu các công ty phải có sự đồng ý của người dùng trước khi sử dụng."
        },
        "answer": "C"
      },
      {
        "question": "MSG Entertainment đã sử dụng công nghệ nhận diện khuôn mặt từ khi nào?",
        "options": {
          "A": "Từ năm 2023.",
          "B": "Từ năm 2020.",
          "C": "Từ năm 2015.",
          "D": "Ít nhất từ năm 2018."
        },
        "answer": "D"
      },
      {
        "question": "Một thẩm phán đã phán quyết như thế nào liên quan đến quyền của MSG trong việc từ chối cho người khác vào địa điểm của họ?",
        "options": {
          "A": "MSG không có quyền từ chối bất kỳ ai vào địa điểm của họ.",
          "B": "MSG có quyền từ chối bất kỳ ai không có vé hợp lệ.",
          "C": "MSG chỉ có thể từ chối những người có tiền án tiền sự.",
          "D": "MSG phải có lý do chính đáng để từ chối ai đó vào địa điểm của họ."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao các nhà bảo vệ quyền riêng tư lo ngại về công nghệ nhận diện khuôn mặt?",
        "options": {
          "A": "Vì nó có thể dẫn đến việc tăng giá vé sự kiện.",
          "B": "Vì nó có thể cho phép các thế lực mạnh mẽ nhắm mục tiêu vào các cá nhân để trả thù.",
          "C": "Vì nó có thể làm giảm chất lượng dịch vụ tại các địa điểm giải trí.",
          "D": "Vì nó có thể gây ra sự chậm trễ trong việc vào các sự kiện."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết cho rằng điều gì có thể xảy ra nếu phản ứng thái quá với việc sử dụng công nghệ nhận diện khuôn mặt một cách thiếu cân nhắc?",
        "options": {
          "A": "Nó có thể dẫn đến việc các công ty đầu tư nhiều hơn vào công nghệ này.",
          "B": "Nó có thể dẫn đến việc các nhà quản lý cấm công nghệ này mặc dù nó có tiềm năng mang lại lợi ích.",
          "C": "Nó có thể dẫn đến việc công chúng chấp nhận công nghệ này một cách rộng rãi hơn.",
          "D": "Nó có thể dẫn đến việc các công ty sử dụng công nghệ này một cách bí mật hơn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất các nhà quản lý nên tập trung vào điều gì khi xem xét công nghệ nhận diện khuôn mặt?",
        "options": {
          "A": "Chỉ tập trung vào những lợi ích kinh tế mà công nghệ này mang lại.",
          "B": "Chỉ tập trung vào những vi phạm rõ ràng mà công nghệ này gây ra.",
          "C": "Tập trung vào cả những vùng xám đạo đức và những vi phạm rõ ràng.",
          "D": "Chỉ tập trung vào việc cải thiện độ chính xác của công nghệ."
        },
        "answer": "C"
      },
      {
        "question": "Ví dụ nào được đưa ra về tiềm năng sử dụng tốt của công nghệ nhận diện khuôn mặt?",
        "options": {
          "A": "Giúp nhân viên an ninh xác định những người được phép vào khu vực VIP.",
          "B": "Giúp nhân viên an ninh xác định những người bị cấm hợp pháp khỏi một khu vực.",
          "C": "Giúp nhân viên an ninh xác định những người có khả năng mua hàng giá trị cao.",
          "D": "Giúp nhân viên an ninh xác định những người có thể cần hỗ trợ y tế."
        },
        "answer": "B"
      },
      {
        "question": "Vụ kiện liên quan đến việc luật sư bị trục xuất khỏi địa điểm của MSG Entertainment hiện đang ở trạng thái nào?",
        "options": {
          "A": "Đã được giải quyết.",
          "B": "Đang diễn ra.",
          "C": "Đã bị bác bỏ.",
          "D": "Đang chờ phán quyết của tòa án tối cao."
        },
        "answer": "B"
      }
    ]
  },
  "chatgpt-accepts-voice-image-input-output": {
    "title": "Painting With Text, Voice, and Images",
    "collection": "business",
    "content": "ChatGPT is going multimodal with help from DALL·E.What’s new:ChatGPT is being geared to accept voice input and output, OpenAIannounced. It will also accept and generate images, thanks tointegrationwith DALL·E 3, a new version of the company’s image generator.How it works:The updates expand ChatGPT into a voice-controlled, interactive system for text and image interpretation and production. New safety features are designed to protect legal rights of artists and public figures.\n\nYes, but:OpenAI said the new voice and image capabilities are limited to the English language. Moreover, the ability to understand and generate highly technical images is limited.Behind the news:OpenAI introduced GPT-4 in March with a demo that translated a napkin sketch of a website into code, but Google was first to make visual input and output to a large language model widely available. Google announced visual features at May’s Google I/O conference and the public could use them by midsummer.Why it matters:ChatGPT has already redefined the possibilities of AI among the general public, businesses, and technical community alike. Voice input opens a world of new applications in any setting where English is spoken, and the coupling of language and vision is bound to spark applications in the arts, sciences, industry, and beyond. DALL·E 3’s safety features sound like an important step forward for image generation.We’re thinking:The notion of generative models that \"do everything\" has entered the public imagination. Combining text, voice, and image generation is an exciting step in that direction.",
    "qa": [
      {
        "question": "ChatGPT đang được nâng cấp để chấp nhận đầu vào bằng hình thức nào?",
        "options": {
          "A": "Chỉ văn bản và hình ảnh.",
          "B": "Giọng nói và hình ảnh.",
          "C": "Chỉ giọng nói.",
          "D": "Văn bản, giọng nói và video."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ tạo ảnh nào được tích hợp vào ChatGPT để tạo và xử lý hình ảnh?",
        "options": {
          "A": "GPT-4.",
          "B": "DALL·E 3.",
          "C": "Google Images.",
          "D": "Midjourney."
        },
        "answer": "B"
      },
      {
        "question": "Những tính năng mới của ChatGPT (giọng nói và hình ảnh) hiện tại bị giới hạn ở ngôn ngữ nào?",
        "options": {
          "A": "Tiếng Tây Ban Nha.",
          "B": "Tiếng Anh.",
          "C": "Tiếng Trung Quốc.",
          "D": "Tất cả các ngôn ngữ."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng mới của ChatGPT gặp hạn chế trong việc hiểu và tạo ra loại hình ảnh nào?",
        "options": {
          "A": "Hình ảnh phong cảnh.",
          "B": "Hình ảnh chân dung.",
          "C": "Hình ảnh kỹ thuật cao.",
          "D": "Hình ảnh nghệ thuật trừu tượng."
        },
        "answer": "C"
      },
      {
        "question": "Công ty nào đã giới thiệu tính năng đầu vào và đầu ra hình ảnh cho mô hình ngôn ngữ lớn trước OpenAI?",
        "options": {
          "A": "Microsoft.",
          "B": "Google.",
          "C": "Meta.",
          "D": "Amazon."
        },
        "answer": "B"
      },
      {
        "question": "GPT-4 đã được giới thiệu với một bản demo về khả năng gì?",
        "options": {
          "A": "Tạo ra video từ văn bản.",
          "B": "Dịch một bản phác thảo trang web thành mã.",
          "C": "Chơi cờ vua.",
          "D": "Viết nhạc."
        },
        "answer": "B"
      },
      {
        "question": "Việc tích hợp giọng nói vào ChatGPT có tiềm năng ứng dụng lớn nhất ở đâu?",
        "options": {
          "A": "Trong các ứng dụng chỉ sử dụng hình ảnh.",
          "B": "Trong mọi môi trường sử dụng tiếng Anh.",
          "C": "Trong các ứng dụng khoa học kỹ thuật.",
          "D": "Trong các ứng dụng chỉ sử dụng văn bản."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng an toàn của DALL·E 3 được thiết kế để bảo vệ điều gì?",
        "options": {
          "A": "Quyền riêng tư của người dùng.",
          "B": "Quyền sở hữu trí tuệ của các nghệ sĩ và người nổi tiếng.",
          "C": "Khả năng tạo ra hình ảnh chất lượng cao.",
          "D": "Khả năng truy cập vào dữ liệu cá nhân."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến khái niệm nào đang dần đi vào nhận thức của công chúng?",
        "options": {
          "A": "Mô hình AI có thể thay thế con người.",
          "B": "Mô hình tạo sinh có thể 'làm mọi thứ'.",
          "C": "Mô hình AI chỉ dành cho chuyên gia.",
          "D": "Mô hình AI không đáng tin cậy."
        },
        "answer": "B"
      },
      {
        "question": "Sự kết hợp giữa ngôn ngữ và thị giác trong ChatGPT được kỳ vọng sẽ thúc đẩy ứng dụng trong lĩnh vực nào?",
        "options": {
          "A": "Chỉ trong lĩnh vực nghệ thuật.",
          "B": "Chỉ trong lĩnh vực khoa học.",
          "C": "Chỉ trong lĩnh vực công nghiệp.",
          "D": "Trong nghệ thuật, khoa học, công nghiệp và hơn thế nữa."
        },
        "answer": "D"
      }
    ]
  },
  "creative-workers-dont-want-ai-developers-to-train-models-on-their-work": {
    "title": "Data Disappears",
    "collection": "culture",
    "content": "The latest advances in AI are built on freely available training data. What will happen if it becomes off-limits?\n\nThe fear:Creative workers don’t want AI developers to train models on their works without permission or compensation, or at all. Data is vanishing as they scramble to lock it down.\n\nHorror stories:Generative AI models readily produce outputs that imitate the styles of individual authors and artists. Creative people and organizations that work on their behalf are reacting by suing AI developers (all proceedings are ongoing at publication time) and restricting access to their works.\n\nSurvival in a data desert:Some AI companies have negotiated agreements for access to data. Others let publishers opt out of their data-collection efforts. Still others are using data already in their possession to train proprietary models.\n\nFacing the fear:Copyright holders and creative workers are understandably worried that generative AI will sap their market value. Whether the law is on their side remains to be seen. Laws in many countries don’t explicitly address use of copyrighted works to train AI systems. Until legislators set a clear standard, disagreements will be decided case by case and country by country.",
    "qa": [
      {
        "question": "Những tiến bộ mới nhất trong lĩnh vực AI được xây dựng dựa trên yếu tố nào?",
        "options": {
          "A": "Các thuật toán phức tạp được bảo mật nghiêm ngặt.",
          "B": "Dữ liệu huấn luyện có sẵn một cách tự do.",
          "C": "Sự hợp tác giữa các nhà khoa học và nghệ sĩ.",
          "D": "Nguồn tài trợ dồi dào từ chính phủ và các tổ chức tư nhân."
        },
        "answer": "B"
      },
      {
        "question": "Nỗi lo sợ chính của những người làm việc sáng tạo liên quan đến AI là gì?",
        "options": {
          "A": "AI sẽ thay thế hoàn toàn công việc của họ trong tương lai.",
          "B": "Các nhà phát triển AI sử dụng tác phẩm của họ để huấn luyện mô hình mà không xin phép hoặc trả thù lao.",
          "C": "AI sẽ làm giảm chất lượng của các tác phẩm nghệ thuật.",
          "D": "AI sẽ tạo ra những tác phẩm đạo nhái khó phân biệt với bản gốc."
        },
        "answer": "B"
      },
      {
        "question": "Một trong những phản ứng của những người làm sáng tạo đối với AI tạo sinh là gì?",
        "options": {
          "A": "Hợp tác với các nhà phát triển AI để tạo ra các công cụ mới.",
          "B": "Kiện các nhà phát triển AI và hạn chế quyền truy cập vào tác phẩm của họ.",
          "C": "Chuyển đổi sang các lĩnh vực sáng tạo khác ít bị ảnh hưởng bởi AI.",
          "D": "Công khai ủng hộ việc sử dụng AI trong nghệ thuật."
        },
        "answer": "B"
      },
      {
        "question": "Một số công ty AI đã làm gì để đối phó với tình trạng khan hiếm dữ liệu?",
        "options": {
          "A": "Từ bỏ việc phát triển các mô hình AI tạo sinh.",
          "B": "Đàm phán các thỏa thuận để truy cập dữ liệu.",
          "C": "Sử dụng dữ liệu đánh cắp từ các nguồn không hợp pháp.",
          "D": "Chỉ tập trung vào việc phát triển các mô hình AI không cần dữ liệu huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đang gây lo ngại cho những người nắm giữ bản quyền và những người làm việc sáng tạo?",
        "options": {
          "A": "AI sẽ giúp họ tạo ra những tác phẩm nghệ thuật độc đáo hơn.",
          "B": "AI tạo sinh sẽ làm giảm giá trị thị trường của họ.",
          "C": "AI sẽ đơn giản hóa quy trình sáng tạo và giảm chi phí sản xuất.",
          "D": "AI sẽ giúp họ tiếp cận được nhiều khán giả hơn."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề pháp lý chính liên quan đến việc sử dụng tác phẩm có bản quyền để huấn luyện AI là gì?",
        "options": {
          "A": "Luật pháp đã cấm hoàn toàn việc sử dụng tác phẩm có bản quyền cho mục đích này.",
          "B": "Luật pháp ở nhiều quốc gia chưa quy định rõ ràng về việc sử dụng tác phẩm có bản quyền để huấn luyện hệ thống AI.",
          "C": "Luật pháp quốc tế đã thống nhất về việc cho phép sử dụng tác phẩm có bản quyền để huấn luyện AI.",
          "D": "Luật pháp chỉ cấm sử dụng tác phẩm có bản quyền cho mục đích thương mại."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì sẽ quyết định các tranh chấp liên quan đến việc sử dụng tác phẩm có bản quyền để huấn luyện AI cho đến khi có tiêu chuẩn rõ ràng?",
        "options": {
          "A": "Quyết định của các tổ chức phi chính phủ.",
          "B": "Quyết định của các nhà phát triển AI.",
          "C": "Quyết định theo từng vụ việc và từng quốc gia.",
          "D": "Quyết định của các tổ chức bảo vệ bản quyền quốc tế."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì đang xảy ra với dữ liệu khi những người làm sáng tạo cố gắng bảo vệ tác phẩm của họ?",
        "options": {
          "A": "Dữ liệu trở nên phong phú hơn và dễ tiếp cận hơn.",
          "B": "Dữ liệu đang biến mất khi họ cố gắng khóa nó lại.",
          "C": "Dữ liệu được chia sẻ rộng rãi hơn thông qua các nền tảng mở.",
          "D": "Dữ liệu được mã hóa để bảo vệ khỏi việc sử dụng trái phép."
        },
        "answer": "B"
      },
      {
        "question": "Một số công ty AI đã cho phép các nhà xuất bản làm gì liên quan đến việc thu thập dữ liệu?",
        "options": {
          "A": "Yêu cầu họ trả phí để được thu thập dữ liệu.",
          "B": "Cho phép họ từ chối tham gia vào các nỗ lực thu thập dữ liệu của họ.",
          "C": "Bắt buộc họ phải cung cấp dữ liệu miễn phí.",
          "D": "Cho phép họ kiểm soát hoàn toàn cách dữ liệu của họ được sử dụng."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến điều gì về các vụ kiện liên quan đến AI và quyền tác giả?",
        "options": {
          "A": "Tất cả các vụ kiện đều đã được giải quyết có lợi cho các nhà phát triển AI.",
          "B": "Tất cả các vụ kiện đều đã được giải quyết có lợi cho những người làm sáng tạo.",
          "C": "Tất cả các vụ kiện vẫn đang diễn ra tại thời điểm xuất bản.",
          "D": "Hầu hết các vụ kiện đã được giải quyết thông qua hòa giải."
        },
        "answer": "C"
      }
    ]
  },
  "deepfakes-profanity": {
    "title": "Deepfakes Against Profanity",
    "collection": "culture",
    "content": "Deepfake technology enabled a feature film to reach a broader audience.\n\nWhat’s new:Fall, a thriller about two friends who climb a 2,000-foot tower only to find themselves trapped at the top, originally included over 30 instances of a certain offensive word. The filmmakers deepfaked the picture to clean up the language, enabling the film to earn a rating that welcomes younger viewers,Varietyreported.How it works:Director and co-writer Scott Mann re-recorded the film’s actors reciting more family-friendly versions of the troublesome word. Then he used a generative adversarial network to regenerate the actors’ lip motions to match the revised dialog.\n\nBehind the news:Neural networks are increasingly common in the edit suite.\n\nWhy it matters:Fall’s distributor Lionsgate determined that the movie would make more money if it was aimed at a younger audience. However, reshooting the offending scenes might have taken months and cost millions of dollars. AI offered a relatively affordable solution.We’re thinking:The global popularity of shows likeSquid Game, in which the original dialog is Korean, andLa Casa de Papel, in which the actors speak Spanish, suggest that dialog replacement could be a blockbuster AI application.",
    "qa": [
      {
        "question": "Bộ phim 'Fall' đã sử dụng công nghệ deepfake để làm gì?",
        "options": {
          "A": "Thay đổi diễn viên chính.",
          "B": "Loại bỏ những từ ngữ thô tục.",
          "C": "Tạo ra hiệu ứng đặc biệt ấn tượng hơn.",
          "D": "Rút ngắn thời lượng phim."
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ deepfake đã giúp bộ phim 'Fall' tiếp cận được đối tượng khán giả nào?",
        "options": {
          "A": "Khán giả lớn tuổi.",
          "B": "Khán giả trẻ tuổi hơn.",
          "C": "Khán giả quốc tế.",
          "D": "Khán giả yêu thích phim kinh dị."
        },
        "answer": "B"
      },
      {
        "question": "Đạo diễn Scott Mann đã sử dụng phương pháp nào để chỉnh sửa lời thoại trong phim 'Fall'?",
        "options": {
          "A": "Thu âm lại toàn bộ lời thoại với diễn viên khác.",
          "B": "Thu âm lại lời thoại với diễn viên cũ và sử dụng mạng đối nghịch sinh (GAN) để điều chỉnh khẩu hình.",
          "C": "Sử dụng phần mềm chỉnh sửa âm thanh để loại bỏ những từ ngữ không phù hợp.",
          "D": "Thay đổi hoàn toàn kịch bản phim."
        },
        "answer": "B"
      },
      {
        "question": "Mạng đối nghịch sinh (GAN) được sử dụng trong quá trình chỉnh sửa phim 'Fall' để làm gì?",
        "options": {
          "A": "Tạo ra các cảnh quay mới.",
          "B": "Điều chỉnh khẩu hình của diễn viên cho phù hợp với lời thoại đã chỉnh sửa.",
          "C": "Tăng độ phân giải của hình ảnh.",
          "D": "Tạo ra nhạc nền cho phim."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì khiến nhà phân phối Lionsgate quyết định sử dụng công nghệ deepfake cho phim 'Fall'?",
        "options": {
          "A": "Để tiết kiệm chi phí sản xuất.",
          "B": "Để tăng doanh thu bằng cách hướng đến đối tượng khán giả trẻ hơn.",
          "C": "Để thử nghiệm công nghệ mới.",
          "D": "Để tránh những tranh cãi về nội dung phim."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến những khó khăn nào nếu không sử dụng công nghệ AI để chỉnh sửa phim 'Fall'?",
        "options": {
          "A": "Tốn kém thời gian và chi phí.",
          "B": "Khó tìm được diễn viên thay thế.",
          "C": "Không thể tái tạo lại các cảnh quay gốc.",
          "D": "Gây ảnh hưởng đến uy tín của nhà sản xuất."
        },
        "answer": "A"
      },
      {
        "question": "Bài viết gợi ý rằng ứng dụng tiềm năng nào của AI trong ngành điện ảnh có thể trở thành 'bom tấn'?",
        "options": {
          "A": "Tạo ra các nhân vật ảo.",
          "B": "Thay thế lời thoại trong phim.",
          "C": "Tự động viết kịch bản.",
          "D": "Chỉnh sửa màu sắc và ánh sáng."
        },
        "answer": "B"
      },
      {
        "question": "Ví dụ nào được đưa ra trong bài viết để minh họa cho tiềm năng của việc thay thế lời thoại trong phim?",
        "options": {
          "A": "Avengers: Endgame.",
          "B": "Squid Game và La Casa de Papel.",
          "C": "The Lord of the Rings.",
          "D": "Avatar."
        },
        "answer": "B"
      },
      {
        "question": "Cụm từ 'generative adversarial network' (mạng đối nghịch sinh) được sử dụng trong bài viết để mô tả điều gì?",
        "options": {
          "A": "Một loại phần mềm chỉnh sửa video.",
          "B": "Một loại mạng lưới thần kinh được sử dụng để tạo ra dữ liệu mới.",
          "C": "Một kỹ thuật quay phim đặc biệt.",
          "D": "Một phương pháp quảng bá phim."
        },
        "answer": "B"
      },
      {
        "question": "Chiều cao của ngọn tháp mà hai người bạn trong phim 'Fall' leo lên là bao nhiêu?",
        "options": {
          "A": "1000 feet.",
          "B": "2000 feet.",
          "C": "3000 feet.",
          "D": "4000 feet."
        },
        "answer": "B"
      }
    ]
  },
  "duolingo-turns-to-ai-translation-to-expand-its-most-popular-courses-to-all-28-user-languages": {
    "title": "Machine Translation in Action",
    "collection": "business",
    "content": "AI is bringing a massive boost in productivity to Duolingo, maker of the most popular app for learning languages.\n\nWhat’s new:Duolingo used generative AI toproduce148 courses, more than doubling its previous catalog. The technology enabled the company to offer some of its most popular courses — Spanish, French, German, Italian, Japanese, Korean, and Mandarin — in 28 languages. Initially, the company is using AI to produce courses aimed at beginners, with more advanced levels to come.\n\nHow it works:Duolingo’sAI-assisted approach to building language coursesquickly turns a single course into many. The new approach revved its pace from building 100 courses over 12 years to producing many more than that in less than a year.\n\nBehind the scenes:AI is at the heart of Duolingo’s expansion into other areas beyond language learning.\n\nWhy it matters:Companies in nearly every industry face pressure to produce more with less amid rising competition. AI can help to accomplish that while potentially improving product quality, and Duolingo has ample reason to move aggressively in this direction. The startupSpeak, which offers a voice-based approach to learning languages, is growing rapidly, and Google just launchedLittle Language Lessonsthat show how an AI-first product could be used as a language teacher and conversational partner.\n\nWe’re thinking:AI is well on the way totransforming educationfor teachers, students, and technology companies!",
    "qa": [
      {
        "question": "Theo bài viết, AI đã mang lại lợi ích gì cho Duolingo?",
        "options": {
          "A": "Giảm chi phí marketing",
          "B": "Tăng năng suất đáng kể",
          "C": "Cải thiện giao diện người dùng",
          "D": "Thu hút nhiều nhà đầu tư hơn"
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng AI đã giúp Duolingo tạo ra bao nhiêu khóa học mới?",
        "options": {
          "A": "Gần 50 khóa học",
          "B": "Hơn 100 khóa học",
          "C": "148 khóa học",
          "D": "Hơn 200 khóa học"
        },
        "answer": "C"
      },
      {
        "question": "Ban đầu, Duolingo sử dụng AI để tạo ra các khóa học dành cho đối tượng nào?",
        "options": {
          "A": "Người học nâng cao",
          "B": "Người học trung cấp",
          "C": "Người học chuyên sâu",
          "D": "Người học mới bắt đầu"
        },
        "answer": "D"
      },
      {
        "question": "Trước khi có AI, Duolingo mất bao lâu để xây dựng 100 khóa học?",
        "options": {
          "A": "5 năm",
          "B": "8 năm",
          "C": "10 năm",
          "D": "12 năm"
        },
        "answer": "D"
      },
      {
        "question": "Bài viết đề cập đến một lĩnh vực nào khác mà Duolingo đang mở rộng nhờ AI?",
        "options": {
          "A": "Phát triển trò chơi giáo dục",
          "B": "Nghiên cứu ngôn ngữ học",
          "C": "Các lĩnh vực ngoài học ngôn ngữ",
          "D": "Hợp tác với các trường đại học"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, áp lực nào đang thúc đẩy các công ty sử dụng AI?",
        "options": {
          "A": "Yêu cầu của chính phủ về chuyển đổi số",
          "B": "Sự phát triển của công nghệ blockchain",
          "C": "Áp lực sản xuất nhiều hơn với nguồn lực ít hơn",
          "D": "Xu hướng làm việc từ xa"
        },
        "answer": "C"
      },
      {
        "question": "Công ty nào được nhắc đến trong bài viết như một đối thủ cạnh tranh của Duolingo?",
        "options": {
          "A": "Rosetta Stone",
          "B": "Memrise",
          "C": "Speak",
          "D": "Babbel"
        },
        "answer": "C"
      },
      {
        "question": "Google đã ra mắt sản phẩm nào liên quan đến học ngôn ngữ sử dụng AI?",
        "options": {
          "A": "Google Translate Pro",
          "B": "Little Language Lessons",
          "C": "Google Language AI",
          "D": "AI Language Tutor"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết dự đoán điều gì về tương lai của giáo dục với sự phát triển của AI?",
        "options": {
          "A": "Giáo viên sẽ bị thay thế hoàn toàn bởi AI",
          "B": "Học sinh sẽ không cần đến trường học nữa",
          "C": "AI sẽ thay đổi giáo dục cho giáo viên, học sinh và các công ty công nghệ",
          "D": "Sách giáo khoa sẽ trở nên lỗi thời"
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu chính của Duolingo khi sử dụng AI trong việc tạo khóa học là gì?",
        "options": {
          "A": "Giảm số lượng nhân viên",
          "B": "Tăng tốc độ sản xuất khóa học",
          "C": "Tăng giá trị thương hiệu",
          "D": "Tạo ra các khóa học phức tạp hơn"
        },
        "answer": "B"
      }
    ]
  },
  "fake-aim": {
    "title": "Fake Aim",
    "collection": "culture",
    "content": "Gamers looking to cheat in first-person shooters can’t miss with AI-assisted marksmanship.What’s new:A video-game hack uses computer vision to blast virtual enemies at superhuman speed, Ars Technicareported. A system that implemented the technique was shut down last week.How it works:Uservizworked with any shooter that runs on PC, PlayStation, or Xbox. It identified and fired on targets in under 10 milliseconds. (Professional gamers have reaction timesbetween 100 and 250 milliseconds.) It worked like this:\n\nBehind the news:Cheat codes that enhance a player’s ability to aim and fire are common but frowned upon. Activision recently banned 60,000 players of Call of Duty: Warzone for using them. Typically, such cheats are add-ons to game software. Tools that use computer vision operate independently of the game and therefore are harder to detect. Userviz was one ofseveralon the market, and some enterprising cheaters havecoded their own.Why it matters:Electronic gaming is a lucrative industry — and so is themarketfor products that make it easier to win.Unscrupulous playersmay have takenmillions of dollarsin competition money.We’re thinking:Like fighting spam and fraud, thwarting aimbots is a game of cat and mouse. The next generation of such bots may behave more like humans — making an average player appear to be highly skilled — and thus be even harder to detect. Who’s up for a round of rock, paper, scissors?",
    "qa": [
      {
        "question": "Công nghệ mới được đề cập trong bài viết giúp người chơi gian lận trong game bắn súng bằng cách nào?",
        "options": {
          "A": "Tăng tốc độ xử lý của máy tính để giảm độ trễ.",
          "B": "Sử dụng thị giác máy tính để tự động ngắm bắn mục tiêu.",
          "C": "Thay đổi mã nguồn của game để tăng sức mạnh cho nhân vật.",
          "D": "Kết nối với một máy chủ đặc biệt để nhận hỗ trợ từ người chơi khác."
        },
        "answer": "B"
      },
      {
        "question": "Thời gian phản ứng của hệ thống gian lận Userviz là bao nhiêu?",
        "options": {
          "A": "Từ 100 đến 250 mili giây.",
          "B": "Dưới 10 mili giây.",
          "C": "Khoảng 50 mili giây.",
          "D": "Tùy thuộc vào cấu hình máy tính."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì xảy ra với hệ thống Userviz được đề cập trong bài viết?",
        "options": {
          "A": "Nó được bán cho một công ty game lớn.",
          "B": "Nó đã bị đóng cửa.",
          "C": "Nó được nâng cấp để khó bị phát hiện hơn.",
          "D": "Nó được sử dụng để đào tạo game thủ chuyên nghiệp."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, hình thức gian lận phổ biến trong game bắn súng thường là gì?",
        "options": {
          "A": "Sử dụng phần cứng đặc biệt để tăng tốc độ chuột.",
          "B": "Sử dụng các add-on để can thiệp vào phần mềm game.",
          "C": "Thuê người chơi giỏi hơn để chơi hộ.",
          "D": "Tấn công vào máy chủ game để thay đổi kết quả."
        },
        "answer": "B"
      },
      {
        "question": "Activision đã thực hiện biện pháp gì đối với những người chơi gian lận trong Call of Duty: Warzone?",
        "options": {
          "A": "Phạt tiền.",
          "B": "Cấm chơi game.",
          "C": "Tước danh hiệu.",
          "D": "Yêu cầu bồi thường thiệt hại."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính giữa các công cụ gian lận sử dụng thị giác máy tính và các add-on thông thường là gì?",
        "options": {
          "A": "Công cụ thị giác máy tính dễ sử dụng hơn.",
          "B": "Công cụ thị giác máy tính hoạt động độc lập với game và khó bị phát hiện hơn.",
          "C": "Công cụ thị giác máy tính có giá thành rẻ hơn.",
          "D": "Công cụ thị giác máy tính chỉ hoạt động trên một số nền tảng nhất định."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến hậu quả tiềm tàng của việc gian lận trong game là gì?",
        "options": {
          "A": "Làm giảm uy tín của game.",
          "B": "Gây thiệt hại về kinh tế cho các giải đấu.",
          "C": "Làm mất cân bằng trong cộng đồng game thủ.",
          "D": "Tất cả các đáp án trên."
        },
        "answer": "D"
      },
      {
        "question": "Bài viết so sánh cuộc chiến chống lại aimbot với cuộc chiến nào?",
        "options": {
          "A": "Cuộc chiến chống khủng bố.",
          "B": "Cuộc chiến chống ma túy.",
          "C": "Cuộc chiến chống spam và gian lận.",
          "D": "Cuộc chiến chống biến đổi khí hậu."
        },
        "answer": "C"
      },
      {
        "question": "Theo dự đoán của bài viết, aimbot thế hệ tiếp theo có thể sẽ như thế nào?",
        "options": {
          "A": "Khó phát hiện hơn vì hành vi giống người chơi giỏi.",
          "B": "Mạnh mẽ hơn về khả năng ngắm bắn chính xác.",
          "C": "Dễ dàng cài đặt và sử dụng hơn.",
          "D": "Hoạt động trên nhiều nền tảng game hơn."
        },
        "answer": "A"
      },
      {
        "question": "Phản ứng thời gian trung bình của game thủ chuyên nghiệp là bao nhiêu?",
        "options": {
          "A": "Dưới 10 mili giây.",
          "B": "Từ 100 đến 250 mili giây.",
          "C": "Khoảng 500 mili giây.",
          "D": "Trên 1 giây."
        },
        "answer": "B"
      }
    ]
  },
  "gamers-are-using-ai-to-cheat-in-rocket-league": {
    "title": "AI Cheat Bedevils Popular Esport",
    "collection": "culture",
    "content": "Reinforcement learning is powering a new generation of video game cheaters.\n\nWhat’s new:Players ofRocket League, a video game that ranks among the world’s most popular esports, are getting trounced by cheaters who use AI models originally developed to train contestants,PC Gamerreported.\n\nThe game:Rocket League’s rules are similar to football (known as soccer in the United States): Players aim to force a ball into their opponent’s goal at the other end of an arena — except, rather than kicking the ball, they push it with a race car. Doing so, however, requires mastering the game’s idiosyncratic physics. Players can drive up the arena’s walls, turbo-boost across the pitch, and launch their car into the air.\n\nHow it works:The cheat takes advantage of a bot known as Nexto. Developed by AI-savvy players as a training tool, Nexto and similar bots typically include hard-coded restrictions against being used in competitive online play. However, someone customized the bot, enabling it to circumvent the restriction, one of Nexto’s developersrevealedin a discussion on Reddit.\n\nBehind the news:Despite reinforcement learning’s ability to master classic games likegoand video games likeStarCraft II, news of AI-powered cheats has been scant. The developers ofUserviz, a cheatbot for first-person shooters that automatically aimed and fired on enemies detected by aYOLOimplementation, deleted access to the app after receiving legal notice from video game publisher Activision.\n\nWhy it matters:Video games are big business. Rampant cheating could impact a game’s sales by ruining the experience for casual players. Cheating can also tarnish the reputation of games that, likeRocket League, are played professionally, where top players stand to winmillionsof dollars.\n\nWe’re thinking:While we condemn cheating, we applaud anyone who is so motivated to improve their gaming skill that they develop reinforcement learning models to compete against!",
    "qa": [
      {
        "question": "Công nghệ nào đang được sử dụng để tạo ra một thế hệ gian lận mới trong trò chơi điện tử?",
        "options": {
          "A": "Thực tế ảo (VR)",
          "B": "Học tăng cường (Reinforcement Learning)",
          "C": "Trí tuệ nhân tạo tổng quát (AGI)",
          "D": "Mạng nơ-ron tích chập (CNN)"
        },
        "answer": "B"
      },
      {
        "question": "Trò chơi điện tử nào được đề cập trong bài viết, nơi người chơi đang gặp phải tình trạng gian lận sử dụng AI?",
        "options": {
          "A": "StarCraft II",
          "B": "Rocket League",
          "C": "Fortnite",
          "D": "League of Legends"
        },
        "answer": "B"
      },
      {
        "question": "Luật chơi của Rocket League tương tự với môn thể thao nào?",
        "options": {
          "A": "Bóng rổ",
          "B": "Bóng đá",
          "C": "Bóng chuyền",
          "D": "Bóng bầu dục"
        },
        "answer": "B"
      },
      {
        "question": "Tên của bot được sử dụng để gian lận trong Rocket League là gì?",
        "options": {
          "A": "YOLO",
          "B": "Userviz",
          "C": "Nexto",
          "D": "AlphaZero"
        },
        "answer": "C"
      },
      {
        "question": "Ban đầu, Nexto được phát triển với mục đích gì?",
        "options": {
          "A": "Để gian lận trong các trận đấu chuyên nghiệp",
          "B": "Để huấn luyện người chơi",
          "C": "Để tự động chơi game",
          "D": "Để khai thác lỗ hổng bảo mật của game"
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào đã gửi thông báo pháp lý đến nhà phát triển Userviz, một cheatbot cho game bắn súng góc nhìn thứ nhất?",
        "options": {
          "A": "Epic Games",
          "B": "Valve",
          "C": "Activision",
          "D": "Riot Games"
        },
        "answer": "C"
      },
      {
        "question": "Userviz sử dụng công nghệ YOLO để làm gì?",
        "options": {
          "A": "Tự động điều khiển xe",
          "B": "Tự động tìm đường đi",
          "C": "Tự động nhắm và bắn vào kẻ địch",
          "D": "Tự động thu thập tài nguyên"
        },
        "answer": "C"
      },
      {
        "question": "Tác động tiêu cực nào của việc gian lận có thể ảnh hưởng đến doanh số của một trò chơi?",
        "options": {
          "A": "Làm giảm sự cạnh tranh giữa những người chơi chuyên nghiệp",
          "B": "Làm tăng độ khó của trò chơi",
          "C": "Phá hỏng trải nghiệm của người chơi thông thường",
          "D": "Làm chậm quá trình phát triển của trò chơi"
        },
        "answer": "C"
      },
      {
        "question": "Ngoài Rocket League, trò chơi nào khác được đề cập trong bài viết mà AI đã chứng minh khả năng làm chủ?",
        "options": {
          "A": "Counter-Strike: Global Offensive",
          "B": "Dota 2",
          "C": "StarCraft II",
          "D": "Overwatch"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, thái độ của tác giả đối với việc sử dụng AI để cải thiện kỹ năng chơi game là gì?",
        "options": {
          "A": "Hoàn toàn phản đối",
          "B": "Ủng hộ việc gian lận để chiến thắng",
          "C": "Khen ngợi sự sáng tạo nhưng không chấp nhận gian lận",
          "D": "Khuyến khích việc sử dụng AI trong các giải đấu chuyên nghiệp"
        },
        "answer": "C"
      }
    ]
  },
  "fast-and-daring-wins-the-race": {
    "title": "Fast and Daring Wins the Race",
    "collection": "culture",
    "content": "Armchair speed demons have a new nemesis.What’s new:Peter Wurman and a team at Sony developedGran Turismo Sophy(GT Sophy), a reinforcement learning model that defeated human champions of Gran Turismo Sport, a PlayStation game that simulates auto races right down to tire friction and air resistance.Key insight:It’s okay to bump another car while racing (as in the video above), but there’s a thin and subjective line between innocuous impacts and those that would give the offender an advantage. In official Gran Turismo Sport competitions — as in real-world races — a human referee makes these calls and penalizes errant drivers. A reinforcement learning algorithm can model such judgments by assigning a cost to each collision, but it must be tuned to avoid an adverse effect on performance: Too high a penalty and drivers become timid, too low and they become dangerous. Penalizing common situations in which a driver typically would be judged at fault, such as rear-ending, side-swiping, and colliding on a curve, should help a neural network learn to drive boldly without ramming its opponents to gain an advantage.How it works:Given information about the car and its environment, a vanilla neural network decided how to steer and accelerate. The authors trained the network on three virtual tracks and in custom scenarios, such as theslingshot pass, that pitted the model against itself, previous iterations of itself, and the in-game AI.\n\nResults:In time trials, GT Sophy achieved faster lap times than three of the world’s top Gran Turismo Sport drivers. In addition, a team of four GT Sophys faced off against four of the best human drivers in two sets of three head-to-head races held months apart. Points were awarded based on the cars’ final positions: 10 points for first place, 8 for second, 6 for third, and from 5 to 1 point for the remaining positions. The human team won the first set 86 to 70. Then the developers increased the model size and changed some rewards and features, among other tweaks, and the GT Sophy team won the second set 104 to 52.Why it matters:Unlike board games like Chess and Go in which learning algorithms have beaten human champions, winning a car race requires making complex decisions at high speed while tracing a fine line between nudging and disabling opponents. That said, there’s still a significant gap between doing well in even an exceptionally realistic video game and driving a real car.We’re thinking:Autonomous driving requires perception, planning, and control. We have little doubt that the latest algorithms can outperform most human drivers in control, but a substantial gap remains in perception and planning.",
    "qa": [
      {
        "question": "GT Sophy là sản phẩm của công ty nào?",
        "options": {
          "A": "Microsoft",
          "B": "Sony",
          "C": "Google",
          "D": "Apple"
        },
        "answer": "B"
      },
      {
        "question": "GT Sophy đã đánh bại các đối thủ là ai trong trò chơi Gran Turismo Sport?",
        "options": {
          "A": "Các tay đua chuyên nghiệp trong thế giới thực",
          "B": "Các nhà phát triển trò chơi",
          "C": "Các nhà vô địch là người chơi Gran Turismo Sport",
          "D": "Các thuật toán AI khác"
        },
        "answer": "C"
      },
      {
        "question": "Yếu tố nào được sử dụng để huấn luyện GT Sophy trong việc va chạm xe?",
        "options": {
          "A": "Loại bỏ hoàn toàn các va chạm",
          "B": "Áp dụng một mức phạt cố định cho mọi va chạm",
          "C": "Gán một chi phí cho mỗi va chạm và điều chỉnh để tránh ảnh hưởng tiêu cực đến hiệu suất",
          "D": "Khuyến khích va chạm để giành lợi thế"
        },
        "answer": "C"
      },
      {
        "question": "Mạng nơ-ron của GT Sophy đưa ra quyết định dựa trên thông tin gì?",
        "options": {
          "A": "Chỉ thông tin về chiếc xe",
          "B": "Chỉ thông tin về môi trường",
          "C": "Thông tin về chiếc xe và môi trường xung quanh",
          "D": "Thông tin về đối thủ"
        },
        "answer": "C"
      },
      {
        "question": "Trong các thử nghiệm, GT Sophy đã được huấn luyện trên những loại đường đua nào?",
        "options": {
          "A": "Chỉ trên các đường đua chính thức của Gran Turismo Sport",
          "B": "Chỉ trong các kịch bản tùy chỉnh",
          "C": "Trên ba đường đua ảo và trong các kịch bản tùy chỉnh",
          "D": "Trên các đường đua thực tế"
        },
        "answer": "C"
      },
      {
        "question": "Trong cuộc đối đầu giữa GT Sophy và các tay đua người, điểm số được tính như thế nào?",
        "options": {
          "A": "1 điểm cho vị trí đầu tiên, 2 điểm cho vị trí thứ hai, v.v.",
          "B": "10 điểm cho vị trí đầu tiên, 8 điểm cho vị trí thứ hai, 6 điểm cho vị trí thứ ba, và từ 5 đến 1 điểm cho các vị trí còn lại",
          "C": "5 điểm cho vị trí đầu tiên, 4 điểm cho vị trí thứ hai, 3 điểm cho vị trí thứ ba, và 2 điểm cho các vị trí còn lại",
          "D": "Điểm số được tính dựa trên thời gian hoàn thành vòng đua"
        },
        "answer": "B"
      },
      {
        "question": "Sau khi thua ở vòng đầu tiên, các nhà phát triển đã thay đổi điều gì để GT Sophy chiến thắng ở vòng thứ hai?",
        "options": {
          "A": "Giảm kích thước mô hình",
          "B": "Tăng số lượng đường đua huấn luyện",
          "C": "Tăng kích thước mô hình và thay đổi một số phần thưởng và tính năng",
          "D": "Thay đổi đội hình các tay đua người"
        },
        "answer": "C"
      },
      {
        "question": "Điểm khác biệt chính giữa việc chiến thắng trong cờ vua/cờ vây và đua xe là gì?",
        "options": {
          "A": "Đua xe đòi hỏi ít quyết định phức tạp hơn",
          "B": "Đua xe đòi hỏi đưa ra các quyết định phức tạp ở tốc độ cao và cân bằng giữa việc va chạm và vô hiệu hóa đối thủ",
          "C": "Cờ vua và cờ vây đòi hỏi nhiều chiến lược hơn",
          "D": "Không có sự khác biệt đáng kể"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lĩnh vực nào mà thuật toán tự lái vẫn còn khoảng cách đáng kể so với con người?",
        "options": {
          "A": "Kiểm soát",
          "B": "Tốc độ",
          "C": "Nhận thức và lập kế hoạch",
          "D": "Sức mạnh"
        },
        "answer": "C"
      },
      {
        "question": "Thuật toán học tăng cường (reinforcement learning) được sử dụng trong GT Sophy có tên gọi là gì?",
        "options": {
          "A": "Vanilla neural network",
          "B": "Deep neural network",
          "C": "Convolutional neural network",
          "D": "Recurrent neural network"
        },
        "answer": "A"
      }
    ]
  },
  "generated-video-with-music-sound-effects-and-dialogue": {
    "title": "David Ding",
    "collection": "culture",
    "content": "Last year, we saw an explosion of models that generate either video or audio outputs in high quality. In the coming year, I look forward to models that produce video clips complete with audio soundtracks including speech, music, and sound effects. I hope these models will bring a new era of cinematic creativity.\n\nThe technologies required for such cinematic video generators are in place. Several companies provide very competitive video models, and Udio and others create music models. All that’s left is to model video and audio simultaneously, including dialog and voiceovers. (In fact, we’ve already seen something like this: Meta’s Movie Gen. Users describe a scene and Movie Gen will produce a video clip complete with a music score and sound effects.)\n\nOf course, training such models will require extensive datasets. But I suspect that the videos used to train existing video generators had soundtracks that include these elements, so data may not be a barrier to developing these models.\n\nInitially, these models won’t produce output that competes with the best work of professional video editors. But they will advance quickly. Before long, they’ll generate videos and soundtracks that approach Hollywood productions in raw quality, just as current image models can produce images that are indistinguishable from high-end photographs.\n\nAt the same time, the amount of control users have over the video and audio outputs will continue to increase. For instance, when we first released Udio, users couldn’t control the harmony it generated. A few months later, we launched an update that enables users to specify the key, or tonal center. So users can take an existing song and remix it in a different key. We are continuing to do research into giving users additional levers of control, such as voice, melody, and beats, and I’m sure video modeling teams are doing similar research on controllability.\n\nSome people may find the prospect of models that generate fully produced cinematic videos unsettling. I understand this feeling. I enjoy photography and playing music, but I’ve found that image and audio generators are helpful starting points for my creative work. If I choose, AI can give me a base image that I can work on in Photoshop, or a musical composition to sample from or build on. Or consider AI coding assistants that generate the files for an entire website. You no longer need to rely on web developers, but if you talk to them, you’ll learn that they don’t always enjoy writing the boilerplate code for a website. Having a tool that builds a site’s scaffold lets them spend their time on development tasks they find more stimulating and fun.\n\nIn a similar way, you’ll be able to write a screenplay and quickly produce a rough draft of what the movie might look like. You might generate 1,000 takes, decide which one you like, and draw inspiration from that to guide a videographer and actors.\n\nArt is all about the creative choices that go into it. Both you and I can use Midjourney to make a picture of a landscape, but if you’re an artist and you have a clear idea of the landscape you want to see, your Midjourney output will be more compelling than mine. Similarly, anyone can use Udio to make high-production quality music, but if you have good musical taste, your music will be better than mine. Video will remain an art form, because individuals will choose what their movie is about, how it looks, and how it feels — and they’ll be able to make those choices more fluidly, quickly, and interactively.\n\nDavid Ding is a lifelong musician and co-founder of Udio, maker of a music-creation web app that empowers users to make original music. Previously, he was a Senior Research Engineer at Google DeepMind.",
    "qa": [
      {
        "question": "Theo tác giả, điều gì đã diễn ra trong năm vừa qua liên quan đến mô hình AI?",
        "options": {
          "A": "Sự ra đời của các mô hình tạo ra hình ảnh chất lượng cao.",
          "B": "Sự bùng nổ của các mô hình tạo ra video hoặc âm thanh chất lượng cao.",
          "C": "Sự phát triển của các mô hình có thể viết kịch bản phim hoàn chỉnh.",
          "D": "Sự cải tiến vượt bậc của các mô hình dịch thuật ngôn ngữ."
        },
        "answer": "B"
      },
      {
        "question": "Tác giả mong đợi điều gì ở các mô hình AI trong tương lai gần?",
        "options": {
          "A": "Các mô hình có thể tạo ra các bộ phim hoạt hình 3D hoàn chỉnh.",
          "B": "Các mô hình có thể tạo ra các đoạn video hoàn chỉnh với nhạc nền, lời thoại và hiệu ứng âm thanh.",
          "C": "Các mô hình có thể thay thế hoàn toàn các nhà làm phim chuyên nghiệp.",
          "D": "Các mô hình có thể tạo ra các trò chơi điện tử với đồ họa siêu thực."
        },
        "answer": "B"
      },
      {
        "question": "Meta's Movie Gen có khả năng gì theo như bài viết?",
        "options": {
          "A": "Tạo ra các đoạn video ngắn dựa trên mô tả bằng văn bản, kèm theo nhạc nền và hiệu ứng âm thanh.",
          "B": "Chỉnh sửa và nâng cấp chất lượng video hiện có.",
          "C": "Tự động viết kịch bản phim dựa trên thể loại được chọn.",
          "D": "Phân tích và đánh giá chất lượng của các bộ phim."
        },
        "answer": "A"
      },
      {
        "question": "Theo tác giả, điều gì có thể không phải là rào cản lớn trong việc phát triển các mô hình tạo video điện ảnh?",
        "options": {
          "A": "Thiếu hụt nhân lực có trình độ cao.",
          "B": "Chi phí đầu tư vào phần cứng quá lớn.",
          "C": "Sự phức tạp của thuật toán AI.",
          "D": "Dữ liệu huấn luyện có thể đã có sẵn từ các video được dùng để huấn luyện các mô hình tạo video hiện tại."
        },
        "answer": "D"
      },
      {
        "question": "Tác giả dự đoán về chất lượng video do AI tạo ra trong tương lai như thế nào?",
        "options": {
          "A": "Sẽ mãi mãi thua kém các sản phẩm của các nhà làm phim chuyên nghiệp.",
          "B": "Sẽ nhanh chóng đạt đến chất lượng tương đương với các sản phẩm Hollywood.",
          "C": "Sẽ chỉ đạt đến chất lượng chấp nhận được cho các dự án nhỏ.",
          "D": "Sẽ tập trung vào việc tạo ra các video mang tính thử nghiệm và nghệ thuật."
        },
        "answer": "B"
      },
      {
        "question": "Ví dụ về Udio được tác giả sử dụng để minh họa cho điều gì?",
        "options": {
          "A": "Sự phức tạp trong việc tạo ra các mô hình AI tạo nhạc.",
          "B": "Sự gia tăng khả năng kiểm soát của người dùng đối với các sản phẩm do AI tạo ra.",
          "C": "Sự cạnh tranh gay gắt giữa các công ty phát triển AI.",
          "D": "Sự cần thiết của việc có một giao diện người dùng thân thiện."
        },
        "answer": "B"
      },
      {
        "question": "Tác giả so sánh các mô hình tạo video điện ảnh với công cụ nào khác?",
        "options": {
          "A": "Máy ảnh kỹ thuật số.",
          "B": "Phần mềm chỉnh sửa ảnh Photoshop.",
          "C": "Các công cụ hỗ trợ lập trình AI.",
          "D": "Các ứng dụng mạng xã hội."
        },
        "answer": "C"
      },
      {
        "question": "Theo tác giả, lợi ích của các công cụ AI tạo video là gì?",
        "options": {
          "A": "Giúp người dùng tạo ra các sản phẩm hoàn hảo ngay lập tức.",
          "B": "Thay thế hoàn toàn vai trò của các chuyên gia trong ngành.",
          "C": "Cung cấp một điểm khởi đầu sáng tạo và giúp người dùng tập trung vào các khía cạnh quan trọng hơn.",
          "D": "Giảm chi phí sản xuất video một cách đáng kể."
        },
        "answer": "C"
      },
      {
        "question": "Tác giả nhấn mạnh điều gì về vai trò của con người trong quá trình sáng tạo video với sự hỗ trợ của AI?",
        "options": {
          "A": "Con người sẽ trở nên thừa thãi vì AI có thể làm mọi thứ.",
          "B": "Con người vẫn đóng vai trò quan trọng trong việc đưa ra các lựa chọn sáng tạo và định hình tác phẩm.",
          "C": "Con người chỉ cần cung cấp ý tưởng ban đầu, còn lại AI sẽ tự động hoàn thành.",
          "D": "Con người chỉ cần kiểm tra và chỉnh sửa những lỗi nhỏ do AI gây ra."
        },
        "answer": "B"
      },
      {
        "question": "David Ding là ai?",
        "options": {
          "A": "Một nhà làm phim Hollywood nổi tiếng.",
          "B": "Một nhà nghiên cứu AI tại Google DeepMind.",
          "C": "Đồng sáng lập của Udio và là một nhạc sĩ.",
          "D": "Một chuyên gia về hiệu ứng âm thanh trong phim."
        },
        "answer": "C"
      }
    ]
  },
  "generative-ai-for-artists": {
    "title": "Hanno Basse",
    "collection": "culture",
    "content": "Stability AI’s aim is to liberate artists of all trades from the repetitive, mechanical aspects of their work and help them spend the majority of their time on the creative side. So our highest hope for next year is that generative AI will help people to be more creative and productive.\n\nIn addition, I hope the AI community will focus on:\n\nHanno Basse is Chief Technology Officer of Stability AI. Previously he served as CTO of Digital Domain, Microsoft Azure Media and Entertainment, and 20th Century Fox Film Corp.",
    "qa": [
      {
        "question": "Mục tiêu chính của Stability AI là gì?",
        "options": {
          "A": "Thay thế hoàn toàn nghệ sĩ bằng AI.",
          "B": "Giải phóng nghệ sĩ khỏi các công việc lặp đi lặp lại và giúp họ tập trung vào sáng tạo.",
          "C": "Tạo ra các tác phẩm nghệ thuật hoàn toàn tự động.",
          "D": "Giảm chi phí sản xuất nghệ thuật."
        },
        "answer": "B"
      },
      {
        "question": "Theo Stability AI, hy vọng lớn nhất cho năm tới liên quan đến AI tạo sinh là gì?",
        "options": {
          "A": "AI sẽ thay thế hoàn toàn công việc của con người.",
          "B": "AI sẽ giúp mọi người sáng tạo và làm việc hiệu quả hơn.",
          "C": "AI sẽ tạo ra các tác phẩm nghệ thuật có giá trị cao.",
          "D": "AI sẽ trở nên phổ biến hơn trong ngành công nghiệp giải trí."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài việc tăng cường sáng tạo, cộng đồng AI nên tập trung vào điều gì khác theo tác giả?",
        "options": {
          "A": "Phát triển các thuật toán AI phức tạp hơn.",
          "B": "Bài viết không đề cập đến điều này.",
          "C": "Tăng cường bảo mật dữ liệu người dùng.",
          "D": "Giảm thiểu tác động tiêu cực của AI đến môi trường."
        },
        "answer": "B"
      },
      {
        "question": "Hanno Basse hiện đang giữ chức vụ gì tại Stability AI?",
        "options": {
          "A": "Giám đốc điều hành (CEO).",
          "B": "Giám đốc công nghệ (CTO).",
          "C": "Giám đốc tài chính (CFO).",
          "D": "Giám đốc marketing (CMO)."
        },
        "answer": "B"
      },
      {
        "question": "Trước khi gia nhập Stability AI, Hanno Basse từng là CTO của công ty nào?",
        "options": {
          "A": "Google.",
          "B": "Apple.",
          "C": "Digital Domain.",
          "D": "Amazon."
        },
        "answer": "C"
      },
      {
        "question": "Hanno Basse cũng từng giữ chức vụ CTO tại Microsoft, cụ thể là bộ phận nào?",
        "options": {
          "A": "Microsoft Office.",
          "B": "Microsoft Azure Media and Entertainment.",
          "C": "Microsoft Gaming.",
          "D": "Microsoft Research."
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào sau đây Hanno Basse từng làm việc?",
        "options": {
          "A": "Warner Bros.",
          "B": "Universal Pictures.",
          "C": "20th Century Fox Film Corp.",
          "D": "Paramount Pictures."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết này chủ yếu tập trung vào vấn đề gì?",
        "options": {
          "A": "Những lo ngại về sự phát triển của AI.",
          "B": "Tiềm năng của AI tạo sinh trong lĩnh vực nghệ thuật và sáng tạo.",
          "C": "Sự cạnh tranh giữa các công ty AI.",
          "D": "Các vấn đề đạo đức liên quan đến AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo tác giả, AI có thể giúp nghệ sĩ như thế nào?",
        "options": {
          "A": "Tự động tạo ra các tác phẩm nghệ thuật hoàn chỉnh.",
          "B": "Giảm bớt gánh nặng về tài chính cho nghệ sĩ.",
          "C": "Tập trung vào các khía cạnh sáng tạo thay vì các công việc lặp đi lặp lại.",
          "D": "Giúp nghệ sĩ nổi tiếng hơn trên mạng xã hội."
        },
        "answer": "C"
      },
      {
        "question": "Vai trò của Hanno Basse trong bài viết là gì?",
        "options": {
          "A": "Một nhà phê bình nghệ thuật.",
          "B": "Một nhà nghiên cứu AI độc lập.",
          "C": "Một đại diện của Stability AI chia sẻ quan điểm về AI tạo sinh.",
          "D": "Một người dùng thử nghiệm các công cụ AI."
        },
        "answer": "C"
      }
    ]
  },
  "generative-ai-from-deviantart-creates-controversy": {
    "title": "Creatives Fight Back",
    "collection": "culture",
    "content": "Artists are rebelling against AI-driven imitation.What’s new:DeviantArt, an online community where artists display and sell their work and marketplace for digital art,launchedDreamUp, a text-to-image generator that aims to help artists thwart attempts to imitate their styles or works.How it works:DreamUp is avanilla implementationof the open sourceStable Diffusiontext-to-image generator.\n\nOpting out:Stable Diffusion was trained on images scraped from the web including works from DeviantArt. Upon its release, some artistsobjectedto the model’s ability to replicate their style via prompts like, “in the style of ____.”\n\nBehind the news:AI’s increasing ability to mimic the styles of individual artists has become a flashpoint between engineers and artists. When acclaimed artist Kim Jung Gidiedin early October, within one day a former game developerreleaseda model trained to produce works in his style. While the developer justified the work “as an homage,” responses included not only criticism and insults but also threats of violence. Such comments, one commenter noted, were part of a recent rise in “extremely violent rhetoric directed at the AI art community.”\n\nWhy it matters:Generative AI is attracting attention andfunding, but the ethics of training and using such systems are still coming into focus. For instance, lawyers arepreparingto argue that GitHub’s CoPilot code-generation system, which was trained on open-source code, violates open-source licenses by improperly crediting coders for their work. The outcome may resolve some uncertainty about how to credit a generative model’s output — but it seems unlikely to address issues of permission and compensation.\n\nWe’re thinking:Artists who have devoted years to developing a distinctive style are justifiably alarmed to see machines crank out imitations of their work. Some kind of protection against copycats is only fair. For the time being, though, the limit of fair use in training and using AI models remains an open question.",
    "qa": [
      {
        "question": "DeviantArt đã ra mắt công cụ nào để hỗ trợ nghệ sĩ chống lại việc sao chép phong cách?",
        "options": {
          "A": "Stable Diffusion",
          "B": "DreamUp",
          "C": "CoPilot",
          "D": "Kim Jung Gi Model"
        },
        "answer": "B"
      },
      {
        "question": "DreamUp được xây dựng dựa trên nền tảng công nghệ nào?",
        "options": {
          "A": "Một thuật toán độc quyền của DeviantArt",
          "B": "Một phiên bản tùy chỉnh của CoPilot",
          "C": "Một triển khai vanilla của Stable Diffusion",
          "D": "Một mô hình AI được phát triển bởi Kim Jung Gi"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì đã khiến một số nghệ sĩ phản đối Stable Diffusion sau khi nó được phát hành?",
        "options": {
          "A": "Khả năng tạo ra các tác phẩm nghệ thuật hoàn toàn mới.",
          "B": "Khả năng sao chép phong cách của họ thông qua các lệnh.",
          "C": "Chi phí sử dụng quá cao.",
          "D": "Giao diện người dùng quá phức tạp."
        },
        "answer": "B"
      },
      {
        "question": "Sau khi nghệ sĩ Kim Jung Gi qua đời, một mô hình AI đã được tạo ra để làm gì?",
        "options": {
          "A": "Để bán các tác phẩm nghệ thuật của ông.",
          "B": "Để tưởng nhớ phong cách nghệ thuật của ông.",
          "C": "Để thay thế ông trong ngành công nghiệp game.",
          "D": "Để phân tích các tác phẩm nghệ thuật của ông."
        },
        "answer": "B"
      },
      {
        "question": "Phản ứng của cộng đồng đối với mô hình AI được tạo ra theo phong cách Kim Jung Gi là gì?",
        "options": {
          "A": "Hoàn toàn ủng hộ và ca ngợi.",
          "B": "Chủ yếu là thờ ơ và không quan tâm.",
          "C": "Bao gồm cả chỉ trích, lăng mạ và đe dọa bạo lực.",
          "D": "Chỉ trích nhẹ nhàng và góp ý xây dựng."
        },
        "answer": "C"
      },
      {
        "question": "Vấn đề pháp lý nào đang được tranh luận liên quan đến GitHub's CoPilot?",
        "options": {
          "A": "Vi phạm bản quyền đối với các tác phẩm nghệ thuật.",
          "B": "Vi phạm luật bảo vệ dữ liệu cá nhân.",
          "C": "Vi phạm giấy phép mã nguồn mở bằng cách không ghi công đúng cách cho người viết mã.",
          "D": "Vi phạm luật chống độc quyền."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, kết quả của vụ kiện liên quan đến CoPilot có khả năng giải quyết vấn đề gì?",
        "options": {
          "A": "Vấn đề bồi thường cho nghệ sĩ bị sao chép phong cách.",
          "B": "Vấn đề xin phép sử dụng phong cách của nghệ sĩ.",
          "C": "Sự không chắc chắn về cách ghi công đầu ra của mô hình tạo sinh.",
          "D": "Tất cả các vấn đề liên quan đến đạo đức AI."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì khiến các nghệ sĩ lo lắng về sự phát triển của AI tạo sinh?",
        "options": {
          "A": "AI sẽ thay thế hoàn toàn công việc của họ.",
          "B": "Máy móc có thể tạo ra các bản sao tác phẩm của họ một cách dễ dàng.",
          "C": "Chi phí sử dụng AI quá đắt đỏ.",
          "D": "AI sẽ làm giảm giá trị của nghệ thuật truyền thống."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến vấn đề gì còn bỏ ngỏ liên quan đến AI?",
        "options": {
          "A": "Khả năng của AI trong việc tạo ra nghệ thuật thực sự.",
          "B": "Giới hạn của việc sử dụng hợp pháp trong việc đào tạo và sử dụng các mô hình AI.",
          "C": "Chi phí phát triển và duy trì các mô hình AI.",
          "D": "Tác động của AI đến thị trường lao động."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của bài viết là gì?",
        "options": {
          "A": "Quảng bá công cụ DreamUp của DeviantArt.",
          "B": "Phân tích kỹ thuật của Stable Diffusion.",
          "C": "Thảo luận về những tranh cãi đạo đức xung quanh việc sử dụng AI trong nghệ thuật.",
          "D": "Dự đoán tương lai của ngành công nghiệp nghệ thuật."
        },
        "answer": "C"
      }
    ]
  },
  "generative-video-models-revolutionize-content-creation-with-stunning-realism": {
    "title": "Generative Video Takes Off",
    "collection": "culture",
    "content": "Video generation exploded in an abundance of powerful models.\n\nWhat happened:Companies big and small introduced new or updated text-to-video generators. Some added image-to-video and/or video-to-video capabilities. While most models focus on generating cinematic clips, some specialize in videos for social media.\n\nDriving the story:Even at the extraordinary pace of AI lately, video generators in the past year matured with remarkable speed.Virtually every major model produces convincing, highly detailed scenes, both realistic and fantastical, while ramping up image resolution, speed, output length, and users’ ability to control their outputs.\n\nBehind the news:Video generation is already reshaping the movie industry. In February, after seeing a preview of Sora, American filmmaker Tyler Perryhalteda planned expansion of his production studio, arguing that within a few years, AI video could put traditional studios out of business. Members of the video graphics team atThe Late Show with Stephen ColbertuseRunway’s technology to add special effects to conventional digital video, cutting editing time from hours to minutes.\n\nWhere things stand:Video generation came a long way in 2024, but there’s still plenty of room for improvement. Because most models only generate a small number of frames at a time, they can struggle to track physics and geometry and to generate consistent characters and scenery over time. The computational demands of maintaining consistency across frames means that generated clips are brief. And even short outputs take substantial time and resources to generate: Sora can take 10 to 20 minutes torenderclips as short as 3 seconds. OpenAI and Runway released faster versions — Sora Turbo and Gen-3 Alpha Turbo — to address the challenge.",
    "qa": [
      {
        "question": "Điều gì đã xảy ra với các mô hình tạo video trong thời gian gần đây?",
        "options": {
          "A": "Chúng trở nên ít phổ biến hơn do chi phí cao.",
          "B": "Sự phát triển mạnh mẽ với sự ra đời của nhiều mô hình mạnh mẽ.",
          "C": "Chúng chỉ được sử dụng trong ngành công nghiệp điện ảnh.",
          "D": "Chúng ngừng phát triển do thiếu dữ liệu huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Đâu là một trong những khả năng mới được thêm vào các mô hình tạo video?",
        "options": {
          "A": "Chuyển văn bản thành âm thanh.",
          "B": "Chuyển hình ảnh thành video.",
          "C": "Tạo ra các trò chơi điện tử.",
          "D": "Dịch ngôn ngữ tự động."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì đặc biệt về tốc độ phát triển của các mô hình tạo video?",
        "options": {
          "A": "Tốc độ phát triển chậm hơn so với các lĩnh vực AI khác.",
          "B": "Tốc độ phát triển ổn định và không có nhiều thay đổi.",
          "C": "Tốc độ phát triển vượt bậc, đặc biệt trong năm vừa qua.",
          "D": "Tốc độ phát triển phụ thuộc hoàn toàn vào nguồn tài trợ."
        },
        "answer": "C"
      },
      {
        "question": "Tyler Perry đã phản ứng như thế nào sau khi xem trước Sora?",
        "options": {
          "A": "Ông đã đầu tư mạnh vào công nghệ này.",
          "B": "Ông đã lên kế hoạch mở rộng studio sản xuất của mình.",
          "C": "Ông đã tạm dừng kế hoạch mở rộng studio vì lo ngại về tác động của AI.",
          "D": "Ông đã hợp tác với OpenAI để phát triển Sora."
        },
        "answer": "C"
      },
      {
        "question": "Công nghệ tạo video đã giúp ích như thế nào cho đội ngũ đồ họa của The Late Show with Stephen Colbert?",
        "options": {
          "A": "Thay thế hoàn toàn đội ngũ đồ họa.",
          "B": "Giảm thời gian chỉnh sửa từ hàng giờ xuống còn vài phút.",
          "C": "Tăng chi phí sản xuất video.",
          "D": "Giúp họ tạo ra các hiệu ứng đặc biệt phức tạp hơn."
        },
        "answer": "B"
      },
      {
        "question": "Một trong những hạn chế của các mô hình tạo video hiện tại là gì?",
        "options": {
          "A": "Khả năng tạo ra video quá chân thực.",
          "B": "Khó khăn trong việc duy trì tính nhất quán của nhân vật và cảnh vật theo thời gian.",
          "C": "Chi phí sản xuất video quá thấp.",
          "D": "Không thể tạo ra video có độ phân giải cao."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao các đoạn video được tạo ra thường ngắn?",
        "options": {
          "A": "Do giới hạn về dung lượng lưu trữ.",
          "B": "Do các nhà phát triển muốn tập trung vào chất lượng hơn số lượng.",
          "C": "Do yêu cầu tính toán lớn để duy trì tính nhất quán giữa các khung hình.",
          "D": "Do người dùng không có nhu cầu xem video dài."
        },
        "answer": "C"
      },
      {
        "question": "Sora mất bao lâu để tạo ra một đoạn video ngắn 3 giây?",
        "options": {
          "A": "Vài giây.",
          "B": "1 đến 2 phút.",
          "C": "10 đến 20 phút.",
          "D": "Hơn một giờ."
        },
        "answer": "C"
      },
      {
        "question": "OpenAI và Runway đã làm gì để giải quyết vấn đề về thời gian tạo video?",
        "options": {
          "A": "Giảm độ phân giải của video.",
          "B": "Phát hành các phiên bản nhanh hơn của mô hình của họ.",
          "C": "Tăng giá dịch vụ.",
          "D": "Hợp tác với các công ty phần cứng."
        },
        "answer": "B"
      },
      {
        "question": "Ngành công nghiệp nào đang được định hình lại bởi công nghệ tạo video?",
        "options": {
          "A": "Ngành công nghiệp sản xuất ô tô.",
          "B": "Ngành công nghiệp thực phẩm.",
          "C": "Ngành công nghiệp điện ảnh.",
          "D": "Ngành công nghiệp du lịch."
        },
        "answer": "C"
      }
    ]
  },
  "google-upgrades-its-ai-music-tools-for-professional-use": {
    "title": "Music Generation for Pros",
    "collection": "culture",
    "content": "Google refreshed its experimental tools for composers and producers.\n\nWhat’s new:Google announced updates of two music-generation apps and the models they're based on.Music AI Sandbox, an app that generates and modifies music according to text prompts, now accepts lyrics to generate songs as well as instrumental music. You can join a waitlisthere.MusicFX DJgenerates a continuous stream of music that users can modify as it plays. Try it outhere.\n\nHow it works:The apps generate 48kHz audio suitable for professional productions. Users can specify key, tempo in beats per minute, instrumentation, style, mood, and other details.\n\nBehind the news:GooglelaunchedLyria 1 and Music AI Sandbox in 2023 as part of an experiment with YouTube, which made them available to composers, producers, and musicians. Since then, the company has developed them with help from music stars including Jacob Collier, Donald “Childish Gambino” Glover, and Wyclef Jean. Lyria 1 recently becameavailablevia the Vertex API to developers who are preapproved by Google.\n\nWhy it matters:While music generators likeSuno and Udioappeal to casual musicians, Music AI Sandbox, with its digital audio workstation-style user interface, aims to address the needs of professionals. This approach puts AI directly into the hands of talented, experienced artists, similar to the way Adobe hasempoweredvideographers and Runway haspartneredwith movie producers.\n\nWe’re thinking:API access to Lyria 2 would be music to our ears!",
    "qa": [
      {
        "question": "Google vừa cập nhật những công cụ thử nghiệm nào dành cho nhà soạn nhạc và nhà sản xuất âm nhạc?",
        "options": {
          "A": "Lyria 1 và MusicFX DJ",
          "B": "Music AI Sandbox và MusicFX DJ",
          "C": "Lyria 2 và Music AI Sandbox",
          "D": "Vertex API và MusicFX DJ"
        },
        "answer": "B"
      },
      {
        "question": "Tính năng mới nào được thêm vào Music AI Sandbox trong bản cập nhật lần này?",
        "options": {
          "A": "Khả năng tạo nhạc từ hình ảnh",
          "B": "Khả năng tạo nhạc từ lời bài hát",
          "C": "Khả năng tạo nhạc từ giọng nói",
          "D": "Khả năng tạo nhạc từ các bản nhạc MIDI"
        },
        "answer": "B"
      },
      {
        "question": "MusicFX DJ tạo ra loại nhạc như thế nào?",
        "options": {
          "A": "Một bản nhạc hoàn chỉnh theo yêu cầu",
          "B": "Một đoạn nhạc ngắn lặp đi lặp lại",
          "C": "Một luồng nhạc liên tục có thể tùy chỉnh",
          "D": "Một bộ sưu tập các hiệu ứng âm thanh"
        },
        "answer": "C"
      },
      {
        "question": "Chất lượng âm thanh đầu ra của các ứng dụng này là bao nhiêu?",
        "options": {
          "A": "44.1kHz",
          "B": "48kHz",
          "C": "96kHz",
          "D": "192kHz"
        },
        "answer": "B"
      },
      {
        "question": "Lyria 1 và Music AI Sandbox được Google ra mắt lần đầu tiên vào năm nào?",
        "options": {
          "A": "2021",
          "B": "2022",
          "C": "2023",
          "D": "2024"
        },
        "answer": "C"
      },
      {
        "question": "Những nghệ sĩ nổi tiếng nào đã tham gia phát triển các công cụ âm nhạc AI của Google?",
        "options": {
          "A": "Taylor Swift, Drake, và Billie Eilish",
          "B": "Jacob Collier, Donald “Childish Gambino” Glover, và Wyclef Jean",
          "C": "Hans Zimmer, John Williams, và Ennio Morricone",
          "D": "David Guetta, Skrillex, và Martin Garrix"
        },
        "answer": "B"
      },
      {
        "question": "Lyria 1 hiện đã có thể truy cập thông qua API nào?",
        "options": {
          "A": "Google Cloud API",
          "B": "YouTube API",
          "C": "Vertex API",
          "D": "TensorFlow API"
        },
        "answer": "C"
      },
      {
        "question": "Điểm khác biệt chính giữa Music AI Sandbox và các trình tạo nhạc như Suno và Udio là gì?",
        "options": {
          "A": "Music AI Sandbox miễn phí, còn Suno và Udio thì trả phí.",
          "B": "Music AI Sandbox có giao diện chuyên nghiệp hơn, hướng đến người dùng chuyên nghiệp.",
          "C": "Music AI Sandbox tạo ra âm thanh chất lượng cao hơn Suno và Udio.",
          "D": "Music AI Sandbox hỗ trợ nhiều thể loại nhạc hơn Suno và Udio."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết so sánh cách tiếp cận của Google trong lĩnh vực âm nhạc AI với cách tiếp cận của công ty nào trong lĩnh vực video và phim ảnh?",
        "options": {
          "A": "Apple và Netflix",
          "B": "Microsoft và Amazon",
          "C": "Adobe và Runway",
          "D": "Sony và Disney"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì mà tác giả bài viết mong muốn Google sẽ cung cấp trong tương lai?",
        "options": {
          "A": "API truy cập vào MusicFX DJ",
          "B": "API truy cập vào Lyria 2",
          "C": "Phiên bản di động của Music AI Sandbox",
          "D": "Hỗ trợ thêm nhiều ngôn ngữ cho Music AI Sandbox"
        },
        "answer": "B"
      }
    ]
  },
  "grimes-released-a-voice-cloning-tool": {
    "title": "Pop Star Invites AI Imitation",
    "collection": "culture",
    "content": "A popular musician is inviting fans to clone her voice. Result: a flood of recordings that sound just like her.What’s new:Experimental pop star Grimes released GrimesAI-1, a generative audio tool that allows anyone to make recordings of their own singing or speech sound like her voice. As of May 24, users had generated more than 15,000 cloned vocal tracks and submitted more than 300 fully produced songs to streaming services,The New York Timesreported.\n\nHow it works: GrimesAI-1 is available onelf.tech, a website built by Grimes and artist-management companyCreateSafe.\n\nBehind the news:Generative audio tools like Murf.ai and Respeecher arefuelinga surge of cloned songs in the styles of popular artists. In April, Universal Music Group, one of the world’s largest owners of music rights, asked streaming services including YouTube and Spotify totake downAI-generated songs.Why it matters:Some voice actors license their voices for use in AI-generated likenesses. Grimes has gone one step further, giving her fans the tools and terms they need to mimic her voice — and perhaps even make money.We’re thinking:While major players in the music industry aim to shut off the spigot of generated music, Grimes is collaborating with her fans. That sounds like a more productive and democratic response.",
    "qa": [
      {
        "question": "GrimesAI-1 là gì?",
        "options": {
          "A": "Một bài hát mới nhất của Grimes.",
          "B": "Một công cụ âm thanh cho phép người dùng tạo ra bản thu âm giọng hát hoặc lời nói nghe giống giọng của Grimes.",
          "C": "Một trang web bán các sản phẩm liên quan đến Grimes.",
          "D": "Một công ty quản lý nghệ sĩ do Grimes thành lập."
        },
        "answer": "B"
      },
      {
        "question": "Tính đến ngày 24 tháng 5, đã có bao nhiêu bản nhạc giọng hát được tạo ra bằng GrimesAI-1?",
        "options": {
          "A": "Hơn 300 bản.",
          "B": "Hơn 15.000 bản.",
          "C": "Chưa đến 1000 bản.",
          "D": "Không có số liệu cụ thể."
        },
        "answer": "B"
      },
      {
        "question": "GrimesAI-1 có sẵn trên nền tảng nào?",
        "options": {
          "A": "YouTube.",
          "B": "Spotify.",
          "C": "Murf.ai.",
          "D": "elf.tech."
        },
        "answer": "D"
      },
      {
        "question": "Công ty nào đã hợp tác với Grimes để xây dựng trang web elf.tech?",
        "options": {
          "A": "Universal Music Group.",
          "B": "CreateSafe.",
          "C": "Respeecher.",
          "D": "The New York Times."
        },
        "answer": "B"
      },
      {
        "question": "Universal Music Group đã có hành động gì liên quan đến các bài hát do AI tạo ra?",
        "options": {
          "A": "Khuyến khích việc sử dụng AI để tạo ra âm nhạc mới.",
          "B": "Yêu cầu các dịch vụ phát trực tuyến gỡ bỏ các bài hát do AI tạo ra.",
          "C": "Hợp tác với các công ty AI để phát triển công nghệ âm nhạc mới.",
          "D": "Mua lại bản quyền của các bài hát do AI tạo ra."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì khiến cách tiếp cận của Grimes khác biệt so với các công ty âm nhạc lớn khác?",
        "options": {
          "A": "Grimes không quan tâm đến việc bảo vệ bản quyền âm nhạc.",
          "B": "Grimes đang hợp tác với người hâm mộ để tạo ra âm nhạc bằng AI.",
          "C": "Grimes đang cố gắng kiểm soát hoàn toàn việc sử dụng giọng hát của mình.",
          "D": "Grimes đang kiện các công ty sử dụng AI để tạo ra âm nhạc."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích của việc cấp phép giọng nói cho AI là gì?",
        "options": {
          "A": "Để ngăn chặn việc sử dụng trái phép giọng nói.",
          "B": "Để cho phép sử dụng giọng nói trong các bản sao do AI tạo ra.",
          "C": "Để tạo ra các hiệu ứng âm thanh đặc biệt.",
          "D": "Để bảo vệ quyền riêng tư của người nổi tiếng."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, GrimesAI-1 có thể giúp người hâm mộ làm gì?",
        "options": {
          "A": "Kiếm tiền từ việc tạo ra các bản nhạc sử dụng giọng của Grimes.",
          "B": "Học cách hát hay hơn.",
          "C": "Trở thành một nghệ sĩ nổi tiếng.",
          "D": "Sản xuất âm nhạc chuyên nghiệp."
        },
        "answer": "A"
      },
      {
        "question": "Các công cụ âm thanh tạo sinh như Murf.ai và Respeecher đang gây ra hiện tượng gì?",
        "options": {
          "A": "Sự sụt giảm trong chất lượng âm nhạc.",
          "B": "Sự gia tăng đột biến của các bài hát sao chép phong cách của các nghệ sĩ nổi tiếng.",
          "C": "Sự khó khăn trong việc phân biệt giữa âm nhạc thật và âm nhạc do AI tạo ra.",
          "D": "Sự phản đối mạnh mẽ từ phía các nghệ sĩ."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đánh giá cách tiếp cận của Grimes như thế nào?",
        "options": {
          "A": "Thiếu sáng tạo và không tôn trọng bản quyền.",
          "B": "Hiệu quả nhưng có thể gây ra nhiều tranh cãi.",
          "C": "Mang tính xây dựng và dân chủ hơn so với các biện pháp kiểm soát khác.",
          "D": "Nguy hiểm và có thể dẫn đến việc lạm dụng công nghệ AI."
        },
        "answer": "C"
      }
    ]
  },
  "harvard-unveils-a-million-book-corpus-for-ai-training": {
    "title": "Massively More Training Text",
    "collection": "science",
    "content": "Harvard University amassed a huge new text corpus for training machine learning models.\n\nWhat’s new:Harvardunveiledthe Harvard Library Public Domain Corpus, nearly 1 million copyright-free books that were digitized as part of the Google Books project. That’s five times as many volumes as Books3, which was used to train large language models including Meta’s Llama 1 and Llama 2 but is no longer available through lawful channels.\n\nHow it works:Harvard Law Library’s Innovation Lab compiled the corpus with funding from Microsoft and OpenAI. For now, it’s available only to current Harvard students, faculty, and staff. The university is working with Google to distribute it widely.\n\nBehind the news:The efforthighlightsthe AI community’s ongoing need for large quantities of high-quality text to keep improving language models. In addition, the EU’s AI Actrequiresthat AI developers disclose the training data they use, a task made simpler by publicly available datasets.Books3, a collection of nearly 200,000 volumes, was withdrawn because it included copyrighted materials. Other large-scale datasets of books includeCommon Corpus, a multilingual library of 2 million to 3 million public-domain books and newspapers.\n\nWhy it matters:Much of the world’s high-quality text that’s easily available on the web already has been collected for training AI models. This makes fresh supplies especially valuable for training larger, more data-hungy models. Projects like the Harvard Library Public Domain Corpus suggest there’s more high-quality text to be mined from books. Classic literature and niche documents also could help AI models draw from a more diverse range of perspectives.\n\nWe’re thinking:Media that has passed out of copyright and into the public domain generally is old — sometimes very old — but it could hold knowledge that’s not widely available elsewhere.",
    "qa": [
      {
        "question": "Đại học Harvard đã công bố một bộ dữ liệu văn bản mới có tên là gì?",
        "options": {
          "A": "Harvard Text Corpus",
          "B": "Harvard Library Public Domain Corpus",
          "C": "Harvard AI Training Data",
          "D": "Harvard Google Books Collection"
        },
        "answer": "B"
      },
      {
        "question": "Số lượng sách trong Harvard Library Public Domain Corpus lớn hơn Books3 bao nhiêu lần?",
        "options": {
          "A": "Gấp đôi",
          "B": "Gấp ba",
          "C": "Gấp năm",
          "D": "Gấp mười"
        },
        "answer": "C"
      },
      {
        "question": "Books3, bộ dữ liệu từng được sử dụng để huấn luyện Llama 1 và Llama 2, hiện tại như thế nào?",
        "options": {
          "A": "Vẫn được sử dụng rộng rãi và hợp pháp.",
          "B": "Đã được thay thế bằng Harvard Library Public Domain Corpus.",
          "C": "Không còn khả dụng thông qua các kênh hợp pháp.",
          "D": "Đang được nâng cấp để tăng số lượng sách."
        },
        "answer": "C"
      },
      {
        "question": "Ai đã tài trợ cho việc biên soạn Harvard Library Public Domain Corpus?",
        "options": {
          "A": "Google và Meta",
          "B": "Microsoft và Google",
          "C": "Microsoft và OpenAI",
          "D": "OpenAI và Meta"
        },
        "answer": "C"
      },
      {
        "question": "Hiện tại, Harvard Library Public Domain Corpus chỉ dành cho đối tượng nào?",
        "options": {
          "A": "Tất cả sinh viên đại học trên toàn thế giới.",
          "B": "Bất kỳ ai đăng ký tài khoản trên trang web của Harvard.",
          "C": "Sinh viên, giảng viên và nhân viên hiện tại của Harvard.",
          "D": "Các nhà nghiên cứu AI được cấp phép bởi Harvard."
        },
        "answer": "C"
      },
      {
        "question": "Đạo luật AI của EU yêu cầu các nhà phát triển AI phải làm gì liên quan đến dữ liệu huấn luyện?",
        "options": {
          "A": "Bảo mật tuyệt đối dữ liệu huấn luyện.",
          "B": "Công khai dữ liệu huấn luyện mà họ sử dụng.",
          "C": "Chỉ sử dụng dữ liệu huấn luyện được cấp phép bởi EU.",
          "D": "Nộp báo cáo chi tiết về dữ liệu huấn luyện cho EU."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính khiến Books3 bị rút khỏi sử dụng là gì?",
        "options": {
          "A": "Chất lượng dữ liệu kém.",
          "B": "Chứa tài liệu vi phạm bản quyền.",
          "C": "Dung lượng quá lớn, khó quản lý.",
          "D": "Không tương thích với các mô hình AI hiện đại."
        },
        "answer": "B"
      },
      {
        "question": "Common Corpus chứa khoảng bao nhiêu sách và báo thuộc phạm vi công cộng?",
        "options": {
          "A": "Gần 1 triệu",
          "B": "Khoảng 200,000",
          "C": "Từ 2 triệu đến 3 triệu",
          "D": "Hơn 5 triệu"
        },
        "answer": "C"
      },
      {
        "question": "Tại sao việc có nguồn cung cấp văn bản chất lượng cao mới lại quan trọng đối với việc huấn luyện mô hình AI?",
        "options": {
          "A": "Giúp giảm chi phí huấn luyện.",
          "B": "Giúp mô hình AI hoạt động nhanh hơn.",
          "C": "Giúp huấn luyện các mô hình lớn hơn, đòi hỏi nhiều dữ liệu hơn.",
          "D": "Giúp mô hình AI dễ dàng được triển khai hơn."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, văn bản cũ (thuộc phạm vi công cộng) có thể mang lại lợi ích gì cho mô hình AI?",
        "options": {
          "A": "Giúp mô hình AI hiểu rõ hơn về lịch sử.",
          "B": "Giúp mô hình AI tạo ra các câu chuyện hấp dẫn hơn.",
          "C": "Giúp mô hình AI truy cập kiến thức không có sẵn ở những nơi khác.",
          "D": "Giúp mô hình AI sử dụng ngôn ngữ một cách trang trọng hơn."
        },
        "answer": "C"
      }
    ]
  },
  "hit-picker": {
    "title": "Hit Picker",
    "collection": "culture",
    "content": "A neural network may help an online music service to spot songs with the potential to go big.What’s new:Musiio uses AI to identify specific attributes and qualities in recorded music. Online audio distributor SoundCloudpurchasedthe Singapore-based startup, which was valued at $10 million last year, for an undisclosed sum.How it works:Musiio trained its model on a proprietary database of songs, each tagged with dozens of labels including genre, vocalist’s gender, instruments featured, and emotions expressed.\n\nBehind the news:A number of companies offer AI-powered tools designed to enable recording companies, artists, and fans to squeeze more value out of music.\n\nWhy it matters:Millions of new songs are released every year. Amid the deluge, AI can help distributors recognize potential hits, recording companies identify talent, fans find music they like, and musicians create sounds that stand out. Of course, the makings of a hit include social dynamics among listeners — presumably that’s where acquirer SoundCloud comes in.We’re thinking:According to models, this edition ofThe Batchhas moderate energy with high variance and a 72 percent chance of being powerful.",
    "qa": [
      {
        "question": "Công ty Musiio sử dụng AI để làm gì?",
        "options": {
          "A": "Tạo ra các bài hát mới.",
          "B": "Xác định các thuộc tính và phẩm chất cụ thể trong âm nhạc đã thu âm.",
          "C": "Phân phối âm nhạc trực tuyến.",
          "D": "Đánh giá giá trị của các công ty âm nhạc."
        },
        "answer": "B"
      },
      {
        "question": "SoundCloud đã mua lại Musiio với mục đích gì?",
        "options": {
          "A": "Để cạnh tranh với các dịch vụ stream nhạc khác.",
          "B": "Để sử dụng AI của Musiio trong việc phát hiện các bài hát tiềm năng.",
          "C": "Để mở rộng thị trường sang Singapore.",
          "D": "Để tăng giá trị công ty lên 10 triệu đô la."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình AI của Musiio được huấn luyện dựa trên dữ liệu nào?",
        "options": {
          "A": "Dữ liệu người dùng SoundCloud.",
          "B": "Dữ liệu các bài hát được gắn nhãn với nhiều thuộc tính khác nhau.",
          "C": "Dữ liệu về xu hướng âm nhạc toàn cầu.",
          "D": "Dữ liệu về doanh thu của các bài hát."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài Musiio, bài viết đề cập đến điều gì về các công ty khác trong lĩnh vực âm nhạc và AI?",
        "options": {
          "A": "Không có công ty nào khác sử dụng AI trong âm nhạc.",
          "B": "Có một số công ty cung cấp các công cụ hỗ trợ AI để khai thác giá trị từ âm nhạc.",
          "C": "Các công ty âm nhạc đang dần từ bỏ việc sử dụng AI.",
          "D": "Chỉ có các công ty lớn mới có khả năng sử dụng AI trong âm nhạc."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, AI có thể giúp ích gì cho các nhà phân phối âm nhạc?",
        "options": {
          "A": "Tự động tạo ra các bài hát mới.",
          "B": "Nhận diện các bài hát có tiềm năng trở thành hit.",
          "C": "Giảm chi phí sản xuất âm nhạc.",
          "D": "Quản lý bản quyền âm nhạc hiệu quả hơn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến yếu tố nào khác ngoài AI có thể tạo nên một bài hit?",
        "options": {
          "A": "Chất lượng thu âm.",
          "B": "Sự nổi tiếng của nghệ sĩ.",
          "C": "Động lực xã hội giữa những người nghe.",
          "D": "Sự hỗ trợ từ các phương tiện truyền thông."
        },
        "answer": "C"
      },
      {
        "question": "Giá trị của Musiio được định giá bao nhiêu trước khi được SoundCloud mua lại?",
        "options": {
          "A": "Không được tiết lộ.",
          "B": "1 triệu đô la.",
          "C": "10 triệu đô la.",
          "D": "100 triệu đô la."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết 'The Batch' được mô tả như thế nào theo các mô hình?",
        "options": {
          "A": "Năng lượng thấp, độ biến động cao, khả năng mạnh mẽ 72%.",
          "B": "Năng lượng vừa phải, độ biến động thấp, khả năng mạnh mẽ 72%.",
          "C": "Năng lượng vừa phải, độ biến động cao, khả năng mạnh mẽ 72%.",
          "D": "Năng lượng cao, độ biến động thấp, khả năng mạnh mẽ 27%."
        },
        "answer": "C"
      },
      {
        "question": "AI có thể giúp các nhạc sĩ làm gì?",
        "options": {
          "A": "Tự động viết lời bài hát.",
          "B": "Tạo ra những âm thanh nổi bật.",
          "C": "Quảng bá âm nhạc của họ trên mạng xã hội.",
          "D": "Tìm kiếm các nhà sản xuất âm nhạc phù hợp."
        },
        "answer": "B"
      },
      {
        "question": "SoundCloud là loại hình dịch vụ gì?",
        "options": {
          "A": "Một công ty sản xuất nhạc cụ.",
          "B": "Một nhà phân phối âm thanh trực tuyến.",
          "C": "Một công ty tổ chức sự kiện âm nhạc.",
          "D": "Một nền tảng mạng xã hội dành cho nhạc sĩ."
        },
        "answer": "B"
      }
    ]
  },
  "how-a-top-architecture-firm-is-using-generative-ai": {
    "title": "Architect’s Sketchbook",
    "collection": "culture",
    "content": "Text-to-image generators are visualizing the next wave of architectural innovation.\n\nWhat’s new:Patrick Schumacher, principal architect at Zaha Hadid Architects,explainedhow the company uses generative AI to come up with ideas. He made the remarks at an industry roundtable called AI and the Future of Design.\n\nHow it works:The architects use DALL•E 2, Midjourney, and Stable Diffusion to generate exterior and interior images of concepts in development. Schumacher showed generated images for projects in development, including a high-rise complex in Hong Kong and Neom, a massive smart city planned for Saudi Arabia.\n\nBehind the news:Text-to-image models are finding their way into a variety of design disciplines.\n\nWhy it matters:Zaha Hadid Architects has worked on Olympic venues, international airport terminals, and skyscrapers. Millions of people soon may interact with buildings visualized by AI.We’re thinking:What a great example of human-computer collaboration: The models learn from the architects’ past designs to help the them envision fresh concepts.",
    "qa": [
      {
        "question": "Công ty kiến trúc Zaha Hadid Architects sử dụng AI tạo sinh để làm gì?",
        "options": {
          "A": "Để thay thế hoàn toàn các kiến trúc sư trong quá trình thiết kế.",
          "B": "Để tạo ra các ý tưởng mới cho các dự án kiến trúc.",
          "C": "Để tự động xây dựng các mô hình 3D của các tòa nhà.",
          "D": "Để kiểm tra tính khả thi về mặt kỹ thuật của các thiết kế hiện có."
        },
        "answer": "B"
      },
      {
        "question": "Những mô hình AI tạo ảnh nào được Zaha Hadid Architects sử dụng?",
        "options": {
          "A": "ChatGPT, Bard, và LLaMA.",
          "B": "DALL•E 2, Midjourney, và Stable Diffusion.",
          "C": "TensorFlow, PyTorch, và Keras.",
          "D": "AutoCAD, Revit, và SketchUp."
        },
        "answer": "B"
      },
      {
        "question": "Patrick Schumacher giữ chức vụ gì tại Zaha Hadid Architects?",
        "options": {
          "A": "Giám đốc điều hành (CEO).",
          "B": "Kiến trúc sư trưởng (Principal Architect).",
          "C": "Giám đốc sáng tạo (Chief Creative Officer).",
          "D": "Quản lý dự án cấp cao (Senior Project Manager)."
        },
        "answer": "B"
      },
      {
        "question": "Neom, một dự án mà Zaha Hadid Architects đang sử dụng AI để hình dung, là gì?",
        "options": {
          "A": "Một khu nghỉ dưỡng sang trọng tại Dubai.",
          "B": "Một thành phố thông minh khổng lồ được quy hoạch tại Ả Rập Saudi.",
          "C": "Một trung tâm nghiên cứu khoa học công nghệ cao ở Thung lũng Silicon.",
          "D": "Một dự án tái thiết đô thị tại London."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến sự hợp tác giữa con người và máy tính như thế nào?",
        "options": {
          "A": "Máy tính thay thế hoàn toàn vai trò của con người trong thiết kế.",
          "B": "Máy tính hỗ trợ con người bằng cách học hỏi từ các thiết kế trước đây và giúp hình dung các ý tưởng mới.",
          "C": "Con người chỉ đóng vai trò giám sát quá trình tạo ra thiết kế bởi máy tính.",
          "D": "Con người và máy tính làm việc độc lập, không có sự tương tác lẫn nhau."
        },
        "answer": "B"
      },
      {
        "question": "Sự kiện nào đã diễn ra mà Patrick Schumacher chia sẻ về việc sử dụng AI trong thiết kế?",
        "options": {
          "A": "Một hội nghị khoa học về trí tuệ nhân tạo.",
          "B": "Một buổi tọa đàm ngành với tên gọi 'AI và Tương lai của Thiết kế'.",
          "C": "Một triển lãm kiến trúc quốc tế.",
          "D": "Một khóa đào tạo về ứng dụng AI trong kiến trúc."
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng của mô hình tạo ảnh từ văn bản (text-to-image) đang được mở rộng sang lĩnh vực nào?",
        "options": {
          "A": "Chỉ giới hạn trong lĩnh vực kiến trúc.",
          "B": "Chỉ giới hạn trong lĩnh vực thiết kế nội thất.",
          "C": "Đang được ứng dụng rộng rãi trong nhiều lĩnh vực thiết kế khác nhau.",
          "D": "Chỉ được sử dụng trong lĩnh vực quảng cáo và marketing."
        },
        "answer": "C"
      },
      {
        "question": "Zaha Hadid Architects nổi tiếng với những loại công trình nào?",
        "options": {
          "A": "Chỉ thiết kế nhà ở dân dụng.",
          "B": "Chỉ thiết kế các công trình công nghiệp.",
          "C": "Các địa điểm Olympic, nhà ga sân bay quốc tế và các tòa nhà chọc trời.",
          "D": "Chỉ thiết kế các công trình tôn giáo."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì có thể xảy ra trong tương lai gần liên quan đến AI và kiến trúc?",
        "options": {
          "A": "Các kiến trúc sư sẽ hoàn toàn bị thay thế bởi AI.",
          "B": "Hàng triệu người có thể sớm tương tác với các tòa nhà được hình dung bởi AI.",
          "C": "Giá trị của các công trình kiến trúc sẽ giảm mạnh do sự can thiệp của AI.",
          "D": "Các công trình kiến trúc sẽ trở nên đơn điệu và thiếu sáng tạo do AI."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc sử dụng AI trong thiết kế kiến trúc là gì?",
        "options": {
          "A": "Giảm chi phí nhân công và tăng lợi nhuận.",
          "B": "Tăng tốc độ hoàn thành dự án và giảm thiểu sai sót.",
          "C": "Hỗ trợ các kiến trúc sư hình dung các ý tưởng mới và sáng tạo hơn.",
          "D": "Tự động hóa hoàn toàn quy trình thiết kế và xây dựng."
        },
        "answer": "C"
      }
    ]
  },
  "how-nvidia-blizzard-and-more-are-using-ai-in-video-games": {
    "title": "Game Makers Embrace Generative AI",
    "collection": "culture",
    "content": "The next generation of video games could be filled with AI-generated text, speech, characters, and background art.What’s new:Nvidiaannounceda system that enables players to converse directly with in-game characters. Meanwhile, game developers are using generative AI to produce media assets,The New York Timesreported.\n\nHow it works:Tech companies are providing software that generates game assets either in production or on the fly. Some large game studios are developing their own tools.\n\nBehind the news:Gamers, too, are using generative AI to modify their favorite games. For instance, modders have used voice cloning tovocalizelines for the main character of “The Elder Scrolls V: Skyrim,” who otherwise is silent.\n\nWhy it matters:Generative AI tools can streamline video game production, which is bound to appeal to developers who aim to cut both costs and timelines. More exciting, it can supercharge their ability to explore art styles, characters, dialog, and other creative features that may not be practical in a conventional production pipeline.We’re thinking:Given the high cost of media production, game development is ripe for disruption by generative AI. While we worry that some artists and writers may lose work, we expect that automating production will also create jobs. Big players are already using the technology to build more elaborate virtual worlds, and many smaller studios will benefit from lower production costs.",
    "qa": [
      {
        "question": "Công nghệ mới nào được Nvidia công bố liên quan đến tương tác trong game?",
        "options": {
          "A": "Hệ thống tạo ra nhân vật game hoàn toàn mới.",
          "B": "Hệ thống cho phép người chơi trò chuyện trực tiếp với nhân vật trong game.",
          "C": "Phần mềm chỉnh sửa giọng nói nhân vật game.",
          "D": "Công cụ tạo ra các đoạn cắt cảnh (cutscene) tự động."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà phát triển game đang sử dụng AI tạo sinh để làm gì?",
        "options": {
          "A": "Tự động chơi game để kiểm tra lỗi.",
          "B": "Sản xuất các tài sản truyền thông (media assets).",
          "C": "Tạo ra các bản mod game.",
          "D": "Phân tích dữ liệu người chơi."
        },
        "answer": "B"
      },
      {
        "question": "Các công ty công nghệ đang cung cấp phần mềm tạo tài sản game theo những cách nào?",
        "options": {
          "A": "Chỉ trong quá trình sản xuất.",
          "B": "Chỉ khi game đang chạy (on the fly).",
          "C": "Cả trong quá trình sản xuất và khi game đang chạy.",
          "D": "Chỉ dành cho các studio game lớn."
        },
        "answer": "C"
      },
      {
        "question": "Người chơi đang sử dụng AI tạo sinh để làm gì với game yêu thích của họ?",
        "options": {
          "A": "Tạo ra các phiên bản game hoàn toàn mới.",
          "B": "Sửa đổi (mod) game.",
          "C": "Tăng độ khó của game.",
          "D": "Chia sẻ game với bạn bè."
        },
        "answer": "B"
      },
      {
        "question": "Ví dụ nào được đưa ra về việc người chơi sử dụng AI tạo sinh để sửa đổi game?",
        "options": {
          "A": "Tạo ra các nhân vật mới cho game Minecraft.",
          "B": "Thêm giọng nói cho nhân vật chính trong 'The Elder Scrolls V: Skyrim'.",
          "C": "Tạo ra các bản đồ mới cho game Call of Duty.",
          "D": "Thay đổi giao diện người dùng của game League of Legends."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích chính của AI tạo sinh đối với quá trình sản xuất game là gì?",
        "options": {
          "A": "Tăng tính cạnh tranh giữa các nhà phát triển.",
          "B": "Đơn giản hóa quá trình sản xuất game.",
          "C": "Tăng giá thành của game.",
          "D": "Giảm số lượng người chơi game."
        },
        "answer": "B"
      },
      {
        "question": "AI tạo sinh có thể giúp các nhà phát triển game khám phá điều gì?",
        "options": {
          "A": "Các phương pháp marketing mới.",
          "B": "Các phong cách nghệ thuật, nhân vật, đối thoại và các tính năng sáng tạo khác.",
          "C": "Các hệ thống thanh toán mới.",
          "D": "Các cách để tăng doanh thu từ game."
        },
        "answer": "B"
      },
      {
        "question": "Ngành nào được cho là sẽ bị 'phá vỡ' bởi AI tạo sinh?",
        "options": {
          "A": "Ngành công nghiệp điện ảnh.",
          "B": "Ngành phát triển game.",
          "C": "Ngành xuất bản sách.",
          "D": "Ngành âm nhạc."
        },
        "answer": "B"
      },
      {
        "question": "Mối lo ngại nào được đề cập liên quan đến việc sử dụng AI tạo sinh trong phát triển game?",
        "options": {
          "A": "Game sẽ trở nên quá dễ.",
          "B": "Một số nghệ sĩ và nhà văn có thể mất việc.",
          "C": "Game sẽ trở nên quá bạo lực.",
          "D": "Người chơi sẽ trở nên nghiện game hơn."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài việc giảm chi phí sản xuất, AI tạo sinh còn mang lại lợi ích gì cho các studio game nhỏ?",
        "options": {
          "A": "Khả năng cạnh tranh với các studio lớn hơn.",
          "B": "Khả năng xây dựng các thế giới ảo phức tạp hơn.",
          "C": "Khả năng tiếp cận thị trường quốc tế dễ dàng hơn.",
          "D": "Khả năng tạo ra các game độc quyền."
        },
        "answer": "B"
      }
    ]
  },
  "joe-rogan-meets-steve-jobs-in-an-ai-generated-podcast": {
    "title": "All Synthetic, All the Time",
    "collection": "culture",
    "content": "Joe Rogan meets Steve Jobs in an AI-generated podcast.\n\nWhat’s new:For the debut episode of a new podcast series, Play.ht synthesized a 19-minute interview between the rock-star podcaster and late Apple CEO. You can hear ithereand propose computer-generated participants in future episodeshere.\n\nHow it works:The Dubai-based startup created the episode using text generation and voice cloning.\n\nBehind the news:Rogan was also the subject of an early experiment in voice cloning. In 2019, Toronto-based Dessareleasedersatz Rogan audio clips — the first of a parade of fake celebrity voices.\n\nWhy it matters:The declamation is occasionally stilted and the script meandering (with occasional lapses into incoherence), but the rapid progress of generative audio combined with the entertainment world’s appetite for novelty suggests that satisfying synthetic productions may not be far off.We’re thinking:How long before we can produceHeroes of Deep Learningwithout actually talking with any of the heroes of deep learning?",
    "qa": [
      {
        "question": "Podcast AI-generated trong bài viết đã tạo ra cuộc phỏng vấn giữa những nhân vật nào?",
        "options": {
          "A": "Bill Gates và Elon Musk",
          "B": "Joe Rogan và Steve Jobs",
          "C": "Tim Cook và Jeff Bezos",
          "D": "Mark Zuckerberg và Satya Nadella"
        },
        "answer": "B"
      },
      {
        "question": "Podcast AI-generated này dài bao nhiêu phút?",
        "options": {
          "A": "10 phút",
          "B": "15 phút",
          "C": "19 phút",
          "D": "25 phút"
        },
        "answer": "C"
      },
      {
        "question": "Công ty nào đã tạo ra podcast AI-generated này?",
        "options": {
          "A": "Dessare",
          "B": "Apple",
          "C": "Play.ht",
          "D": "Google"
        },
        "answer": "C"
      },
      {
        "question": "Công ty Play.ht có trụ sở tại đâu?",
        "options": {
          "A": "Toronto",
          "B": "Dubai",
          "C": "California",
          "D": "New York"
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ nào được sử dụng để tạo ra podcast AI-generated này?",
        "options": {
          "A": "Deepfake và Machine Learning",
          "B": "Text generation và Voice cloning",
          "C": "Image recognition và Natural Language Processing",
          "D": "Blockchain và Cryptocurrency"
        },
        "answer": "B"
      },
      {
        "question": "Joe Rogan đã từng là đối tượng của một thí nghiệm nào trước đây?",
        "options": {
          "A": "Tạo ảnh deepfake",
          "B": "Tạo video giả mạo",
          "C": "Nhân bản giọng nói",
          "D": "Tạo chatbot AI"
        },
        "answer": "C"
      },
      {
        "question": "Công ty nào đã phát hành các đoạn âm thanh giả mạo của Joe Rogan vào năm 2019?",
        "options": {
          "A": "Play.ht",
          "B": "Apple",
          "C": "Dessare",
          "D": "Google AI"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, một hạn chế của podcast AI-generated là gì?",
        "options": {
          "A": "Chất lượng âm thanh kém",
          "B": "Giọng đọc đôi khi gượng gạo và kịch bản lan man",
          "C": "Nội dung không chính xác",
          "D": "Thời lượng quá ngắn"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết dự đoán điều gì về tương lai của sản xuất âm thanh tổng hợp?",
        "options": {
          "A": "Sẽ không bao giờ đạt đến chất lượng chấp nhận được",
          "B": "Sẽ sớm tạo ra các sản phẩm tổng hợp thỏa mãn",
          "C": "Sẽ chỉ được sử dụng cho mục đích giải trí",
          "D": "Sẽ bị cấm do lo ngại về đạo đức"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến một ý tưởng về việc sản xuất chương trình nào mà không cần phỏng vấn trực tiếp?",
        "options": {
          "A": "Heroes of Silicon Valley",
          "B": "Heroes of Artificial Intelligence",
          "C": "Heroes of Deep Learning",
          "D": "Heroes of Machine Learning"
        },
        "answer": "C"
      }
    ]
  },
  "k-pop-hit-song-recorded-in-6-languages-using-deep-learning": {
    "title": "K-Pop Sings in Many Tongues",
    "collection": "culture",
    "content": "A Korean pop star recorded a song in six languages, thanks to deep learning.\n\nWhat’s new:Midnatt (better known as Lee Hyun) sang his latest release, “Masquerade,” in English, Japanese, Mandarin, Spanish, and Vietnamese — none of which he speaks fluently — as well as his native Korean. The entertainment company Hybe used a deep learning system to improve his pronunciation,Reutersreported. You can listen to the resultshere.How it works:Hybe used Neural Analysis and Synthesis (NANSY), a neural speech processor developed by the Seoul-based startup Supertone, which Hybe acquired in January for $36 million.\n\nBehind the news:The music industry has been paying close attention to generative audio models lately, as fans have used deep learning systems tomimicthe voices of established artists. Reactions from artists and music companies have been mixed.\n\nWhy it matters:This application of generated audio suggests that the technology could have tremendous commercial value. K-pop artists frequently release songs in English and Japanese, and popular musicians have recorded their songs in multiple languages since at least the 1930s, when Marlene Dietrich recorded her hits in English as well as her native German. This approach could help singers all over the world to reach listeners who may be more receptive to songs in a familiar language.We’re thinking:Auto-Tune software began as a tool for correcting flaws in vocal performances, but musicians quickly exploited it as an effect in its own right. How long before adventurous artists use pronunciation correction to, say, sing in their own languages with foreign accents?",
    "qa": [
      {
        "question": "Ca sĩ Midnatt (Lee Hyun) đã hát bài 'Masquerade' bằng bao nhiêu ngôn ngữ?",
        "options": {
          "A": "4",
          "B": "6",
          "C": "5",
          "D": "7"
        },
        "answer": "B"
      },
      {
        "question": "Công ty giải trí Hybe đã sử dụng công nghệ gì để cải thiện phát âm cho Midnatt?",
        "options": {
          "A": "Auto-Tune",
          "B": "Deep learning",
          "C": "Neural Analysis and Correction (NAC)",
          "D": "Phần mềm chỉnh sửa âm thanh truyền thống"
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống xử lý giọng nói NANSY được phát triển bởi công ty nào?",
        "options": {
          "A": "Hybe",
          "B": "Reuters",
          "C": "Seoul Music",
          "D": "Supertone"
        },
        "answer": "D"
      },
      {
        "question": "Hybe đã mua lại Supertone với giá bao nhiêu?",
        "options": {
          "A": "$3.6 triệu",
          "B": "$360 triệu",
          "C": "$63 triệu",
          "D": "$36 triệu"
        },
        "answer": "D"
      },
      {
        "question": "Ngành công nghiệp âm nhạc đang quan tâm đến loại mô hình nào gần đây?",
        "options": {
          "A": "Mô hình dự đoán doanh thu",
          "B": "Mô hình âm thanh tổng quát (generative audio models)",
          "C": "Mô hình phân tích xu hướng âm nhạc",
          "D": "Mô hình tạo video âm nhạc"
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng của âm thanh được tạo ra có thể mang lại giá trị thương mại lớn như thế nào?",
        "options": {
          "A": "Không đáng kể",
          "B": "Có thể có giá trị thương mại lớn",
          "C": "Chỉ có giá trị trong ngành K-pop",
          "D": "Chỉ có giá trị về mặt nghệ thuật"
        },
        "answer": "B"
      },
      {
        "question": "Ca sĩ nào được nhắc đến trong bài viết như một ví dụ về việc thu âm các bài hát bằng nhiều ngôn ngữ từ những năm 1930?",
        "options": {
          "A": "Lee Hyun",
          "B": "Marlene Dietrich",
          "C": "Một ca sĩ K-pop nổi tiếng",
          "D": "Một ca sĩ người Đức"
        },
        "answer": "B"
      },
      {
        "question": "Phần mềm Auto-Tune ban đầu được tạo ra với mục đích gì?",
        "options": {
          "A": "Tạo hiệu ứng giọng hát đặc biệt",
          "B": "Chỉnh sửa các lỗi trong giọng hát",
          "C": "Tự động sáng tác nhạc",
          "D": "Thay đổi hoàn toàn giọng hát của ca sĩ"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết gợi ý gì về việc sử dụng công nghệ chỉnh sửa phát âm trong tương lai?",
        "options": {
          "A": "Sẽ bị cấm sử dụng",
          "B": "Có thể được sử dụng để hát bằng ngôn ngữ của mình với giọng nước ngoài",
          "C": "Chỉ được sử dụng để hát bằng tiếng Anh",
          "D": "Sẽ trở nên lỗi thời"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, phản ứng của các nghệ sĩ và công ty âm nhạc đối với việc sử dụng deep learning để mô phỏng giọng ca sĩ như thế nào?",
        "options": {
          "A": "Hoàn toàn ủng hộ",
          "B": "Hoàn toàn phản đối",
          "C": "Trái chiều",
          "D": "Chưa có phản ứng gì"
        },
        "answer": "C"
      }
    ]
  },
  "microsoft-extends-copilot-365-windows": {
    "title": "Chatbots for Productivity",
    "collection": "culture",
    "content": "Having broken the ice around chat-enabled web search, Microsoft has extended the concept to coding, office productivity, and the operating system itself.What’s new:Microsoftrefreshedits Copilot line of chatbots, adding new features, renaming old ones, and unifying the brand into what it calls an “everyday AI companion.”How it works:Microsoft offers Copilots for its subsidiary GitHub, Microsoft 365, and Windows.\n\nBehind the news:The emergence of ChatGPT set off aracebetween Microsoft and Alphabet to integrate large language models into search and beyond. Microsoft seized the day in early February when it launched a version of its Bing search engine that incorporated OpenAI’s technology, and its Copilot strategy has extended that lead. But Alphabet is nipping at Microsoft’s heels. It’sbringingits Bard chatbot to Google productivity apps, from email to spreadsheets.Why it matters:The combination of large language models and productivity software is a significant step. Microsoft’s approach seems likely to inspire millions of people who have never written a macro or opened the command line to start prompting AI models.We’re thinking:Copilot is a great concept. It helped make software engineers early adopters of large language models — for writing code, not prose.\n\nThis story first appeared in theSeptember 27, 2023edition of The Batch.",
    "qa": [
      {
        "question": "Microsoft đã mở rộng khái niệm tìm kiếm web hỗ trợ chat sang những lĩnh vực nào?",
        "options": {
          "A": "Marketing, bán hàng và dịch vụ khách hàng.",
          "B": "Lập trình, năng suất văn phòng và hệ điều hành.",
          "C": "Thiết kế đồ họa, chỉnh sửa video và sản xuất âm nhạc.",
          "D": "Nghiên cứu khoa học, phân tích dữ liệu và trí tuệ nhân tạo."
        },
        "answer": "B"
      },
      {
        "question": "Microsoft gọi dòng chatbot Copilot của mình là gì?",
        "options": {
          "A": "Trợ lý ảo cá nhân.",
          "B": "Người bạn đồng hành AI hàng ngày.",
          "C": "Công cụ hỗ trợ công việc thông minh.",
          "D": "Hệ thống tự động hóa quy trình."
        },
        "answer": "B"
      },
      {
        "question": "Copilot của Microsoft được cung cấp cho những nền tảng nào?",
        "options": {
          "A": "GitHub, Microsoft 365 và Android.",
          "B": "GitHub, Microsoft 365 và Windows.",
          "C": "Windows, iOS và Microsoft Azure.",
          "D": "Microsoft Azure, GitHub và Microsoft Teams."
        },
        "answer": "B"
      },
      {
        "question": "Sự kiện nào đã thúc đẩy cuộc đua giữa Microsoft và Alphabet trong việc tích hợp mô hình ngôn ngữ lớn?",
        "options": {
          "A": "Sự ra mắt của Google Assistant.",
          "B": "Sự ra mắt của ChatGPT.",
          "C": "Sự ra mắt của Siri của Apple.",
          "D": "Sự ra mắt của Alexa của Amazon."
        },
        "answer": "B"
      },
      {
        "question": "Microsoft đã tận dụng lợi thế trong cuộc đua AI bằng cách nào?",
        "options": {
          "A": "Mua lại OpenAI.",
          "B": "Ra mắt phiên bản Bing tích hợp công nghệ OpenAI.",
          "C": "Phát triển mô hình ngôn ngữ lớn riêng.",
          "D": "Hợp tác với các trường đại học hàng đầu."
        },
        "answer": "B"
      },
      {
        "question": "Alphabet đang cạnh tranh với Microsoft bằng cách nào?",
        "options": {
          "A": "Mua lại GitHub.",
          "B": "Đưa chatbot Bard vào các ứng dụng năng suất của Google.",
          "C": "Phát triển hệ điều hành mới cạnh tranh với Windows.",
          "D": "Tập trung vào nghiên cứu trí tuệ nhân tạo tổng quát."
        },
        "answer": "B"
      },
      {
        "question": "Sự kết hợp giữa mô hình ngôn ngữ lớn và phần mềm năng suất có ý nghĩa gì?",
        "options": {
          "A": "Giảm chi phí phát triển phần mềm.",
          "B": "Một bước tiến quan trọng trong lĩnh vực công nghệ.",
          "C": "Tăng cường bảo mật dữ liệu người dùng.",
          "D": "Đơn giản hóa việc quản lý dự án."
        },
        "answer": "B"
      },
      {
        "question": "Cách tiếp cận của Microsoft có khả năng truyền cảm hứng cho những ai?",
        "options": {
          "A": "Các nhà khoa học dữ liệu chuyên nghiệp.",
          "B": "Những người chưa từng viết macro hoặc mở dòng lệnh.",
          "C": "Các nhà quản lý dự án công nghệ thông tin.",
          "D": "Các chuyên gia bảo mật mạng."
        },
        "answer": "B"
      },
      {
        "question": "Copilot ban đầu được sử dụng chủ yếu bởi ai?",
        "options": {
          "A": "Các nhà văn và biên tập viên.",
          "B": "Các kỹ sư phần mềm.",
          "C": "Các nhà thiết kế đồ họa.",
          "D": "Các chuyên gia marketing."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết này lần đầu tiên xuất hiện trên ấn phẩm nào và vào ngày nào?",
        "options": {
          "A": "The New York Times, ngày 26 tháng 9 năm 2023.",
          "B": "The Batch, ngày 27 tháng 9 năm 2023.",
          "C": "TechCrunch, ngày 28 tháng 9 năm 2023.",
          "D": "Wired, ngày 29 tháng 9 năm 2023."
        },
        "answer": "B"
      }
    ]
  },
  "openai-launches-api-access-to-gpt-image-1-chatgpts-viral-image-generator": {
    "title": "New Image Generator for OpenAI API",
    "collection": "culture",
    "content": "ChatGPT’s image generator is available via API.\n\nWhat’s new:GPT Image 1, which produces images from text or other images, has proven enormously popular among ChatGPT users. TheOpenAI Images APIenables developers to incorporate OpenAI’s most sophisticated image generator into their own software tools and platforms.\n\nHow it works:GPT Image 1generates and modifies imagesin a wide range of styles, performs image editing and other alterations, renders text, and follows detailed instructions. Shortly after its debut, the version of GPT-4o equipped with GPT Image 1 quickly soared to the No. 1 spot on theArtificial Analysis Image Arena leaderboard.\n\nBehind the news:In March, OpenAI attracted huge public interest when it deployed the model, then unnamed, inChatGPT. Within the first week,130 millionusers used it to create more than 700 million images.\n\nWhy it matters:Adding GPT Image 1 to the API enables developers to use OpenAI’s most sophisticated image generator in a wide variety of automated workflows. OpenAI’s initial API partners include design companies (Adobe and Canva), marketers (HubSpot), and web designers (GoDaddy), all of which are using GPT Image 1.\n\nWe’re thinking:GPT Image 1 is part of an exciting trend toward unification of multimodal architectures. Researchers have progressed fromtext-in, text-outtotext/images-in, text-outand increasinglytext/images/audio-in, text/images/audio-out. This paints a beautiful picture of where multimodal models can go!",
    "qa": [
      {
        "question": "GPT Image 1 của OpenAI hiện đã có thể được sử dụng thông qua phương thức nào?",
        "options": {
          "A": "Trực tiếp trên trang web OpenAI.",
          "B": "Thông qua API.",
          "C": "Thông qua ứng dụng di động của OpenAI.",
          "D": "Thông qua các đối tác được ủy quyền của OpenAI."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã khiến GPT Image 1 trở nên phổ biến nhanh chóng?",
        "options": {
          "A": "Khả năng tạo ra hình ảnh 3D chân thực.",
          "B": "Khả năng tạo ra hình ảnh từ văn bản hoặc hình ảnh khác.",
          "C": "Khả năng tạo ra video ngắn từ văn bản.",
          "D": "Khả năng tạo ra hình ảnh với độ phân giải cực cao."
        },
        "answer": "B"
      },
      {
        "question": "GPT Image 1 đã đạt được vị trí số 1 trên bảng xếp hạng nào sau khi ra mắt?",
        "options": {
          "A": "Artificial Intelligence Performance Index.",
          "B": "Artificial Analysis Image Arena leaderboard.",
          "C": "Global AI Ranking.",
          "D": "AI Model Efficiency Benchmark."
        },
        "answer": "B"
      },
      {
        "question": "Trong tuần đầu tiên ra mắt, có bao nhiêu hình ảnh đã được tạo ra bởi người dùng sử dụng GPT Image 1 trong ChatGPT?",
        "options": {
          "A": "70 triệu.",
          "B": "130 triệu.",
          "C": "500 triệu.",
          "D": "700 triệu."
        },
        "answer": "D"
      },
      {
        "question": "Công ty nào sau đây KHÔNG được đề cập đến như một đối tác API ban đầu của OpenAI sử dụng GPT Image 1?",
        "options": {
          "A": "Adobe.",
          "B": "Canva.",
          "C": "HubSpot.",
          "D": "Microsoft."
        },
        "answer": "D"
      },
      {
        "question": "GPT Image 1 có khả năng thực hiện những chức năng nào sau đây?",
        "options": {
          "A": "Chỉ tạo hình ảnh từ văn bản.",
          "B": "Chỉ chỉnh sửa hình ảnh có sẵn.",
          "C": "Tạo và sửa đổi hình ảnh, thực hiện chỉnh sửa, hiển thị văn bản và tuân theo hướng dẫn chi tiết.",
          "D": "Chỉ tạo hình ảnh theo phong cách hoạt hình."
        },
        "answer": "C"
      },
      {
        "question": "Xu hướng phát triển của các mô hình đa phương tiện (multimodal architectures) được mô tả trong bài viết là gì?",
        "options": {
          "A": "Từ chỉ văn bản đầu vào và văn bản đầu ra.",
          "B": "Từ văn bản đầu vào và hình ảnh đầu ra.",
          "C": "Từ văn bản/hình ảnh đầu vào và văn bản đầu ra, đến văn bản/hình ảnh/âm thanh đầu vào và văn bản/hình ảnh/âm thanh đầu ra.",
          "D": "Từ hình ảnh đầu vào và văn bản đầu ra."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc thêm GPT Image 1 vào API là gì?",
        "options": {
          "A": "Để người dùng cá nhân dễ dàng tạo hình ảnh hơn.",
          "B": "Để các nhà phát triển sử dụng trình tạo hình ảnh tiên tiến nhất của OpenAI trong các quy trình làm việc tự động.",
          "C": "Để giảm chi phí tạo hình ảnh.",
          "D": "Để cạnh tranh với các trình tạo hình ảnh khác trên thị trường."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã thu hút sự quan tâm lớn của công chúng đối với mô hình tạo ảnh của OpenAI vào tháng 3?",
        "options": {
          "A": "Việc phát hành phiên bản beta miễn phí.",
          "B": "Việc triển khai mô hình (lúc đó chưa được đặt tên) trong ChatGPT.",
          "C": "Việc hợp tác với các nghệ sĩ nổi tiếng.",
          "D": "Việc quảng cáo rầm rộ trên các phương tiện truyền thông."
        },
        "answer": "B"
      },
      {
        "question": "GPT Image 1 được mô tả là một phần của xu hướng thú vị nào?",
        "options": {
          "A": "Sự phát triển của các mô hình ngôn ngữ lớn.",
          "B": "Sự thống nhất của các kiến trúc đa phương tiện.",
          "C": "Sự gia tăng của các ứng dụng trí tuệ nhân tạo trong y tế.",
          "D": "Sự phát triển của các công cụ chỉnh sửa ảnh trực tuyến."
        },
        "answer": "B"
      }
    ]
  },
  "prompting-dall-e-for-fun-and-profit": {
    "title": "Prompting DALL·E for Fun and Profit",
    "collection": "culture",
    "content": "An online marketplace enables people to buy text prompts designed to produce consistent output from the new generation of text-to-image generators.\n\nWhat’s new:PromptBase is a virtual marketplace for bespoke text strings designed as input for programs likeDALL·E 2,Midjourney, andStable Diffusion,The Vergereported.\n\nHow it works:Buyers can browse PromptBase by specifying the desired system, searching categories such as “jewelry” or “wallpaper,” or typing in keywords. They can click to purchase the prompt via credit card or Google Pay. The site, which launched in June, has 50,000 active monthly users.\n\nWhat they’re saying:“Every word in a prompt has a weight associated with it, so trying to work out what works best and where becomes a core asset in the skillset,” prompt engineer Justin Reckling, toldThe Verge.\n\nBehind the News:Designer and illustrator Guy Parsons offersThe DALL·E 2 Prompt Book, a compendium of tips for producing effective prompts for text-to-image generators. The book offers several pages of tips including words that describe specific art styles, materials, compositional structures, colors, and emotions, as well as words that can influence photorealistic output such as camera angles, settings, lenses, lighting, film stocks, and so on. Moreover, research published last yearinvestigatesthe relationship between prompt structure, model parameters, and text-to-image output. The work presents a number of helpful guidelines such as, “Keep the focus on keywords rather than rephrasings.”\n\nWhy it matters:AI-driven media generators are opening a universe of productivity in imagery, text, and music. Marketplaces for effective prompts can supercharge these already-powerful tools by cutting the time it takes to generate desirable output. They can also serve as training grounds for the emerging discipline ofprompt engineering: the craft of addressing generative models in ways that yield precise, repeatable output.\n\nWe’re thinking:While they may not immediately replace professional illustrators — many generated images require touching up for professional purposes — image generators are becoming a staple tool of artists and graphic designers and seem likely to put many of them out of work. We hope that prompt engineering can provide an alternative livelihood for some.",
    "qa": [
      {
        "question": "PromptBase là gì?",
        "options": {
          "A": "Một công cụ chỉnh sửa ảnh trực tuyến.",
          "B": "Một thị trường trực tuyến cho phép mua bán các chuỗi văn bản (prompt) được thiết kế để tạo ra kết quả nhất quán từ các trình tạo ảnh từ văn bản.",
          "C": "Một nền tảng mạng xã hội dành cho các nhà thiết kế đồ họa.",
          "D": "Một khóa học trực tuyến về kỹ thuật prompt."
        },
        "answer": "B"
      },
      {
        "question": "Những chương trình nào được đề cập đến trong bài viết có thể sử dụng các prompt mua từ PromptBase?",
        "options": {
          "A": "Photoshop, Illustrator, Figma.",
          "B": "DALL·E 2, Midjourney, Stable Diffusion.",
          "C": "Canva, PicsArt, GIMP.",
          "D": "Blender, Maya, 3ds Max."
        },
        "answer": "B"
      },
      {
        "question": "PromptBase ra mắt vào thời gian nào?",
        "options": {
          "A": "Tháng 1 năm 2022.",
          "B": "Tháng 6 năm 2022.",
          "C": "Tháng 12 năm 2021.",
          "D": "Tháng 3 năm 2023."
        },
        "answer": "B"
      },
      {
        "question": "Theo Justin Reckling, yếu tố nào quan trọng trong việc tạo ra một prompt hiệu quả?",
        "options": {
          "A": "Sử dụng nhiều từ đồng nghĩa.",
          "B": "Mỗi từ trong prompt đều có một trọng số nhất định, và việc tìm ra sự kết hợp tốt nhất là kỹ năng cốt lõi.",
          "C": "Sử dụng câu văn dài và phức tạp.",
          "D": "Tập trung vào việc sử dụng các từ ngữ hoa mỹ."
        },
        "answer": "B"
      },
      {
        "question": "Cuốn sách 'The DALL·E 2 Prompt Book' của Guy Parsons cung cấp thông tin gì?",
        "options": {
          "A": "Hướng dẫn sử dụng phần mềm DALL·E 2.",
          "B": "Các mẹo để tạo ra các prompt hiệu quả cho các trình tạo ảnh từ văn bản.",
          "C": "Phân tích xu hướng thiết kế đồ họa hiện tại.",
          "D": "Hướng dẫn kiếm tiền từ việc bán ảnh AI."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu được đề cập trong bài viết tập trung vào điều gì?",
        "options": {
          "A": "So sánh hiệu suất của các trình tạo ảnh từ văn bản khác nhau.",
          "B": "Mối quan hệ giữa cấu trúc prompt, các tham số mô hình và kết quả tạo ảnh từ văn bản.",
          "C": "Ảnh hưởng của mạng xã hội đến sự phát triển của nghệ thuật AI.",
          "D": "Đánh giá đạo đức của việc sử dụng AI để tạo ra hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích chính của việc sử dụng các marketplace cho prompt là gì?",
        "options": {
          "A": "Giảm chi phí thuê họa sĩ minh họa chuyên nghiệp.",
          "B": "Tăng tốc độ tạo ra kết quả mong muốn và cung cấp nền tảng đào tạo cho kỹ thuật prompt.",
          "C": "Đảm bảo tính độc quyền của hình ảnh được tạo ra.",
          "D": "Tăng cường khả năng sáng tạo của người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết dự đoán điều gì về tương lai của các trình tạo ảnh?",
        "options": {
          "A": "Chúng sẽ hoàn toàn thay thế các họa sĩ minh họa chuyên nghiệp.",
          "B": "Chúng sẽ trở thành công cụ chính của các nghệ sĩ và nhà thiết kế đồ họa, nhưng có thể khiến nhiều người mất việc.",
          "C": "Chúng sẽ chỉ được sử dụng trong lĩnh vực giải trí.",
          "D": "Chúng sẽ không có ảnh hưởng đáng kể đến thị trường lao động."
        },
        "answer": "B"
      },
      {
        "question": "Kỹ thuật 'prompt engineering' được định nghĩa như thế nào trong bài viết?",
        "options": {
          "A": "Quá trình tối ưu hóa phần cứng để chạy các mô hình AI.",
          "B": "Nghệ thuật giao tiếp với các mô hình tạo sinh theo cách tạo ra kết quả chính xác và có thể lặp lại.",
          "C": "Việc phát triển các thuật toán mới cho các trình tạo ảnh.",
          "D": "Việc sử dụng các công cụ chỉnh sửa ảnh để cải thiện chất lượng hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất giải pháp nào cho những người có thể mất việc do sự phát triển của trình tạo ảnh?",
        "options": {
          "A": "Học các kỹ năng lập trình.",
          "B": "Chuyển sang làm việc trong lĩnh vực marketing.",
          "C": "Kỹ thuật prompt có thể cung cấp một sinh kế thay thế.",
          "D": "Tìm kiếm các công việc liên quan đến quản lý dự án."
        },
        "answer": "C"
      }
    ]
  },
  "remix-master": {
    "title": "Remix Master",
    "collection": "culture",
    "content": "Music generated by learning algorithms got a major push with Apple’s acquisition of a startup that makes automated mash-ups.What’s new:Apple purchasedAI Music, a London startup whose software generates new music from existing recordings,Bloombergreported.How it works:Founded in 2016, AI Music reshapes prerecorded music according to user input. Among its projects prior to the acquisition:\n\nBehind the news:AI Music is one of many industrial-scale efforts to generate music in real time, complementing impressive research in the field likeMuseNet. (You can read an interview with MuseNet creator Christine Paynehere).\n\nWhy it matters:Decades ago, Apple’s iTunes servicerevolutionizeddigital music distribution. Today, Apple Music has about half as manysubscribersas Spotify, the leading distributor of streaming music. Its acquisition of AI Music suggests that it sees generated music as a strategic asset.We’re thinking:AI systems don’t yet generate great original music, and copyright law for algorithmically generated music is still evolving. That said, a streaming platform that grinds out music for which it owns the copyright could reap ample rewards.",
    "qa": [
      {
        "question": "Công ty nào đã mua lại AI Music?",
        "options": {
          "A": "Spotify",
          "B": "Apple",
          "C": "Google",
          "D": "Microsoft"
        },
        "answer": "B"
      },
      {
        "question": "AI Music là một startup có trụ sở tại đâu?",
        "options": {
          "A": "New York",
          "B": "London",
          "C": "Silicon Valley",
          "D": "Berlin"
        },
        "answer": "B"
      },
      {
        "question": "AI Music tạo ra âm nhạc mới bằng cách nào?",
        "options": {
          "A": "Sử dụng các nhạc cụ điện tử mới",
          "B": "Tạo ra các bản nhạc gốc hoàn toàn mới",
          "C": "Biến đổi các bản thu âm có sẵn",
          "D": "Kết hợp các thể loại nhạc khác nhau"
        },
        "answer": "C"
      },
      {
        "question": "MuseNet là gì?",
        "options": {
          "A": "Một công ty đối thủ của AI Music",
          "B": "Một dự án nghiên cứu ấn tượng trong lĩnh vực tạo nhạc bằng AI",
          "C": "Một dịch vụ streaming nhạc trực tuyến",
          "D": "Một phần mềm chỉnh sửa âm thanh chuyên nghiệp"
        },
        "answer": "B"
      },
      {
        "question": "Ai là người tạo ra MuseNet?",
        "options": {
          "A": "Tim Cook",
          "B": "Daniel Ek",
          "C": "Christine Payne",
          "D": "Một nhóm các nhà khoa học ẩn danh"
        },
        "answer": "C"
      },
      {
        "question": "Dịch vụ nào của Apple đã từng cách mạng hóa việc phân phối nhạc kỹ thuật số?",
        "options": {
          "A": "Apple Music",
          "B": "iTunes",
          "C": "GarageBand",
          "D": "iMovie"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, Apple Music hiện có số lượng người đăng ký như thế nào so với Spotify?",
        "options": {
          "A": "Gấp đôi",
          "B": "Bằng nhau",
          "C": "Khoảng một nửa",
          "D": "Ít hơn rất nhiều"
        },
        "answer": "C"
      },
      {
        "question": "Việc Apple mua lại AI Music cho thấy điều gì?",
        "options": {
          "A": "Apple muốn cạnh tranh trực tiếp với các công ty sản xuất nhạc cụ",
          "B": "Apple coi âm nhạc do AI tạo ra là một tài sản chiến lược",
          "C": "Apple muốn ngừng phát triển Apple Music",
          "D": "Apple muốn tập trung vào việc phát triển phần mềm chỉnh sửa âm thanh"
        },
        "answer": "B"
      },
      {
        "question": "Một trong những thách thức hiện tại đối với âm nhạc do thuật toán tạo ra là gì?",
        "options": {
          "A": "Chi phí sản xuất quá cao",
          "B": "Chất lượng âm nhạc chưa cao và luật bản quyền chưa rõ ràng",
          "C": "Khó khăn trong việc phân phối đến người dùng",
          "D": "Sự phản đối từ các nhạc sĩ chuyên nghiệp"
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích tiềm năng của một nền tảng streaming sở hữu bản quyền âm nhạc do AI tạo ra là gì?",
        "options": {
          "A": "Giảm chi phí bản quyền",
          "B": "Tăng tính sáng tạo trong âm nhạc",
          "C": "Thu hút nhiều nghệ sĩ mới",
          "D": "Cải thiện chất lượng âm thanh"
        },
        "answer": "A"
      }
    ]
  },
  "sony-music-accuses-ai-developers-of-copyright-violations": {
    "title": "Music Titan Targets AI",
    "collection": "culture",
    "content": "The world’s second-largest music publisher accused AI developers of potential copyright violations.What’s new:Sony Music Groupdeclaredthat AI developers had trained models on Sony’s intellectual property without permission and that any method of collecting media or other data owned by the company violated its copyrights. Whether AI developers actually have violated copyrights has not been established.\n\nHow it works:In astatementposted on the company’s website andlettersto developers, Sony forbade the use of its music or other media such as lyrics, music videos, album art for “training, developing, or commercializing any AI systems.”\n\nBehind the news:In April, more than 200 music artistscalledfor streaming services and AI developers to stop using their work for training and stop generating music in the styles of specific musicians without compensation. Universal Music Group (UMG), which is Sony Music’s top competitor, has also opposed unrestricted AI-generated music.\n\nLast year, UMGorderedApple Music and Spotify to block AI developers from downloading its recordings and issued takedown notices to YouTube and Spotify uploaders who generated music that sounds like artists who are under contract to Universal.\n\nWhy it matters:Sony Music Group’s warning comes as generated audio isapproachinga level of quality that might attract a mainstream audience, and it could chill further progress. Although it is not yet clear whether training AI systems on music recordings without permission violates copyrights, Sony Music Group hasdemonstratedits willingness to pursue both individuals and companies for alleged copyright violations. The company accounted for 22 percent of the global music market in 2023. (UMG accounted for 32 percent.) Its catalog includes many of the world’s most popular artists including AC/DC, Adele, Celine Dion, and Harry Styles.\n\nWe’re thinking:We believe that AI developers should be allowed to let their software learn from data that’s freely available on the internet, but uncertainty over the limits of copyright protection isn’t good for anyone. It’s high time toupdateto intellectual property laws for the era of generative AI.",
    "qa": [
      {
        "question": "Tổ chức nào đã cáo buộc các nhà phát triển AI vi phạm bản quyền?",
        "options": {
          "A": "Universal Music Group (UMG)",
          "B": "Sony Music Group",
          "C": "Apple Music",
          "D": "Spotify"
        },
        "answer": "B"
      },
      {
        "question": "Theo Sony Music Group, hành động nào của các nhà phát triển AI bị xem là vi phạm bản quyền?",
        "options": {
          "A": "Sử dụng âm nhạc của Sony để tạo ra các bài hát mới.",
          "B": "Thu thập dữ liệu thuộc sở hữu của Sony để huấn luyện mô hình AI mà không được phép.",
          "C": "Phân phối âm nhạc của Sony thông qua các nền tảng AI.",
          "D": "Sử dụng phong cách âm nhạc của các nghệ sĩ thuộc Sony để tạo ra âm nhạc mới."
        },
        "answer": "B"
      },
      {
        "question": "Sony Music Group đã cấm sử dụng tài sản trí tuệ của mình cho mục đích nào liên quan đến AI?",
        "options": {
          "A": "Phân tích dữ liệu âm nhạc.",
          "B": "Huấn luyện, phát triển hoặc thương mại hóa bất kỳ hệ thống AI nào.",
          "C": "Nghiên cứu về xu hướng âm nhạc.",
          "D": "Tạo ra các công cụ hỗ trợ sáng tác âm nhạc."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài Sony Music Group, tổ chức nào khác cũng phản đối việc sử dụng âm nhạc do AI tạo ra một cách không hạn chế?",
        "options": {
          "A": "Apple Music",
          "B": "Spotify",
          "C": "Universal Music Group (UMG)",
          "D": "YouTube"
        },
        "answer": "C"
      },
      {
        "question": "UMG đã có hành động gì để ngăn chặn việc sử dụng trái phép âm nhạc của mình bởi các nhà phát triển AI?",
        "options": {
          "A": "Khởi kiện tất cả các nhà phát triển AI.",
          "B": "Yêu cầu Apple Music và Spotify chặn các nhà phát triển AI tải xuống bản ghi âm của mình.",
          "C": "Hợp tác với các nhà phát triển AI để tạo ra các công cụ âm nhạc mới.",
          "D": "Cấm tất cả các nghệ sĩ của mình sử dụng AI trong quá trình sáng tác."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì có thể bị ảnh hưởng bởi cảnh báo của Sony Music Group?",
        "options": {
          "A": "Sự phát triển của ngành công nghiệp âm nhạc nói chung.",
          "B": "Tiến độ phát triển của âm thanh do AI tạo ra.",
          "C": "Mối quan hệ giữa các nghệ sĩ và công ty thu âm.",
          "D": "Giá trị cổ phiếu của Sony Music Group."
        },
        "answer": "B"
      },
      {
        "question": "Thị phần của Sony Music Group trên thị trường âm nhạc toàn cầu năm 2023 là bao nhiêu?",
        "options": {
          "A": "32%",
          "B": "22%",
          "C": "54%",
          "D": "10%"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất gì về luật sở hữu trí tuệ trong kỷ nguyên AI?",
        "options": {
          "A": "Bãi bỏ hoàn toàn luật sở hữu trí tuệ.",
          "B": "Cần cập nhật để phù hợp với kỷ nguyên AI tạo sinh.",
          "C": "Áp dụng luật sở hữu trí tuệ nghiêm ngặt hơn.",
          "D": "Giữ nguyên luật sở hữu trí tuệ hiện hành."
        },
        "answer": "B"
      },
      {
        "question": "Nghệ sĩ nào KHÔNG được đề cập đến trong danh sách các nghệ sĩ nổi tiếng thuộc sở hữu của Sony Music Group?",
        "options": {
          "A": "AC/DC",
          "B": "Adele",
          "C": "Taylor Swift",
          "D": "Harry Styles"
        },
        "answer": "C"
      },
      {
        "question": "Thái độ của bài viết đối với việc các nhà phát triển AI sử dụng dữ liệu có sẵn trên internet là gì?",
        "options": {
          "A": "Phản đối hoàn toàn.",
          "B": "Ủng hộ việc cho phép phần mềm học hỏi từ dữ liệu đó.",
          "C": "Chỉ ủng hộ nếu có sự cho phép của chủ sở hữu bản quyền.",
          "D": "Không đưa ra ý kiến cụ thể."
        },
        "answer": "B"
      }
    ]
  },
  "stability-ai-launches-stable-audio-a-text-to-music-generator-2": {
    "title": "Music Generation For the Masses",
    "collection": "culture",
    "content": "Text-to-music generation has arrived.\n\nWhat's new:Stability.ai, maker of the Stable Diffusion image generator and StableLM text generator, launchedStable Audio, a system that generates music and sound effects from text. You can play with it and listen to exampleshere. The service is free for 20 generations per month up to 45 seconds long. The professional tier allows 500 generations per month, up to 90 seconds long, for $11.99 per month. An enterprise tier is negotiable. The company said it would open-source the model eventually.\n\nHow it works:Stable Audio is alatent diffusionmodel. It generates audio by a process that’s similar to the way Stable Diffusion generates images, but it uses a variational autoencoder to map audio to an embedding for processing and back to audio for your listening pleasure. The authors trained the system on800,000 audio filescontaining music, sound effects, and performances on individual instruments and corresponding descriptions.\n\nBehind the News:Stable Audio joins earlier services including Boomy, Mubert, plugger.ai, Soundful, and VEED.IO. It follows tantalizing advances in audio generation.\n\nYes, but:Stable Audio excels when generating instrumental and ambient music, but its output tends to suffer from some of the same flaws as previous text-to-music generators: Longer outputs often lack a coherent structure, and the clarity and detail of individual instruments and sound effects varies wildly. It also doesn’t effectively generate the sound of a vocalist pronouncing words.\n\nWhy it matters:AI has demonstrated its prowess at generating convincing text and images. Generated audio has implications for producers not only of music but also of videos, video games, and podcasts. Stable Audio sounds like an early step, but it stands out for its speed, high-resolution output, and the inclusion of a mechanism for learning musical structure.\n\nWe're thinking:Stable Audio is impressive, but this doesn’t quite feel like music’s GPT moment. Text and image generation took off as soon as highly capable generative models appeared. Music generation may yet await models that can produce not only high-res output but also sonorities and structures coherent and varied enough to be widely useful.",
    "qa": [
      {
        "question": "Stable Audio là sản phẩm của công ty nào?",
        "options": {
          "A": "Google AI",
          "B": "Stability.ai",
          "C": "OpenAI",
          "D": "Mubert"
        },
        "answer": "B"
      },
      {
        "question": "Phiên bản miễn phí của Stable Audio cho phép tạo tối đa bao nhiêu lần tạo âm thanh mỗi tháng?",
        "options": {
          "A": "10",
          "B": "20",
          "C": "30",
          "D": "50"
        },
        "answer": "B"
      },
      {
        "question": "Stable Audio hoạt động dựa trên mô hình nào?",
        "options": {
          "A": "Generative Adversarial Network (GAN)",
          "B": "Recurrent Neural Network (RNN)",
          "C": "Latent Diffusion Model",
          "D": "Transformer Network"
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống Stable Audio được huấn luyện trên bao nhiêu file âm thanh?",
        "options": {
          "A": "500,000",
          "B": "600,000",
          "C": "700,000",
          "D": "800,000"
        },
        "answer": "D"
      },
      {
        "question": "Dịch vụ nào sau đây KHÔNG được đề cập đến như một dịch vụ tạo nhạc từ văn bản đã có trước Stable Audio?",
        "options": {
          "A": "Boomy",
          "B": "Mubert",
          "C": "Soundful",
          "D": "Midjourney"
        },
        "answer": "D"
      },
      {
        "question": "Điểm mạnh của Stable Audio được đề cập trong bài viết là gì?",
        "options": {
          "A": "Khả năng tạo ra giọng hát rõ ràng và chi tiết",
          "B": "Khả năng tạo ra các bản nhạc dài với cấu trúc mạch lạc",
          "C": "Tốc độ tạo âm thanh nhanh và độ phân giải cao",
          "D": "Khả năng tạo ra âm thanh của nhiều loại nhạc cụ khác nhau một cách hoàn hảo"
        },
        "answer": "C"
      },
      {
        "question": "Một trong những hạn chế của Stable Audio được đề cập trong bài viết là gì?",
        "options": {
          "A": "Khó khăn trong việc tạo ra hình ảnh từ âm thanh",
          "B": "Khó khăn trong việc tạo ra âm thanh của giọng hát phát âm từ ngữ",
          "C": "Khó khăn trong việc tạo ra văn bản từ âm thanh",
          "D": "Khó khăn trong việc tạo ra video từ âm thanh"
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng tiềm năng của công nghệ tạo âm thanh bằng AI KHÔNG bao gồm lĩnh vực nào sau đây?",
        "options": {
          "A": "Sản xuất video",
          "B": "Sản xuất trò chơi điện tử",
          "C": "Sản xuất podcast",
          "D": "Nghiên cứu y học"
        },
        "answer": "D"
      },
      {
        "question": "Bài viết nhận định gì về khả năng của Stable Audio so với bước đột phá của GPT trong lĩnh vực văn bản?",
        "options": {
          "A": "Stable Audio đã đạt đến trình độ tương đương với GPT",
          "B": "Stable Audio vượt trội hơn GPT trong lĩnh vực âm nhạc",
          "C": "Stable Audio chưa đạt đến trình độ đột phá như GPT",
          "D": "Stable Audio và GPT không thể so sánh vì thuộc hai lĩnh vực khác nhau"
        },
        "answer": "C"
      },
      {
        "question": "Yếu tố nào được cho là cần thiết để công nghệ tạo nhạc bằng AI trở nên hữu ích rộng rãi?",
        "options": {
          "A": "Khả năng tạo ra âm thanh có độ phân giải cao",
          "B": "Khả năng tạo ra âm thanh với cấu trúc mạch lạc và đa dạng",
          "C": "Khả năng tạo ra âm thanh giống hệt âm thanh thật",
          "D": "Khả năng tạo ra âm thanh với chi phí thấp"
        },
        "answer": "B"
      }
    ]
  },
  "viral-video-uses-ai-to-depict-celebrities-without-consent-sparking-legal-debate": {
    "title": "Deepfake Developers Appropriate Celebrity Likenesses",
    "collection": "culture",
    "content": "A viral deepfake video showed media superstars who appeared to support a cause — but it was made without their participation or permission.\n\nWhat’s new:Thevideoshows AI-generated likenesses of 20 Jewish celebrities ranging from Scarlett Johansson to Simon & Garfunkel. They appear wearing T-shirts that feature a middle finger inscribed with the Star of David above the word “KANYE.” The clip, which ends with the words “Enough is enough” followed by “Join the fight against antisemitism,” responds to rapper Kanye West, who sold T-shirts emblazoned with swastikas on Shopify before the ecommerce platform shut down his store.\n\nWho created it:Israeli developers Guy Bar and Ori Bejerano generated the video to spark a conversation about antisemitism, BartoldThe Jerusalem Post. The team didn’t reveal the AI models, editing tools, or techniques used to produce the video.\n\nJohansson reacts:Scarlett Johanssondenouncedthe clip and urged the U.S. to regulate deepfakes. In 2024, sheobjectedto one of the voices of OpenAI’s voice assistant, which she claimed resembled her own voice, leading the company to remove that voice from its service. The prior year, her attorneys ordered a company to stop using an unauthorized AI-generated version of her image in an advertisement.\n\nLikenesses up for grabs:Existing U.S. laws protect some uses of a celebrity’s likeness in the form of a photo, drawing, or human lookalike, but they don’t explicitly protect against reproduction by AI systems. This leaves celebrities and public figures with limited recourse against unauthorized deepfakes.\n\nWhy it matters:Non-consensual deepfake pornography is widely condemned, but AI enables many other non-consensual uses of someone’s likeness, and their limits are not yet consistently coded into law. If the creators of the video that appropriated the images of celebrities had responded to Johansson’s criticism with an AI-generated satire, would that be a legitimate exercise of free speech or another misuse of AI? Previously, an ambiguous legal framework may have been acceptable because such images, and thus lawsuits arising from them, were uncommon. Now, as synthetic likenesses of specific people become easier to generate, clear legal boundaries are needed to keep misuses in check.\n\nWe’re thinking:Creating unauthorized lookalikes of existing people is not a good way to advance any cause, however worthy. Developers should work with businesses policymakers to establish standards that differentiate legitimate uses from unfair or misleading exploitation.",
    "qa": [
      {
        "question": "Video deepfake lan truyền trong bài viết đã sử dụng hình ảnh của những ai?",
        "options": {
          "A": "Các chính trị gia nổi tiếng.",
          "B": "20 người nổi tiếng Do Thái.",
          "C": "Các vận động viên thể thao hàng đầu.",
          "D": "Các nhà khoa học đoạt giải Nobel."
        },
        "answer": "B"
      },
      {
        "question": "Thông điệp chính mà video deepfake này muốn truyền tải là gì?",
        "options": {
          "A": "Ủng hộ Kanye West.",
          "B": "Phản đối Kanye West và chống lại chủ nghĩa bài Do Thái.",
          "C": "Quảng bá sản phẩm thời trang mới.",
          "D": "Kêu gọi hòa bình thế giới."
        },
        "answer": "B"
      },
      {
        "question": "Ai là người đã tạo ra video deepfake gây tranh cãi này?",
        "options": {
          "A": "Kanye West.",
          "B": "Một nhóm các nhà hoạt động xã hội Mỹ.",
          "C": "Các nhà phát triển người Israel, Guy Bar và Ori Bejerano.",
          "D": "Một công ty quảng cáo lớn."
        },
        "answer": "C"
      },
      {
        "question": "Phản ứng của Scarlett Johansson về video deepfake có hình ảnh của cô là gì?",
        "options": {
          "A": "Cô ủng hộ việc sử dụng hình ảnh của mình để nâng cao nhận thức về các vấn đề xã hội.",
          "B": "Cô im lặng và không đưa ra bất kỳ bình luận nào.",
          "C": "Cô lên án video và kêu gọi chính phủ Mỹ điều chỉnh deepfake.",
          "D": "Cô hợp tác với những người tạo ra video để lan truyền thông điệp."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì đã xảy ra trước đó liên quan đến Scarlett Johansson và công nghệ AI?",
        "options": {
          "A": "Cô đã đầu tư vào một công ty phát triển AI.",
          "B": "Cô đã kiện một công ty sử dụng trái phép hình ảnh AI tạo ra của cô trong quảng cáo và phản đối giọng nói AI giống cô.",
          "C": "Cô đã tạo ra một ứng dụng AI của riêng mình.",
          "D": "Cô đã tham gia một hội nghị về đạo đức AI."
        },
        "answer": "B"
      },
      {
        "question": "Luật pháp hiện hành của Hoa Kỳ bảo vệ hình ảnh của người nổi tiếng như thế nào?",
        "options": {
          "A": "Bảo vệ hoàn toàn trước mọi hình thức sử dụng hình ảnh, bao gồm cả AI.",
          "B": "Không có luật nào bảo vệ hình ảnh của người nổi tiếng.",
          "C": "Bảo vệ một số hình thức sử dụng hình ảnh như ảnh, tranh vẽ hoặc người giống thật, nhưng không rõ ràng đối với việc tái tạo bằng AI.",
          "D": "Chỉ bảo vệ hình ảnh của người nổi tiếng nếu họ đồng ý."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao việc tạo ra các bản sao trái phép của người thật lại không được khuyến khích?",
        "options": {
          "A": "Vì nó tốn kém và phức tạp.",
          "B": "Vì nó có thể vi phạm quyền riêng tư và gây hiểu lầm.",
          "C": "Vì nó không hiệu quả trong việc truyền tải thông điệp.",
          "D": "Vì nó không được các nhà phát triển công nghệ ủng hộ."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất giải pháp nào để giải quyết vấn đề lạm dụng deepfake?",
        "options": {
          "A": "Cấm hoàn toàn việc sử dụng công nghệ AI.",
          "B": "Các nhà phát triển nên làm việc với các nhà hoạch định chính sách để thiết lập các tiêu chuẩn phân biệt giữa sử dụng hợp pháp và khai thác không công bằng.",
          "C": "Khuyến khích người nổi tiếng tự bảo vệ hình ảnh của mình.",
          "D": "Để thị trường tự điều chỉnh."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì sẽ xảy ra nếu những người tạo ra video deepfake phản hồi lời chỉ trích của Johansson bằng một hình thức châm biếm AI?",
        "options": {
          "A": "Chắc chắn đó là một hành động bất hợp pháp.",
          "B": "Chắc chắn đó là một hành động được bảo vệ bởi quyền tự do ngôn luận.",
          "C": "Vấn đề này đặt ra câu hỏi về ranh giới giữa quyền tự do ngôn luận và lạm dụng AI, cần được làm rõ về mặt pháp lý.",
          "D": "Không có gì xảy ra vì Johansson không có quyền kiện."
        },
        "answer": "C"
      },
      {
        "question": "Trước đây, tại sao khung pháp lý mơ hồ về deepfake có thể chấp nhận được?",
        "options": {
          "A": "Vì deepfake không gây ra bất kỳ tác hại nào.",
          "B": "Vì các vụ kiện liên quan đến deepfake rất phổ biến.",
          "C": "Vì những hình ảnh như vậy, và do đó các vụ kiện phát sinh từ chúng, không phổ biến.",
          "D": "Vì luật pháp đã quá rõ ràng."
        },
        "answer": "C"
      }
    ]
  },
  "agentic-workflow-generates-novel-scientific-research-papers": {
    "title": "AI Agents for AI Research",
    "collection": "ml-research",
    "content": "While some observers argue that large language models can’t produce truly original output, new work prompted them to generate novel scientific research.\n\nWhat’s new:Researchers proposedAI Scientist, an agentic workflow that directs large language models to generate ideas for AI research, produce code to test them, and document the enquiry. You can see examples of its output and download the code to generate your own papershere. The team included Chris Lu, Cong Lu, Robert Tjarko Lange, and colleagues at Tokyo-based startup Sakana AI, University of Oxford, University of British Columbia, Vector Institute, and the Canadian Institute for Advanced Research.\n\nHow it works:The authors used Claude Sonnet 3.5, GPT-4o, DeepSeek Coder, and LLama 3.1 405B to generate papers in three categories: diffusion image modeling, transformer-based language modeling, and “grokking,” which the authors define as generalization and speed of learning in deep neural networks.\n\nResults:The team used GPT-4o to evaluate the generated papers according to theguidelinesfor papers presented at the Neural Information Processing Systems (NeurIPS) conference. The guidelines include an overall score between 1 (very strongly reject) and 10 (award-quality: flawless and groundbreaking) and a decision to reject or accept the paper.\n\nWhy it matters:Agentic workflows are a rising theme in AI research from simpler design patterns likereflectionto complex workflows fortranslating literature. These workflows make it possible to break down complex problems into more manageable subtasks. By breaking the task of conducting AI research into various stages of generating ideas, testing them, and writing a paper, an LLM that has access to the right tools can generate novel research papers with actual experimental results.\n\nWe’re thinking:Rather than merely synthesizing existing knowledge, this work points a fascinating direction for using AI to generate new knowledge! Right now, an LLM can suggest starting points for human researchers along with experiments that back up its suggestions.",
    "qa": [
      {
        "question": "AI Scientist được đề xuất để làm gì?",
        "options": {
          "A": "Thay thế hoàn toàn các nhà nghiên cứu AI.",
          "B": "Tạo ra các ý tưởng nghiên cứu AI, kiểm tra chúng bằng code và viết tài liệu.",
          "C": "Đánh giá chất lượng các bài báo khoa học do con người viết.",
          "D": "Dịch các tài liệu khoa học từ ngôn ngữ này sang ngôn ngữ khác."
        },
        "answer": "B"
      },
      {
        "question": "Những mô hình ngôn ngữ lớn nào đã được sử dụng trong nghiên cứu này?",
        "options": {
          "A": "GPT-3, BERT, và T5.",
          "B": "Claude Sonnet 3.5, GPT-4o, DeepSeek Coder, và LLama 3.1 405B.",
          "C": "Bard, Gemini, và LaMDA.",
          "D": "ChatGPT, DALL-E 2, và Stable Diffusion."
        },
        "answer": "B"
      },
      {
        "question": "Các bài báo do AI tạo ra được đánh giá dựa trên tiêu chí nào?",
        "options": {
          "A": "Số lượng trích dẫn mà bài báo nhận được.",
          "B": "Hướng dẫn dành cho các bài báo trình bày tại hội nghị NeurIPS.",
          "C": "Độ dài của bài báo và số lượng hình ảnh được sử dụng.",
          "D": "Mức độ dễ hiểu đối với người đọc không chuyên."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, 'grokking' được định nghĩa là gì?",
        "options": {
          "A": "Quá trình tạo ra các hình ảnh từ văn bản.",
          "B": "Khả năng hiểu và sử dụng ngôn ngữ tự nhiên của máy tính.",
          "C": "Sự tổng quát hóa và tốc độ học tập trong mạng nơ-ron sâu.",
          "D": "Kỹ thuật mã hóa thông tin để bảo mật dữ liệu."
        },
        "answer": "C"
      },
      {
        "question": "Điểm số cao nhất mà GPT-4o có thể cho một bài báo theo hướng dẫn của NeurIPS là bao nhiêu?",
        "options": {
          "A": "5",
          "B": "7",
          "C": "9",
          "D": "10"
        },
        "answer": "D"
      },
      {
        "question": "Công việc này có ý nghĩa gì trong việc sử dụng AI?",
        "options": {
          "A": "Chỉ tổng hợp kiến thức hiện có.",
          "B": "Tạo ra kiến thức mới và đề xuất các điểm khởi đầu cho các nhà nghiên cứu.",
          "C": "Thay thế hoàn toàn công việc nghiên cứu của con người.",
          "D": "Tự động hóa quá trình dịch thuật các tài liệu khoa học."
        },
        "answer": "B"
      },
      {
        "question": "Workflow 'agentic' được mô tả trong bài viết là gì?",
        "options": {
          "A": "Một phương pháp để tăng tốc độ xử lý dữ liệu của LLM.",
          "B": "Một cách để chia nhỏ các vấn đề phức tạp thành các nhiệm vụ con dễ quản lý hơn.",
          "C": "Một kỹ thuật để cải thiện khả năng tạo ra văn bản mạch lạc của LLM.",
          "D": "Một giao diện người dùng cho phép người dùng tương tác với LLM một cách trực quan."
        },
        "answer": "B"
      },
      {
        "question": "Các lĩnh vực nghiên cứu nào được sử dụng để thử nghiệm AI Scientist?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên và thị giác máy tính.",
          "B": "Mô hình hóa ảnh khuếch tán, mô hình hóa ngôn ngữ dựa trên transformer và 'grokking'.",
          "C": "Học tăng cường và học không giám sát.",
          "D": "Robot học và điều khiển tự động."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích của việc sử dụng GPT-4o trong nghiên cứu này là gì?",
        "options": {
          "A": "Tạo ra các ý tưởng nghiên cứu mới.",
          "B": "Viết code để kiểm tra các ý tưởng nghiên cứu.",
          "C": "Đánh giá chất lượng của các bài báo được tạo ra.",
          "D": "Dịch các bài báo sang nhiều ngôn ngữ khác nhau."
        },
        "answer": "C"
      },
      {
        "question": "Công ty Sakana AI có trụ sở ở đâu?",
        "options": {
          "A": "Oxford.",
          "B": "Vancouver.",
          "C": "Toronto.",
          "D": "Tokyo."
        },
        "answer": "D"
      }
    ]
  },
  "a-roadmap-explores-how-ai-can-detect-and-mitigate-greenhouse-gases": {
    "title": "AI Against Climate Change",
    "collection": "science",
    "content": "How can AI help to fight climate change? A new report evaluates progress so far and explores options for the future.What’s new:The Innovation for Cool Earth Forum, a conference of climate researchers hosted by Japan, published a roadmap for the use of data science, computer vision, and AI-driven simulation to reduce greenhouse gas emissions. The roadmap evaluates existing approaches and suggests ways to scale them up.How it works:The roadmap identifies 6 “high-potential opportunities”: activities in which AI systems can make a significant difference based on the size of the opportunity, real-world results, and validated research. The authors emphasize the need for data, technical and scientific talent, computing power, funding, and leadership to take advantage of these opportunities.\n\nWhy it matters:AI has demonstrated its value in identifying sources of emissions, optimizing energy consumption, and developing and understanding materials. Scaling and extending this value in areas that generate the most greenhouse gasses — particularly energy generation, manufacturing, food production, and transportation — could make a significant dent in greenhouse gas emissions.We’re thinking:AI also has an important role to play in advancing the science of climate geoengineering, such as stratospheric aerosol injection (SAI), to cool down the planet. More research is needed to determine whether SAI is a good idea, but AI-enabled climate modeling will help answer this question.",
    "qa": [
      {
        "question": "Diễn đàn Innovation for Cool Earth Forum được tổ chức ở quốc gia nào?",
        "options": {
          "A": "Hoa Kỳ",
          "B": "Nhật Bản",
          "C": "Vương Quốc Anh",
          "D": "Đức"
        },
        "answer": "B"
      },
      {
        "question": "Báo cáo của Innovation for Cool Earth Forum tập trung vào việc sử dụng công nghệ nào để giảm phát thải khí nhà kính?",
        "options": {
          "A": "Năng lượng mặt trời và năng lượng gió",
          "B": "Khoa học dữ liệu, thị giác máy tính và mô phỏng dựa trên AI",
          "C": "Công nghệ thu giữ và lưu trữ carbon",
          "D": "Sản xuất hydro xanh"
        },
        "answer": "B"
      },
      {
        "question": "Báo cáo xác định bao nhiêu 'cơ hội tiềm năng cao' mà hệ thống AI có thể tạo ra sự khác biệt đáng kể?",
        "options": {
          "A": "4",
          "B": "5",
          "C": "6",
          "D": "7"
        },
        "answer": "C"
      },
      {
        "question": "Theo báo cáo, yếu tố nào sau đây KHÔNG được nhấn mạnh là cần thiết để tận dụng các cơ hội tiềm năng cao?",
        "options": {
          "A": "Dữ liệu",
          "B": "Tài năng kỹ thuật và khoa học",
          "C": "Phần mềm chuyên dụng",
          "D": "Nguồn vốn"
        },
        "answer": "C"
      },
      {
        "question": "Lĩnh vực nào sau đây được đề cập trong bài viết là một trong những lĩnh vực tạo ra nhiều khí nhà kính nhất?",
        "options": {
          "A": "Khai thác mỏ",
          "B": "Sản xuất năng lượng",
          "C": "Du lịch hàng không",
          "D": "Ngành công nghiệp thời trang"
        },
        "answer": "B"
      },
      {
        "question": "AI đã chứng minh giá trị của nó trong việc nào sau đây?",
        "options": {
          "A": "Phát triển các loại vắc-xin mới",
          "B": "Xác định nguồn phát thải",
          "C": "Dự báo thị trường chứng khoán",
          "D": "Tự động hóa hoàn toàn quy trình sản xuất"
        },
        "answer": "B"
      },
      {
        "question": "SAI (stratospheric aerosol injection) là một ví dụ về công nghệ nào?",
        "options": {
          "A": "Thu giữ carbon trực tiếp từ không khí",
          "B": "Năng lượng tái tạo tiên tiến",
          "C": "Địa kỹ thuật khí hậu",
          "D": "Lưu trữ năng lượng quy mô lớn"
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của SAI (stratospheric aerosol injection) là gì?",
        "options": {
          "A": "Giảm lượng khí nhà kính trong khí quyển",
          "B": "Làm mát hành tinh",
          "C": "Tăng cường hấp thụ carbon của đại dương",
          "D": "Phục hồi tầng ozone"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì cần thiết để xác định xem SAI có phải là một ý tưởng tốt hay không?",
        "options": {
          "A": "Đầu tư lớn vào công nghệ",
          "B": "Nghiên cứu sâu hơn",
          "C": "Sự đồng thuận quốc tế",
          "D": "Thử nghiệm quy mô lớn"
        },
        "answer": "B"
      },
      {
        "question": "Loại mô hình nào sẽ giúp trả lời câu hỏi liệu SAI có phải là một ý tưởng tốt hay không?",
        "options": {
          "A": "Mô hình kinh tế",
          "B": "Mô hình khí hậu hỗ trợ bởi AI",
          "C": "Mô hình dịch tễ học",
          "D": "Mô hình tài chính"
        },
        "answer": "B"
      }
    ]
  },
  "a-neural-network-shows-remarkable-accuracy-in-forecasting-risk-of-pancreatic-cancer": {
    "title": "Early Detection for Pancreatic Cancer",
    "collection": "science",
    "content": "A neural network detected early signs of pancreatic cancer more effectively than doctors who used the usual risk-assessment criteria.\n\nWhat’s new:Researchers at MIT and oncologists at Beth Israel Medical Center in Bostonbuilta model that analyzed existing medical records to predict the risk that an individual will develop the most common form of pancreatic cancer. The model outperformed commonly used genetic tests.How it works:The authors trained PrismNN, a vanilla neural network, to predict a patient’s risk of receiving a diagnosis of pancreatic ductal adenocarcinoma (PDAC) in the next 6 to 18 months.\n\nResults:PrismNN identified as high-risk 35.9 percent of patients who went on to develop PDAC, with a false-positive rate of 4.7 percent. In comparison, the genetic criteria typically used to identify patients for pancreatic cancer screening flags 10 percent of patients who go on to develop PDAC. The model performed similarly across age, race, gender, and location, although some groups (particularly Asian and Native American patients) were underrepresented in its training data.\n\nBehind the news:AI shows promise in detecting various forms of cancer. In a randomized, controlled trial last year, a neural networkrecognizedbreast tumors in mammograms at a rate comparable to human radiologists. In 2022, an algorithm successfullyidentifiedtumors in lymph node biopsies.\n\nWhy it matters:Cancer of the pancreas is one of the deadliest. Only 11 percent of patientssurvivefor 5 years after diagnosis. Most cases aren’t diagnosed until the disease has reached an advanced stage. Models that can spot early cases could boost the survival rate significantly.\n\nWe’re thinking:The fact that this study required no additional testing is remarkable and means the authors’ method could be deployed cheaply. However, the results were based on patients who had already been diagnosed with cancer. It remains for other teams to replicate them with patients who have not received a diagnosis, perhaps followed by a randomized, controlled clinical trial.",
    "qa": [
      {
        "question": "Mục tiêu chính của mô hình PrismNN là gì?",
        "options": {
          "A": "Phân tích dữ liệu di truyền để xác định nguy cơ ung thư nói chung.",
          "B": "Dự đoán nguy cơ một cá nhân mắc ung thư biểu mô tuyến tụy (PDAC).",
          "C": "So sánh hiệu quả của các phương pháp điều trị ung thư tụy khác nhau.",
          "D": "Xác định các yếu tố di truyền cụ thể liên quan đến ung thư tụy."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình PrismNN hoạt động dựa trên loại mạng nơ-ron nào?",
        "options": {
          "A": "Mạng nơ-ron tích chập (Convolutional Neural Network).",
          "B": "Mạng nơ-ron hồi quy (Recurrent Neural Network).",
          "C": "Mạng nơ-ron thông thường (Vanilla Neural Network).",
          "D": "Mạng nơ-ron đối nghịch sinh (Generative Adversarial Network)."
        },
        "answer": "C"
      },
      {
        "question": "So với các tiêu chí di truyền thông thường, PrismNN xác định được bao nhiêu phần trăm bệnh nhân có nguy cơ cao phát triển PDAC?",
        "options": {
          "A": "10%",
          "B": "35.9%",
          "C": "4.7%",
          "D": "50%"
        },
        "answer": "B"
      },
      {
        "question": "Tỷ lệ dương tính giả (false-positive rate) của PrismNN là bao nhiêu?",
        "options": {
          "A": "10%",
          "B": "35.9%",
          "C": "4.7%",
          "D": "11%"
        },
        "answer": "C"
      },
      {
        "question": "Nhóm bệnh nhân nào ít được đại diện trong dữ liệu huấn luyện của PrismNN?",
        "options": {
          "A": "Bệnh nhân da trắng.",
          "B": "Bệnh nhân nam.",
          "C": "Bệnh nhân lớn tuổi.",
          "D": "Bệnh nhân gốc Á và người Mỹ bản địa."
        },
        "answer": "D"
      },
      {
        "question": "Bài viết đề cập đến một nghiên cứu nào khác về ứng dụng AI trong phát hiện ung thư?",
        "options": {
          "A": "Phát hiện ung thư phổi từ ảnh chụp X-quang.",
          "B": "Phát hiện ung thư vú từ ảnh chụp nhũ ảnh.",
          "C": "Phát hiện ung thư da từ hình ảnh lâm sàng.",
          "D": "Phát hiện ung thư máu từ xét nghiệm máu."
        },
        "answer": "B"
      },
      {
        "question": "Tỷ lệ sống sót sau 5 năm của bệnh nhân ung thư tụy sau khi chẩn đoán là bao nhiêu?",
        "options": {
          "A": "5%",
          "B": "11%",
          "C": "35.9%",
          "D": "50%"
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc phát hiện sớm ung thư tụy lại quan trọng?",
        "options": {
          "A": "Giảm chi phí điều trị.",
          "B": "Tăng tỷ lệ sống sót đáng kể.",
          "C": "Giảm tác dụng phụ của hóa trị.",
          "D": "Giúp bệnh nhân dễ dàng chấp nhận bệnh hơn."
        },
        "answer": "B"
      },
      {
        "question": "Một ưu điểm nổi bật của phương pháp phát hiện ung thư tụy bằng PrismNN là gì?",
        "options": {
          "A": "Độ chính xác tuyệt đối.",
          "B": "Không yêu cầu xét nghiệm bổ sung, có thể triển khai với chi phí thấp.",
          "C": "Có thể phát hiện tất cả các loại ung thư tụy.",
          "D": "Thời gian xử lý nhanh chóng."
        },
        "answer": "B"
      },
      {
        "question": "Bước tiếp theo được đề xuất để xác nhận hiệu quả của PrismNN là gì?",
        "options": {
          "A": "Thử nghiệm trên động vật.",
          "B": "Sao chép kết quả với bệnh nhân chưa được chẩn đoán, có thể kèm theo thử nghiệm lâm sàng ngẫu nhiên có đối chứng.",
          "C": "Phát triển một ứng dụng di động dựa trên PrismNN.",
          "D": "Kết hợp PrismNN với các phương pháp chẩn đoán ung thư khác."
        },
        "answer": "B"
      }
    ]
  },
  "ai-and-data-center-boom-challenges-big-techs-emissions-targets": {
    "title": "AI’s Path to Zero Emissions Is Cloudy",
    "collection": "science",
    "content": "The boom in AI is jeopardizing big tech’s efforts to reach its targets for emissions of greenhouse gasses.\n\nWhat’s new:Google’sannual environmental reportshows that the company’s total carbon dioxide emissions rose nearly 50 percent between 2019 and 2023 to 14.3 million tons. Google attributes the rise to its efforts to satisfy rising demand for AI.\n\nHow it works:Google’s carbon emissions increased 16.7 percent from 2021 to 2022 and another 13.5 percent from 2022 to 2023 for a total 48 percent rise over those periods. “As we further integrate AI into our products, reducing emissions may be challenging due to increasing energy demands from the greater intensity of AI compute, and the emissions associated with the expected increases in our technical infrastructure investment,” the report states.\n\nCountering the trend:Google is working to reduce its greenhouse gas emissions on several fronts. Its effort to purchase electricity from low-emissions sources cut its net carbon footprint by around 30 percent in 2023. It claims that its owned-and-operated data centers are 1.8 times more energy-efficient than a typical enterprise data center, and its sixth-generation tensor processing units (TPUs) are 67 percent more efficient than the prior generation. Google has asked its largest hardware partners to match 100 percent of their energy consumption with renewable energy 2029. The company is pursuing several AI-based initiatives to mitigate climate change from weather prediction to fuel-efficient vehicle routing. It says that AI has the potential to mitigate 5 to 10 percent of global greenhouse gas emissions by 2030.\n\nBehind the news:In 2020, after five years of successfullyreducingits carbon footprint, Google set an ambitious target to reach net-zero greenhouse gas emissions by 2030. But its total emissions since then have risen each year. Google’s experience mirrors that of Amazon and Microsoft, which aim to reach net-zero carbon emissions by 2030 and 2040 respectively. Amazon’s emissionsincreased39 percent from 2019 to 2022, while Microsoft’s emissionsrose29 percent between 2020 and 2023. (Amazon’s and Microsoft’s cloud computing revenues were roughly triple Google’s in 2023 and thus their AI-related greenhouse case emissions  presumably were larger.)\n\nWhy it matters:Growing use of AI means greater consumption of energy. The tech giants’ ambitious emissions goals predate the rapid growth of generative AI, and their latest reports show that it’s time to rethink them. This adds urgency to already critical efforts to develop renewable and other low-emissions energy sources.\n\nWe’re thinking:We applaud Google’s efforts to cut its carbon emissions and its transparency in issuing annual environmental reports. We’re somewhat relieved to note that, for now, data centers and cloud computing are responsible for1 percentof the world’s energy-related greenhouse gas emissions; a drop in the bucket compared to transportation, construction, or agriculture. Moreover, we believe that AI stands to create huge benefits relative to the climate impact of its emissions, and AI is one of the most powerful tools we have to develop low-carbon energy sources and boost energy efficiency throughout society. Continuing to improve the technology will help us develop lower-carbon energy sources and efficient ways to harness them.",
    "qa": [
      {
        "question": "Theo báo cáo của Google, nguyên nhân chính dẫn đến sự gia tăng đáng kể lượng khí thải carbon dioxide của công ty từ năm 2019 đến 2023 là gì?",
        "options": {
          "A": "Sự mở rộng quy mô hoạt động của các trung tâm dữ liệu.",
          "B": "Nỗ lực đáp ứng nhu cầu ngày càng tăng đối với trí tuệ nhân tạo (AI).",
          "C": "Sự gia tăng số lượng nhân viên và văn phòng trên toàn cầu.",
          "D": "Việc sử dụng năng lượng không hiệu quả trong các hoạt động hàng ngày."
        },
        "answer": "B"
      },
      {
        "question": "Google đang thực hiện những biện pháp nào để giảm lượng khí thải nhà kính?",
        "options": {
          "A": "Tăng cường sử dụng năng lượng hóa thạch để đảm bảo nguồn cung ổn định.",
          "B": "Mua điện từ các nguồn phát thải thấp và cải thiện hiệu quả năng lượng của các trung tâm dữ liệu.",
          "C": "Giảm đầu tư vào nghiên cứu và phát triển các công nghệ mới.",
          "D": "Chuyển toàn bộ hoạt động sang các quốc gia có tiêu chuẩn môi trường thấp hơn."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu mà Google đã đặt ra vào năm 2020 liên quan đến lượng khí thải nhà kính là gì?",
        "options": {
          "A": "Giảm 50% lượng khí thải nhà kính so với năm 2010 vào năm 2030.",
          "B": "Đạt mức phát thải ròng bằng không (net-zero) vào năm 2030.",
          "C": "Ổn định lượng khí thải nhà kính ở mức năm 2020 cho đến năm 2030.",
          "D": "Trở thành công ty có lượng khí thải nhà kính thấp nhất trong ngành công nghệ vào năm 2030."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, các công ty công nghệ lớn khác như Amazon và Microsoft đang đối mặt với thách thức nào tương tự như Google?",
        "options": {
          "A": "Khó khăn trong việc duy trì lợi nhuận trong bối cảnh cạnh tranh gay gắt.",
          "B": "Sự gia tăng lượng khí thải do nhu cầu năng lượng tăng cao từ AI, gây khó khăn cho việc đạt mục tiêu phát thải.",
          "C": "Áp lực từ các nhà đầu tư về việc tăng cường trách nhiệm xã hội.",
          "D": "Sự thiếu hụt nhân tài có kỹ năng trong lĩnh vực AI."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến tiềm năng của AI trong việc giảm thiểu biến đổi khí hậu như thế nào?",
        "options": {
          "A": "AI không có vai trò đáng kể trong việc giảm thiểu biến đổi khí hậu.",
          "B": "AI có thể giúp giảm từ 5 đến 10% lượng khí thải nhà kính toàn cầu vào năm 2030.",
          "C": "AI chỉ có thể giúp các công ty công nghệ giảm lượng khí thải của riêng họ.",
          "D": "AI sẽ thay thế hoàn toàn các nguồn năng lượng hóa thạch trong tương lai gần."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, các trung tâm dữ liệu và điện toán đám mây hiện chịu trách nhiệm cho bao nhiêu phần trăm lượng khí thải nhà kính liên quan đến năng lượng trên toàn thế giới?",
        "options": {
          "A": "Khoảng 5%.",
          "B": "Khoảng 1%.",
          "C": "Khoảng 10%.",
          "D": "Khoảng 20%."
        },
        "answer": "B"
      },
      {
        "question": "Google yêu cầu các đối tác phần cứng lớn nhất của mình thực hiện điều gì liên quan đến năng lượng tái tạo?",
        "options": {
          "A": "Giảm 50% lượng khí thải carbon vào năm 2025.",
          "B": "Sử dụng 100% năng lượng tái tạo cho tất cả các hoạt động vào năm 2029.",
          "C": "Đầu tư vào các dự án năng lượng tái tạo do Google tài trợ.",
          "D": "Cung cấp dữ liệu về mức tiêu thụ năng lượng hàng năm cho Google."
        },
        "answer": "B"
      },
      {
        "question": "Thế hệ bộ xử lý tensor (TPU) thứ sáu của Google hiệu quả hơn bao nhiêu so với thế hệ trước đó?",
        "options": {
          "A": "Hiệu quả hơn 25%.",
          "B": "Hiệu quả hơn 50%.",
          "C": "Hiệu quả hơn 67%.",
          "D": "Hiệu quả hơn 80%."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết cho rằng điều gì là cần thiết để giảm thiểu tác động tiêu cực của AI đến môi trường?",
        "options": {
          "A": "Hạn chế sự phát triển của AI để giảm tiêu thụ năng lượng.",
          "B": "Phát triển các nguồn năng lượng carbon thấp và các phương pháp hiệu quả để khai thác chúng.",
          "C": "Chuyển các trung tâm dữ liệu sang các khu vực có khí hậu lạnh hơn để giảm nhu cầu làm mát.",
          "D": "Tăng cường sử dụng năng lượng hạt nhân để đáp ứng nhu cầu năng lượng ngày càng tăng."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lĩnh vực nào không được đề cập đến như một lĩnh vực có lượng khí thải nhà kính liên quan đến năng lượng lớn hơn so với trung tâm dữ liệu và điện toán đám mây?",
        "options": {
          "A": "Giao thông vận tải.",
          "B": "Xây dựng.",
          "C": "Nông nghiệp.",
          "D": "Sản xuất phần mềm."
        },
        "answer": "D"
      }
    ]
  },
  "ai-co-scientist-an-agent-that-generates-research-hypotheses-aiding-drug-discovery": {
    "title": "Science Research Proposals Made to Order",
    "collection": "ml-research",
    "content": "An AI agent synthesizes novel scientific research hypotheses. It's already making an impact in biomedicine.\n\nWhat’s new:Google introducedAI co-scientist, a general multi-agent system designed to generate in-depth research proposals within constraints specified by the user. The team generated and evaluated proposals for repurposing drugs, identifying drug targets, and explaining antimicrobial resistance in real-world laboratories. It’s available to research organizations on a limited basis.\n\nHow it works:AI co-scientist accepts a text description of a research goal, including relevant constraints or ideas. In response, it generates research proposals and reviews, ranks, and improves them using seven agents based on Google’s Gemini 2.0 family of large language models. The completed proposals include sections that explain background, unmet needs, a proposed solution, goals, hypotheses, reasoning, study steps, and relevant articles. The agents take feedback and outputs from other agents to perform their prompted task simultaneously.\n\nResults:AI co-scientist achieved a number of impressive biomedical results in tests.\n\nBehind the news:A few AI systems have begun to produce original scientific work. For instance, a modelgenerated research proposalsthat human judges deemed more novel than proposals written by flesh-and-blood scientists, and an agentic workflowproduced research papersthat met standards for acceptance by top conferences.\n\nWhy it matters:While previous work used agentic workflows to propose research ideas on a general topic, this work generates proposals for specific ideas according to a researcher’s constraints (for example, a researcher could specify that a novel medical treatment for a specific disease only consider drugs already approved for human trials for other uses) and further instructions. AI co-scientist can take feedback at any point, allowing humans to collaborate with the machine: People provide ideas, feedback, and guidance for the model, and the model researches and proposes ideas in return.\n\nWe’re thinking:I asked my AI system to propose a new chemical experiment. But there was no reaction!",
    "qa": [
      {
        "question": "AI co-scientist được Google giới thiệu là một hệ thống như thế nào?",
        "options": {
          "A": "Một hệ thống quản lý dữ liệu khoa học.",
          "B": "Một hệ thống đa tác nhân tổng quát được thiết kế để tạo ra các đề xuất nghiên cứu chuyên sâu.",
          "C": "Một hệ thống phân tích kết quả thí nghiệm sinh học.",
          "D": "Một hệ thống dự đoán xu hướng phát triển của khoa học."
        },
        "answer": "B"
      },
      {
        "question": "AI co-scientist sử dụng mô hình ngôn ngữ lớn nào của Google?",
        "options": {
          "A": "LaMDA",
          "B": "BERT",
          "C": "Gemini 2.0",
          "D": "Transformer"
        },
        "answer": "C"
      },
      {
        "question": "AI co-scientist tạo ra các đề xuất nghiên cứu bao gồm những phần nào?",
        "options": {
          "A": "Tóm tắt, phương pháp, kết quả, thảo luận.",
          "B": "Bối cảnh, nhu cầu chưa được đáp ứng, giải pháp đề xuất, mục tiêu, giả thuyết, lý luận, các bước nghiên cứu, và các bài viết liên quan.",
          "C": "Giới thiệu, vật liệu và phương pháp, kết quả, kết luận.",
          "D": "Mục tiêu, giả thuyết, thiết kế thí nghiệm, phân tích thống kê."
        },
        "answer": "B"
      },
      {
        "question": "Trong quá trình hoạt động, các tác nhân của AI co-scientist tương tác với nhau như thế nào?",
        "options": {
          "A": "Hoạt động độc lập và không chia sẻ thông tin.",
          "B": "Các tác nhân lấy phản hồi và đầu ra từ các tác nhân khác để thực hiện nhiệm vụ được giao đồng thời.",
          "C": "Chỉ có một tác nhân chính điều khiển các tác nhân còn lại.",
          "D": "Các tác nhân hoạt động tuần tự, tác nhân sau chỉ hoạt động khi tác nhân trước hoàn thành."
        },
        "answer": "B"
      },
      {
        "question": "Một ví dụ về ứng dụng của AI co-scientist trong lĩnh vực y sinh là gì?",
        "options": {
          "A": "Phát triển các thuật toán chẩn đoán hình ảnh.",
          "B": "Tái sử dụng thuốc, xác định mục tiêu thuốc và giải thích sự kháng kháng sinh.",
          "C": "Thiết kế các thiết bị y tế thông minh.",
          "D": "Nghiên cứu về bộ gen người."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính của AI co-scientist so với các hệ thống AI tạo đề xuất nghiên cứu trước đây là gì?",
        "options": {
          "A": "Khả năng tạo ra các đề xuất nghiên cứu nhanh hơn.",
          "B": "Khả năng tạo ra các đề xuất nghiên cứu trên các chủ đề chung.",
          "C": "Khả năng tạo ra các đề xuất nghiên cứu cho các ý tưởng cụ thể theo các ràng buộc của nhà nghiên cứu.",
          "D": "Khả năng tạo ra các đề xuất nghiên cứu với chi phí thấp hơn."
        },
        "answer": "C"
      },
      {
        "question": "AI co-scientist cho phép con người tương tác và cộng tác như thế nào?",
        "options": {
          "A": "Con người chỉ có thể sử dụng kết quả cuối cùng do AI tạo ra.",
          "B": "Con người có thể cung cấp ý tưởng, phản hồi và hướng dẫn cho mô hình, và mô hình nghiên cứu và đề xuất ý tưởng đáp lại.",
          "C": "Con người chỉ có thể điều chỉnh các tham số của mô hình trước khi nó bắt đầu tạo đề xuất.",
          "D": "Con người chỉ có thể đánh giá chất lượng của các đề xuất do AI tạo ra."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, một hệ thống AI khác đã tạo ra những đề xuất nghiên cứu được đánh giá như thế nào so với đề xuất của các nhà khoa học?",
        "options": {
          "A": "Kém sáng tạo hơn.",
          "B": "Tương đương về độ sáng tạo.",
          "C": "Sáng tạo hơn.",
          "D": "Dễ hiểu hơn."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến việc một quy trình làm việc dựa trên tác nhân đã tạo ra những bài báo nghiên cứu như thế nào?",
        "options": {
          "A": "Không đáp ứng được tiêu chuẩn chấp nhận của các hội nghị hàng đầu.",
          "B": "Đáp ứng được tiêu chuẩn chấp nhận của các hội nghị hàng đầu.",
          "C": "Chỉ được chấp nhận bởi các tạp chí khoa học ít uy tín.",
          "D": "Cần phải chỉnh sửa nhiều trước khi được chấp nhận."
        },
        "answer": "B"
      },
      {
        "question": "Câu chuyện cuối bài viết về việc yêu cầu hệ thống AI đề xuất một thí nghiệm hóa học và không có phản ứng xảy ra nhằm mục đích gì?",
        "options": {
          "A": "Để chứng minh rằng AI vẫn còn nhiều hạn chế.",
          "B": "Để minh họa khả năng của AI trong việc dự đoán kết quả thí nghiệm.",
          "C": "Để thể hiện sự hài hước và tính tương tác của AI.",
          "D": "Để nhấn mạnh tầm quan trọng của việc kiểm tra kết quả do AI tạo ra."
        },
        "answer": "A"
      }
    ]
  },
  "ai-depression": {
    "title": "Which Drug Helps Your Depression?",
    "collection": "science",
    "content": "People seeking treatment for depression often experiment with different medications for months before finding one that works. Machine learning may remove some of the guesswork.What’s new:Deep learning can predict how patients will respond to two antidepressant medicines, according to astudyled by Albert Montillo and Madhukar Trivedi at University of Texas Southwestern Medical Center.Key Insight:Patients with depression show various patterns of depressed brain activity in brain scans. At the same time, they vary in their reported responses to different drugs. Given brain scans of depressed people and their reports of effective treatment, a neural network can learn to match patients with medications likely to relieve their symptoms.How it works:The authors trained separate vanilla neural networks to predict the change in patients’ depression levels after treatment with each of two drugs as well as placebo.\n\nResults:The authors evaluated their models on held-out data according toR2value, a measure of performance in which 100 percent is perfect. The sertraline model achieved an R2value of 48 percent. The bupropion model achieved 34 percent. Techniques that use brain scans to predict a patient’s response to drugs without deep learning have achieved R2values around 15 percent, Montillo toldThe Batch.Why it matters:Millions of adults suffer from major depression, andone-third of thosetry at least three drugs before settling on one. Moreover, many doctors are influenced by outcomes they observe in a handful of patients and aren’t able to systematically analyze data from a large cohort. Reliable predictions about which medicines are likely to work best — even if they’re far from perfectly accurate — could make a difference.We’re thinking:Bringing this work into clinical practice would require training models to classify responses to many other antidepressants. The authors plan to apply their method to drugs beyond the two in this study, and we look forward to their progress.",
    "qa": [
      {
        "question": "Vấn đề chính mà bài viết đề cập đến là gì?",
        "options": {
          "A": "Sự phát triển của các loại thuốc chống trầm cảm mới.",
          "B": "Ứng dụng của machine learning trong việc dự đoán hiệu quả của thuốc chống trầm cảm.",
          "C": "Những khó khăn trong việc điều trị trầm cảm bằng liệu pháp tâm lý.",
          "D": "So sánh hiệu quả giữa các phương pháp điều trị trầm cảm khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Theo nghiên cứu của Albert Montillo và Madhukar Trivedi, phương pháp deep learning có thể làm gì?",
        "options": {
          "A": "Chữa khỏi hoàn toàn bệnh trầm cảm.",
          "B": "Dự đoán phản ứng của bệnh nhân với hai loại thuốc chống trầm cảm.",
          "C": "Thay thế hoàn toàn việc sử dụng thuốc chống trầm cảm.",
          "D": "Giảm thiểu tác dụng phụ của thuốc chống trầm cảm."
        },
        "answer": "B"
      },
      {
        "question": "Cơ sở để mạng neural có thể dự đoán hiệu quả của thuốc là gì?",
        "options": {
          "A": "Phân tích gen của bệnh nhân.",
          "B": "So sánh các triệu chứng lâm sàng của bệnh nhân.",
          "C": "Đối chiếu giữa kết quả quét não và báo cáo về hiệu quả điều trị của bệnh nhân.",
          "D": "Đo lường mức độ stress của bệnh nhân."
        },
        "answer": "C"
      },
      {
        "question": "Trong nghiên cứu, mô hình nào đạt được giá trị R2 cao hơn?",
        "options": {
          "A": "Mô hình dự đoán hiệu quả của placebo.",
          "B": "Mô hình dự đoán hiệu quả của sertraline.",
          "C": "Mô hình dự đoán hiệu quả của bupropion.",
          "D": "Cả hai mô hình sertraline và bupropion đều đạt giá trị R2 tương đương."
        },
        "answer": "B"
      },
      {
        "question": "Giá trị R2 được sử dụng để làm gì trong nghiên cứu này?",
        "options": {
          "A": "Đo lường mức độ trầm cảm của bệnh nhân.",
          "B": "Đánh giá hiệu suất của mô hình dự đoán.",
          "C": "Xác định loại thuốc chống trầm cảm phù hợp nhất.",
          "D": "So sánh hiệu quả của deep learning với các phương pháp khác."
        },
        "answer": "B"
      },
      {
        "question": "Theo Montillo, giá trị R2 trung bình đạt được khi sử dụng các kỹ thuật không phải deep learning để dự đoán phản ứng của bệnh nhân với thuốc là bao nhiêu?",
        "options": {
          "A": "5%",
          "B": "15%",
          "C": "34%",
          "D": "48%"
        },
        "answer": "B"
      },
      {
        "question": "Một trong những lý do khiến việc dự đoán hiệu quả của thuốc chống trầm cảm trở nên quan trọng là gì?",
        "options": {
          "A": "Thuốc chống trầm cảm rất đắt tiền.",
          "B": "Nhiều bệnh nhân phải thử nhiều loại thuốc trước khi tìm được loại phù hợp.",
          "C": "Thuốc chống trầm cảm có nhiều tác dụng phụ nghiêm trọng.",
          "D": "Việc điều trị trầm cảm thường kéo dài rất lâu."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì có thể ảnh hưởng đến quyết định kê đơn thuốc của bác sĩ, theo bài viết?",
        "options": {
          "A": "Kết quả nghiên cứu khoa học quy mô lớn.",
          "B": "Kinh nghiệm cá nhân với một vài bệnh nhân.",
          "C": "Hướng dẫn điều trị chuẩn từ các tổ chức y tế.",
          "D": "Mong muốn của bệnh nhân về loại thuốc cụ thể."
        },
        "answer": "B"
      },
      {
        "question": "Bước tiếp theo mà các tác giả dự định thực hiện là gì?",
        "options": {
          "A": "Phát triển một loại thuốc chống trầm cảm mới.",
          "B": "Áp dụng phương pháp của họ cho nhiều loại thuốc chống trầm cảm khác.",
          "C": "Thử nghiệm phương pháp của họ trên động vật.",
          "D": "Xuất bản kết quả nghiên cứu trên các tạp chí khoa học hàng đầu."
        },
        "answer": "B"
      },
      {
        "question": "Một hạn chế tiềm năng của việc đưa phương pháp này vào thực tế lâm sàng là gì?",
        "options": {
          "A": "Chi phí quét não quá cao.",
          "B": "Cần phải huấn luyện mô hình cho nhiều loại thuốc chống trầm cảm khác.",
          "C": "Phương pháp này chỉ hiệu quả với một số ít bệnh nhân.",
          "D": "Việc thu thập dữ liệu quét não là rất khó khăn."
        },
        "answer": "B"
      }
    ]
  },
  "ai-designs-chemical-weapons": {
    "title": "AI Designs Chemical Weapons",
    "collection": "science",
    "content": "It’s surprisingly easy to turn a well-intended machine learning model to the dark side.What’s new:In an experiment, Fabio Urbina and colleagues at Collaborations Pharmaceuticals, who had built a drug-discovery model to design useful compounds and avoid toxic ones, retrained it togenerate poisons. In six hours, the model generated 40,000 toxins, some of them actual chemical warfare agents that weren’t in the initial dataset.How it works:The authors didn’t detail the architecture, dataset, and method to avoid encouraging bad actors. The following description is drawn from the few particulars they did reveal along with accounts of the company’s existing generative model,MegaSyn.\n\nWhy it matters:The authors took an industrial model and turned it into what they call “a computational proof of concept for making biochemical weapons.” They emphasize that it wouldn’t be difficult to copy using publicly available datasets and models. It may be similarly easy to subvert models built for tasks other than drug discovery, turning helpful models into harmful ones.We’re thinking:Despite machine learning’s enormous potential to do good, it can be harnessed for evil. Designing effective safeguards for machine learning research and implementation is a very difficult problem. What is clear is that we in the AI community need to recognize the destructive potential of our work and move with haste and deliberation toward a framework that can minimize it. NeurIPS’effortsto promote introspection on the part of AI researchers are a notable start — despiteargumentsthat they politicize basic research — and much work remains to be done.",
    "qa": [
      {
        "question": "Mục đích ban đầu của mô hình học máy được Fabio Urbina và đồng nghiệp xây dựng là gì?",
        "options": {
          "A": "Tạo ra các loại vũ khí hóa học mới.",
          "B": "Thiết kế các hợp chất hữu ích và tránh các hợp chất độc hại.",
          "C": "Nghiên cứu tác động của chất độc lên cơ thể người.",
          "D": "Phát triển các phương pháp điều trị ngộ độc."
        },
        "answer": "B"
      },
      {
        "question": "Trong thí nghiệm, mô hình học máy đã tạo ra bao nhiêu chất độc sau khi được huấn luyện lại?",
        "options": {
          "A": "400 chất độc.",
          "B": "4,000 chất độc.",
          "C": "40,000 chất độc.",
          "D": "400,000 chất độc."
        },
        "answer": "C"
      },
      {
        "question": "Thời gian cần thiết để mô hình tạo ra các chất độc là bao lâu?",
        "options": {
          "A": "Một ngày.",
          "B": "Một tuần.",
          "C": "Sáu giờ.",
          "D": "Một tháng."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về việc sao chép thí nghiệm này?",
        "options": {
          "A": "Rất khó để sao chép do yêu cầu kỹ thuật cao.",
          "B": "Cần có dữ liệu và mô hình độc quyền để thực hiện.",
          "C": "Có thể dễ dàng sao chép bằng cách sử dụng dữ liệu và mô hình công khai.",
          "D": "Chỉ có các chuyên gia hàng đầu mới có thể thực hiện được."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến nguy cơ tiềm ẩn nào của mô hình học máy?",
        "options": {
          "A": "Chỉ có thể gây hại trong lĩnh vực y học.",
          "B": "Có thể bị lợi dụng để biến các mô hình hữu ích thành các mô hình gây hại.",
          "C": "Chỉ gây hại nếu được sử dụng bởi các chính phủ độc tài.",
          "D": "Không có nguy cơ tiềm ẩn nào nếu được giám sát chặt chẽ."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết kêu gọi cộng đồng AI cần làm gì để giảm thiểu nguy cơ tiềm ẩn của học máy?",
        "options": {
          "A": "Ngừng phát triển các mô hình học máy phức tạp.",
          "B": "Tập trung vào việc phát triển các mô hình học máy an toàn hơn.",
          "C": "Nhận thức về khả năng gây hại của công việc và nhanh chóng xây dựng một khuôn khổ giảm thiểu nó.",
          "D": "Hạn chế công bố các nghiên cứu về học máy."
        },
        "answer": "C"
      },
      {
        "question": "NeurIPS đang nỗ lực làm gì liên quan đến vấn đề này?",
        "options": {
          "A": "Tài trợ cho các nghiên cứu về vũ khí hóa học.",
          "B": "Cấm các nghiên cứu về học máy có khả năng gây hại.",
          "C": "Thúc đẩy sự tự vấn trong giới nghiên cứu AI.",
          "D": "Phát triển các công cụ để phát hiện các mô hình học máy độc hại."
        },
        "answer": "C"
      },
      {
        "question": "Tác giả của thí nghiệm đã làm gì để tránh khuyến khích những kẻ xấu?",
        "options": {
          "A": "Công bố chi tiết kiến trúc, tập dữ liệu và phương pháp sử dụng.",
          "B": "Giữ bí mật thông tin chi tiết về kiến trúc, tập dữ liệu và phương pháp.",
          "C": "Chỉ chia sẻ thông tin với các nhà nghiên cứu được ủy quyền.",
          "D": "Phát triển một hệ thống giám sát để ngăn chặn việc sử dụng sai mục đích."
        },
        "answer": "B"
      },
      {
        "question": "MegaSyn là gì trong bối cảnh bài viết?",
        "options": {
          "A": "Một loại chất độc mạnh.",
          "B": "Một mô hình tạo sinh hiện có của Collaborations Pharmaceuticals.",
          "C": "Một phương pháp huấn luyện mô hình học máy.",
          "D": "Một tổ chức chuyên nghiên cứu về vũ khí hóa học."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết gọi thí nghiệm này là gì?",
        "options": {
          "A": "Một thất bại trong nghiên cứu học máy.",
          "B": "Một bằng chứng tính toán về khả năng tạo ra vũ khí sinh hóa.",
          "C": "Một phương pháp mới để phát triển thuốc.",
          "D": "Một cảnh báo về sự nguy hiểm của trí tuệ nhân tạo."
        },
        "answer": "B"
      }
    ]
  },
  "ai-illuminates-dark-regions-of-the-moon": {
    "title": "The Dark Side of the Moon — Lit Up! AI Illuminates Dark Regions of the Moon",
    "collection": "science",
    "content": "Neural networks are making it possible to view parts of the Moon that are perpetually shrouded by darkness.\n\nWhat’s new:Valentin Bickel at ETH Zürich and colleagues devised a method calledHyper-effective Noise Removal U-net Software(HORUS) to remove noise from images of the Moon’s south pole, where direct sunlight never falls. The National Aeronautics and Space Administration (NASA) is using the denoised images to plan lunar missions that will put humans on the Moon for the first time in decades.\n\nThe challenge:The only light that strikes the lunar south pole’s craters, boulders, mounds, and crevasses comes from scant photons that reflect off Earth or nearby lunar landforms or arrive from faraway stars. An imaging system aboard NASA’s Lunar Reconnaissance Orbiter can capture features that are lit this way, but it has a tendency todetect photons where none exist. Transmitting and processing the images introduces more noise, further blurring details in the already-dim images. Removing noise optimizes the available light, making it possible to see the landscape.\n\nHow it works:The authorstrainedtwo neural networks to remove the noise from lunar images.\n\nResults:HORUS removed noise from 200,000 images of the lunar surface. The authors identified possible landing sites, hazards to avoid, and evidence that some areas may contain water ice beneath the surface.\n\nBehind the news:The Moon’s south pole is the target for NASA’s upcoming Artemis program. Artemis 1, scheduled to launch in late September, will be fully automated. Artemis 2, scheduled for 2024, aims to land humans on the Moon for the first time since NASA’s final Apollo mission in 1972.\n\nWhy it matters:NASA chose the Moon’s south pole as the target for future missions because water may be frozen at the bottoms of craters there. Water on the Moon could provide clues about the heavenly body’s origin as well as hydration, radiation shielding, and propellant for missions further out in the solar system.\n\nWe’re thinking:This AI project is out of this world!",
    "qa": [
      {
        "question": "Phương pháp HORUS được phát triển bởi ai và ở đâu?",
        "options": {
          "A": "NASA, Hoa Kỳ",
          "B": "Valentin Bickel và các đồng nghiệp tại ETH Zürich",
          "C": "Chính phủ Thụy Sĩ",
          "D": "Một nhóm các nhà khoa học độc lập"
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của việc sử dụng phương pháp HORUS là gì?",
        "options": {
          "A": "Tăng độ sáng của hình ảnh Mặt Trăng",
          "B": "Loại bỏ nhiễu từ hình ảnh cực nam của Mặt Trăng",
          "C": "Tìm kiếm dấu hiệu của sự sống trên Mặt Trăng",
          "D": "Tạo ra bản đồ 3D chi tiết về bề mặt Mặt Trăng"
        },
        "answer": "B"
      },
      {
        "question": "Tại sao cực nam của Mặt Trăng lại tối và khó quan sát?",
        "options": {
          "A": "Do từ trường mạnh của Mặt Trăng",
          "B": "Do thiếu ánh sáng Mặt Trời trực tiếp",
          "C": "Do lớp bụi dày đặc bao phủ bề mặt",
          "D": "Do sự hấp thụ ánh sáng bởi các khoáng chất đặc biệt"
        },
        "answer": "B"
      },
      {
        "question": "NASA sử dụng hình ảnh đã được xử lý bằng HORUS cho mục đích gì?",
        "options": {
          "A": "Nghiên cứu thành phần hóa học của đất Mặt Trăng",
          "B": "Lập kế hoạch cho các nhiệm vụ đổ bộ lên Mặt Trăng",
          "C": "Tìm kiếm dấu hiệu của người ngoài hành tinh",
          "D": "Dự báo thời tiết trên Mặt Trăng"
        },
        "answer": "B"
      },
      {
        "question": "Nguồn gốc của nhiễu trong hình ảnh Mặt Trăng đến từ đâu?",
        "options": {
          "A": "Ánh sáng phản xạ từ các hành tinh khác",
          "B": "Hệ thống hình ảnh trên tàu Lunar Reconnaissance Orbiter và quá trình xử lý ảnh",
          "C": "Bức xạ vũ trụ từ không gian sâu",
          "D": "Hoạt động địa chất trên Mặt Trăng"
        },
        "answer": "B"
      },
      {
        "question": "HORUS sử dụng công nghệ nào để loại bỏ nhiễu?",
        "options": {
          "A": "Thuật toán lọc Kalman",
          "B": "Mạng nơ-ron (neural networks)",
          "C": "Biến đổi Fourier",
          "D": "Phân tích thành phần chính (PCA)"
        },
        "answer": "B"
      },
      {
        "question": "Chương trình Artemis của NASA dự kiến sẽ đưa con người lên Mặt Trăng vào năm nào?",
        "options": {
          "A": "2023",
          "B": "2024",
          "C": "2025",
          "D": "2026"
        },
        "answer": "B"
      },
      {
        "question": "Tại sao cực nam của Mặt Trăng lại là mục tiêu của chương trình Artemis?",
        "options": {
          "A": "Do có trữ lượng lớn helium-3",
          "B": "Do có thể có nước đóng băng dưới đáy các miệng núi lửa",
          "C": "Do có nhiều khoáng sản quý hiếm",
          "D": "Do có địa hình bằng phẳng, thuận lợi cho việc hạ cánh"
        },
        "answer": "B"
      },
      {
        "question": "Việc tìm thấy nước trên Mặt Trăng có ý nghĩa gì đối với các nhiệm vụ không gian trong tương lai?",
        "options": {
          "A": "Giúp làm mát các thiết bị điện tử",
          "B": "Cung cấp nước uống, bảo vệ khỏi bức xạ và nhiên liệu cho các nhiệm vụ xa hơn",
          "C": "Tạo ra môi trường sống cho các nhà khoa học",
          "D": "Sử dụng để sản xuất oxy cho các phi hành gia"
        },
        "answer": "B"
      },
      {
        "question": "HORUS đã xử lý bao nhiêu hình ảnh của bề mặt Mặt Trăng?",
        "options": {
          "A": "20,000",
          "B": "200,000",
          "C": "2,000,000",
          "D": "20,000,000"
        },
        "answer": "B"
      }
    ]
  },
  "ai-matches-humans-in-breast-cancer-diagnosis": {
    "title": "Rigorous Trial",
    "collection": "science",
    "content": "A deep learning system detected breast cancer in mammograms as well as experienced radiologists, according to a landmark study.\n\nWhat’s new:Researchers at Lund University in Swedenconducteda randomized, controlled, clinical trial to determine whether an AI system could save radiologists’ time without endangering patients — purportedly the first study of AI’s ability to diagnose breast cancer from mammograms whose design met the so-called gold standard for medical tests. Their human-plus-machine evaluation procedure enabled radiologists to spend substantially less time per patient while exceeding a baseline for safety.\n\nHow it works:The authors randomly divided 80,000 Swedish women into a control group and an experimental group.\n\nResults: The AI-assisted diagnosis achieved a cancer detection rate of 6.1 per 1,000 patients screened, comparable to the control method and above an established lower limit for safety. The radiologists recalled 2.0 percent of the control group and 2.2 percent of the experimental group, and both the control and experimental groups showed the same false-positive rate of 1.5 percent. (The difference in recall rates coupled with the matching false-positive rate suggests that the AI method detected 20 percent more cancer cases than the manual method, though authors didn’t emphasize that finding.) Moreover, since approximately 37,000 patients were only examined by one radiologist, the results indicate that AI saved 44.3 percent of the examination workload without increasing the number of misdiagnosed patients.\n\nYes, but:The authors’ method requires more study before it can enter clinical practice; for instance, tracking patients of varied genetic backgrounds. The authors are continuing the trial and plan to publish a further analysis after 100,000 patients have been enrolled for two years.\n\nBehind the news:Radiologists have used AI to help diagnose breast cancer since the 1980s (though that method isquestionable.) A 2020studyby Google Health claimed that AI outperformed radiologists, but critics found flaws in the methodology.\n\nWhy it matters:Breast cancercausesmore than 600,000 deaths annually worldwide. This work suggests that AI can enable doctors to evaluate more cases faster, helping to alleviate a shortage of radiologists. Moreover, treatment is more effective the earlier the cancer is diagnosed, and the authors’ method caught more early than late ones.\n\nWe’re thinking:Medical AI systems that perform well in the lab often fail in the clinic. For instance, a neural network may outperform humans at cancer diagnosis in a specific setting but, having been trained and tested on the same data distribution, isn’t robust to changes in input (say, images from different hospitals or patients from different populations). Meanwhile, medical AI systems have been subjected to veryfewrandomized, controlled trials, which is considered the gold standard for medical testing. Such trials have their limitations, but they’re a powerful tool for bridging the gap between lab and clinic.",
    "qa": [
      {
        "question": "Nghiên cứu tại Đại học Lund ở Thụy Điển đã thực hiện loại thử nghiệm lâm sàng nào để đánh giá khả năng của AI trong việc chẩn đoán ung thư vú?",
        "options": {
          "A": "Thử nghiệm mù đôi có đối chứng giả dược.",
          "B": "Thử nghiệm lâm sàng ngẫu nhiên, có đối chứng.",
          "C": "Thử nghiệm quan sát hồi cứu.",
          "D": "Thử nghiệm trên động vật trước khi thử nghiệm trên người."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả chính của nghiên cứu về tỷ lệ phát hiện ung thư vú khi sử dụng AI so với phương pháp truyền thống là gì?",
        "options": {
          "A": "AI phát hiện ung thư vú với tỷ lệ cao hơn đáng kể so với phương pháp truyền thống.",
          "B": "AI phát hiện ung thư vú với tỷ lệ thấp hơn đáng kể so với phương pháp truyền thống.",
          "C": "AI phát hiện ung thư vú với tỷ lệ tương đương với phương pháp truyền thống và trên ngưỡng an toàn.",
          "D": "AI không thể phát hiện ung thư vú, trong khi phương pháp truyền thống có thể."
        },
        "answer": "C"
      },
      {
        "question": "Tỷ lệ bệnh nhân được gọi lại (recall rate) trong nhóm đối chứng và nhóm thử nghiệm AI là bao nhiêu?",
        "options": {
          "A": "Nhóm đối chứng 2.2%, nhóm thử nghiệm 2.0%.",
          "B": "Nhóm đối chứng 1.5%, nhóm thử nghiệm 2.0%.",
          "C": "Nhóm đối chứng 2.0%, nhóm thử nghiệm 2.2%.",
          "D": "Nhóm đối chứng 1.5%, nhóm thử nghiệm 1.5%."
        },
        "answer": "C"
      },
      {
        "question": "Nghiên cứu chỉ ra rằng AI đã giúp tiết kiệm bao nhiêu phần trăm khối lượng công việc của bác sĩ X-quang mà không làm tăng số lượng bệnh nhân bị chẩn đoán sai?",
        "options": {
          "A": "20%",
          "B": "37%",
          "C": "44.3%",
          "D": "60%"
        },
        "answer": "C"
      },
      {
        "question": "Một trong những hạn chế được đề cập của phương pháp sử dụng AI trong chẩn đoán ung thư vú là gì?",
        "options": {
          "A": "Chi phí triển khai quá cao.",
          "B": "Yêu cầu cần có đội ngũ kỹ thuật viên chuyên nghiệp để vận hành.",
          "C": "Cần nghiên cứu thêm trên các bệnh nhân có nền tảng di truyền khác nhau.",
          "D": "Không thể tích hợp với hệ thống lưu trữ dữ liệu hiện có của bệnh viện."
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu tiếp theo của các nhà nghiên cứu trong thử nghiệm này là gì?",
        "options": {
          "A": "Ngừng thử nghiệm do kết quả không khả quan.",
          "B": "Phân tích sâu hơn sau khi thu thập dữ liệu từ 100,000 bệnh nhân trong hai năm.",
          "C": "Mở rộng thử nghiệm sang các quốc gia khác.",
          "D": "Tập trung vào phát triển các thuật toán AI phức tạp hơn."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì khiến các hệ thống AI y tế hoạt động tốt trong phòng thí nghiệm thường thất bại trong thực tế lâm sàng?",
        "options": {
          "A": "Do thiếu kinh phí để duy trì hệ thống.",
          "B": "Do sự thay đổi trong dữ liệu đầu vào (ví dụ: hình ảnh từ các bệnh viện khác nhau).",
          "C": "Do bác sĩ không tin tưởng vào kết quả của AI.",
          "D": "Do hệ thống AI quá phức tạp để sử dụng."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao các thử nghiệm lâm sàng ngẫu nhiên, có đối chứng được coi là tiêu chuẩn vàng cho các thử nghiệm y tế?",
        "options": {
          "A": "Vì chúng dễ thực hiện và chi phí thấp.",
          "B": "Vì chúng cung cấp bằng chứng mạnh mẽ về hiệu quả và an toàn của một phương pháp điều trị.",
          "C": "Vì chúng không yêu cầu sự tham gia của bệnh nhân.",
          "D": "Vì chúng luôn cho kết quả tích cực."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh tầm quan trọng của việc chẩn đoán sớm ung thư vú vì lý do gì?",
        "options": {
          "A": "Giúp giảm chi phí điều trị.",
          "B": "Giúp bệnh nhân dễ dàng chấp nhận bệnh hơn.",
          "C": "Giúp tăng hiệu quả điều trị.",
          "D": "Giúp giảm số lượng bác sĩ cần thiết."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, việc sử dụng AI trong chẩn đoán ung thư vú có thể giúp giải quyết vấn đề gì?",
        "options": {
          "A": "Tình trạng thiếu hụt bác sĩ X-quang.",
          "B": "Chi phí điều trị ung thư vú quá cao.",
          "C": "Sự phức tạp của các phương pháp điều trị ung thư vú.",
          "D": "Sự thiếu hụt các thiết bị chẩn đoán hiện đại."
        },
        "answer": "A"
      }
    ]
  },
  "ai-on-the-cob": {
    "title": "AI on the Cob",
    "collection": "science",
    "content": "Deep learning research is harvesting better ways to manage farms.What’s new:A convolutional neural networkpredictedcorn yields in fields across the U.S. Midwest.How it works:Researchers from the University of Illinois at Urbana-Champaign built a network that forecasts the quantity of corn that will grow seasonally in a given field under variable rates of seeding and nitrogen fertilization.\n\nResults:The team’s model averaged .70 root mean squared error of the mean yield standard deviation in all fields. It predicted yields more accurately than other neural networks the team built in all but one. It was also better than a set of non-neural benchmarks, outperforming a random forest model by 29 percent and a multiple linear regression model by 68 percent.Behind the news:Agriculture requires farmers to manage numerous environmental factors and decision points, from weather patterns to hiring manual labor. Machine learning can help at every stage. Big-ag heavyweights like John Deere as well as startups like Dot and SwarmFarm offer highly automated tractors including machines that use advanced image recognition to kill individual weeds. Landing AI helped design a rig that automatically optimizes harvesting. (Disclosure: Andrew Ng is CEO of Landing AI.) Other companies specialize in evaluatingproduce quality,crop health, and multi-farm operations.Why it matters:Systems like this could help farmers increase yields, save on seed costs, and reduce excess nitrogen that ends up running off into water sources. The authors are performing more trials to improve the model and working on an optimization algorithm so farmers can generate fertilizer and seed maps for their own fields.We’re thinking:In many developing economies, younger people don’t want to make their living from farming, and small family-run farms are being consolidated into larger plots. This creates opportunities for AI and automation to make agriculture more efficient, and potentially to make food more affordable and protect the environment.",
    "qa": [
      {
        "question": "Mạng nơ-ron tích chập (convolutional neural network) trong nghiên cứu này được sử dụng để làm gì?",
        "options": {
          "A": "Phân loại các loại cây trồng khác nhau.",
          "B": "Dự đoán năng suất ngô trên các cánh đồng.",
          "C": "Điều khiển máy kéo tự động.",
          "D": "Tối ưu hóa việc thu hoạch nông sản."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình của nhóm nghiên cứu từ Đại học Illinois tại Urbana-Champaign dự đoán năng suất ngô dựa trên yếu tố nào?",
        "options": {
          "A": "Giá cả thị trường của ngô.",
          "B": "Tỷ lệ gieo hạt và lượng phân bón nitơ.",
          "C": "Số lượng nhân công lao động trên cánh đồng.",
          "D": "Loại đất và lượng mưa trung bình."
        },
        "answer": "B"
      },
      {
        "question": "So với mô hình Random Forest, mô hình của nhóm nghiên cứu dự đoán năng suất ngô chính xác hơn bao nhiêu phần trăm?",
        "options": {
          "A": "29%",
          "B": "68%",
          "C": "70%",
          "D": "97%"
        },
        "answer": "A"
      },
      {
        "question": "Công ty nào được nhắc đến trong bài viết đã giúp thiết kế một hệ thống tự động tối ưu hóa việc thu hoạch?",
        "options": {
          "A": "John Deere",
          "B": "Dot",
          "C": "SwarmFarm",
          "D": "Landing AI"
        },
        "answer": "D"
      },
      {
        "question": "Lợi ích tiềm năng nào của các hệ thống AI trong nông nghiệp được đề cập trong bài viết?",
        "options": {
          "A": "Giảm chi phí thuê nhân công.",
          "B": "Tăng năng suất, tiết kiệm chi phí hạt giống và giảm lượng nitơ dư thừa.",
          "C": "Cải thiện chất lượng đất.",
          "D": "Dự báo thời tiết chính xác hơn."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu tiếp theo của các tác giả nghiên cứu là gì?",
        "options": {
          "A": "Phát triển các loại cây trồng biến đổi gen.",
          "B": "Cải thiện mô hình và phát triển thuật toán tối ưu hóa cho bản đồ phân bón và hạt giống.",
          "C": "Mở rộng nghiên cứu sang các loại cây trồng khác.",
          "D": "Thương mại hóa công nghệ cho các công ty nông nghiệp lớn."
        },
        "answer": "B"
      },
      {
        "question": "Xu hướng nào trong lĩnh vực nông nghiệp được đề cập đến, tạo cơ hội cho AI và tự động hóa?",
        "options": {
          "A": "Sự gia tăng của các trang trại hữu cơ.",
          "B": "Sự chuyển đổi từ các trang trại gia đình nhỏ sang các khu đất lớn hơn.",
          "C": "Sự phục hồi của các phương pháp canh tác truyền thống.",
          "D": "Sự gia tăng nhu cầu về thực phẩm biến đổi gen."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài việc dự đoán năng suất, AI còn được sử dụng trong nông nghiệp để làm gì?",
        "options": {
          "A": "Kiểm soát dịch bệnh trên cây trồng.",
          "B": "Đánh giá chất lượng sản phẩm, sức khỏe cây trồng và hoạt động đa trang trại.",
          "C": "Tạo ra các loại phân bón mới.",
          "D": "Phát triển các giống cây trồng kháng sâu bệnh."
        },
        "answer": "B"
      },
      {
        "question": "Chỉ số nào được sử dụng để đánh giá độ chính xác của mô hình dự đoán năng suất ngô?",
        "options": {
          "A": "Tỷ lệ chính xác (Accuracy)",
          "B": "Sai số bình phương gốc trung bình (Root Mean Squared Error)",
          "C": "Độ lệch chuẩn (Standard Deviation)",
          "D": "Hệ số tương quan (Correlation Coefficient)"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, việc sử dụng AI và tự động hóa trong nông nghiệp có thể mang lại lợi ích nào cho môi trường?",
        "options": {
          "A": "Giảm lượng khí thải nhà kính từ máy móc nông nghiệp.",
          "B": "Giảm lượng nitơ dư thừa chảy vào các nguồn nước.",
          "C": "Bảo tồn đa dạng sinh học trong các trang trại.",
          "D": "Tăng cường khả năng hấp thụ carbon của đất."
        },
        "answer": "B"
      }
    ]
  },
  "ai-reproducibility-crisis": {
    "title": "Bad Machine Learning Makes Bad Science",
    "collection": "science",
    "content": "Misuse of machine learning by scientific researchers is causing a spate of irreproducible results.\n\nWhat’s new:A recentworkshophighlighted the impact of poorly designed models in medicine, security, software engineering, and other disciplines,Wiredreported.Flawed machine learning:Speakers at the Princeton University event highlighted common pitfalls that undermine reproducibility:\n\nBehind the news:The workshop followed a recentmeta-analysisby Princeton researchers that identified 329 scientific papers in which poorly implemented machine learning yielded questionable results.\n\nWhy it matters:Experienced machine learning practitioners are well aware of the pitfalls detailed by the workshop, but researchers from other disciplines may not be. When they apply machine learning in a naive way, they can generate invalid results that inherit an aura of credibility owing to machine learning’s track record of success. Such results degrade science and impinge on the willingness of more skeptical scientists to trust the efficacy of learning algorithms. Enquiries like this one will be necessary at least until machine learning becomes far more widely practiced and understood.\n\nWe’re thinking:Many AI practitioners are eager to contribute to meaningful projects. Partnering with scientists in other fields is a great way to gain experience developing effective models and educate experts in other domains about the uses and limitations of machine learning.",
    "qa": [
      {
        "question": "Vấn đề chính được đề cập trong bài viết là gì?",
        "options": {
          "A": "Sự thiếu hụt các hội thảo về ứng dụng Machine Learning.",
          "B": "Việc sử dụng sai Machine Learning dẫn đến kết quả nghiên cứu không thể tái tạo.",
          "C": "Sự cạnh tranh gay gắt giữa các nhà nghiên cứu Machine Learning.",
          "D": "Sự thiếu hiểu biết về Machine Learning trong công chúng."
        },
        "answer": "B"
      },
      {
        "question": "Hội thảo được đề cập trong bài viết đã nhấn mạnh điều gì?",
        "options": {
          "A": "Sự cần thiết của việc sử dụng các mô hình Machine Learning phức tạp hơn.",
          "B": "Tác động của các mô hình được thiết kế kém trong nhiều lĩnh vực.",
          "C": "Sự thành công vượt trội của Machine Learning trong y học.",
          "D": "Sự phát triển nhanh chóng của các thuật toán Machine Learning mới."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu meta-analysis của các nhà nghiên cứu Princeton đã xác định được bao nhiêu bài báo khoa học có kết quả đáng ngờ do Machine Learning được triển khai kém?",
        "options": {
          "A": "392",
          "B": "239",
          "C": "329",
          "D": "293"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì khiến kết quả nghiên cứu sử dụng Machine Learning một cách 'ngây thơ' trở nên đáng tin cậy?",
        "options": {
          "A": "Sự phức tạp của các thuật toán Machine Learning.",
          "B": "Danh tiếng thành công của Machine Learning.",
          "C": "Sự kiểm duyệt nghiêm ngặt của các tạp chí khoa học.",
          "D": "Sự tin tưởng tuyệt đối của công chúng vào công nghệ."
        },
        "answer": "B"
      },
      {
        "question": "Hậu quả của việc tạo ra các kết quả không hợp lệ bằng Machine Learning là gì?",
        "options": {
          "A": "Thúc đẩy sự phát triển của các thuật toán mới.",
          "B": "Nâng cao uy tín của các nhà nghiên cứu.",
          "C": "Làm suy giảm khoa học và giảm sự tin tưởng vào hiệu quả của các thuật toán học máy.",
          "D": "Tăng cường hợp tác giữa các nhà khoa học."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết cho rằng điều gì là cần thiết cho đến khi Machine Learning được thực hành và hiểu rộng rãi hơn?",
        "options": {
          "A": "Tăng cường đầu tư vào nghiên cứu Machine Learning.",
          "B": "Tổ chức nhiều hội thảo chuyên sâu hơn.",
          "C": "Thực hiện các cuộc điều tra và đánh giá.",
          "D": "Phát triển các công cụ Machine Learning dễ sử dụng hơn."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết khuyến khích các chuyên gia AI nên làm gì?",
        "options": {
          "A": "Tập trung vào việc phát triển các thuật toán Machine Learning mới.",
          "B": "Hợp tác với các nhà khoa học trong các lĩnh vực khác để phát triển các mô hình hiệu quả và giáo dục về Machine Learning.",
          "C": "Xuất bản nhiều bài báo khoa học hơn về Machine Learning.",
          "D": "Thành lập các công ty khởi nghiệp về Machine Learning."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, ai có thể không nhận thức được những cạm bẫy khi sử dụng Machine Learning?",
        "options": {
          "A": "Các chuyên gia Machine Learning giàu kinh nghiệm.",
          "B": "Các nhà nghiên cứu từ các lĩnh vực khác.",
          "C": "Các nhà phát triển phần mềm.",
          "D": "Các chuyên gia bảo mật."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc hợp tác giữa các chuyên gia AI và các nhà khoa học trong các lĩnh vực khác là gì?",
        "options": {
          "A": "Để tăng tốc độ phát triển của các thuật toán Machine Learning.",
          "B": "Để kiếm được nhiều tiền hơn từ các dự án nghiên cứu.",
          "C": "Để có được kinh nghiệm phát triển các mô hình hiệu quả và giáo dục về Machine Learning.",
          "D": "Để tạo ra các sản phẩm Machine Learning thương mại."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến lĩnh vực nào mà Machine Learning được sử dụng sai dẫn đến kết quả không thể tái tạo?",
        "options": {
          "A": "Chỉ y học.",
          "B": "Chỉ bảo mật.",
          "C": "Chỉ kỹ thuật phần mềm.",
          "D": "Y học, bảo mật, kỹ thuật phần mềm và các lĩnh vực khác."
        },
        "answer": "D"
      }
    ]
  },
  "ai-predicts-scientific-breakthroughs-using-social-graphs": {
    "title": "Predicting Scientific Discoveries",
    "collection": "ml-research",
    "content": "A new AI method directs scientists toward promising avenues of inquiry.\n\nWhat's new:Jamshid Sourati and James A. Evans at University of Chicago proposed amethod to predict new scientific discoveriesby building a graph that connects researchers, their objects of study, and the scientific properties thereof. They evaluated their approach using data from materials science.\n\nKey insight:Overlapping interests among researchers may indicate areas where further research would be fruitful. For example, if one group of researchers studies a material A and its property P, a second group studies materials A and B, and another group studies materials B and C, it may turn out that material C exhibits property P.\n\nHow it works:The authors tried to predict whether certain inorganic materials have certain electrical properties based onscientific literaturethrough the year 2000. From 1.5 million articles that described 100,000 inorganic compounds, they extracted the author names, materials mentioned (for example, sodium nitrite), and their properties (for example, thermoelectricity, the ability to convert heat into electricity and vice versa). They used this data to construct a graph whose nodes were authors, materials, and properties. Edges connected the nodes that appeared in the same paper, for example a particular author whose paper covered specific material or property.\n\nResults:The authors predicted which materials possessed each of three properties. They compared their results with predictions obtained in a similar way using a Word2Vec model trained exclusively on text from scientific papers. They used papers from 2001 through 2018 to evaluate the predictions. For thermoelectricity, the cumulative precision (percentage of predicted discoveries proven correct) was 76 percent, while the cumulative precision of the alternative method was 48 percent. The cumulative precision of random guesses was about 3 percent. The authors obtained similar results for the other two properties.\n\nWhy it matters:Science is a social endeavor, where the connections between people and their work can be represented as a graph that reflects the collective attention of the scientific community. The collective attention acts as a signal that predicts promising avenues for further research — a signal that machine learning can help to tease out.\n\nWe're thinking:The authors also predicted drug discoveries with similarly good results. Their method may be useful for identifying fruitful directions in other scientific areas, and perhaps in other domains entirely.",
    "qa": [
      {
        "question": "Phương pháp AI mới được đề xuất trong bài viết này tập trung vào việc gì?",
        "options": {
          "A": "Tự động viết các bài báo khoa học.",
          "B": "Dự đoán các khám phá khoa học mới.",
          "C": "Phân tích cấu trúc gen của các nhà khoa học.",
          "D": "Tối ưu hóa quy trình xuất bản khoa học."
        },
        "answer": "B"
      },
      {
        "question": "Jamshid Sourati và James A. Evans đến từ trường đại học nào?",
        "options": {
          "A": "Đại học Harvard.",
          "B": "Đại học Chicago.",
          "C": "Đại học Stanford.",
          "D": "Đại học MIT."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu nào được sử dụng để đánh giá phương pháp dự đoán trong nghiên cứu này?",
        "options": {
          "A": "Dữ liệu về hành vi của người dùng trên mạng xã hội.",
          "B": "Dữ liệu từ lĩnh vực khoa học vật liệu.",
          "C": "Dữ liệu về thị trường chứng khoán.",
          "D": "Dữ liệu về biến đổi khí hậu."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, yếu tố nào có thể chỉ ra các lĩnh vực nghiên cứu hứa hẹn?",
        "options": {
          "A": "Sự khác biệt trong quan điểm giữa các nhà nghiên cứu.",
          "B": "Sự trùng lặp về mối quan tâm giữa các nhà nghiên cứu.",
          "C": "Số lượng bài báo khoa học được xuất bản hàng năm.",
          "D": "Kinh nghiệm làm việc của các nhà nghiên cứu."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp AI trong bài viết xây dựng một đồ thị kết nối những yếu tố nào?",
        "options": {
          "A": "Các nhà khoa học, các bài báo khoa học và các tạp chí khoa học.",
          "B": "Các nhà khoa học, đối tượng nghiên cứu và các thuộc tính khoa học của chúng.",
          "C": "Các nhà khoa học, các quỹ tài trợ nghiên cứu và các trường đại học.",
          "D": "Các nhà khoa học, các bằng sáng chế và các công ty công nghệ."
        },
        "answer": "B"
      },
      {
        "question": "Trong thử nghiệm, phương pháp AI đã dự đoán điều gì liên quan đến các vật liệu vô cơ?",
        "options": {
          "A": "Khả năng chống ăn mòn của chúng.",
          "B": "Các tính chất điện của chúng.",
          "C": "Khả năng tái chế của chúng.",
          "D": "Giá trị thị trường của chúng."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu từ năm nào đến năm nào được sử dụng để đánh giá các dự đoán của phương pháp AI?",
        "options": {
          "A": "1990 đến 2000.",
          "B": "2001 đến 2018.",
          "C": "2010 đến 2020.",
          "D": "2019 đến 2023."
        },
        "answer": "B"
      },
      {
        "question": "Thuật ngữ 'thermoelectricity' trong bài viết đề cập đến khả năng gì?",
        "options": {
          "A": "Khả năng dẫn nhiệt của vật liệu.",
          "B": "Khả năng chuyển đổi nhiệt thành điện và ngược lại.",
          "C": "Khả năng chịu nhiệt của vật liệu.",
          "D": "Khả năng hấp thụ nhiệt của vật liệu."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì đóng vai trò như một tín hiệu dự đoán các hướng nghiên cứu đầy hứa hẹn?",
        "options": {
          "A": "Số lượng trích dẫn của một bài báo khoa học.",
          "B": "Sự chú ý tập thể của cộng đồng khoa học.",
          "C": "Ý kiến của các nhà khoa học hàng đầu.",
          "D": "Ngân sách dành cho nghiên cứu khoa học."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài khoa học vật liệu, phương pháp AI này còn được dự đoán là có thể ứng dụng trong lĩnh vực nào khác?",
        "options": {
          "A": "Nghiên cứu vũ trụ.",
          "B": "Phát hiện thuốc mới.",
          "C": "Nghiên cứu lịch sử.",
          "D": "Phân tích tài chính."
        },
        "answer": "B"
      }
    ]
  },
  "ai-tackles-ocd": {
    "title": "AI Tackles OCD",
    "collection": "science",
    "content": "A drug designed by AI has been approved for testing in humans.What’s new:A UK startup focused on automated drug discovery teamed up with a Japanese pharmaceutical company to produce a new medicine for obsessive compulsive disorder. The compound, known as DSP1181, is designed to take effect more quickly and last longer than existing treatments. Japanese authoritiesclearedit for a clinical trial.How it works:Exscientia’s drug-discoveryplatformcan start with a biological target known to influence a particular medical condition.\n\nWhy it matters:Pharmaceutical companies invest upward of$2.6 billionto develop a single drug, and it can take three to six years tofinda compound that’s viable for testing in humans— with no guarantee that it will prove safe and effective. Automating even small parts of the process can save big money. That’s one reason why Exscientia is one of nearly 200 companies worldwide using AI to find new drugs.We’re thinking:AI is no magic bullet for drug discovery. But cutting the enormous cost of development would enable pharma companies to study more molecules and potentially to bring more medicines to market.",
    "qa": [
      {
        "question": "Công ty khởi nghiệp Exscientia có trụ sở tại quốc gia nào?",
        "options": {
          "A": "Nhật Bản",
          "B": "Vương quốc Anh",
          "C": "Hoa Kỳ",
          "D": "Đức"
        },
        "answer": "B"
      },
      {
        "question": "DSP1181 là loại thuốc được thiết kế để điều trị bệnh gì?",
        "options": {
          "A": "Alzheimer",
          "B": "Rối loạn ám ảnh cưỡng chế",
          "C": "Parkinson",
          "D": "Ung thư"
        },
        "answer": "B"
      },
      {
        "question": "Cơ quan nào đã phê duyệt DSP1181 cho thử nghiệm lâm sàng?",
        "options": {
          "A": "Cơ quan Quản lý Thực phẩm và Dược phẩm Hoa Kỳ (FDA)",
          "B": "Cơ quan Dược phẩm Châu Âu (EMA)",
          "C": "Cơ quan quản lý tại Nhật Bản",
          "D": "Bộ Y tế Vương quốc Anh"
        },
        "answer": "C"
      },
      {
        "question": "Nền tảng khám phá thuốc của Exscientia bắt đầu từ đâu?",
        "options": {
          "A": "Phân tích dữ liệu bệnh nhân",
          "B": "Mục tiêu sinh học ảnh hưởng đến một tình trạng bệnh cụ thể",
          "C": "Thử nghiệm trên động vật",
          "D": "Nghiên cứu các loại thảo dược"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, chi phí trung bình để phát triển một loại thuốc mới là bao nhiêu?",
        "options": {
          "A": "500 triệu đô la",
          "B": "1 tỷ đô la",
          "C": "2.6 tỷ đô la",
          "D": "5 tỷ đô la"
        },
        "answer": "C"
      },
      {
        "question": "Thời gian trung bình để tìm ra một hợp chất có thể thử nghiệm trên người là bao lâu?",
        "options": {
          "A": "1-2 năm",
          "B": "3-6 năm",
          "C": "7-10 năm",
          "D": "10-15 năm"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến khoảng bao nhiêu công ty trên toàn thế giới đang sử dụng AI để tìm kiếm thuốc mới?",
        "options": {
          "A": "Dưới 50",
          "B": "Khoảng 100",
          "C": "Gần 200",
          "D": "Hơn 300"
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích chính của việc tự động hóa quá trình khám phá thuốc là gì?",
        "options": {
          "A": "Tăng độ chính xác của thử nghiệm lâm sàng",
          "B": "Giảm chi phí phát triển thuốc",
          "C": "Loại bỏ hoàn toàn rủi ro trong quá trình phát triển",
          "D": "Đảm bảo 100% thuốc mới sẽ hiệu quả"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, AI có phải là giải pháp hoàn hảo cho việc khám phá thuốc không?",
        "options": {
          "A": "Có, AI đảm bảo thành công trong mọi dự án.",
          "B": "Có, AI giúp giảm thời gian phát triển thuốc đáng kể.",
          "C": "Không, AI không phải là 'viên đạn thần kỳ' nhưng có thể giảm chi phí đáng kể.",
          "D": "Không, AI không có tác dụng gì trong việc khám phá thuốc."
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu cuối cùng của việc giảm chi phí phát triển thuốc là gì?",
        "options": {
          "A": "Tăng lợi nhuận cho các công ty dược phẩm.",
          "B": "Nghiên cứu nhiều phân tử hơn và đưa nhiều loại thuốc ra thị trường hơn.",
          "C": "Giảm giá thuốc cho người tiêu dùng.",
          "D": "Tạo ra nhiều việc làm trong ngành dược phẩm."
        },
        "answer": "B"
      }
    ]
  },
  "albert-gu-more-learning-less-data": {
    "title": "Albert Gu",
    "collection": "ml-research",
    "content": "Building a foundation model takes tremendous amounts of data. In the coming year, I hope we’ll enable models to learn more from less data.\n\nThe AI community has achieved remarkable success by scaling up transformers and datasets. But this approach may be reaching a point of diminishing returns — an increasingly widespread belief among the pretraining community as they try to train next-generation models. In any case, the current approach poses practical problems. Training huge models on huge datasets consumes huge amounts of time and energy, and we’re running out of new sources of data for training large models.\n\nThe fact is, current models consume much more data than humans require for learning. We’ve known this for a while, but we’ve ignored it due to the amazing effectiveness of scaling. It takes trillions of tokens to train a model but orders of magnitude less for a human to become a reasonably intelligent being. So there’s a difference in sample efficiency between our best models and humans. Human learning shows that there’s a learning algorithm, objective function, architecture, or a combination thereof that can learn more sample-efficiently than current models.\n\nOne of the keys to solving this problem is enabling models to produce higher-level abstractions and filter out noise. I believe this concept, and thus the general problem of data efficiency, is related to several other current problems in AI:\n\nConsidering data efficiency in light of these other problems, I believe they’re all related. It’s not clear which is the cause and which are the effects. If we solve interpretability, the mechanisms we engineer may lead to models that can extract better features and lead to more data-efficient models. Or we may find that greater data efficiency leads to more interpretable models.\n\nEither way, data efficiency is fundamentally important, and progress in that area will be an indicator of broader progress in AI. I hope to see major strides in the coming year.\n\nAlbert Gu is an Assistant Professor of Machine Learning at Carnegie Mellon University and Chief Scientist of Cartesia AI. He appears on Time’s list of the most influential people in AI in 2024.",
    "qa": [
      {
        "question": "Theo tác giả, điều gì đang trở thành một vấn đề ngày càng lớn đối với việc huấn luyện các mô hình AI?",
        "options": {
          "A": "Sự thiếu hụt các nhà nghiên cứu có kinh nghiệm trong lĩnh vực AI.",
          "B": "Việc tiêu thụ quá nhiều thời gian, năng lượng và sự cạn kiệt nguồn dữ liệu mới.",
          "C": "Sự phức tạp trong việc thiết kế các kiến trúc mạng nơ-ron mới.",
          "D": "Sự khó khăn trong việc tích hợp các mô hình AI vào các ứng dụng thực tế."
        },
        "answer": "B"
      },
      {
        "question": "Tác giả chỉ ra sự khác biệt chính nào giữa cách học của mô hình AI hiện tại và cách học của con người?",
        "options": {
          "A": "Mô hình AI cần nhiều thời gian hơn để học so với con người.",
          "B": "Mô hình AI cần ít dữ liệu hơn để học so với con người.",
          "C": "Mô hình AI hiệu quả hơn trong việc xử lý thông tin phức tạp so với con người.",
          "D": "Mô hình AI cần lượng dữ liệu lớn hơn đáng kể so với con người để đạt được mức độ thông minh tương đương."
        },
        "answer": "D"
      },
      {
        "question": "Theo tác giả, yếu tố nào có thể giúp giải quyết vấn đề hiệu quả dữ liệu trong AI?",
        "options": {
          "A": "Tăng cường khả năng tính toán của các hệ thống AI.",
          "B": "Phát triển các thuật toán học sâu phức tạp hơn.",
          "C": "Cho phép mô hình tạo ra các trừu tượng cấp cao hơn và loại bỏ nhiễu.",
          "D": "Sử dụng nhiều dữ liệu hơn từ các nguồn khác nhau."
        },
        "answer": "C"
      },
      {
        "question": "Tác giả tin rằng hiệu quả dữ liệu có liên quan đến vấn đề nào khác trong AI?",
        "options": {
          "A": "Khả năng mở rộng của các mô hình AI.",
          "B": "Khả năng giải thích (interpretability) của các mô hình AI.",
          "C": "Khả năng thích ứng của các mô hình AI với các môi trường khác nhau.",
          "D": "Khả năng bảo mật của các mô hình AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo tác giả, điều gì có thể xảy ra nếu chúng ta giải quyết được vấn đề về khả năng giải thích (interpretability) của AI?",
        "options": {
          "A": "Chúng ta có thể tạo ra các mô hình AI có khả năng tự học hỏi.",
          "B": "Chúng ta có thể phát triển các mô hình AI có khả năng trích xuất các đặc trưng tốt hơn, dẫn đến hiệu quả dữ liệu cao hơn.",
          "C": "Chúng ta có thể giảm chi phí huấn luyện các mô hình AI.",
          "D": "Chúng ta có thể tăng cường tính bảo mật của các mô hình AI."
        },
        "answer": "B"
      },
      {
        "question": "Tác giả dự đoán điều gì về tiến bộ trong lĩnh vực hiệu quả dữ liệu?",
        "options": {
          "A": "Tiến bộ trong lĩnh vực này sẽ không có tác động đáng kể đến sự phát triển của AI.",
          "B": "Tiến bộ trong lĩnh vực này sẽ là một chỉ số cho thấy sự tiến bộ rộng lớn hơn trong AI.",
          "C": "Tiến bộ trong lĩnh vực này sẽ chỉ mang lại lợi ích cho một số lĩnh vực cụ thể của AI.",
          "D": "Tiến bộ trong lĩnh vực này sẽ làm chậm sự phát triển của các lĩnh vực khác trong AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, cộng đồng AI đã đạt được thành công đáng kể bằng cách nào?",
        "options": {
          "A": "Bằng cách phát triển các thuật toán học sâu mới.",
          "B": "Bằng cách tăng quy mô của các transformers và bộ dữ liệu.",
          "C": "Bằng cách tập trung vào việc cải thiện khả năng giải thích của AI.",
          "D": "Bằng cách hợp tác chặt chẽ với các ngành công nghiệp khác."
        },
        "answer": "B"
      },
      {
        "question": "Tác giả Albert Gu hiện đang giữ chức vụ gì?",
        "options": {
          "A": "Giám đốc điều hành của Google AI.",
          "B": "Giáo sư thỉnh giảng tại Đại học Stanford.",
          "C": "Trợ lý Giáo sư về Machine Learning tại Đại học Carnegie Mellon và Nhà khoa học trưởng của Cartesia AI.",
          "D": "Nhà nghiên cứu chính tại OpenAI."
        },
        "answer": "C"
      },
      {
        "question": "Theo tác giả, điều gì có thể xảy ra nếu chúng ta đạt được hiệu quả dữ liệu cao hơn?",
        "options": {
          "A": "Các mô hình AI sẽ trở nên ít tin cậy hơn.",
          "B": "Các mô hình AI sẽ trở nên khó giải thích hơn.",
          "C": "Các mô hình AI có thể trở nên dễ giải thích hơn.",
          "D": "Các mô hình AI sẽ yêu cầu nhiều năng lượng hơn để hoạt động."
        },
        "answer": "C"
      },
      {
        "question": "Cụm từ 'diminishing returns' trong bài viết đề cập đến điều gì?",
        "options": {
          "A": "Sự giảm sút về chất lượng dữ liệu huấn luyện.",
          "B": "Sự giảm sút về số lượng nhà nghiên cứu AI.",
          "C": "Sự giảm sút về lợi ích thu được từ việc tiếp tục tăng quy mô mô hình và dữ liệu.",
          "D": "Sự giảm sút về khả năng ứng dụng của AI trong thực tế."
        },
        "answer": "C"
      }
    ]
  },
  "algorithms-for-elephants": {
    "title": "Algorithms For Elephants",
    "collection": "science",
    "content": "An AI-powered collar may help protect wild elephants from poachers, hunters, and other hostile humans.What’s new:TenElephantEdgewireless tracking collars will be fitted onto African elephants next year,TechCrunchreported. The product of an open source collaboration between hardware and software engineers, the collar serves as a platform for machine learning models designed to interpret elephant behavior and alert sympathetic humans when the animals are in trouble.How it works:The models included are winners of a competition organized byHackster.io,a hardware engineering community, andSmart Parks,a Dutch conservation group. They were built using  development tools fromEdge Impulseand work with hardware from organizations includingInstitute IrnasandAvnet.\n\nBehind the news:Defenders of wildlife are increasingly using AI to extend their reach and effectiveness.\n\nWhy it matters:Africa’s elephant population has plummeted in recent years. Only about 350,000 wild elephants remain on the continent, and poachers illegallykillupward of 15,000 a year. These animals need all the help they can get.We’re thinking:This work addresses the elephant in the room.",
    "qa": [
      {
        "question": "Mục đích chính của việc sử dụng vòng cổ AI cho voi là gì?",
        "options": {
          "A": "Nghiên cứu hành vi của voi trong môi trường sống tự nhiên.",
          "B": "Bảo vệ voi hoang dã khỏi những kẻ săn trộm và các mối đe dọa khác từ con người.",
          "C": "Theo dõi di chuyển của voi để phục vụ mục đích du lịch sinh thái.",
          "D": "Cải thiện sức khỏe và tuổi thọ của voi thông qua việc theo dõi các chỉ số sinh học."
        },
        "answer": "B"
      },
      {
        "question": "Số lượng vòng cổ theo dõi không dây ElephantEdge dự kiến được gắn cho voi châu Phi vào năm tới là bao nhiêu?",
        "options": {
          "A": "5",
          "B": "10",
          "C": "15",
          "D": "20"
        },
        "answer": "B"
      },
      {
        "question": "Vòng cổ AI cho voi hoạt động dựa trên nền tảng nào?",
        "options": {
          "A": "Công nghệ GPS và bản đồ số.",
          "B": "Sự hợp tác mã nguồn mở giữa các kỹ sư phần cứng và phần mềm.",
          "C": "Mạng lưới các cảm biến được đặt trong môi trường sống của voi.",
          "D": "Dữ liệu thu thập từ các vệ tinh quan sát Trái Đất."
        },
        "answer": "B"
      },
      {
        "question": "Các mô hình máy học được sử dụng trong vòng cổ AI cho voi được phát triển thông qua cuộc thi do tổ chức nào tổ chức?",
        "options": {
          "A": "TechCrunch và Institute Irnas",
          "B": "Hackster.io và Smart Parks",
          "C": "Edge Impulse và Avnet",
          "D": "Institute Irnas và Avnet"
        },
        "answer": "B"
      },
      {
        "question": "Công cụ phát triển nào được sử dụng để xây dựng các mô hình máy học cho vòng cổ AI?",
        "options": {
          "A": "Smart Parks",
          "B": "Hackster.io",
          "C": "Edge Impulse",
          "D": "Institute Irnas"
        },
        "answer": "C"
      },
      {
        "question": "Tổ chức nào sau đây KHÔNG được đề cập đến như một phần của sự hợp tác phát triển vòng cổ AI cho voi?",
        "options": {
          "A": "TechCrunch",
          "B": "Institute Irnas",
          "C": "Avnet",
          "D": "Smart Parks"
        },
        "answer": "A"
      },
      {
        "question": "Xu hướng nào đang ngày càng được sử dụng để bảo vệ động vật hoang dã?",
        "options": {
          "A": "Sử dụng các biện pháp răn đe pháp lý mạnh mẽ hơn.",
          "B": "Tăng cường tuần tra và giám sát bằng trực thăng.",
          "C": "Sử dụng trí tuệ nhân tạo (AI).",
          "D": "Xây dựng các khu bảo tồn thiên nhiên rộng lớn hơn."
        },
        "answer": "C"
      },
      {
        "question": "Ước tính hiện tại có khoảng bao nhiêu con voi hoang dã còn lại ở châu Phi?",
        "options": {
          "A": "Khoảng 150,000",
          "B": "Khoảng 250,000",
          "C": "Khoảng 350,000",
          "D": "Khoảng 450,000"
        },
        "answer": "C"
      },
      {
        "question": "Mỗi năm, ước tính có bao nhiêu con voi bị giết bất hợp pháp bởi những kẻ săn trộm?",
        "options": {
          "A": "Dưới 5,000",
          "B": "Từ 5,000 đến 10,000",
          "C": "Từ 10,000 đến 15,000",
          "D": "Trên 15,000"
        },
        "answer": "D"
      },
      {
        "question": "Cụm từ 'elephant in the room' được sử dụng trong bài viết có ý nghĩa gì?",
        "options": {
          "A": "Sự cần thiết phải bảo tồn voi như một biểu tượng của châu Phi.",
          "B": "Vấn đề lớn và rõ ràng nhưng thường bị bỏ qua hoặc né tránh.",
          "C": "Sự khó khăn trong việc theo dõi và bảo vệ voi trong môi trường sống tự nhiên.",
          "D": "Sự phức tạp của việc giải quyết vấn đề săn trộm voi."
        },
        "answer": "B"
      }
    ]
  },
  "algorithms-for-orcas": {
    "title": "Algorithms for Orcas",
    "collection": "science",
    "content": "A combination of computer vision and drones could help restore dwindling killer whale populations.What’s new:Researchers at Oregon State University and conservation groupsSR3andVulcandeveloped asystemthat assesses the health of orcas,Geekwirereported.How it works:The researchers fly drones off the coast of British Columbia and Washington State to capture video of orcas as they swim near the water’s surface. Four machine learning models collectively called Aquatic Mammal Photogrammetry Tool analyze the imagery.\n\nBehind the news:Conservationists are getting help from machine learning across the animal kingdom.\n\nWhy it matters:With detailed information about the health of individual creatures, conservationists can respond more quickly when they’re in trouble. The developers plan to open-source their work so it can be adapted to other populations of orcas and possibly other species of aquatic mammals.We’re thinking:The Pacific Northwest orca population has shrunk to 75 individuals, the lowest number in 30 years. We hope for a rebound.",
    "qa": [
      {
        "question": "Công nghệ nào được kết hợp để giúp phục hồi số lượng cá voi sát thủ?",
        "options": {
          "A": "Trí tuệ nhân tạo và robot",
          "B": "Thị giác máy tính và máy bay không người lái",
          "C": "Hệ thống định vị toàn cầu và cảm biến",
          "D": "Công nghệ sinh học và phân tích gen"
        },
        "answer": "B"
      },
      {
        "question": "Tổ chức nào KHÔNG tham gia vào việc phát triển hệ thống đánh giá sức khỏe cá voi sát thủ?",
        "options": {
          "A": "Oregon State University",
          "B": "SR3",
          "C": "Vulcan",
          "D": "Greenpeace"
        },
        "answer": "D"
      },
      {
        "question": "Hệ thống đánh giá sức khỏe cá voi sát thủ hoạt động bằng cách nào?",
        "options": {
          "A": "Gắn thiết bị theo dõi vào cá voi",
          "B": "Phân tích video quay từ máy bay không người lái",
          "C": "Thu thập mẫu nước để phân tích DNA",
          "D": "Sử dụng sóng siêu âm để theo dõi cá voi"
        },
        "answer": "B"
      },
      {
        "question": "Công cụ phân tích hình ảnh cá voi sát thủ được gọi là gì?",
        "options": {
          "A": "Aquatic Animal Tracking System",
          "B": "Marine Mammal Health Analyzer",
          "C": "Aquatic Mammal Photogrammetry Tool",
          "D": "Oceanic Wildlife Monitoring Program"
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích chính của việc sử dụng machine learning trong bảo tồn động vật là gì?",
        "options": {
          "A": "Giảm chi phí nghiên cứu",
          "B": "Cung cấp thông tin chi tiết về sức khỏe cá thể",
          "C": "Tăng cường khả năng theo dõi động vật di cư",
          "D": "Cải thiện phương pháp nhân giống động vật"
        },
        "answer": "B"
      },
      {
        "question": "Các nhà phát triển dự định làm gì với công cụ của họ để giúp bảo tồn cá voi sát thủ?",
        "options": {
          "A": "Bán công cụ cho các tổ chức bảo tồn",
          "B": "Giữ bí mật công nghệ để đảm bảo tính độc quyền",
          "C": "Mở mã nguồn công cụ để có thể được điều chỉnh cho các quần thể khác",
          "D": "Chỉ sử dụng công cụ cho quần thể cá voi sát thủ ở Thái Bình Dương"
        },
        "answer": "C"
      },
      {
        "question": "Số lượng cá voi sát thủ ở khu vực Tây Bắc Thái Bình Dương hiện tại là bao nhiêu?",
        "options": {
          "A": "50",
          "B": "75",
          "C": "100",
          "D": "125"
        },
        "answer": "B"
      },
      {
        "question": "Số lượng cá voi sát thủ hiện tại ở Tây Bắc Thái Bình Dương so với 30 năm trước như thế nào?",
        "options": {
          "A": "Cao hơn",
          "B": "Tương đương",
          "C": "Thấp hơn",
          "D": "Không có dữ liệu so sánh"
        },
        "answer": "C"
      },
      {
        "question": "Địa điểm chính mà các nhà nghiên cứu sử dụng máy bay không người lái để thu thập dữ liệu về cá voi sát thủ là ở đâu?",
        "options": {
          "A": "California và Oregon",
          "B": "British Columbia và Washington State",
          "C": "Alaska và Hawaii",
          "D": "Florida và Georgia"
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu cuối cùng của dự án này là gì?",
        "options": {
          "A": "Nghiên cứu hành vi di cư của cá voi sát thủ",
          "B": "Phát triển công nghệ máy bay không người lái tiên tiến",
          "C": "Phục hồi số lượng cá voi sát thủ",
          "D": "Xây dựng cơ sở dữ liệu toàn diện về các loài động vật biển có vú"
        },
        "answer": "C"
      }
    ]
  },
  "alphageometry-a-system-that-nears-expert-proficiency-in-proving-complex-geometry-theorems": {
    "title": "Learning the Language of Geometry",
    "collection": "ml-research",
    "content": "Machine learning algorithms often struggle with geometry. A language model learned to prove relatively difficult theorems.\n\nWhat's new:Trieu Trinh, Yuhuai Wu, Quoc Le, and colleagues at Google and New York University proposedAlphaGeometry, a system that can prove geometry theorems almost as well as the most accomplished high school students. The authors focused on non-combinatorial Euclidean plane geometry.\n\nHow it works:AlphaGeometry has two components. (i) Given a geometrical premise and an unproven proposition, an off-the-shelfgeometric proof finderderived statements that followed from the premise. The authors modified the proof finder to deduce proofs from not only geometric concepts but also algebraic concepts such as ratios, angles, and distances. (ii) A transformer learned to read and write proofs in the proof finder’s specialized language.\n\nResults:The authors tested AlphaGeometry on 30 problems posed by the International Mathematical Olympiad, an annual competition for high school students. AlphaGeometry solved 25 of them correctly. Comparing that achievement to human performance isn’t so straightforward because human competitors can receive partial credit. Human gold medalists since 2000 solved 25.9 problems correctly, silver medalists solved 22.9 problems, and bronze medalists solved 19.3 problems. Theprevious state-of-the-art approachsolved 10 problems, and the modified proof finder solved 14 problems. In one instance, the system identified an unused premise and found a more generalized proof than required, effectively solving many similar problems at once.\n\nWhy it matters:Existing AI systems can juggle symbols and follow simple rules of deduction, but they struggle with steps that human mathematicians represent visually by, say, drawing a diagram. It’s possible to make up this deficit by (i) alternating between a large language model (LLM) and a proof finder, (ii) combining geometric and algebraic reasoning, and (iii) training the LLM on a large data set. The result is a breakthrough for geometric problem solving.\n\nWe're thinking:In 1993, the teenaged Andrew Ng represented Singapore in the International Mathematics Olympiad, where hewona silver medal. AI’s recent progress in solving hard problems is a sine of the times!",
    "qa": [
      {
        "question": "AlphaGeometry được phát triển bởi tổ chức nào?",
        "options": {
          "A": "Stanford University và Microsoft",
          "B": "Google và New York University",
          "C": "MIT và DeepMind",
          "D": "Cambridge University và OpenAI"
        },
        "answer": "B"
      },
      {
        "question": "AlphaGeometry tập trung giải quyết loại hình học nào?",
        "options": {
          "A": "Hình học phi Euclid",
          "B": "Hình học Euclid phẳng phi tổ hợp",
          "C": "Hình học không gian",
          "D": "Hình học vi phân"
        },
        "answer": "B"
      },
      {
        "question": "AlphaGeometry bao gồm mấy thành phần chính?",
        "options": {
          "A": "Một thành phần",
          "B": "Hai thành phần",
          "C": "Ba thành phần",
          "D": "Bốn thành phần"
        },
        "answer": "B"
      },
      {
        "question": "Thành phần nào của AlphaGeometry có khả năng đọc và viết chứng minh?",
        "options": {
          "A": "Bộ tìm chứng minh hình học (geometric proof finder)",
          "B": "Transformer",
          "C": "Bộ tiền xử lý dữ liệu",
          "D": "Bộ tối ưu hóa thuật toán"
        },
        "answer": "B"
      },
      {
        "question": "AlphaGeometry đã giải được bao nhiêu bài toán trong số 30 bài toán của kỳ thi Olympic Toán Quốc tế (IMO)?",
        "options": {
          "A": "10",
          "B": "14",
          "C": "25",
          "D": "28"
        },
        "answer": "C"
      },
      {
        "question": "So với người đạt huy chương vàng IMO, AlphaGeometry giải được số lượng bài toán như thế nào?",
        "options": {
          "A": "Giải được nhiều hơn",
          "B": "Giải được ít hơn một chút",
          "C": "Giải được bằng",
          "D": "Không thể so sánh do khác biệt về cách chấm điểm"
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp tiếp cận trước đây (state-of-the-art) đã giải được bao nhiêu bài toán IMO?",
        "options": {
          "A": "5",
          "B": "10",
          "C": "14",
          "D": "20"
        },
        "answer": "B"
      },
      {
        "question": "Điểm mới nào giúp AlphaGeometry vượt trội so với các hệ thống AI hiện có trong giải toán hình học?",
        "options": {
          "A": "Chỉ sử dụng suy luận đại số",
          "B": "Chỉ sử dụng suy luận hình học",
          "C": "Kết hợp suy luận hình học và đại số, cùng với LLM được huấn luyện trên bộ dữ liệu lớn",
          "D": "Sử dụng một mạng nơ-ron duy nhất"
        },
        "answer": "C"
      },
      {
        "question": "Andrew Ng đã đạt được thành tích gì tại kỳ thi Olympic Toán Quốc tế?",
        "options": {
          "A": "Huy chương vàng",
          "B": "Huy chương bạc",
          "C": "Huy chương đồng",
          "D": "Không tham gia"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết kết luận rằng sự tiến bộ của AI trong việc giải các bài toán khó là dấu hiệu của điều gì?",
        "options": {
          "A": "Sự suy giảm của trí tuệ con người",
          "B": "Sự phát triển vượt bậc của công nghệ",
          "C": "Sự cần thiết phải thay thế con người bằng máy móc",
          "D": "Một xu hướng tất yếu của thời đại"
        },
        "answer": "D"
      }
    ]
  },
  "an-ai-powered-microscope-that-helps-pathologists-detect-cancer": {
    "title": "Sharper Vision for Cancer",
    "collection": "science",
    "content": "A microscope enhanced with augmented reality is helping pathologists recognize cancerous tissue.\n\nWhat’s new:The United States Department of Defense is usingmicroscopesthat use machine learning models based on research from Google to detect cancers.How it works:The microscope, which costs $90,000 to $100,000, looks like a typical lab instrument, but it connects to a computer that superimposes the output of computer vision models over the view. Two controlled studies are underway at government hospitals, Defense Department research centers, and at the Mitre Corp., a nonprofit technology lab, where 13 units have been integrated into the regular pathology workflow.\n\nBehind the news:Google researchersproposedan AI-powered augmented reality microscope in 2018, andpublishedits research inNaturein 2019. The U.S. government joined the project in 2020. A 2022 paperdemonstratedthe breast-cancer algorithm’s success at detecting tumors in lymph nodes.\n\nWhy it matters:Cancer can be deadly, and early identification of a cancer’s type — and thus how aggressive it is — is a key to effective treatment. Microscopes equipped with computer vision can help pathologists diagnose tumors faster and more accurately. They also may be useful for training new pathologists to identify cancers visually.We’re thinking:Some previous medical AI projects, after initialexcitement, turned out to behardto operationalize due to variations in the surrounding environment and other factors. The relatively controlled nature of pathology samples seems like a good bet for deployment of augmented-reality microscopes. We look forward to the conclusions of the currently ongoing studies.",
    "qa": [
      {
        "question": "Công nghệ mới nào đang được sử dụng để hỗ trợ các nhà nghiên cứu bệnh học trong việc nhận diện mô ung thư?",
        "options": {
          "A": "Kính hiển vi điện tử quét (SEM)",
          "B": "Kính hiển vi thực tế tăng cường (augmented reality microscope)",
          "C": "Kính hiển vi huỳnh quang (fluorescence microscope)",
          "D": "Kính hiển vi tương phản pha (phase contrast microscope)"
        },
        "answer": "B"
      },
      {
        "question": "Cơ quan nào của Hoa Kỳ đang sử dụng kính hiển vi hỗ trợ bởi trí tuệ nhân tạo để phát hiện ung thư?",
        "options": {
          "A": "Cục Quản lý Thực phẩm và Dược phẩm (FDA)",
          "B": "Bộ Quốc phòng (Department of Defense)",
          "C": "Viện Y tế Quốc gia (NIH)",
          "D": "Trung tâm Kiểm soát và Phòng ngừa Dịch bệnh (CDC)"
        },
        "answer": "B"
      },
      {
        "question": "Kính hiển vi thực tế tăng cường hoạt động bằng cách nào?",
        "options": {
          "A": "Sử dụng tia laser để phân tích cấu trúc tế bào.",
          "B": "Kết nối với máy tính để chồng kết quả của mô hình thị giác máy tính lên hình ảnh hiển thị.",
          "C": "Tự động nhuộm màu các tế bào ung thư để dễ nhận biết hơn.",
          "D": "Tăng độ phóng đại lên mức chưa từng có để quan sát chi tiết hơn."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu về kính hiển vi thực tế tăng cường do Google đề xuất lần đầu tiên được công bố vào năm nào?",
        "options": {
          "A": "2016",
          "B": "2017",
          "C": "2018",
          "D": "2019"
        },
        "answer": "C"
      },
      {
        "question": "Bài báo năm 2022 đã chứng minh thành công của thuật toán AI trong việc phát hiện loại ung thư nào?",
        "options": {
          "A": "Ung thư phổi",
          "B": "Ung thư vú",
          "C": "Ung thư tuyến tiền liệt",
          "D": "Ung thư da"
        },
        "answer": "B"
      },
      {
        "question": "Việc xác định sớm loại ung thư có tầm quan trọng như thế nào trong điều trị?",
        "options": {
          "A": "Không quan trọng, vì tất cả các loại ung thư đều được điều trị giống nhau.",
          "B": "Quan trọng, vì nó giúp xác định mức độ xâm lấn của ung thư và lựa chọn phương pháp điều trị hiệu quả.",
          "C": "Chỉ quan trọng đối với một số loại ung thư nhất định.",
          "D": "Chỉ quan trọng trong giai đoạn cuối của bệnh."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài việc chẩn đoán, kính hiển vi hỗ trợ bởi thị giác máy tính còn có thể hữu ích trong lĩnh vực nào khác?",
        "options": {
          "A": "Phát triển thuốc mới.",
          "B": "Đào tạo các nhà nghiên cứu bệnh học mới.",
          "C": "Phẫu thuật ung thư.",
          "D": "Chăm sóc giảm nhẹ cho bệnh nhân ung thư."
        },
        "answer": "B"
      },
      {
        "question": "Một thách thức tiềm ẩn đối với việc triển khai các dự án AI y tế, bao gồm cả kính hiển vi thực tế tăng cường, là gì?",
        "options": {
          "A": "Chi phí quá cao.",
          "B": "Sự biến đổi trong môi trường xung quanh và các yếu tố khác.",
          "C": "Thiếu dữ liệu để huấn luyện mô hình AI.",
          "D": "Sự phản đối từ các bác sĩ."
        },
        "answer": "B"
      },
      {
        "question": "Môi trường nào được coi là phù hợp cho việc triển khai kính hiển vi thực tế tăng cường?",
        "options": {
          "A": "Môi trường phẫu thuật.",
          "B": "Môi trường phòng thí nghiệm bệnh học với các mẫu được kiểm soát.",
          "C": "Môi trường chăm sóc tại nhà.",
          "D": "Môi trường cấp cứu."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích của các nghiên cứu đang được tiến hành về kính hiển vi thực tế tăng cường là gì?",
        "options": {
          "A": "Xác định giá thành sản xuất hàng loạt.",
          "B": "Đánh giá hiệu quả và tính khả thi của việc triển khai trong thực tế.",
          "C": "So sánh với các phương pháp chẩn đoán ung thư khác.",
          "D": "Tìm kiếm các ứng dụng mới ngoài chẩn đoán ung thư."
        },
        "answer": "B"
      }
    ]
  },
  "birdwatching-with-ai": {
    "title": "Birdwatching With AI",
    "collection": "science",
    "content": "Neural networks learned to tell one bird from another, enabling scientists to study their behavior in greater detail.What’s new:Researchers from universities in Europe and Africa trained neural networks to recognize individual birds with up to 90 percent accuracy, as detailed inMethods in Ecology and Evolution.How it works:Researchers collected data by attaching radio-frequency identification tags to 35 of the African songbirds known as sociable weavers. Then they set up cameras to snap pictures, tagged with each creature’s identity, automatically whenever one entered a feeding area.\n\nBehind the news:AI is increasingly useful for identifying individuals of various animal species, includingchimpanzees,elephants, andpigs.Why it matters:The researchers aimed to learn how sociable weavers cooperate to build large, communal nests. Catching, tagging, and observing animals in the wild takes a lot of time and effort. AI that automates the process can free up researchers to focus on extracting insights from the behavioral data they gather.We’re thinking:Now birds are getting the face recognition tweetment!",
    "qa": [
      {
        "question": "Mục đích chính của nghiên cứu được đề cập trong bài viết là gì?",
        "options": {
          "A": "Phát triển công nghệ nhận diện khuôn mặt cho các loài chim.",
          "B": "Nghiên cứu hành vi hợp tác xây tổ của chim sẻ thợ dệt châu Phi.",
          "C": "Tìm hiểu cách chim sẻ thợ dệt châu Phi giao tiếp với nhau.",
          "D": "Cải thiện độ chính xác của việc gắn thẻ RFID cho động vật hoang dã."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã sử dụng phương pháp nào để thu thập dữ liệu về chim sẻ thợ dệt?",
        "options": {
          "A": "Quan sát trực tiếp và ghi chép thủ công.",
          "B": "Gắn thẻ RFID và sử dụng camera tự động chụp ảnh.",
          "C": "Sử dụng micro gắn trên chim để ghi âm tiếng kêu.",
          "D": "Phân tích DNA để xác định cá thể chim."
        },
        "answer": "B"
      },
      {
        "question": "Mạng nơ-ron trong nghiên cứu này có độ chính xác nhận diện chim cá thể là bao nhiêu?",
        "options": {
          "A": "50%",
          "B": "70%",
          "C": "90%",
          "D": "100%"
        },
        "answer": "C"
      },
      {
        "question": "Công nghệ AI đang được ứng dụng để nhận diện những loài động vật nào khác ngoài chim?",
        "options": {
          "A": "Sư tử, hổ, báo.",
          "B": "Tinh tinh, voi, lợn.",
          "C": "Cá heo, hải cẩu, rái cá.",
          "D": "Gấu trúc, gấu Bắc cực, gấu nâu."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích chính của việc sử dụng AI trong nghiên cứu hành vi động vật là gì?",
        "options": {
          "A": "Giảm chi phí nghiên cứu.",
          "B": "Tăng tốc độ thu thập dữ liệu.",
          "C": "Giải phóng thời gian cho các nhà nghiên cứu để tập trung vào phân tích dữ liệu.",
          "D": "Loại bỏ hoàn toàn nhu cầu quan sát trực tiếp động vật."
        },
        "answer": "C"
      },
      {
        "question": "Loại chim nào được nghiên cứu trong bài viết này?",
        "options": {
          "A": "Chim sẻ thường.",
          "B": "Chim sẻ thợ dệt châu Phi.",
          "C": "Chim bồ câu.",
          "D": "Chim đại bàng."
        },
        "answer": "B"
      },
      {
        "question": "Thông tin chi tiết về nghiên cứu này được công bố ở đâu?",
        "options": {
          "A": "Nature.",
          "B": "Science.",
          "C": "Methods in Ecology and Evolution.",
          "D": "Proceedings of the National Academy of Sciences."
        },
        "answer": "C"
      },
      {
        "question": "Các nhà nghiên cứu đã gắn thiết bị gì lên chim sẻ thợ dệt để thu thập dữ liệu?",
        "options": {
          "A": "Máy ghi âm.",
          "B": "Thiết bị GPS.",
          "C": "Thẻ RFID.",
          "D": "Cảm biến nhiệt độ."
        },
        "answer": "C"
      },
      {
        "question": "Cụm từ 'face recognition tweetment' ở cuối bài viết ám chỉ điều gì?",
        "options": {
          "A": "Việc sử dụng Twitter để chia sẻ thông tin về nghiên cứu.",
          "B": "Sự tương đồng giữa việc nhận diện khuôn mặt người và nhận diện chim.",
          "C": "Việc chim sẻ thợ dệt hót líu lo giống như đang tweet.",
          "D": "Sự phát triển của công nghệ nhận diện khuôn mặt trên các nền tảng mạng xã hội."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đặc biệt về tổ của chim sẻ thợ dệt châu Phi?",
        "options": {
          "A": "Chúng được xây dựng dưới lòng đất.",
          "B": "Chúng có kích thước rất nhỏ.",
          "C": "Chúng là tổ cộng đồng lớn.",
          "D": "Chúng được làm từ bùn và đất sét."
        },
        "answer": "C"
      }
    ]
  },
  "brain-implants-paired-with-neural-network-reconstruct-speech-for-als-patient": {
    "title": "A Lost Voice Regained",
    "collection": "science",
    "content": "A man who lost the ability to speak four years ago is sounding like his earlier self, thanks to a collection of brain implants and machine learning models.\n\nWhat’s new:Researchers built a system thatdecodes speech signals from the brainof a man who lost the ability to speak clearly due to amyotrophic lateral sclerosis, also known as ALS, and enables him to speak through a synthetic version of his former voice. At the start of the study, his efforts to speak were intelligible only to his personal caregiver. Now he converses regularly with family and friends,The New York Timesreported. Nicholas Card built the system with colleagues University of California-Davis, Stanford University, Washington University, Brown University, VA Providence Healthcare, and Harvard Medical School.\n\nHow it works:The authors surgically implanted four electrode arrays into areas of the brain that are responsible for speech. The system learned to decode the patient’s brain signals, decide the most likely phonemes he intended to speak, determine the words those phonemes express, and display and speak the words aloud using a personalized speech synthesizer.\n\nResults:After two hours of recording the patient’s brain signals and training on that data, the system achieved 90.2 percent accuracy in the copying task. By the final session, the system achieved 97.5 percent accuracy and enabled the patient to speak on average 31.6 words per minute using a vocabulary of 125,000 words.\n\nBehind the news:Previous work either had muchlower accuracyor generated alimited vocabulary. The new work improved upon a 2023studythat enabled ALS patients to speak with 76.2 percent accuracy using a vocabulary of equal size.\n\nWhy it matters:Relative to the 2023 study on which this one was based, the authors changed the positions of the electrodes in the brain and continued to update the GRU throughout the recording/training sessions. It’s unclear which changes contributed most to the improved outcome. As language models improve, new models potentially could act as drop-in replacements for the models in the authors’ system, further improving accuracy. Likewise, improvements in speech-to-text systems could increase the similarity between the synthetic voice and the patient’s former voice.\n\nWe’re thinking:Enabling someone to speak again restores agency. Enabling someone to speak again in their own voice restores identity.",
    "qa": [
      {
        "question": "Công nghệ mới giúp người mất khả năng nói có thể giao tiếp trở lại nhờ vào yếu tố chính nào?",
        "options": {
          "A": "Thuốc đặc trị ALS và liệu pháp ngôn ngữ chuyên sâu.",
          "B": "Hệ thống cấy ghép não và mô hình học máy.",
          "C": "Phẫu thuật tái tạo dây thanh quản và kích thích điện.",
          "D": "Ứng dụng phiên dịch ngôn ngữ và thiết bị hỗ trợ phát âm."
        },
        "answer": "B"
      },
      {
        "question": "Trước khi sử dụng hệ thống mới, khả năng giao tiếp của bệnh nhân ALS được mô tả như thế nào?",
        "options": {
          "A": "Anh ấy có thể giao tiếp trôi chảy với bất kỳ ai.",
          "B": "Anh ấy chỉ có thể được hiểu bởi người chăm sóc cá nhân.",
          "C": "Anh ấy có thể viết nhưng không thể nói.",
          "D": "Anh ấy có thể sử dụng ngôn ngữ ký hiệu để giao tiếp."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống mới hoạt động bằng cách nào để giải mã tín hiệu não thành lời nói?",
        "options": {
          "A": "Sử dụng sóng não để điều khiển một robot phiên dịch.",
          "B": "Giải mã tín hiệu não, xác định âm vị, từ ngữ và phát ra âm thanh bằng bộ tổng hợp giọng nói.",
          "C": "Chuyển đổi suy nghĩ thành văn bản và đọc văn bản đó thành tiếng.",
          "D": "Phân tích biểu cảm khuôn mặt và chuyển đổi chúng thành lời nói."
        },
        "answer": "B"
      },
      {
        "question": "Độ chính xác của hệ thống trong việc sao chép lời nói của bệnh nhân sau hai giờ huấn luyện là bao nhiêu?",
        "options": {
          "A": "76.2%",
          "B": "90.2%",
          "C": "97.5%",
          "D": "100%"
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống mới cho phép bệnh nhân nói trung bình bao nhiêu từ mỗi phút?",
        "options": {
          "A": "15.8 từ",
          "B": "31.6 từ",
          "C": "63.2 từ",
          "D": "125 từ"
        },
        "answer": "B"
      },
      {
        "question": "Điểm cải tiến chính của nghiên cứu này so với nghiên cứu năm 2023 là gì?",
        "options": {
          "A": "Sử dụng một loại điện cực mới.",
          "B": "Độ chính xác cao hơn và vị trí điện cực trong não được thay đổi.",
          "C": "Sử dụng một bộ từ vựng lớn hơn nhiều.",
          "D": "Không cần phẫu thuật cấy ghép điện cực."
        },
        "answer": "B"
      },
      {
        "question": "Số lượng từ vựng mà hệ thống có thể sử dụng là bao nhiêu?",
        "options": {
          "A": "125 từ",
          "B": "1,250 từ",
          "C": "12,500 từ",
          "D": "125,000 từ"
        },
        "answer": "D"
      },
      {
        "question": "Điều gì có thể cải thiện độ chính xác của hệ thống trong tương lai?",
        "options": {
          "A": "Sử dụng các loại thuốc mới để tăng cường hoạt động não.",
          "B": "Cải tiến mô hình ngôn ngữ và hệ thống chuyển giọng nói thành văn bản.",
          "C": "Tăng cường luyện tập thể chất cho bệnh nhân.",
          "D": "Sử dụng các phương pháp thôi miên để kích thích trí nhớ."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã cấy bao nhiêu điện cực vào não bệnh nhân?",
        "options": {
          "A": "Một điện cực",
          "B": "Hai điện cực",
          "C": "Ba điện cực",
          "D": "Bốn điện cực"
        },
        "answer": "D"
      },
      {
        "question": "Ý nghĩa sâu sắc nhất của việc giúp một người nói lại được bằng chính giọng nói của họ là gì?",
        "options": {
          "A": "Giúp họ tiết kiệm chi phí giao tiếp.",
          "B": "Khôi phục bản sắc cá nhân của họ.",
          "C": "Giúp họ tìm được công việc mới.",
          "D": "Giúp họ dễ dàng học ngoại ngữ hơn."
        },
        "answer": "B"
      }
    ]
  },
  "brain2qwerty-a-system-that-decodes-thoughts-using-brain-waves-without-surgery": {
    "title": "Reading Minds, No Brain Implant Required",
    "collection": "science",
    "content": "To date, efforts to decode what people are thinking from their brain waves often relied on electrodes implanted in the cortex. New work used devices outside the head to pick up brain signals that enabled an AI system, as a subject typed, to accurately guess what they were typing.\n\nWhat’s new:Researchers presentedBrain2Qwerty, a non-invasive method to translate brain waves into text. In addition, their workshed lighton how the brain processes language. The team included people at Meta, Paris Sciences et Lettres University, Hospital Foundation Adolphe de Rothschild, Basque Center on Cognition, Brain and Language, Basque Foundation for Science, Aix-Marseille University, and Paris Cité University.\n\nGathering brainwave data:The authors recorded the brain activity of 35 healthy participants who typed Spanish-language sentences. The participants were connected to either an electroencephalogram (EEG), which records the brain’s electrical activity via electrodes on the scalp, or a magnetoencephalogram (MEG), which records magnetic activity through a device that surrounds the head but isn’t attached. 15 participants used each device and five used both.\n\nThoughts into text:Brain2Qwerty used a system made up of a convolutional neural network, transformer, and a9-gram character-level language modelpretrained on Spanish Wikipedia. The system classified the text a user typed from their brain activity. The authors trained separate systems on MEG and EEG data.\n\nResults.The authors’ MEG model achieved 32 percent character error rate (CER), much higher accuracy than the EEG competitors. Their EEG system outperformedEEGNet, a model designed to process EEG data that had been trained on the authors’ EEG data. It achieved 67 percent CER, while EEGNet achieved 78 percent CER.\n\nBehind the news:For decades, researchers have used learning algorithms to interpret various aspects of brain activity with varying degrees of success. In recent years, they’ve used neural networks togeneratetextandspeechfrom implanted electrodes, generateimagesof whatpeople seewhile in an fMRI, and enable people tocontrol robotsusing EEG signals.\n\nWhy it matters:In research into interpreting brain signals, subjects who are outfitted with surgical implants typically have supplied the highest-quality brain signals. fMRI scans, while similarly noninvasive, are less precise temporally, which makes them less useful for monitoring or predicting language production. Effective systems based on MEG, which can tap brain signals precisely without requiring participants to undergo surgery, open the door to collecting far more data, training far more robust models, and conducting a wider variety of experiments.\n\nWe’re thinking:The privacy implications of such research may be troubling, but keep in mind that Brain2Qwerty’s MEG system, which was the most effective approach tested, required patients to spend extended periods of time sitting still in a shielded room. We aren’t going to read minds in the wild anytime soon.",
    "qa": [
      {
        "question": "Phương pháp Brain2Qwerty sử dụng loại dữ liệu nào để dịch sóng não thành văn bản?",
        "options": {
          "A": "Dữ liệu từ điện cực cấy ghép trực tiếp vào vỏ não.",
          "B": "Dữ liệu từ điện não đồ (EEG) và từ não đồ (MEG).",
          "C": "Dữ liệu từ chụp cộng hưởng từ chức năng (fMRI).",
          "D": "Dữ liệu từ các cảm biến sinh học gắn trên cơ thể."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Brain2Qwerty sử dụng công nghệ AI nào để phân loại văn bản từ hoạt động não?",
        "options": {
          "A": "Mạng nơ-ron hồi quy (RNN).",
          "B": "Mạng nơ-ron tích chập (CNN), Transformer và mô hình ngôn ngữ n-gram.",
          "C": "Máy học tăng cường (Reinforcement Learning).",
          "D": "Mạng nơ-ron đối nghịch (GAN)."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả nghiên cứu cho thấy mô hình nào của Brain2Qwerty đạt độ chính xác cao hơn?",
        "options": {
          "A": "Mô hình sử dụng dữ liệu EEG.",
          "B": "Mô hình sử dụng dữ liệu MEG.",
          "C": "Cả hai mô hình có độ chính xác tương đương.",
          "D": "Mô hình kết hợp dữ liệu EEG và MEG."
        },
        "answer": "B"
      },
      {
        "question": "Tỷ lệ lỗi ký tự (CER) mà mô hình MEG của Brain2Qwerty đạt được là bao nhiêu?",
        "options": {
          "A": "78%",
          "B": "67%",
          "C": "32%",
          "D": "12%"
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc sử dụng các phương pháp không xâm lấn như MEG trong nghiên cứu giải mã tín hiệu não là gì?",
        "options": {
          "A": "Tăng cường độ chính xác của tín hiệu não.",
          "B": "Thu thập dữ liệu từ nhiều đối tượng hơn và thực hiện nhiều thí nghiệm đa dạng hơn.",
          "C": "Giảm chi phí nghiên cứu.",
          "D": "Đơn giản hóa quy trình xử lý dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Điểm yếu của phương pháp fMRI so với MEG trong việc theo dõi và dự đoán quá trình sản xuất ngôn ngữ là gì?",
        "options": {
          "A": "fMRI yêu cầu phẫu thuật cấy ghép.",
          "B": "fMRI ít chính xác về mặt thời gian.",
          "C": "fMRI không thể thu thập dữ liệu từ não.",
          "D": "fMRI có độ phân giải không gian kém hơn."
        },
        "answer": "B"
      },
      {
        "question": "Ngôn ngữ nào được sử dụng trong các câu mà người tham gia gõ trong nghiên cứu Brain2Qwerty?",
        "options": {
          "A": "Tiếng Anh.",
          "B": "Tiếng Pháp.",
          "C": "Tiếng Tây Ban Nha.",
          "D": "Tiếng Đức."
        },
        "answer": "C"
      },
      {
        "question": "Trong bối cảnh nghiên cứu giải mã tín hiệu não, ưu điểm lớn nhất của việc sử dụng cấy ghép phẫu thuật là gì?",
        "options": {
          "A": "Dễ dàng thu thập dữ liệu hơn.",
          "B": "Cung cấp tín hiệu não chất lượng cao nhất.",
          "C": "Giảm thiểu rủi ro cho người tham gia.",
          "D": "Cho phép theo dõi hoạt động não trong thời gian dài hơn."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình EEGNet được sử dụng trong nghiên cứu này với vai trò gì?",
        "options": {
          "A": "Mô hình chính để dịch sóng não thành văn bản.",
          "B": "Mô hình so sánh để đánh giá hiệu quả của Brain2Qwerty.",
          "C": "Mô hình để tiền xử lý dữ liệu EEG.",
          "D": "Mô hình để tạo ra dữ liệu EEG giả lập."
        },
        "answer": "B"
      },
      {
        "question": "Một trong những hạn chế hiện tại của hệ thống Brain2Qwerty, đặc biệt là mô hình MEG, là gì?",
        "options": {
          "A": "Yêu cầu người tham gia phải trải qua phẫu thuật.",
          "B": "Yêu cầu người tham gia phải ngồi yên trong phòng cách ly trong thời gian dài.",
          "C": "Không thể xử lý dữ liệu từ nhiều người tham gia cùng một lúc.",
          "D": "Chỉ hoạt động với một số ngôn ngữ nhất định."
        },
        "answer": "B"
      }
    ]
  },
  "bugbot": {
    "title": "Bugbot",
    "collection": "science",
    "content": "An insect-sorting robot could help scientists grapple with the global biodiversity crisis.\n\nWhat’s new:Anautomated insect classifiersucks in tiny arthropods, classifies them, and maps their most important identifying features. It was developed by researchers at Karlsruhe Institute of Technology, Berlin Natural History Museum, Bavarian State Collection of Zoology, Sapienza University of Rome, and National University of Singapore.\n\nHow it works:The bot integrates systems that transport insects in and out, snap photos of them, and process the images. A touch screen serves as the user interface and displays model output. The authors pretrained aVGG19convolutional neural network on ImageNet and fine-tuned it using 4,325 images of insects plus augmentations.\n\nResults:In testing, the system scored an average of 91.4 percent precision across all species — good butnot up to the level of a human expert.\n\nBehind the news:This is just the latest use of AI in the time-consuming task of insect identification.\n\nWe’re thinking:If this system stopped working, someone would have to debug it.",
    "qa": [
      {
        "question": "Mục đích chính của robot phân loại côn trùng là gì?",
        "options": {
          "A": "Thay thế hoàn toàn các nhà khoa học trong việc nghiên cứu côn trùng.",
          "B": "Hỗ trợ các nhà khoa học giải quyết khủng hoảng đa dạng sinh học toàn cầu.",
          "C": "Thu thập và lưu trữ hình ảnh côn trùng cho mục đích thương mại.",
          "D": "Nghiên cứu và phát triển các loại thuốc trừ sâu mới."
        },
        "answer": "B"
      },
      {
        "question": "Robot phân loại côn trùng được phát triển bởi những tổ chức nào?",
        "options": {
          "A": "Chỉ bởi Karlsruhe Institute of Technology.",
          "B": "Một nhóm các nhà nghiên cứu độc lập từ khắp nơi trên thế giới.",
          "C": "Một liên minh giữa Karlsruhe Institute of Technology, Berlin Natural History Museum, Bavarian State Collection of Zoology, Sapienza University of Rome, và National University of Singapore.",
          "D": "Chính phủ Đức và Singapore."
        },
        "answer": "C"
      },
      {
        "question": "Robot phân loại côn trùng hoạt động bằng cách nào?",
        "options": {
          "A": "Sử dụng sóng siêu âm để xác định loài côn trùng.",
          "B": "Hút côn trùng, chụp ảnh và xử lý hình ảnh bằng mạng nơ-ron tích chập.",
          "C": "Phân tích DNA của côn trùng để xác định loài.",
          "D": "Sử dụng cảm biến nhiệt để phát hiện và phân loại côn trùng."
        },
        "answer": "B"
      },
      {
        "question": "Mạng nơ-ron tích chập VGG19 được huấn luyện trên dữ liệu nào trước khi được tinh chỉnh cho việc phân loại côn trùng?",
        "options": {
          "A": "Dữ liệu âm thanh của côn trùng.",
          "B": "Dữ liệu hình ảnh từ ImageNet.",
          "C": "Dữ liệu DNA của côn trùng.",
          "D": "Dữ liệu cảm biến nhiệt của côn trùng."
        },
        "answer": "B"
      },
      {
        "question": "Độ chính xác trung bình của hệ thống trong quá trình thử nghiệm là bao nhiêu?",
        "options": {
          "A": "Gần như tuyệt đối, đạt 99.9%.",
          "B": "Cao hơn so với chuyên gia con người.",
          "C": "Trung bình 91.4% trên tất cả các loài.",
          "D": "Chỉ khoảng 50%, cần cải thiện thêm."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến điều gì về việc sử dụng AI trong việc xác định côn trùng?",
        "options": {
          "A": "Đây là lần đầu tiên AI được sử dụng trong lĩnh vực này.",
          "B": "AI hoàn toàn không hiệu quả trong việc xác định côn trùng.",
          "C": "Đây chỉ là một trong những ứng dụng mới nhất của AI trong công việc tốn thời gian là xác định côn trùng.",
          "D": "AI chỉ được sử dụng để xác định các loài côn trùng quý hiếm."
        },
        "answer": "C"
      },
      {
        "question": "Giao diện người dùng của robot phân loại côn trùng là gì?",
        "options": {
          "A": "Một bàn phím và chuột.",
          "B": "Một màn hình cảm ứng hiển thị kết quả của mô hình.",
          "C": "Một hệ thống điều khiển bằng giọng nói.",
          "D": "Một ứng dụng trên điện thoại thông minh."
        },
        "answer": "B"
      },
      {
        "question": "Số lượng hình ảnh côn trùng được sử dụng để tinh chỉnh mạng nơ-ron VGG19 là bao nhiêu (bao gồm cả dữ liệu tăng cường)?",
        "options": {
          "A": "Chỉ 4,325 hình ảnh.",
          "B": "Ít hơn 1000 hình ảnh.",
          "C": "4,325 hình ảnh cộng với dữ liệu tăng cường.",
          "D": "Hàng triệu hình ảnh."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì sẽ xảy ra nếu hệ thống robot phân loại côn trùng ngừng hoạt động?",
        "options": {
          "A": "Không ai có thể sửa chữa nó.",
          "B": "Một chuyên gia về AI sẽ phải gỡ lỗi nó.",
          "C": "Một nhà khoa học sẽ phải gỡ lỗi nó.",
          "D": "Ai đó sẽ phải gỡ lỗi nó."
        },
        "answer": "D"
      },
      {
        "question": "Điểm yếu lớn nhất của hệ thống robot phân loại côn trùng so với chuyên gia con người là gì?",
        "options": {
          "A": "Tốc độ phân loại chậm hơn.",
          "B": "Độ chính xác thấp hơn.",
          "C": "Khả năng xử lý các loài côn trùng mới kém hơn.",
          "D": "Chi phí vận hành cao hơn."
        },
        "answer": "B"
      }
    ]
  },
  "cancer-in-the-crosshairs": {
    "title": "Cancer in the Crosshairs",
    "collection": "science",
    "content": "Computer vision has potential to spot cancer earlier and more accurately than human experts. A new system surpassed human accuracy in trials, but critics aren’t convinced.What’s new:A computer vision model for diagnosing breast cancer outperformed radiologists in the U.S. and UK, according to a study published inNature. The announcement, however, met with skepticism from some experts.How it works:Researchers at Google Health, DeepMind, and other organizations trained a model on 76,000 X-ray images from one U.S. clinic and 30,000 from two UK screening centers. Each image came with data from a follow up visit at least a year later, when doctors either confirmed or ruled out a tumor. The researchers graded the model’s accuracy against average diagnostic accuracy in each country’s health care system.\n\nYes, but:The studyfacedcriticismthat the dataset, model, and procedural details were not available to researchers aiming to reproduce its results. Moreover, experts said the images used in the new studydidn’t adequately representthe at-risk population, according to the Advisory Board, a healthcare consultancy. Incidence of breast cancer in the sample dataset was higher than average, and the images weren’t annotated with the patients’ genetic heritage — which could skew the results, because some ethnic groups are at greater risk of developing tumors.Behind the news:Google’s study overshadowed earlierresultsfrom NYU, where researchers trained a similar model to detect cancer in mammograms. Their model scored highly on images that had been verified independently, and it matched the performance of a panel of 12 radiologists. The researchers also found that a hybrid model — which averaged a human radiologist’s decision with the model’s prediction — outperformed either one separately.Why it matters:Worldwide, breast canceraccountsfor 12 percent of all cancer cases. The disease has been on the rise since 2008, with confirmed cases increasing by 20 percent and mortality by 14 percent. Meanwhile, the UKsuffersa shortage of trained radiologists. Effective AI-driven detection could save countless lives.We’re thinking:Google and NYU are both making strides in computer vision for medical diagnosis, though clearly Google has a much larger PR team. We urge reporters to cover a diverse range of AI projects.",
    "qa": [
      {
        "question": "Mục tiêu chính của hệ thống computer vision được đề cập trong bài viết là gì?",
        "options": {
          "A": "Thay thế hoàn toàn các bác sĩ X-quang.",
          "B": "Phát hiện ung thư vú sớm và chính xác hơn so với các chuyên gia.",
          "C": "Nghiên cứu các phương pháp điều trị ung thư vú mới.",
          "D": "Tự động phân tích dữ liệu di truyền của bệnh nhân ung thư."
        },
        "answer": "B"
      },
      {
        "question": "Nguồn gốc dữ liệu được sử dụng để huấn luyện mô hình computer vision của Google đến từ đâu?",
        "options": {
          "A": "Chỉ từ các bệnh viện ở Hoa Kỳ.",
          "B": "Chỉ từ các trung tâm sàng lọc ở Vương quốc Anh.",
          "C": "Từ một phòng khám ở Hoa Kỳ và hai trung tâm sàng lọc ở Vương quốc Anh.",
          "D": "Từ các nghiên cứu trên toàn thế giới về ung thư vú."
        },
        "answer": "C"
      },
      {
        "question": "Một trong những chỉ trích chính đối với nghiên cứu của Google là gì?",
        "options": {
          "A": "Mô hình không đủ mạnh để xử lý lượng dữ liệu lớn.",
          "B": "Dữ liệu và quy trình không được công khai để các nhà nghiên cứu khác kiểm chứng.",
          "C": "Kết quả nghiên cứu không được công bố trên tạp chí khoa học uy tín.",
          "D": "Mô hình chỉ hoạt động tốt trên một loại ung thư vú cụ thể."
        },
        "answer": "B"
      },
      {
        "question": "Theo Advisory Board, một vấn đề với dữ liệu hình ảnh được sử dụng trong nghiên cứu của Google là gì?",
        "options": {
          "A": "Chất lượng hình ảnh quá thấp để phân tích chính xác.",
          "B": "Tỷ lệ mắc ung thư vú trong bộ dữ liệu cao hơn mức trung bình.",
          "C": "Hình ảnh không được chụp bằng công nghệ X-quang hiện đại nhất.",
          "D": "Dữ liệu không bao gồm thông tin về độ tuổi của bệnh nhân."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu của NYU sử dụng phương pháp nào để cải thiện hiệu suất phát hiện ung thư?",
        "options": {
          "A": "Sử dụng dữ liệu từ nhiều quốc gia khác nhau.",
          "B": "Kết hợp quyết định của bác sĩ X-quang với dự đoán của mô hình.",
          "C": "Tập trung vào việc phát hiện các loại ung thư vú hiếm gặp.",
          "D": "Sử dụng thuật toán học sâu tiên tiến nhất."
        },
        "answer": "B"
      },
      {
        "question": "Tỷ lệ ung thư vú trên tổng số ca ung thư trên toàn thế giới là bao nhiêu?",
        "options": {
          "A": "5 phần trăm.",
          "B": "8 phần trăm.",
          "C": "12 phần trăm.",
          "D": "15 phần trăm."
        },
        "answer": "C"
      },
      {
        "question": "Tình hình ung thư vú trên toàn thế giới từ năm 2008 đến nay được mô tả như thế nào?",
        "options": {
          "A": "Số ca mắc và tỷ lệ tử vong đều giảm.",
          "B": "Số ca mắc tăng, nhưng tỷ lệ tử vong giảm.",
          "C": "Số ca mắc giảm, nhưng tỷ lệ tử vong tăng.",
          "D": "Số ca mắc và tỷ lệ tử vong đều tăng."
        },
        "answer": "D"
      },
      {
        "question": "Một trong những vấn đề mà Vương quốc Anh đang phải đối mặt liên quan đến việc phát hiện ung thư vú là gì?",
        "options": {
          "A": "Thiếu trang thiết bị y tế hiện đại.",
          "B": "Thiếu bác sĩ X-quang được đào tạo.",
          "C": "Chi phí sàng lọc ung thư vú quá cao.",
          "D": "Tỷ lệ người dân tham gia sàng lọc ung thư vú thấp."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về việc đưa tin về các dự án AI trong lĩnh vực y tế?",
        "options": {
          "A": "Chỉ nên tập trung vào các dự án lớn của các công ty công nghệ hàng đầu.",
          "B": "Nên bao gồm một loạt các dự án AI đa dạng.",
          "C": "Nên ưu tiên các dự án có khả năng thương mại hóa cao.",
          "D": "Nên tránh đưa tin về các dự án còn đang trong giai đoạn thử nghiệm."
        },
        "answer": "B"
      },
      {
        "question": "Yếu tố nào có thể làm sai lệch kết quả của mô hình do sự khác biệt về di truyền giữa các nhóm dân tộc?",
        "options": {
          "A": "Sự khác biệt về lối sống.",
          "B": "Sự khác biệt về chế độ ăn uống.",
          "C": "Sự khác biệt về nguy cơ phát triển khối u.",
          "D": "Sự khác biệt về khả năng tiếp cận dịch vụ y tế."
        },
        "answer": "C"
      }
    ]
  },
  "caught-bearfaced": {
    "title": "Caught Bearfaced",
    "collection": "science",
    "content": "Many people worry that face recognition is intrusive, but wild animals seem to find it bearable.What’s new:Melanie Clapham at University of Victoria with teammates of theBearID Projectdeveloped a model that performsface recognition for brown bears.How it works:BearID recognizes individual bears with 84 percent accuracy. It comprises four components: bearface, bearchip, bearembed, and bearsvm.\n\nBehind the news:Face recognition systems have been built for a growing number of non-human species, includingchimpanzees,lemurs, andpandas.Why it matters:By providing a low-cost way to track individual animals, apps like BearID could help researchers and conservationists map habitats for protection and monitor the health of animal populations. Clapham has been experimenting with the model in the field, and the team hopes to pair it with camera traps, which would allow researchers to monitor large wild populations.We’re thinking:We’re so impressed, we can bearly contain our appaws!",
    "qa": [
      {
        "question": "Dự án BearID được phát triển bởi ai?",
        "options": {
          "A": "Một nhóm các nhà nghiên cứu độc lập.",
          "B": "Melanie Clapham và các đồng nghiệp tại Đại học Victoria.",
          "C": "Một tổ chức bảo tồn động vật hoang dã quốc tế.",
          "D": "Một công ty công nghệ chuyên về nhận diện khuôn mặt."
        },
        "answer": "B"
      },
      {
        "question": "Độ chính xác của mô hình BearID trong việc nhận diện gấu nâu là bao nhiêu?",
        "options": {
          "A": "Khoảng 75%.",
          "B": "Khoảng 84%.",
          "C": "Khoảng 90%.",
          "D": "Gần như tuyệt đối (99%)."
        },
        "answer": "B"
      },
      {
        "question": "BearID bao gồm bao nhiêu thành phần chính?",
        "options": {
          "A": "3",
          "B": "4",
          "C": "5",
          "D": "6"
        },
        "answer": "B"
      },
      {
        "question": "Ngoài gấu nâu, hệ thống nhận diện khuôn mặt đã được xây dựng cho những loài động vật nào khác?",
        "options": {
          "A": "Sư tử, hổ, báo.",
          "B": "Voi, tê giác, hươu cao cổ.",
          "C": "Tinh tinh, vượn cáo, gấu trúc.",
          "D": "Cá voi, cá heo, hải cẩu."
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích chính của các ứng dụng như BearID trong nghiên cứu và bảo tồn động vật là gì?",
        "options": {
          "A": "Cung cấp phương pháp theo dõi động vật cá thể với chi phí thấp.",
          "B": "Giúp huấn luyện động vật hoang dã dễ dàng hơn.",
          "C": "Cho phép du khách dễ dàng nhận biết các loài động vật khác nhau.",
          "D": "Tăng cường khả năng giao tiếp giữa con người và động vật."
        },
        "answer": "A"
      },
      {
        "question": "Melanie Clapham và nhóm của cô ấy hy vọng sẽ kết hợp mô hình BearID với công cụ nào?",
        "options": {
          "A": "Thiết bị định vị GPS.",
          "B": "Máy ảnh bẫy.",
          "C": "Micro gắn trên động vật.",
          "D": "Drone (thiết bị bay không người lái)."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của việc sử dụng máy ảnh bẫy kết hợp với BearID là gì?",
        "options": {
          "A": "Thu thập hình ảnh đẹp về động vật hoang dã.",
          "B": "Giám sát các quần thể động vật hoang dã lớn.",
          "C": "Phát hiện các hành vi bất thường của động vật.",
          "D": "Ngăn chặn nạn săn bắn trái phép."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì khiến nhiều người lo lắng về công nghệ nhận diện khuôn mặt?",
        "options": {
          "A": "Chi phí phát triển quá cao.",
          "B": "Tính xâm phạm quyền riêng tư.",
          "C": "Độ chính xác còn hạn chế.",
          "D": "Khả năng bị lạm dụng vào mục đích xấu."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích của việc lập bản đồ môi trường sống của động vật thông qua các ứng dụng như BearID là gì?",
        "options": {
          "A": "Để phục vụ mục đích du lịch sinh thái.",
          "B": "Để bảo vệ môi trường sống của chúng.",
          "C": "Để khai thác tài nguyên thiên nhiên hiệu quả hơn.",
          "D": "Để di dời động vật đến các khu vực an toàn hơn."
        },
        "answer": "B"
      },
      {
        "question": "Thành phần nào của BearID được đề cập đến nhưng không được giải thích cụ thể trong bài viết?",
        "options": {
          "A": "bearface",
          "B": "bearchip",
          "C": "bearembed",
          "D": "bearsvm"
        },
        "answer": "B"
      }
    ]
  },
  "chatgpt-may-ease-loneliness-but-increase-dependence-studies-suggest": {
    "title": "Chatbot Use Creates Emotional Bonds",
    "collection": "science",
    "content": "A pair of papers investigate how increasingly human-like chatbots affect users’ emotions.\n\nWhat’s new:Jason Phang at OpenAI, Cathy Mengying Fang at MIT Media Lab, and colleagues at those organizations publishedcomplementarystudiesthat examine ChatGPT’s influence on loneliness, social interactions, emotional dependence, and potentially problematic use.\n\nHow it works:One study was a large-scale analysis of real-world conversations, and the other was a randomized control trial that tracked conversations of a selected cohort. Both evaluated conversations according toEmoClassifiersV1, a set of classifiers based on large language models that evaluate five top-level emotional classes (loneliness, dependence, and the like) and 20 sub-classes of emotional indicators (seeking support, use of pet names, and so on).\n\nResults:Both studies found that using ChatGPT was associated with reduced loneliness and increased emotional chat. However, it was also associated with decreased interpersonal social interaction and greater dependence on the chatbot, especially among users who spent more time chatting.\n\nYes, but:The authors of the randomized controlled trial acknowledged significant limitations. For instance, the study lacked a non-ChatGPT control group to differentiate AI-specific effects from influences such as seasonal emotional shifts, and the trial’s time frame and assignments may not mirror real-world behavior.\n\nWhy it matters:As AI chatbot behavior becomes more human-like, people may lean on large language models to satisfy emotional needs such as easinglonelinessorgrief. Yet we know little about their effects. These studies offer a starting point for AI developers who want to both foster emotional support and protect against over-reliance, and for social scientists who want to better understand the impact of chatbots.\n\nWe’re thinking:Social media turned out to causeemotional harmto some people in ways that were not obvious when the technology was new. As chatbots evolve, research like this can help us steer them toward protecting and enhancing mental health.",
    "qa": [
      {
        "question": "Nghiên cứu của Jason Phang và Cathy Mengying Fang tập trung vào ảnh hưởng của ChatGPT lên những khía cạnh nào của người dùng?",
        "options": {
          "A": "Năng suất làm việc, khả năng sáng tạo và kỹ năng giao tiếp.",
          "B": "Sự cô đơn, tương tác xã hội, sự phụ thuộc cảm xúc và khả năng sử dụng có vấn đề.",
          "C": "Khả năng học tập, trí nhớ và sự tập trung.",
          "D": "Sức khỏe thể chất, giấc ngủ và chế độ ăn uống."
        },
        "answer": "B"
      },
      {
        "question": "Hai nghiên cứu được đề cập trong bài viết sử dụng phương pháp nào để đánh giá các cuộc trò chuyện?",
        "options": {
          "A": "Phỏng vấn trực tiếp người dùng và phân tích nhật ký hoạt động trực tuyến.",
          "B": "Phân tích quy mô lớn các cuộc trò chuyện thực tế và thử nghiệm đối chứng ngẫu nhiên.",
          "C": "Khảo sát trực tuyến và phân tích dữ liệu từ mạng xã hội.",
          "D": "Thử nghiệm trong phòng thí nghiệm và theo dõi hoạt động não bộ."
        },
        "answer": "B"
      },
      {
        "question": "EmoClassifiersV1 là gì?",
        "options": {
          "A": "Một công cụ đánh giá hiệu quả của các mô hình ngôn ngữ lớn.",
          "B": "Một bộ phân loại dựa trên mô hình ngôn ngữ lớn để đánh giá các lớp cảm xúc.",
          "C": "Một phương pháp mã hóa dữ liệu cảm xúc trong các cuộc trò chuyện.",
          "D": "Một thuật toán để tạo ra các cuộc trò chuyện cảm xúc tự nhiên."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả của các nghiên cứu cho thấy việc sử dụng ChatGPT có liên quan đến điều gì?",
        "options": {
          "A": "Tăng cường tương tác xã hội và giảm sự cô đơn.",
          "B": "Giảm sự cô đơn và tăng cường trò chuyện cảm xúc, nhưng giảm tương tác xã hội và tăng sự phụ thuộc.",
          "C": "Tăng cường sự sáng tạo và giảm căng thẳng.",
          "D": "Giảm sự lo lắng và cải thiện giấc ngủ."
        },
        "answer": "B"
      },
      {
        "question": "Một trong những hạn chế được các tác giả của thử nghiệm đối chứng ngẫu nhiên thừa nhận là gì?",
        "options": {
          "A": "Thiếu dữ liệu về nhân khẩu học của người tham gia.",
          "B": "Thiếu nhóm đối chứng không sử dụng ChatGPT để phân biệt các ảnh hưởng cụ thể của AI.",
          "C": "Sử dụng các phương pháp thống kê không phù hợp.",
          "D": "Thời gian thử nghiệm quá ngắn để thu thập đủ dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao các nghiên cứu này lại quan trọng?",
        "options": {
          "A": "Chúng cung cấp thông tin chi tiết về cách cải thiện hiệu suất của ChatGPT.",
          "B": "Chúng cung cấp điểm khởi đầu cho các nhà phát triển AI và khoa học xã hội để hiểu rõ hơn về tác động của chatbot lên cảm xúc.",
          "C": "Chúng giúp xác định các thuật toán tốt nhất để xây dựng chatbot.",
          "D": "Chúng chứng minh rằng chatbot có thể thay thế hoàn toàn các tương tác xã hội thực tế."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết liên hệ tác động tiềm tàng của chatbot với tác động của công nghệ nào trong quá khứ?",
        "options": {
          "A": "Điện thoại di động.",
          "B": "Mạng xã hội.",
          "C": "Email.",
          "D": "Trò chơi điện tử."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu của nghiên cứu về chatbot, theo bài viết, là gì?",
        "options": {
          "A": "Tối ưu hóa lợi nhuận cho các công ty phát triển chatbot.",
          "B": "Định hướng chatbot để bảo vệ và tăng cường sức khỏe tinh thần.",
          "C": "Thay thế các liệu pháp tâm lý truyền thống bằng chatbot.",
          "D": "Phát triển chatbot có khả năng thay thế hoàn toàn con người trong giao tiếp."
        },
        "answer": "B"
      },
      {
        "question": "Theo nghiên cứu, điều gì xảy ra khi người dùng dành nhiều thời gian trò chuyện với ChatGPT?",
        "options": {
          "A": "Họ trở nên ít phụ thuộc vào chatbot hơn.",
          "B": "Họ trở nên phụ thuộc vào chatbot nhiều hơn.",
          "C": "Không có sự thay đổi đáng kể về mức độ phụ thuộc.",
          "D": "Họ cải thiện kỹ năng giao tiếp xã hội."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu sử dụng những loại chỉ số cảm xúc nào để đánh giá các cuộc trò chuyện?",
        "options": {
          "A": "Chỉ số về sự hài lòng, hạnh phúc và hứng thú.",
          "B": "Chỉ số về sự cô đơn, phụ thuộc và các chỉ báo cảm xúc phụ như tìm kiếm sự hỗ trợ và sử dụng tên gọi thân mật.",
          "C": "Chỉ số về sự tức giận, sợ hãi và buồn bã.",
          "D": "Chỉ số về sự tin tưởng, tôn trọng và yêu thương."
        },
        "answer": "B"
      }
    ]
  },
  "chimp-recognition": {
    "title": "Chimp Recognition",
    "collection": "science",
    "content": "AI is capable of picking faces out of the crowd — even if that crowd is squabbling over bananas in a jungle.\n\nWhat’s new:Researchers at the University of Oxford developed aface recognition appthat identifies individual chimpanzees in footage shot in the wilds of Guinea. The work could give wildlife conservation efforts a powerful new tool.\n\nHow it works:The group adapted the VGG-M convolutional neural network architecture. They trained the model on roughly 50 hours of footage representing 23 individuals over 14 years.\n\nBehind the news:Zoologists have embraced image recognition for conservation efforts. The technology is countinggiraffesin Africa and trackingwolverinesin the Pacific Northwest. An innovative application called WildBook that trawls YouTube for wildlife videos has been used to catalogwhale sharkmigrations.\n\nWhy it matters:Chimpanzees, like humans, are highly social animals. The ability to track individuals enabled the researchers to map the tribe’s structure. The model generalized well to other primate species in preliminary tests. The researchers suggest that their approach could be used with other animals where a sufficient video record exists.\n\nWe’re thinking:Applications like this could help cash-strapped conservation efforts to focus on translating data into action, and reduce the need for invasive, labor-intensive methods like tagging animals with RFID.",
    "qa": [
      {
        "question": "Ứng dụng nhận diện khuôn mặt mới được phát triển bởi Đại học Oxford có khả năng gì?",
        "options": {
          "A": "Nhận diện tất cả các loài động vật trong tự nhiên.",
          "B": "Nhận diện từng cá thể tinh tinh trong các đoạn phim quay ở Guinea.",
          "C": "Phân biệt các loại trái cây khác nhau trong rừng.",
          "D": "Dự đoán hành vi của tinh tinh dựa trên biểu cảm khuôn mặt."
        },
        "answer": "B"
      },
      {
        "question": "Mạng nơ-ron tích chập VGG-M đã được sử dụng như thế nào trong nghiên cứu này?",
        "options": {
          "A": "Để tạo ra các đoạn phim về tinh tinh.",
          "B": "Để huấn luyện mô hình nhận diện khuôn mặt tinh tinh.",
          "C": "Để phân tích cấu trúc xã hội của tinh tinh.",
          "D": "Để theo dõi sự di cư của tinh tinh."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu huấn luyện cho mô hình nhận diện khuôn mặt tinh tinh bao gồm những gì?",
        "options": {
          "A": "Hình ảnh tĩnh của 23 cá thể tinh tinh.",
          "B": "Khoảng 50 giờ phim về 23 cá thể tinh tinh trong 14 năm.",
          "C": "Dữ liệu GPS về vị trí của 23 cá thể tinh tinh.",
          "D": "Thông tin về chế độ ăn uống của 23 cá thể tinh tinh."
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ nhận diện hình ảnh đã được ứng dụng trong bảo tồn động vật hoang dã như thế nào?",
        "options": {
          "A": "Chỉ được sử dụng để đếm số lượng hươu cao cổ ở Châu Phi.",
          "B": "Chỉ được sử dụng để theo dõi chồn sói ở Tây Bắc Thái Bình Dương.",
          "C": "Được sử dụng để đếm hươu cao cổ, theo dõi chồn sói và lập danh mục di cư của cá mập voi.",
          "D": "Chỉ được sử dụng để phân tích DNA của các loài động vật hoang dã."
        },
        "answer": "C"
      },
      {
        "question": "Ứng dụng WildBook được sử dụng để làm gì?",
        "options": {
          "A": "Theo dõi sự di cư của các loài chim.",
          "B": "Lập danh mục di cư của cá mập voi.",
          "C": "Phân tích tiếng kêu của các loài động vật hoang dã.",
          "D": "Dự đoán thời tiết dựa trên hành vi của động vật."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc theo dõi từng cá thể tinh tinh lại quan trọng?",
        "options": {
          "A": "Để xác định tuổi thọ trung bình của tinh tinh.",
          "B": "Để lập bản đồ cấu trúc xã hội của bầy tinh tinh.",
          "C": "Để nghiên cứu sự tiến hóa của tinh tinh.",
          "D": "Để tìm hiểu về kỹ năng sử dụng công cụ của tinh tinh."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả ban đầu cho thấy mô hình nhận diện khuôn mặt tinh tinh có khả năng gì?",
        "options": {
          "A": "Chỉ hoạt động tốt với tinh tinh.",
          "B": "Không hoạt động tốt với bất kỳ loài linh trưởng nào khác.",
          "C": "Có thể khái quát hóa tốt cho các loài linh trưởng khác.",
          "D": "Chỉ hoạt động tốt với tinh tinh đực."
        },
        "answer": "C"
      },
      {
        "question": "Các nhà nghiên cứu đề xuất phương pháp của họ có thể được sử dụng cho những trường hợp nào?",
        "options": {
          "A": "Chỉ những loài động vật có nguy cơ tuyệt chủng.",
          "B": "Chỉ những loài động vật sống trong môi trường hoang dã.",
          "C": "Những loài động vật có đủ dữ liệu video.",
          "D": "Chỉ những loài động vật có khuôn mặt dễ nhận diện."
        },
        "answer": "C"
      },
      {
        "question": "Ứng dụng nhận diện khuôn mặt động vật có thể giúp ích gì cho các nỗ lực bảo tồn?",
        "options": {
          "A": "Giảm chi phí cho việc nghiên cứu DNA của động vật.",
          "B": "Tăng cường khả năng xâm lấn vào môi trường sống của động vật.",
          "C": "Tập trung vào việc chuyển đổi dữ liệu thành hành động và giảm sự cần thiết của các phương pháp xâm lấn.",
          "D": "Thay thế hoàn toàn các phương pháp theo dõi truyền thống."
        },
        "answer": "C"
      },
      {
        "question": "RFID (Radio-Frequency Identification) được đề cập trong bài viết với vai trò gì?",
        "options": {
          "A": "Một công nghệ mới để nhận diện khuôn mặt động vật.",
          "B": "Một phương pháp xâm lấn và tốn kém để theo dõi động vật.",
          "C": "Một công cụ để phân tích DNA của động vật.",
          "D": "Một phương pháp để tạo ra các đoạn phim về động vật hoang dã."
        },
        "answer": "B"
      }
    ]
  },
  "coding-framework-llamaindex-enables-data-interaction-with-llms": {
    "title": "Letting Chatbots See Your Data",
    "collection": "science",
    "content": "A new coding framework lets you pipe your own data into large language models.\n\nWhat’s new:LlamaIndexstreamlines the coding involved in enabling developers to summarize, reason over, and otherwise manipulate data from documents, databases, and apps using models like GPT-4.How it works:LlamaIndex is a free Pythonlibrarythat works with any large language model.\n\nBehind the news:Former Uber research scientist Jerry Liu began building LlamaIndex (originally GPT Index) in late 2022 and co-founded a company around it earlier this year. The company, which recentlyreceived$8.5 million in seed funding, plans to launch an enterprise version later this year.Why it matters:Developing bespoke apps that use a large language model typically requires building custom programs to parse private databases. LlamaIndex offers a more direct route.We’re thinking:Large language models are excitingnew tools for developing AI applications. Libraries like LlamaIndex andLangChainprovide glue code that makes building complex applications much easier — early entries in a growing suite of tools that promise to make LLMs even more useful.",
    "qa": [
      {
        "question": "LlamaIndex là gì?",
        "options": {
          "A": "Một mô hình ngôn ngữ lớn mới cạnh tranh với GPT-4.",
          "B": "Một thư viện Python miễn phí giúp đơn giản hóa việc sử dụng mô hình ngôn ngữ lớn với dữ liệu.",
          "C": "Một công ty khởi nghiệp chuyên về phát triển ứng dụng AI.",
          "D": "Một ngôn ngữ lập trình mới được thiết kế cho AI."
        },
        "answer": "B"
      },
      {
        "question": "LlamaIndex cho phép nhà phát triển làm gì với dữ liệu?",
        "options": {
          "A": "Tạo ra các mô hình ngôn ngữ lớn mới từ dữ liệu.",
          "B": "Tóm tắt, suy luận và thao tác dữ liệu từ tài liệu, cơ sở dữ liệu và ứng dụng bằng các mô hình ngôn ngữ lớn.",
          "C": "Mã hóa và bảo mật dữ liệu trước khi đưa vào mô hình ngôn ngữ lớn.",
          "D": "Chuyển đổi dữ liệu sang định dạng phù hợp với các mô hình ngôn ngữ lớn."
        },
        "answer": "B"
      },
      {
        "question": "Ai là người bắt đầu xây dựng LlamaIndex?",
        "options": {
          "A": "Một nhóm các nhà nghiên cứu tại Google.",
          "B": "Jerry Liu, một cựu nhà khoa học nghiên cứu tại Uber.",
          "C": "Các nhà phát triển của OpenAI.",
          "D": "Một cộng đồng mã nguồn mở lớn."
        },
        "answer": "B"
      },
      {
        "question": "LlamaIndex (ban đầu) có tên gọi là gì?",
        "options": {
          "A": "AI Index.",
          "B": "Data Index.",
          "C": "GPT Index.",
          "D": "Language Index."
        },
        "answer": "C"
      },
      {
        "question": "Công ty đứng sau LlamaIndex đã nhận được bao nhiêu vốn đầu tư ban đầu?",
        "options": {
          "A": "$5 triệu.",
          "B": "$10 triệu.",
          "C": "$8.5 triệu.",
          "D": "$12 triệu."
        },
        "answer": "C"
      },
      {
        "question": "Phiên bản doanh nghiệp của LlamaIndex dự kiến ra mắt khi nào?",
        "options": {
          "A": "Đã ra mắt vào đầu năm nay.",
          "B": "Cuối năm nay.",
          "C": "Đầu năm sau.",
          "D": "Chưa có kế hoạch cụ thể."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích chính của LlamaIndex là gì?",
        "options": {
          "A": "Giảm chi phí đào tạo các mô hình ngôn ngữ lớn.",
          "B": "Cung cấp một con đường trực tiếp hơn để phát triển các ứng dụng tùy chỉnh sử dụng mô hình ngôn ngữ lớn.",
          "C": "Tăng cường khả năng bảo mật cho dữ liệu được sử dụng bởi các mô hình ngôn ngữ lớn.",
          "D": "Tự động hóa quá trình tạo ra các mô hình ngôn ngữ lớn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến thư viện nào khác cùng loại với LlamaIndex?",
        "options": {
          "A": "TensorFlow.",
          "B": "PyTorch.",
          "C": "LangChain.",
          "D": "Scikit-learn."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích của các thư viện như LlamaIndex và LangChain là gì?",
        "options": {
          "A": "Thay thế các mô hình ngôn ngữ lớn.",
          "B": "Cung cấp mã 'keo' giúp xây dựng các ứng dụng phức tạp dễ dàng hơn.",
          "C": "Tối ưu hóa hiệu suất của các mô hình ngôn ngữ lớn.",
          "D": "Tạo ra các giao diện người dùng cho các mô hình ngôn ngữ lớn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đánh giá như thế nào về các mô hình ngôn ngữ lớn?",
        "options": {
          "A": "Chúng là những công cụ đã lỗi thời.",
          "B": "Chúng là những công cụ mới thú vị để phát triển các ứng dụng AI.",
          "C": "Chúng chỉ hữu ích cho một số ứng dụng cụ thể.",
          "D": "Chúng quá phức tạp để sử dụng rộng rãi."
        },
        "answer": "B"
      }
    ]
  },
  "crowdsourcing-against-coronavirus": {
    "title": "Crowdsourcing Against Coronavirus",
    "collection": "science",
    "content": "Covid Moonshot, an open-source project to vet potential medicines using machine learning, is closing in on compounds that might help curb Covid-19.What’s new:Four new antiviral drugs identified by the project are ready to advance to animal trials, according toIEEE Spectrum. Unlike vaccines, which prevent infection,antiviralstreat people who are already infected.How it works:Last spring, PostEra, a UK chemistry company, invited scientists to submit designs for molecules with potential to thwart the virus. It used asemisupervised deep learning platformto analyze more than 14,000 submissions. You can read our earlier report on the projecthere.\n\nBehind the news:Covid Moonshot does not seek to profit from its effort. If any of its compounds successfully complete animal trials, which could happen by mid-2021, they will enter human clinical trials. If they pass that test, they will be made available to drug makers at no cost to manufacture and distribute.Why it matters:Antivirals typically are far less expensive to produce and easier to distribute than vaccines. These drugs could help keep the pandemic in check while inoculations make their way through the global population.We’re thinking:Although vaccines are beginning to roll out, now is no time to relax. Keep social distancing and hand washing until public-health experts say otherwise.",
    "qa": [
      {
        "question": "Dự án Covid Moonshot sử dụng công nghệ nào để sàng lọc các loại thuốc tiềm năng?",
        "options": {
          "A": "Thử nghiệm lâm sàng trực tiếp trên người.",
          "B": "Học máy (machine learning).",
          "C": "Phân tích hóa học truyền thống.",
          "D": "Mô phỏng trên máy tính lượng tử."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính giữa thuốc kháng virus (antivirals) và vaccine là gì?",
        "options": {
          "A": "Vaccine rẻ hơn thuốc kháng virus.",
          "B": "Thuốc kháng virus ngăn ngừa nhiễm trùng, vaccine điều trị người đã nhiễm bệnh.",
          "C": "Vaccine ngăn ngừa nhiễm trùng, thuốc kháng virus điều trị người đã nhiễm bệnh.",
          "D": "Thuốc kháng virus dễ sản xuất hơn vaccine."
        },
        "answer": "C"
      },
      {
        "question": "Công ty nào đã mời các nhà khoa học gửi thiết kế phân tử cho dự án Covid Moonshot?",
        "options": {
          "A": "IEEE Spectrum.",
          "B": "WHO.",
          "C": "PostEra.",
          "D": "FDA."
        },
        "answer": "C"
      },
      {
        "question": "Nền tảng học sâu bán giám sát (semisupervised deep learning platform) đã phân tích bao nhiêu thiết kế phân tử?",
        "options": {
          "A": "Hơn 1400.",
          "B": "Hơn 14000.",
          "C": "Hơn 140000.",
          "D": "Hơn 14 triệu."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của Covid Moonshot là gì?",
        "options": {
          "A": "Thu lợi nhuận từ việc phát triển thuốc.",
          "B": "Cạnh tranh với các công ty dược phẩm lớn.",
          "C": "Cung cấp thuốc miễn phí cho các nhà sản xuất để phân phối.",
          "D": "Nghiên cứu vaccine hiệu quả hơn."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, khi nào các hợp chất của Covid Moonshot có thể bắt đầu thử nghiệm lâm sàng trên người (nếu thành công ở thử nghiệm trên động vật)?",
        "options": {
          "A": "Đầu năm 2021.",
          "B": "Giữa năm 2021.",
          "C": "Cuối năm 2021.",
          "D": "Đầu năm 2022."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao thuốc kháng virus lại quan trọng trong bối cảnh đại dịch?",
        "options": {
          "A": "Chúng hiệu quả hơn vaccine trong việc ngăn ngừa lây nhiễm.",
          "B": "Chúng dễ sản xuất và phân phối hơn vaccine.",
          "C": "Chúng đắt tiền hơn vaccine, thúc đẩy nghiên cứu và phát triển.",
          "D": "Chúng chỉ có tác dụng phụ nhẹ."
        },
        "answer": "B"
      },
      {
        "question": "Lời khuyên nào được đưa ra trong bài viết liên quan đến các biện pháp phòng ngừa dịch bệnh?",
        "options": {
          "A": "Nới lỏng giãn cách xã hội sau khi tiêm vaccine.",
          "B": "Ngừng rửa tay sau khi tiêm vaccine.",
          "C": "Tiếp tục giãn cách xã hội và rửa tay cho đến khi có hướng dẫn khác.",
          "D": "Chỉ cần tiêm vaccine là đủ, không cần các biện pháp khác."
        },
        "answer": "C"
      },
      {
        "question": "IEEE Spectrum đưa tin về điều gì liên quan đến dự án Covid Moonshot?",
        "options": {
          "A": "Dự án đã thất bại trong việc tìm ra các hợp chất tiềm năng.",
          "B": "Bốn loại thuốc kháng virus mới đã sẵn sàng cho thử nghiệm trên động vật.",
          "C": "Vaccine của dự án đã được phê duyệt sử dụng.",
          "D": "Dự án đã ngừng hoạt động do thiếu kinh phí."
        },
        "answer": "B"
      },
      {
        "question": "Loại dữ liệu nào được sử dụng để huấn luyện nền tảng học sâu trong dự án Covid Moonshot?",
        "options": {
          "A": "Dữ liệu về các triệu chứng của bệnh nhân Covid-19.",
          "B": "Dữ liệu về cấu trúc protein của virus SARS-CoV-2.",
          "C": "Dữ liệu về thiết kế phân tử của các hợp chất tiềm năng.",
          "D": "Dữ liệu về hiệu quả của các loại vaccine khác nhau."
        },
        "answer": "C"
      }
    ]
  },
  "cutting-the-carbon-cost-of-training": {
    "title": "Cutting the Carbon Cost of Training",
    "collection": "science",
    "content": "You can reduce your model’s carbon emissions by being choosy about when and where you train it.What’s new:Researchers at the Allen Institute for AI, HuggingFace, Microsoft, the University of Washington, Carnegie Mellon University, and the Hebrew University of Jerusalemdevelopeda tool that measures atmospheric carbon emitted by cloud servers while training machine learning models. After a model’s size, the biggest variables were the server’s location and time of day it was active.How it works:The authors’ calculations account for kilowatt hours used by a cloud computing system, emissions from the local electrical grid, and emissions while manufacturing and disposing of the system’s hardware. They based their method on anapproachdeveloped by the Green Software Foundation.\n\nResults:Training a model in a low-emissions region like France and Norway could save over 70 percent of the carbon that would be emitted in a carbon-heavy region like the central United States or Germany.\n\nYes, but:A 2021 study found that large transformersconsumemore energy, and yield more carbon emissions, during inference than training.Behind the news:Energy consumption and the associated carbon emissions are growing concerns as machine learning models and datasets balloon.\n\nWhy it matters:Atmospheric carbon is causing changes in climate that are devastating many communities across the globe. Data centers alone accounted for 1 percent of electricityconsumedglobally in 2020 (although the portion of data center usage devoted to AI is unknown). Machine learning engineers can do their part to reduce carbon emissions by choosing carefully when and where to train models.We’re thinking:It's impractical to expect every team to minimize carbon emissions by choosing times and locations to process training jobs. We urge cloud providers to consider pricing and other signals that would help — better yet, incentivize — engineers to cut emissions.",
    "qa": [
      {
        "question": "Công cụ mới được phát triển bởi các nhà nghiên cứu có chức năng gì?",
        "options": {
          "A": "Tối ưu hóa tốc độ đào tạo mô hình học máy.",
          "B": "Đo lường lượng khí carbon thải ra từ các máy chủ đám mây trong quá trình đào tạo mô hình học máy.",
          "C": "Dự đoán kích thước tối ưu cho mô hình học máy để giảm thiểu năng lượng tiêu thụ.",
          "D": "Phân tích hiệu quả sử dụng năng lượng của các trung tâm dữ liệu trên toàn cầu."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài kích thước mô hình, yếu tố nào ảnh hưởng lớn nhất đến lượng khí thải carbon trong quá trình đào tạo?",
        "options": {
          "A": "Loại thuật toán được sử dụng.",
          "B": "Địa điểm đặt máy chủ và thời gian hoạt động của nó.",
          "C": "Số lượng dữ liệu được sử dụng để đào tạo.",
          "D": "Cấu hình phần cứng của máy chủ."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp tính toán lượng khí thải carbon của các tác giả dựa trên cách tiếp cận nào?",
        "options": {
          "A": "Tiêu chuẩn quốc tế về khí thải nhà kính.",
          "B": "Phương pháp được phát triển bởi Quỹ Phần mềm Xanh.",
          "C": "Dữ liệu thống kê từ các nhà cung cấp dịch vụ đám mây lớn.",
          "D": "Mô hình dự báo khí hậu toàn cầu."
        },
        "answer": "B"
      },
      {
        "question": "Việc đào tạo mô hình ở các khu vực như Pháp và Na Uy có thể tiết kiệm được bao nhiêu phần trăm lượng carbon so với các khu vực có lượng carbon cao?",
        "options": {
          "A": "Khoảng 20%",
          "B": "Khoảng 50%",
          "C": "Hơn 70%",
          "D": "Gần 90%"
        },
        "answer": "C"
      },
      {
        "question": "Một nghiên cứu năm 2021 cho thấy điều gì về mô hình transformer lớn?",
        "options": {
          "A": "Chúng tiêu thụ ít năng lượng hơn trong quá trình suy luận so với đào tạo.",
          "B": "Chúng tạo ra ít khí thải carbon hơn trong quá trình đào tạo so với suy luận.",
          "C": "Chúng tiêu thụ nhiều năng lượng hơn và tạo ra nhiều khí thải carbon hơn trong quá trình suy luận so với đào tạo.",
          "D": "Chúng có hiệu quả năng lượng tương đương trong cả quá trình đào tạo và suy luận."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, các trung tâm dữ liệu chiếm bao nhiêu phần trăm lượng điện tiêu thụ toàn cầu vào năm 2020?",
        "options": {
          "A": "Dưới 0.5%",
          "B": "Khoảng 1%",
          "C": "Khoảng 5%",
          "D": "Hơn 10%"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết khuyến nghị các kỹ sư học máy nên làm gì để giảm lượng khí thải carbon?",
        "options": {
          "A": "Sử dụng các thuật toán học máy hiệu quả hơn.",
          "B": "Chọn thời điểm và địa điểm đào tạo mô hình một cách cẩn thận.",
          "C": "Giảm kích thước của bộ dữ liệu đào tạo.",
          "D": "Tái sử dụng các mô hình đã được đào tạo trước đó."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết kêu gọi ai xem xét việc định giá và các tín hiệu khác để khuyến khích kỹ sư giảm lượng khí thải?",
        "options": {
          "A": "Các chính phủ trên toàn thế giới.",
          "B": "Các nhà cung cấp dịch vụ đám mây.",
          "C": "Các tổ chức phi chính phủ về môi trường.",
          "D": "Các trường đại học và viện nghiên cứu."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đang gây ra những thay đổi khí hậu tàn phá nhiều cộng đồng trên toàn cầu?",
        "options": {
          "A": "Sự suy giảm tầng ozone.",
          "B": "Lượng carbon trong khí quyển.",
          "C": "Ô nhiễm nguồn nước.",
          "D": "Mất đa dạng sinh học."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, mối quan tâm ngày càng tăng liên quan đến mô hình học máy và bộ dữ liệu lớn là gì?",
        "options": {
          "A": "Sự phức tạp của các thuật toán.",
          "B": "Tiêu thụ năng lượng và lượng khí thải carbon liên quan.",
          "C": "Khả năng bảo mật dữ liệu.",
          "D": "Chi phí đào tạo mô hình."
        },
        "answer": "B"
      }
    ]
  },
  "deep-doo-doo": {
    "title": "Deep Doo-Doo",
    "collection": "science",
    "content": "People who suffer from gastrointestinal conditions such as irritable bowel syndrome are number two when it comes to describing the characteristics of their own poop.What’s new:The smartphone appDietahelps patients to keep gastrointestinal illnesses in check by tracking their own behaviors and symptoms. It includes a computer vision model that recognizes medically salient characteristics of excrement as accurately as doctors and better than most patients, a recentstudyfound.How it works:The app enables patients to log symptoms such as nausea, constipation, and abdominal pain; behaviors like exercise, sleep, and meals; treatments including medications, supplements, and diet; and feelings of illness or wellbeing. It also helps patients experiment on themselves, recommending lifestyle changes and treatments and enabling patients to forward the results to caregivers. A computer vision model classifies feces according to characteristics that are useful in diagnosis.\n\nBehind the news:Machine learning engineers have trained other models to peer into the toilet.\n\nWhy it matters:Roughly 40 percent of adults worldwide may suffer from gastrointestinal conditions, according to a 2021study. Tracking bowel movements helps to diagnose these conditions earlier and more accurately.We’re thinking:We’re grateful that someone — other than us — builds models that classify the Bristol Stool Scale.",
    "qa": [
      {
        "question": "Ứng dụng Dieta được thiết kế để giúp những đối tượng nào?",
        "options": {
          "A": "Những người muốn cải thiện chế độ ăn uống.",
          "B": "Những người mắc các bệnh về đường tiêu hóa như hội chứng ruột kích thích.",
          "C": "Các bác sĩ muốn chẩn đoán bệnh chính xác hơn.",
          "D": "Các nhà nghiên cứu về trí tuệ nhân tạo trong y học."
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng Dieta theo dõi những loại thông tin nào của người dùng?",
        "options": {
          "A": "Chỉ các triệu chứng bệnh và loại thuốc đang sử dụng.",
          "B": "Các triệu chứng bệnh, thói quen sinh hoạt, phương pháp điều trị và cảm xúc.",
          "C": "Chế độ ăn uống và mức độ tập thể dục hàng ngày.",
          "D": "Lịch sử bệnh án và thông tin di truyền."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình thị giác máy tính trong ứng dụng Dieta có khả năng gì?",
        "options": {
          "A": "Phân tích thành phần dinh dưỡng của thức ăn.",
          "B": "Nhận diện các đặc điểm y học quan trọng của phân.",
          "C": "Dự đoán nguy cơ mắc bệnh tiêu hóa.",
          "D": "Đề xuất các bài tập thể dục phù hợp."
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng Dieta hỗ trợ người dùng như thế nào trong việc tự thử nghiệm?",
        "options": {
          "A": "Cung cấp thông tin về các loại thuốc mới nhất.",
          "B": "Đề xuất các thay đổi lối sống và phương pháp điều trị.",
          "C": "Kết nối người dùng với các chuyên gia dinh dưỡng.",
          "D": "Theo dõi chỉ số BMI và các chỉ số sức khỏe khác."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, khoảng bao nhiêu phần trăm người trưởng thành trên toàn thế giới có thể mắc các bệnh về đường tiêu hóa?",
        "options": {
          "A": "10%",
          "B": "20%",
          "C": "30%",
          "D": "40%"
        },
        "answer": "D"
      },
      {
        "question": "Tại sao việc theo dõi nhu động ruột lại quan trọng trong việc chẩn đoán bệnh tiêu hóa?",
        "options": {
          "A": "Giúp xác định nguyên nhân gây ra bệnh.",
          "B": "Giúp chẩn đoán bệnh sớm và chính xác hơn.",
          "C": "Giúp giảm chi phí điều trị.",
          "D": "Giúp ngăn ngừa các biến chứng nguy hiểm."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc các kỹ sư học máy huấn luyện các mô hình để 'nhìn vào bồn cầu' là gì?",
        "options": {
          "A": "Để tự động dọn dẹp bồn cầu.",
          "B": "Để phân tích các đặc điểm của phân phục vụ cho mục đích y học.",
          "C": "Để phát hiện các chất độc hại trong nước thải.",
          "D": "Để cải thiện hệ thống thoát nước."
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng Dieta cho phép người dùng chia sẻ kết quả theo dõi với ai?",
        "options": {
          "A": "Chỉ với các nhà nghiên cứu.",
          "B": "Chỉ với các thành viên trong gia đình.",
          "C": "Với những người chăm sóc sức khỏe.",
          "D": "Với bất kỳ ai sử dụng ứng dụng."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì khiến tác giả bài viết 'biết ơn' trong bối cảnh này?",
        "options": {
          "A": "Sự phát triển của công nghệ y tế.",
          "B": "Có người khác xây dựng mô hình phân loại phân theo thang Bristol.",
          "C": "Sự phổ biến của các ứng dụng theo dõi sức khỏe.",
          "D": "Khả năng chẩn đoán bệnh tiêu hóa từ xa."
        },
        "answer": "B"
      },
      {
        "question": "So với bệnh nhân, độ chính xác của mô hình thị giác máy tính trong việc nhận diện đặc điểm phân như thế nào?",
        "options": {
          "A": "Kém chính xác hơn.",
          "B": "Chính xác tương đương.",
          "C": "Chính xác hơn hầu hết bệnh nhân.",
          "D": "Chỉ chính xác hơn trong một số trường hợp đặc biệt."
        },
        "answer": "C"
      }
    ]
  },
  "deep-learning-model-identifies-high-risk-patients-from-ekg-readings": {
    "title": "Heart-Risk Model Saves Lives",
    "collection": "science",
    "content": "A deep learning model significantly reduced deaths among critically ill hospital patients.\n\nWhat’s new:A system built by Chin-Sheng Lin and colleagues at Taiwan’s National Defense Medical Center analyzed patients’ heart signals and alerted physicians if it detected a high risk of death. Itreduceddeaths of high-risk patients by 31 percent in a randomized clinical trial.\n\nHow it works:Researcherstraineda convolutional neural network, given an electrocardiogram (a measurement of the heart’s electrical activity), toestimatea risk score. The system compares a patient’s risk score against those of other patients. Scores that rank in the 95th percentile or higher are considered high risk of death within 90 days.\n\nResults:8.6 percent of patients in the control group and 8.9 percent of patients in the experimental group raised a high-risk alert during the trial. In the experimental group, 16 percent of high-risk patients died; in the control group, 23 percent of high-risk patients died. Overall, in the experimental group, 3.6 percent of patients died; in the control group, 4.3 percent of patients died. The model was trained to predict mortality from all causes, but it showed unusually strong predictive capability for heart-related deaths. Examining causes of death, the authors found that 0.2 percent of patients in the experimental group died from heart-related conditions such as cardiac arrest versus 2.4 percent in the control group.Behind the news:Hospitals use AI-powered alert systems toidentifypatients in need of urgent medical attention. Such systems monitor emergency room patients for sepsis, predict whether those patients need intensive care, and predict the risk that discharged patients will require further care. They help hospitals to allocate resources by directing attention where it’s needed most urgently.Why it matters:It’s rare for any kind of medical intervention to reduce mortality in a subgroup by 31 percent. The authors speculate that the system not only helped direct attention to patients urgently in need of attention but also may have identified electrocardiogram features that doctors typically either don’t understand well or can’t detect.\n\nWe’re thinking:This relatively low-cost AI system unambiguously saved lives over three months at different hospitals! We look forward to seeing it scale up.",
    "qa": [
      {
        "question": "Mục tiêu chính của hệ thống AI được phát triển bởi Chin-Sheng Lin và cộng sự là gì?",
        "options": {
          "A": "Dự đoán nguy cơ mắc bệnh tim ở bệnh nhân.",
          "B": "Giảm tỷ lệ tử vong ở bệnh nhân bệnh nặng trong bệnh viện.",
          "C": "Cải thiện hiệu quả quản lý bệnh nhân trong phòng cấp cứu.",
          "D": "Phân tích dữ liệu điện tâm đồ để phát hiện các bất thường."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống AI này hoạt động bằng cách nào?",
        "options": {
          "A": "Phân tích tiền sử bệnh án của bệnh nhân để đánh giá rủi ro.",
          "B": "Sử dụng mạng nơ-ron tích chập để ước tính điểm rủi ro dựa trên điện tâm đồ.",
          "C": "Theo dõi dấu hiệu sinh tồn của bệnh nhân và cảnh báo khi có dấu hiệu bất thường.",
          "D": "So sánh dữ liệu của bệnh nhân với một cơ sở dữ liệu lớn về bệnh tim."
        },
        "answer": "B"
      },
      {
        "question": "Điểm rủi ro được coi là cao khi nào theo hệ thống này?",
        "options": {
          "A": "Khi điểm số vượt quá mức trung bình của tất cả bệnh nhân.",
          "B": "Khi điểm số nằm trong top 5% cao nhất so với các bệnh nhân khác.",
          "C": "Khi điểm số cho thấy nguy cơ tử vong trong vòng 30 ngày.",
          "D": "Khi điểm số vượt quá một ngưỡng cố định được xác định trước."
        },
        "answer": "B"
      },
      {
        "question": "Trong thử nghiệm lâm sàng, tỷ lệ tử vong ở nhóm bệnh nhân có cảnh báo rủi ro cao trong nhóm đối chứng là bao nhiêu?",
        "options": {
          "A": "16%",
          "B": "8.6%",
          "C": "23%",
          "D": "3.6%"
        },
        "answer": "C"
      },
      {
        "question": "Tỷ lệ tử vong chung ở nhóm thử nghiệm (experimental group) là bao nhiêu?",
        "options": {
          "A": "4.3%",
          "B": "8.9%",
          "C": "3.6%",
          "D": "16%"
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống AI này thể hiện khả năng dự đoán đặc biệt mạnh mẽ đối với loại tử vong nào?",
        "options": {
          "A": "Tử vong do nhiễm trùng.",
          "B": "Tử vong do tai nạn.",
          "C": "Tử vong do bệnh tim.",
          "D": "Tử vong do ung thư."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, hệ thống AI này đã giảm tỷ lệ tử vong do các bệnh liên quan đến tim mạch trong nhóm thử nghiệm so với nhóm đối chứng là bao nhiêu?",
        "options": {
          "A": "2.4%",
          "B": "2.2%",
          "C": "3.6%",
          "D": "0.2%"
        },
        "answer": "B"
      },
      {
        "question": "Các hệ thống cảnh báo dựa trên AI thường được sử dụng trong bệnh viện để làm gì?",
        "options": {
          "A": "Tự động điều trị cho bệnh nhân.",
          "B": "Xác định bệnh nhân cần được chăm sóc y tế khẩn cấp.",
          "C": "Thay thế bác sĩ trong việc chẩn đoán bệnh.",
          "D": "Giảm chi phí hoạt động của bệnh viện."
        },
        "answer": "B"
      },
      {
        "question": "Theo các tác giả, hệ thống AI có thể đã giúp ích bằng cách nào ngoài việc hướng sự chú ý đến bệnh nhân cần chăm sóc khẩn cấp?",
        "options": {
          "A": "Tự động điều chỉnh liều lượng thuốc cho bệnh nhân.",
          "B": "Xác định các đặc điểm điện tâm đồ mà bác sĩ thường không hiểu rõ hoặc không phát hiện được.",
          "C": "Cung cấp thông tin chi tiết về tiền sử bệnh án của bệnh nhân.",
          "D": "Dự đoán chính xác thời gian nằm viện của bệnh nhân."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đánh giá như thế nào về hệ thống AI này?",
        "options": {
          "A": "Hệ thống này còn nhiều hạn chế và cần được cải thiện thêm.",
          "B": "Hệ thống này đã cứu sống nhiều người một cách rõ ràng và nên được mở rộng quy mô.",
          "C": "Hệ thống này chỉ hiệu quả trong một số trường hợp nhất định.",
          "D": "Hệ thống này quá đắt đỏ để triển khai rộng rãi."
        },
        "answer": "B"
      }
    ]
  },
  "deep-learning-tackles-skin-ailments": {
    "title": "Deep Learning Tackles Skin Ailments",
    "collection": "science",
    "content": "Skin conditions are the fourth-largest cause of nonfatal disease worldwide, but access to dermatological care is sparse. A new study shows that a neural network can do front-line diagnostic work.What’s new:Researchers at Google Health, UCSF, MIT, and the Medical University of Graz trained a model to examine patient records and predict the likelihood of 26 common skin diseases. The researchers believe that theirsystemcould improve the diagnostic performance of primary-care centers for skin disease.Key insight:The system is designed to mimic the typical diagnostic process in a teledermatology setting. It accepts a patient’s medical history and up to six images, and returns a differential diagnosis, or a ranked list of likely diagnoses.How it works:Yuan Liu and her colleagues collected anonymized patient histories and images from a dermatology service serving 17 sites across two U.S. states. They trained on data collected a few years ago, and they tested on data generated more recently to approximate real-world conditions. The system includes:\n\nResults:The model classified diseases more accurately than primary care physicians and nurse practitioners. Allowed three guesses, it was more accurate than dermatologists by 10 percent. The system proved robust to skin color and type and its performance remained consistent across variations.Why it matters:Most previous models consider only a single image and classify a single disease. Inspired by current medical practices, this model uses a variable number of input images, makes use of non-visual patient information as well, and classifies a variety of conditions. The research also shows how to establish model robustness by comparing performance across characteristics like skin color, age, and sex.Yes, but:This study drew data from a limited geographic area. It remains to be seen whether the results generalize to other regions or whether such systems need to be trained or fine-tuned to account for specific geographic areas.We’re thinking:Computer vision has been making greatprogressin dermatology. Still, there are many difficult steps between encouraging results and deployment in clinical settings.",
    "qa": [
      {
        "question": "Theo bài viết, bệnh về da đứng thứ mấy trong các nguyên nhân gây bệnh không gây tử vong trên toàn thế giới?",
        "options": {
          "A": "Thứ hai",
          "B": "Thứ tư",
          "C": "Thứ ba",
          "D": "Thứ năm"
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu mới được đề cập trong bài viết tập trung vào việc phát triển một mạng nơ-ron có khả năng gì?",
        "options": {
          "A": "Phát triển thuốc điều trị các bệnh về da",
          "B": "Thực hiện công việc chẩn đoán ban đầu các bệnh về da",
          "C": "Nghiên cứu nguyên nhân gây ra các bệnh về da",
          "D": "Cải thiện quy trình chăm sóc da tại nhà"
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống được phát triển trong nghiên cứu này được thiết kế để mô phỏng quy trình chẩn đoán nào?",
        "options": {
          "A": "Chẩn đoán trực tiếp tại bệnh viện",
          "B": "Chẩn đoán từ xa (teledermatology)",
          "C": "Chẩn đoán bằng xét nghiệm máu",
          "D": "Chẩn đoán dựa trên tiền sử bệnh án"
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống này chấp nhận những thông tin đầu vào nào từ bệnh nhân?",
        "options": {
          "A": "Chỉ hình ảnh da",
          "B": "Tiền sử bệnh án và tối đa sáu hình ảnh",
          "C": "Kết quả xét nghiệm máu và sinh thiết da",
          "D": "Thông tin di truyền và thói quen sinh hoạt"
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu được sử dụng để huấn luyện mô hình trong nghiên cứu này được thu thập từ đâu?",
        "options": {
          "A": "Các bệnh viện trên toàn thế giới",
          "B": "Một dịch vụ da liễu phục vụ 17 địa điểm ở hai bang của Hoa Kỳ",
          "C": "Các phòng khám tư nhân ở Châu Âu",
          "D": "Dữ liệu tổng hợp từ các nghiên cứu trước đó"
        },
        "answer": "B"
      },
      {
        "question": "So với bác sĩ chăm sóc ban đầu và y tá, mô hình này phân loại bệnh chính xác hơn như thế nào?",
        "options": {
          "A": "Chính xác hơn một chút",
          "B": "Chính xác hơn đáng kể",
          "C": "Kém chính xác hơn",
          "D": "Có độ chính xác tương đương"
        },
        "answer": "B"
      },
      {
        "question": "Khi được phép đưa ra ba dự đoán, mô hình này chính xác hơn bác sĩ da liễu bao nhiêu phần trăm?",
        "options": {
          "A": "5 phần trăm",
          "B": "10 phần trăm",
          "C": "15 phần trăm",
          "D": "20 phần trăm"
        },
        "answer": "B"
      },
      {
        "question": "Một điểm nổi bật của mô hình này so với các mô hình trước đây là gì?",
        "options": {
          "A": "Chỉ xem xét một hình ảnh duy nhất",
          "B": "Chỉ phân loại một bệnh duy nhất",
          "C": "Sử dụng số lượng hình ảnh đầu vào thay đổi và thông tin bệnh nhân phi trực quan",
          "D": "Chỉ sử dụng thông tin di truyền của bệnh nhân"
        },
        "answer": "C"
      },
      {
        "question": "Một hạn chế được đề cập trong bài viết về nghiên cứu này là gì?",
        "options": {
          "A": "Dữ liệu được thu thập từ một khu vực địa lý hạn chế",
          "B": "Mô hình không hoạt động tốt trên các loại da khác nhau",
          "C": "Mô hình không thể phân loại được tất cả các bệnh về da",
          "D": "Mô hình yêu cầu phần cứng máy tính quá mạnh"
        },
        "answer": "A"
      },
      {
        "question": "Bài viết kết luận rằng cần có những bước nào trước khi triển khai các hệ thống này trong môi trường lâm sàng?",
        "options": {
          "A": "Cần có sự chấp thuận của FDA",
          "B": "Cần có nhiều bước khó khăn giữa kết quả khả quan và triển khai thực tế",
          "C": "Cần có sự hợp tác giữa các bác sĩ và kỹ sư",
          "D": "Cần có thêm dữ liệu từ các khu vực địa lý khác nhau"
        },
        "answer": "B"
      }
    ]
  },
  "deepminds-alphafold-3-enhances-3d-biomolecular-modeling": {
    "title": "AlphaFold 3 Embraces All Biochemistry",
    "collection": "science",
    "content": "The latest update of DeepMind’s AlphaFold model is designed to find the structures of not just proteins but all biologically active molecules as well as interactions between them.\n\nWhat’s new:GoogleannouncedAlphaFold 3, which models the 3D shapes of biomolecules including proteins, DNA, RNA, and ligands (molecules that bind to proteins or DNA, which includes antibodies and many drugs) in any combination. AlphaFold Serverprovidesaccess for noncommercial uses (with some limitations). Unlike earlier versions, AlphaFold 3 is not open source.Key insight:Given a sequence of amino acids (the building blocks of proteins), the previous version of AlphaFold drew on an existing knowledge of amino acid structures, computed their locations and angles, and assembled them like Lego blocks. To adapt the system for molecules that aren’t made of amino acids, AlphaFold 3 represents them as collections of individual atoms and uses a generative model to find their positions in space.How it works:Given a list of molecules, AlphaFold 3 generates their joint 3D structure, revealing how they fit together. Several transformers hone embeddings of proteins and amino acids, while a diffusion model (also a transformer) processes embeddings of atoms. The team trained the system on five datasets including ground truth protein, DNA, and RNA structures interactions in theProtein Data Bank. They also trained it on protein shapes computed by AlphaFold 2; that model’s explicit knowledge of amino acid structures helped overcome AlphaFold 3’s tendency to hallucinate in some instances. Among the key processes:\n\nResults: OnPoseBusters, a database of protein and protein-molecule shapes, AlphaFold 3 successfully found the shapes of about 77 percent of examples, while AutoDock Vina (a non-learning program that models molecular interactions) achieved about 53 percent. On a Protein Data Bank evaluation set, AlphaFold 3 successfully found about 84 percent of protein shapes, while AlphaFold Multimer 2.3 (an update of AlphaFold 2) found 83 percent. Modeling protein-protein interactions, AlphaFold 3 achieved 77 percent, while AlphaFold Multimer 2.3 achieved 67 percent, according toDockQ(a metric for the quality of such interactions).Behind the news:The original AlphaFold solved one of the most challenging problems in molecular biology by figuring out how long chains of amino acids would fold, giving scientists clear targets for designing new bioactive molecules. Googlespun offIsomorphic Labs to apply AlphaFold 2 to drug discovery. That company will use AlphaFold 3 and control commercial access to it.Why it matters:AlphaFold 3 is a triumph of machine learning. It extends the utility of the previous version beyond proteins, and it computes with unprecedented accuracy how biological molecules will combine, allowing for a more comprehensive understanding of how drugs interact with the body. Its ability to predict how antibodies will bind to proteins could help stave off future pandemics and other illnesses.We’re thinking:Although Isomorphic Labs retains control of AlphaFold 3, biologistssaidthe information in the paper is enough for other researchers to develop similar systems. We look forward to open versions!",
    "qa": [
      {
        "question": "Điểm mới của AlphaFold 3 so với các phiên bản trước là gì?",
        "options": {
          "A": "Chỉ mô hình hóa cấu trúc protein chính xác hơn.",
          "B": "Mô hình hóa cấu trúc 3D của nhiều loại phân tử sinh học khác nhau và tương tác giữa chúng.",
          "C": "Là mã nguồn mở, cho phép mọi người sử dụng và phát triển.",
          "D": "Sử dụng phương pháp tiếp cận hoàn toàn mới, không dựa trên dữ liệu đã biết."
        },
        "answer": "B"
      },
      {
        "question": "AlphaFold 3 không còn là mã nguồn mở, quyền truy cập thương mại được kiểm soát bởi tổ chức nào?",
        "options": {
          "A": "Google DeepMind.",
          "B": "Protein Data Bank.",
          "C": "Isomorphic Labs.",
          "D": "PoseBusters."
        },
        "answer": "C"
      },
      {
        "question": "AlphaFold 3 sử dụng phương pháp nào để mô hình hóa các phân tử không phải protein?",
        "options": {
          "A": "Sử dụng kiến thức về cấu trúc amino acid đã biết.",
          "B": "Lắp ráp các phân tử như các khối Lego.",
          "C": "Đại diện chúng như tập hợp các nguyên tử riêng lẻ và sử dụng mô hình sinh để tìm vị trí của chúng trong không gian.",
          "D": "Áp dụng trực tiếp các thuật toán từ AlphaFold 2."
        },
        "answer": "C"
      },
      {
        "question": "AlphaFold 3 được huấn luyện trên những loại dữ liệu nào?",
        "options": {
          "A": "Chỉ dữ liệu về cấu trúc protein.",
          "B": "Dữ liệu về cấu trúc DNA và RNA.",
          "C": "Dữ liệu về cấu trúc protein, DNA, RNA và tương tác giữa chúng, cùng với kết quả từ AlphaFold 2.",
          "D": "Dữ liệu tổng hợp được tạo ra bởi các mô hình máy tính khác."
        },
        "answer": "C"
      },
      {
        "question": "Trên cơ sở dữ liệu PoseBusters, AlphaFold 3 đạt được độ chính xác bao nhiêu trong việc tìm hình dạng phân tử?",
        "options": {
          "A": "53%",
          "B": "67%",
          "C": "77%",
          "D": "84%"
        },
        "answer": "C"
      },
      {
        "question": "Chương trình nào được sử dụng để so sánh hiệu suất của AlphaFold 3 trong việc mô hình hóa tương tác phân tử?",
        "options": {
          "A": "AlphaFold Multimer 2.3.",
          "B": "AutoDock Vina.",
          "C": "Protein Data Bank.",
          "D": "PoseBusters."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, ứng dụng tiềm năng nào của AlphaFold 3 có thể giúp ngăn chặn đại dịch trong tương lai?",
        "options": {
          "A": "Thiết kế các loại thuốc mới hiệu quả hơn.",
          "B": "Dự đoán cách kháng thể liên kết với protein.",
          "C": "Tìm hiểu cấu trúc của virus và vi khuẩn.",
          "D": "Tăng tốc quá trình phát triển vaccine."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc Google tách Isomorphic Labs ra khỏi DeepMind là gì?",
        "options": {
          "A": "Để phát triển các thuật toán máy học mới.",
          "B": "Để ứng dụng AlphaFold 2 vào việc khám phá thuốc.",
          "C": "Để cạnh tranh với các công ty dược phẩm khác.",
          "D": "Để tập trung vào nghiên cứu cơ bản về sinh học phân tử."
        },
        "answer": "B"
      },
      {
        "question": "DockQ là gì trong bối cảnh bài viết?",
        "options": {
          "A": "Một cơ sở dữ liệu về cấu trúc protein.",
          "B": "Một chương trình mô hình hóa tương tác phân tử.",
          "C": "Một chỉ số đánh giá chất lượng tương tác protein-protein.",
          "D": "Một phiên bản mã nguồn mở của AlphaFold."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì khiến các nhà sinh học tin rằng các nhà nghiên cứu khác có thể phát triển các hệ thống tương tự AlphaFold 3?",
        "options": {
          "A": "AlphaFold 3 là mã nguồn mở.",
          "B": "Thông tin trong bài báo đủ để phát triển các hệ thống tương tự.",
          "C": "Google DeepMind sẽ chia sẻ công nghệ với các nhà nghiên cứu khác.",
          "D": "Các hệ thống tương tự đã tồn tại trước AlphaFold 3."
        },
        "answer": "B"
      }
    ]
  },
  "drones-of-a-feather": {
    "title": "Drones of a Feather",
    "collection": "science",
    "content": "Deep learning is coordinating drones so they can flock together without colliding.What’s new:Caltech researchers Soon-Jo Chung and Yisong Yue developed apair of modelsthat enables swarms of networked drones to navigate autonomously through cluttered environments.How it works:Sensors on each drone collect real-time data that are shared among a swarm. A neural network calledGLASplans drone actions, while another one calledNeural-Swarmhelps compensate for wind caused by nearby fliers.\n\nResults:The authors tested GLAS and Neural-Swarm separately. In comparisons with astate-of-the-artmotion planning algorithm, 16 drones piloted by GLAS navigated 20 percent more effectively through a variety of obstacle courses. Drones controlled by Neural-Swarm were four times better than a baseline linear tracking controller at staying on course.Why it matters:Drones capable of maneuvering safely in swarms could aid urban search and rescue operations, accelerate industrial inspections, and provide comprehensive aerial mapping.We’re thinking:Is anyone else excited to see drone shows even more spectacular than the one that lit up the2018 Olympics?",
    "qa": [
      {
        "question": "Công nghệ deep learning được sử dụng trong bài viết này để làm gì?",
        "options": {
          "A": "Điều khiển một drone duy nhất bay qua chướng ngại vật.",
          "B": "Điều phối một đàn drone bay cùng nhau mà không va chạm.",
          "C": "Tăng tốc độ xử lý dữ liệu cho drone.",
          "D": "Cải thiện chất lượng hình ảnh thu được từ drone."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu Soon-Jo Chung và Yisong Yue đến từ đâu?",
        "options": {
          "A": "MIT.",
          "B": "Stanford.",
          "C": "Caltech.",
          "D": "Harvard."
        },
        "answer": "C"
      },
      {
        "question": "Mạng nơ-ron GLAS được sử dụng để làm gì trong hệ thống điều khiển drone?",
        "options": {
          "A": "Thu thập dữ liệu thời gian thực từ các cảm biến.",
          "B": "Chia sẻ dữ liệu giữa các drone trong đàn.",
          "C": "Lập kế hoạch hành động cho drone.",
          "D": "Bù đắp ảnh hưởng của gió lên drone."
        },
        "answer": "C"
      },
      {
        "question": "Mạng nơ-ron Neural-Swarm có chức năng chính là gì?",
        "options": {
          "A": "Điều hướng drone trong môi trường phức tạp.",
          "B": "Giúp drone tránh va chạm với các vật thể tĩnh.",
          "C": "Bù đắp ảnh hưởng của gió do các drone khác gây ra.",
          "D": "Tối ưu hóa năng lượng tiêu thụ của drone."
        },
        "answer": "C"
      },
      {
        "question": "Trong thử nghiệm, GLAS đã cải thiện hiệu quả điều hướng của drone so với thuật toán lập kế hoạch chuyển động hiện đại nhất là bao nhiêu?",
        "options": {
          "A": "10%.",
          "B": "20%.",
          "C": "30%.",
          "D": "40%."
        },
        "answer": "B"
      },
      {
        "question": "Neural-Swarm giúp drone duy trì đúng hướng tốt hơn bao nhiêu lần so với bộ điều khiển theo dõi tuyến tính cơ bản?",
        "options": {
          "A": "Hai lần.",
          "B": "Ba lần.",
          "C": "Bốn lần.",
          "D": "Năm lần."
        },
        "answer": "C"
      },
      {
        "question": "Ứng dụng tiềm năng nào của đàn drone được đề cập trong bài viết?",
        "options": {
          "A": "Vận chuyển hàng hóa nhanh chóng.",
          "B": "Tìm kiếm và cứu hộ đô thị.",
          "C": "Giám sát giao thông.",
          "D": "Phân tích chất lượng không khí."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài tìm kiếm cứu hộ, đàn drone còn có thể được sử dụng trong lĩnh vực nào khác được đề cập trong bài?",
        "options": {
          "A": "Nông nghiệp chính xác.",
          "B": "Kiểm tra công nghiệp.",
          "C": "Dự báo thời tiết.",
          "D": "Nghiên cứu khoa học."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích của việc lập bản đồ trên không toàn diện bằng drone là gì?",
        "options": {
          "A": "Tạo ra bản đồ 3D chi tiết của các thành phố.",
          "B": "Hỗ trợ quy hoạch đô thị và phát triển cơ sở hạ tầng.",
          "C": "Cung cấp dữ liệu cho các ứng dụng thực tế ảo.",
          "D": "Tất cả các đáp án trên."
        },
        "answer": "D"
      },
      {
        "question": "Sự kiện nào được nhắc đến trong bài viết liên quan đến màn trình diễn drone?",
        "options": {
          "A": "Thế vận hội Mùa đông 2014.",
          "B": "Thế vận hội Mùa hè 2016.",
          "C": "Thế vận hội Mùa đông 2018.",
          "D": "Thế vận hội Mùa hè 2020."
        },
        "answer": "C"
      }
    ]
  },
  "extreme-weather-warning": {
    "title": "Extreme Weather Warning",
    "collection": "science",
    "content": "Severe heat waves and cold snaps are especially hard to forecast because atmospheric perturbations can have effects that are difficult to compute. Neural networks show promise where typical methods have stumbled.What’s new:Researchers at Rice University used a capsule neural network — a variation on a convolutional neural network — toforecastregional temperature extremes based on far fewer variables than usual.How it works:Good historical observations date back only to 1979 and don’t include enough extreme-weather examples to train a neural network. So the researchers trained their model on simulated data from the National Center for Atmospheric Research’sLarge Ensemble Community Project(LENS).\n\nThe next step:By adding further variables like soil moisture and ocean surface temperature, the researchers believe they can extend their model’s accuracy beyond 10 days. That would help meteorologists spot regional temperature extremes well ahead of time. Then they would use conventional methods to home in on local effects.Why it matters:Extreme temperatures are disruptive at best, deadly at worst. Advance warning would help farmers save crops, first responders save lives, and ordinary people stay safe.Behind the news:Most weather forecasting is based on crunching dozens of variables according to math formulas. In its reliance on matching historical patterns, this study’s technique — indeed, any deep learning approach to weather prediction — is a throwback to earlier methods. For instance, the U.S. military used temperature and atmospheric pressure maps to predict the weather before the U.S.invasion of Normandyin 1944.We’re thinking:Who says talking about the weather is boring?",
    "qa": [
      {
        "question": "Tại sao việc dự báo các đợt nắng nóng và rét đậm trở nên đặc biệt khó khăn?",
        "options": {
          "A": "Do thiếu dữ liệu lịch sử về các hiện tượng thời tiết cực đoan.",
          "B": "Do các nhiễu loạn khí quyển có thể gây ra những ảnh hưởng khó tính toán.",
          "C": "Do các phương pháp dự báo truyền thống không còn hiệu quả.",
          "D": "Do sự thay đổi thất thường của nhiệt độ bề mặt đại dương."
        },
        "answer": "B"
      },
      {
        "question": "Mạng nơ-ron capsule được sử dụng trong nghiên cứu này là một biến thể của loại mạng nơ-ron nào?",
        "options": {
          "A": "Mạng nơ-ron hồi quy.",
          "B": "Mạng nơ-ron lan truyền ngược.",
          "C": "Mạng nơ-ron tích chập.",
          "D": "Mạng nơ-ron tái phát."
        },
        "answer": "C"
      },
      {
        "question": "Dữ liệu nào được các nhà nghiên cứu sử dụng để huấn luyện mô hình mạng nơ-ron của họ?",
        "options": {
          "A": "Dữ liệu quan sát lịch sử từ năm 1900.",
          "B": "Dữ liệu quan sát lịch sử từ năm 1979.",
          "C": "Dữ liệu mô phỏng từ Dự án Cộng đồng Lớn của Trung tâm Nghiên cứu Khí quyển Quốc gia (LENS).",
          "D": "Dữ liệu thời tiết thực tế từ các trạm khí tượng trên toàn thế giới."
        },
        "answer": "C"
      },
      {
        "question": "Các nhà nghiên cứu tin rằng việc bổ sung thêm những biến số nào có thể kéo dài độ chính xác dự báo của mô hình?",
        "options": {
          "A": "Áp suất khí quyển và tốc độ gió.",
          "B": "Độ ẩm đất và nhiệt độ bề mặt đại dương.",
          "C": "Lượng mưa và độ che phủ của mây.",
          "D": "Độ cao địa hình và mật độ dân số."
        },
        "answer": "B"
      },
      {
        "question": "Việc cảnh báo sớm về nhiệt độ khắc nghiệt có thể giúp ích cho những đối tượng nào?",
        "options": {
          "A": "Nông dân, lực lượng cứu hộ và người dân.",
          "B": "Các nhà khoa học, chính phủ và doanh nghiệp.",
          "C": "Các nhà đầu tư, nhà báo và nghệ sĩ.",
          "D": "Các nhà khí tượng học, kỹ sư và giáo viên."
        },
        "answer": "A"
      },
      {
        "question": "Phương pháp dự báo thời tiết dựa trên việc khớp các mẫu lịch sử được xem là sự trở lại của phương pháp nào?",
        "options": {
          "A": "Phương pháp dự báo bằng vệ tinh.",
          "B": "Phương pháp dự báo bằng máy tính.",
          "C": "Phương pháp dự báo truyền thống sử dụng công thức toán học.",
          "D": "Phương pháp dự báo thời tiết sơ khai sử dụng bản đồ nhiệt độ và áp suất khí quyển."
        },
        "answer": "D"
      },
      {
        "question": "Dự án Cộng đồng Lớn (LENS) thuộc về tổ chức nào?",
        "options": {
          "A": "Cơ quan Vũ trụ Hoa Kỳ (NASA).",
          "B": "Trung tâm Nghiên cứu Khí quyển Quốc gia (NCAR).",
          "C": "Cục Quản lý Đại dương và Khí quyển Quốc gia (NOAA).",
          "D": "Tổ chức Khí tượng Thế giới (WMO)."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của việc phát triển mô hình dự báo nhiệt độ khắc nghiệt là gì?",
        "options": {
          "A": "Để cải thiện độ chính xác của các mô hình khí hậu dài hạn.",
          "B": "Để giúp các nhà khí tượng học hiểu rõ hơn về các hiện tượng thời tiết.",
          "C": "Để cung cấp cảnh báo sớm, giúp giảm thiểu tác động tiêu cực của thời tiết khắc nghiệt.",
          "D": "Để phát triển các công nghệ mới cho việc thu thập dữ liệu thời tiết."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì khiến nghiên cứu này khác biệt so với các phương pháp dự báo thời tiết thông thường?",
        "options": {
          "A": "Nó sử dụng nhiều biến số hơn để dự đoán thời tiết.",
          "B": "Nó dựa trên các công thức toán học phức tạp.",
          "C": "Nó sử dụng mạng nơ-ron capsule và ít biến số hơn.",
          "D": "Nó chỉ tập trung vào dự báo nhiệt độ tối đa."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, sự kiện lịch sử nào được nhắc đến liên quan đến việc sử dụng bản đồ thời tiết để dự đoán?",
        "options": {
          "A": "Cuộc khủng hoảng tên lửa Cuba.",
          "B": "Chiến tranh Việt Nam.",
          "C": "Cuộc xâm lược Normandy của Hoa Kỳ năm 1944.",
          "D": "Sự kiện Trân Châu Cảng."
        },
        "answer": "C"
      }
    ]
  },
  "embeddings-ai-enhances-cell-type-discovery-identifies-previously-elusive-norn-cells": {
    "title": "Cross-Species Cell Embeddings",
    "collection": "science",
    "content": "Researchers used an AI system to identify animal cell types from gene sequences, including a cell type that conventional approaches had discovered only in the past year.\n\nWhat’s new:Biologists at Stanford trained asystemto produce embeddings that represent individual cells in an organism. This enabled them to find cell types that have common function in different animals; for instance, the Norn cell, a type of kidney cell that biologists had previously theorized butdiscoveredonly in 2023.\n\nHow it works:Universal Cell Embedding (UCE) comprises two transformers that produce embeddings of genes and cells respectively, plus a classifier based on a vanilla neural network. The authors trained the classifier, given embeddings of a gene and cell, to classify whether or not the cell produces the protein coded by that gene. The training dataset included RNA sequences of 36.2 million cells from eight animal species (humans and mice accounted for 33.9 million) along with related protein structures.\n\nResults:Cell embeddings produced by UCE enabled the authors to identify cell types in animal species that weren’t in the training set. For instance, the authors embedded a dataset of mouse cells and appliedUMAPclustering to differentiate the types. They labeled the clusters as specific cell types (including Norn cells, which biologists took more than a century to find) based on the presence of certain genes that distinguish one cell type from another. Using the labels, they trained a logistic classifier. They applied the classifier to their training dataset and found Norn cells, among other cell types, in species other than mice. They verified the findings by looking for genes that tend to show up only in Norn cells.\n\nWhy it matters:UCE’s embeddings encode biologically meaningful information about individual cells, enabling a clustering algorithm to group them into recognized cell types. The fact that the recently discovered Norn cell was among those clusters suggests that UCE may yield further discoveries that accelerate development of new medicines, lab processes, and research methods. In fact, the model found Norn cells — which are known to occur in the kidney — in organs where they have not been seen before. If this result turns out to be valid, UCE will have made a discovery that has eluded biologists to date.\n\nWe’re thinking:It’s a truism that a machine learning model is only as good as its data. That makes this work all the more impressive: Its training data included a handful of species, yet it generalized to others.",
    "qa": [
      {
        "question": "Hệ thống AI được các nhà nghiên cứu Stanford sử dụng để làm gì?",
        "options": {
          "A": "Dự đoán cấu trúc protein từ trình tự gen.",
          "B": "Xác định các loại tế bào động vật từ trình tự gen.",
          "C": "Phát triển các loại thuốc mới dựa trên cấu trúc tế bào.",
          "D": "Tối ưu hóa quy trình nuôi cấy tế bào trong phòng thí nghiệm."
        },
        "answer": "B"
      },
      {
        "question": "Tế bào Norn là loại tế bào gì và được phát hiện gần đây ở đâu?",
        "options": {
          "A": "Tế bào thần kinh được phát hiện ở não chuột.",
          "B": "Tế bào thận được phát hiện ở nhiều loài động vật, bao gồm cả chuột.",
          "C": "Tế bào gan được phát hiện ở người.",
          "D": "Tế bào miễn dịch được phát hiện ở hệ tiêu hóa của chuột."
        },
        "answer": "B"
      },
      {
        "question": "UCE (Universal Cell Embedding) bao gồm những thành phần chính nào?",
        "options": {
          "A": "Một mạng nơ-ron tích chập và một bộ phân loại tuyến tính.",
          "B": "Hai transformers tạo ra embeddings của gen và tế bào, cùng một bộ phân loại dựa trên mạng nơ-ron vanilla.",
          "C": "Một bộ mã hóa tự động biến đổi và một mạng nơ-ron tái tạo.",
          "D": "Một mạng nơ-ron hồi quy và một bộ phân loại dựa trên cây quyết định."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu huấn luyện cho UCE bao gồm những gì?",
        "options": {
          "A": "Trình tự DNA của vi khuẩn và cấu trúc protein liên quan.",
          "B": "Trình tự RNA của tế bào động vật và cấu trúc protein liên quan.",
          "C": "Hình ảnh tế bào động vật và thông tin về chức năng của chúng.",
          "D": "Dữ liệu về biểu hiện gen của thực vật và động vật."
        },
        "answer": "B"
      },
      {
        "question": "UCE đã giúp các nhà nghiên cứu xác định loại tế bào nào mà trước đây rất khó tìm thấy?",
        "options": {
          "A": "Tế bào gốc phôi.",
          "B": "Tế bào Norn.",
          "C": "Tế bào ung thư.",
          "D": "Tế bào thần kinh đệm."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã xác minh kết quả của UCE bằng cách nào?",
        "options": {
          "A": "So sánh kết quả với các nghiên cứu trước đó về tế bào học.",
          "B": "Tìm kiếm các gen đặc trưng chỉ xuất hiện trong tế bào Norn.",
          "C": "Sử dụng kính hiển vi điện tử để quan sát cấu trúc tế bào.",
          "D": "Thực hiện các thí nghiệm in-vitro để kiểm tra chức năng của tế bào."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc UCE tìm thấy tế bào Norn lại quan trọng?",
        "options": {
          "A": "Chứng minh rằng UCE có thể tìm thấy các tế bào mới hoàn toàn chưa được biết đến.",
          "B": "Cho thấy UCE có thể giúp phát triển thuốc mới, quy trình phòng thí nghiệm và phương pháp nghiên cứu.",
          "C": "Xác nhận rằng tế bào Norn chỉ tồn tại ở chuột.",
          "D": "Chứng minh rằng các phương pháp truyền thống không còn hiệu quả."
        },
        "answer": "B"
      },
      {
        "question": "UCE đã tìm thấy tế bào Norn ở những vị trí nào?",
        "options": {
          "A": "Chỉ ở thận, nơi chúng đã được biết đến trước đây.",
          "B": "Ở thận và các cơ quan khác nơi chúng chưa từng được thấy trước đây.",
          "C": "Chỉ ở các cơ quan của chuột, không phải ở người.",
          "D": "Ở các cơ quan bị tổn thương do bệnh tật."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì được coi là một hạn chế tiềm ẩn của các mô hình học máy như UCE?",
        "options": {
          "A": "Khả năng xử lý dữ liệu quá lớn.",
          "B": "Chất lượng của mô hình phụ thuộc vào chất lượng dữ liệu huấn luyện.",
          "C": "Khả năng khái quát hóa kém đối với các loài khác nhau.",
          "D": "Yêu cầu phần cứng quá cao để chạy mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì khiến kết quả của UCE trở nên ấn tượng, mặc dù có hạn chế về dữ liệu huấn luyện?",
        "options": {
          "A": "UCE có thể khái quát hóa cho các loài khác mặc dù chỉ được huấn luyện trên một số ít loài.",
          "B": "UCE có thể tìm thấy tế bào Norn nhanh hơn các phương pháp truyền thống.",
          "C": "UCE có thể xử lý dữ liệu từ nhiều nguồn khác nhau.",
          "D": "UCE có thể dự đoán cấu trúc protein chính xác hơn các phương pháp khác."
        },
        "answer": "A"
      }
    ]
  },
  "first-make-no-harmful-models": {
    "title": "First, Make No Harmful Models",
    "collection": "science",
    "content": "Researchers have rushed out a battery of AI-powered tools to combat the coronavirus, but an assessment of dozens of models is a wake-up call for machine learning engineers.What’s new:Many models built to spot Covid-19 infection, predict the likelihood of hospitalization, or forecast outcomes are built on flawed science, according to asurveypublished in theBritish Medical Journal.What they found:A group of clinicians, scientists, and engineers led by Laure Winants, an epidemiologist at Maastricht University in the Netherlands, found that biased data compromised all of the 31 models analyzed.\n\nResults:In a commentary that accompanied the survey,BMJ’s editors declared the models so “uniformly poor” that “none can be recommended for clinical use.”The path forward:The authors recommend that machine learning researchers adopt the 22-pointTRIPODchecklist as a standard for developing predictive medical AI. Developed by an international consortium of physicians and data scientists, the checklist is designed to help engineers report their work clearly and reduces risk of developing models with biased data.Why it matters:Patients and health care systems alike need more accurate and faster diagnoses and prognoses. The AI community is used to publishing preliminary results to accelerate progress, but the health care community tends to wait for rigorous peer review to avoid causing harm.We’re thinking:Given how fast the Covid-19 situation is evolving, sharing results early and often is a good thing. But the AI community also needs new mechanisms to make sure preliminary models don’t cause harm.",
    "qa": [
      {
        "question": "Theo bài viết, vấn đề chính của các mô hình AI được phát triển để chống lại Covid-19 là gì?",
        "options": {
          "A": "Sử dụng thuật toán quá phức tạp.",
          "B": "Dữ liệu sử dụng bị thiên vị.",
          "C": "Thiếu sự hợp tác giữa các nhà nghiên cứu.",
          "D": "Thời gian phát triển quá ngắn."
        },
        "answer": "B"
      },
      {
        "question": "Tổ chức nào đã công bố bài đánh giá về các mô hình AI chống Covid-19?",
        "options": {
          "A": "Tổ chức Y tế Thế giới (WHO).",
          "B": "Tạp chí Y khoa Anh (British Medical Journal).",
          "C": "Đại học Maastricht.",
          "D": "Một liên minh quốc tế gồm các bác sĩ và nhà khoa học dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Kết luận chính của bài đánh giá về các mô hình AI chống Covid-19 là gì?",
        "options": {
          "A": "Các mô hình này có tiềm năng lớn nhưng cần được cải thiện.",
          "B": "Không có mô hình nào được khuyến nghị sử dụng trong thực tế lâm sàng.",
          "C": "Các mô hình này hiệu quả hơn các phương pháp chẩn đoán truyền thống.",
          "D": "Cần thêm dữ liệu để đánh giá chính xác hiệu quả của các mô hình."
        },
        "answer": "B"
      },
      {
        "question": "TRIPOD checklist là gì và nó được sử dụng để làm gì?",
        "options": {
          "A": "Một loại thuốc mới để điều trị Covid-19.",
          "B": "Một tiêu chuẩn để phát triển AI dự đoán trong y tế.",
          "C": "Một phương pháp thu thập dữ liệu y tế hiệu quả.",
          "D": "Một công cụ để đánh giá rủi ro lây nhiễm Covid-19."
        },
        "answer": "B"
      },
      {
        "question": "Ai là người đứng đầu nhóm nghiên cứu đã phân tích các mô hình AI chống Covid-19?",
        "options": {
          "A": "Một biên tập viên của BMJ.",
          "B": "Laure Winants, một nhà dịch tễ học.",
          "C": "Một kỹ sư máy học giấu tên.",
          "D": "Một bác sĩ lâm sàng tại Hà Lan."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến sự khác biệt trong cách tiếp cận giữa cộng đồng AI và cộng đồng y tế là gì?",
        "options": {
          "A": "Cộng đồng AI tập trung vào tốc độ, trong khi cộng đồng y tế chú trọng đến tính chính xác.",
          "B": "Cộng đồng AI ưu tiên công bố kết quả sớm, trong khi cộng đồng y tế chờ đợi đánh giá nghiêm ngặt.",
          "C": "Cộng đồng AI sử dụng dữ liệu lớn, trong khi cộng đồng y tế dựa vào kinh nghiệm lâm sàng.",
          "D": "Cộng đồng AI phát triển mô hình phức tạp, trong khi cộng đồng y tế sử dụng phương pháp đơn giản."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, tại sao việc chia sẻ kết quả sớm trong bối cảnh Covid-19 lại quan trọng?",
        "options": {
          "A": "Để thu hút sự chú ý của giới truyền thông.",
          "B": "Để tăng tốc độ tiến bộ trong nghiên cứu.",
          "C": "Để cạnh tranh với các nhóm nghiên cứu khác.",
          "D": "Để chứng minh khả năng của công nghệ AI."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh sự cần thiết của điều gì để đảm bảo các mô hình AI sơ bộ không gây hại?",
        "options": {
          "A": "Sử dụng phần cứng mạnh mẽ hơn.",
          "B": "Cơ chế mới để kiểm soát và đánh giá.",
          "C": "Tăng cường đào tạo cho các nhà nghiên cứu.",
          "D": "Hợp tác chặt chẽ hơn với các công ty công nghệ."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu cuối cùng của việc phát triển các mô hình AI trong y tế là gì?",
        "options": {
          "A": "Thay thế bác sĩ lâm sàng.",
          "B": "Tăng tốc độ chẩn đoán và tiên lượng bệnh.",
          "C": "Giảm chi phí chăm sóc sức khỏe.",
          "D": "Tự động hóa quy trình nghiên cứu y học."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, yếu tố nào đã làm ảnh hưởng đến tất cả 31 mô hình AI được phân tích?",
        "options": {
          "A": "Thiếu dữ liệu huấn luyện.",
          "B": "Dữ liệu bị thiên vị.",
          "C": "Thuật toán không phù hợp.",
          "D": "Thiếu sự tham gia của các chuyên gia y tế."
        },
        "answer": "B"
      }
    ]
  },
  "fish-recognition": {
    "title": "Fish Recognition",
    "collection": "science",
    "content": "A deep learning system is helping biologists who survey offshore fish populations to prevent overfishing.What’s new:The U.S. agency in charge of protecting ocean resources is using an underwater camera and neural network tocount fishin real time.How it works:Alaska’s walleye pollock fishery is America’s largest by volume. (You may not recognize a walleye pollock, but you’ve probably eaten one in fish sticks, fast-food sandwiches, or imitation crab meat. They are delicious!) Scientists with the U.S. National Oceanic and Atmospheric Administration chose this fishery as a pilot in their automatic fish-identification program.\n\nBehind the news:Congress passed the Sustainable Fisheries Act in 1996, requiring NOAA to track U.S.commercial fish populations. For some fisheries, the biologists venture out on boats, casting nets to capture samples of what’s in the water. They dump the contents onto the deck, count and measure each creature, release the haul, and cast the net again. NOAA launched the initiative to automate these counts using artificial intelligence in 2014.Why it matters:Fish stock assessments, and the limits they impose on commercial fishing, keep fish populations sustainable and fisheries productive over the long term. Automating the process reduces error and frees up biologists for other work.We’re thinking:Deep learning is producing more and better data for environmental stewardship. It’s up to citizens to put that data to best use.",
    "qa": [
      {
        "question": "Hệ thống deep learning được sử dụng trong bài viết này giúp ích cho các nhà sinh vật học trong việc gì?",
        "options": {
          "A": "Nghiên cứu các loài cá mới ở vùng biển sâu.",
          "B": "Ngăn chặn tình trạng đánh bắt cá quá mức.",
          "C": "Phát triển các loại thức ăn mới từ cá.",
          "D": "Dự đoán sự di cư của các loài cá."
        },
        "answer": "B"
      },
      {
        "question": "Cơ quan nào của Hoa Kỳ đang sử dụng camera dưới nước và mạng nơ-ron để đếm cá?",
        "options": {
          "A": "Bộ Nông nghiệp Hoa Kỳ (USDA).",
          "B": "Cơ quan Bảo vệ Môi trường Hoa Kỳ (EPA).",
          "C": "Cơ quan Quản lý Khí quyển và Đại dương Quốc gia Hoa Kỳ (NOAA).",
          "D": "Cục Cá và Động vật hoang dã Hoa Kỳ (USFWS)."
        },
        "answer": "C"
      },
      {
        "question": "Loại cá nào được chọn làm thí điểm trong chương trình nhận dạng cá tự động của NOAA?",
        "options": {
          "A": "Cá hồi Đại Tây Dương.",
          "B": "Cá tuyết chấm đen Alaska (walleye pollock).",
          "C": "Cá ngừ vây xanh.",
          "D": "Cá bơn Thái Bình Dương."
        },
        "answer": "B"
      },
      {
        "question": "Đạo luật nào của Quốc hội Hoa Kỳ yêu cầu NOAA theo dõi quần thể cá thương mại của Hoa Kỳ?",
        "options": {
          "A": "Đạo luật Bảo tồn Biển năm 1972.",
          "B": "Đạo luật Nghề cá Bền vững năm 1996.",
          "C": "Đạo luật Bảo vệ Động vật có Nguy cơ Tuyệt chủng năm 1973.",
          "D": "Đạo luật Chính sách Môi trường Quốc gia năm 1969."
        },
        "answer": "B"
      },
      {
        "question": "Trước khi có hệ thống AI, các nhà sinh vật học thường làm gì để đánh giá số lượng cá?",
        "options": {
          "A": "Sử dụng sonar để ước tính số lượng cá.",
          "B": "Thu thập mẫu nước và phân tích DNA.",
          "C": "Đi thuyền, thả lưới, đếm và đo từng con cá.",
          "D": "Quan sát từ trên không bằng máy bay không người lái."
        },
        "answer": "C"
      },
      {
        "question": "NOAA bắt đầu sáng kiến tự động hóa việc đếm cá bằng trí tuệ nhân tạo vào năm nào?",
        "options": {
          "A": "2004.",
          "B": "2010.",
          "C": "2014.",
          "D": "2020."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao việc đánh giá trữ lượng cá lại quan trọng?",
        "options": {
          "A": "Để tăng sản lượng đánh bắt cá hàng năm.",
          "B": "Để giữ cho quần thể cá bền vững và nghề cá hiệu quả trong dài hạn.",
          "C": "Để phát triển các loại thuốc mới từ cá.",
          "D": "Để bảo vệ các loài động vật biển khác."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích chính của việc tự động hóa quy trình đếm cá là gì?",
        "options": {
          "A": "Giảm chi phí nhiên liệu cho tàu thuyền.",
          "B": "Giảm thiểu sai sót và giải phóng các nhà sinh vật học cho công việc khác.",
          "C": "Tăng tốc độ đánh bắt cá.",
          "D": "Cải thiện chất lượng cá."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, công nghệ deep learning đang đóng góp vào lĩnh vực nào?",
        "options": {
          "A": "Phát triển năng lượng tái tạo.",
          "B": "Quản lý tài chính toàn cầu.",
          "C": "Quản lý môi trường.",
          "D": "Nghiên cứu y học."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết kết luận rằng ai có trách nhiệm sử dụng dữ liệu từ deep learning một cách tốt nhất?",
        "options": {
          "A": "Các nhà khoa học.",
          "B": "Các chính trị gia.",
          "C": "Các công ty công nghệ.",
          "D": "Công dân."
        },
        "answer": "D"
      }
    ]
  },
  "getting-a-charge-from-ai": {
    "title": "Getting a Charge From AI",
    "collection": "science",
    "content": "Machine learning is helping to design energy cells that charge faster and last longer.What’s new:Battery developers are using ML algorithms to devise new chemicals, components, and charging techniques faster than traditional techniques allow, according toWired.How it works: Designing better batteries involves tweaking variables such as electrode architecture, chemical composition, and patterns of current and voltage during charging. Typically, researchers change one at a time and can’t analyze the results until a battery dies. AI lets them test many at once and get results while the battery still has juice.\n\nBehind the news:In recent years, machine learning has also helped researchers discover new molecules thatimprove energy density,predict how batteries will performin different electric vehicles,testhow well capacitor designs store energy, and advanced battery research inmany other ways.Why it matters:Batteries that last long, charge fast, and cost little are a key enabler for devices from self-driving cars to brain implants.We’re thinking:In our recentHeroes of NLPinterview, Chris Manning joked that “electricity is the new AI.” Maybe he was right! You can watch the whole thinghere.",
    "qa": [
      {
        "question": "Theo bài viết, Machine Learning (ML) đang hỗ trợ các nhà phát triển pin như thế nào?",
        "options": {
          "A": "Giúp họ giảm chi phí sản xuất pin.",
          "B": "Giúp họ tìm ra các hóa chất, thành phần và kỹ thuật sạc mới nhanh hơn.",
          "C": "Giúp họ kéo dài tuổi thọ của các thiết bị điện tử.",
          "D": "Giúp họ tự động hóa quy trình sản xuất pin hoàn toàn."
        },
        "answer": "B"
      },
      {
        "question": "Trong quá trình thiết kế pin tốt hơn, các nhà nghiên cứu thường thay đổi những yếu tố nào?",
        "options": {
          "A": "Kích thước và hình dạng của pin.",
          "B": "Kiến trúc điện cực, thành phần hóa học và mô hình dòng điện/điện áp khi sạc.",
          "C": "Vật liệu cách điện và hệ thống tản nhiệt.",
          "D": "Phần mềm quản lý năng lượng và giao diện người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm chính của việc sử dụng AI trong thử nghiệm pin là gì?",
        "options": {
          "A": "Giảm thiểu rủi ro cháy nổ trong quá trình thử nghiệm.",
          "B": "Cho phép thử nghiệm nhiều biến số cùng lúc và thu được kết quả khi pin vẫn còn năng lượng.",
          "C": "Tăng độ chính xác của các phép đo điện áp và dòng điện.",
          "D": "Giúp kéo dài tuổi thọ của các thiết bị thử nghiệm."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài việc thiết kế pin, Machine Learning còn được sử dụng để làm gì trong lĩnh vực năng lượng?",
        "options": {
          "A": "Dự đoán giá điện trên thị trường.",
          "B": "Phát hiện các lỗi trong hệ thống điện lưới.",
          "C": "Khám phá các phân tử mới cải thiện mật độ năng lượng.",
          "D": "Tối ưu hóa việc sử dụng năng lượng trong các tòa nhà."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến ứng dụng nào của pin được cải tiến nhờ Machine Learning?",
        "options": {
          "A": "Điện thoại thông minh có thời lượng pin dài hơn.",
          "B": "Xe tự lái và thiết bị cấy ghép não.",
          "C": "Máy tính xách tay có hiệu suất cao hơn.",
          "D": "Đèn LED tiết kiệm năng lượng hơn."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì là yếu tố then chốt để phát triển các thiết bị như xe tự lái?",
        "options": {
          "A": "Phần mềm điều khiển tiên tiến.",
          "B": "Hệ thống cảm biến chính xác.",
          "C": "Pin có tuổi thọ cao, sạc nhanh và chi phí thấp.",
          "D": "Hạ tầng giao thông thông minh."
        },
        "answer": "C"
      },
      {
        "question": "Trong những năm gần đây, Machine Learning đã giúp các nhà nghiên cứu làm gì liên quan đến tụ điện?",
        "options": {
          "A": "Giảm kích thước của tụ điện.",
          "B": "Tăng điện áp hoạt động của tụ điện.",
          "C": "Kiểm tra khả năng lưu trữ năng lượng của các thiết kế tụ điện.",
          "D": "Tìm ra vật liệu mới cho tụ điện."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, phương pháp truyền thống trong thiết kế pin thường gặp hạn chế gì?",
        "options": {
          "A": "Tốn nhiều thời gian và chi phí.",
          "B": "Chỉ thay đổi một biến số tại một thời điểm và phải đợi pin hỏng mới phân tích được kết quả.",
          "C": "Đòi hỏi kiến thức chuyên môn sâu rộng về hóa học và vật lý.",
          "D": "Khó dự đoán hiệu suất của pin trong các điều kiện khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Chris Manning đã ví von điều gì với trí tuệ nhân tạo (AI)?",
        "options": {
          "A": "Năng lượng tái tạo.",
          "B": "Điện.",
          "C": "Internet.",
          "D": "Dữ liệu lớn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến việc Machine Learning có thể giúp dự đoán điều gì liên quan đến pin trong xe điện?",
        "options": {
          "A": "Giá thành của pin.",
          "B": "Hiệu suất của pin trong các loại xe điện khác nhau.",
          "C": "Thời gian sản xuất pin.",
          "D": "Khả năng tái chế của pin."
        },
        "answer": "B"
      }
    ]
  },
  "in-a-galaxy-far-far-away": {
    "title": "In a Galaxy Far, Far Away",
    "collection": "science",
    "content": "The origin of the brief, high-intensity signals from outer space called fast radio bursts baffles astronomers. Now AI is generating real-time data to help solve the mystery.\n\nWhat’s new:A machine learning model deployed at the Molonglo Radio Telescope in Australiadetectedfive fast radio bursts in unprecedented detail.\n\nHow it works:The Molonglo telescope uses a standard program to flag incoming electromagnetic waves as fast radio burst candidates. However, the mystery signals share the same frequency band as cell phones, lightning storms, and solar emissions, so the system is prone to false positives. Researcher Wael Farah developed a machine learning model to pick out the most viable candidates.\n\nResults:Since the model debuted in April, 2018, it has flagged the most energetic fast radio burst and the one with the broadest spectrum, and it has captured the most detailed view of the signals’ rapidly fluctuating voltage.\n\nBehind the news:Earlier this year, American scientist Brian Metzger won a $3 million Breakthrough Prize for hisworkon a theory about the genesis of fast radio bursts — not SOSes from an alien intelligence, sadly, but shock waves produced by young neutron stars with dense magnetic fields.\n\nWhy it matters:Testing ideas about fast radio bursts requires more, and more detailed, data. Farrah’s model delivers it.\n\nWe’re thinking:Telescopes collect a crushing torrent of data. With the help of AI, human astronomers might manage to analyze them before the universe’s Big Crunch.",
    "qa": [
      {
        "question": "Hiện tượng nào đang gây khó khăn cho các nhà thiên văn học trong việc giải mã các vụ nổ sóng vô tuyến nhanh (fast radio bursts)?",
        "options": {
          "A": "Sự can thiệp từ các hành tinh xa xôi.",
          "B": "Nguồn gốc và bản chất của chúng vẫn chưa được xác định rõ.",
          "C": "Sự thiếu hụt các thiết bị quan sát hiện đại.",
          "D": "Sự phức tạp trong việc giải mã các tín hiệu từ người ngoài hành tinh."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình học máy được triển khai tại kính viễn vọng Molonglo ở Úc đã làm gì?",
        "options": {
          "A": "Phát hiện các hành tinh mới có khả năng chứa sự sống.",
          "B": "Phát hiện năm vụ nổ sóng vô tuyến nhanh với độ chi tiết chưa từng có.",
          "C": "Dự đoán thời điểm xảy ra các vụ nổ sóng vô tuyến nhanh.",
          "D": "Loại bỏ hoàn toàn các tín hiệu nhiễu từ môi trường."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính mà chương trình tiêu chuẩn của kính viễn vọng Molonglo gặp phải là gì?",
        "options": {
          "A": "Không đủ mạnh để phát hiện các tín hiệu yếu.",
          "B": "Dễ bị ảnh hưởng bởi các tín hiệu nhiễu từ các nguồn khác.",
          "C": "Quá chậm để xử lý lượng dữ liệu khổng lồ.",
          "D": "Không thể phân biệt được các loại sóng điện từ khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của mô hình học máy do Wael Farah phát triển là gì?",
        "options": {
          "A": "Tăng cường độ nhạy của kính viễn vọng.",
          "B": "Lọc ra các ứng cử viên tiềm năng nhất cho các vụ nổ sóng vô tuyến nhanh.",
          "C": "Phân tích thành phần hóa học của các vụ nổ sóng vô tuyến nhanh.",
          "D": "Dự đoán quỹ đạo của các vật thể phát ra sóng vô tuyến."
        },
        "answer": "B"
      },
      {
        "question": "Từ khi ra mắt vào tháng 4 năm 2018, mô hình học máy đã phát hiện ra điều gì đáng chú ý?",
        "options": {
          "A": "Vụ nổ sóng vô tuyến nhanh gần Trái Đất nhất.",
          "B": "Vụ nổ sóng vô tuyến nhanh mạnh nhất và có phổ rộng nhất.",
          "C": "Vụ nổ sóng vô tuyến nhanh có chu kỳ lặp lại đều đặn.",
          "D": "Vụ nổ sóng vô tuyến nhanh có nguồn gốc từ một thiên hà xa xôi."
        },
        "answer": "B"
      },
      {
        "question": "Brian Metzger đã nhận giải thưởng Breakthrough Prize cho công trình nghiên cứu về điều gì?",
        "options": {
          "A": "Phát hiện ra nguồn gốc của các vụ nổ sóng vô tuyến nhanh từ người ngoài hành tinh.",
          "B": "Xây dựng lý thuyết về sự hình thành của các vụ nổ sóng vô tuyến nhanh từ sao neutron trẻ.",
          "C": "Phát triển công nghệ mới để thu thập dữ liệu về các vụ nổ sóng vô tuyến nhanh.",
          "D": "Chứng minh rằng các vụ nổ sóng vô tuyến nhanh là tín hiệu tự nhiên từ vũ trụ."
        },
        "answer": "B"
      },
      {
        "question": "Theo lý thuyết của Brian Metzger, các vụ nổ sóng vô tuyến nhanh có thể được tạo ra bởi yếu tố nào?",
        "options": {
          "A": "Sóng xung kích từ các lỗ đen.",
          "B": "Sóng xung kích từ các sao neutron trẻ có từ trường mạnh.",
          "C": "Sự va chạm giữa các thiên hà.",
          "D": "Sự phân rã của vật chất tối."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc thu thập dữ liệu chi tiết hơn về các vụ nổ sóng vô tuyến nhanh lại quan trọng?",
        "options": {
          "A": "Để xác định vị trí chính xác của các nền văn minh ngoài hành tinh.",
          "B": "Để kiểm tra các giả thuyết về nguồn gốc và bản chất của chúng.",
          "C": "Để phát triển công nghệ liên lạc vượt không gian.",
          "D": "Để tìm kiếm các nguồn năng lượng mới trong vũ trụ."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết gợi ý rằng AI có thể giúp các nhà thiên văn học như thế nào?",
        "options": {
          "A": "Thay thế hoàn toàn công việc của các nhà thiên văn học.",
          "B": "Phân tích lượng dữ liệu khổng lồ mà kính viễn vọng thu thập được.",
          "C": "Tạo ra các mô hình vũ trụ ảo để nghiên cứu.",
          "D": "Dự đoán các sự kiện thiên văn trong tương lai."
        },
        "answer": "B"
      },
      {
        "question": "Cụm từ 'Big Crunch' trong bài viết đề cập đến điều gì?",
        "options": {
          "A": "Sự sụp đổ của một ngôi sao lớn.",
          "B": "Một giả thuyết về sự kết thúc của vũ trụ.",
          "C": "Sự va chạm giữa các thiên hà.",
          "D": "Sự hình thành của một lỗ đen."
        },
        "answer": "B"
      }
    ]
  },
  "high-energy-deep-learning": {
    "title": "High-Energy Deep Learning",
    "collection": "science",
    "content": "Nuclear fusion technology, long touted as an unlimited source of safe, clean energy, took a step toward reality with a machine learning algorithm that molds the fuel in a reactor’s core.What’s new:Researchers at DeepMind and École Polytechnique Fédérale de Lausanne (EPFL)developeda reinforcement learning algorithm to manipulate hydrogen plasma — an extremely high-energy form of matter — into an optimal shape for energy production.How it works:Reactors that confine plasma in a chamber known as a tokamak generate energy by pushing its atoms so close together that they fuse. A tokamak uses powerful magnetic coils to compress the plasma, heating it to the neighborhood of 100 million degrees Celsius to overcome the electrostatic force that normally pushes them apart. The authors trained a reinforcement learning model to control the voltage of 19 magnetic coils in a small, experimental tokamak reactor, enabling them to shape the plasma in ways that are consistent with maintaining an ongoing fusion reaction.\n\nResults:In experimental runs with the real-world reactor, a previous algorithm controlled the coils to form a preliminary plasma shape before handing off the task to the authors’ model. Plasma can't be observed directly, so the authors calculated its shape and position properties based on measurements of the magnetic field within the tokamak. In five separate experiments, the controller formed the plasma into distinct shapes, such as a conventional elongated shape and a prospective “snowflake” shape, within particular tolerances (2 centimeters root mean squared error for shape, 5 kiloamperes root mean squared error for current passing through the plasma). In a novel feat, the algorithm maintained two separate plasma droplets for 200 milliseconds.Behind the news:Conventional nuclear energy results from nuclear fission. Scientists have been trying to harness nuclear fusion since the 1950s. Yet no fusion reactor has generated more energy than it consumed. (The U.S. National Ignition Facilitycame the closest yetlast year.) A growing number of scientists areenlistingmachine learning to manage the hundreds of factors involved in sustaining a fusion reaction.\n\nWhy it matters:Plasma in a tokamak, which is several times hotter than the sun and reverts to vapor if its electromagnetic container falters, is continually in flux. This work not only shows that deep learning can shape it in real time, it also opens the door to forming plasma in ways that might yield more energy. The next challenge: Scale up to a reactor large enough to produce meaningful quantities of energy.We’re thinking:Fusion energy — if it ever works — would be a game changer for civilization. It’s thrilling to see deep learning potentially playing a key role in this technology.",
    "qa": [
      {
        "question": "Công nghệ nào đã được sử dụng để tạo hình plasma trong lò phản ứng tokamak?",
        "options": {
          "A": "Mô hình mô phỏng vật lý lượng tử",
          "B": "Thuật toán học tăng cường (reinforcement learning)",
          "C": "Phương pháp điều khiển phản hồi tuyến tính",
          "D": "Mạng nơ-ron tích chập (convolutional neural network)"
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của việc sử dụng thuật toán học tăng cường trong lò phản ứng hạt nhân tổng hợp là gì?",
        "options": {
          "A": "Giảm chi phí xây dựng lò phản ứng",
          "B": "Tối ưu hóa hình dạng plasma để sản xuất năng lượng hiệu quả hơn",
          "C": "Tăng cường độ an toàn của lò phản ứng",
          "D": "Giảm thiểu lượng chất thải phóng xạ"
        },
        "answer": "B"
      },
      {
        "question": "Tokamak sử dụng yếu tố nào để nén và làm nóng plasma?",
        "options": {
          "A": "Áp suất cực cao",
          "B": "Từ trường mạnh",
          "C": "Sóng siêu âm",
          "D": "Bức xạ laser cường độ cao"
        },
        "answer": "B"
      },
      {
        "question": "Nhiệt độ cần thiết để các nguyên tử plasma hợp nhất trong lò phản ứng tokamak là khoảng bao nhiêu?",
        "options": {
          "A": "1 triệu độ C",
          "B": "10 triệu độ C",
          "C": "100 triệu độ C",
          "D": "1 tỷ độ C"
        },
        "answer": "C"
      },
      {
        "question": "Trong các thí nghiệm được mô tả, thuật toán đã kiểm soát yếu tố nào của các cuộn dây từ tính?",
        "options": {
          "A": "Điện trở",
          "B": "Điện áp",
          "C": "Dòng điện",
          "D": "Từ thông"
        },
        "answer": "B"
      },
      {
        "question": "Sai số trung phương gốc (root mean squared error) cho hình dạng plasma trong các thí nghiệm là bao nhiêu?",
        "options": {
          "A": "1 centimet",
          "B": "2 centimet",
          "C": "5 centimet",
          "D": "10 centimet"
        },
        "answer": "B"
      },
      {
        "question": "Điểm mới trong thí nghiệm được đề cập là gì?",
        "options": {
          "A": "Duy trì plasma trong thời gian dài hơn",
          "B": "Tạo ra năng lượng nhiều hơn năng lượng tiêu thụ",
          "C": "Duy trì hai giọt plasma riêng biệt",
          "D": "Sử dụng vật liệu mới cho lò phản ứng"
        },
        "answer": "C"
      },
      {
        "question": "Nguồn năng lượng hạt nhân thông thường hiện nay dựa trên quá trình nào?",
        "options": {
          "A": "Phản ứng tổng hợp hạt nhân",
          "B": "Phản ứng phân hạch hạt nhân",
          "C": "Phản ứng hóa học",
          "D": "Phản ứng nhiệt hạch"
        },
        "answer": "B"
      },
      {
        "question": "Thách thức lớn nhất hiện tại trong việc phát triển năng lượng hạt nhân tổng hợp là gì?",
        "options": {
          "A": "Tìm kiếm vật liệu chịu nhiệt tốt hơn",
          "B": "Giảm chi phí xây dựng lò phản ứng",
          "C": "Tạo ra lò phản ứng sản xuất nhiều năng lượng hơn năng lượng tiêu thụ",
          "D": "Giải quyết vấn đề chất thải phóng xạ"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì xảy ra nếu thùng chứa điện từ của plasma trong tokamak bị lỗi?",
        "options": {
          "A": "Plasma sẽ nguội đi nhanh chóng",
          "B": "Plasma sẽ chuyển thành hơi",
          "C": "Plasma sẽ phát nổ",
          "D": "Plasma sẽ trở nên ổn định hơn"
        },
        "answer": "B"
      }
    ]
  },
  "johnson-johnson-reveals-its-revised-ai-strategy": {
    "title": "AI Insights from Big Pharma",
    "collection": "science",
    "content": "The world’s biggest pharmaceutical company by revenue shed light on its AI strategy.\n\nWhat’s new:Johnson & Johnson, after experimenting broadly with generative AI, settled on a short list of projects that aid in sales, drug development, supply-chain management, and internal communications. A company executive described the process and results to the venture-capital firmGreylockandThe Wall Street Journal.\n\nHow it works:The 140-year-old medical company spent roughly a year experimenting with various AIapplicationsthroughout the company, according to Chief Information Officer Jim Swanson. A centralized governing board oversaw as many as 900 experiments. After finding that 10 percent to 15 percent of use cases drove about 80 percent of the value, the company shifted responsibility for AI projects to specific departments to focus on high-value applications. In the end, the criteria for choosing a project was threefold: (i) how readily it could be implemented, (ii) how useful it would be throughout the company, and (iii) how much it would benefit the business.\n\nBehind the news:Generative AI is expected to bring in up to $110 billion in annual revenue across the pharmaceutical industry,according to McKinsey. The consultancy breaks down this number into the following categories, in order of their contribution to the total: commercial (AI for sales and marketing), research (AI for designing, screening, and manufacturing molecules), clinical (AI to facilitate trials), enterprise, operations, and medical (processing medical literature).\n\nWhy it matters:Johnson & Johnson’s experience offers a peek into AI development at a major legacy company in a key sector. The company has identified high-value opportunities in enterprise-wide operations, departmental priorities, and core products. It’s pursuing all three.\n\nWe’re thinking:Notably, this medical stalwart is building AI applications for human resources, sales, and supply-chain management. Similar opportunities exist at companies old and new, big and small, far and wide.",
    "qa": [
      {
        "question": "Công ty dược phẩm lớn nhất thế giới theo doanh thu trong bài viết là công ty nào?",
        "options": {
          "A": "Pfizer",
          "B": "Johnson & Johnson",
          "C": "Merck & Co.",
          "D": "Novartis"
        },
        "answer": "B"
      },
      {
        "question": "Johnson & Johnson đã sử dụng AI trong lĩnh vực nào sau đây?",
        "options": {
          "A": "Nghiên cứu vũ trụ",
          "B": "Phát triển thuốc",
          "C": "Xây dựng cơ sở hạ tầng",
          "D": "Sản xuất ô tô"
        },
        "answer": "B"
      },
      {
        "question": "Ai là người chịu trách nhiệm chính trong việc giám sát các thử nghiệm AI tại Johnson & Johnson?",
        "options": {
          "A": "Giám đốc điều hành (CEO)",
          "B": "Hội đồng quản trị trung ương",
          "C": "Giám đốc tài chính (CFO)",
          "D": "Giám đốc công nghệ (CTO)"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, Johnson & Johnson đã thực hiện khoảng bao nhiêu thử nghiệm AI?",
        "options": {
          "A": "Khoảng 90 thử nghiệm",
          "B": "Khoảng 500 thử nghiệm",
          "C": "Khoảng 900 thử nghiệm",
          "D": "Khoảng 1500 thử nghiệm"
        },
        "answer": "C"
      },
      {
        "question": "Sau quá trình thử nghiệm, Johnson & Johnson đã chuyển giao trách nhiệm cho các dự án AI cho ai?",
        "options": {
          "A": "Các công ty tư vấn bên ngoài",
          "B": "Các phòng ban cụ thể",
          "C": "Một nhóm chuyên gia AI tập trung",
          "D": "Các trường đại học và viện nghiên cứu"
        },
        "answer": "B"
      },
      {
        "question": "Tiêu chí nào KHÔNG được Johnson & Johnson sử dụng để lựa chọn dự án AI?",
        "options": {
          "A": "Khả năng triển khai dễ dàng",
          "B": "Mức độ hữu ích cho toàn công ty",
          "C": "Lợi ích kinh doanh mang lại",
          "D": "Tính độc đáo và sáng tạo của dự án"
        },
        "answer": "D"
      },
      {
        "question": "Theo McKinsey, doanh thu hàng năm từ AI trong ngành dược phẩm dự kiến đạt bao nhiêu?",
        "options": {
          "A": "50 tỷ đô la",
          "B": "75 tỷ đô la",
          "C": "100 tỷ đô la",
          "D": "110 tỷ đô la"
        },
        "answer": "D"
      },
      {
        "question": "Lĩnh vực nào được McKinsey dự đoán sẽ đóng góp nhiều nhất vào doanh thu AI trong ngành dược phẩm?",
        "options": {
          "A": "Nghiên cứu",
          "B": "Kinh doanh (Sales)",
          "C": "Lâm sàng (Clinical)",
          "D": "Vận hành (Operations)"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về kinh nghiệm của Johnson & Johnson trong việc phát triển AI?",
        "options": {
          "A": "Sự thất bại trong việc áp dụng AI vào các quy trình cốt lõi",
          "B": "Cái nhìn sâu sắc về quá trình phát triển AI tại một công ty lớn trong một lĩnh vực quan trọng",
          "C": "Sự phụ thuộc quá mức vào các giải pháp AI từ bên ngoài",
          "D": "Việc thiếu sự đầu tư vào đào tạo nhân viên về AI"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết gợi ý rằng cơ hội áp dụng AI có thể tìm thấy ở đâu?",
        "options": {
          "A": "Chỉ ở các công ty công nghệ lớn",
          "B": "Chỉ ở các công ty dược phẩm",
          "C": "Ở các công ty thuộc mọi quy mô và lĩnh vực",
          "D": "Chỉ ở các công ty mới thành lập"
        },
        "answer": "C"
      }
    ]
  },
  "managing-medical-uncertainty": {
    "title": "Managing Medical Uncertainty",
    "collection": "science",
    "content": "Hospitals across the United States are relying on AI to keep patients safe.What’s new:Doctors are using a variety of machine learning systems to assess the risk that a given patient will suffer complications,The Wall Street Journalreported.How it works:Several facilities are using AI to identify patients who need special attention.\n\nBehind the news:Government regulators are beginning to accept machine learning’s potential to transform healthcare.\n\nWhy it matters:The Covid-19 pandemic has highlighted tragically underfunded and overworked healthcare workers around the globe. Automated tools could help providers make better use of limited time and resources and help them to focus their attention on the most important cases.We’re thinking:Many countries face a demographic cliff: The population of younger people is falling precipitously, while the number of elders is growing. It seems likely that AI will be instrumental in helping doctors care for an aging population with a rising life expectancy.",
    "qa": [
      {
        "question": "Các bệnh viện ở Hoa Kỳ đang sử dụng AI để làm gì?",
        "options": {
          "A": "Thay thế hoàn toàn bác sĩ trong việc chẩn đoán bệnh.",
          "B": "Đảm bảo an toàn cho bệnh nhân.",
          "C": "Giảm chi phí hoạt động của bệnh viện.",
          "D": "Nghiên cứu các phương pháp điều trị mới."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, hệ thống máy học được sử dụng để làm gì trong các bệnh viện?",
        "options": {
          "A": "Tự động phẫu thuật cho bệnh nhân.",
          "B": "Đánh giá nguy cơ biến chứng của bệnh nhân.",
          "C": "Quản lý hồ sơ bệnh án điện tử.",
          "D": "Dự đoán số lượng bệnh nhân nhập viện."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến việc cơ quan quản lý chính phủ đang có thái độ như thế nào đối với việc ứng dụng máy học trong y tế?",
        "options": {
          "A": "Phản đối mạnh mẽ vì lo ngại về rủi ro.",
          "B": "Bắt đầu chấp nhận tiềm năng chuyển đổi của máy học.",
          "C": "Chưa có bất kỳ phản hồi nào.",
          "D": "Yêu cầu các bệnh viện ngừng sử dụng AI ngay lập tức."
        },
        "answer": "B"
      },
      {
        "question": "Đại dịch Covid-19 đã làm nổi bật vấn đề gì trong ngành y tế?",
        "options": {
          "A": "Sự thiếu hụt công nghệ hiện đại.",
          "B": "Tình trạng thiếu kinh phí và quá tải công việc của nhân viên y tế.",
          "C": "Sự phân bố không đồng đều các bệnh viện trên toàn quốc.",
          "D": "Sự thiếu hụt các bác sĩ chuyên khoa."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ tự động hóa có thể giúp các nhà cung cấp dịch vụ y tế như thế nào?",
        "options": {
          "A": "Giảm số lượng bệnh nhân cần điều trị.",
          "B": "Sử dụng hiệu quả hơn thời gian và nguồn lực hạn chế.",
          "C": "Tăng lương cho nhân viên y tế.",
          "D": "Thay thế hoàn toàn vai trò của bác sĩ."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến 'vách đá nhân khẩu học' là gì?",
        "options": {
          "A": "Sự gia tăng đột ngột số lượng người nhập cư.",
          "B": "Sự suy giảm nhanh chóng dân số trẻ và sự gia tăng dân số già.",
          "C": "Sự phân bố không đồng đều dân số giữa các vùng.",
          "D": "Sự gia tăng tỷ lệ sinh ở các nước phát triển."
        },
        "answer": "B"
      },
      {
        "question": "AI có khả năng đóng vai trò gì trong việc chăm sóc sức khỏe cho dân số già?",
        "options": {
          "A": "Thay thế hoàn toàn các viện dưỡng lão.",
          "B": "Hỗ trợ bác sĩ chăm sóc dân số già với tuổi thọ ngày càng tăng.",
          "C": "Giảm chi phí bảo hiểm y tế cho người cao tuổi.",
          "D": "Kéo dài tuổi thọ trung bình của con người."
        },
        "answer": "B"
      },
      {
        "question": "Tờ báo nào đã đưa tin về việc sử dụng AI trong các bệnh viện ở Hoa Kỳ?",
        "options": {
          "A": "The New York Times.",
          "B": "The Wall Street Journal.",
          "C": "The Washington Post.",
          "D": "USA Today."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của việc sử dụng AI trong các bệnh viện là gì?",
        "options": {
          "A": "Tăng lợi nhuận cho bệnh viện.",
          "B": "Giảm thời gian chờ đợi của bệnh nhân.",
          "C": "Tập trung sự chú ý vào các trường hợp quan trọng nhất.",
          "D": "Thu thập dữ liệu bệnh nhân cho mục đích nghiên cứu."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì có khả năng xảy ra khi dân số trẻ giảm và dân số già tăng lên?",
        "options": {
          "A": "Nguồn cung lao động sẽ tăng lên.",
          "B": "AI sẽ đóng vai trò quan trọng trong việc chăm sóc sức khỏe.",
          "C": "Chi phí giáo dục sẽ giảm đáng kể.",
          "D": "Các bệnh viện sẽ trở nên ít quan trọng hơn."
        },
        "answer": "B"
      }
    ]
  },
  "listening-to-the-brain": {
    "title": "Listening to the Brain",
    "collection": "science",
    "content": "Neural networks translated a paralyzed man’s brainwaves into conversational phrases.\n\nWhat’s new:Researchers at UC San Francisco and UC Berkeley trained asystemto interpret electrical impulses from the brain of a man who had lost the ability to speak 15 years ago, and displayed them as words on a video screen.\n\nHow it works:The researchers implanted an array of 128 electrodes into the region of the brain responsible for movement of the mouth, lips, jaw, tongue, and larynx. They connected the implant to a computer. Then they asked the patient to try to speak 50 common words and 50 common phrases and recorded the resulting brain activity. They trained the system on 22 hours of these signals, team member Sean Metzger at UC San Francisco toldThe Batch.\n\nResults:During tests, the system decoded a median of 15.2 words per minute and translated sentences with a median error rate of 25.6 percent.\n\nBehind the news:The system was built on more than a decade of research by lead author and neurosurgeon Edward F. Chang intolinksbetween neurological activity and the sounds of spoken language. A similar project called BrainGatetranslatedbrain signals associated with the act of handwriting into text.\n\nWhy it matters:Accidents, diseases, and other tragedies rob countless people of their ability to communicate. This technology opens a pathway for them to reconnect.\n\nWe’re thinking:It’s wonderful to seenatural language modelsrestoring the most natural form of language.",
    "qa": [
      {
        "question": "Công nghệ mới được đề cập trong bài viết đã giúp một người bị liệt có thể làm gì?",
        "options": {
          "A": "Đi lại bình thường.",
          "B": "Giao tiếp bằng lời nói thông qua giải mã sóng não.",
          "C": "Điều khiển các thiết bị điện tử bằng suy nghĩ.",
          "D": "Cảm nhận xúc giác trở lại."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã cấy ghép bao nhiêu điện cực vào não của bệnh nhân?",
        "options": {
          "A": "64",
          "B": "128",
          "C": "256",
          "D": "50"
        },
        "answer": "B"
      },
      {
        "question": "Khu vực não bộ nào được các nhà nghiên cứu tập trung vào để cấy ghép điện cực?",
        "options": {
          "A": "Khu vực chịu trách nhiệm về thị giác.",
          "B": "Khu vực chịu trách nhiệm về trí nhớ.",
          "C": "Khu vực chịu trách nhiệm về vận động của miệng, môi, hàm, lưỡi và thanh quản.",
          "D": "Khu vực chịu trách nhiệm về cảm xúc."
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống đã được huấn luyện trong bao lâu để giải mã tín hiệu não?",
        "options": {
          "A": "10 giờ",
          "B": "15 giờ",
          "C": "22 giờ",
          "D": "30 giờ"
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống có thể giải mã trung bình bao nhiêu từ mỗi phút?",
        "options": {
          "A": "10.5",
          "B": "12.8",
          "C": "15.2",
          "D": "20.0"
        },
        "answer": "C"
      },
      {
        "question": "Tỷ lệ lỗi trung bình khi hệ thống dịch các câu là bao nhiêu?",
        "options": {
          "A": "15.2%",
          "B": "20.0%",
          "C": "25.6%",
          "D": "30.0%"
        },
        "answer": "C"
      },
      {
        "question": "Ai là tác giả chính và là nhà giải phẫu thần kinh đứng sau nghiên cứu này?",
        "options": {
          "A": "Sean Metzger",
          "B": "Edward F. Chang",
          "C": "UC San Francisco",
          "D": "UC Berkeley"
        },
        "answer": "B"
      },
      {
        "question": "Dự án nào tương tự đã dịch tín hiệu não liên quan đến hành động viết tay thành văn bản?",
        "options": {
          "A": "Neuralink",
          "B": "BrainGate",
          "C": "OpenAI",
          "D": "DeepMind"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, công nghệ này có ý nghĩa quan trọng như thế nào?",
        "options": {
          "A": "Giúp con người giao tiếp nhanh hơn.",
          "B": "Mở ra con đường kết nối lại cho những người mất khả năng giao tiếp.",
          "C": "Tăng cường khả năng ghi nhớ của con người.",
          "D": "Thay thế hoàn toàn ngôn ngữ nói."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết thể hiện quan điểm gì về việc sử dụng mô hình ngôn ngữ tự nhiên trong nghiên cứu này?",
        "options": {
          "A": "Mô hình ngôn ngữ tự nhiên còn nhiều hạn chế.",
          "B": "Mô hình ngôn ngữ tự nhiên không phù hợp với việc giải mã sóng não.",
          "C": "Việc sử dụng mô hình ngôn ngữ tự nhiên là một bước tiến tuyệt vời trong việc khôi phục ngôn ngữ tự nhiên.",
          "D": "Mô hình ngôn ngữ tự nhiên chỉ nên được sử dụng trong các ứng dụng giải trí."
        },
        "answer": "C"
      }
    ]
  },
  "materials-science-gets-a-boost": {
    "title": "Materials Science Gets a Boost",
    "collection": "science",
    "content": "Neural nets could speed up development of new materials.What’s new:A deep learningsystemfrom Sandia National Laboratories dramatically accelerated simulations that help scientists understand how changes to the design or fabrication of a material — say, the balance of metals in an alloy — change its properties.How it works:The researchers trained an LSTM to predict how the properties of a material evolve during the process known as spinodal decomposition, in which a material separates into its constituents in the presence or absence of heat.\n\nResults:In tests, the model simulated thermodynamic processes, such as the way a molten alloy congeals as it cools, more than 42,000 times faster than traditional simulations: 60 milliseconds versus 12 minutes. However, the increased speed came at a cost of slightly reduced accuracy, which fell by 5 percent compared to the traditional approach.Behind the news:Machine learning has shown promise as a shortcut to a variety of scientific simulations.\n\nWhy it matters:Faster simulations of materials can quicken the pace of discovery in areas as diverse as optics, aerospace, energy storage, and medicine. The Sandia team plans to use its model to explore ultrathin optical technologies for next-generation video monitors.We’re thinking:From Gorilla Glass to graphene,advanced materialsare transforming the world. Machine learning is poised to help such innovations reach the market faster than ever.",
    "qa": [
      {
        "question": "Hệ thống deep learning được đề cập trong bài viết đến từ đâu?",
        "options": {
          "A": "Google AI",
          "B": "Sandia National Laboratories",
          "C": "Massachusetts Institute of Technology (MIT)",
          "D": "Stanford University"
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống deep learning này được huấn luyện để dự đoán điều gì?",
        "options": {
          "A": "Sự thay đổi giá cổ phiếu của các công ty vật liệu",
          "B": "Cách các thuộc tính của vật liệu tiến triển trong quá trình phân tách spinodal",
          "C": "Ảnh hưởng của nhiệt độ lên độ bền của vật liệu",
          "D": "Cấu trúc tinh thể của các hợp kim mới"
        },
        "answer": "B"
      },
      {
        "question": "LSTM là viết tắt của cụm từ nào trong bối cảnh bài viết?",
        "options": {
          "A": "Long Short-Term Memory",
          "B": "Linear System Thermal Modeling",
          "C": "Latent Semantic Text Matching",
          "D": "Local Spatial Temporal Mapping"
        },
        "answer": "A"
      },
      {
        "question": "Trong các thử nghiệm, mô hình deep learning nhanh hơn bao nhiêu lần so với các mô phỏng truyền thống?",
        "options": {
          "A": "Gấp 42 lần",
          "B": "Gấp 420 lần",
          "C": "Gấp 4,200 lần",
          "D": "Gấp 42,000 lần"
        },
        "answer": "D"
      },
      {
        "question": "Tốc độ tăng lên của mô hình deep learning đi kèm với sự đánh đổi nào?",
        "options": {
          "A": "Độ phức tạp của thuật toán tăng lên",
          "B": "Độ chính xác giảm đi một chút",
          "C": "Yêu cầu phần cứng cao hơn",
          "D": "Khả năng mở rộng bị hạn chế"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến lĩnh vực nào có thể được hưởng lợi từ các mô phỏng vật liệu nhanh hơn?",
        "options": {
          "A": "Nông nghiệp",
          "B": "Tài chính",
          "C": "Hàng không vũ trụ",
          "D": "Marketing"
        },
        "answer": "C"
      },
      {
        "question": "Nhóm nghiên cứu Sandia dự định sử dụng mô hình của họ để khám phá công nghệ nào?",
        "options": {
          "A": "Công nghệ pin mặt trời hiệu suất cao",
          "B": "Công nghệ quang học siêu mỏng cho màn hình video thế hệ mới",
          "C": "Công nghệ vật liệu siêu dẫn nhiệt độ cao",
          "D": "Công nghệ in 3D vật liệu composite"
        },
        "answer": "B"
      },
      {
        "question": "Quá trình 'spinodal decomposition' được mô tả trong bài viết là gì?",
        "options": {
          "A": "Quá trình làm nóng chảy kim loại ở nhiệt độ cao",
          "B": "Quá trình vật liệu tách thành các thành phần cấu tạo của nó khi có hoặc không có nhiệt",
          "C": "Quá trình tạo ra vật liệu nano bằng cách sử dụng tia laser",
          "D": "Quá trình phủ một lớp vật liệu mỏng lên bề mặt khác"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết sử dụng ví dụ nào để minh họa cho sự biến đổi thế giới nhờ vật liệu tiên tiến?",
        "options": {
          "A": "Nhựa tái chế và sợi carbon",
          "B": "Gorilla Glass và graphene",
          "C": "Thép không gỉ và nhôm",
          "D": "Gốm sứ và thủy tinh hữu cơ"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lợi ích chính của việc sử dụng machine learning trong mô phỏng vật liệu là gì?",
        "options": {
          "A": "Giảm chi phí sản xuất vật liệu",
          "B": "Tăng độ bền của vật liệu",
          "C": "Rút ngắn thời gian đưa các cải tiến vật liệu ra thị trường",
          "D": "Cải thiện khả năng tái chế vật liệu"
        },
        "answer": "C"
      }
    ]
  },
  "mattergen-a-diffusion-model-that-designs-new-materials-with-specified-properties": {
    "title": "Designer Materials",
    "collection": "science",
    "content": "Materials that have specific properties are essential to progress in critical technologies like solar cells and batteries. A machine learning model designs new materials to order.\n\nWhat’s new:Researchers at Microsoft and Shenzhen Institute of Advanced Technology proposedMatterGen, a diffusion model that generates a material’s chemical composition and structure from a prompt that specifies a desired property. The model and code areavailableunder a license that allows commercial as well as noncommercial uses without limitation. The trainingdataalso is noncommercially available.\n\nHow it works:MatterGen’s training followed a two-stage process. In the first stage, it learned to generate materials (specifically crystals — no liquids, gasses, or amorphous solids like glass). In the second, it learned to generate materials given a target mechanical, electronic, magnetic, or chemical property such as magnetic density or bulk modulus (the material’s resistance to compression).\n\nResults:The authors generated a variety of materials, and they synthesized one to test whether it had a target property. Specifically, they generated over 8,000 candidates with the target bulk modulus of 200 gigapascals (a measure of resistance to uniform compression), then automatically filtered them based on a number of factors to eliminate material in their dataset and unstable materials. Of the remaining candidates, they chose four manually and successfully synthesized one. The resulting crystal had a measured bulk modulus of 158 gigapascals. (Most materials in the dataset had a bulk modulus of between 0 and 400 gigapascals.)\n\nBehind the news:Published in 2023,DiffCSPalso uses a diffusion model to generate the structures of new materials. However, it does so without considering their desired properties.\n\nWhy it matters:Discovering materials relies mostly on searching large databases of existing materials for those with desired properties or synthesizing new materials and testing their properties by trial and error. Designing new crystals with desired properties at the click of a button accelerates the process dramatically.\n\nWe’re thinking:While using AI to design materials accelerates an important step, determining whether a hypothesized material can be  manufactured efficiently at scale is still challenging. We look forward to research into AI models that also take into account ease of manufacturing.",
    "qa": [
      {
        "question": "Mục đích chính của MatterGen là gì?",
        "options": {
          "A": "Tìm kiếm vật liệu hiện có trong cơ sở dữ liệu lớn.",
          "B": "Thiết kế vật liệu mới theo yêu cầu về tính chất.",
          "C": "Tổng hợp vật liệu mới và thử nghiệm tính chất của chúng.",
          "D": "Cải thiện quy trình sản xuất vật liệu hiện có."
        },
        "answer": "B"
      },
      {
        "question": "MatterGen được phát triển bởi tổ chức nào?",
        "options": {
          "A": "Google và Viện Công nghệ Tiên tiến Thâm Quyến.",
          "B": "Microsoft và Viện Công nghệ Massachusetts.",
          "C": "Microsoft và Viện Công nghệ Tiên tiến Thâm Quyến.",
          "D": "Stanford và Viện Công nghệ California."
        },
        "answer": "C"
      },
      {
        "question": "MatterGen sử dụng mô hình nào để tạo ra vật liệu?",
        "options": {
          "A": "Mô hình hồi quy tuyến tính.",
          "B": "Mô hình phân loại cây quyết định.",
          "C": "Mô hình khuếch tán (diffusion model).",
          "D": "Mạng nơ-ron tích chập."
        },
        "answer": "C"
      },
      {
        "question": "Trong quá trình huấn luyện, MatterGen học cách tạo ra loại vật liệu nào?",
        "options": {
          "A": "Chất lỏng.",
          "B": "Chất khí.",
          "C": "Chất rắn vô định hình.",
          "D": "Tinh thể."
        },
        "answer": "D"
      },
      {
        "question": "Tính chất nào của vật liệu được MatterGen sử dụng làm mục tiêu trong giai đoạn huấn luyện thứ hai?",
        "options": {
          "A": "Độ dẫn điện.",
          "B": "Độ bền kéo.",
          "C": "Mô đun khối (bulk modulus).",
          "D": "Nhiệt độ nóng chảy."
        },
        "answer": "C"
      },
      {
        "question": "Trong thử nghiệm được đề cập, MatterGen đã tạo ra vật liệu có mô đun khối gần với giá trị mục tiêu nào?",
        "options": {
          "A": "50 gigapascal.",
          "B": "100 gigapascal.",
          "C": "158 gigapascal.",
          "D": "200 gigapascal."
        },
        "answer": "C"
      },
      {
        "question": "DiffCSP khác với MatterGen ở điểm nào?",
        "options": {
          "A": "DiffCSP sử dụng mô hình hồi quy thay vì mô hình khuếch tán.",
          "B": "DiffCSP xem xét các tính chất mong muốn của vật liệu.",
          "C": "DiffCSP không xem xét các tính chất mong muốn của vật liệu.",
          "D": "DiffCSP chỉ tạo ra chất lỏng và chất khí."
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích chính của việc sử dụng AI để thiết kế vật liệu là gì?",
        "options": {
          "A": "Giảm chi phí sản xuất vật liệu.",
          "B": "Tăng độ bền của vật liệu.",
          "C": "Tăng tốc quá trình khám phá vật liệu mới.",
          "D": "Loại bỏ hoàn toàn nhu cầu thử nghiệm vật liệu."
        },
        "answer": "C"
      },
      {
        "question": "Thách thức nào vẫn còn tồn tại trong việc sử dụng AI để thiết kế vật liệu?",
        "options": {
          "A": "Khả năng dự đoán chính xác tính chất của vật liệu.",
          "B": "Khả năng sản xuất vật liệu hiệu quả ở quy mô lớn.",
          "C": "Khả năng tạo ra vật liệu hoàn toàn mới.",
          "D": "Khả năng tích hợp AI vào quy trình sản xuất hiện có."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu huấn luyện của MatterGen có sẵn cho mục đích sử dụng nào?",
        "options": {
          "A": "Chỉ cho mục đích phi thương mại.",
          "B": "Chỉ cho mục đích thương mại.",
          "C": "Cho cả mục đích thương mại và phi thương mại.",
          "D": "Chỉ cho mục đích nghiên cứu học thuật."
        },
        "answer": "C"
      }
    ]
  },
  "model-see-model-do": {
    "title": "Model See, Model Do",
    "collection": "science",
    "content": "Scientists who study animal behavior spend endless hours observing and taking notes about a creature’s actions and reactions. Computer vision could automate much of that work.What’s new:Researchers at Facebook, the Max Planck Institute for Evolutionary Anthropology, and the Pan-African Programme (part of a partnership between African and European governments) built aneural network that tracks the body position of chimpanzees. The system captures the animals’ behavior in three dimensions for study and analysis.How it works:The researchers started withDensePose, a pose estimator pre-trained on videos of humans. They fine-tuned it for chimps in two phases, first using a segmentation model and then using a teacher-student scheme.\n\nBehind the news:This work complements earlier efforts to use deep learning to help scientists study animal behavior.\n\nWhy it matters:Annotating videos of animal behavior is labor-intensive, and building annotated datasets for thousands of species would be prohibitively expensive. The authors adapted a neural network’s knowledge of human anatomy to work with another species, albeit a similar one. They believe their method could work with less human-like species as well.We’re thinking:What a brilliant ape-lication!",
    "qa": [
      {
        "question": "Mục đích chính của việc nghiên cứu hành vi động vật là gì?",
        "options": {
          "A": "Để huấn luyện động vật phục vụ con người.",
          "B": "Để quan sát và ghi chép lại các hành động và phản ứng của chúng.",
          "C": "Để tìm hiểu về giải phẫu học của động vật.",
          "D": "Để phát triển các phương pháp bảo tồn động vật hoang dã."
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ mới nào được đề cập trong bài viết có thể giúp tự động hóa việc nghiên cứu hành vi động vật?",
        "options": {
          "A": "Công nghệ sinh học phân tử.",
          "B": "Thị giác máy tính (Computer vision).",
          "C": "Công nghệ nano.",
          "D": "Công nghệ in 3D."
        },
        "answer": "B"
      },
      {
        "question": "Mạng nơ-ron được phát triển trong nghiên cứu này có khả năng gì?",
        "options": {
          "A": "Phân tích DNA của tinh tinh.",
          "B": "Theo dõi vị trí cơ thể của tinh tinh trong không gian ba chiều.",
          "C": "Dự đoán thời tiết dựa trên hành vi của tinh tinh.",
          "D": "Giao tiếp với tinh tinh bằng ngôn ngữ ký hiệu."
        },
        "answer": "B"
      },
      {
        "question": "Mạng nơ-ron này ban đầu được huấn luyện trên dữ liệu nào?",
        "options": {
          "A": "Hình ảnh và video của các loài động vật khác nhau.",
          "B": "Video của con người.",
          "C": "Dữ liệu cảm biến từ môi trường sống của tinh tinh.",
          "D": "Hình ảnh X-quang của tinh tinh."
        },
        "answer": "B"
      },
      {
        "question": "Kỹ thuật nào được sử dụng để điều chỉnh mạng nơ-ron cho phù hợp với tinh tinh?",
        "options": {
          "A": "Sử dụng thuật toán di truyền.",
          "B": "Tinh chỉnh bằng mô hình phân đoạn và lược đồ giáo viên-học sinh.",
          "C": "Huấn luyện tăng cường.",
          "D": "Sử dụng mạng đối nghịch sinh (GAN)."
        },
        "answer": "B"
      },
      {
        "question": "DensePose là gì?",
        "options": {
          "A": "Một loại thức ăn đặc biệt dành cho tinh tinh.",
          "B": "Một ước tính tư thế được huấn luyện trước trên video của con người.",
          "C": "Một phương pháp theo dõi GPS cho động vật hoang dã.",
          "D": "Một phần mềm phân tích hành vi động vật."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc chú thích video về hành vi động vật lại tốn nhiều công sức?",
        "options": {
          "A": "Do chất lượng video thường kém.",
          "B": "Do đòi hỏi kiến thức chuyên môn sâu về hành vi động vật.",
          "C": "Do số lượng video cần xử lý rất lớn.",
          "D": "Do phần mềm chú thích video còn nhiều hạn chế."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích chính của việc sử dụng deep learning trong nghiên cứu hành vi động vật là gì?",
        "options": {
          "A": "Giảm chi phí nghiên cứu.",
          "B": "Tăng tốc độ phân tích dữ liệu.",
          "C": "Tự động hóa quá trình chú thích video.",
          "D": "Tất cả các đáp án trên."
        },
        "answer": "D"
      },
      {
        "question": "Các tác giả tin rằng phương pháp của họ có thể áp dụng cho những loài nào?",
        "options": {
          "A": "Chỉ những loài có cấu trúc giải phẫu tương tự như con người.",
          "B": "Chỉ những loài linh trưởng.",
          "C": "Cả những loài ít giống con người hơn.",
          "D": "Chỉ những loài sống trong môi trường hoang dã."
        },
        "answer": "C"
      },
      {
        "question": "Cụm từ \"ape-lication\" trong bài viết mang ý nghĩa gì?",
        "options": {
          "A": "Một ứng dụng dành riêng cho tinh tinh.",
          "B": "Một cách chơi chữ thông minh, kết hợp giữa \"ape\" (vượn) và \"application\" (ứng dụng).",
          "C": "Một loại thuốc mới dành cho động vật.",
          "D": "Một phương pháp nghiên cứu hành vi động vật mới."
        },
        "answer": "B"
      }
    ]
  },
  "medical-ai-gets-a-grip": {
    "title": "Medical AI Gets a Grip",
    "collection": "science",
    "content": "Surgical robots perform millions of delicate operations annually under human control. Now they’re getting ready to operate on their own.What’s new:Researchers at UC Berkeley, UC San Francisco, and SRI International trained a machine learning system to pilot ada Vincitwo-armed surgical robot through a task that tested its dexterity, precision, and speed,The New York Timesreported.How it works:The system learned via imitation learning to lift tiny plastic rings off a pegboard, pass them from one claw to the other, and slide them onto different pegs. The task is a exercise for surgeons learning to perform laparoscopic procedures, in which a camera and other specialized instruments are inserted into the patient’s body through a small incision.\n\nBehind the news:AI already assists physicians in a few small but important procedures. For instance, a robotic tool from the Dutch companyMicrosure, which helps suture tiny incisions on blood vessels, uses AI to stabilize shaking in the operator’s hands.Why it matters:This is a nice example of an algorithm that handles concept drift in robotic control. A lot of work in model-based reinforcement learning assumes a fixed model. But just as the dynamics of a human arm change as the arm tires — and a surgeon must adapt to control that tiring arm — we want learning algorithms to adapt to gradual changes in the robot’s dynamics.We’re thinking:We’re looking to AI systems that help optimizenutrition,exercise, andsleepto help steer us clear of AI systems that wield a scalpel!",
    "qa": [
      {
        "question": "Hàng năm, robot phẫu thuật thực hiện bao nhiêu ca phẫu thuật dưới sự điều khiển của con người?",
        "options": {
          "A": "Hàng trăm ca",
          "B": "Hàng nghìn ca",
          "C": "Hàng triệu ca",
          "D": "Hàng tỷ ca"
        },
        "answer": "C"
      },
      {
        "question": "Nghiên cứu về robot phẫu thuật tự động được thực hiện bởi các tổ chức nào?",
        "options": {
          "A": "UC Berkeley và SRI International",
          "B": "UC San Francisco và SRI International",
          "C": "UC Berkeley và UC San Francisco",
          "D": "UC Berkeley, UC San Francisco và SRI International"
        },
        "answer": "D"
      },
      {
        "question": "Hệ thống học máy được huấn luyện để điều khiển robot phẫu thuật thông qua phương pháp nào?",
        "options": {
          "A": "Học tăng cường",
          "B": "Học có giám sát",
          "C": "Học bắt chước",
          "D": "Học sâu"
        },
        "answer": "C"
      },
      {
        "question": "Bài tập mà robot phẫu thuật được huấn luyện thực hiện mô phỏng kỹ năng nào của bác sĩ phẫu thuật?",
        "options": {
          "A": "Phẫu thuật tim mạch",
          "B": "Phẫu thuật nội soi",
          "C": "Phẫu thuật thần kinh",
          "D": "Phẫu thuật thẩm mỹ"
        },
        "answer": "B"
      },
      {
        "question": "Công ty Microsure đến từ quốc gia nào?",
        "options": {
          "A": "Mỹ",
          "B": "Đức",
          "C": "Hà Lan",
          "D": "Nhật Bản"
        },
        "answer": "C"
      },
      {
        "question": "Công cụ robot của Microsure hỗ trợ bác sĩ phẫu thuật trong việc gì?",
        "options": {
          "A": "Ổn định nhịp tim",
          "B": "Ổn định huyết áp",
          "C": "Ổn định độ rung tay",
          "D": "Ổn định nhiệt độ cơ thể"
        },
        "answer": "C"
      },
      {
        "question": "Khái niệm 'concept drift' trong bài viết đề cập đến điều gì?",
        "options": {
          "A": "Sự thay đổi trong thiết kế robot",
          "B": "Sự thay đổi trong mô hình học máy",
          "C": "Sự thay đổi trong động lực học của robot",
          "D": "Sự thay đổi trong giao diện người dùng"
        },
        "answer": "C"
      },
      {
        "question": "Ví dụ về sự thay đổi động lực học của cánh tay người được đưa ra trong bài viết là gì?",
        "options": {
          "A": "Cánh tay bị gãy",
          "B": "Cánh tay bị mỏi",
          "C": "Cánh tay bị tê",
          "D": "Cánh tay bị chuột rút"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết bày tỏ mong muốn AI sẽ hỗ trợ trong lĩnh vực nào hơn là phẫu thuật?",
        "options": {
          "A": "Giáo dục",
          "B": "Giao thông",
          "C": "Dinh dưỡng, tập luyện và giấc ngủ",
          "D": "Năng lượng tái tạo"
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu của việc phát triển thuật toán thích ứng với sự thay đổi động lực học của robot là gì?",
        "options": {
          "A": "Tăng tốc độ phẫu thuật",
          "B": "Giảm thiểu sai sót trong phẫu thuật",
          "C": "Tự động hóa hoàn toàn quy trình phẫu thuật",
          "D": "Nâng cao độ chính xác và linh hoạt của robot"
        },
        "answer": "D"
      }
    ]
  },
  "more-autonomy-for-martian-drone": {
    "title": "More Autonomy for Martian Drone",
    "collection": "science",
    "content": "The United States space agency is upgrading the system that pilots its helicopter on the Red Planet.What’s new:The National Aeronautics and Space Administration (NASA) announced that Ingenuity, a drone sent to Mars as part of its 2020 mission to Mars, will receive a new collision-avoidance algorithm,Wiredreported. Ingenuity acts as a scout for the Perseverance rover as it travels from relatively flat, featureless areas to more hazardous terrain.How it works:NASA engineers on Earth plot waypoints in a simulation. They transmit the waypoints to the rover, which relays them to the drone, where algorithmsdetermineits path based on input from an onboard camera, altimeter, and other devices.\n\nBehind the news:Ingenuity was designed for only five flights, but has flown 29 times since its debut in April 2021. NASA hopes to extend its lifespan even further by letting it hibernate through the Martian winter. Solar energy is scarce for four months starting in July, and hibernation will enable the craft to devote its battery to keeping its electronics warm. The team plans to install the upgrade during that period.Why it matters:Ingenuity’s evolving combination of Earthbound direction and local autonomy lays the groundwork for missions deeper into the solar system, where the delay in communications — up to 24 minutes between Earth and Mars — will be even longer. For example, theDragonflyoctocopter is scheduled to take off for Titan’s soupy atmosphere in 2027.We’re thinking:Over-the-air software updates aren’t only for terrestrial devices!",
    "qa": [
      {
        "question": "Cơ quan nào đang nâng cấp hệ thống điều khiển trực thăng trên Sao Hỏa?",
        "options": {
          "A": "European Space Agency (ESA)",
          "B": "Japan Aerospace Exploration Agency (JAXA)",
          "C": "National Aeronautics and Space Administration (NASA)",
          "D": "Roscosmos State Corporation"
        },
        "answer": "C"
      },
      {
        "question": "Thuật toán mới được thêm vào Ingenuity nhằm mục đích gì?",
        "options": {
          "A": "Tăng tốc độ bay của trực thăng.",
          "B": "Tránh va chạm.",
          "C": "Cải thiện khả năng chụp ảnh.",
          "D": "Tiết kiệm năng lượng."
        },
        "answer": "B"
      },
      {
        "question": "Ingenuity đóng vai trò gì trong nhiệm vụ Sao Hỏa?",
        "options": {
          "A": "Thu thập mẫu đất đá.",
          "B": "Tìm kiếm dấu hiệu của sự sống.",
          "C": "Trinh sát cho xe tự hành Perseverance.",
          "D": "Truyền thông tin về Trái Đất."
        },
        "answer": "C"
      },
      {
        "question": "Dữ liệu đường đi được truyền đến Ingenuity thông qua phương tiện nào?",
        "options": {
          "A": "Trực tiếp từ Trái Đất.",
          "B": "Thông qua vệ tinh nhân tạo trên quỹ đạo Sao Hỏa.",
          "C": "Thông qua xe tự hành Perseverance.",
          "D": "Thông qua một trạm phát sóng trên bề mặt Sao Hỏa."
        },
        "answer": "C"
      },
      {
        "question": "Ingenuity ban đầu được thiết kế cho bao nhiêu chuyến bay?",
        "options": {
          "A": "1 chuyến.",
          "B": "3 chuyến.",
          "C": "5 chuyến.",
          "D": "10 chuyến."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao NASA muốn Ingenuity 'ngủ đông' trong mùa đông trên Sao Hỏa?",
        "options": {
          "A": "Để bảo trì các bộ phận cơ khí.",
          "B": "Để tránh bão bụi.",
          "C": "Để tiết kiệm năng lượng cho việc giữ ấm các thiết bị điện tử.",
          "D": "Để tránh bị hư hại do nhiệt độ quá thấp."
        },
        "answer": "C"
      },
      {
        "question": "Nâng cấp phần mềm cho Ingenuity được thực hiện bằng phương pháp nào?",
        "options": {
          "A": "Thay thế phần cứng trực tiếp trên Sao Hỏa.",
          "B": "Gửi phần mềm mới qua đường truyền vô tuyến (over-the-air).",
          "C": "Sử dụng tia laser để truyền dữ liệu.",
          "D": "Không thể nâng cấp phần mềm."
        },
        "answer": "B"
      },
      {
        "question": "Sự tự chủ của Ingenuity có ý nghĩa gì đối với các nhiệm vụ không gian trong tương lai?",
        "options": {
          "A": "Giảm chi phí cho các nhiệm vụ không gian.",
          "B": "Cho phép thực hiện các nhiệm vụ ở những nơi có độ trễ liên lạc lớn.",
          "C": "Tăng cường khả năng thu thập dữ liệu khoa học.",
          "D": "Giảm thiểu rủi ro cho các phi hành gia."
        },
        "answer": "B"
      },
      {
        "question": "Tàu Dragonfly dự kiến sẽ khám phá hành tinh nào?",
        "options": {
          "A": "Sao Hỏa.",
          "B": "Sao Kim.",
          "C": "Titan.",
          "D": "Europa."
        },
        "answer": "C"
      },
      {
        "question": "Độ trễ liên lạc giữa Trái Đất và Sao Hỏa có thể lên đến bao nhiêu phút?",
        "options": {
          "A": "5 phút.",
          "B": "10 phút.",
          "C": "15 phút.",
          "D": "24 phút."
        },
        "answer": "D"
      }
    ]
  },
  "more-data-for-medical-ai": {
    "title": "More Data for Medical AI",
    "collection": "science",
    "content": "Convolutional neural networks are good at recognizing disease symptoms in medical scans of patients who were injected with iodine-based dye, known as radiocontrast, that makes their organs more visible. But some patients can’t take the dye. Now synthetic scans from a GAN are helping CNNs learn to analyze undyed images.What’s new:Researchers from the U.S. National Institutes of Health and University of Wisconsindevelopeda GAN that generates labeled, undyed computerized tomography (CT) images of lesions on kidneys, spleens, and livers. They added these images to real-world training data to improve performance of a segmentation model that marks lesions in diagnostic scans.How it works:The work is based onCycleGANand theDeepLesiondataset of CTs. CycleGAN has been used toturn pictures of horses into pictures of zebraswithout needing to match particular zebra and horse pics. This work takes advantage of that capability to map between dyed and undyed CTs.\n\nResults:Tested on undyed, real-world CT scans, the U-Net trained on the combination of CycleGAN output and natural images outperformed the others. It was best at identifying lesions on kidneys, achieving a 57 percent improvement over the next-best model. With lesions on spleens, the spread was 4 percent; on livers, 3 percent. In estimating lesion volume, it achieved  an average error of 0.178, compared to the next-highest score of 0.254. Tested on the remainder of the dyed DeepLesion images, all four U-Nets isolated lesions roughly equally well.Behind the news:The researchers behind this model have used it to improve screening for dangerous levels ofliverfatand to identify patients with high risk ofmetabolic syndrome, a precursor to heart disease, diabetes, and stroke.Why it matters:Medical data can be hard to come by and labeled medical data even more so. GANs are making it easier and less expensive to create large, annotated datasets for training AI diagnostic tools.We’re thinking:Medical AI is just beginning to berecognized by key healthcare playersin the U.S. Clever uses of CycleGAN and other architectures could accelerate the process.",
    "qa": [
      {
        "question": "Mạng nơ-ron tích chập (CNN) thường gặp khó khăn gì khi phân tích ảnh y tế?",
        "options": {
          "A": "Không thể phân biệt được các cơ quan nội tạng.",
          "B": "Khó nhận diện các triệu chứng bệnh trong ảnh chụp không sử dụng thuốc cản quang iodine.",
          "C": "Yêu cầu lượng dữ liệu huấn luyện quá lớn.",
          "D": "Không thể xử lý ảnh chụp CT có độ phân giải thấp."
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ nào được sử dụng để tạo ra ảnh chụp CT tổng hợp không sử dụng thuốc cản quang?",
        "options": {
          "A": "Mạng nơ-ron truyền thẳng (Feedforward Neural Network).",
          "B": "Mạng nơ-ron hồi quy (Recurrent Neural Network).",
          "C": "Mạng đối kháng sinh (Generative Adversarial Network - GAN).",
          "D": "Mạng tự mã hóa (Autoencoder)."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc sử dụng ảnh CT tổng hợp trong nghiên cứu này là gì?",
        "options": {
          "A": "Thay thế hoàn toàn ảnh CT thật để tiết kiệm chi phí.",
          "B": "Cải thiện hiệu suất của mô hình phân đoạn trong việc nhận diện tổn thương trên ảnh không thuốc cản quang.",
          "C": "Tạo ra ảnh CT có độ phân giải cao hơn.",
          "D": "Giảm thiểu tác dụng phụ của thuốc cản quang iodine."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình CycleGAN được sử dụng trong nghiên cứu này để làm gì?",
        "options": {
          "A": "Phân loại các loại tổn thương khác nhau.",
          "B": "Chuyển đổi giữa ảnh CT có thuốc cản quang và ảnh CT không thuốc cản quang.",
          "C": "Tăng cường độ tương phản của ảnh CT.",
          "D": "Xây dựng lại ảnh CT 3D từ ảnh 2D."
        },
        "answer": "B"
      },
      {
        "question": "Bộ dữ liệu nào được sử dụng làm cơ sở cho nghiên cứu này?",
        "options": {
          "A": "ImageNet.",
          "B": "MNIST.",
          "C": "DeepLesion.",
          "D": "CIFAR-10."
        },
        "answer": "C"
      },
      {
        "question": "Kết quả tốt nhất đạt được khi mô hình được huấn luyện bằng ảnh tổng hợp và ảnh thật là gì?",
        "options": {
          "A": "Nhận diện tổn thương trên gan.",
          "B": "Nhận diện tổn thương trên lách.",
          "C": "Nhận diện tổn thương trên thận.",
          "D": "Nhận diện tổn thương trên tim."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình U-Net được sử dụng trong nghiên cứu này để làm gì?",
        "options": {
          "A": "Tạo ra ảnh CT tổng hợp.",
          "B": "Phân đoạn và đánh dấu các tổn thương trong ảnh CT.",
          "C": "Chuyển đổi ảnh CT thành ảnh X-quang.",
          "D": "Dự đoán nguy cơ mắc bệnh tim mạch."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài việc nhận diện tổn thương, mô hình này còn được sử dụng để cải thiện sàng lọc bệnh gì?",
        "options": {
          "A": "Ung thư phổi.",
          "B": "Mức độ mỡ trong gan nguy hiểm.",
          "C": "Bệnh Alzheimer.",
          "D": "Viêm khớp dạng thấp."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình này có thể giúp xác định bệnh nhân có nguy cơ cao mắc hội chứng chuyển hóa, tiền thân của bệnh nào?",
        "options": {
          "A": "HIV/AIDS.",
          "B": "Bệnh Parkinson.",
          "C": "Bệnh tim mạch, tiểu đường và đột quỵ.",
          "D": "Bệnh lao."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao việc sử dụng GANs trong y học lại quan trọng?",
        "options": {
          "A": "Giảm chi phí mua sắm thiết bị y tế.",
          "B": "Tăng cường bảo mật dữ liệu bệnh nhân.",
          "C": "Giúp tạo ra các bộ dữ liệu lớn, được chú thích để huấn luyện các công cụ chẩn đoán AI dễ dàng và ít tốn kém hơn.",
          "D": "Thay thế hoàn toàn bác sĩ trong việc chẩn đoán bệnh."
        },
        "answer": "C"
      }
    ]
  },
  "old-drugs-for-new-ailments": {
    "title": "Old Drugs for New Ailments",
    "collection": "science",
    "content": "Many medical drugs work by modulating the body’s production of specific proteins. Recent research aimed to predict this activity, enabling researchers to identify drugs that might counteract the effects of Covid-19.What’s new:Thai-Hoang Pham and colleagues at The Ohio State University and The City University of New York developedDeepCE, a system designed to predict how particular drugs will influence the amounts of RNA, and therefore the amounts of various proteins, produced by a cell.Key insight:In machine learning, attention layers learn to represent how the various parts of two input sequences interact with one another. In biology, genes mediate the production of RNA, while drugs can affect the action of genes. Given separate embeddings that represent genes and chemical structures of drugs, attention can capture how a drug affects RNA production.How it works:Given a drug, a dose, and a line of cells cloned from a particular patient, DeepCE predicts the amount of RNA produced by each of roughly 1,000 genes. (Collectively, this information constitutes a gene expression profile). The training and test data included more than 600 drugs for a total of over 4,000 gene expression profiles from seven human cell lines in theL1000database.\n\nResults:The authors compared DeepCE’s predictions with those of several baseline methods using the Pearson correlation coefficient, a measure of the correlation between predictions and ground truth. DeepCE outperformed all of them with a score of 0.4907. The next-best method, a two-layer feed-forward network, scored 0.4270. They also used DeepCE to look for existing drugs that might treat Covid-19. They compared the predictions formore than 11,000 drugswith corresponding profiles ofCovid-19patients, looking for the greatest negative correlations — an indicator that the drug would fight the illness. Of 25 drugs surfaced by DeepCE, at least five already had shown potential as Covid-19 treatments; others had been used for different viruses with similar symptoms.Why it matters:Complex datasets may have features that aren’t processed easily by a single network. By using a different network for each type of input and combining their outputs, machine learning engineers can extract useful information that otherwise might be inaccessible.We’re thinking:The next blockbuster antiviral (or antidepressant, anti-inflammatory, or heart medicine) may already be on pharmacy shelves. Wouldn’t it be wonderful if deep learning found it?",
    "qa": [
      {
        "question": "Mục tiêu chính của nghiên cứu được đề cập trong bài viết là gì?",
        "options": {
          "A": "Phát triển một loại thuốc mới để điều trị Covid-19.",
          "B": "Dự đoán tác động của thuốc lên quá trình sản xuất protein trong cơ thể, đặc biệt liên quan đến Covid-19.",
          "C": "Nghiên cứu cấu trúc RNA của virus Covid-19.",
          "D": "Cải thiện hiệu quả của các phương pháp điều trị Covid-19 hiện có."
        },
        "answer": "B"
      },
      {
        "question": "DeepCE là một hệ thống được phát triển bởi ai?",
        "options": {
          "A": "Một nhóm các nhà khoa học tại Đại học Harvard.",
          "B": "Thai-Hoang Pham và các đồng nghiệp tại Đại học Ohio State và Đại học City của New York.",
          "C": "Các nhà nghiên cứu tại Viện Y tế Quốc gia (NIH).",
          "D": "Một công ty dược phẩm tư nhân."
        },
        "answer": "B"
      },
      {
        "question": "DeepCE dự đoán điều gì liên quan đến hoạt động của thuốc?",
        "options": {
          "A": "Tác dụng phụ tiềm ẩn của thuốc.",
          "B": "Ảnh hưởng của thuốc lên lượng RNA và do đó, lượng protein được sản xuất bởi tế bào.",
          "C": "Khả năng tương tác của thuốc với các loại thuốc khác.",
          "D": "Thời gian bán thải của thuốc trong cơ thể."
        },
        "answer": "B"
      },
      {
        "question": "Trong DeepCE, attention layers được sử dụng để làm gì?",
        "options": {
          "A": "Tăng tốc quá trình xử lý dữ liệu.",
          "B": "Biểu diễn sự tương tác giữa các phần khác nhau của hai chuỗi đầu vào, cụ thể là gen và cấu trúc hóa học của thuốc.",
          "C": "Giảm thiểu sai số trong quá trình dự đoán.",
          "D": "Phân loại các loại thuốc khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu huấn luyện và kiểm tra của DeepCE bao gồm thông tin từ cơ sở dữ liệu nào?",
        "options": {
          "A": "PubMed.",
          "B": "L1000.",
          "C": "GenBank.",
          "D": "The Human Protein Atlas."
        },
        "answer": "B"
      },
      {
        "question": "Chỉ số nào được sử dụng để so sánh hiệu suất của DeepCE với các phương pháp khác?",
        "options": {
          "A": "Độ chính xác (Accuracy).",
          "B": "Hệ số tương quan Pearson (Pearson correlation coefficient).",
          "C": "Giá trị F1 (F1-score).",
          "D": "Độ nhạy (Sensitivity)."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả tốt nhất mà DeepCE đạt được (hệ số tương quan Pearson) là bao nhiêu?",
        "options": {
          "A": "0.3270.",
          "B": "0.4270.",
          "C": "0.4907.",
          "D": "0.5907."
        },
        "answer": "C"
      },
      {
        "question": "DeepCE đã được sử dụng để tìm kiếm điều gì liên quan đến Covid-19?",
        "options": {
          "A": "Các biến thể mới của virus Covid-19.",
          "B": "Các loại thuốc hiện có có thể điều trị Covid-19.",
          "C": "Các yếu tố nguy cơ gây bệnh Covid-19.",
          "D": "Các phương pháp chẩn đoán Covid-19 nhanh chóng."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lợi ích của việc sử dụng nhiều mạng nơ-ron khác nhau cho các loại đầu vào khác nhau là gì?",
        "options": {
          "A": "Giảm chi phí tính toán.",
          "B": "Tăng độ chính xác của mô hình.",
          "C": "Trích xuất thông tin hữu ích mà có thể không thể truy cập được nếu chỉ sử dụng một mạng duy nhất.",
          "D": "Đơn giản hóa quá trình huấn luyện mô hình."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết gợi ý điều gì về tương lai của việc tìm kiếm thuốc mới?",
        "options": {
          "A": "Việc phát triển thuốc mới sẽ trở nên khó khăn hơn do sự phức tạp của dữ liệu sinh học.",
          "B": "Các loại thuốc tiềm năng có thể đã có sẵn và có thể được tìm thấy bằng cách sử dụng học sâu.",
          "C": "Cần tập trung vào việc phát triển các loại thuốc hoàn toàn mới thay vì tìm kiếm các ứng dụng mới cho các loại thuốc hiện có.",
          "D": "Học sâu không có khả năng đóng góp đáng kể vào việc tìm kiếm thuốc mới."
        },
        "answer": "B"
      }
    ]
  },
  "new-materials-courtesy-of-bayes": {
    "title": "New Materials Courtesy of Bayes",
    "collection": "science",
    "content": "Would you like an umbrella that fits in your pocket? Researchers used machine learning to invent sturdy but collapsible materials that might lead to such a fantastical object.What’s new:Researchers at the Netherlands’ Delft University of Technology used aBayesian modelto find arrangements of brittle polymers that are sturdy, lightweight, compressible, and able to spring back to their original shape. The machine learning algorithm made it possible to design and produce materials without conducting the usual trial-and-error physical experiments.How it works:Principal investigator Miguel Bessa designed a mock-up with two disks connected by flexible poles, or longerons, that fold in a spiral pattern when the dishes are pressed together.\n\nResults:The microscopic prototype — built for strength — was fully compressible and able to withstand intense pressure without buckling. For the human-scale version, it was important that it spring back into its original shape, which it did even when compressed nearly flat by a machine press.\n\nWhy it matters:Scientists working on metamaterials (structural arrangements of existing materials that exhibit characteristics not found in nature) alter material geometries, shapes, sizes, and orientations to produce novel properties. Typically this requires lots of trial and error. Machine learning can curate arrangements likely to have the right properties, enabling researchers to focus on the most promising candidates.We’re thinking:From materials science to drug design, brute force experimentation still plays a large role in bleeding-edge science. AI-driven screening is beginning to help researchers find shorter routes to Eureka.",
    "qa": [
      {
        "question": "Mục tiêu chính của nghiên cứu được đề cập trong bài viết là gì?",
        "options": {
          "A": "Phát triển một loại vật liệu mới hoàn toàn từ các nguyên tố hóa học chưa từng được sử dụng.",
          "B": "Sử dụng học máy để tạo ra các vật liệu có thể thu gọn và bền chắc, ví dụ như một chiếc ô bỏ túi.",
          "C": "Nghiên cứu các đặc tính của các polyme giòn dưới áp suất cao.",
          "D": "Cải thiện quy trình sản xuất các vật liệu hiện có bằng cách giảm chi phí và thời gian."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Bayesian được sử dụng trong nghiên cứu này để làm gì?",
        "options": {
          "A": "Dự đoán thời tiết để đảm bảo điều kiện thí nghiệm tối ưu.",
          "B": "Tìm ra các cách sắp xếp các polyme giòn để đạt được các đặc tính mong muốn.",
          "C": "Kiểm tra độ bền của vật liệu sau khi nén.",
          "D": "Tối ưu hóa thuật toán học máy để tăng tốc độ xử lý dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Đâu là đặc điểm quan trọng của vật liệu được tạo ra trong nghiên cứu này?",
        "options": {
          "A": "Khả năng tự phục hồi sau khi bị hư hỏng do nhiệt độ cao.",
          "B": "Khả năng dẫn điện tốt hơn so với các vật liệu thông thường.",
          "C": "Khả năng chịu được áp lực lớn và khả năng thu gọn về kích thước nhỏ.",
          "D": "Khả năng chống thấm nước tuyệt đối và không bị ảnh hưởng bởi tia UV."
        },
        "answer": "C"
      },
      {
        "question": "Vai trò của Miguel Bessa trong nghiên cứu này là gì?",
        "options": {
          "A": "Phân tích dữ liệu thu thập được từ các thí nghiệm vật lý.",
          "B": "Thiết kế mô hình thử nghiệm với các đĩa và các thanh nối linh hoạt.",
          "C": "Phát triển thuật toán học máy được sử dụng trong nghiên cứu.",
          "D": "Quản lý dự án và đảm bảo nguồn tài chính cho nghiên cứu."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả quan trọng nào đã được ghi nhận từ nguyên mẫu vĩ mô (human-scale version)?",
        "options": {
          "A": "Nó có thể chịu được nhiệt độ cực cao mà không bị biến dạng.",
          "B": "Nó có khả năng tự phục hồi hình dạng ban đầu sau khi bị nén gần như phẳng.",
          "C": "Nó có trọng lượng nhẹ hơn đáng kể so với các vật liệu tương tự.",
          "D": "Nó có khả năng hấp thụ ánh sáng mặt trời và chuyển đổi thành năng lượng."
        },
        "answer": "B"
      },
      {
        "question": "Metamaterials là gì?",
        "options": {
          "A": "Các vật liệu tự nhiên có cấu trúc phân tử phức tạp.",
          "B": "Các vật liệu tổng hợp được tạo ra từ các nguyên tố hiếm.",
          "C": "Các cấu trúc được sắp xếp từ các vật liệu hiện có để tạo ra các đặc tính mới.",
          "D": "Các vật liệu có khả năng thay đổi hình dạng dưới tác động của điện trường."
        },
        "answer": "C"
      },
      {
        "question": "Thách thức lớn nhất trong việc phát triển metamaterials trước đây là gì?",
        "options": {
          "A": "Chi phí sản xuất quá cao.",
          "B": "Khó tìm được các vật liệu phù hợp.",
          "C": "Yêu cầu thử nghiệm và sai sót tốn kém và mất thời gian.",
          "D": "Thiếu các công cụ mô phỏng chính xác."
        },
        "answer": "C"
      },
      {
        "question": "Học máy giúp ích như thế nào trong việc nghiên cứu metamaterials?",
        "options": {
          "A": "Tự động tạo ra các vật liệu mới từ các nguyên tố hóa học.",
          "B": "Dự đoán chính xác các đặc tính của vật liệu trước khi sản xuất.",
          "C": "Lựa chọn các cách sắp xếp vật liệu có khả năng mang lại các đặc tính mong muốn.",
          "D": "Giảm thiểu sự phụ thuộc vào các chuyên gia trong lĩnh vực vật liệu."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến lĩnh vực nào khác mà AI có thể giúp rút ngắn con đường đến khám phá?",
        "options": {
          "A": "Năng lượng tái tạo.",
          "B": "Thiết kế thuốc.",
          "C": "Nghiên cứu vũ trụ.",
          "D": "Nông nghiệp công nghệ cao."
        },
        "answer": "B"
      },
      {
        "question": "Cụm từ \"brute force experimentation\" trong bài viết ám chỉ điều gì?",
        "options": {
          "A": "Sử dụng các phương pháp thí nghiệm mạnh mẽ và tốn kém.",
          "B": "Thực hiện nhiều thí nghiệm một cách ngẫu nhiên và không có hệ thống.",
          "C": "Sử dụng các công cụ và thiết bị thí nghiệm hiện đại nhất.",
          "D": "Thực hiện các thí nghiệm lặp đi lặp lại để tìm ra giải pháp bằng cách thử và sai."
        },
        "answer": "D"
      }
    ]
  },
  "over-150-scientists-commit-to-ensure-ai-safety-in-synthetic-biology-research": {
    "title": "Toward Managing AI Bio Risk",
    "collection": "science",
    "content": "Scientists pledged to control their use of AI to produce potentially hazardous biological materials.\n\nWhat’s new:More than 150 biologists in Asia, Europe, and North Americasigneda voluntary commitment to internal and external oversight of machine learning models that can be used to design proteins.\n\nHow it works:The scientists made 10 voluntary commitments regarding synthetic biology research. They promised broadly to avoid research likely to enable harm and to promote research that responds to infectious disease outbreaks or similar emergencies.\n\nBehind the news:The potential role of AI in producing bioweapons is a major focus of research in AI safety. The current pledge arose from a University of Washington meeting on responsible AI and protein design held late last year. TheAI Safety Summit, which took place at around the same time, also addressed the topic, and Helena, a think tank devoted to solving global problems, convened a similar meeting in mid-2023.\n\nWhy it matters:DeepMind’sAlphaFold, which finds the structures of proteins, hasspawnedmodels that enable users to design proteins with specific properties. Their output could help scientists cure diseases, boost agricultural production, and craft enzymes that aid industrial processes. However, their potential for misuse has led to scrutiny bynationalandinternationalorganizations. The biology community’s commitment to use such models safely may reassure the public and forestall onerous regulations.\n\nWe’re thinking:The commitments are long on general principles and relatively short on concrete actions. We’re glad they call for ongoing revision and action, and we hope they lead to the development of effective safeguards.",
    "qa": [
      {
        "question": "Hơn 150 nhà sinh học đã ký cam kết tự nguyện về vấn đề gì?",
        "options": {
          "A": "Phát triển các mô hình AI mạnh mẽ hơn để thiết kế protein.",
          "B": "Giám sát nội bộ và bên ngoài các mô hình học máy dùng để thiết kế protein.",
          "C": "Chia sẻ dữ liệu nghiên cứu về protein cho cộng đồng khoa học.",
          "D": "Tăng cường hợp tác quốc tế trong lĩnh vực sinh học tổng hợp."
        },
        "answer": "B"
      },
      {
        "question": "Cam kết của các nhà khoa học tập trung vào lĩnh vực nghiên cứu nào?",
        "options": {
          "A": "Nghiên cứu về vũ khí sinh học.",
          "B": "Nghiên cứu về sinh học tổng hợp.",
          "C": "Nghiên cứu về trí tuệ nhân tạo.",
          "D": "Nghiên cứu về bệnh truyền nhiễm."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của cam kết này là gì?",
        "options": {
          "A": "Thúc đẩy nghiên cứu về các ứng dụng có hại của AI trong sinh học.",
          "B": "Ngăn chặn sự phát triển của các mô hình AI có thể tạo ra vũ khí sinh học.",
          "C": "Tránh các nghiên cứu có khả năng gây hại và thúc đẩy nghiên cứu ứng phó với các dịch bệnh.",
          "D": "Tăng cường sự hợp tác giữa các nhà khoa học và các tổ chức quốc tế."
        },
        "answer": "C"
      },
      {
        "question": "Hội nghị nào đã dẫn đến cam kết hiện tại về sử dụng AI có trách nhiệm trong thiết kế protein?",
        "options": {
          "A": "AI Safety Summit.",
          "B": "Hội nghị do Helena tổ chức.",
          "C": "Hội nghị tại Đại học Washington.",
          "D": "Hội nghị quốc tế về sinh học tổng hợp."
        },
        "answer": "C"
      },
      {
        "question": "AlphaFold của DeepMind có vai trò gì trong lĩnh vực thiết kế protein?",
        "options": {
          "A": "Phát triển các loại thuốc mới để chữa bệnh.",
          "B": "Tìm ra cấu trúc của protein, từ đó tạo ra các mô hình thiết kế protein.",
          "C": "Tăng cường sản xuất nông nghiệp.",
          "D": "Tạo ra các enzyme hỗ trợ các quy trình công nghiệp."
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng tiềm năng nào của việc thiết kế protein bằng AI được đề cập trong bài viết?",
        "options": {
          "A": "Tạo ra các loại vũ khí sinh học mới.",
          "B": "Phát triển các phương pháp điều trị bệnh, tăng sản lượng nông nghiệp và tạo ra enzyme công nghiệp.",
          "C": "Tăng cường khả năng dự đoán các đợt bùng phát dịch bệnh.",
          "D": "Cải thiện hiệu quả của các quy trình sản xuất công nghiệp."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc sử dụng AI trong thiết kế protein cần được giám sát chặt chẽ?",
        "options": {
          "A": "Vì nó có thể gây ra các vấn đề về đạo đức.",
          "B": "Vì nó có thể bị lạm dụng để tạo ra các vật liệu sinh học nguy hiểm.",
          "C": "Vì nó có thể làm giảm sự sáng tạo của các nhà khoa học.",
          "D": "Vì nó có thể gây ra các lỗi trong quá trình thiết kế protein."
        },
        "answer": "B"
      },
      {
        "question": "Cam kết của cộng đồng sinh học có thể mang lại lợi ích gì?",
        "options": {
          "A": "Giảm chi phí nghiên cứu.",
          "B": "Tăng cường sự tin tưởng của công chúng và ngăn chặn các quy định quá khắt khe.",
          "C": "Thúc đẩy sự phát triển của các công nghệ mới.",
          "D": "Cải thiện chất lượng của các nghiên cứu khoa học."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đánh giá như thế nào về tính cụ thể của các cam kết?",
        "options": {
          "A": "Các cam kết rất cụ thể và chi tiết.",
          "B": "Các cam kết tập trung vào các nguyên tắc chung và thiếu các hành động cụ thể.",
          "C": "Các cam kết cân bằng giữa nguyên tắc chung và hành động cụ thể.",
          "D": "Các cam kết quá tập trung vào hành động cụ thể mà bỏ qua các nguyên tắc chung."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết hy vọng điều gì về các cam kết này trong tương lai?",
        "options": {
          "A": "Các cam kết sẽ được thực hiện một cách nghiêm túc và hiệu quả.",
          "B": "Các cam kết sẽ được sửa đổi và bổ sung liên tục để phát triển các biện pháp bảo vệ hiệu quả.",
          "C": "Các cam kết sẽ được áp dụng rộng rãi trên toàn thế giới.",
          "D": "Các cam kết sẽ giúp giải quyết tất cả các vấn đề liên quan đến an toàn AI."
        },
        "answer": "B"
      }
    ]
  },
  "predicting-the-next-eruption": {
    "title": "Predicting the Next Eruption",
    "collection": "science",
    "content": "AI is providing an early warning system for volcanoes on the verge of blowing their top.What happened:Researchers at the University of Leedsdevelopeda neural net that scans satellite data for indications that the ground near a volcano is swelling—a sign it may be close to erupting.How it works:Satellites carrying certain sensors can track centimeter-scale deformations of Earth’s crust. Seismologists in the 1990sfigured outhow to manually read this data for signs of underground magma buildups. However, human eyeballs are neither numerous nor sharp enough to monitor data for all of Earth’s 1,400 active volcanoes.\n\nBehind the news:Researchers at the University of Bristoldevelopeda similar method to measure deformations in the Earth’s crust using satellite data. However, their model can be fooled by atmospheric distortion that produces similar signals in the data. The Leeds and Bristol groups plan to collaborate in side-by-side tests of their models on a global dataset in the near future. Another group based at Cornell University is attempting to make similar predictions through satellite data of surface temperature anomalies, ash, and gaseous emissions.Why it matters:Approximately 800 million people live within the blast zones of active volcanoes, and millions of sightseers visit their slopes each year. On Monday, New Zealand’s White Island volcanoerupted, killing at least five tourists.\n\nWe’re thinking:If researchers can scale their model up to cover the entire globe, they’ll deserve applause that thunders as loudly as Krakatoa.",
    "qa": [
      {
        "question": "Hệ thống cảnh báo sớm núi lửa sử dụng AI được phát triển bởi Đại học Leeds dựa trên dữ liệu nào?",
        "options": {
          "A": "Dữ liệu địa chấn từ các trạm quan trắc mặt đất.",
          "B": "Dữ liệu vệ tinh về sự biến dạng của mặt đất.",
          "C": "Dữ liệu về thành phần hóa học của khí thải núi lửa.",
          "D": "Dữ liệu lịch sử về các vụ phun trào núi lửa trước đây."
        },
        "answer": "B"
      },
      {
        "question": "Trước khi có AI, việc phát hiện dấu hiệu núi lửa sắp phun trào dựa trên dữ liệu biến dạng mặt đất được thực hiện như thế nào?",
        "options": {
          "A": "Sử dụng các thuật toán máy tính phức tạp.",
          "B": "Phân tích thủ công bởi các nhà địa chấn học.",
          "C": "Dựa vào cảm biến áp suất dưới lòng đất.",
          "D": "Quan sát trực tiếp bằng mắt thường."
        },
        "answer": "B"
      },
      {
        "question": "Nhược điểm chính của mô hình do Đại học Bristol phát triển là gì?",
        "options": {
          "A": "Độ chính xác thấp khi dự đoán thời gian phun trào.",
          "B": "Dễ bị ảnh hưởng bởi sự biến dạng khí quyển.",
          "C": "Chỉ hoạt động hiệu quả với một số loại núi lửa nhất định.",
          "D": "Yêu cầu lượng dữ liệu đầu vào rất lớn."
        },
        "answer": "B"
      },
      {
        "question": "Đại học Cornell đang cố gắng dự đoán phun trào núi lửa bằng cách phân tích dữ liệu vệ tinh về yếu tố nào?",
        "options": {
          "A": "Sự thay đổi từ trường xung quanh núi lửa.",
          "B": "Độ ẩm của đất gần núi lửa.",
          "C": "Nhiệt độ bề mặt, tro và khí thải.",
          "D": "Mức độ bức xạ từ lòng đất."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến vụ phun trào núi lửa nào gần đây gây thương vong?",
        "options": {
          "A": "Núi lửa Etna ở Ý.",
          "B": "Núi lửa Krakatoa ở Indonesia.",
          "C": "Núi lửa White Island ở New Zealand.",
          "D": "Núi lửa Mount St. Helens ở Mỹ."
        },
        "answer": "C"
      },
      {
        "question": "Khoảng bao nhiêu người đang sống trong khu vực nguy hiểm của các núi lửa đang hoạt động?",
        "options": {
          "A": "Khoảng 8 triệu người.",
          "B": "Khoảng 80 triệu người.",
          "C": "Khoảng 800 triệu người.",
          "D": "Khoảng 8 tỷ người."
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu cuối cùng của các nhà nghiên cứu trong việc phát triển hệ thống cảnh báo sớm núi lửa là gì?",
        "options": {
          "A": "Giảm thiểu thiệt hại kinh tế do phun trào núi lửa.",
          "B": "Cung cấp cảnh báo cho tất cả các núi lửa trên toàn cầu.",
          "C": "Nghiên cứu sâu hơn về cấu trúc bên trong của núi lửa.",
          "D": "Phát triển công nghệ khai thác năng lượng địa nhiệt."
        },
        "answer": "B"
      },
      {
        "question": "Các nhóm nghiên cứu từ Đại học Leeds và Đại học Bristol dự định làm gì trong tương lai gần?",
        "options": {
          "A": "Xuất bản một bài báo khoa học chung.",
          "B": "Hợp tác thử nghiệm mô hình của họ trên một bộ dữ liệu toàn cầu.",
          "C": "Phát triển một mô hình dự đoán phun trào núi lửa duy nhất.",
          "D": "Xin cấp bằng sáng chế cho công nghệ của họ."
        },
        "answer": "B"
      },
      {
        "question": "Cụm từ \"blowing their top\" trong đoạn đầu tiên của bài viết có nghĩa là gì?",
        "options": {
          "A": "Núi lửa đang nguội dần.",
          "B": "Núi lửa đang phun trào.",
          "C": "Núi lửa đang hình thành.",
          "D": "Núi lửa đang được nghiên cứu."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh tầm quan trọng của việc cảnh báo sớm phun trào núi lửa vì điều gì?",
        "options": {
          "A": "Để bảo vệ các công trình kiến trúc lịch sử gần núi lửa.",
          "B": "Để giảm thiểu tác động đến ngành du lịch.",
          "C": "Để bảo vệ tính mạng của người dân và du khách.",
          "D": "Để nghiên cứu các hiện tượng tự nhiên hiếm gặp."
        },
        "answer": "C"
      }
    ]
  },
  "planet-hunter": {
    "title": "Planet Hunter",
    "collection": "science",
    "content": "A machine learning model is scouring the cosmos for undiscovered planets.What’s new:Astronomers from the University of Warwickdevelopeda system that learned to identify faraway worlds in a dataset of thousands of candidates.How it works:Astronomers oftenfindplanets outside Earth’s solar system, or exoplanets, by scanning the sky for stars that flicker, which indicates that a planet might pass in front of them. Given a set of possible planets, the researchers used machine learning to sift out false positives caused by camera errors, cosmic rays, or stars eclipsing one another to identify the real deal.\n\nResults:In some test cases when the authors’ models and the earlier technique disagreed strongly, their approach identified confirmed exoplanets that the old approach missed. Similarly, the authors identified a preponderance of confirmed false positives that the earlier approach classified as planets with greater than 99 percent confidence.\n\nWhat’s next:The authors’ models analyzed 2,680 unconfirmed candidates and classified 83 likely exoplanets. The earlier technique agreed that 50 of them were bona fide exoplanets — prime targets for further study. The authors hope to apply their method to the dataset collected from NASA’s recent Transiting Exoplanet Survey Satellite mission, which contains thousands more unconfirmed candidates.\n\nWhy it matters:Any indirect method of determining an exoplanet’s existence is bound to be imperfect. By combining approaches, researchers aim to improve the likelihood that what they take to be planets really are, so scientists can proceed with deeper investigations.We’re thinking:Outer space offers an endless supply of data, and machine learning is the ultimate tool for crunching it. A match made in the heavens!",
    "qa": [
      {
        "question": "Phương pháp chính mà các nhà thiên văn học sử dụng để tìm kiếm ngoại hành tinh là gì?",
        "options": {
          "A": "Phân tích thành phần hóa học của các ngôi sao.",
          "B": "Tìm kiếm sự nhấp nháy của các ngôi sao, cho thấy có hành tinh đi qua phía trước.",
          "C": "Sử dụng kính viễn vọng để quan sát trực tiếp các hành tinh.",
          "D": "Đo sự thay đổi trọng lực của các ngôi sao."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính mà các nhà nghiên cứu gặp phải khi xác định ngoại hành tinh là gì?",
        "options": {
          "A": "Thiếu dữ liệu từ không gian.",
          "B": "Khó khăn trong việc phân biệt giữa ngoại hành tinh thực và các tín hiệu sai.",
          "C": "Chi phí quá cao để sử dụng kính viễn vọng.",
          "D": "Sự can thiệp của các hành tinh khác trong hệ mặt trời."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích của việc sử dụng mô hình học máy trong nghiên cứu này là gì?",
        "options": {
          "A": "Tăng tốc độ thu thập dữ liệu từ kính viễn vọng.",
          "B": "Phân loại và loại bỏ các tín hiệu sai để xác định ngoại hành tinh thực.",
          "C": "Dự đoán vị trí của các ngoại hành tinh trong tương lai.",
          "D": "Tạo ra hình ảnh 3D của các ngoại hành tinh."
        },
        "answer": "B"
      },
      {
        "question": "Trong các thử nghiệm, mô hình học máy đã phát hiện ra điều gì đáng chú ý so với phương pháp cũ?",
        "options": {
          "A": "Nó tìm thấy nhiều ngoại hành tinh hơn phương pháp cũ.",
          "B": "Nó xác định được các ngoại hành tinh đã được xác nhận mà phương pháp cũ bỏ sót.",
          "C": "Nó có thể xác định kích thước và khối lượng của các ngoại hành tinh chính xác hơn.",
          "D": "Nó có thể phân biệt giữa các loại ngoại hành tinh khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã phân loại bao nhiêu ứng viên là ngoại hành tinh tiềm năng từ 2,680 ứng viên chưa được xác nhận?",
        "options": {
          "A": "33",
          "B": "50",
          "C": "83",
          "D": "2680"
        },
        "answer": "C"
      },
      {
        "question": "Có bao nhiêu ngoại hành tinh tiềm năng mà cả mô hình học máy và phương pháp cũ đều đồng ý là có khả năng tồn tại?",
        "options": {
          "A": "33",
          "B": "50",
          "C": "83",
          "D": "2680"
        },
        "answer": "B"
      },
      {
        "question": "Nhiệm vụ Transiting Exoplanet Survey Satellite (TESS) của NASA có vai trò gì trong nghiên cứu này?",
        "options": {
          "A": "Cung cấp dữ liệu về thành phần hóa học của các ngoại hành tinh.",
          "B": "Cung cấp dữ liệu về kích thước và khối lượng của các ngoại hành tinh.",
          "C": "Cung cấp một lượng lớn dữ liệu về các ứng viên ngoại hành tinh chưa được xác nhận.",
          "D": "Cung cấp hình ảnh trực tiếp của các ngoại hành tinh."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao việc kết hợp nhiều phương pháp khác nhau lại quan trọng trong việc xác định ngoại hành tinh?",
        "options": {
          "A": "Để giảm chi phí nghiên cứu.",
          "B": "Để tăng tốc độ xử lý dữ liệu.",
          "C": "Để cải thiện độ chính xác và giảm thiểu sai sót.",
          "D": "Để đơn giản hóa quá trình phân tích dữ liệu."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì khiến học máy trở thành một công cụ mạnh mẽ trong việc nghiên cứu không gian?",
        "options": {
          "A": "Khả năng tạo ra hình ảnh 3D của các hành tinh.",
          "B": "Khả năng xử lý lượng lớn dữ liệu một cách hiệu quả.",
          "C": "Khả năng du hành đến các hành tinh khác.",
          "D": "Khả năng giao tiếp với người ngoài hành tinh."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì sẽ xảy ra tiếp theo trong nghiên cứu này?",
        "options": {
          "A": "Các nhà nghiên cứu sẽ xây dựng một kính viễn vọng mới.",
          "B": "Các nhà nghiên cứu sẽ áp dụng phương pháp của họ vào dữ liệu từ nhiệm vụ TESS.",
          "C": "Các nhà nghiên cứu sẽ gửi tàu vũ trụ đến các ngoại hành tinh đã được xác định.",
          "D": "Các nhà nghiên cứu sẽ tìm kiếm sự sống trên các ngoại hành tinh."
        },
        "answer": "B"
      }
    ]
  },
  "prehistoric-pictures-rediscovered": {
    "title": "Prehistoric Pictures Rediscovered",
    "collection": "science",
    "content": "Image analysis guided by AI revealed a 2,000-year-old picture dug into the Peruvian desert.What happened:Researchers analyzing aerial imagery shot over Perufounda pattern that looks like a three-horned humanoid holding a staff. The figure is roughly 16 feet across and may have served as a waypoint along an ancient path. Known as geoglyphs, such pictures were created by people who predated the arrival of Columbus by 1500 years. The sprawling patterns are visible only from higher elevations.How it works:Using manual methods, researchers at Yamagata University found more than 100 geoglyphs in satellite photos and other imagery from the region of southeastern Peru called the Nazca Pampa. But they had collected too much data from surrounding areas to search manually. So they teamed with IBM Japan to feed the data into PAIRS Geoscope, a cloud-based deep learning system that analyzes geospatial data. Thisvideodescribes the project.\n\nBehind the news:The people who created the Nazca geoglyphs lived on the arid Peruvian plains, or pampas. They made these shapes by removing the top layer of pebbles to expose lighter-colored clay roughly six inches below. Conquistadors noted the geoglyphs in their travelogues as far back as the 1500s, but it wasn’t until the 1940s that researchers began studying their origin and purpose.Why it matters:Remote sensing techniques have spurred arenaissancein archaeology. They’ve helped uncover Mayan pyramids on Mexico’s Yucatan peninsula and abandoned cities in the Cambodian jungle.We’re thinking:Who wants to team with us to create a massivedeeplearning.aigeoglyph to confuse and amuse future generations?",
    "qa": [
      {
        "question": "Hình ảnh phân tích bằng AI đã phát hiện ra hình vẽ cổ đại bao nhiêu năm tuổi ở Peru?",
        "options": {
          "A": "1000 năm",
          "B": "2000 năm",
          "C": "1500 năm",
          "D": "500 năm"
        },
        "answer": "B"
      },
      {
        "question": "Hình dạng của hình vẽ mới được phát hiện ở Peru được mô tả như thế nào?",
        "options": {
          "A": "Một con vật có cánh",
          "B": "Một người ba sừng cầm một cây trượng",
          "C": "Một mê cung phức tạp",
          "D": "Một hình xoắn ốc khổng lồ"
        },
        "answer": "B"
      },
      {
        "question": "Các hình vẽ trên sa mạc Nazca Pampa được gọi là gì?",
        "options": {
          "A": "Petroglyphs",
          "B": "Hieroglyphs",
          "C": "Geoglyphs",
          "D": "Ideograms"
        },
        "answer": "C"
      },
      {
        "question": "Những người tạo ra các hình vẽ Nazca đã sống trước khi Columbus đến châu Mỹ bao nhiêu năm?",
        "options": {
          "A": "500 năm",
          "B": "1000 năm",
          "C": "1500 năm",
          "D": "2000 năm"
        },
        "answer": "C"
      },
      {
        "question": "Đại học Yamagata đã sử dụng phương pháp nào để tìm kiếm các hình vẽ trên sa mạc Nazca Pampa trước khi sử dụng AI?",
        "options": {
          "A": "Sử dụng máy bay không người lái",
          "B": "Sử dụng phương pháp thủ công",
          "C": "Sử dụng kính viễn vọng",
          "D": "Sử dụng radar xuyên đất"
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống deep learning nào đã được sử dụng để phân tích dữ liệu địa không gian trong dự án này?",
        "options": {
          "A": "Google Earth Engine",
          "B": "PAIRS Geoscope",
          "C": "Amazon SageMaker",
          "D": "Microsoft Azure AI"
        },
        "answer": "B"
      },
      {
        "question": "Người Nazca tạo ra các hình vẽ bằng cách nào?",
        "options": {
          "A": "Sơn lên đá",
          "B": "Khắc vào đá",
          "C": "Loại bỏ lớp sỏi trên bề mặt để lộ lớp đất sét bên dưới",
          "D": "Sử dụng thuốc nhuộm tự nhiên"
        },
        "answer": "C"
      },
      {
        "question": "Ai là những người đầu tiên ghi nhận sự tồn tại của các hình vẽ Nazca trong các ghi chép của họ?",
        "options": {
          "A": "Các nhà khảo cổ học",
          "B": "Các nhà thiên văn học",
          "C": "Các nhà chinh phục Tây Ban Nha (Conquistadors)",
          "D": "Các nhà thám hiểm người Anh"
        },
        "answer": "C"
      },
      {
        "question": "Kỹ thuật viễn thám đã giúp khám phá ra điều gì ở bán đảo Yucatan của Mexico?",
        "options": {
          "A": "Các kim tự tháp của người Aztec",
          "B": "Các kim tự tháp của người Maya",
          "C": "Các thành phố cổ của người Inca",
          "D": "Các bức tượng đá khổng lồ"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất ý tưởng gì để 'gây nhầm lẫn và thích thú' cho các thế hệ tương lai?",
        "options": {
          "A": "Xây dựng một bảo tàng ảo về các hình vẽ Nazca",
          "B": "Tạo ra một hình vẽ geoglyph AI khổng lồ",
          "C": "Phát triển một ứng dụng để giải mã các hình vẽ Nazca",
          "D": "Tổ chức một cuộc thi thiết kế hình vẽ geoglyph"
        },
        "answer": "B"
      }
    ]
  },
  "prelude-to-a-quake": {
    "title": "Prelude to a Quake?",
    "collection": "science",
    "content": "Geologists call them slow slips: deep, low-frequency earthquakes that can last a month but have little effect on the surface. A model trained to predict such events could help with forecasting potentially catastrophic quakes.What’s new:French and American seismologists trained amodelto recognize acoustic patterns associated with slow slips where one tectonic plate slides beneath another. Some seismologists believe that slow slips shift stress from deep in a geological fault up to the Earth’s brittle crust, presaging potentially catastrophic quakes.How it works:The authors began by simulating slow slips in the lab using two sheets of synthetic material, like acrylic plastic, separated by a thin layer of a granular, sandy medium. The video above is a microscopic view of the sheets in action.\n\nWe’re thinking:Seismologists already provide short-term risk assessments for a given location and time span. This research could lead to long-term forecasts, months or years out, allowing planners to expedite earthquake safety upgrades that otherwise may be delayed due to their cost.",
    "qa": [
      {
        "question": "Các nhà địa chất gọi hiện tượng trượt chậm là gì?",
        "options": {
          "A": "Động đất mạnh tần số cao",
          "B": "Động đất sâu, tần số thấp",
          "C": "Sự dịch chuyển mảng kiến tạo đột ngột",
          "D": "Sự sụt lún đất do hoạt động địa chất"
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc huấn luyện mô hình dự đoán trượt chậm là gì?",
        "options": {
          "A": "Nghiên cứu cấu trúc bên trong của mảng kiến tạo",
          "B": "Dự báo các trận động đất có khả năng gây thảm họa",
          "C": "Tìm hiểu về thành phần hóa học của lớp vỏ Trái Đất",
          "D": "Phát triển công nghệ khai thác tài nguyên dưới lòng đất"
        },
        "answer": "B"
      },
      {
        "question": "Các nhà địa chấn học người Pháp và Mỹ đã sử dụng phương pháp nào để huấn luyện mô hình?",
        "options": {
          "A": "Phân tích dữ liệu từ các trạm quan sát động đất trên toàn cầu",
          "B": "Huấn luyện mô hình nhận diện các mẫu âm thanh liên quan đến trượt chậm",
          "C": "Sử dụng hình ảnh vệ tinh để theo dõi sự dịch chuyển của các mảng kiến tạo",
          "D": "Nghiên cứu các mẫu lõi khoan từ sâu trong lòng đất"
        },
        "answer": "B"
      },
      {
        "question": "Một số nhà địa chấn học tin rằng trượt chậm có thể gây ra điều gì?",
        "options": {
          "A": "Làm giảm áp lực lên lớp vỏ Trái Đất",
          "B": "Gây ra hiện tượng núi lửa phun trào",
          "C": "Chuyển ứng suất từ sâu trong đứt gãy địa chất lên lớp vỏ giòn của Trái Đất",
          "D": "Làm thay đổi từ trường của Trái Đất"
        },
        "answer": "C"
      },
      {
        "question": "Trong phòng thí nghiệm, các tác giả đã mô phỏng trượt chậm bằng cách sử dụng vật liệu gì?",
        "options": {
          "A": "Hai tấm kim loại và một lớp dầu bôi trơn",
          "B": "Hai tấm vật liệu tổng hợp và một lớp vật liệu hạt, dạng cát",
          "C": "Hai tấm đá tự nhiên và một lớp đất sét",
          "D": "Hai tấm kính và một lớp nước"
        },
        "answer": "B"
      },
      {
        "question": "Đoạn video được đề cập trong bài viết thể hiện điều gì?",
        "options": {
          "A": "Sự hình thành của các mảng kiến tạo",
          "B": "Quá trình phun trào núi lửa",
          "C": "Hình ảnh hiển vi của các tấm vật liệu trong quá trình mô phỏng trượt chậm",
          "D": "Sự lan truyền của sóng địa chấn"
        },
        "answer": "C"
      },
      {
        "question": "Đánh giá rủi ro ngắn hạn hiện tại của các nhà địa chấn học cung cấp thông tin gì?",
        "options": {
          "A": "Dự báo động đất trong vòng vài năm tới",
          "B": "Đánh giá rủi ro cho một địa điểm và khoảng thời gian cụ thể",
          "C": "Xác định vị trí chính xác của tâm chấn động đất",
          "D": "Đo cường độ của các trận động đất trong quá khứ"
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu về trượt chậm có thể dẫn đến loại dự báo nào?",
        "options": {
          "A": "Dự báo thời tiết chính xác hơn",
          "B": "Dự báo động đất dài hạn, tính bằng tháng hoặc năm",
          "C": "Dự báo về sự thay đổi mực nước biển",
          "D": "Dự báo về sự xuất hiện của các loại khoáng sản mới"
        },
        "answer": "B"
      },
      {
        "question": "Việc dự báo động đất dài hạn có thể giúp ích gì cho các nhà hoạch định?",
        "options": {
          "A": "Giảm chi phí xây dựng các công trình mới",
          "B": "Đẩy nhanh việc nâng cấp an toàn động đất có thể bị trì hoãn do chi phí",
          "C": "Phát triển các phương pháp khai thác tài nguyên hiệu quả hơn",
          "D": "Cải thiện hệ thống cảnh báo sóng thần"
        },
        "answer": "B"
      },
      {
        "question": "Thuật ngữ 'brittle crust' trong bài viết đề cập đến điều gì?",
        "options": {
          "A": "Lớp vỏ Trái Đất dễ bị biến dạng",
          "B": "Lớp vỏ Trái Đất giòn, dễ vỡ",
          "C": "Lớp phủ của Trái Đất",
          "D": "Lõi của Trái Đất"
        },
        "answer": "B"
      }
    ]
  },
  "protection-for-pollinators": {
    "title": "Protection for Pollinators",
    "collection": "science",
    "content": "A machine learning method could help chemists formulate pesticides that target harmful insects but leave bees alone.What’s new:Researchers at Oregon State Universitydevelopedmodels that classify whether or not a chemical is fatally toxic to bees. The authors believe their approach could be used to screen pesticide formulations for potential harm to these crucial pollinators.How it works:The authors trained two support vector machines to classify molecules as lethal or nonlethal. The dataset was 382 graphs ofpesticide molecules, in which each atom is a node and each bond between atoms is an edge, labeled for toxicity. The researchers used a different method to train each model.\n\nResults:The two models performed similarly. They accurately classified 81 to 82 percent of molecules as lethal or nonlethal to bees. Of the molecules classified as lethal, 67 to 68 percent were truly lethal.Behind the news:Bees play a crucial role inpollinatingmany agricultural products. Without them, yields of important crops like cotton, avocados, and most fruit would drop precipitously.Numerous studieshave shown that pesticides are harmful to bees. Pesticides have contributed to increased mortality amongdomesticated honey beesas well as a decline in the number ofwild bee species.Why it matters:Pesticides, herbicides, and fungicides have their dangers, but they help enable farms to produce sufficient food to feed a growing global population. Machine learning may help chemists engineer pesticides that are benign to all creatures except their intended targets.We’re thinking:It’s good to see machine learning take some of the sting out of using pesticides.",
    "qa": [
      {
        "question": "Phương pháp học máy được đề cập trong bài viết có mục đích chính là gì?",
        "options": {
          "A": "Tăng cường khả năng kháng thuốc của côn trùng gây hại.",
          "B": "Phát triển thuốc trừ sâu nhắm mục tiêu côn trùng gây hại nhưng không ảnh hưởng đến ong.",
          "C": "Nghiên cứu vòng đời của các loài ong khác nhau.",
          "D": "Tăng năng suất cây trồng bằng cách sử dụng ít thuốc trừ sâu hơn."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu tại Đại học Oregon State đã sử dụng loại mô hình học máy nào?",
        "options": {
          "A": "Mạng nơ-ron tích chập (Convolutional Neural Networks).",
          "B": "Máy hỗ trợ vectơ (Support Vector Machines).",
          "C": "Cây quyết định (Decision Trees).",
          "D": "Hồi quy tuyến tính (Linear Regression)."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu được sử dụng để huấn luyện mô hình bao gồm những thông tin gì?",
        "options": {
          "A": "Hình ảnh của các loài ong khác nhau.",
          "B": "Đồ thị phân tử của thuốc trừ sâu, trong đó mỗi nguyên tử là một nút và mỗi liên kết là một cạnh, được gán nhãn độc tính.",
          "C": "Dữ liệu về số lượng ong chết do các loại thuốc trừ sâu khác nhau.",
          "D": "Thông tin về các loại cây trồng mà ong thường thụ phấn."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả của mô hình cho thấy độ chính xác trong việc phân loại các phân tử là độc hại hay không độc hại đối với ong là bao nhiêu?",
        "options": {
          "A": "Khoảng 50-60%.",
          "B": "Khoảng 70-75%.",
          "C": "Khoảng 81-82%.",
          "D": "Khoảng 90-95%."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhấn mạnh vai trò quan trọng của ong trong việc gì?",
        "options": {
          "A": "Kiểm soát số lượng côn trùng gây hại.",
          "B": "Sản xuất mật ong và các sản phẩm từ ong.",
          "C": "Thụ phấn cho nhiều sản phẩm nông nghiệp.",
          "D": "Duy trì sự cân bằng sinh thái trong tự nhiên."
        },
        "answer": "C"
      },
      {
        "question": "Tác động tiêu cực của thuốc trừ sâu đối với ong được thể hiện như thế nào?",
        "options": {
          "A": "Gây ra sự thay đổi hành vi của ong.",
          "B": "Làm giảm khả năng tìm kiếm thức ăn của ong.",
          "C": "Góp phần làm tăng tỷ lệ tử vong ở ong mật và suy giảm số lượng ong hoang dã.",
          "D": "Làm suy yếu hệ miễn dịch của ong."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc sử dụng thuốc trừ sâu, thuốc diệt cỏ và thuốc diệt nấm là gì?",
        "options": {
          "A": "Bảo vệ môi trường khỏi các tác nhân gây hại.",
          "B": "Tăng cường chất lượng sản phẩm nông nghiệp.",
          "C": "Giảm chi phí sản xuất nông nghiệp.",
          "D": "Giúp các trang trại sản xuất đủ lương thực để nuôi sống dân số toàn cầu ngày càng tăng."
        },
        "answer": "D"
      },
      {
        "question": "Theo bài viết, lợi ích tiềm năng của việc sử dụng học máy trong lĩnh vực thuốc trừ sâu là gì?",
        "options": {
          "A": "Giảm thiểu hoàn toàn việc sử dụng thuốc trừ sâu.",
          "B": "Phát triển các loại thuốc trừ sâu có tác dụng nhanh hơn.",
          "C": "Thiết kế các loại thuốc trừ sâu chỉ gây hại cho mục tiêu đã định.",
          "D": "Tăng cường khả năng phân hủy sinh học của thuốc trừ sâu."
        },
        "answer": "C"
      },
      {
        "question": "Trong số các loại cây trồng được đề cập, loại cây nào phụ thuộc nhiều vào việc thụ phấn của ong?",
        "options": {
          "A": "Lúa gạo.",
          "B": "Ngô.",
          "C": "Bông, bơ và hầu hết các loại trái cây.",
          "D": "Lúa mì."
        },
        "answer": "C"
      },
      {
        "question": "Tỷ lệ phần trăm các phân tử được phân loại là gây chết ong, nhưng thực tế đúng là gây chết ong là bao nhiêu?",
        "options": {
          "A": "Khoảng 50-55%.",
          "B": "Khoảng 67-68%.",
          "C": "Khoảng 81-82%.",
          "D": "Khoảng 90-95%."
        },
        "answer": "B"
      }
    ]
  },
  "quantum-leap": {
    "title": "Quantum Leap",
    "collection": "science",
    "content": "A leaked paper from Google’s quantum computing lab claims “supremacy” over conventional computers.What’s new:The U.S. space agency NASA, whose scientists are collaborating with Google on a quantum computer, accidentally published a paper describing the breakthrough. TheFinancial Timessnagged a copy before it was taken down, naming machine learning, chemistry, and materials science as likely uses for the technology. Google declined to comment pending the paper’s official release.How it works:Google designed the special-purpose system, called Sycamore, to determine whether sets of randomly generated numbers were truly random. Researchers estimate that it would have taken the world’s fastest conventional supercomputer, IBM’sSummit, 10,000 years to solve the problem. Sycamore solved it in 3 minutes and 20 seconds, an early demonstration of the capability known as quantum supremacy.\n\nBehind the news:Physicist Paul Benioff wrote a paper in 1980 describing how quantum-mechanical phenomena like superposition and entanglement could be applied to computing. Google, IBM, Intel, and Microsoft lately have made substantial progress in implementing those ideas.Why it matters:Quantum computing’s promise of exponentially faster processing in particular applications has many in the AI community excited to apply it to tasks like search and pattern matching. There’s no telling when quantum AI will emerge, but when it does, it probably will require new types of models tailored to the peculiar nature of qubits.We’re thinking:The problem Sycamore solved doesn’t have much practical value, as computer scientist Scott Aaronson points out in his excellent quantum-supremacyFAQ. It’s more “like the Wright Brothers’ flight” circa 1903, he says: The technology works, but it will be a while before actual users can climb aboard.",
    "qa": [
      {
        "question": "Theo bài viết, cơ quan nào của Hoa Kỳ đã vô tình công bố tài liệu về đột phá trong lĩnh vực máy tính lượng tử?",
        "options": {
          "A": "Bộ Quốc phòng Hoa Kỳ",
          "B": "Cơ quan Hàng không Vũ trụ Hoa Kỳ (NASA)",
          "C": "Cục Tình báo Trung ương (CIA)",
          "D": "Bộ Năng lượng Hoa Kỳ"
        },
        "answer": "B"
      },
      {
        "question": "Tờ báo nào đã nhanh chóng thu thập được bản sao của tài liệu bị rò rỉ trước khi nó bị gỡ xuống?",
        "options": {
          "A": "The New York Times",
          "B": "The Wall Street Journal",
          "C": "The Financial Times",
          "D": "The Washington Post"
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống máy tính lượng tử đặc biệt của Google được gọi là gì?",
        "options": {
          "A": "Summit",
          "B": "QuantumLeap",
          "C": "Sycamore",
          "D": "Google Quantum"
        },
        "answer": "C"
      },
      {
        "question": "Theo ước tính, siêu máy tính thông thường nhanh nhất thế giới (IBM's Summit) sẽ mất bao lâu để giải quyết vấn đề mà Sycamore đã giải quyết?",
        "options": {
          "A": "3 phút 20 giây",
          "B": "1 năm",
          "C": "100 năm",
          "D": "10.000 năm"
        },
        "answer": "D"
      },
      {
        "question": "Khái niệm 'quantum supremacy' (ưu thế lượng tử) được hiểu là gì trong bối cảnh bài viết?",
        "options": {
          "A": "Khả năng máy tính lượng tử thay thế hoàn toàn máy tính thông thường.",
          "B": "Khả năng máy tính lượng tử giải quyết các vấn đề mà máy tính thông thường không thể giải quyết trong một khoảng thời gian hợp lý.",
          "C": "Khả năng máy tính lượng tử có kích thước nhỏ hơn nhiều so với máy tính thông thường.",
          "D": "Khả năng máy tính lượng tử tiêu thụ ít năng lượng hơn so với máy tính thông thường."
        },
        "answer": "B"
      },
      {
        "question": "Nhà vật lý nào đã viết một bài báo vào năm 1980 mô tả cách các hiện tượng cơ học lượng tử có thể được áp dụng vào điện toán?",
        "options": {
          "A": "Albert Einstein",
          "B": "Stephen Hawking",
          "C": "Paul Benioff",
          "D": "Richard Feynman"
        },
        "answer": "C"
      },
      {
        "question": "Những công ty nào được đề cập trong bài viết là đang có những tiến bộ đáng kể trong việc triển khai các ý tưởng về điện toán lượng tử?",
        "options": {
          "A": "Apple, Samsung, Huawei",
          "B": "Google, IBM, Intel, Microsoft",
          "C": "Amazon, Facebook, Netflix",
          "D": "Tesla, SpaceX, Boeing"
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng nào sau đây được đề cập trong bài viết là một trong những lĩnh vực mà máy tính lượng tử có thể mang lại lợi ích?",
        "options": {
          "A": "Xử lý văn bản",
          "B": "Thiết kế đồ họa",
          "C": "Tìm kiếm và đối sánh mẫu",
          "D": "Quản lý cơ sở dữ liệu"
        },
        "answer": "C"
      },
      {
        "question": "Theo Scott Aaronson, vấn đề mà Sycamore đã giải quyết có giá trị thực tế như thế nào?",
        "options": {
          "A": "Có giá trị thực tế rất lớn trong lĩnh vực tài chính.",
          "B": "Có giá trị thực tế rất lớn trong lĩnh vực y học.",
          "C": "Không có nhiều giá trị thực tế.",
          "D": "Có giá trị thực tế tương đương với các ứng dụng AI hiện tại."
        },
        "answer": "C"
      },
      {
        "question": "Scott Aaronson so sánh thành tựu của Sycamore với sự kiện lịch sử nào?",
        "options": {
          "A": "Sự ra đời của Internet",
          "B": "Chuyến bay đầu tiên của anh em nhà Wright",
          "C": "Sự phát minh ra bóng đèn điện",
          "D": "Sự phát minh ra điện thoại"
        },
        "answer": "B"
      }
    ]
  },
  "researchers-trained-neural-networks-to-assist-brain-surgeons-real-time-tumor-removal-decisions": {
    "title": "Guiding the Scalpel",
    "collection": "science",
    "content": "A neural network helped brain surgeons decide how much healthy tissue to cut out when removing tumors — while the patients were on the operating table.\n\nWhat’s new:Researchers from Amsterdam University Medical Centers and Princess Máxima Center for Pediatric Oncology in the Netherlandsbuilta system to assess how aggressively surgeons should treat tumors. It worked accurately and quickly enough to enable doctors to adjust their approach in the operating room.Key insight:Brain surgeons don’t know the type of tumor they will remove until an operation is underway. When they have a sample — about the size of a kernel of corn — they can classify it by looking at it under a microscope. Alternatively, they can send it out for DNA sequencing, which can take weeks, requiring a second surgery. However, faster, less precise DNA sequencing can be performed on-site, and a neural network can classify such preliminary DNA sequences quickly and accurately. This way, a doctor can proceed with the operation with confidence in the tumor’s classification.\n\nHow it works:The authors trained a system of four vanilla neural networks to classify brain tumors.\n\nResults:The authors’ system performed well on tumor DNA samples in an existing collection as well as those gathered in an operating room. Tested on samples from 415 tumors, it classified 60.7 percent of them accurately, misclassified 1.9 percent, and was unable to classify 37.3 percent. Tested on samples collected during 25 real surgeries, it correctly classified 18 tumors and was unable to classify 7. In all cases, it returned results within 90 minutes (45 minutes to collect the DNA and 45 minutes to analyze it).\n\nWhy it matters:90 minutes is fast enough to inform brain surgeons what kind of tumor they’re dealing with in the early phase of an operation. If this technique can be rolled out widely, it may help save many lives.We’re thinking:Inferencing presumably takes seconds. The authors say the quick sequencing method processes DNA in 20 to 40 minutes. Speeding up that step offers great potential to accelerate the process.",
    "qa": [
      {
        "question": "Mục đích chính của hệ thống mạng nơ-ron được phát triển là gì?",
        "options": {
          "A": "Giúp bác sĩ phẫu thuật não loại bỏ hoàn toàn các tế bào ung thư.",
          "B": "Hỗ trợ bác sĩ phẫu thuật não quyết định lượng mô khỏe mạnh cần cắt bỏ khi loại bỏ khối u.",
          "C": "Thay thế hoàn toàn việc giải trình tự DNA truyền thống trong chẩn đoán ung thư não.",
          "D": "Dự đoán khả năng tái phát của khối u não sau phẫu thuật."
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm chính của việc sử dụng mạng nơ-ron so với giải trình tự DNA truyền thống là gì?",
        "options": {
          "A": "Độ chính xác cao hơn trong việc phân loại khối u.",
          "B": "Thời gian phân tích nhanh hơn, cho phép điều chỉnh phương pháp phẫu thuật ngay trong phòng mổ.",
          "C": "Chi phí thấp hơn đáng kể so với giải trình tự DNA truyền thống.",
          "D": "Khả năng xác định chính xác nguồn gốc của khối u."
        },
        "answer": "B"
      },
      {
        "question": "Kích thước mẫu khối u được sử dụng để phân loại bằng mạng nơ-ron tương đương với gì?",
        "options": {
          "A": "Một hạt đậu.",
          "B": "Một hạt ngô.",
          "C": "Một hạt gạo.",
          "D": "Một hạt vừng."
        },
        "answer": "B"
      },
      {
        "question": "Mạng nơ-ron được huấn luyện bằng cách sử dụng bao nhiêu mạng nơ-ron đơn lẻ?",
        "options": {
          "A": "Hai.",
          "B": "Ba.",
          "C": "Bốn.",
          "D": "Năm."
        },
        "answer": "C"
      },
      {
        "question": "Trong thử nghiệm trên các mẫu khối u đã có sẵn, hệ thống phân loại chính xác bao nhiêu phần trăm?",
        "options": {
          "A": "37.3%",
          "B": "1.9%",
          "C": "60.7%",
          "D": "100%"
        },
        "answer": "C"
      },
      {
        "question": "Trong thử nghiệm trên các ca phẫu thuật thực tế, hệ thống không thể phân loại được bao nhiêu khối u?",
        "options": {
          "A": "0.",
          "B": "7.",
          "C": "18.",
          "D": "25."
        },
        "answer": "B"
      },
      {
        "question": "Tổng thời gian cần thiết để thu thập DNA và phân tích bằng mạng nơ-ron là bao lâu?",
        "options": {
          "A": "30 phút.",
          "B": "45 phút.",
          "C": "60 phút.",
          "D": "90 phút."
        },
        "answer": "D"
      },
      {
        "question": "Theo bài viết, bước nào trong quy trình phân tích DNA có tiềm năng lớn nhất để tăng tốc độ?",
        "options": {
          "A": "Thu thập mẫu DNA.",
          "B": "Phân loại bằng mạng nơ-ron.",
          "C": "Giải trình tự DNA.",
          "D": "Chuẩn bị mẫu cho giải trình tự."
        },
        "answer": "C"
      },
      {
        "question": "Loại mạng nơ-ron nào được sử dụng trong hệ thống này?",
        "options": {
          "A": "Mạng nơ-ron tích chập (Convolutional Neural Network).",
          "B": "Mạng nơ-ron tái phát (Recurrent Neural Network).",
          "C": "Mạng nơ-ron vanilla (Vanilla Neural Network).",
          "D": "Mạng nơ-ron đối nghịch sinh (Generative Adversarial Network)."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết được thực hiện bởi các nhà nghiên cứu đến từ đâu?",
        "options": {
          "A": "Hoa Kỳ.",
          "B": "Vương quốc Anh.",
          "C": "Hà Lan.",
          "D": "Đức."
        },
        "answer": "C"
      }
    ]
  },
  "researchers-used-neural-networks-to-find-a-new-class-of-antibiotics": {
    "title": "Deep Learning Discovers Antibiotics",
    "collection": "science",
    "content": "Biologists used neural networks to find a new class of antibiotics.\n\nWhat’s new:Researchers at MIT and Harvardtrainedmodels to screen chemical compounds for those that kill methicillin-resistantStaphylococcus aureus(MRSA), the deadliest among bacteria that have evolved to be invulnerable to common antibiotics, and aren’t toxic to humans.\n\nHow it works:The authors built a training set of 39,312 compounds including most known antibiotics and a diverse selection of other molecules. In a lab, they tested each compound for its ability to inhibit growth of MRSA and its toxicity to human liver, skeletal muscle, and lung cells. Using the resulting data, they trained four ensembles of 20 graph neural networks each to classify compounds for (i) antibiotic properties, (ii) toxicity to the liver, (iii) toxicity to skeletal muscles, and (iv) toxicity to the lungs.\n\nResults:Of the compounds predicted to be likely antibiotics and nontoxic, the authors lab-tested 241 that were not known to work against MRSA. Of those, 8.7 percent inhibited the bacterium’s growth. This exceeds the percentage of antibiotics in the training set (1.3 percent), suggesting that the authors’ approach could be a useful first step in finding new antibiotics. The authors also tested 30 compounds predicted not to be antibiotics. None of them (0 percent) inhibited the bacterium’s growth — further evidence that their approach could be a useful first step. Two of the compounds that inhibited MRSA share a similar and novel mechanism of action against bacteria and also inhibited other antibiotic-resistant infections in lab tests. One of them proved effective against MRSA infections in mice.\n\nBehind the news:Most antibiotics currently in use were discovered in the mid-20th century, a golden age of antibiotics, which brought many formerly deadly pathogens under control. Modern techniques, including genomics and synthetic antibiotics, extended discoveries through the end of the century by identifying variants on existing drugs. However, in the 21st century, new antibiotics have either been redundant or haven’t been clinically successful, a report by the National Institutes of Healthnoted. At the same time, widespread use of antibiotics has pushed many dangerous bacteria to evolve resistance. Pathogens chiefly responsible for a variety of ailments are generally resistant even to antibiotics reserved for use as a last resort.Why it matters:Antibiotic-resistant infections are among the top global public health threats directly responsible for 1.27 million deaths in 2019,according tothe World Health Organization.New options, as well as efforts to fight the emergence of resistant strains, are needed.\n\nWe’re thinking:If neural networks canidentifynew classes of medicines, AI could bring a golden age of medical discovery. That hope helps to explain why pharmaceutical companies arehiringmachine learning engineers at unprecedented rates.",
    "qa": [
      {
        "question": "Mục tiêu chính của nghiên cứu được đề cập trong bài viết là gì?",
        "options": {
          "A": "Phát triển các phương pháp mới để điều trị ung thư gan.",
          "B": "Tìm kiếm một loại kháng sinh mới chống lại vi khuẩn Staphylococcus aureus kháng methicillin (MRSA).",
          "C": "Nghiên cứu tác động của kháng sinh lên hệ thần kinh trung ương.",
          "D": "Cải thiện hiệu quả của các loại kháng sinh hiện có."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã sử dụng phương pháp nào để sàng lọc các hợp chất hóa học?",
        "options": {
          "A": "Kỹ thuật di truyền.",
          "B": "Mạng nơ-ron nhân tạo.",
          "C": "Tổng hợp hóa học.",
          "D": "Phân tích геном."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu nào được sử dụng để huấn luyện các mô hình mạng nơ-ron?",
        "options": {
          "A": "Dữ liệu về cấu trúc gen của vi khuẩn MRSA.",
          "B": "Dữ liệu về khả năng ức chế sự phát triển của MRSA và độc tính đối với tế bào người của các hợp chất.",
          "C": "Dữ liệu về lịch sử sử dụng kháng sinh của bệnh nhân.",
          "D": "Dữ liệu về các loại thuốc điều trị ung thư gan."
        },
        "answer": "B"
      },
      {
        "question": "Tỷ lệ phần trăm các hợp chất được dự đoán là kháng sinh và không độc hại, sau đó được chứng minh là có khả năng ức chế sự phát triển của MRSA trong phòng thí nghiệm là bao nhiêu?",
        "options": {
          "A": "1.3%",
          "B": "8.7%",
          "C": "39.312%",
          "D": "100%"
        },
        "answer": "B"
      },
      {
        "question": "Điều gì cho thấy phương pháp của các tác giả có thể là một bước hữu ích trong việc tìm kiếm kháng sinh mới?",
        "options": {
          "A": "Tất cả các hợp chất được dự đoán là không có tác dụng đều không ức chế sự phát triển của vi khuẩn.",
          "B": "Tỷ lệ kháng sinh trong tập huấn luyện cao hơn tỷ lệ các hợp chất ức chế vi khuẩn.",
          "C": "Tỷ lệ các hợp chất ức chế vi khuẩn trong các hợp chất được dự đoán là kháng sinh cao hơn tỷ lệ kháng sinh trong tập huấn luyện.",
          "D": "Các hợp chất mới được tìm thấy có cấu trúc tương tự các kháng sinh đã biết."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, phần lớn các loại kháng sinh hiện đang được sử dụng được phát hiện vào thời điểm nào?",
        "options": {
          "A": "Đầu thế kỷ 20.",
          "B": "Giữa thế kỷ 20.",
          "C": "Cuối thế kỷ 20.",
          "D": "Đầu thế kỷ 21."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính mà các nhà khoa học đang đối mặt trong việc phát triển kháng sinh mới trong thế kỷ 21 là gì?",
        "options": {
          "A": "Thiếu nguồn tài trợ cho nghiên cứu.",
          "B": "Các kháng sinh mới thường trùng lặp hoặc không thành công trên lâm sàng.",
          "C": "Khó khăn trong việc tìm kiếm các hợp chất tự nhiên có khả năng kháng khuẩn.",
          "D": "Các quy định nghiêm ngặt của chính phủ về thử nghiệm thuốc."
        },
        "answer": "B"
      },
      {
        "question": "Theo Tổ chức Y tế Thế giới (WHO), có bao nhiêu ca tử vong liên quan trực tiếp đến nhiễm trùng kháng kháng sinh vào năm 2019?",
        "options": {
          "A": "127.000",
          "B": "1.27 triệu",
          "C": "12.7 triệu",
          "D": "127 triệu"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất giải pháp nào để giải quyết vấn đề kháng kháng sinh?",
        "options": {
          "A": "Hạn chế sử dụng kháng sinh trong nông nghiệp.",
          "B": "Phát triển các lựa chọn điều trị mới và nỗ lực chống lại sự xuất hiện của các chủng kháng thuốc.",
          "C": "Tăng cường giám sát việc sử dụng kháng sinh trong bệnh viện.",
          "D": "Đầu tư vào nghiên cứu về các phương pháp điều trị thay thế."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao các công ty dược phẩm lại tuyển dụng kỹ sư học máy với tốc độ chưa từng có?",
        "options": {
          "A": "Để giảm chi phí nghiên cứu và phát triển.",
          "B": "Để tăng cường khả năng tiếp thị sản phẩm.",
          "C": "Để tận dụng AI trong việc khám phá các loại thuốc mới.",
          "D": "Để tuân thủ các quy định mới về an toàn thuốc."
        },
        "answer": "C"
      }
    ]
  },
  "robochem-a-system-that-outshines-human-chemists-in-chemical-synthesis-efficiency": {
    "title": "Robot Chemist",
    "collection": "science",
    "content": "A robot outperformed human chemists at synthesizing chemicals.\n\nWhat’s new:Researchers at University of Amsterdam builtRoboChem, an integrated robotic system that learned to design light-activated chemical reactions while achieving optimal yields and throughput.\n\nHow it works:RoboChem includes a computer that runs a machine learning model and a set of automated lab instruments including a liquid handler, syringe pumps, and a photochemical reactor, all enclosed in an airtight vacuum chamber. Given a set of reagents and resulting product, RoboChem aimed to find conditions that maximize the yield (the ratio of the amount of a product synthesized to the potential amount, expressed as a percentage) and throughput (rate of synthesis) in the fewest experimental runs. It followed a 3-part cycle: (i) determine experimental conditions (amounts and concentrations of the given reagents, intensity of light, and time spent in the reactor), (ii) combine the reagents under those conditions, and (iii) evaluate the yield and throughput via a spectrometer.\n\nResults:Robochem executed reactions to produce 18 substances. In all cases, it found experimental conditions that had either higher throughput and yield, or higher throughput and nearly equivalent yield, than the best conditions previously known. In one reaction, RoboChem achieved yield of 58 percent and throughput of 95.6 g/Lh (gram yield per liter in the reactor per hour), while previous work had achieved 45 percent and 2.8 g/Lh. In another reaction, RoboChem achieved 81 percent and 1720 g/Lh, where previous best results achieved 82 percent and 3 g/Lh — 1 percent lower yield but 573 times greater throughput.\n\nBehind the news:In 2020, researchers at the University of Liverpooltraineda mobile robot arm to navigate a chemistry lab, mix chemicals, and operate equipment. That robot used a similar optimization method. However, the Amsterdam robot is much less expensive and proved itself in a wider range of experiments.\n\nWhy it matters:The authors believe that RoboChem could dramatically increase lab productivity at lower cost in time and money. The light-activated reactions they focused on have applications in fields including pharmaceuticals, household chemicals, and renewable energy.We’re thinking:These researchers clearly are in their element.",
    "qa": [
      {
        "question": "Hệ thống RoboChem được phát triển bởi trường đại học nào?",
        "options": {
          "A": "Đại học Liverpool",
          "B": "Đại học Amsterdam",
          "C": "Đại học Oxford",
          "D": "Đại học Cambridge"
        },
        "answer": "B"
      },
      {
        "question": "RoboChem sử dụng phương pháp nào để thiết kế các phản ứng hóa học?",
        "options": {
          "A": "Thử nghiệm ngẫu nhiên",
          "B": "Mô hình học máy",
          "C": "Phản ứng quang hóa",
          "D": "Phân tích thống kê"
        },
        "answer": "B"
      },
      {
        "question": "Trong chu trình hoạt động của RoboChem, bước nào đánh giá hiệu suất và thông lượng?",
        "options": {
          "A": "Xác định điều kiện thí nghiệm",
          "B": "Kết hợp các chất phản ứng",
          "C": "Đánh giá bằng quang phổ kế",
          "D": "Điều chỉnh áp suất chân không"
        },
        "answer": "C"
      },
      {
        "question": "Hai yếu tố chính mà RoboChem tối ưu hóa trong các phản ứng hóa học là gì?",
        "options": {
          "A": "Nhiệt độ và áp suất",
          "B": "Nồng độ và thể tích",
          "C": "Hiệu suất và thông lượng",
          "D": "Thời gian phản ứng và chất xúc tác"
        },
        "answer": "C"
      },
      {
        "question": "Trong một ví dụ cụ thể, RoboChem đã đạt được thông lượng cao hơn bao nhiêu lần so với kết quả tốt nhất trước đó, mặc dù hiệu suất thấp hơn 1%?",
        "options": {
          "A": "57 lần",
          "B": "172 lần",
          "C": "573 lần",
          "D": "1720 lần"
        },
        "answer": "C"
      },
      {
        "question": "Robot hóa học của Đại học Liverpool năm 2020 khác biệt so với RoboChem ở điểm nào?",
        "options": {
          "A": "Sử dụng phương pháp tối ưu hóa khác",
          "B": "Có khả năng di chuyển trong phòng thí nghiệm",
          "C": "Đắt tiền hơn và thử nghiệm trên phạm vi hẹp hơn",
          "D": "Không sử dụng cánh tay robot"
        },
        "answer": "C"
      },
      {
        "question": "Ứng dụng tiềm năng nào KHÔNG được đề cập trong bài viết liên quan đến các phản ứng quang hóa mà RoboChem tập trung vào?",
        "options": {
          "A": "Dược phẩm",
          "B": "Hóa chất gia dụng",
          "C": "Năng lượng tái tạo",
          "D": "Sản xuất phân bón"
        },
        "answer": "D"
      },
      {
        "question": "Bộ phận nào của RoboChem chịu trách nhiệm điều khiển việc xử lý chất lỏng?",
        "options": {
          "A": "Bộ xử lý trung tâm (CPU)",
          "B": "Bộ điều khiển áp suất chân không",
          "C": "Bộ xử lý chất lỏng",
          "D": "Bơm tiêm"
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu chính của RoboChem khi được cung cấp một tập hợp các chất phản ứng và sản phẩm là gì?",
        "options": {
          "A": "Tìm điều kiện để giảm thiểu chi phí thí nghiệm",
          "B": "Tìm điều kiện để tối đa hóa hiệu suất và thông lượng trong số lần thử nghiệm ít nhất",
          "C": "Tìm điều kiện để tạo ra sản phẩm phụ ít nhất",
          "D": "Tìm điều kiện để phản ứng xảy ra nhanh nhất"
        },
        "answer": "B"
      },
      {
        "question": "Theo tác giả, RoboChem có thể mang lại lợi ích gì cho các phòng thí nghiệm?",
        "options": {
          "A": "Giảm thiểu rủi ro cháy nổ",
          "B": "Tăng đáng kể năng suất với chi phí thấp hơn",
          "C": "Loại bỏ hoàn toàn sự can thiệp của con người",
          "D": "Tạo ra các hợp chất hóa học mới hoàn toàn"
        },
        "answer": "B"
      }
    ]
  },
  "science-community-outreach": {
    "title": "(Science) Community Outreach",
    "collection": "science",
    "content": "Are your scientist friends intimidated by machine learning? They might be inspired by a primer from one of the world’s premier tech titans.What’s new:Former Google CEO Eric Schmidt and Cornell PhD candidate Maithra Raghu school scientists in machine learning in a sprawlingoverview.Scientific Revolution 2.0:Science producesmountains of data, and machine learning can help make sense of it. Schmidt and Raghu offer a brisk tour of architectures and techniques, explaining how neural networks have served disciplines from astronomy to radiography.\n\nBehind the news:Maithra Raghu isn’t as famous as her co-author, but her star is on the rise. Named amongForbes’ “30 Under 30” last year, she focuses on improving human-machine collaboration.Why it matters:The range of mysteries that machine learning can help solve is limited by the number of scientists who are proficient in machine learning.We’re thinking:We’d like to see more CEOs publish technical papers on arXiv.org!",
    "qa": [
      {
        "question": "Bài viết này chủ yếu nói về điều gì?",
        "options": {
          "A": "Sự cạnh tranh giữa các công ty công nghệ hàng đầu trong lĩnh vực trí tuệ nhân tạo.",
          "B": "Một bài giới thiệu về machine learning dành cho các nhà khoa học, được viết bởi Eric Schmidt và Maithra Raghu.",
          "C": "Những khó khăn mà các nhà khoa học gặp phải khi sử dụng machine learning.",
          "D": "Sự trỗi dậy của Maithra Raghu trong lĩnh vực khoa học máy tính."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, tại sao machine learning lại hữu ích cho khoa học?",
        "options": {
          "A": "Nó giúp các nhà khoa học kiếm được nhiều tiền hơn.",
          "B": "Nó giúp xử lý và phân tích lượng lớn dữ liệu mà khoa học tạo ra.",
          "C": "Nó thay thế các phương pháp nghiên cứu khoa học truyền thống.",
          "D": "Nó giúp các nhà khoa học nổi tiếng hơn."
        },
        "answer": "B"
      },
      {
        "question": "Eric Schmidt và Maithra Raghu đã sử dụng ví dụ nào để minh họa ứng dụng của mạng neural trong khoa học?",
        "options": {
          "A": "Sinh học và hóa học.",
          "B": "Vật lý và toán học.",
          "C": "Thiên văn học và X-quang.",
          "D": "Địa chất học và khí tượng học."
        },
        "answer": "C"
      },
      {
        "question": "Maithra Raghu được biết đến với vai trò gì?",
        "options": {
          "A": "Cựu CEO của Google.",
          "B": "Người sáng lập một công ty khởi nghiệp về trí tuệ nhân tạo.",
          "C": "Nghiên cứu sinh tiến sĩ tại Cornell và chuyên gia về hợp tác giữa người và máy.",
          "D": "Một nhà khoa học nổi tiếng trong lĩnh vực thiên văn học."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì được coi là hạn chế sự phát triển của việc ứng dụng machine learning trong giải quyết các vấn đề khoa học?",
        "options": {
          "A": "Sự thiếu hụt dữ liệu khoa học.",
          "B": "Chi phí đầu tư vào machine learning quá cao.",
          "C": "Số lượng nhà khoa học thành thạo machine learning còn hạn chế.",
          "D": "Sự phức tạp của các thuật toán machine learning."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến việc Maithra Raghu đã được vinh danh trong danh sách nào?",
        "options": {
          "A": "Time 100.",
          "B": "Forbes '30 Under 30'.",
          "C": "Fortune 500.",
          "D": "MIT Technology Review's 35 Innovators Under 35."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của Maithra Raghu là gì?",
        "options": {
          "A": "Phát triển các thuật toán machine learning phức tạp hơn.",
          "B": "Cải thiện sự hợp tác giữa con người và máy móc.",
          "C": "Tìm ra các ứng dụng mới của machine learning trong lĩnh vực y tế.",
          "D": "Đào tạo các nhà khoa học trẻ về machine learning."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì sẽ thúc đẩy sự phát triển của machine learning trong khoa học?",
        "options": {
          "A": "Việc các CEO công nghệ công bố các bài báo khoa học.",
          "B": "Việc chính phủ đầu tư nhiều hơn vào nghiên cứu machine learning.",
          "C": "Việc các trường đại học mở rộng chương trình đào tạo về machine learning.",
          "D": "Việc các nhà khoa học hợp tác chặt chẽ hơn với các kỹ sư machine learning."
        },
        "answer": "A"
      },
      {
        "question": "Bài viết gọi sự kết hợp giữa khoa học và machine learning là gì?",
        "options": {
          "A": "Cuộc cách mạng công nghiệp 4.0.",
          "B": "Cuộc cách mạng khoa học lần thứ ba.",
          "C": "Cuộc cách mạng khoa học 2.0.",
          "D": "Kỷ nguyên trí tuệ nhân tạo."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết được đăng tải trên nền tảng nào?",
        "options": {
          "A": "Một tạp chí khoa học uy tín.",
          "B": "Một trang web tin tức công nghệ.",
          "C": "arXiv.org.",
          "D": "Một blog cá nhân."
        },
        "answer": "C"
      }
    ]
  },
  "seeing-cancer": {
    "title": "Seeing Cancer",
    "collection": "science",
    "content": "Microscopes outfitted with AI-driven augmented reality could improve the accuracy of cancer diagnoses.\n\nWhat’s happened:Google Health developed anattachmentfor analog microscopes that outlines signs of breast and prostate cancer in real time.How it works:A computer-vision system spots cancer in a cell slide, while augmented-reality tech superimposes the AI’s prediction over the slide at around 27 frames per second.\n\nBehind the news:Pathologists use microscopes to measure tumor size relative to nearby lymph nodes and to count the number of cells nearing or undergoing mitosis. That information tells them how aggressively a patient’s cancer is spreading.Why it matters:Interpreting cell slides is subjective, and one pathologist’s understanding can differ greatly from another’s. Patients in locations where trained pathologists are scarce tend to suffer most from this inconsistency. AI-enhanced tools could help make diagnoses more reliable.\n\nWe’re thinking:AI is a natural complement to digital microscopes, but analog microscopes are far more common. This technology promises to upgrade those tools at a fraction of the cost of replacing them.",
    "qa": [
      {
        "question": "Công nghệ thực tế tăng cường hỗ trợ AI trong kính hiển vi giúp cải thiện điều gì?",
        "options": {
          "A": "Tốc độ xử lý hình ảnh của kính hiển vi.",
          "B": "Độ chính xác của chẩn đoán ung thư.",
          "C": "Khả năng phóng đại của kính hiển vi.",
          "D": "Khả năng kết nối internet của kính hiển vi."
        },
        "answer": "B"
      },
      {
        "question": "Google Health đã phát triển một thiết bị hỗ trợ cho loại kính hiển vi nào?",
        "options": {
          "A": "Kính hiển vi điện tử.",
          "B": "Kính hiển vi tương tự (analog).",
          "C": "Kính hiển vi kỹ thuật số.",
          "D": "Kính hiển vi huỳnh quang."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống thị giác máy tính (computer-vision system) trong thiết bị của Google Health có chức năng gì?",
        "options": {
          "A": "Tăng độ phân giải của hình ảnh tế bào.",
          "B": "Phát hiện dấu hiệu ung thư trong mẫu tế bào.",
          "C": "Điều chỉnh độ sáng của kính hiển vi.",
          "D": "Tự động lấy nét hình ảnh tế bào."
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ thực tế tăng cường (augmented reality) trong thiết bị của Google Health hiển thị thông tin gì lên hình ảnh tế bào?",
        "options": {
          "A": "Thông tin về kích thước tế bào.",
          "B": "Dự đoán của AI về khả năng ung thư.",
          "C": "Thông tin về các loại tế bào khác nhau.",
          "D": "Thông tin về lịch sử bệnh án của bệnh nhân."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà bệnh lý học sử dụng kính hiển vi để đo lường yếu tố nào liên quan đến khối u?",
        "options": {
          "A": "Màu sắc của khối u.",
          "B": "Kích thước khối u so với hạch bạch huyết lân cận.",
          "C": "Độ cứng của khối u.",
          "D": "Nhiệt độ của khối u."
        },
        "answer": "B"
      },
      {
        "question": "Thông tin về số lượng tế bào đang phân chia (mitosis) giúp các nhà bệnh lý học đánh giá điều gì?",
        "options": {
          "A": "Khả năng kháng thuốc của tế bào ung thư.",
          "B": "Mức độ lây lan của ung thư.",
          "C": "Loại thuốc điều trị phù hợp.",
          "D": "Khả năng tái phát của ung thư."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì có thể xảy ra do sự khác biệt trong cách giải thích mẫu tế bào giữa các nhà bệnh lý học?",
        "options": {
          "A": "Tăng chi phí điều trị.",
          "B": "Chẩn đoán không nhất quán.",
          "C": "Thời gian điều trị kéo dài.",
          "D": "Tăng nguy cơ tác dụng phụ của thuốc."
        },
        "answer": "B"
      },
      {
        "question": "Đối tượng nào có xu hướng chịu ảnh hưởng nhiều nhất từ sự không nhất quán trong chẩn đoán do thiếu chuyên gia?",
        "options": {
          "A": "Bệnh nhân ở các thành phố lớn.",
          "B": "Bệnh nhân ở các khu vực có ít nhà bệnh lý học được đào tạo.",
          "C": "Bệnh nhân có bảo hiểm y tế tốt.",
          "D": "Bệnh nhân có tiền sử gia đình mắc ung thư."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, AI được xem là gì đối với kính hiển vi kỹ thuật số?",
        "options": {
          "A": "Một sự thay thế hoàn toàn.",
          "B": "Một sự bổ sung tự nhiên.",
          "C": "Một công cụ chẩn đoán độc lập.",
          "D": "Một phương pháp điều trị ung thư."
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm chính của việc nâng cấp kính hiển vi tương tự bằng công nghệ AI so với việc thay thế bằng kính hiển vi kỹ thuật số là gì?",
        "options": {
          "A": "Độ chính xác cao hơn.",
          "B": "Chi phí thấp hơn.",
          "C": "Tốc độ xử lý nhanh hơn.",
          "D": "Dễ sử dụng hơn."
        },
        "answer": "B"
      }
    ]
  },
  "scientific-discovery-on-a-roll": {
    "title": "Scientific Discovery on a Roll",
    "collection": "science",
    "content": "A mechanical lab assistant could accelerate chemistry research.What’s new:Researchers at the University of Liverpool trained amobile robot armto navigate a lab, operate equipment, handle samples, and obtain results far faster than a human scientist. The authors believe their system is the first mobile robot capable of running lab experiments.How it works:In a recent study, the articulated arm on wheels completed 688 experiments, testing various hypotheses to extract hydrogen from water efficiently using chemicals and light.\n\nResults:The study discovered chemical formulae that made it easier to separate hydrogen from oxygen in water. More important, it proved that a robot can do such work effectively, speedily, and without interruption. The authors estimate that a human scientist would have taken 1,000 times longer to produce similar results.Why it matters:The authors hope to offer robots forsalewithin 18 months. The $150,000-plus price tag might be a bargain if the Covid-19 pandemic makes in-person lab experimentation unfeasible.We’re thinking:Most factory automation involves stationary robots positioned along a manufacturing line. Perhaps mobile manipulation — where the arm moves to the object being manipulated — will prove to be more efficient for automating science labs.",
    "qa": [
      {
        "question": "Nghiên cứu được đề cập trong bài viết được thực hiện tại đâu?",
        "options": {
          "A": "Đại học Cambridge",
          "B": "Đại học Oxford",
          "C": "Đại học Liverpool",
          "D": "Viện Công nghệ Massachusetts (MIT)"
        },
        "answer": "C"
      },
      {
        "question": "Robot trong nghiên cứu này có khả năng gì đặc biệt?",
        "options": {
          "A": "Phân tích dữ liệu phức tạp",
          "B": "Di chuyển trong phòng thí nghiệm và thực hiện thí nghiệm",
          "C": "Dự đoán kết quả thí nghiệm",
          "D": "Tự động viết báo cáo khoa học"
        },
        "answer": "B"
      },
      {
        "question": "Trong thí nghiệm được mô tả, robot đã thực hiện bao nhiêu thí nghiệm?",
        "options": {
          "A": "100",
          "B": "500",
          "C": "688",
          "D": "1000"
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu chính của các thí nghiệm mà robot thực hiện là gì?",
        "options": {
          "A": "Tìm kiếm vật liệu mới",
          "B": "Nghiên cứu về năng lượng hạt nhân",
          "C": "Chiết xuất hydro từ nước một cách hiệu quả",
          "D": "Phát triển phương pháp tổng hợp protein"
        },
        "answer": "C"
      },
      {
        "question": "Kết quả quan trọng nhất mà nghiên cứu này chứng minh là gì?",
        "options": {
          "A": "Robot có thể thay thế hoàn toàn con người trong phòng thí nghiệm",
          "B": "Robot có thể thực hiện công việc thí nghiệm một cách hiệu quả, nhanh chóng và liên tục",
          "C": "Robot có thể tạo ra các công thức hóa học mới",
          "D": "Robot có thể tự học và cải thiện kỹ năng thí nghiệm"
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu ước tính robot thực hiện thí nghiệm nhanh hơn con người bao nhiêu lần?",
        "options": {
          "A": "10 lần",
          "B": "100 lần",
          "C": "500 lần",
          "D": "1000 lần"
        },
        "answer": "D"
      },
      {
        "question": "Các tác giả hy vọng sẽ bán robot này trong khoảng thời gian nào?",
        "options": {
          "A": "Trong vòng 6 tháng",
          "B": "Trong vòng 12 tháng",
          "C": "Trong vòng 18 tháng",
          "D": "Trong vòng 24 tháng"
        },
        "answer": "C"
      },
      {
        "question": "Giá dự kiến của một robot thí nghiệm này là bao nhiêu?",
        "options": {
          "A": "Dưới 50.000 đô la",
          "B": "Khoảng 100.000 đô la",
          "C": "Trên 150.000 đô la",
          "D": "Khoảng 200.000 đô la"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết gợi ý rằng tự động hóa phòng thí nghiệm bằng robot di động có thể hiệu quả hơn so với phương pháp nào?",
        "options": {
          "A": "Sử dụng phần mềm mô phỏng",
          "B": "Sử dụng robot cố định trên dây chuyền sản xuất",
          "C": "Sử dụng trí tuệ nhân tạo để phân tích dữ liệu",
          "D": "Sử dụng các thiết bị thí nghiệm truyền thống"
        },
        "answer": "B"
      },
      {
        "question": "Đại dịch Covid-19 có thể ảnh hưởng đến việc sử dụng robot trong phòng thí nghiệm như thế nào?",
        "options": {
          "A": "Làm giảm nhu cầu sử dụng robot",
          "B": "Làm tăng chi phí sản xuất robot",
          "C": "Làm cho việc thí nghiệm trực tiếp trở nên khó khăn hơn, thúc đẩy việc sử dụng robot",
          "D": "Không có ảnh hưởng gì"
        },
        "answer": "C"
      }
    ]
  },
  "seeing-sea-plastic": {
    "title": "Seeing Sea Plastic",
    "collection": "science",
    "content": "A machine learning model is scanning the oceans for the glint of garbage.What’s new:Researchers from the UK’s Plymouth Marine Laboratory trained amodelto identify ocean-borne refuse.How it works:The European Space Agency’s two Sentinel-2 satellites capture light that reflects off the Earth’s surface. The algorithm examines this imagery, pixel by pixel, for evidence of plastic.\n\nResults:The team tested the model on imagery of coastal sites in western Canada, Ghana, Vietnam, and Scotland. It averaged 86 percent accuracy.Behind the news:Marine scientists are finding a variety of uses for AI in ocean conservation. For instance, Google built aneural networkthat recognizes humpback whale songs using data from the U.S. National Oceanic and Atmospheric Administration. Researchers use the model to follow migrations.Why it matters:Fish and whales often die from ingesting or getting tangled inpieces of plastic. As the materialbreaks downinto tiny fragments, it gets eaten by smaller organisms, which get eaten by larger organisms, includingfishconsumed by humans, with potentially toxic effects.We’re thinking:Pointing this model at the beach might be even more helpful: Most ocean plasticoriginateson land, so coastlines may be the best places to capture it before it enters the food web.",
    "qa": [
      {
        "question": "Mục đích chính của mô hình machine learning được đề cập trong bài viết là gì?",
        "options": {
          "A": "Theo dõi sự di cư của cá voi lưng gù.",
          "B": "Phát hiện rác thải nhựa trôi nổi trên đại dương.",
          "C": "Phân tích thành phần hóa học của nước biển.",
          "D": "Dự đoán thời tiết trên biển."
        },
        "answer": "B"
      },
      {
        "question": "Cơ quan nào cung cấp dữ liệu hình ảnh cho mô hình machine learning này?",
        "options": {
          "A": "U.S. National Oceanic and Atmospheric Administration.",
          "B": "Google.",
          "C": "Plymouth Marine Laboratory.",
          "D": "European Space Agency."
        },
        "answer": "D"
      },
      {
        "question": "Mô hình machine learning này hoạt động bằng cách nào?",
        "options": {
          "A": "Phân tích âm thanh phát ra từ rác thải nhựa.",
          "B": "Tìm kiếm ánh sáng phản xạ từ rác thải nhựa trong hình ảnh vệ tinh.",
          "C": "Sử dụng cảm biến nhiệt để phát hiện rác thải nhựa.",
          "D": "Phân tích dòng chảy của đại dương để dự đoán vị trí rác thải nhựa."
        },
        "answer": "B"
      },
      {
        "question": "Độ chính xác trung bình của mô hình khi được thử nghiệm ở các khu vực ven biển là bao nhiêu?",
        "options": {
          "A": "76%",
          "B": "86%",
          "C": "96%",
          "D": "66%"
        },
        "answer": "B"
      },
      {
        "question": "Ngoài việc phát hiện rác thải nhựa, AI còn được sử dụng trong lĩnh vực bảo tồn biển để làm gì?",
        "options": {
          "A": "Dự đoán sự tuyệt chủng của các loài sinh vật biển.",
          "B": "Nhận diện tiếng hát của cá voi lưng gù để theo dõi sự di cư.",
          "C": "Phân tích thành phần dinh dưỡng của các loài tảo biển.",
          "D": "Kiểm soát ô nhiễm tiếng ồn dưới nước."
        },
        "answer": "B"
      },
      {
        "question": "Tác động tiêu cực của rác thải nhựa đối với sinh vật biển là gì?",
        "options": {
          "A": "Gây ra sự thay đổi màu sắc của san hô.",
          "B": "Làm tăng nhiệt độ nước biển.",
          "C": "Gây ra ngộ độc và mắc kẹt dẫn đến tử vong.",
          "D": "Làm giảm độ mặn của nước biển."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì xảy ra khi rác thải nhựa phân hủy thành các mảnh nhỏ?",
        "options": {
          "A": "Chúng trở nên vô hại và tự phân hủy hoàn toàn.",
          "B": "Chúng được các sinh vật nhỏ ăn vào và đi vào chuỗi thức ăn.",
          "C": "Chúng lắng xuống đáy biển và tạo thành lớp trầm tích.",
          "D": "Chúng phản xạ ánh sáng mặt trời và làm giảm nhiệt độ nước biển."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, nguồn gốc chính của rác thải nhựa trên đại dương là từ đâu?",
        "options": {
          "A": "Các hoạt động đánh bắt cá trên biển.",
          "B": "Các tàu chở hàng bị đắm.",
          "C": "Các hoạt động du lịch trên biển.",
          "D": "Đất liền."
        },
        "answer": "D"
      },
      {
        "question": "Địa điểm nào được cho là hiệu quả nhất để thu gom rác thải nhựa trước khi chúng gây hại cho hệ sinh thái biển?",
        "options": {
          "A": "Các vùng biển sâu.",
          "B": "Các khu vực ven biển.",
          "C": "Các dòng hải lưu lớn.",
          "D": "Các khu vực tập trung nhiều tàu thuyền."
        },
        "answer": "B"
      },
      {
        "question": "Ai là người đã huấn luyện mô hình để xác định rác thải nhựa trên đại dương?",
        "options": {
          "A": "Các nhà khoa học từ Google.",
          "B": "Các nhà nghiên cứu từ U.S. National Oceanic and Atmospheric Administration.",
          "C": "Các nhà nghiên cứu từ Plymouth Marine Laboratory.",
          "D": "Các nhà khoa học từ European Space Agency."
        },
        "answer": "C"
      }
    ]
  },
  "solar-system": {
    "title": "Solar System",
    "collection": "science",
    "content": "Astronomers may use deep learning to keep the sun in focus.What’s new:Researchers at the U.S. National Aeronautics and Space Administration (NASA), Catholic University of America, University of Oslo, and elsewhere developed amodelthat helps recalibrate a space telescope focused on the sun.Key insight:Although the sun is a writhing ball of fiery plasma, patterns across its surface correlate with its brightness. A neural network can learn to associate these patterns with their characteristic brightness, so its output can be used to recalibrate equipment that monitors Earth’s nearest star.How it works:The Solar Dynamics Observatory is a satellite that watches activity in the sun’s outer layers from orbit. Over time, light and space-borne particles degrade its lenses and sensors, dimming its output. NASA typically recalibrates the equipment by comparing the observatory’s images with similar pictures captured by instruments aboard small rockets — an expensive method carried out only periodically. The new model generates a calibration curve that can be used to adjust the observatory on an ongoing basis.\n\nResults:In tests usingimagestaken by uncalibrated equipment, the model outperformed a baseline method that didn’t involve machine learning. Defining success as a prediction within 10 percent of the actual degree of dimming, the authors obtained 77 percent mean success across all wavelengths. The baseline achieved 43 percent mean success.Why it matters:Recalibrating the observatory based on data from the rockets results in downtime as the equipment degrades between launches. Automated recalibration could keep the equipment operating continuously. This approach could also be a boon to probes that monitor faraway bodies, which can’t rely on rocket-assisted correction.We’re thinking:Mother always told us not to stare at the sun, but she didn’t say anything about making a neural network do it for us.",
    "qa": [
      {
        "question": "Mục đích chính của việc nghiên cứu sử dụng deep learning trong bài viết này là gì?",
        "options": {
          "A": "Nghiên cứu cấu trúc bên trong của Mặt Trời.",
          "B": "Tự động hiệu chỉnh kính viễn vọng không gian quan sát Mặt Trời.",
          "C": "Phát hiện các vụ nổ năng lượng mặt trời nguy hiểm.",
          "D": "Thay thế hoàn toàn các phương pháp hiệu chỉnh truyền thống bằng rocket."
        },
        "answer": "B"
      },
      {
        "question": "Cơ sở nào để mô hình deep learning có thể hiệu chỉnh kính viễn vọng?",
        "options": {
          "A": "Mô hình phân tích thành phần hóa học của plasma mặt trời.",
          "B": "Mô hình học cách liên kết các hình ảnh bề mặt Mặt Trời với độ sáng đặc trưng.",
          "C": "Mô hình dự đoán chính xác thời điểm xảy ra các vụ phun trào nhật hoa.",
          "D": "Mô hình đo lường sự thay đổi từ trường của Mặt Trời."
        },
        "answer": "B"
      },
      {
        "question": "Solar Dynamics Observatory (SDO) là gì?",
        "options": {
          "A": "Một loại rocket được sử dụng để hiệu chỉnh kính viễn vọng.",
          "B": "Một kính viễn vọng đặt trên mặt đất để quan sát Mặt Trời.",
          "C": "Một vệ tinh quan sát hoạt động của các lớp ngoài của Mặt Trời.",
          "D": "Một mô hình deep learning dùng để phân tích dữ liệu mặt trời."
        },
        "answer": "C"
      },
      {
        "question": "Vấn đề chính mà SDO gặp phải theo thời gian là gì?",
        "options": {
          "A": "Nhiệt độ tăng cao làm hỏng các bộ phận điện tử.",
          "B": "Ánh sáng và các hạt trong không gian làm giảm chất lượng ống kính và cảm biến.",
          "C": "Va chạm với các thiên thạch nhỏ làm sai lệch hướng quan sát.",
          "D": "Phần mềm điều khiển bị lỗi do bức xạ mặt trời."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp hiệu chỉnh truyền thống mà NASA sử dụng trước đây tốn kém vì lý do gì?",
        "options": {
          "A": "Cần phải thuê các chuyên gia hàng đầu thế giới.",
          "B": "Phải sử dụng các thiết bị đo lường cực kỳ chính xác.",
          "C": "Phải phóng rocket mang theo các thiết bị đo lường.",
          "D": "Phải xây dựng các trạm quan sát mặt đất ở nhiều địa điểm khác nhau."
        },
        "answer": "C"
      },
      {
        "question": "Ưu điểm chính của mô hình deep learning so với phương pháp hiệu chỉnh truyền thống là gì?",
        "options": {
          "A": "Chính xác tuyệt đối, không có sai số.",
          "B": "Có thể hiệu chỉnh liên tục, không gây thời gian chết.",
          "C": "Có thể dự đoán các vụ nổ mặt trời trong tương lai.",
          "D": "Chi phí đầu tư ban đầu thấp hơn nhiều."
        },
        "answer": "B"
      },
      {
        "question": "Trong các thử nghiệm, mô hình deep learning đạt được tỷ lệ thành công trung bình bao nhiêu khi dự đoán độ mờ trong vòng 10% so với thực tế?",
        "options": {
          "A": "43%",
          "B": "50%",
          "C": "77%",
          "D": "90%"
        },
        "answer": "C"
      },
      {
        "question": "Ứng dụng tiềm năng nào khác của phương pháp hiệu chỉnh tự động này được đề cập trong bài viết?",
        "options": {
          "A": "Nghiên cứu về các hành tinh ngoài hệ Mặt Trời.",
          "B": "Giám sát các thiên thạch có khả năng va chạm với Trái Đất.",
          "C": "Hiệu chỉnh các thiết bị quan sát các thiên thể ở xa.",
          "D": "Phát triển năng lượng mặt trời hiệu quả hơn."
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp baseline được sử dụng để so sánh với mô hình deep learning có đặc điểm gì?",
        "options": {
          "A": "Sử dụng một mạng nơ-ron phức tạp hơn.",
          "B": "Không sử dụng machine learning.",
          "C": "Dựa trên dữ liệu từ các kính viễn vọng mặt đất.",
          "D": "Chỉ hiệu chỉnh ở một bước sóng duy nhất."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì xảy ra với thiết bị quan sát giữa các lần phóng rocket để hiệu chỉnh?",
        "options": {
          "A": "Thiết bị được bảo trì và nâng cấp.",
          "B": "Thiết bị ngừng hoạt động để tiết kiệm năng lượng.",
          "C": "Thiết bị tiếp tục hoạt động nhưng chất lượng dữ liệu giảm dần.",
          "D": "Thiết bị tự động hiệu chỉnh bằng các thuật toán đơn giản."
        },
        "answer": "C"
      }
    ]
  },
  "slime-pays": {
    "title": "Slime Pays",
    "collection": "science",
    "content": "A new machine learning technique is boosting algae as a renewable, carbon-neural source of fuel for airplanes and other vehicles typically powered by fossil fuels.What’s new:Researchers at Texas A&M and the National Renewable Energy Laboratorydevelopeda system that helps algae farmers keep an algal colony growing at top speed.How it works:Individual algae cells shade out their neighbors if they grow too densely, keeping the colony from taking full advantage of available light. The authors built an algal growth simulator that lets farmers know when to harvest algae to optimize the colony’s density for growth. The training data consisted of grayscale images of algal colonies under six lighting conditions and at 23 intervals over time. Each example included its average algal concentration, and each pixel was labeled with the light intensity.\n\nResults:The authors found that growth rates across all lighting conditions were at their highest when pixels darkened by algal growth accounted for between 43 percent and 65 percent of an image. They used their system to determine when to harvest indoor and outdoor algae farms. The outdoor farm produced 43.3 grams of biomass per day, the indoor pond 48.1 grams per day. A commercial operation using the authors’ method would produce a biofuel sale price of $281 per ton. That’s comparable to the $260-per-ton price of ethanol derived from corn, which requires expensive processing that algae doesn’t.Behind the news:Depending on the species and processing method, algae can be turned into a variety of fuel products including diesel, alcohol, jet fuel, gasoline, hydrogen, and methane. It was firstproposedas a source of fuel in the 1950s and has been a growing area of sustainable-energy research since the 1970s. However, algal fuels have made little commercial headway due largely to low yields and the cost of processing harvested biomass.Why it matters:Converting algae into fuel is attractive because the biomass is renewable, absorbs as much atmospheric carbon as it emits, and works with internal-combustion engines. To date, it hasn’t scaled well. If machine learning can make it more productive, it could revitalize this approach to alternative energy.We’re thinking:Between this work, Fraunhofer Institute’s similar algal growthsystem, and Hypergiant’s AI-powered algaebioreactor, machine learning applications for algae are blooming!",
    "qa": [
      {
        "question": "Kỹ thuật máy học mới được đề cập trong bài viết giúp cải thiện điều gì ở tảo?",
        "options": {
          "A": "Khả năng hấp thụ ánh sáng mặt trời của tảo.",
          "B": "Tốc độ tăng trưởng của quần thể tảo.",
          "C": "Khả năng chuyển hóa carbon của tảo.",
          "D": "Khả năng chống chịu bệnh tật của tảo."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính mà các nhà nghiên cứu giải quyết liên quan đến mật độ tảo là gì?",
        "options": {
          "A": "Mật độ tảo quá thấp làm giảm hiệu quả hấp thụ carbon.",
          "B": "Mật độ tảo quá cao làm giảm lượng ánh sáng đến các tế bào tảo.",
          "C": "Mật độ tảo không đồng đều gây khó khăn cho việc thu hoạch.",
          "D": "Mật độ tảo không ổn định làm giảm chất lượng nhiên liệu sinh học."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu huấn luyện cho bộ mô phỏng tăng trưởng tảo bao gồm những thông tin nào?",
        "options": {
          "A": "Hình ảnh màu của quần thể tảo, nhiệt độ và độ ẩm.",
          "B": "Hình ảnh thang độ xám của quần thể tảo, cường độ ánh sáng và nồng độ tảo trung bình.",
          "C": "Hình ảnh hồng ngoại của quần thể tảo, lượng oxy hòa tan và độ pH.",
          "D": "Hình ảnh 3D của quần thể tảo, tốc độ dòng chảy và áp suất."
        },
        "answer": "B"
      },
      {
        "question": "Theo nghiên cứu, tỷ lệ pixel tối do tảo che phủ trong ảnh tối ưu cho sự tăng trưởng là bao nhiêu?",
        "options": {
          "A": "Từ 20% đến 30%.",
          "B": "Từ 33% đến 45%.",
          "C": "Từ 43% đến 65%.",
          "D": "Từ 70% đến 80%."
        },
        "answer": "C"
      },
      {
        "question": "Sản lượng sinh khối hàng ngày của trang trại tảo ngoài trời là bao nhiêu?",
        "options": {
          "A": "38.8 gram.",
          "B": "43.3 gram.",
          "C": "48.1 gram.",
          "D": "52.5 gram."
        },
        "answer": "B"
      },
      {
        "question": "Giá bán nhiên liệu sinh học từ tảo sử dụng phương pháp của các tác giả nghiên cứu ước tính là bao nhiêu?",
        "options": {
          "A": "$200 mỗi tấn.",
          "B": "$260 mỗi tấn.",
          "C": "$281 mỗi tấn.",
          "D": "$300 mỗi tấn."
        },
        "answer": "C"
      },
      {
        "question": "Loại nhiên liệu sinh học nào được so sánh với nhiên liệu sinh học từ tảo về giá thành?",
        "options": {
          "A": "Diesel sinh học từ đậu nành.",
          "B": "Ethanol từ ngô.",
          "C": "Butanol từ củ cải đường.",
          "D": "Methane từ chất thải hữu cơ."
        },
        "answer": "B"
      },
      {
        "question": "Nhiên liệu từ tảo lần đầu tiên được đề xuất như một nguồn năng lượng vào thời gian nào?",
        "options": {
          "A": "Những năm 1950.",
          "B": "Những năm 1970.",
          "C": "Những năm 1990.",
          "D": "Những năm 2000."
        },
        "answer": "A"
      },
      {
        "question": "Một trong những ưu điểm chính của việc chuyển đổi tảo thành nhiên liệu là gì?",
        "options": {
          "A": "Quá trình này tạo ra ít chất thải hơn so với các phương pháp khác.",
          "B": "Sinh khối tảo có thể tái tạo, hấp thụ carbon và tương thích với động cơ đốt trong.",
          "C": "Chi phí đầu tư ban đầu thấp hơn so với các nhà máy lọc dầu truyền thống.",
          "D": "Nhiên liệu từ tảo có hiệu suất cao hơn so với xăng dầu."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì đang thúc đẩy sự phát triển của các ứng dụng máy học trong lĩnh vực nuôi trồng tảo?",
        "options": {
          "A": "Sự gia tăng dân số và nhu cầu năng lượng ngày càng tăng.",
          "B": "Sự phát triển của các hệ thống tăng trưởng tảo tương tự và lò phản ứng sinh học hỗ trợ bởi AI.",
          "C": "Sự hỗ trợ tài chính từ chính phủ và các tổ chức phi lợi nhuận.",
          "D": "Sự khan hiếm tài nguyên hóa thạch và biến đổi khí hậu."
        },
        "answer": "B"
      }
    ]
  },
  "sorting-shattered-traditions": {
    "title": "Sorting Shattered Traditions",
    "collection": "science",
    "content": "Computer vision is probing the history of ancient pottery.\n\nWhat’s new:Researchers at Northern Arizona Universitydevelopeda machine learning model that identifies different styles of Native American painting on ceramic fragments and sorts the shards by historical period.\n\nHow it works:The researchers started with an ensemble ofVGG16andResNet50convolutional neural networks pretrained on ImageNet. They fine-tuned the ensemble to predict pottery fragments’ historical period.\n\nResults:In tests, the model classified tens of thousands of unlabeled fragments. It scored higher than two experts and roughly equal to two others.\n\nBehind the news:AI is helping archaeologists discover long-lost civilizations and make sense of clues they had already uncovered.\n\nWhy it matters:For human archaeologists, learning to recognize the patterns on ancient pottery takes years of practice, and they often disagree on a given fragment’s provenance. Machine learning could sift through heaps of pottery shards far more quickly, allowing the humans to focus on interpreting the results.\n\nWe’re thinking:Even when experts correctly identify a fragment, they can’t always explain what features led them to their conclusion. Heat maps from machine learning models could help teach the next generation of archaeologists how to read the past.",
    "qa": [
      {
        "question": "Mục đích chính của nghiên cứu được đề cập trong bài viết là gì?",
        "options": {
          "A": "Phát triển một phương pháp mới để khai quật các di tích cổ.",
          "B": "Sử dụng mô hình học máy để xác định phong cách và niên đại của các mảnh gốm cổ.",
          "C": "So sánh hiệu suất của các mạng nơ-ron khác nhau trong việc phân loại hình ảnh.",
          "D": "Đào tạo các nhà khảo cổ học sử dụng công nghệ mới."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình học máy trong nghiên cứu này được xây dựng dựa trên kiến trúc mạng nơ-ron nào?",
        "options": {
          "A": "AlexNet và GoogleNet.",
          "B": "VGG16 và ResNet50.",
          "C": "LeNet-5 và R-CNN.",
          "D": "LSTM và Transformer."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu nào được sử dụng để huấn luyện trước (pre-train) mô hình học máy?",
        "options": {
          "A": "Bộ dữ liệu hình ảnh gốm cổ.",
          "B": "Bộ dữ liệu ImageNet.",
          "C": "Bộ dữ liệu hình ảnh các di tích khảo cổ.",
          "D": "Bộ dữ liệu hình ảnh các loại hình nghệ thuật khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả của mô hình học máy so với các chuyên gia khảo cổ như thế nào?",
        "options": {
          "A": "Mô hình luôn vượt trội hơn tất cả các chuyên gia.",
          "B": "Mô hình kém hơn tất cả các chuyên gia.",
          "C": "Mô hình tốt hơn hai chuyên gia và tương đương với hai chuyên gia khác.",
          "D": "Mô hình chỉ có thể phân loại một số loại gốm nhất định."
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích chính của việc sử dụng học máy trong khảo cổ học là gì?",
        "options": {
          "A": "Giảm chi phí khai quật.",
          "B": "Tăng độ chính xác của việc xác định niên đại bằng carbon.",
          "C": "Tăng tốc độ phân loại các mảnh gốm, cho phép các nhà khảo cổ tập trung vào việc giải thích kết quả.",
          "D": "Thay thế hoàn toàn vai trò của các nhà khảo cổ học."
        },
        "answer": "C"
      },
      {
        "question": "Một trong những khó khăn mà các nhà khảo cổ học gặp phải khi xác định niên đại gốm là gì?",
        "options": {
          "A": "Thiếu công cụ để phân tích thành phần hóa học của gốm.",
          "B": "Mất nhiều năm thực hành và thường có sự bất đồng về nguồn gốc của một mảnh gốm.",
          "C": "Không có đủ mẫu gốm để so sánh.",
          "D": "Gốm thường bị hư hỏng nặng sau thời gian dài."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất gì về việc sử dụng 'heat maps' từ mô hình học máy?",
        "options": {
          "A": "Để xác định vị trí chính xác của các di tích khảo cổ.",
          "B": "Để tạo ra các bản sao 3D của gốm cổ.",
          "C": "Để giúp đào tạo thế hệ nhà khảo cổ học tiếp theo cách đọc quá khứ.",
          "D": "Để xác định thành phần hóa học của gốm."
        },
        "answer": "C"
      },
      {
        "question": "Công nghệ thị giác máy tính (Computer vision) đang được ứng dụng vào lĩnh vực nào?",
        "options": {
          "A": "Nghiên cứu về ngôn ngữ cổ.",
          "B": "Nghiên cứu về lịch sử gốm cổ.",
          "C": "Nghiên cứu về cấu trúc gen của người cổ đại.",
          "D": "Nghiên cứu về biến đổi khí hậu trong quá khứ."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, AI giúp các nhà khảo cổ học như thế nào?",
        "options": {
          "A": "Tìm kiếm các kho báu bị chôn vùi.",
          "B": "Khám phá các nền văn minh đã mất từ lâu và hiểu rõ hơn về các manh mối đã có.",
          "C": "Dịch các văn bản cổ.",
          "D": "Tái tạo lại các công trình kiến trúc cổ."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì xảy ra khi các chuyên gia xác định chính xác một mảnh vỡ gốm?",
        "options": {
          "A": "Họ luôn có thể giải thích những đặc điểm nào dẫn họ đến kết luận đó.",
          "B": "Họ thường không thể giải thích những đặc điểm nào dẫn họ đến kết luận đó.",
          "C": "Họ sử dụng phương pháp định tuổi bằng carbon để xác nhận kết quả.",
          "D": "Họ luôn đồng ý với các chuyên gia khác về nguồn gốc của mảnh vỡ."
        },
        "answer": "B"
      }
    ]
  },
  "spot-the-bad-mutation": {
    "title": "Spot the Bad Mutation",
    "collection": "science",
    "content": "Every gene in the human genome exists in a variety of mutations, and some encode protein variants that cause cells to malfunction, resulting in illness. Yet which mutations are associated with disease is largely unknown. Can deep learning identify them?What’s new:Jonathan Frazer, Pascal Notin, Mafalda Dias, and colleagues at Harvard Medical School and University of Oxford introducedEvolutionary Model of Variant Effect(EVE), a neural network that learned to classify disease-causing protein variants — and thus dangerous mutations — without labeled data.Key insight:Mutations that encode disease-causing proteins tend to be rare because individuals who carry them are less likely to survive to reproductive age. Thus the prevalence of a given mutation indicates its potential role in illness. Among a collection of variants on a particular protein — a protein family — each variant is produced by a distinct mutation of a particular gene. Clustering uncommon and common variants within the family can sort the mutations likely to be associated with disease.How it works:Avariational autoencoder(VAE) learns to reproduce an input sequence by maximizing the likelihood that output tokens match the corresponding input tokens. In this case, the sequence is a chain of amino acids that make up a protein in adatabaseof 250 million proteins. The authors trained a separate VAE for each protein family. Given one variant in a protein family, it learned to compute the likelihood of each amino acid in the sequence. This enabled the authors to derive the likelihood of the entire sequence.\n\nResults:The authors compared EVE’s classifications to those of 23 supervised and unsupervised models built to perform the same task. They checked the models’ classifications for3,219 genesfor which labels are known. EVE achieved 0.92 AUC, or average area under the curve, while other methods achieved between 0.7 AUC and 0.9 AUC (higher is better). The authors also compared EVE’s output with lab tests that measure, for example, how cells that contain mutations respond to certain chemicals. EVE scored as well as or better than those tests on the five gene families in which labels are known with highest confidence. For example, for the gene known as TP53, EVE achieved 0.99 AUC while the lab test achieved 0.95 AUC.Why it matters:Unsupervised clustering can substitute for labels when we have a belief about what caused certain clusters to emerge; for instance, that natural selection reduces the likelihood of disease-causing protein variants. This approach may open doors to analyze other large datasets in which labels are unavailable.We're thinking:Clustering unlabeled data and examining the clusters for insights is a tried-and-true technique. By employing VAEs to assess likelihoods, this work extends basic clustering to a wider array of problems.",
    "qa": [
      {
        "question": "Mục tiêu chính của mô hình EVE là gì?",
        "options": {
          "A": "Phân loại tất cả các biến thể protein trong cơ thể người.",
          "B": "Phân loại các biến thể protein gây bệnh và do đó là các đột biến nguy hiểm.",
          "C": "Xác định tất cả các gen trong bộ gen người.",
          "D": "Tạo ra các biến thể protein mới để chữa bệnh."
        },
        "answer": "B"
      },
      {
        "question": "Nguyên tắc chính mà EVE sử dụng để xác định các đột biến gây bệnh là gì?",
        "options": {
          "A": "Độ dài của chuỗi amino acid trong protein.",
          "B": "Tần suất xuất hiện của đột biến trong quần thể.",
          "C": "Sự tương đồng của đột biến với các protein đã biết.",
          "D": "Phản ứng của tế bào chứa đột biến với các hóa chất."
        },
        "answer": "B"
      },
      {
        "question": "VAE (Variational Autoencoder) được sử dụng trong EVE để làm gì?",
        "options": {
          "A": "Tạo ra các protein mới từ các amino acid.",
          "B": "Phân tích cấu trúc ba chiều của protein.",
          "C": "Học cách tái tạo một chuỗi đầu vào bằng cách tối đa hóa khả năng các token đầu ra khớp với các token đầu vào.",
          "D": "Xác định vị trí của các gen trên nhiễm sắc thể."
        },
        "answer": "C"
      },
      {
        "question": "Dữ liệu đầu vào chính để huấn luyện VAE trong mô hình EVE là gì?",
        "options": {
          "A": "Dữ liệu về các bệnh di truyền đã được gắn nhãn.",
          "B": "Chuỗi amino acid của 250 triệu protein.",
          "C": "Kết quả xét nghiệm trong phòng thí nghiệm về phản ứng của tế bào với hóa chất.",
          "D": "Thông tin về cấu trúc gen của các loài khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "AUC (Area Under the Curve) được sử dụng để đánh giá điều gì trong nghiên cứu này?",
        "options": {
          "A": "Độ phức tạp của mô hình học sâu.",
          "B": "Hiệu suất của mô hình trong việc phân loại các đột biến gây bệnh.",
          "C": "Số lượng protein được phân tích bởi mô hình.",
          "D": "Thời gian cần thiết để huấn luyện mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả AUC mà EVE đạt được so với các mô hình khác như thế nào?",
        "options": {
          "A": "EVE đạt được kết quả thấp hơn đáng kể so với các mô hình khác.",
          "B": "EVE đạt được kết quả tương đương với các mô hình khác.",
          "C": "EVE đạt được kết quả cao hơn so với các mô hình khác, đạt 0.92 AUC.",
          "D": "EVE chỉ hoạt động tốt trên một số ít gen nhất định."
        },
        "answer": "C"
      },
      {
        "question": "Trong trường hợp gen TP53, kết quả AUC của EVE so với xét nghiệm trong phòng thí nghiệm như thế nào?",
        "options": {
          "A": "EVE đạt kết quả thấp hơn đáng kể so với xét nghiệm trong phòng thí nghiệm.",
          "B": "EVE đạt kết quả tương đương với xét nghiệm trong phòng thí nghiệm.",
          "C": "EVE đạt kết quả cao hơn xét nghiệm trong phòng thí nghiệm (0.99 AUC so với 0.95 AUC).",
          "D": "Xét nghiệm trong phòng thí nghiệm không thể đánh giá gen TP53."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao việc sử dụng phân cụm không giám sát (unsupervised clustering) lại quan trọng trong nghiên cứu này?",
        "options": {
          "A": "Nó cho phép tạo ra dữ liệu được gắn nhãn một cách tự động.",
          "B": "Nó cho phép phân tích dữ liệu lớn mà không cần dữ liệu được gắn nhãn.",
          "C": "Nó giúp tăng tốc quá trình huấn luyện mô hình.",
          "D": "Nó cải thiện độ chính xác của các xét nghiệm trong phòng thí nghiệm."
        },
        "answer": "B"
      },
      {
        "question": "Ý nghĩa của việc sử dụng VAE để đánh giá khả năng xảy ra (likelihood) trong nghiên cứu này là gì?",
        "options": {
          "A": "Nó giới hạn phạm vi ứng dụng của phân cụm cơ bản.",
          "B": "Nó mở rộng phân cụm cơ bản sang một loạt các vấn đề rộng hơn.",
          "C": "Nó thay thế hoàn toàn các phương pháp phân cụm truyền thống.",
          "D": "Nó làm giảm độ chính xác của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Tác giả của nghiên cứu này đến từ những tổ chức nào?",
        "options": {
          "A": "Stanford University và MIT.",
          "B": "Harvard Medical School và University of Oxford.",
          "C": "California Institute of Technology và Princeton University.",
          "D": "University of Cambridge và Imperial College London."
        },
        "answer": "B"
      }
    ]
  },
  "standards-for-testing-medical-ai": {
    "title": "Standards for Testing Medical AI",
    "collection": "science",
    "content": "New guidelines for reporting on experiments with medical AI aim to ensure that such research is transparent, rigorous, and reliable.What’s new:Spirit-AIandConsort-AIare complementary protocols designed to improve the quality of clinical trials for AI-based interventions.How it works:The guidelines are intended to address concerns of doctors, regulators, and funders of technologies such as the Google tumor detector shown above.\n\nBehind the news:Less than 1 percent of 20,500 studies of medical AI met benchmarks for quality and transparency, according to a 2019studyby researchers involved in the new initiatives.Why it matters:These protocols could help medical AI products pass peer and regulatory reviews faster, so they can help patients sooner.We’re thinking:The medical community has set high standards for safety and efficacy. Medical AI needs to meet — better yet, exceed — them. But the technology also poses new challenges such as explainability, and a comprehensive set of standards must address issues like that as well.",
    "qa": [
      {
        "question": "Mục tiêu chính của các hướng dẫn mới về báo cáo các thí nghiệm với AI y tế là gì?",
        "options": {
          "A": "Tăng tốc độ phát triển của các sản phẩm AI y tế.",
          "B": "Đảm bảo tính minh bạch, nghiêm ngặt và đáng tin cậy của nghiên cứu.",
          "C": "Giảm chi phí cho các thử nghiệm lâm sàng AI.",
          "D": "Thúc đẩy việc sử dụng AI trong chẩn đoán và điều trị bệnh."
        },
        "answer": "B"
      },
      {
        "question": "Spirit-AI và Consort-AI là gì?",
        "options": {
          "A": "Hai công ty hàng đầu trong lĩnh vực phát triển AI y tế.",
          "B": "Hai giao thức bổ sung được thiết kế để cải thiện chất lượng thử nghiệm lâm sàng cho các can thiệp dựa trên AI.",
          "C": "Hai loại thuật toán AI được sử dụng trong chẩn đoán ung thư.",
          "D": "Hai tiêu chuẩn đánh giá hiệu quả của các sản phẩm AI y tế."
        },
        "answer": "B"
      },
      {
        "question": "Các hướng dẫn mới này nhằm giải quyết mối quan tâm của những đối tượng nào?",
        "options": {
          "A": "Bệnh nhân và người nhà.",
          "B": "Bác sĩ, nhà quản lý và các nhà tài trợ công nghệ.",
          "C": "Các nhà phát triển AI và kỹ sư phần mềm.",
          "D": "Các nhà nghiên cứu và học giả trong lĩnh vực AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo một nghiên cứu năm 2019, tỷ lệ các nghiên cứu về AI y tế đáp ứng các tiêu chuẩn về chất lượng và tính minh bạch là bao nhiêu?",
        "options": {
          "A": "Khoảng 10%.",
          "B": "Dưới 1%.",
          "C": "Khoảng 50%.",
          "D": "Hơn 75%."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao các giao thức mới này lại quan trọng?",
        "options": {
          "A": "Giúp giảm thiểu rủi ro pháp lý cho các công ty AI y tế.",
          "B": "Giúp các sản phẩm AI y tế vượt qua các đánh giá ngang hàng và quy định nhanh hơn, để có thể giúp bệnh nhân sớm hơn.",
          "C": "Tăng cường sự tin tưởng của công chúng vào AI y tế.",
          "D": "Thúc đẩy sự hợp tác giữa các nhà nghiên cứu và các công ty AI."
        },
        "answer": "B"
      },
      {
        "question": "Thách thức mới nào mà công nghệ AI y tế đặt ra, cần được giải quyết bởi một bộ tiêu chuẩn toàn diện?",
        "options": {
          "A": "Khả năng bảo mật dữ liệu cá nhân.",
          "B": "Khả năng giải thích (explainability) cách AI đưa ra quyết định.",
          "C": "Chi phí phát triển và triển khai cao.",
          "D": "Sự thiếu hụt nhân lực có trình độ trong lĩnh vực AI y tế."
        },
        "answer": "B"
      },
      {
        "question": "Cộng đồng y tế đặt ra tiêu chuẩn nào cho các sản phẩm y tế?",
        "options": {
          "A": "Tính thẩm mỹ và dễ sử dụng.",
          "B": "An toàn và hiệu quả.",
          "C": "Giá cả phải chăng và dễ tiếp cận.",
          "D": "Tính sáng tạo và đổi mới."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất gì về việc đáp ứng các tiêu chuẩn an toàn và hiệu quả của AI y tế?",
        "options": {
          "A": "AI y tế cần đáp ứng các tiêu chuẩn hiện có.",
          "B": "AI y tế cần đáp ứng, hoặc tốt hơn là vượt qua các tiêu chuẩn hiện có.",
          "C": "Các tiêu chuẩn hiện có cần được điều chỉnh để phù hợp với AI y tế.",
          "D": "Không cần thiết phải áp dụng các tiêu chuẩn quá khắt khe cho AI y tế."
        },
        "answer": "B"
      },
      {
        "question": "Ví dụ về công nghệ AI y tế được đề cập trong bài viết là gì?",
        "options": {
          "A": "Robot phẫu thuật.",
          "B": "Máy dò khối u của Google.",
          "C": "Ứng dụng theo dõi sức khỏe.",
          "D": "Hệ thống quản lý bệnh viện thông minh."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích của việc cải thiện chất lượng báo cáo trong nghiên cứu AI y tế là gì?",
        "options": {
          "A": "Để thu hút nhiều nhà đầu tư hơn vào lĩnh vực này.",
          "B": "Để tăng số lượng các nghiên cứu được công bố.",
          "C": "Để đảm bảo rằng nghiên cứu được thực hiện một cách có đạo đức và đáng tin cậy.",
          "D": "Để đơn giản hóa quy trình phê duyệt sản phẩm AI y tế."
        },
        "answer": "C"
      }
    ]
  },
  "stanford-study-finds-ai-matches-human-experts-at-writing-research-proposals": {
    "title": "When LLMs Propose Research Ideas",
    "collection": "science",
    "content": "How do agents based on large language models compare to human experts when it comes to proposing machine learning research? Pretty well, according to one study.\n\nWhat’s new:Chenglei Si, Diyi Yang, and Tatsunori Hashimoto at Stanford produced ideas for research in machine learning using Anthropic’s Claude 3.5 Sonnet and human researchers, and alsoevaluatedthem using both manual and automated methods. Claude 3.5 Sonnet generated competitive proposals, but its evaluations of proposals were less compelling.\n\nHow it works:Each proposal included a problem statement, motivation, step-by-step plan, backup plan, and examples of baseline outcomes versus expected experimental outcomes.\n\nResults:Human judges deemed proposals generated by Claude 3.5 Sonnet as good as or better than those produced by humans. However, large language models proved less effective at judging the proposals’ quality.\n\nWhy it matters:AI models play a growingroleinscientificdiscovery. This work shows they can set directions for research — in machine learning, at least —  that rival those set by humans. However, human evaluation remains the gold standard for comparing performance on complex problems like generating text.\n\nWe’re thinking:Coming up with good research ideas is hard! That a large language model can do it with some competency has exciting implications for the future of both AI and science.",
    "qa": [
      {
        "question": "Nghiên cứu được đề cập trong bài viết sử dụng mô hình ngôn ngữ lớn nào?",
        "options": {
          "A": "GPT-4",
          "B": "Claude 3.5 Sonnet",
          "C": "Llama 3",
          "D": "Gemini Pro"
        },
        "answer": "B"
      },
      {
        "question": "Theo nghiên cứu, mô hình ngôn ngữ lớn và các nhà nghiên cứu con người cùng tạo ra những gì?",
        "options": {
          "A": "Các bài báo khoa học hoàn chỉnh",
          "B": "Các ý tưởng nghiên cứu trong lĩnh vực học máy",
          "C": "Các thuật toán học máy mới",
          "D": "Các bộ dữ liệu huấn luyện lớn"
        },
        "answer": "B"
      },
      {
        "question": "Một đề xuất nghiên cứu trong nghiên cứu này bao gồm những yếu tố nào?",
        "options": {
          "A": "Mã nguồn và dữ liệu thử nghiệm",
          "B": "Tuyên bố vấn đề, động lực, kế hoạch từng bước, kế hoạch dự phòng và ví dụ về kết quả",
          "C": "Đánh giá rủi ro và kế hoạch tài chính",
          "D": "Danh sách các nhà nghiên cứu liên quan và lịch trình dự kiến"
        },
        "answer": "B"
      },
      {
        "question": "Kết quả chính của nghiên cứu cho thấy điều gì về chất lượng của các đề xuất do mô hình ngôn ngữ lớn tạo ra so với các đề xuất của con người?",
        "options": {
          "A": "Kém hơn đáng kể",
          "B": "Tương đương hoặc tốt hơn",
          "C": "Chỉ tốt hơn trong một số lĩnh vực cụ thể",
          "D": "Chỉ tốt hơn khi có sự can thiệp của con người"
        },
        "answer": "B"
      },
      {
        "question": "Trong việc đánh giá chất lượng của các đề xuất, mô hình ngôn ngữ lớn thể hiện như thế nào so với con người?",
        "options": {
          "A": "Hiệu quả hơn đáng kể",
          "B": "Kém hiệu quả hơn",
          "C": "Hiệu quả tương đương",
          "D": "Chỉ hiệu quả khi đánh giá các đề xuất do chính nó tạo ra"
        },
        "answer": "B"
      },
      {
        "question": "Tại sao đánh giá của con người vẫn được coi là 'tiêu chuẩn vàng' trong nghiên cứu này?",
        "options": {
          "A": "Vì con người có khả năng xử lý dữ liệu lớn tốt hơn",
          "B": "Vì con người có khả năng đánh giá các vấn đề phức tạp như tạo văn bản tốt hơn",
          "C": "Vì con người ít bị thiên vị hơn so với mô hình ngôn ngữ lớn",
          "D": "Vì con người có thể hiểu được ngữ cảnh xã hội và đạo đức của nghiên cứu"
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu này có ý nghĩa gì đối với vai trò của mô hình AI trong khám phá khoa học?",
        "options": {
          "A": "Mô hình AI chỉ có thể hỗ trợ các nhà khoa học, không thể tự đưa ra định hướng nghiên cứu.",
          "B": "Mô hình AI có thể đóng vai trò ngày càng tăng trong việc định hướng nghiên cứu, ít nhất là trong lĩnh vực học máy.",
          "C": "Mô hình AI sẽ sớm thay thế hoàn toàn các nhà khoa học trong việc đưa ra ý tưởng nghiên cứu.",
          "D": "Mô hình AI chỉ hữu ích trong việc phân tích dữ liệu, không thể tham gia vào quá trình sáng tạo ý tưởng."
        },
        "answer": "B"
      },
      {
        "question": "Tác giả của bài viết cho rằng điều gì là 'khó'?",
        "options": {
          "A": "Viết mã cho mô hình ngôn ngữ lớn",
          "B": "Đưa ra những ý tưởng nghiên cứu tốt",
          "C": "Đánh giá chất lượng của các đề xuất nghiên cứu",
          "D": "Thực hiện các thí nghiệm học máy"
        },
        "answer": "B"
      },
      {
        "question": "Tên của những nhà nghiên cứu thực hiện nghiên cứu này là gì?",
        "options": {
          "A": "Si Chenglei, Yang Diyi, Hashimoto Tatsunori",
          "B": "Chenglei Si, Diyi Yang, Tatsunori Hashimoto",
          "C": "Hashimoto Tatsunori, Si Chenglei, Yang Diyi",
          "D": "Yang Diyi, Hashimoto Tatsunori, Chenglei Si"
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu này được thực hiện tại đâu?",
        "options": {
          "A": "Viện Công nghệ Massachusetts (MIT)",
          "B": "Đại học Stanford",
          "C": "Đại học California, Berkeley",
          "D": "Đại học Oxford"
        },
        "answer": "B"
      }
    ]
  },
  "taxation-with-vector-representation": {
    "title": "Taxation With Vector Representation",
    "collection": "science",
    "content": "Governments have struggled to find a tax formula that promotes prosperity without creating extremes of wealth and poverty. Can machine learning show the way?What’s new:Data scientists at Salesforce usedreinforcement learningto develop a tax policy aimed at optimizing worker productivity and income equality.How it works:The researchers developed a video game-type simulation in which four reinforcement learning agents worked to earn money while a fifth taxed their income.\n\nResults:The system optimized the balance between productivity and inequality more effectively than the human-created strategies. Its policy counterintuitively set high tax rates for the highest and lowest earners and assigned the lowest rates to middle earners.Yes, but:A model with four workers isn’t nearly complex enough to simulate a real economy, Blake LeBaron, an economist at Brandeis UniversitytoldMIT Technology Review. The Salesforce team plans to scale up the system to 100 workers.Why it matters:More than 70 percent of the world’s population live in nations whereincome inequality is rising, according to the United Nations. Tax policy is a powerful tool for building more prosperous, resilient economies.We’re thinking:Using AI to discover good social policies? Great idea! Imposing high tax rates on the lowest earners? Not so much.",
    "qa": [
      {
        "question": "Mục tiêu chính của nghiên cứu được thực hiện bởi các nhà khoa học dữ liệu tại Salesforce là gì?",
        "options": {
          "A": "Phát triển một trò chơi điện tử mô phỏng nền kinh tế.",
          "B": "Phát triển một chính sách thuế tối ưu hóa năng suất lao động và sự bình đẳng thu nhập.",
          "C": "Chứng minh rằng chính sách thuế do con người tạo ra luôn hiệu quả hơn.",
          "D": "Nghiên cứu tác động của thuế đối với người có thu nhập cao nhất."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp học máy nào đã được sử dụng trong nghiên cứu này?",
        "options": {
          "A": "Học có giám sát (Supervised learning).",
          "B": "Học tăng cường (Reinforcement learning).",
          "C": "Học không giám sát (Unsupervised learning).",
          "D": "Học sâu (Deep learning)."
        },
        "answer": "B"
      },
      {
        "question": "Trong mô phỏng, các tác nhân học tăng cường đã làm gì?",
        "options": {
          "A": "Thu thuế từ người khác.",
          "B": "Làm việc để kiếm tiền.",
          "C": "Quản lý nền kinh tế.",
          "D": "Phân phối lại tài sản."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả bất ngờ nào đã được tìm thấy trong chính sách thuế do hệ thống AI tạo ra?",
        "options": {
          "A": "Áp dụng thuế suất thấp cho tất cả mọi người.",
          "B": "Áp dụng thuế suất cao cho người có thu nhập trung bình.",
          "C": "Áp dụng thuế suất cao cho người có thu nhập cao nhất và thấp nhất, và thuế suất thấp cho người có thu nhập trung bình.",
          "D": "Không áp dụng thuế cho người có thu nhập thấp."
        },
        "answer": "C"
      },
      {
        "question": "Nhà kinh tế Blake LeBaron đã chỉ trích điều gì về mô hình trong nghiên cứu?",
        "options": {
          "A": "Mô hình quá phức tạp để hiểu.",
          "B": "Mô hình không đủ phức tạp để mô phỏng một nền kinh tế thực tế.",
          "C": "Mô hình sử dụng phương pháp học máy không phù hợp.",
          "D": "Mô hình không xem xét đến các yếu tố chính trị."
        },
        "answer": "B"
      },
      {
        "question": "Kế hoạch tiếp theo của nhóm nghiên cứu Salesforce là gì?",
        "options": {
          "A": "Xuất bản kết quả nghiên cứu trên các tạp chí khoa học.",
          "B": "Mở rộng hệ thống lên 100 người lao động.",
          "C": "Áp dụng chính sách thuế này vào thực tế.",
          "D": "Nghiên cứu các yếu tố khác ảnh hưởng đến năng suất lao động."
        },
        "answer": "B"
      },
      {
        "question": "Theo Liên Hợp Quốc, tình trạng bất bình đẳng thu nhập trên thế giới hiện nay như thế nào?",
        "options": {
          "A": "Đang giảm ở hầu hết các quốc gia.",
          "B": "Đang tăng ở hơn 70% các quốc gia.",
          "C": "Ổn định ở hầu hết các quốc gia.",
          "D": "Không có dữ liệu thống kê chính xác."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ nào được đề cập trong bài viết như một phương tiện mạnh mẽ để xây dựng nền kinh tế thịnh vượng và kiên cường hơn?",
        "options": {
          "A": "Chính sách tiền tệ.",
          "B": "Chính sách thương mại.",
          "C": "Chính sách thuế.",
          "D": "Chính sách giáo dục."
        },
        "answer": "C"
      },
      {
        "question": "Quan điểm của người viết về việc sử dụng AI để khám phá các chính sách xã hội tốt là gì?",
        "options": {
          "A": "Hoàn toàn phản đối.",
          "B": "Ủng hộ mạnh mẽ.",
          "C": "Là một ý tưởng tuyệt vời.",
          "D": "Cần phải xem xét kỹ lưỡng hơn."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì khiến người viết không đồng tình trong kết quả nghiên cứu?",
        "options": {
          "A": "Việc sử dụng học tăng cường.",
          "B": "Việc mô phỏng nền kinh tế.",
          "C": "Việc áp dụng thuế suất cao cho người có thu nhập thấp nhất.",
          "D": "Việc tối ưu hóa năng suất lao động."
        },
        "answer": "C"
      }
    ]
  },
  "the-chatbot-search-engines-for-scientific-research": {
    "title": "Language Models in Lab Coats",
    "collection": "science",
    "content": "Specialized chatbots are providing answers to scientific questions.\n\nWhat’s new:A new breed of search engines including Consensus, Elicit, and Scite use large language models to enable scientific researchers to find and summarize significant publications,Naturereported.\n\nHow it works:The models answer text questions by retrieving information from databases of peer-reviewed scientific research.\n\nYes, but:These tools may struggle with sensitive or fast-moving fields. For example, in response to the question, “Do vaccines cause autism?”, pediatrician Meghan Azad at the University of Manitoba found that Consensus returned a paper that focused on public opinion rather than scientific research. Clémentine Fourrier, who evaluates language models at HuggingFace, said that searching for machine learning papers via Elicit often brought up obsolete results.\n\nWhy it matters:Search engines that rank and summarize relevant research can save untold hours for scientists, students, and seekers of knowledge in general. With continued improvement, they stand to accelerate the pace of progress.We’re thinking:These systems show promise and point in an exciting direction. When search was young, search engines that covered the web (like Google) competed with vertical search engines that covered niches such as retail (Amazon) or travel (Expedia). A similar competition is shaping up between general-purpose chatbots and vertical chatbots.",
    "qa": [
      {
        "question": "Các công cụ tìm kiếm chuyên biệt như Consensus, Elicit và Scite sử dụng công nghệ nào để hỗ trợ nghiên cứu khoa học?",
        "options": {
          "A": "Cơ sở dữ liệu thống kê toàn cầu.",
          "B": "Mô hình ngôn ngữ lớn (Large Language Models).",
          "C": "Mạng lưới thần kinh nhân tạo phức tạp.",
          "D": "Thuật toán tìm kiếm dựa trên từ khóa đơn giản."
        },
        "answer": "B"
      },
      {
        "question": "Chức năng chính của các chatbot chuyên biệt trong lĩnh vực khoa học là gì?",
        "options": {
          "A": "Tạo ra các bài báo khoa học mới.",
          "B": "Tìm kiếm và tóm tắt các ấn phẩm khoa học quan trọng.",
          "C": "Thực hiện các thí nghiệm khoa học ảo.",
          "D": "Dịch các tài liệu khoa học sang nhiều ngôn ngữ."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, một hạn chế của các công cụ tìm kiếm khoa học mới là gì?",
        "options": {
          "A": "Khả năng xử lý dữ liệu quá chậm.",
          "B": "Gặp khó khăn với các lĩnh vực nhạy cảm hoặc thay đổi nhanh chóng.",
          "C": "Chỉ hỗ trợ một số ít ngôn ngữ.",
          "D": "Yêu cầu phần cứng máy tính quá mạnh."
        },
        "answer": "B"
      },
      {
        "question": "Trong ví dụ được đề cập, Consensus đã trả về kết quả gì khi được hỏi về mối liên hệ giữa vắc-xin và tự kỷ?",
        "options": {
          "A": "Một nghiên cứu chứng minh vắc-xin gây ra tự kỷ.",
          "B": "Một bài báo tập trung vào ý kiến công chúng thay vì nghiên cứu khoa học.",
          "C": "Một tổng quan hệ thống về các nghiên cứu liên quan.",
          "D": "Không tìm thấy kết quả nào liên quan."
        },
        "answer": "B"
      },
      {
        "question": "Theo Clémentine Fourrier, vấn đề thường gặp khi tìm kiếm các bài báo về máy học thông qua Elicit là gì?",
        "options": {
          "A": "Kết quả tìm kiếm thường bị lỗi định dạng.",
          "B": "Kết quả thường trả về các bài viết đã lỗi thời.",
          "C": "Kết quả thường bị thiếu thông tin quan trọng.",
          "D": "Kết quả thường bị trùng lặp với các nguồn khác."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích chính của các công cụ tìm kiếm khoa học được đề cập trong bài viết là gì?",
        "options": {
          "A": "Giảm chi phí xuất bản khoa học.",
          "B": "Tiết kiệm thời gian cho các nhà khoa học, sinh viên và người tìm kiếm kiến thức.",
          "C": "Tăng cường tính bảo mật của dữ liệu nghiên cứu.",
          "D": "Đơn giản hóa quy trình đánh giá ngang hàng."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết dự đoán điều gì về sự cạnh tranh giữa các chatbot?",
        "options": {
          "A": "Chatbot đa năng sẽ hoàn toàn thay thế chatbot chuyên biệt.",
          "B": "Sẽ có sự cạnh tranh giữa chatbot đa năng và chatbot chuyên biệt, tương tự như giữa các công cụ tìm kiếm web và tìm kiếm theo lĩnh vực.",
          "C": "Chatbot chuyên biệt sẽ chỉ tồn tại trong các lĩnh vực nghiên cứu hẹp.",
          "D": "Sự hợp tác giữa chatbot đa năng và chatbot chuyên biệt sẽ trở nên phổ biến."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến tạp chí nào đã đưa tin về sự phát triển của các công cụ tìm kiếm khoa học mới?",
        "options": {
          "A": "Science.",
          "B": "Nature.",
          "C": "The Lancet.",
          "D": "Cell."
        },
        "answer": "B"
      },
      {
        "question": "Meghan Azad, người đã đánh giá kết quả tìm kiếm của Consensus, là chuyên gia trong lĩnh vực nào?",
        "options": {
          "A": "Khoa học máy tính.",
          "B": "Nhi khoa.",
          "C": "Thống kê sinh học.",
          "D": "Xã hội học."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, sự cải tiến liên tục của các công cụ tìm kiếm khoa học có thể dẫn đến điều gì?",
        "options": {
          "A": "Sự suy giảm chất lượng của các bài báo khoa học.",
          "B": "Sự gia tăng tốc độ tiến bộ trong khoa học.",
          "C": "Sự phụ thuộc quá mức vào công nghệ trong nghiên cứu.",
          "D": "Sự mất việc làm của các nhà nghiên cứu."
        },
        "answer": "B"
      }
    ]
  },
  "the-international-energy-agency-examines-the-energy-costs-and-potential-savings-of-the-ai-boom": {
    "title": "AI Uses Energy, AI Saves Energy",
    "collection": "hardware",
    "content": "AI’s thirst for energy is growing, but the technology also could help produce huge energy savings over the next five to 10 years, according to a recent report.\n\nWhat’s new:The International Energy Agency (IEA), which advises 44 countries on energy policy, performed a comprehensiveanalysisof AI’s energy consumption including energy required to obtain critical materials needed for chips and data centers. The report sees dark clouds ahead but also silver linings.\n\nDark clouds:The report, which is based on interviews with officials in government, energy, and technology, makes four projections for AI’s energy consumption. In the base scenario, future growth and efficiency gains are similar to those of the past five years. The agency also plots a “take-off” scenario in which AI adoption happens faster, a “high efficiency” scenario with lower energy needs, and a “headwinds” scenario in which adoption of AI slows or infrastructure bottlenecks impede construction. Among the conclusions:\n\nSilver linings:AI already makes energy generation, distribution, and use more efficient. The authors expect these savings to accelerate.\n\nYes, but:The authors concede that lower energy costs for AI likely will lead to much greater consumption — according to theJevons paradox— so more-efficient models and hardware will result in higher energy consumption overall.\n\nBehind the news:Data centers were growing rapidly prior to the boom in generative AI. Data centers’ electricity use doubled between 2000 and 2005 and again between 2017 and 2022, driven by the growth of cloud computing and data storage, streaming and social media, and cryptocurrency mining. However, these periods of accelerating growth were followed by periods of slower growth as efforts to cut costs led to more-efficient software and hardware. The authors expect this pattern to hold.\n\nWhy it matters:The IEA report is a first-of-its-kind analysis of AI’s energy requirements, how they’re likely to grow, as well as the potential of the technology itself to reduce those requirements. It confirms that AI is poised to consume huge amounts of energy. However, it also suggests that today’s energy costs will be tomorrow’s energy savings as AI makes energy generation, distribution, and use more efficient across a wide variety of industries.\n\nWe’re thinking:While demand for electricity for data centers is growing rapidly, calibrating the right level of investment is tricky. High levels of growth come with high levels of hype that can lead analysts to overestimate future demand. For example, Microsoft, after examining its forecasts,canceleddata-center projects that would have consumed 2 gigawatts.",
    "qa": [
      {
        "question": "Theo báo cáo của IEA, trong khoảng thời gian nào AI có thể giúp tiết kiệm năng lượng đáng kể?",
        "options": {
          "A": "Trong vòng 1 đến 2 năm tới",
          "B": "Trong vòng 5 đến 10 năm tới",
          "C": "Trong vòng 10 đến 15 năm tới",
          "D": "Trong vòng 20 đến 25 năm tới"
        },
        "answer": "B"
      },
      {
        "question": "IEA là tổ chức tư vấn chính sách năng lượng cho bao nhiêu quốc gia?",
        "options": {
          "A": "24 quốc gia",
          "B": "34 quốc gia",
          "C": "44 quốc gia",
          "D": "54 quốc gia"
        },
        "answer": "C"
      },
      {
        "question": "Báo cáo của IEA đưa ra mấy kịch bản dự báo về mức tiêu thụ năng lượng của AI?",
        "options": {
          "A": "2 kịch bản",
          "B": "3 kịch bản",
          "C": "4 kịch bản",
          "D": "5 kịch bản"
        },
        "answer": "C"
      },
      {
        "question": "Kịch bản nào trong báo cáo của IEA đề cập đến việc áp dụng AI diễn ra nhanh chóng?",
        "options": {
          "A": "Kịch bản cơ bản",
          "B": "Kịch bản cất cánh",
          "C": "Kịch bản hiệu quả cao",
          "D": "Kịch bản ngược gió"
        },
        "answer": "B"
      },
      {
        "question": "Theo báo cáo, AI hiện tại đang giúp ích cho lĩnh vực nào liên quan đến năng lượng?",
        "options": {
          "A": "Giảm chi phí khai thác nhiên liệu hóa thạch",
          "B": "Tăng cường khả năng lưu trữ năng lượng tái tạo",
          "C": "Sản xuất, phân phối và sử dụng năng lượng hiệu quả hơn",
          "D": "Phát triển các nguồn năng lượng hạt nhân an toàn hơn"
        },
        "answer": "C"
      },
      {
        "question": "Hiệu ứng Jevons được đề cập trong bài viết liên quan đến vấn đề gì?",
        "options": {
          "A": "Việc sử dụng năng lượng hiệu quả hơn có thể dẫn đến tiêu thụ năng lượng tổng thể cao hơn",
          "B": "Việc tăng giá năng lượng có thể thúc đẩy các giải pháp tiết kiệm năng lượng",
          "C": "Việc giảm chi phí năng lượng có thể hạn chế đầu tư vào năng lượng tái tạo",
          "D": "Việc sử dụng năng lượng tái tạo có thể làm giảm chi phí năng lượng"
        },
        "answer": "A"
      },
      {
        "question": "Trong giai đoạn nào, mức tiêu thụ điện của các trung tâm dữ liệu tăng gấp đôi do sự phát triển của điện toán đám mây và lưu trữ dữ liệu?",
        "options": {
          "A": "Giữa năm 1990 và 1995",
          "B": "Giữa năm 2000 và 2005",
          "C": "Giữa năm 2005 và 2010",
          "D": "Giữa năm 2010 và 2015"
        },
        "answer": "B"
      },
      {
        "question": "Báo cáo của IEA được xem là gì về phân tích nhu cầu năng lượng của AI?",
        "options": {
          "A": "Báo cáo tổng quan nhất",
          "B": "Báo cáo chi tiết nhất",
          "C": "Báo cáo đầu tiên thuộc loại này",
          "D": "Báo cáo chính xác nhất"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì có thể khiến các nhà phân tích đánh giá quá cao nhu cầu năng lượng trong tương lai của các trung tâm dữ liệu?",
        "options": {
          "A": "Sự thiếu hụt dữ liệu lịch sử",
          "B": "Sự cường điệu quá mức về tốc độ tăng trưởng",
          "C": "Sự phức tạp của các thuật toán AI",
          "D": "Sự thay đổi nhanh chóng của công nghệ phần cứng"
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào đã hủy bỏ các dự án trung tâm dữ liệu sau khi xem xét lại dự báo của mình?",
        "options": {
          "A": "Google",
          "B": "Amazon",
          "C": "Microsoft",
          "D": "Apple"
        },
        "answer": "C"
      }
    ]
  },
  "the-kings-moleskine": {
    "title": "The King’s Moleskine",
    "collection": "science",
    "content": "Machine learning promises to streamline handling of tomorrow’s bureaucratic drudgery — and, it turns out, that of 2,500 years ago.What’s new:Computer vision is helping researchers at the University of Chicagotranslatea massive collection of ancient records inscribed on clay tablets.How it works:Persian scribes around 500 BCE produced thousands of documents now collected in thePersepolis Fortification Archive.\n\nResearchers have been translating the cuneiform characters for decades. Now they hope to speed up the job with help from DeepScribe, a model built by computer scientistSanjay Krishnan.\n\nBehind the news:The archive mostly contains records of government purchases, sales, and transport of food, helping scholars develop a detailed understanding of life in the First Persian Empire. University of Chicago archaeologistsfoundthe tablets in 1933 near the palace sites of early Persian kings. Theyreturnedthe artifacts to Iran in 2019.Why it matters:DeepScribe’s current accuracy is good enough to automate translation of repetitive words and phrases, freeing up human attention for more specialized work like translating place names or deciphering particular words in context. The researchers also believe the model could be useful for filling in gaps on tablets where text has worn away or is indecipherable.We’re thinking:These tablets hold an important lesson for all of us during tax season: Never throw away your receipts.",
    "qa": [
      {
        "question": "Công nghệ nào đang được sử dụng để hỗ trợ dịch các bản khắc cổ trên phiến đất sét?",
        "options": {
          "A": "Thực tế ảo (Virtual Reality)",
          "B": "Thị giác máy tính (Computer Vision)",
          "C": "Xử lý ngôn ngữ tự nhiên (Natural Language Processing)",
          "D": "Internet vạn vật (Internet of Things)"
        },
        "answer": "B"
      },
      {
        "question": "Các bản khắc được đề cập trong bài viết có niên đại từ khoảng thời gian nào?",
        "options": {
          "A": "500 năm sau Công Nguyên",
          "B": "500 năm trước Công Nguyên",
          "C": "1500 năm trước Công Nguyên",
          "D": "1000 năm sau Công Nguyên"
        },
        "answer": "B"
      },
      {
        "question": "Tên của mô hình máy học được sử dụng để dịch các bản khắc là gì?",
        "options": {
          "A": "PersianScribe",
          "B": "CuneiformAI",
          "C": "DeepScribe",
          "D": "TabletTranslator"
        },
        "answer": "C"
      },
      {
        "question": "Ai là người đã xây dựng mô hình DeepScribe?",
        "options": {
          "A": "Một nhóm các nhà khảo cổ học tại Đại học Chicago",
          "B": "Một nhóm các nhà ngôn ngữ học tại Đại học Tehran",
          "C": "Nhà khoa học máy tính Sanjay Krishnan",
          "D": "Một nhóm các nhà sử học tại Đại học Oxford"
        },
        "answer": "C"
      },
      {
        "question": "Nội dung chính của các bản khắc trong Persepolis Fortification Archive là gì?",
        "options": {
          "A": "Các bài thơ và câu chuyện thần thoại",
          "B": "Các ghi chép về chiến tranh và chính trị",
          "C": "Các ghi chép về mua bán, vận chuyển thực phẩm của chính phủ",
          "D": "Các luật lệ và quy định của đế chế Ba Tư"
        },
        "answer": "C"
      },
      {
        "question": "Các phiến đất sét được tìm thấy ở đâu?",
        "options": {
          "A": "Trong các thư viện cổ ở Hy Lạp",
          "B": "Gần các khu vực cung điện của các vị vua Ba Tư thời kỳ đầu",
          "C": "Trong các hầm mộ ở Ai Cập",
          "D": "Dưới lòng sông Tigris và Euphrates"
        },
        "answer": "B"
      },
      {
        "question": "Năm nào các hiện vật này được trả lại cho Iran?",
        "options": {
          "A": "1933",
          "B": "2000",
          "C": "2010",
          "D": "2019"
        },
        "answer": "D"
      },
      {
        "question": "DeepScribe có thể giúp ích như thế nào trong việc dịch các bản khắc?",
        "options": {
          "A": "Thay thế hoàn toàn công việc của các nhà ngôn ngữ học",
          "B": "Tự động dịch toàn bộ các bản khắc một cách chính xác",
          "C": "Tự động dịch các từ và cụm từ lặp đi lặp lại, giải phóng thời gian cho công việc chuyên môn hơn",
          "D": "Xác định vị trí chính xác của các bản khắc bị mất"
        },
        "answer": "C"
      },
      {
        "question": "Ngoài việc dịch, DeepScribe còn có thể được sử dụng cho mục đích nào khác?",
        "options": {
          "A": "Xác định niên đại chính xác của các bản khắc",
          "B": "Phục hồi các phần văn bản bị mờ hoặc không đọc được",
          "C": "Tạo ra các bản sao 3D của các bản khắc",
          "D": "Phân tích thành phần hóa học của đất sét"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết muốn nhắn nhủ điều gì thông qua việc đề cập đến các bản khắc cổ?",
        "options": {
          "A": "Tầm quan trọng của việc bảo tồn di sản văn hóa",
          "B": "Sự phát triển vượt bậc của công nghệ máy học",
          "C": "Bài học về việc lưu giữ hóa đơn trong mùa thuế",
          "D": "Sự phức tạp của ngôn ngữ cổ đại"
        },
        "answer": "C"
      }
    ]
  },
  "the-many-faces-of-genetic-illness": {
    "title": "The Many Faces of Genetic Illness",
    "collection": "science",
    "content": "People with certain genetic disorders share common facial features. Doctors are using computer vision to identify such syndromes in children so they can get early treatment.What’s new:Face2Geneis an app from Boston-basedFDNAthat recognizes genetic disorders from images of patients’ faces. Introduced in 2014, it was upgraded recently to identify over 1,000 syndromes (more than three times as many as the previous version) based on fewer examples. In addition, the upgrade can recognize additional conditions as photos of them are added to the company’s database — no retraining required.How it works:Newworkby Aviram Bar-Haim at FDNA, Tzung-Chien Hsieh at Rheinische Friedrich-Wilhelms-Universität Bonn, and colleagues describes the revised model.\n\nResults:In tests, the new version proved somewhat less accurate than its predecessor at recognizing the 91 syndromes pictured in theLondon Medical Database. It ranked the correct syndrome in the top 30 possibilities 86.59 percent of the time versus the earlier version’s 88.34 percent. However, it was able to identify 816 conditions that its predecessor couldn’t, ranking the correct one in the top 30 possibilities 24.41 percent of the time and in the top position 7.07 percent of the time. (The chance of choosing the correct syndrome randomly was 0.09 percent.)Why it matters:Some350 million peopleworldwide live with a rare genetic disorder. Such conditions are especially difficult to diagnose because they’re so numerous, and many doctors never encounter a case. Face2Gene, which reportedly is used by thousands of geneticists, has beencreditedwith making the job much easier.We’re thinking:Humanity has a sad history of judging people based on appearance. While this model is designed for healthcare professionals to evaluate children who may need medical treatment, we caution against trying to use AI to classify an individual’s traits such as intelligence, character, or sexual preference based on their looks.",
    "qa": [
      {
        "question": "Ứng dụng Face2Gene được phát triển bởi công ty nào?",
        "options": {
          "A": "Rheinische Friedrich-Wilhelms-Universität Bonn",
          "B": "FDNA",
          "C": "London Medical Database",
          "D": "Aviram Bar-Haim's Lab"
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc sử dụng Face2Gene là gì?",
        "options": {
          "A": "Phân loại trí thông minh của một người dựa trên khuôn mặt.",
          "B": "Chẩn đoán sớm các hội chứng di truyền ở trẻ em.",
          "C": "Đánh giá tính cách của một người dựa trên ngoại hình.",
          "D": "Xác định khuynh hướng tình dục của một người dựa trên khuôn mặt."
        },
        "answer": "B"
      },
      {
        "question": "Phiên bản nâng cấp mới của Face2Gene có khả năng nhận diện bao nhiêu hội chứng di truyền?",
        "options": {
          "A": "91 hội chứng",
          "B": "Ít hơn 300 hội chứng",
          "C": "Hơn 1000 hội chứng",
          "D": "816 hội chứng"
        },
        "answer": "C"
      },
      {
        "question": "Ưu điểm nổi bật của phiên bản nâng cấp Face2Gene so với phiên bản trước là gì?",
        "options": {
          "A": "Độ chính xác cao hơn trong việc nhận diện các hội chứng đã biết.",
          "B": "Khả năng nhận diện nhiều hội chứng hơn và không cần huấn luyện lại khi thêm dữ liệu.",
          "C": "Tốc độ xử lý hình ảnh nhanh hơn.",
          "D": "Giao diện người dùng thân thiện hơn."
        },
        "answer": "B"
      },
      {
        "question": "Trong các thử nghiệm, phiên bản mới của Face2Gene xếp hạng đúng hội chứng trong top 30 khả năng bao nhiêu phần trăm thời gian khi nhận diện 816 hội chứng mà phiên bản cũ không nhận diện được?",
        "options": {
          "A": "88.34%",
          "B": "86.59%",
          "C": "7.07%",
          "D": "24.41%"
        },
        "answer": "D"
      },
      {
        "question": "Theo bài viết, có khoảng bao nhiêu người trên thế giới mắc các rối loạn di truyền hiếm gặp?",
        "options": {
          "A": "91 triệu",
          "B": "816 triệu",
          "C": "350 triệu",
          "D": "1000 triệu"
        },
        "answer": "C"
      },
      {
        "question": "Tổ chức nào được cho là đang sử dụng Face2Gene để hỗ trợ công việc của họ?",
        "options": {
          "A": "Các nhà tâm lý học",
          "B": "Các nhà di truyền học",
          "C": "Các nhà xã hội học",
          "D": "Các nhà nhân chủng học"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đưa ra cảnh báo gì liên quan đến việc sử dụng AI và ngoại hình?",
        "options": {
          "A": "Không nên sử dụng AI để đánh giá các đặc điểm cá nhân như trí thông minh dựa trên ngoại hình.",
          "B": "Nên sử dụng AI để cải thiện ngoại hình của con người.",
          "C": "Nên sử dụng AI để dự đoán tương lai của một người dựa trên ngoại hình.",
          "D": "Nên sử dụng AI để phân loại các nhóm người khác nhau dựa trên ngoại hình."
        },
        "answer": "A"
      },
      {
        "question": "Trong thử nghiệm với London Medical Database, độ chính xác của phiên bản mới Face2Gene so với phiên bản cũ như thế nào?",
        "options": {
          "A": "Chính xác hơn đáng kể.",
          "B": "Chính xác hơn một chút.",
          "C": "Kém chính xác hơn một chút.",
          "D": "Hoàn toàn tương đương."
        },
        "answer": "C"
      },
      {
        "question": "Tỷ lệ chọn đúng hội chứng một cách ngẫu nhiên là bao nhiêu?",
        "options": {
          "A": "7.07%",
          "B": "24.41%",
          "C": "86.59%",
          "D": "0.09%"
        },
        "answer": "D"
      }
    ]
  },
  "treatment-the-elusive-molecule": {
    "title": "Treatment — The Elusive Molecule",
    "collection": "science",
    "content": "Will deep learning discover new medicines? Startups — and big-pharma partners — are betting on it.The problem:In theory, there’s a pharmacological cure for just about any ailment. In practice, discovering those therapies takes years and billions of dollars.The solution:Deep learning, with its ability to discern patterns amid noise, could speed up drug discovery considerably. In a dramatic test,Insilicoused an algorithm to sift through petabytes of biochemical data to find potential drugs in 21 days.How it works:Based in Rockville, Maryland, Insilico used itsGenerative Tensorial Reinforcement Learning, or GENTRL, to create digital representations of molecules with properties that inhibit anenzymelinked to several types of cancer, atherosclerosis, and fibrosis.\n\nStatus:Insilico’s enzyme inhibitor was only a proof of concept. However, it attracted partnerships withGlaxoSmithKline,Jiangsu Chia Tai Fenghai Pharmaceutical, andPfizer.Behind the news:Drug discovery is an attractive target for AI startups, given the abundance of biochemical data and desperation of pharmaceutical giants to cut costs. But success still seems hit-or-miss. Only one AI-designed drug — made byExscientia— has progressed tohuman trials.Verseonhas been working on the problem for nearly two decades without creating a marketable product. And, crucially, no one has found a reliable way to accelerate clinical trials, the mostexpensive and time-consumingpart of drug development.Why it matters:The average successful drug costs$2.5 billion dollarsto bring to market, according to a 2016 study. Cutting even a fraction of that cost could allow companies to channel resources towards more and different drugs, potentially providing the public with more cures in less time.We’re thinking:Finding a molecule that becomes a viable drug is like hunting for a single, specific plankton in the Pacific Ocean. Good thing machine learning engineers relish searching for tiny patterns in massive pools of data.\n\nUse deep learning to estimate treatment effects for individual patients in Course 3 of ourAI for Medicine Specialization.",
    "qa": [
      {
        "question": "Bài viết này chủ yếu nói về điều gì?",
        "options": {
          "A": "Những khó khăn trong việc phát triển thuốc mới và cách các công ty dược phẩm lớn đang cố gắng giải quyết chúng.",
          "B": "Tiềm năng của deep learning trong việc đẩy nhanh quá trình khám phá thuốc mới.",
          "C": "Sự cạnh tranh giữa các công ty khởi nghiệp AI và các công ty dược phẩm lớn trong lĩnh vực phát triển thuốc.",
          "D": "Chi phí tốn kém của việc đưa một loại thuốc mới ra thị trường và những nỗ lực để giảm chi phí này."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, vấn đề lớn nhất trong việc khám phá thuốc mới là gì?",
        "options": {
          "A": "Sự thiếu hụt dữ liệu sinh hóa cần thiết để phát triển thuốc.",
          "B": "Quá trình này tốn quá nhiều thời gian và chi phí.",
          "C": "Các thuật toán AI hiện tại chưa đủ mạnh để tìm ra các loại thuốc tiềm năng.",
          "D": "Sự thiếu hợp tác giữa các công ty khởi nghiệp AI và các công ty dược phẩm lớn."
        },
        "answer": "B"
      },
      {
        "question": "Công ty Insilico sử dụng thuật toán nào để tìm kiếm các loại thuốc tiềm năng?",
        "options": {
          "A": "Generative Adversarial Network (GAN)",
          "B": "Recurrent Neural Network (RNN)",
          "C": "Generative Tensorial Reinforcement Learning (GENTRL)",
          "D": "Convolutional Neural Network (CNN)"
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu của chất ức chế enzyme do Insilico phát triển là gì?",
        "options": {
          "A": "Điều trị bệnh Alzheimer.",
          "B": "Ức chế một enzyme liên quan đến một số loại ung thư, xơ vữa động mạch và xơ hóa.",
          "C": "Tăng cường hệ miễn dịch.",
          "D": "Giảm đau mãn tính."
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào đã hợp tác với Insilico trong việc phát triển thuốc?",
        "options": {
          "A": "Exscientia",
          "B": "Verseon",
          "C": "DeepMind",
          "D": "GlaxoSmithKline"
        },
        "answer": "D"
      },
      {
        "question": "Theo bài viết, có bao nhiêu loại thuốc được thiết kế bởi AI đã tiến hành thử nghiệm trên người?",
        "options": {
          "A": "Không có loại nào.",
          "B": "Một loại.",
          "C": "Hai loại.",
          "D": "Nhiều loại."
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào đã làm việc gần hai thập kỷ để phát triển thuốc nhưng chưa có sản phẩm thương mại?",
        "options": {
          "A": "Insilico",
          "B": "Exscientia",
          "C": "Verseon",
          "D": "GlaxoSmithKline"
        },
        "answer": "C"
      },
      {
        "question": "Giai đoạn nào của quá trình phát triển thuốc tốn kém và mất thời gian nhất?",
        "options": {
          "A": "Tìm kiếm và xác định các phân tử tiềm năng.",
          "B": "Thử nghiệm lâm sàng.",
          "C": "Tổng hợp và sản xuất thuốc.",
          "D": "Nghiên cứu tiền lâm sàng."
        },
        "answer": "B"
      },
      {
        "question": "Theo một nghiên cứu năm 2016, chi phí trung bình để đưa một loại thuốc thành công ra thị trường là bao nhiêu?",
        "options": {
          "A": "250 triệu đô la.",
          "B": "500 triệu đô la.",
          "C": "1 tỷ đô la.",
          "D": "2,5 tỷ đô la."
        },
        "answer": "D"
      },
      {
        "question": "Bài viết so sánh việc tìm kiếm một phân tử có thể trở thành thuốc với việc gì?",
        "options": {
          "A": "Tìm kiếm một cây kim trong đống cỏ khô.",
          "B": "Tìm kiếm một viên ngọc trai trong đại dương.",
          "C": "Tìm kiếm một loại vi khuẩn cụ thể trong đất.",
          "D": "Tìm kiếm một loài sinh vật phù du cụ thể ở Thái Bình Dương."
        },
        "answer": "D"
      }
    ]
  },
  "triage-for-pandemic-patients": {
    "title": "Triage for Pandemic Patients",
    "collection": "science",
    "content": "Israeli and American hospitals are using an algorithm to flag individuals at high risk for Covid-19 complications.What’s new:Israel’s Maccabi Healthcare Services and U.S.-based Kaiser Permanente are using a model dubbedCovid Complications AlgoMarkerto identify patients likely to be hospitalized, develop complications, or die from Covid-19. The developer, Medial EarlySign, is offering it forfreeto other health systems.How it works:The model analyzes the electronic medical records of patients in a given health system. It assigns each one a score that indicates their level of risk based on demographics, hospital admission history, prescribed medications, whether they have respiratory and cardiac diseases, and other factors. If a high-scoring patient tests positive for Covid-19, physicians have early warning that they need to take extra care to prevent or manage complications.\n\nFast Track:The model identified about 40,000 members as high risk and put them on the fast track fortesting. If they test positive, doctors will use their risk scores to help determine whether they should be hospitalized, quarantined, or sent home. EarlySign will continue to retrain the model as more data comes in.Yes, but:Privacy laws like the EU’sGeneral Data Protection Regulationmake it difficult to roll out a system like this, which would work best if allowed to automatically scan a massive number of patients’ health records. Another obstacle: Many healthcare systems in the U.S. and elsewhere use oldercomputer systemsthat don’t integrate well with newer systems.Why it matters:With no end to the pandemic in sight, AI that helps hospitals triage patients efficiently can help save lives.We’re thinking:Although the privacy, data aggregation, and data cleaning issues are formidable, systems like this might help us figure out who to allow back to work, who to keep at home, and who needs special care.",
    "qa": [
      {
        "question": "Mục đích chính của thuật toán Covid Complications AlgoMarker là gì?",
        "options": {
          "A": "Dự đoán chính xác thời điểm kết thúc đại dịch Covid-19.",
          "B": "Xác định những bệnh nhân có nguy cơ cao gặp biến chứng do Covid-19.",
          "C": "Phát triển các loại thuốc mới để điều trị Covid-19 hiệu quả hơn.",
          "D": "Tự động quét và làm sạch dữ liệu y tế của bệnh nhân."
        },
        "answer": "B"
      },
      {
        "question": "Tổ chức nào đã hợp tác để sử dụng mô hình Covid Complications AlgoMarker?",
        "options": {
          "A": "Tổ chức Y tế Thế giới (WHO) và Trung tâm Kiểm soát và Phòng ngừa Dịch bệnh Hoa Kỳ (CDC).",
          "B": "Maccabi Healthcare Services (Israel) và Kaiser Permanente (Hoa Kỳ).",
          "C": "Bệnh viện Johns Hopkins và Đại học Harvard.",
          "D": "Chính phủ Israel và Chính phủ Hoa Kỳ."
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào đã phát triển mô hình Covid Complications AlgoMarker?",
        "options": {
          "A": "Kaiser Permanente.",
          "B": "Maccabi Healthcare Services.",
          "C": "Medial EarlySign.",
          "D": "Tổ chức Y tế Thế giới (WHO)."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình Covid Complications AlgoMarker phân tích dữ liệu nào để đánh giá mức độ rủi ro của bệnh nhân?",
        "options": {
          "A": "Kết quả xét nghiệm PCR và nồng độ kháng thể.",
          "B": "Thông tin di truyền và tiền sử gia đình.",
          "C": "Hồ sơ bệnh án điện tử, bao gồm thông tin nhân khẩu học, tiền sử nhập viện, thuốc kê đơn, bệnh hô hấp và tim mạch.",
          "D": "Dữ liệu vị trí và lịch sử tiếp xúc của bệnh nhân."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì xảy ra khi một bệnh nhân có điểm số rủi ro cao xét nghiệm dương tính với Covid-19?",
        "options": {
          "A": "Họ sẽ được tự động đưa vào danh sách chờ ghép tạng.",
          "B": "Bác sĩ sẽ được cảnh báo sớm để có biện pháp phòng ngừa và quản lý biến chứng.",
          "C": "Họ sẽ được yêu cầu cách ly tại nhà trong 21 ngày.",
          "D": "Họ sẽ được tiêm một loại thuốc thử nghiệm mới."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Covid Complications AlgoMarker đã giúp Maccabi Healthcare Services xác định được bao nhiêu thành viên có nguy cơ cao?",
        "options": {
          "A": "Khoảng 4,000 thành viên.",
          "B": "Khoảng 40,000 thành viên.",
          "C": "Khoảng 400,000 thành viên.",
          "D": "Khoảng 4 triệu thành viên."
        },
        "answer": "B"
      },
      {
        "question": "Một trong những thách thức chính đối với việc triển khai rộng rãi hệ thống như Covid Complications AlgoMarker là gì?",
        "options": {
          "A": "Sự thiếu hụt nhân viên y tế được đào tạo để sử dụng hệ thống.",
          "B": "Chi phí quá cao để duy trì và cập nhật hệ thống.",
          "C": "Các quy định về quyền riêng tư như GDPR của EU.",
          "D": "Sự phản đối từ các công ty dược phẩm."
        },
        "answer": "C"
      },
      {
        "question": "Một trở ngại khác đối với việc triển khai hệ thống này là gì?",
        "options": {
          "A": "Sự thiếu hụt dữ liệu y tế điện tử.",
          "B": "Hệ thống máy tính cũ không tích hợp tốt với các hệ thống mới hơn.",
          "C": "Sự thiếu quan tâm từ các bệnh viện và cơ sở y tế.",
          "D": "Sự phức tạp của thuật toán."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, tại sao AI giúp các bệnh viện phân loại bệnh nhân hiệu quả lại quan trọng?",
        "options": {
          "A": "Giúp giảm chi phí điều trị.",
          "B": "Giúp tiết kiệm thời gian cho bác sĩ.",
          "C": "Giúp cứu sống nhiều người hơn trong bối cảnh đại dịch chưa có dấu hiệu kết thúc.",
          "D": "Giúp cải thiện chất lượng dịch vụ y tế."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết gợi ý rằng hệ thống như Covid Complications AlgoMarker có thể giúp ích trong việc gì?",
        "options": {
          "A": "Phát triển vắc-xin Covid-19 hiệu quả hơn.",
          "B": "Quyết định ai nên được phép quay trở lại làm việc, ai nên ở nhà và ai cần được chăm sóc đặc biệt.",
          "C": "Dự đoán chính xác các đợt bùng phát dịch bệnh trong tương lai.",
          "D": "Tự động hóa quy trình chẩn đoán bệnh."
        },
        "answer": "B"
      }
    ]
  },
  "underwater-atlas": {
    "title": "Underwater Atlas",
    "collection": "science",
    "content": "The ocean contains distinct ecosystems, but they’re much harder to see than terrestrial forests or savannas. A new model helps scientists better understand patterns of undersea life, which is threatened by pollution, invasive species, and warming temperatures.What’s new:Researchers from MIT and Harvard used neural networks toupdate existing maps of undersea ecosystems.How it works:The authors used unsupervised learning to analyze relationships between different species of plankton and the nutrients they consume.\n\nResults:The model’s predictions aligned well with measurements taken by scientific surveys and satellite data.Behind the news:Deep learning is being used to tacklea variety of environmental problems.\n\nWhy it matters:Phytoplankton feed aquatic creatures from microorganisms to whales, produce half of the world’s oxygen, and absorb enormous amounts ofatmospheric carbon. Models like this could help oceanographers gauge the planet’s capacity to sustain life.We’re thinking:As educators, we’re all for algorithms that help fish. We don’t want them to drop out of school.",
    "qa": [
      {
        "question": "Mục đích chính của mô hình mới được đề cập trong bài viết là gì?",
        "options": {
          "A": "Nghiên cứu sự di cư của các loài cá voi.",
          "B": "Hiểu rõ hơn về các mô hình của sự sống dưới đáy biển.",
          "C": "Dự đoán sự thay đổi của mực nước biển do biến đổi khí hậu.",
          "D": "Phát triển công nghệ khai thác tài nguyên biển bền vững."
        },
        "answer": "B"
      },
      {
        "question": "Những yếu tố nào được đề cập trong bài viết là mối đe dọa đối với sự sống dưới đáy biển?",
        "options": {
          "A": "Ô nhiễm, sóng thần và động đất.",
          "B": "Ô nhiễm, các loài xâm lấn và nhiệt độ tăng.",
          "C": "Khai thác dầu khí, đánh bắt cá quá mức và bão.",
          "D": "Ô nhiễm ánh sáng, tiếng ồn và sự thay đổi độ mặn."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu từ tổ chức nào đã sử dụng mạng nơ-ron để cập nhật bản đồ hệ sinh thái dưới biển?",
        "options": {
          "A": "NASA và NOAA.",
          "B": "MIT và Harvard.",
          "C": "Stanford và Berkeley.",
          "D": "Oxford và Cambridge."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp học máy nào đã được sử dụng để phân tích mối quan hệ giữa các loài sinh vật phù du và chất dinh dưỡng?",
        "options": {
          "A": "Học có giám sát (Supervised learning).",
          "B": "Học không giám sát (Unsupervised learning).",
          "C": "Học tăng cường (Reinforcement learning).",
          "D": "Học bán giám sát (Semi-supervised learning)."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả của mô hình mới so sánh như thế nào với các dữ liệu thu thập được?",
        "options": {
          "A": "Mô hình cho kết quả hoàn toàn khác biệt so với dữ liệu thực tế.",
          "B": "Mô hình có sai số lớn so với các phép đo khoa học.",
          "C": "Mô hình dự đoán khá khớp với các phép đo khoa học và dữ liệu vệ tinh.",
          "D": "Mô hình chỉ chính xác ở một số khu vực nhất định."
        },
        "answer": "C"
      },
      {
        "question": "Công nghệ học sâu (Deep learning) đang được sử dụng để giải quyết vấn đề gì?",
        "options": {
          "A": "Các vấn đề về kinh tế và xã hội.",
          "B": "Các vấn đề về môi trường.",
          "C": "Các vấn đề về y tế và sức khỏe.",
          "D": "Các vấn đề về an ninh quốc phòng."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao sinh vật phù du (Phytoplankton) lại quan trọng đối với hệ sinh thái?",
        "options": {
          "A": "Chúng là nguồn thức ăn duy nhất cho các loài cá lớn.",
          "B": "Chúng sản xuất một nửa lượng oxy của thế giới và hấp thụ lượng lớn carbon trong khí quyển.",
          "C": "Chúng giúp điều hòa nhiệt độ của đại dương.",
          "D": "Chúng tạo ra các rạn san hô và bảo vệ bờ biển."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình này có thể giúp các nhà hải dương học đánh giá điều gì?",
        "options": {
          "A": "Khả năng tự làm sạch của đại dương.",
          "B": "Khả năng phục hồi của các rạn san hô.",
          "C": "Khả năng duy trì sự sống của hành tinh.",
          "D": "Khả năng dự báo thời tiết trên biển."
        },
        "answer": "C"
      },
      {
        "question": "Theo tác giả, điều gì quan trọng đối với các nhà giáo dục liên quan đến thuật toán và cá?",
        "options": {
          "A": "Đảm bảo cá có đủ thức ăn để phát triển.",
          "B": "Hỗ trợ các thuật toán giúp cá, không muốn chúng bỏ học.",
          "C": "Nghiên cứu hành vi của cá trong môi trường học đường.",
          "D": "Phát triển các chương trình giáo dục về bảo tồn cá."
        },
        "answer": "B"
      },
      {
        "question": "Loại dữ liệu nào được sử dụng để đánh giá độ chính xác của mô hình?",
        "options": {
          "A": "Dữ liệu về nhiệt độ nước biển thu thập từ tàu thuyền.",
          "B": "Dữ liệu về dòng hải lưu thu thập từ phao nổi.",
          "C": "Dữ liệu từ các cuộc khảo sát khoa học và dữ liệu vệ tinh.",
          "D": "Dữ liệu về độ mặn của nước biển thu thập từ các trạm quan trắc."
        },
        "answer": "C"
      }
    ]
  },
  "virtual-creatures-come-to-life": {
    "title": "Virtual Creatures Come to Life",
    "collection": "science",
    "content": "When artificial intelligence meets biology, even the simplest life forms can be mind-blowing.What happened:Researchers at Tufts and the University of Vermontprogrammedan evolutionary algorithm to design virtual organisms with specific capabilities. Then they implemented the designs using animal cells to produce living machines, as illustrated in thisvideo.How it works:The algorithm designed organisms to meet one of four behavioral goals: locomotion, object manipulation, object transportation, and collective behavior.\n\nWhy it matters:The authors envision a “scalable pipeline for creating functional novel life forms.” They believe their approach could yield bugs thatperforma variety of tasks, like digesting spilled oil or gathering ocean-borne plastic particles. They could also deliver medicine, identify cancer, or clear away arterial plaque.We’re thinking:We humbly request an army of biobots designed to scrub bathrooms.",
    "qa": [
      {
        "question": "Nghiên cứu được đề cập trong bài viết là sự kết hợp giữa lĩnh vực nào?",
        "options": {
          "A": "Vật lý và hóa học",
          "B": "Trí tuệ nhân tạo và sinh học",
          "C": "Toán học và kinh tế",
          "D": "Kỹ thuật và y học"
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã sử dụng phương pháp nào để thiết kế các sinh vật ảo?",
        "options": {
          "A": "Mô hình hóa 3D",
          "B": "Thuật toán tiến hóa",
          "C": "Kỹ thuật di truyền",
          "D": "Phân tích dữ liệu lớn"
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của việc thiết kế các sinh vật ảo là gì?",
        "options": {
          "A": "Tạo ra các loài mới",
          "B": "Đạt được các khả năng cụ thể",
          "C": "Nghiên cứu sự tiến hóa",
          "D": "Ứng dụng trong nông nghiệp"
        },
        "answer": "B"
      },
      {
        "question": "Các sinh vật sống được tạo ra trong nghiên cứu này được gọi là gì?",
        "options": {
          "A": "Robot sinh học",
          "B": "Sinh vật biến đổi gen",
          "C": "Máy sống",
          "D": "Vi sinh vật nhân tạo"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến mấy mục tiêu hành vi cụ thể mà thuật toán được dùng để thiết kế sinh vật?",
        "options": {
          "A": "Hai",
          "B": "Ba",
          "C": "Bốn",
          "D": "Năm"
        },
        "answer": "C"
      },
      {
        "question": "Theo tác giả, phương pháp này có thể dẫn đến điều gì?",
        "options": {
          "A": "Sự tuyệt chủng của các loài",
          "B": "Một đường ống có thể mở rộng để tạo ra các dạng sống mới chức năng",
          "C": "Sự phát triển của vũ khí sinh học",
          "D": "Sự ô nhiễm môi trường"
        },
        "answer": "B"
      },
      {
        "question": "Một trong những ứng dụng tiềm năng của 'bugs' được đề cập trong bài viết là gì?",
        "options": {
          "A": "Sản xuất năng lượng sạch",
          "B": "Tiêu hóa dầu tràn",
          "C": "Tạo ra thực phẩm mới",
          "D": "Xây dựng nhà cửa"
        },
        "answer": "B"
      },
      {
        "question": "Ngoài việc xử lý ô nhiễm, 'bugs' còn có thể được sử dụng trong lĩnh vực nào khác?",
        "options": {
          "A": "Năng lượng tái tạo",
          "B": "Y học",
          "C": "Giao thông vận tải",
          "D": "Giáo dục"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất một ứng dụng hài hước nào cho biobots?",
        "options": {
          "A": "Lái xe tự động",
          "B": "Dọn dẹp phòng tắm",
          "C": "Nấu ăn",
          "D": "Làm vườn"
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đến từ những trường đại học nào?",
        "options": {
          "A": "Harvard và MIT",
          "B": "Stanford và Berkeley",
          "C": "Tufts và Đại học Vermont",
          "D": "Yale và Princeton"
        },
        "answer": "C"
      }
    ]
  },
  "would-your-doctor-take-ais-advice": {
    "title": "Would Your Doctor Take AI’s Advice?",
    "collection": "science",
    "content": "Some doctors don’t trust a second opinion when it comes from an AI system.What’s new:A team at MIT and Regensburg Universityinvestigatedhow physicians responded to diagnostic advice they received from a machine learning model versus a human expert.How it works:The authors recruited doctors to diagnose chest X-rays.\n\nResults:The radiologists generally rated as lower-quality advice they believed was generated by AI. The others rated AI and human advice to be roughly of equal quality. Both groups made more accurate diagnoses when given accurate advice, regardless of its source. However, 27 percent of radiologists and 41 percent of the less experienced offered an incorrect diagnosis when given inaccurate advice.Behind the news:AI-powered diagnostic tools are proliferating and becoming more widely acceptedin the U.S.and elsewhere. These tools maywork about as well as traditional methodsat predicting clinical outcomes. Those that work wellmay only do so on certain populationsdue to biased training data.Why it matters:It’s not enough to develop AI systems in isolation. It’s important also to understand how humans use them. The best diagnostic algorithm in the world won’t help if people don’t heed its recommendations.We’re thinking:While some doctors are skeptical of AI, others may trust it too much, which also can lead to errors. Practitioners in a wide variety of fields will need to cultivate a balance between skepticism and trust in machine learning systems. We welcome help from the computer-human interface community in wrestling with these challenges.",
    "qa": [
      {
        "question": "Nghiên cứu của MIT và Đại học Regensburg tập trung vào điều gì?",
        "options": {
          "A": "So sánh hiệu quả của các mô hình học máy khác nhau trong chẩn đoán hình ảnh.",
          "B": "Đánh giá phản ứng của bác sĩ đối với lời khuyên chẩn đoán từ AI so với chuyên gia.",
          "C": "Xác định loại dữ liệu huấn luyện nào tạo ra kết quả chẩn đoán AI chính xác nhất.",
          "D": "Nghiên cứu tác động của AI đến thời gian chẩn đoán bệnh của bác sĩ."
        },
        "answer": "B"
      },
      {
        "question": "Theo nghiên cứu, các bác sĩ thường đánh giá lời khuyên từ AI như thế nào so với lời khuyên từ chuyên gia con người?",
        "options": {
          "A": "Cao hơn đáng kể về chất lượng.",
          "B": "Thấp hơn về chất lượng nếu họ tin rằng nó đến từ AI.",
          "C": "Tương đương về chất lượng, bất kể nguồn gốc.",
          "D": "Chỉ cao hơn khi chẩn đoán các bệnh hiếm gặp."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì xảy ra khi các bác sĩ nhận được lời khuyên không chính xác, bất kể nguồn gốc?",
        "options": {
          "A": "Họ luôn đưa ra chẩn đoán chính xác dựa trên kinh nghiệm của mình.",
          "B": "Họ có xu hướng tin tưởng vào lời khuyên và đưa ra chẩn đoán sai.",
          "C": "Họ thường tham khảo ý kiến của một chuyên gia khác trước khi đưa ra quyết định.",
          "D": "Họ bỏ qua lời khuyên và dựa vào kết quả xét nghiệm khác."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, một vấn đề tiềm ẩn với các công cụ chẩn đoán AI là gì?",
        "options": {
          "A": "Chúng quá đắt để triển khai rộng rãi.",
          "B": "Chúng có thể hoạt động không tốt bằng các phương pháp truyền thống.",
          "C": "Chúng có thể chỉ hoạt động tốt trên một số nhóm dân số nhất định do dữ liệu huấn luyện bị thiên vị.",
          "D": "Chúng yêu cầu bác sĩ phải có kiến thức chuyên sâu về lập trình."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao việc hiểu cách con người sử dụng hệ thống AI lại quan trọng?",
        "options": {
          "A": "Để đảm bảo rằng AI không thay thế hoàn toàn vai trò của bác sĩ.",
          "B": "Để tối ưu hóa hiệu suất của các thuật toán AI.",
          "C": "Vì thuật toán chẩn đoán tốt nhất cũng vô ích nếu mọi người không chú ý đến khuyến nghị của nó.",
          "D": "Để giảm chi phí phát triển và triển khai các hệ thống AI."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề xuất sự cân bằng nào cần thiết trong việc sử dụng hệ thống học máy?",
        "options": {
          "A": "Giữa tốc độ và độ chính xác.",
          "B": "Giữa chi phí và lợi ích.",
          "C": "Giữa sự hoài nghi và tin tưởng.",
          "D": "Giữa kiến thức chuyên môn và kinh nghiệm thực tế."
        },
        "answer": "C"
      },
      {
        "question": "Cộng đồng nào được bài viết mời tham gia giải quyết các thách thức liên quan đến việc sử dụng AI trong chẩn đoán?",
        "options": {
          "A": "Cộng đồng y tế công cộng.",
          "B": "Cộng đồng giao diện người-máy tính.",
          "C": "Cộng đồng phát triển phần mềm.",
          "D": "Cộng đồng nghiên cứu đạo đức AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì đang xảy ra với các công cụ chẩn đoán hỗ trợ bởi AI ở Mỹ và các nơi khác?",
        "options": {
          "A": "Chúng đang dần bị loại bỏ do thiếu chính xác.",
          "B": "Chúng đang ngày càng phổ biến và được chấp nhận rộng rãi hơn.",
          "C": "Chúng chỉ được sử dụng trong các thử nghiệm lâm sàng.",
          "D": "Chúng đang được thay thế bằng các phương pháp chẩn đoán truyền thống."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả nghiên cứu cho thấy sự khác biệt về độ chính xác chẩn đoán giữa bác sĩ có kinh nghiệm và ít kinh nghiệm khi nhận được lời khuyên sai từ AI là gì?",
        "options": {
          "A": "Bác sĩ có kinh nghiệm ít bị ảnh hưởng hơn bởi lời khuyên sai.",
          "B": "Bác sĩ ít kinh nghiệm ít bị ảnh hưởng hơn bởi lời khuyên sai.",
          "C": "Cả hai nhóm đều bị ảnh hưởng như nhau bởi lời khuyên sai.",
          "D": "Không có đủ dữ liệu để so sánh."
        },
        "answer": "A"
      },
      {
        "question": "Bài viết nhấn mạnh rằng việc phát triển hệ thống AI nên đi kèm với điều gì?",
        "options": {
          "A": "Việc đào tạo chuyên sâu cho các bác sĩ về cách sử dụng AI.",
          "B": "Việc hiểu cách con người sử dụng chúng.",
          "C": "Việc đảm bảo rằng dữ liệu huấn luyện là hoàn toàn không thiên vị.",
          "D": "Việc giảm chi phí phát triển và triển khai."
        },
        "answer": "B"
      }
    ]
  },
  "ai-creates-an-interactive-minecraft-like-world-in-real-time": {
    "title": "No Game Engine Required",
    "collection": "ml-research",
    "content": "A real-time video generator lets you explore an open-ended, interactive virtual world — a video game without a game engine.\n\nWhat’s new:Decart, a startup that’s building a platform for AI applications, and Etched, which designs specialized AI chips, introducedOasis, which generates a Minecraft-like game in real time. The weights are open and availablehere. You can play with a demohere.\n\nHow it works:The system generates one frame at a time based on a user’s keystrokes, mouse movements, and previously generated frames. The training dataset is undisclosed, but it’s almost certainly based on videos of Minecraft gameplay, given the output’s striking semblance to that game.\n\nResults:The Oasis web demo enables users to interact with 360-by-360-pixel frames at 20 frames per second. Users can place blocks, place fences, and move through a Minecraft-like world. The demo starts with an image of a location, but users can upload an image (turning, say, a photo of your cat into a blocky Minecraft-style level, asreportedbyWired).\n\nYes, but:The game has its fair share of issues. For instance, objects disappear and menus items change unaccountably. The world’s physics are similarly inconsistent. For instance, players don’t fall into holes dug directly beneath them and, after jumping into water, players are likely to find themselves standing on a blue floor.\n\nBehind the news:In February, Google announcedGenie, a model that generates two-dimensional platformer games from input images. We weren’t able to find a publicly available demo or model.\n\nWhy it matters:Oasis is more a proof of concept than a product. Nonetheless, as an open-world video game entirely generated by AI — albeit based on data produced by a traditional implementation — it sets a bar for future game generators.\n\nWe’re thinking:Real-time video generation suggests a wealth of potential applications — say, a virtual workspace for interior decorating that can see and generate your home, or an interactive car repair manual that can create custom clips based on your own vehicle. Oasis is an early step in this direction.",
    "qa": [
      {
        "question": "Oasis là sản phẩm của công ty nào?",
        "options": {
          "A": "Google và Etched",
          "B": "Decart và Etched",
          "C": "Google và Decart",
          "D": "Minecraft và Decart"
        },
        "answer": "B"
      },
      {
        "question": "Oasis tạo ra loại trò chơi nào?",
        "options": {
          "A": "Trò chơi platformer 2D",
          "B": "Trò chơi chiến thuật thời gian thực",
          "C": "Trò chơi thế giới mở tương tự Minecraft",
          "D": "Trò chơi giải đố 3D"
        },
        "answer": "C"
      },
      {
        "question": "Dữ liệu đầu vào chính của Oasis là gì?",
        "options": {
          "A": "Hình ảnh do người dùng tải lên",
          "B": "Video gameplay của Minecraft",
          "C": "Dữ liệu được thu thập từ các trò chơi khác",
          "D": "Dữ liệu được tạo ra bởi các thuật toán ngẫu nhiên"
        },
        "answer": "B"
      },
      {
        "question": "Người dùng có thể tương tác với Oasis thông qua những hành động nào?",
        "options": {
          "A": "Chỉ sử dụng chuột",
          "B": "Chỉ sử dụng bàn phím",
          "C": "Sử dụng bàn phím, chuột và hình ảnh tải lên",
          "D": "Sử dụng giọng nói và cử chỉ"
        },
        "answer": "C"
      },
      {
        "question": "Một trong những hạn chế của Oasis được đề cập trong bài viết là gì?",
        "options": {
          "A": "Đồ họa quá chân thực",
          "B": "Vật lý trong game không nhất quán",
          "C": "Yêu cầu cấu hình máy tính quá cao",
          "D": "Không có chế độ nhiều người chơi"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Genie của Google tạo ra loại trò chơi nào?",
        "options": {
          "A": "Trò chơi thế giới mở 3D",
          "B": "Trò chơi platformer 2D",
          "C": "Trò chơi thực tế ảo",
          "D": "Trò chơi mô phỏng"
        },
        "answer": "B"
      },
      {
        "question": "Điều gì khiến Oasis trở nên quan trọng mặc dù vẫn còn nhiều hạn chế?",
        "options": {
          "A": "Nó là một sản phẩm hoàn chỉnh có thể sử dụng ngay lập tức.",
          "B": "Nó là một bằng chứng về khả năng tạo ra trò chơi hoàn toàn bằng AI.",
          "C": "Nó có đồ họa đẹp mắt và gameplay mượt mà.",
          "D": "Nó được phát triển bởi một công ty công nghệ lớn."
        },
        "answer": "B"
      },
      {
        "question": "Tốc độ khung hình (frame rate) mà người dùng có thể trải nghiệm trong bản demo Oasis là bao nhiêu?",
        "options": {
          "A": "60 khung hình/giây",
          "B": "30 khung hình/giây",
          "C": "20 khung hình/giây",
          "D": "15 khung hình/giây"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề xuất ứng dụng tiềm năng nào của công nghệ tạo video thời gian thực?",
        "options": {
          "A": "Tạo ra các bộ phim hoạt hình chất lượng cao.",
          "B": "Tạo ra các công cụ chỉnh sửa ảnh chuyên nghiệp.",
          "C": "Tạo ra các hướng dẫn sửa chữa xe tương tác.",
          "D": "Tạo ra các trò chơi thực tế ảo phức tạp."
        },
        "answer": "C"
      },
      {
        "question": "Độ phân giải của khung hình (frame) trong bản demo Oasis là bao nhiêu?",
        "options": {
          "A": "1920x1080 pixel",
          "B": "1280x720 pixel",
          "C": "640x480 pixel",
          "D": "360x360 pixel"
        },
        "answer": "D"
      }
    ]
  },
  "a-sleeping-giant-stirs": {
    "title": "A Sleeping Giant Stirs",
    "collection": "business",
    "content": "Sony, the consumer-electronics powerhouse behind the PlayStation and other hit gadgets, is launching three research-and-design centers to focus on AI. Staffing up means competing with — and likely poaching talent from — frontrunners like Google, Facebook, and Microsoft.What’s new:The company next month will open AI offices in Tokyo, Austin, and a European city to be named. The company says it will hire local machine learning engineers. It hasn’t said how many it will employ.The plan:Hiroaki Kitano, president of Sony’s Computer Science Laboratories, will lead the effort. His vision encompasses three areas: Gaming, sensing and hardware, and — surprise! — gastronomy. Sony provided few details, but other news offers clues:\n\nBehind the news:Sony’s Computer Science Laboratories is known for its independence, secrecy, and freedom to pursue blue-sky projects. The division’s most notable product is Aibo, the AI-powered robot dog. It also did pioneering research inaugmented realityand developedvideo conferencing protocols.Why it matters:Sony invested in AI in the 1990s and early 2000s, but it sat out the deep learning revolution. With AI centers in the U.S. and Europe, the Japanese company likely will focus on consumer products and experiences while competing for talent with companies that dove into deep learning head-first.We’re thinking:Kitano has passion and clout, but he also has an awful lot on his plate. Outside of Sony, he’s the founding president of theRoboCup Federation, an international group of computer scientists aiming to win the 2050 World Cup with a team of robot soccer players. Meanwhile, he runs the nonprofitSystems Biology Instituteand holds aprofessorshipat the Okinawa Institute of Research and Technology.",
    "qa": [
      {
        "question": "Sony đang mở các trung tâm nghiên cứu và thiết kế AI với mục tiêu chính là gì?",
        "options": {
          "A": "Phát triển công nghệ AI cho quân sự.",
          "B": "Tập trung vào các sản phẩm điện tử tiêu dùng và trải nghiệm người dùng.",
          "C": "Nghiên cứu các ứng dụng AI trong lĩnh vực y tế.",
          "D": "Cạnh tranh trực tiếp với các công ty công nghệ hàng đầu trong mọi lĩnh vực AI."
        },
        "answer": "B"
      },
      {
        "question": "Ai là người đứng đầu nỗ lực phát triển AI của Sony?",
        "options": {
          "A": "Chủ tịch của Sony.",
          "B": "Hiroaki Kitano, chủ tịch của Sony’s Computer Science Laboratories.",
          "C": "Giám đốc điều hành của PlayStation.",
          "D": "Một kỹ sư trưởng giấu tên."
        },
        "answer": "B"
      },
      {
        "question": "Ba lĩnh vực chính mà Sony dự định tập trung vào trong lĩnh vực AI là gì?",
        "options": {
          "A": "Robot, y tế và giáo dục.",
          "B": "Gaming, cảm biến và phần cứng, và ẩm thực.",
          "C": "Xe tự lái, năng lượng tái tạo và tài chính.",
          "D": "Quốc phòng, an ninh mạng và truyền thông."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đặc biệt về Sony’s Computer Science Laboratories?",
        "options": {
          "A": "Nổi tiếng với việc hợp tác chặt chẽ với các trường đại học hàng đầu.",
          "B": "Được biết đến với sự độc lập, bí mật và tự do theo đuổi các dự án đột phá.",
          "C": "Chuyên về phát triển phần mềm mã nguồn mở.",
          "D": "Tập trung vào việc thương mại hóa các công nghệ hiện có."
        },
        "answer": "B"
      },
      {
        "question": "Sản phẩm nổi tiếng nhất của Sony’s Computer Science Laboratories là gì?",
        "options": {
          "A": "PlayStation.",
          "B": "Aibo, chú chó robot được trang bị AI.",
          "C": "Điện thoại thông minh Xperia.",
          "D": "Tivi Bravia."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao bài viết lại nhấn mạnh việc Sony đã 'bỏ lỡ cuộc cách mạng deep learning'?",
        "options": {
          "A": "Để chỉ trích Sony vì đã không đầu tư đủ vào AI.",
          "B": "Để giải thích lý do Sony cần phải cạnh tranh để thu hút nhân tài trong lĩnh vực AI.",
          "C": "Để chứng minh rằng Sony không có khả năng cạnh tranh trong lĩnh vực AI.",
          "D": "Để ca ngợi các công ty khác đã đi đầu trong lĩnh vực deep learning."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài Sony, Hiroaki Kitano còn đảm nhiệm những vai trò nào khác?",
        "options": {
          "A": "Chỉ là chủ tịch của Sony’s Computer Science Laboratories.",
          "B": "Chủ tịch sáng lập của RoboCup Federation, điều hành Systems Biology Institute và là giáo sư tại Okinawa Institute of Research and Technology.",
          "C": "Giám đốc điều hành của một công ty khởi nghiệp về AI.",
          "D": "Cố vấn cho chính phủ Nhật Bản về chính sách công nghệ."
        },
        "answer": "B"
      },
      {
        "question": "RoboCup Federation có mục tiêu gì?",
        "options": {
          "A": "Phát triển robot phục vụ trong ngành công nghiệp.",
          "B": "Giành chức vô địch World Cup 2050 với một đội bóng đá robot.",
          "C": "Nghiên cứu về trí tuệ nhân tạo tổng quát.",
          "D": "Tổ chức các cuộc thi robot trên toàn thế giới."
        },
        "answer": "B"
      },
      {
        "question": "Địa điểm nào KHÔNG được đề cập đến là nơi Sony sẽ mở trung tâm AI?",
        "options": {
          "A": "Tokyo.",
          "B": "Austin.",
          "C": "Berlin.",
          "D": "Một thành phố ở Châu Âu (không được nêu tên cụ thể)."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết ngụ ý gì về khả năng thành công của Sony trong lĩnh vực AI?",
        "options": {
          "A": "Sony chắc chắn sẽ thành công nhờ nguồn lực tài chính dồi dào.",
          "B": "Sony có thể gặp khó khăn do Hiroaki Kitano phải đảm nhiệm quá nhiều vai trò.",
          "C": "Sony sẽ dễ dàng vượt qua các đối thủ cạnh tranh nhờ kinh nghiệm lâu năm trong lĩnh vực điện tử.",
          "D": "Sony sẽ tập trung vào các lĩnh vực AI mà các công ty khác đã bỏ qua."
        },
        "answer": "B"
      }
    ]
  },
  "ai-chip-leaders-join-forces": {
    "title": "AI Chip Leaders Join Forces",
    "collection": "hardware",
    "content": "A major corporate acquisition could reshape the hardware that makes AI tick.What’s new:U.S. processor giant Nvidia, the world’s leading vendor of the graphics processing units (GPUs) that perform calculations for deep learning, struck a deal topurchaseUK chip designer Arm for $40 billion. The transaction faces regulatory approvals and other hurdles, but if it’s completed, it will be the biggest-ever acquisition in the chip industry and one of the biggest technology deals.Deal drivers:Nvidia’s technology undergirds much of the cloud infrastructure for AI workloads, while Arm’s technology drives inference in95 percent of smartphones.\n\nBehind the news:Nvidia developed GPUs to process high-resolution video game graphics in 1999. Nearly a decade later researchersrealizedtheir potential for training deep learning models. Since then, the company’s value has multipliedtenfold.Why it matters:By combining Arm’s energy efficiency with its growing presence in the cloud, Nvidia chips may be able to drive coming generations of multi-trillion parameter models.Yes, but:Mergers are difficult to pull off, and international tie-ups of this scale especially so. Whether Nvidia can take full advantage of its new possession may remain unclear for a long time. Meanwhile, Arm co-founder Hermann Hauser isurgingUK authorities to block the deal on the grounds that it would put Nvidia on the road to monopolizing the chip industry.We’re thinking:Data centers increasingly require both CPUs to process traditional workloads and GPUs to process deep learning (with help from a CPU). Data center operators would appreciate a vendor that can supply CPUs and GPUs that interoperate smoothly. That’s one reason why CPU producers like Intel and AMD are expanding into GPUs, and why Nvidia wants to buy Arm.",
    "qa": [
      {
        "question": "Công ty Nvidia dự kiến mua lại công ty Arm với giá trị bao nhiêu?",
        "options": {
          "A": "10 tỷ đô la",
          "B": "40 tỷ đô la",
          "C": "100 tỷ đô la",
          "D": "50 tỷ đô la"
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ của Arm hiện đang được sử dụng rộng rãi nhất trong lĩnh vực nào?",
        "options": {
          "A": "Máy tính cá nhân",
          "B": "Điện thoại thông minh",
          "C": "Trung tâm dữ liệu",
          "D": "Xe tự hành"
        },
        "answer": "B"
      },
      {
        "question": "Nvidia ban đầu phát triển GPU cho mục đích gì?",
        "options": {
          "A": "Tính toán khoa học",
          "B": "Đồ họa trò chơi điện tử",
          "C": "Khai thác tiền điện tử",
          "D": "Xử lý dữ liệu lớn"
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã khiến giá trị của Nvidia tăng gấp mười lần?",
        "options": {
          "A": "Sự phát triển của công nghệ CPU",
          "B": "Việc sử dụng GPU trong đào tạo mô hình học sâu",
          "C": "Sự gia tăng nhu cầu về điện thoại thông minh",
          "D": "Việc mở rộng sang thị trường xe tự hành"
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích tiềm năng nào mà Nvidia có thể đạt được khi kết hợp công nghệ của Arm?",
        "options": {
          "A": "Tăng cường khả năng xử lý dữ liệu lớn",
          "B": "Cải thiện hiệu suất năng lượng và mở rộng sự hiện diện trên đám mây",
          "C": "Giảm chi phí sản xuất chip",
          "D": "Thâm nhập thị trường máy tính cá nhân"
        },
        "answer": "B"
      },
      {
        "question": "Ai đang kêu gọi các nhà chức trách Anh ngăn chặn thương vụ mua lại Arm của Nvidia?",
        "options": {
          "A": "CEO của Intel",
          "B": "CEO của AMD",
          "C": "Đồng sáng lập của Arm, Hermann Hauser",
          "D": "Bộ trưởng Bộ Tài chính Anh"
        },
        "answer": "C"
      },
      {
        "question": "Lý do chính mà Hermann Hauser đưa ra để phản đối thương vụ này là gì?",
        "options": {
          "A": "Nvidia sẽ trở thành độc quyền trong ngành công nghiệp chip",
          "B": "Thương vụ sẽ làm giảm giá trị của Arm",
          "C": "Thương vụ sẽ gây ra tình trạng mất việc làm ở Anh",
          "D": "Thương vụ sẽ ảnh hưởng đến an ninh quốc gia"
        },
        "answer": "A"
      },
      {
        "question": "Xu hướng nào đang diễn ra trong các trung tâm dữ liệu liên quan đến CPU và GPU?",
        "options": {
          "A": "Chỉ sử dụng CPU để tiết kiệm chi phí",
          "B": "Chỉ sử dụng GPU để tăng hiệu suất",
          "C": "Yêu cầu cả CPU và GPU để xử lý các loại công việc khác nhau",
          "D": "Loại bỏ cả CPU và GPU để chuyển sang các công nghệ mới"
        },
        "answer": "C"
      },
      {
        "question": "Tại sao các nhà sản xuất CPU như Intel và AMD đang mở rộng sang lĩnh vực GPU?",
        "options": {
          "A": "Để giảm sự phụ thuộc vào Nvidia",
          "B": "Để đáp ứng nhu cầu ngày càng tăng về xử lý đồ họa",
          "C": "Để cung cấp các giải pháp tích hợp CPU và GPU cho trung tâm dữ liệu",
          "D": "Tất cả các đáp án trên"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì có thể cản trở việc Nvidia tận dụng tối đa việc mua lại Arm?",
        "options": {
          "A": "Sự cạnh tranh từ các công ty khác",
          "B": "Những khó khăn trong việc sáp nhập và các rào cản quốc tế",
          "C": "Sự thay đổi trong công nghệ chip",
          "D": "Sự thiếu hụt nhân tài"
        },
        "answer": "B"
      }
    ]
  },
  "ai-electricity-demands-spur-an-expansion-of-power-sources": {
    "title": "GPU Data Centers Strain Grid Power",
    "collection": "hardware",
    "content": "The AI boom is taxing power grids and pushing builders of data centers to rethink their sources of electricity.\n\nWhat’s new:New data centers packed with GPUs optimized for AI workloads are being approved at a record pace,The Informationreported. The extreme energy requirements of such chips are pushing builders to place data centers near inexpensive power sources, which may be far away from where users live.\n\nHow it works:The coming generation of GPU data centers promises to supply processing power for the burgeoning AI era. But builders aren’t always able to find electricity to run them.\n\nWhat they’re saying:“We still don’t appreciate the energy needs of [AI] technology. There's no way to get there without a breakthrough.” — Sam Altman, CEO, OpenAI, on January 16, 2024,quotedbyReuters.\n\nBehind the news:Data centers aloneaccount for1 to 1.5 percent of global demand for electricity. It’s unclear how much of that figure is attributable to AI, but the share is likely to grow.\n\nWhy it matters:The world needs innovation in both energy resources and power-efficient machine learning. The dawning era of pervasive AI brings with it the challenge of producing energy to develop and deploy the technology, which can contribute to pollution that disrupts ecosystems and accelerates climate change. Fortunately, AI can shrink the environmental footprint of some energy-intensive activities; for example, searching the web for information generates far less CO2emissions than driving to a library.\n\nWe’re thinking:Climate change is a slow-motion tragedy. We must push toward AI infrastructure that uses less energy (for example, by using more efficient algorithms or hardware) and emits less carbon (for example, by using renewable sources of energy). That said, concentrating computation in a data center creates a point of significant leverage for optimizing energy usage. For example, it’s more economical to raise the energy efficiency of 10,000 servers in a data center than 10,000 PCs that carry out the same workload in 10,000 homes.",
    "qa": [
      {
        "question": "Sự bùng nổ của AI đang gây ra tác động chính nào đối với lưới điện?",
        "options": {
          "A": "Làm giảm đáng kể nhu cầu sử dụng điện.",
          "B": "Gây áp lực lớn lên hệ thống cung cấp điện.",
          "C": "Giúp ổn định lưới điện nhờ khả năng dự báo nhu cầu.",
          "D": "Thúc đẩy việc sử dụng năng lượng tái tạo trong các hộ gia đình."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, các nhà xây dựng trung tâm dữ liệu đang xem xét điều gì để đáp ứng nhu cầu năng lượng của AI?",
        "options": {
          "A": "Giảm số lượng GPU sử dụng trong trung tâm dữ liệu.",
          "B": "Đặt trung tâm dữ liệu gần các nguồn năng lượng giá rẻ.",
          "C": "Tăng cường sử dụng năng lượng mặt trời trên mái nhà.",
          "D": "Hợp tác với các công ty điện lực để xây dựng nhà máy điện mới."
        },
        "answer": "B"
      },
      {
        "question": "Sam Altman, CEO của OpenAI, đã phát biểu gì về nhu cầu năng lượng của công nghệ AI?",
        "options": {
          "A": "Nhu cầu năng lượng của AI đã được đánh giá đầy đủ.",
          "B": "Cần có một bước đột phá để đáp ứng nhu cầu năng lượng của AI.",
          "C": "Năng lượng tái tạo là giải pháp duy nhất cho nhu cầu năng lượng của AI.",
          "D": "Nhu cầu năng lượng của AI không đáng lo ngại."
        },
        "answer": "B"
      },
      {
        "question": "Trung tâm dữ liệu chiếm bao nhiêu phần trăm nhu cầu điện toàn cầu?",
        "options": {
          "A": "Dưới 0.5%.",
          "B": "Từ 1 đến 1.5%.",
          "C": "Khoảng 5%.",
          "D": "Hơn 10%."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh tầm quan trọng của điều gì trong bối cảnh AI ngày càng phát triển?",
        "options": {
          "A": "Tăng cường đầu tư vào phần cứng AI mạnh mẽ hơn.",
          "B": "Đổi mới trong cả nguồn năng lượng và máy học tiết kiệm năng lượng.",
          "C": "Giảm thiểu việc sử dụng AI để bảo vệ môi trường.",
          "D": "Tập trung vào việc phát triển các ứng dụng AI thương mại."
        },
        "answer": "B"
      },
      {
        "question": "Một ví dụ được đưa ra trong bài viết về việc AI có thể giúp giảm tác động môi trường là gì?",
        "options": {
          "A": "Sản xuất điện sạch hơn.",
          "B": "Tìm kiếm thông tin trên web tạo ra ít CO2 hơn so với lái xe đến thư viện.",
          "C": "Giảm lượng khí thải từ các nhà máy sản xuất.",
          "D": "Tối ưu hóa việc sử dụng nước trong nông nghiệp."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất giải pháp nào để giảm lượng khí thải carbon từ cơ sở hạ tầng AI?",
        "options": {
          "A": "Sử dụng ít năng lượng hơn và phát thải ít carbon hơn.",
          "B": "Chuyển tất cả các trung tâm dữ liệu đến các vùng nông thôn.",
          "C": "Hạn chế sự phát triển của các ứng dụng AI.",
          "D": "Tăng cường sử dụng năng lượng hạt nhân."
        },
        "answer": "A"
      },
      {
        "question": "Việc tập trung tính toán trong một trung tâm dữ liệu mang lại lợi thế gì về mặt sử dụng năng lượng?",
        "options": {
          "A": "Giảm chi phí xây dựng trung tâm dữ liệu.",
          "B": "Dễ dàng tối ưu hóa việc sử dụng năng lượng hơn so với nhiều máy tính cá nhân.",
          "C": "Tăng tốc độ xử lý dữ liệu.",
          "D": "Giảm thiểu rủi ro an ninh mạng."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì sẽ xảy ra nếu không có sự đổi mới trong năng lượng và máy học tiết kiệm năng lượng?",
        "options": {
          "A": "Sự phát triển của AI sẽ bị đình trệ.",
          "B": "Ô nhiễm sẽ gia tăng, gây rối loạn hệ sinh thái và đẩy nhanh biến đổi khí hậu.",
          "C": "Chi phí phát triển AI sẽ tăng cao.",
          "D": "Các công ty công nghệ sẽ mất lợi thế cạnh tranh."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh rằng việc sử dụng các thuật toán hiệu quả hơn có thể giúp làm gì?",
        "options": {
          "A": "Tăng tốc độ xử lý của AI.",
          "B": "Giảm năng lượng tiêu thụ của cơ sở hạ tầng AI.",
          "C": "Cải thiện độ chính xác của các mô hình AI.",
          "D": "Giảm chi phí phát triển phần mềm AI."
        },
        "answer": "B"
      }
    ]
  },
  "all-about-nvidia-gpu-shortage": {
    "title": "GPU Shortage Intensifies",
    "collection": "hardware",
    "content": "Nvidia’s top-of-the-line chips are in high demand and short supply.\n\nWhat’s new:There aren’t enough H100 graphics processing units (GPUs) to meet the crush of demand brought on by the vogue for generative AI,VentureBeatreported.\n\nBottleneck:Cloud providers began havingtrouble finding GPUsearlier this year, but the shortfall has spread to AI companies large and small. SemiAnalysis, a semiconductor market research firm,estimatesthat the chip will remain sold out into 2024.\n\nWho’s buying:Demand for H100s is hard to quantify. Large AI companies and cloud providers may need tens of thousands to hundreds of thousands of them, while AI startups may need hundreds to thousands.\n\nBehind the news:Nvidiaannouncedthe H100 early last year and began full production in September. Compared to its predecessor, the A100, the H100 performs about 2.3 times faster in training and 3.5 times faster at inference.\n\nWhy it matters:Developers need these top-of-the-line chips to train high-performance models and deploy them in cutting-edge products. At a time when AI is white-hot, a dearth of chips could affect the pace of innovation.We’re thinking:Nvidia’s CUDA software, which undergirds many deep learning software packages, gives the company’s chips a significant advantage. However, AMD’s open source ROCm is making great strides, and its MI250 and upcoming MI300-series chips appear to be promising alternatives. An open software infrastructure that made it easy to choose among GPU providers would benefit the AI community.",
    "qa": [
      {
        "question": "Loại chip nào của Nvidia đang có nhu cầu cao nhưng nguồn cung hạn chế?",
        "options": {
          "A": "A100",
          "B": "H100",
          "C": "MI250",
          "D": "MI300"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, yếu tố nào đang thúc đẩy nhu cầu lớn đối với chip H100?",
        "options": {
          "A": "Sự phát triển của công nghệ thực tế ảo (VR)",
          "B": "Sự phổ biến của trí tuệ nhân tạo tạo sinh (generative AI)",
          "C": "Sự gia tăng của các ứng dụng blockchain",
          "D": "Sự phát triển của ngành công nghiệp game"
        },
        "answer": "B"
      },
      {
        "question": "Theo SemiAnalysis, tình trạng thiếu hụt chip H100 dự kiến sẽ kéo dài đến khi nào?",
        "options": {
          "A": "Cuối năm 2023",
          "B": "Đầu năm 2024",
          "C": "Giữa năm 2024",
          "D": "Hết năm 2024"
        },
        "answer": "D"
      },
      {
        "question": "So với chip A100, chip H100 có hiệu suất huấn luyện (training) nhanh hơn khoảng bao nhiêu lần?",
        "options": {
          "A": "1.5 lần",
          "B": "2.3 lần",
          "C": "3.5 lần",
          "D": "4.0 lần"
        },
        "answer": "B"
      },
      {
        "question": "So với chip A100, chip H100 có hiệu suất suy luận (inference) nhanh hơn khoảng bao nhiêu lần?",
        "options": {
          "A": "1.5 lần",
          "B": "2.3 lần",
          "C": "3.5 lần",
          "D": "4.0 lần"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì có thể bị ảnh hưởng bởi sự thiếu hụt chip H100?",
        "options": {
          "A": "Giá cổ phiếu của Nvidia",
          "B": "Tốc độ đổi mới trong lĩnh vực trí tuệ nhân tạo",
          "C": "Số lượng việc làm trong ngành công nghệ",
          "D": "Sự phát triển của các ứng dụng di động"
        },
        "answer": "B"
      },
      {
        "question": "Phần mềm nào của Nvidia mang lại lợi thế đáng kể cho chip của họ?",
        "options": {
          "A": "TensorFlow",
          "B": "PyTorch",
          "C": "CUDA",
          "D": "ROCm"
        },
        "answer": "C"
      },
      {
        "question": "ROCm là một nền tảng phần mềm mã nguồn mở của công ty nào?",
        "options": {
          "A": "Nvidia",
          "B": "Intel",
          "C": "AMD",
          "D": "Google"
        },
        "answer": "C"
      },
      {
        "question": "Dòng chip nào của AMD được đề cập đến như một giải pháp thay thế đầy hứa hẹn cho chip H100?",
        "options": {
          "A": "Ryzen",
          "B": "Threadripper",
          "C": "MI250 và MI300",
          "D": "Radeon"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì sẽ mang lại lợi ích cho cộng đồng AI?",
        "options": {
          "A": "Sự độc quyền của Nvidia trên thị trường chip",
          "B": "Một cơ sở hạ tầng phần mềm mở giúp dễ dàng lựa chọn giữa các nhà cung cấp GPU",
          "C": "Việc tăng cường kiểm soát của chính phủ đối với ngành công nghiệp AI",
          "D": "Sự phát triển của các thuật toán AI độc quyền"
        },
        "answer": "B"
      }
    ]
  },
  "ai-sales-closing-in-on-500-billion": {
    "title": "AI Sales Closing In on $500 Billion",
    "collection": "business",
    "content": "A new report projects a rosy future for the AI industry.What’s new:Astudyfrom market research firm IDC estimates that global revenues for AI software, hardware, and services will reach $341.8 billion in 2021 — up from anestimated$156.5 billion last year — and will break $500 billion by 2024. The study reflects interviews, distribution statistics, financial reports, and other data from over 700 AI companies around the world.What they found:The AI industry’s annual growth rate is expected to exceed 18.8 percent next year. The analysis breaks up that growth into three broad categories. Some of the most important findings:\n\nBehind the news:IDC’s most recent predictions are in line with theirprevious report, published in February, and jibe withresearch from MIT Technology Review.Why it matters:In the AI world — as in other high-tech sectors — it’s often difficult to discern real growth potential from gossip-fueled hype. Research reports that provide granular insights are a crucial tool for business leaders and investors who aim to capitalize on this industry, not to mention machine learning engineers who are plotting a career.We’re thinking:We’ve seen market research reports that later proved right and many that later proved dead wrong. We hope this is one of the former!",
    "qa": [
      {
        "question": "Theo báo cáo của IDC, doanh thu toàn cầu cho phần mềm, phần cứng và dịch vụ AI ước tính đạt bao nhiêu vào năm 2021?",
        "options": {
          "A": "$156.5 tỷ USD",
          "B": "$341.8 tỷ USD",
          "C": "$500 tỷ USD",
          "D": "$1 nghìn tỷ USD"
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu của IDC dựa trên những nguồn thông tin nào?",
        "options": {
          "A": "Chỉ phỏng vấn các công ty AI",
          "B": "Chỉ thống kê phân phối và báo cáo tài chính",
          "C": "Phỏng vấn, thống kê phân phối, báo cáo tài chính và dữ liệu từ hơn 700 công ty AI",
          "D": "Chỉ dữ liệu từ các báo cáo trước đó của IDC"
        },
        "answer": "C"
      },
      {
        "question": "Tốc độ tăng trưởng hàng năm dự kiến của ngành công nghiệp AI trong năm tới là bao nhiêu?",
        "options": {
          "A": "10%",
          "B": "15%",
          "C": "18.8%",
          "D": "25%"
        },
        "answer": "C"
      },
      {
        "question": "Báo cáo dự đoán doanh thu toàn cầu cho AI sẽ vượt mốc bao nhiêu vào năm 2024?",
        "options": {
          "A": "$341.8 tỷ USD",
          "B": "$400 tỷ USD",
          "C": "$450 tỷ USD",
          "D": "$500 tỷ USD"
        },
        "answer": "D"
      },
      {
        "question": "Báo cáo của IDC được so sánh với nghiên cứu từ tổ chức nào?",
        "options": {
          "A": "Harvard Business Review",
          "B": "MIT Technology Review",
          "C": "Stanford AI Lab",
          "D": "Google AI"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, tại sao các báo cáo nghiên cứu chi tiết lại quan trọng trong lĩnh vực AI?",
        "options": {
          "A": "Giúp các kỹ sư máy học tìm việc làm",
          "B": "Giúp phân biệt tiềm năng tăng trưởng thực tế với những tin đồn thổi phồng",
          "C": "Giúp các công ty AI quảng bá sản phẩm của họ",
          "D": "Giúp các nhà nghiên cứu AI công bố kết quả nghiên cứu của họ"
        },
        "answer": "B"
      },
      {
        "question": "Báo cáo gần đây nhất của IDC được công bố vào thời điểm nào?",
        "options": {
          "A": "Tháng 1",
          "B": "Tháng 2",
          "C": "Tháng 3",
          "D": "Tháng 4"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến việc các báo cáo nghiên cứu thị trường có thể...",
        "options": {
          "A": "Luôn chính xác",
          "B": "Luôn sai",
          "C": "Có thể đúng hoặc sai",
          "D": "Chỉ đúng trong lĩnh vực AI"
        },
        "answer": "C"
      },
      {
        "question": "Đối tượng nào có thể hưởng lợi từ các báo cáo nghiên cứu chi tiết về AI?",
        "options": {
          "A": "Chỉ các nhà đầu tư",
          "B": "Chỉ các lãnh đạo doanh nghiệp",
          "C": "Chỉ các kỹ sư máy học",
          "D": "Lãnh đạo doanh nghiệp, nhà đầu tư và kỹ sư máy học"
        },
        "answer": "D"
      },
      {
        "question": "Mục đích chính của bài viết là gì?",
        "options": {
          "A": "Quảng bá cho công ty nghiên cứu thị trường IDC",
          "B": "Phân tích chi tiết về các thuật toán AI mới nhất",
          "C": "Tóm tắt và đánh giá một báo cáo mới về ngành công nghiệp AI",
          "D": "Dự đoán tương lai của trí tuệ nhân tạo nói chung"
        },
        "answer": "C"
      }
    ]
  },
  "all-about-nvidias-new-blackwell-architecture-and-b200-gpu": {
    "title": "Nvidia Revs AI Engine",
    "collection": "hardware",
    "content": "Nvidia’s latest chip promises to boost AI’s speed and energy efficiency.\n\nWhat’s new:The market leader in AI chipsannouncedthe B100 and B200 graphics processing units (GPUs) designed to eclipse its in-demand H100 and H200 chips. The company will also offer systems that integrate two, eight, and 72 chips.\n\nHow it works:The new chips are based on Blackwell, an updated chip architecture specialized for training and inferencing transformer models. Compared to Nvidia’s earlier Hopper architecture, used by H-series chips, Blackwell features hardware and firmware upgrades intended to cut the energy required for model training and inference.\n\nPrice and availability:The B200 will cost between $30,000 and $40,000, similar to thegoing ratefor H100s today, Nvidia CEO Jensen HuangtoldCNBC. Nvidia did not specify when the chip would be available. Google, Amazon, and Microsoftstatedintentions to offer Blackwell GPUs to their cloud customers.\n\nBehind the news:Demand for the H100 chip has been so intense that the chip has beendifficultto find, driving some users to adopt alternatives such as AMD’s MI300X. Moreover, in 2022, the U.S.restrictedthe export of H100s and other advanced chips to China. The B200 also falls under the ban.Why it matters:Nvidiaholdsabout 80 percent of the market for specialized AI chips. The new chips are primed to enable developers to continue pushing AI’s boundaries, training multi-trillion-parameter models and running more instances at once.We’re thinking:Cathie Wood, author of ARK Invest’s “Big Ideas 2024”report, estimated that training costs are falling at a very rapid 75 percent annually, around half due to algorithmic improvements and half due to compute hardware improvements. Nvidia’s progress paints an optimistic picture of further gains. It also signals the difficulty of trying to use model training to build a moat around a business. It’s not easy to maintain a lead if you spend $100 million on training and next year a competitor can replicate the effort for $25 million.",
    "qa": [
      {
        "question": "Chip B100 và B200 của Nvidia được thiết kế để thay thế loại chip nào?",
        "options": {
          "A": "MI300X",
          "B": "H100 và H200",
          "C": "A100 và A200",
          "D": "V100 và V200"
        },
        "answer": "B"
      },
      {
        "question": "Kiến trúc chip mới của Nvidia, Blackwell, được tối ưu hóa cho tác vụ nào?",
        "options": {
          "A": "Xử lý đồ họa game",
          "B": "Khai thác tiền điện tử",
          "C": "Huấn luyện và suy luận mô hình transformer",
          "D": "Mô phỏng vật lý"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, giá dự kiến của chip B200 là bao nhiêu?",
        "options": {
          "A": "Từ $10,000 đến $20,000",
          "B": "Từ $30,000 đến $40,000",
          "C": "Từ $50,000 đến $60,000",
          "D": "Từ $70,000 đến $80,000"
        },
        "answer": "B"
      },
      {
        "question": "Những công ty nào được đề cập trong bài viết có ý định cung cấp GPU Blackwell cho khách hàng đám mây của họ?",
        "options": {
          "A": "Google, Amazon và Tesla",
          "B": "Microsoft, Apple và Google",
          "C": "Amazon, Microsoft và Google",
          "D": "Tesla, Apple và Microsoft"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì đã thúc đẩy một số người dùng tìm đến các giải pháp thay thế cho chip H100?",
        "options": {
          "A": "Giá thành của H100 quá cao.",
          "B": "H100 không tương thích với phần mềm của họ.",
          "C": "H100 khó tìm mua do nhu cầu cao.",
          "D": "H100 tiêu thụ quá nhiều năng lượng."
        },
        "answer": "C"
      },
      {
        "question": "Chính phủ Hoa Kỳ đã hạn chế xuất khẩu chip H100 và B200 sang quốc gia nào?",
        "options": {
          "A": "Nga",
          "B": "Trung Quốc",
          "C": "Iran",
          "D": "Bắc Triều Tiên"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, Nvidia hiện nắm giữ khoảng bao nhiêu phần trăm thị phần chip AI chuyên dụng?",
        "options": {
          "A": "50%",
          "B": "60%",
          "C": "70%",
          "D": "80%"
        },
        "answer": "D"
      },
      {
        "question": "Cathie Wood ước tính chi phí huấn luyện mô hình AI giảm bao nhiêu phần trăm mỗi năm?",
        "options": {
          "A": "25%",
          "B": "50%",
          "C": "75%",
          "D": "90%"
        },
        "answer": "C"
      },
      {
        "question": "Theo Cathie Wood, yếu tố nào đóng góp vào việc giảm chi phí huấn luyện mô hình AI?",
        "options": {
          "A": "Chỉ cải tiến thuật toán",
          "B": "Chỉ cải tiến phần cứng máy tính",
          "C": "Cả cải tiến thuật toán và phần cứng máy tính",
          "D": "Chỉ giảm giá điện"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết ngụ ý gì về việc sử dụng huấn luyện mô hình để xây dựng lợi thế cạnh tranh bền vững?",
        "options": {
          "A": "Rất dễ để duy trì lợi thế cạnh tranh nếu đầu tư mạnh vào huấn luyện.",
          "B": "Việc huấn luyện mô hình là cách duy nhất để tạo ra lợi thế cạnh tranh.",
          "C": "Rất khó để duy trì lợi thế cạnh tranh vì chi phí huấn luyện đang giảm nhanh chóng.",
          "D": "Lợi thế cạnh tranh từ huấn luyện mô hình sẽ kéo dài ít nhất 5 năm."
        },
        "answer": "C"
      }
    ]
  },
  "amazon-google-and-microsoft-bet-on-nuclear-power-to-meet-ai-energy-demands": {
    "title": "AI Giants Go Nuclear",
    "collection": "hardware",
    "content": "Major AI companies plan to meet the growing demand with nuclear energy.\n\nWhat’s new:Amazon, Google, and Microsoftannouncedsubstantial investments in nuclear power projects. Amazon and Google forged partnerships to build a new generation of small reactors, while Microsoft cut a deal to revive a shuttered nuclear plant. (Andrew Ng is a member of Amazon’s board of directors.)\n\nHow it works:Nuclear powerprovidesaround 18 percent of electricity in the United States and more in France and several other European countries. Its steady generating capacity and zero carbon emissions (after plant construction) make it an attractive way to power AI infrastructure. However, new nuclear plants have been difficult to build in the U.S. since a string of high-profile accidents at Three Mile Island in the U.S. (1979), Chernobyl in Ukraine (1986), and Fukishima in Japan (2011). Since then, pressure to reduce carbon emissions has driven calls to build new plants. In March, President Bidensignedlegislation that streamlines construction and regulation of nuclear plants.\n\nBehind the news:The tech industry’s growing interest in nuclear power is driven by surging demand for AI and corporate commitments to reduce carbon emissions. Data centers that train and run AI models consume vast amounts of electricity, and nuclear energy offers a reliable, carbon-free source. Microsoft, Nvidia, and OpenAI haveurgedthe White House to deliver a so-called “energy New Deal” that would allocate hundreds of billions of dollars to subsidize new power plants.\n\nWhy it matters:The fact that tech giants are investing directly in nuclear power plants indicates the high stakes of competition in AI. Economistsestimatethat data centers that process AI, among other workloads, will consume more than 1,000 terawatt-hours of electricity by 2026, more than double the amount they consumed in 2022. Nuclear power could give them bountiful, carbon-free energy for decades to come.\n\nWe’re thinking:Fossil fuels like coal do tremendous damage to the environment, while renewables like solar and wind energy can’t fully meet the always-on demands of AI infrastructure. Next-generation reactor designs that improve safety and reduce costs are worth exploring. However, a significant obstacle remains: Few countries have a certifiably safe repository for long-term disposal of highly radioactive spent fuel. U.S. efforts toward this goal arestalled.",
    "qa": [
      {
        "question": "Các công ty công nghệ lớn như Amazon, Google và Microsoft đang đầu tư vào năng lượng hạt nhân vì lý do chính nào?",
        "options": {
          "A": "Để đa dạng hóa danh mục đầu tư của họ.",
          "B": "Để đáp ứng nhu cầu năng lượng ngày càng tăng của AI và giảm lượng khí thải carbon.",
          "C": "Để cạnh tranh với các công ty năng lượng truyền thống.",
          "D": "Do chính phủ yêu cầu các công ty công nghệ phải sử dụng năng lượng hạt nhân."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, năng lượng hạt nhân đóng góp khoảng bao nhiêu phần trăm vào tổng sản lượng điện của Hoa Kỳ?",
        "options": {
          "A": "Khoảng 5 phần trăm.",
          "B": "Khoảng 18 phần trăm.",
          "C": "Khoảng 35 phần trăm.",
          "D": "Khoảng 50 phần trăm."
        },
        "answer": "B"
      },
      {
        "question": "Sự kiện nào trong lịch sử đã gây khó khăn cho việc xây dựng các nhà máy điện hạt nhân mới ở Hoa Kỳ?",
        "options": {
          "A": "Chiến tranh Việt Nam.",
          "B": "Khủng hoảng kinh tế năm 2008.",
          "C": "Một loạt các tai nạn hạt nhân nghiêm trọng như Three Mile Island, Chernobyl và Fukushima.",
          "D": "Sự phát triển của năng lượng tái tạo."
        },
        "answer": "C"
      },
      {
        "question": "Tổng thống Biden đã ký đạo luật nào liên quan đến năng lượng hạt nhân?",
        "options": {
          "A": "Đạo luật cấm xây dựng nhà máy điện hạt nhân mới.",
          "B": "Đạo luật khuyến khích sử dụng năng lượng mặt trời.",
          "C": "Đạo luật đơn giản hóa việc xây dựng và quy định các nhà máy điện hạt nhân.",
          "D": "Đạo luật tăng thuế đối với các công ty năng lượng hạt nhân."
        },
        "answer": "C"
      },
      {
        "question": "Microsoft, Nvidia và OpenAI đã kêu gọi Nhà Trắng thực hiện điều gì liên quan đến năng lượng?",
        "options": {
          "A": "Giảm thuế cho các công ty năng lượng tái tạo.",
          "B": "Tăng cường nghiên cứu về năng lượng mặt trời.",
          "C": "Phân bổ hàng trăm tỷ đô la để trợ cấp cho các nhà máy điện mới, một 'Thỏa thuận năng lượng mới'.",
          "D": "Cấm sử dụng năng lượng hóa thạch."
        },
        "answer": "C"
      },
      {
        "question": "Theo ước tính của các nhà kinh tế, các trung tâm dữ liệu xử lý AI sẽ tiêu thụ bao nhiêu điện vào năm 2026?",
        "options": {
          "A": "Ít hơn 500 terawatt-giờ.",
          "B": "Khoảng 750 terawatt-giờ.",
          "C": "Hơn 1,000 terawatt-giờ.",
          "D": "Khoảng 2,000 terawatt-giờ."
        },
        "answer": "C"
      },
      {
        "question": "Loại nhiên liệu hóa thạch nào được đề cập trong bài viết là gây tổn hại lớn cho môi trường?",
        "options": {
          "A": "Khí đốt tự nhiên.",
          "B": "Dầu mỏ.",
          "C": "Than đá.",
          "D": "Dầu đá phiến."
        },
        "answer": "C"
      },
      {
        "question": "Một trong những thách thức lớn nhất còn tồn tại đối với năng lượng hạt nhân là gì?",
        "options": {
          "A": "Chi phí xây dựng nhà máy quá cao.",
          "B": "Nguồn cung uranium hạn chế.",
          "C": "Thiếu các biện pháp an toàn hiệu quả.",
          "D": "Thiếu một kho lưu trữ an toàn được chứng nhận cho việc xử lý lâu dài nhiên liệu đã qua sử dụng có tính phóng xạ cao."
        },
        "answer": "D"
      },
      {
        "question": "Ai là thành viên hội đồng quản trị của Amazon, được đề cập trong bài viết?",
        "options": {
          "A": "Bill Gates.",
          "B": "Elon Musk.",
          "C": "Andrew Ng.",
          "D": "Satya Nadella."
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích chính của năng lượng hạt nhân so với năng lượng tái tạo như năng lượng mặt trời và gió là gì?",
        "options": {
          "A": "Chi phí sản xuất rẻ hơn.",
          "B": "Ít gây ô nhiễm tiếng ồn hơn.",
          "C": "Khả năng đáp ứng nhu cầu năng lượng liên tục của cơ sở hạ tầng AI.",
          "D": "Dễ dàng xây dựng và bảo trì hơn."
        },
        "answer": "C"
      }
    ]
  },
  "andromeda-supercomputer-from-cerebras-speeds-up-ai": {
    "title": "Built to Scale",
    "collection": "hardware",
    "content": "A new computing cluster delivers more bang per chip.\n\nWhat’s new:Cerebras, one of several startups vying to supply the market for specialized AI chips,unveiledAndromeda, a supercomputer based on its processors. Unlike conventional clusters, which incur data bottlenecks as processors are added, the system’s processing speed rises linearly with additional processors.How it works:Andromeda comprises 16 CerebrasCS-2 Wafer Scale Enginechips. Each chip holds 850,000 processing cores (more than 100 times the number found on anNvidia A100) on a silicon disc that measures 21.5 centimeters across.\n\nSpeed tests:Scientists at Argonne National Laboratory used the system totrainGenSLM language models in several sizes. Increasing the number of processors from one to four boosted throughput nearly linearly while training models of 123 million parameters and 1.3 billion parameters. Going from one to four chips also cut the smaller model’s training time from 4.1 to 2.4 hours and cut the larger model’s training time to 15.6 to 10.4 hours.\n\nBehind the news:As interest rates rise, AI chip startups are facing headwinds in raising enough capital to support their often huge expenses.\n\nWhy it matters:Neural networkshavebreachedthe 1 trillion-parameters mark, and numbers one or two orders of magnitude greater may be close at hand. More efficient compute clusters could train those models more quickly and consume less energy doing it.We’re thinking:For most current machine learning models, the usual GPUs should be fine. Cerebras specializes in models and compute loads too large for a handful of GPUs in a single server — an interesting business as model sizes balloon.",
    "qa": [
      {
        "question": "Hệ thống Andromeda được phát triển bởi công ty nào?",
        "options": {
          "A": "Nvidia",
          "B": "Cerebras",
          "C": "Argonne National Laboratory",
          "D": "Google"
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính của Andromeda so với các cụm máy tính thông thường là gì?",
        "options": {
          "A": "Sử dụng ít năng lượng hơn",
          "B": "Tốc độ xử lý tăng tuyến tính khi thêm bộ xử lý",
          "C": "Giá thành rẻ hơn",
          "D": "Dễ dàng nâng cấp hơn"
        },
        "answer": "B"
      },
      {
        "question": "Mỗi chip Cerebras CS-2 Wafer Scale Engine chứa bao nhiêu lõi xử lý?",
        "options": {
          "A": "85,000",
          "B": "850,000",
          "C": "8,500,000",
          "D": "85,000,000"
        },
        "answer": "B"
      },
      {
        "question": "Trong các thử nghiệm tại Argonne National Laboratory, hệ thống Andromeda được sử dụng để huấn luyện loại mô hình nào?",
        "options": {
          "A": "Mô hình nhận diện ảnh",
          "B": "Mô hình ngôn ngữ GenSLM",
          "C": "Mô hình dự báo thời tiết",
          "D": "Mô hình phân tích dữ liệu tài chính"
        },
        "answer": "B"
      },
      {
        "question": "Việc tăng số lượng chip từ một lên bốn đã ảnh hưởng như thế nào đến thời gian huấn luyện mô hình 1.3 tỷ tham số?",
        "options": {
          "A": "Tăng từ 10.4 giờ lên 15.6 giờ",
          "B": "Giảm từ 15.6 giờ xuống 10.4 giờ",
          "C": "Không thay đổi",
          "D": "Giảm xuống còn 5.2 giờ"
        },
        "answer": "B"
      },
      {
        "question": "Một trong những thách thức mà các công ty khởi nghiệp về chip AI đang đối mặt là gì?",
        "options": {
          "A": "Thiếu hụt nhân tài",
          "B": "Khó khăn trong việc huy động vốn",
          "C": "Công nghệ chưa đủ phát triển",
          "D": "Cạnh tranh từ các công ty lớn"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến ngưỡng tham số của mạng nơ-ron đã vượt qua là bao nhiêu?",
        "options": {
          "A": "1 triệu",
          "B": "1 tỷ",
          "C": "1 nghìn tỷ",
          "D": "1 triệu tỷ"
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích tiềm năng của các cụm máy tính hiệu quả hơn là gì?",
        "options": {
          "A": "Huấn luyện mô hình nhanh hơn và tiêu thụ ít năng lượng hơn",
          "B": "Giảm chi phí sản xuất chip",
          "C": "Tăng độ chính xác của mô hình",
          "D": "Đơn giản hóa quá trình triển khai mô hình"
        },
        "answer": "A"
      },
      {
        "question": "Theo bài viết, GPU thông thường phù hợp với loại mô hình học máy nào?",
        "options": {
          "A": "Mô hình có kích thước quá lớn cho một vài GPU trong một máy chủ",
          "B": "Mô hình có kích thước vừa phải",
          "C": "Mô hình yêu cầu độ chính xác cao",
          "D": "Mô hình cần xử lý thời gian thực"
        },
        "answer": "B"
      },
      {
        "question": "Đường kính của đĩa silicon chứa chip Cerebras CS-2 là bao nhiêu?",
        "options": {
          "A": "2.15 cm",
          "B": "21.5 cm",
          "C": "215 cm",
          "D": "215 mm"
        },
        "answer": "B"
      }
    ]
  },
  "built-for-speed": {
    "title": "Built for Speed",
    "collection": "hardware",
    "content": "Chips specially designed for AI are becoming much faster at training neural networks, judging from recent trials.What’s new:MLPerf, an organization that’s developing standards for hardware performance in machine learning tasks, releasedresultsfrom its third benchmark competition. Nvidia’s latest products led the pack, but Google’s forthcoming hardware surpassed Nvidia’s scores.Start your engines:MLPerf measures how long it takes various hardware configurations to train particular machine learningmodels. Tasks include object detection, image classification, language translation, recommendation, and reinforcement learning goals.\n\nBehind the news:Nvidia’s GPUs have long been the premier machine learning chips, thanks to their ability to process large volumes of floating point integers per second. But startups including Cerebras, Graphcore, and Habana (acquired by Intel in December) are vying for that position, and Google Cloud is making a strong play for AI workloads.Why it matters:It’s good to be past the era ofMythbusters videosas a way to compare AI hardware. Machine learning engineers benefit from faster, more energy-efficient hardware systems, but we need clear, consistent metrics like MLPerf to evaluate hardware performance with particular models.We’re thinking:Since MLPerf’s first tests two years ago, the time required to train some models has plummeted from hours to seconds. Clearly semiconductor companies have been chipping away at the problem.",
    "qa": [
      {
        "question": "Tổ chức nào đang phát triển các tiêu chuẩn để đánh giá hiệu suất phần cứng trong các tác vụ học máy?",
        "options": {
          "A": "Nvidia",
          "B": "MLPerf",
          "C": "Google Cloud",
          "D": "Intel"
        },
        "answer": "B"
      },
      {
        "question": "Trong cuộc thi đánh giá hiệu suất phần cứng học máy gần đây nhất, sản phẩm của công ty nào đã vượt qua Nvidia?",
        "options": {
          "A": "Cerebras",
          "B": "Graphcore",
          "C": "Habana",
          "D": "Google"
        },
        "answer": "D"
      },
      {
        "question": "MLPerf đo lường điều gì trong các cấu hình phần cứng khác nhau?",
        "options": {
          "A": "Số lượng phép toán dấu phẩy động mà phần cứng có thể thực hiện mỗi giây.",
          "B": "Thời gian cần thiết để đào tạo các mô hình học máy cụ thể.",
          "C": "Mức tiêu thụ năng lượng của phần cứng trong quá trình đào tạo.",
          "D": "Kích thước của bộ nhớ mà phần cứng có thể truy cập."
        },
        "answer": "B"
      },
      {
        "question": "GPU của Nvidia nổi tiếng trong lĩnh vực học máy nhờ khả năng gì?",
        "options": {
          "A": "Xử lý lượng lớn số nguyên dấu phẩy động mỗi giây.",
          "B": "Tích hợp các thuật toán học máy tiên tiến nhất.",
          "C": "Tiêu thụ năng lượng thấp hơn so với các đối thủ cạnh tranh.",
          "D": "Khả năng tương thích với nhiều loại mô hình học máy."
        },
        "answer": "A"
      },
      {
        "question": "Công ty nào đã mua lại Habana vào tháng 12?",
        "options": {
          "A": "Nvidia",
          "B": "Google",
          "C": "Intel",
          "D": "Cerebras"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến lợi ích chính của việc có các số liệu đánh giá phần cứng học máy rõ ràng và nhất quán như MLPerf là gì?",
        "options": {
          "A": "Giúp giảm chi phí phát triển phần cứng.",
          "B": "Giúp các kỹ sư học máy đánh giá hiệu suất phần cứng với các mô hình cụ thể.",
          "C": "Tăng cường cạnh tranh giữa các nhà sản xuất phần cứng.",
          "D": "Đơn giản hóa quá trình lựa chọn phần cứng cho các ứng dụng học máy."
        },
        "answer": "B"
      },
      {
        "question": "Trước khi có các tiêu chuẩn như MLPerf, việc so sánh phần cứng AI thường được thực hiện bằng cách nào?",
        "options": {
          "A": "Thông qua các bài báo khoa học được bình duyệt.",
          "B": "Thông qua các video kiểu Mythbusters.",
          "C": "Thông qua các thử nghiệm nội bộ của các công ty.",
          "D": "Thông qua các cuộc khảo sát người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, thời gian cần thiết để đào tạo một số mô hình học máy đã giảm đáng kể như thế nào kể từ các thử nghiệm đầu tiên của MLPerf?",
        "options": {
          "A": "Từ ngày xuống giờ.",
          "B": "Từ giờ xuống phút.",
          "C": "Từ phút xuống giây.",
          "D": "Từ giờ xuống giây."
        },
        "answer": "D"
      },
      {
        "question": "Các tác vụ nào được sử dụng để đo hiệu suất phần cứng trong MLPerf?",
        "options": {
          "A": "Dự báo thời tiết, phân tích thị trường chứng khoán, và dịch thuật văn bản.",
          "B": "Phát hiện đối tượng, phân loại hình ảnh, dịch ngôn ngữ, đề xuất và học tăng cường.",
          "C": "Thiết kế chip, sản xuất phần mềm, và kiểm tra phần cứng.",
          "D": "Phân tích dữ liệu tài chính, quản lý chuỗi cung ứng, và tự động hóa quy trình sản xuất."
        },
        "answer": "B"
      },
      {
        "question": "Cụm từ 'chipping away at the problem' trong bài viết ám chỉ điều gì?",
        "options": {
          "A": "Các công ty bán dẫn đang tập trung vào việc sản xuất chip nhỏ hơn.",
          "B": "Các công ty bán dẫn đang dần dần cải thiện hiệu suất của chip AI.",
          "C": "Các công ty bán dẫn đang cạnh tranh gay gắt để giành thị phần.",
          "D": "Các công ty bán dẫn đang gặp khó khăn trong việc giải quyết các vấn đề kỹ thuật."
        },
        "answer": "B"
      }
    ]
  },
  "chips-at-risk": {
    "title": "Chips at Risk",
    "collection": "hardware",
    "content": "The hardware that runs the latest AI systems faces rising uncertainty as models grow larger and more computationally intensive.What’s new:The U.S. Commerce Department sounded an alarm over bottlenecks in the availability of semiconductor chips, the integrated circuits at the heart of virtually all digital devices. The supply of advanced microprocessors that drive cutting-edge AI is vulnerable,The New York Timesreported.How it works:Geopolitical tensions, rising costs, and supply-chain disruptions threaten the supply of AI chips.\n\nWhy it matters:So far, the post-pandemic semiconductor shortage mostly has affected chips that rely on older manufacturing methods, such as those used in automobiles, medical devices, radio-frequency identification, and optical sensors. As AI grows ever more hungry for processing power, a sustained shortage of advanced chips could be a significant barrier to progress in the field and beyond.We’re thinking: International cooperation generally fosters prosperity. In AI, it's essential to progress.",
    "qa": [
      {
        "question": "Theo bài viết, điều gì đang gây ra sự bất ổn cho phần cứng chạy các hệ thống AI mới nhất?",
        "options": {
          "A": "Sự lỗi thời của các thuật toán AI.",
          "B": "Sự tăng trưởng về quy mô và yêu cầu tính toán của các mô hình AI.",
          "C": "Sự thiếu hụt về nhân lực có trình độ cao trong lĩnh vực AI.",
          "D": "Sự cạnh tranh gay gắt giữa các công ty công nghệ."
        },
        "answer": "B"
      },
      {
        "question": "Cơ quan nào của Hoa Kỳ đã lên tiếng cảnh báo về tình trạng tắc nghẽn trong việc cung cấp chip bán dẫn?",
        "options": {
          "A": "Bộ Quốc phòng Hoa Kỳ.",
          "B": "Bộ Thương mại Hoa Kỳ.",
          "C": "Bộ Năng lượng Hoa Kỳ.",
          "D": "Bộ Tài chính Hoa Kỳ."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về nguồn cung của các vi xử lý tiên tiến dùng cho AI?",
        "options": {
          "A": "Nguồn cung đang dồi dào và đáp ứng đủ nhu cầu.",
          "B": "Nguồn cung đang ổn định nhờ các chính sách hỗ trợ của chính phủ.",
          "C": "Nguồn cung đang dễ bị tổn thương.",
          "D": "Nguồn cung đang được kiểm soát chặt chẽ bởi các tập đoàn lớn."
        },
        "answer": "C"
      },
      {
        "question": "Những yếu tố nào được đề cập đến là mối đe dọa đối với nguồn cung chip AI?",
        "options": {
          "A": "Chiến tranh thương mại, biến đổi khí hậu và sự phát triển của công nghệ lượng tử.",
          "B": "Căng thẳng địa chính trị, chi phí gia tăng và gián đoạn chuỗi cung ứng.",
          "C": "Sự cạnh tranh không lành mạnh, thiếu hụt nguyên liệu thô và sự xâm nhập của tin tặc.",
          "D": "Sự độc quyền của các công ty sản xuất chip, chính sách thuế bất lợi và sự thiếu hụt năng lượng."
        },
        "answer": "B"
      },
      {
        "question": "Sự thiếu hụt chip bán dẫn sau đại dịch chủ yếu ảnh hưởng đến loại chip nào?",
        "options": {
          "A": "Chip sử dụng công nghệ sản xuất tiên tiến nhất.",
          "B": "Chip sử dụng công nghệ sản xuất cũ hơn.",
          "C": "Chip được sử dụng trong điện thoại thông minh.",
          "D": "Chip được sử dụng trong máy tính cá nhân."
        },
        "answer": "B"
      },
      {
        "question": "Những lĩnh vực nào được nêu tên chịu ảnh hưởng bởi sự thiếu hụt chip sử dụng công nghệ sản xuất cũ?",
        "options": {
          "A": "Điện thoại thông minh, máy tính bảng và thiết bị đeo thông minh.",
          "B": "Ô tô, thiết bị y tế, nhận dạng tần số vô tuyến và cảm biến quang học.",
          "C": "Máy chủ, trung tâm dữ liệu và hệ thống lưu trữ đám mây.",
          "D": "Thiết bị quân sự, hệ thống vũ khí và công nghệ hàng không vũ trụ."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì có thể xảy ra nếu tình trạng thiếu chip tiên tiến kéo dài khi AI ngày càng đòi hỏi nhiều sức mạnh xử lý?",
        "options": {
          "A": "Sự phát triển của AI sẽ được thúc đẩy mạnh mẽ hơn.",
          "B": "Sự phát triển của AI có thể gặp phải rào cản đáng kể.",
          "C": "Các công ty sẽ chuyển sang sử dụng các thuật toán AI ít tốn kém hơn.",
          "D": "Giá thành của các sản phẩm AI sẽ giảm đáng kể."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, hợp tác quốc tế có vai trò như thế nào trong lĩnh vực AI?",
        "options": {
          "A": "Không quan trọng vì các quốc gia có thể tự phát triển AI.",
          "B": "Chỉ quan trọng đối với các quốc gia đang phát triển.",
          "C": "Thường thúc đẩy sự thịnh vượng và đặc biệt cần thiết cho sự tiến bộ của AI.",
          "D": "Chỉ cần thiết trong việc chia sẻ dữ liệu, không cần thiết trong phát triển phần cứng."
        },
        "answer": "C"
      },
      {
        "question": "Theo New York Times, điều gì đang gây ra sự bất ổn cho nguồn cung chip AI?",
        "options": {
          "A": "Sự cạnh tranh giữa các nhà sản xuất chip.",
          "B": "Sự thiếu hụt nguyên liệu thô.",
          "C": "Nguồn cung của các vi xử lý tiên tiến dễ bị tổn thương.",
          "D": "Sự phát triển của các công nghệ thay thế."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết ngụ ý điều gì về tầm quan trọng của chip bán dẫn?",
        "options": {
          "A": "Chip bán dẫn chỉ quan trọng đối với các thiết bị điện tử tiêu dùng.",
          "B": "Chip bán dẫn là trung tâm của hầu hết mọi thiết bị kỹ thuật số.",
          "C": "Chip bán dẫn đang dần được thay thế bởi các công nghệ mới.",
          "D": "Chip bán dẫn chỉ quan trọng đối với các ứng dụng AI."
        },
        "answer": "B"
      }
    ]
  },
  "compact-ai-models-redefine-efficiency-bringing-advanced-capabilities-to-everyday-devices": {
    "title": "Smaller Is Beautiful",
    "collection": "ml-research",
    "content": "For years, the best AI models got bigger and bigger. But in 2024, some popular large language models were small enough to run on a smartphone.\n\nWhat happened: Instead of putting all their resources into building big models, top AI companies promoted families of large language models that offer a choice of small, medium, and large. Model families such as Microsoft Phi-3 (in versions of roughly 3.8 billion, 7 billion, and 14 billion parameters), Google Gemma 2 (2 billion, 9 billion, and 27 billion), and Hugging Face SmolLM (135 million, 360 million, and 1.7 billion) specialize in small.\n\nDriving the story:Smaller models have become more capable thanks to techniques like knowledge distillation (in which a larger teacher model is used to train a smaller student model to match its output), parameter pruning (which removes less-influential parameters), quantization (which reduces neural network sizes by representing each parameter with fewer bits), and greater attention to curating training sets for data quality. Beyond performance, speed, and price, the ability to run on relatively low-powered hardware is a competitive advantage for a variety of uses.\n\nBehind the news:Distillation, pruning, quantization, and data curation are longstanding practices. But these techniques have not resulted in models quite this ratio of size and capability before, arguably because the larger models that are distilled, pruned, or quantized have never been so capable.\n\nWhere things stand:Smaller models dramatically widen the options for cost, speed, and deployment. As researchers find ways to shrink models without sacrificing performance, developers are gaining new ways to build profitable applications, deliver timely services, and distribute processing to the edges of the internet.",
    "qa": [
      {
        "question": "Xu hướng nào đã diễn ra trong lĩnh vực mô hình AI vào năm 2024?",
        "options": {
          "A": "Các mô hình AI lớn nhất trở nên phổ biến hơn.",
          "B": "Một số mô hình ngôn ngữ lớn đủ nhỏ để chạy trên điện thoại thông minh.",
          "C": "Các công ty AI tập trung vào việc xây dựng các mô hình chuyên biệt cho từng tác vụ.",
          "D": "Giá của các mô hình AI lớn tăng đáng kể."
        },
        "answer": "B"
      },
      {
        "question": "Các công ty AI hàng đầu đã làm gì thay vì chỉ tập trung vào xây dựng các mô hình lớn?",
        "options": {
          "A": "Phát triển các mô hình AI chuyên dụng cho các ngành công nghiệp khác nhau.",
          "B": "Quảng bá các dòng mô hình ngôn ngữ lớn với các phiên bản nhỏ, vừa và lớn.",
          "C": "Hợp tác với các trường đại học để nghiên cứu các thuật toán AI mới.",
          "D": "Tập trung vào việc cải thiện hiệu suất của các mô hình AI hiện có."
        },
        "answer": "B"
      },
      {
        "question": "Microsoft Phi-3 có những phiên bản kích thước tham số nào?",
        "options": {
          "A": "2 tỷ, 9 tỷ và 27 tỷ tham số.",
          "B": "135 triệu, 360 triệu và 1.7 tỷ tham số.",
          "C": "3.8 tỷ, 7 tỷ và 14 tỷ tham số.",
          "D": "5 tỷ, 10 tỷ và 20 tỷ tham số."
        },
        "answer": "C"
      },
      {
        "question": "Kỹ thuật nào được sử dụng để huấn luyện một mô hình nhỏ hơn (học sinh) dựa trên một mô hình lớn hơn (giáo viên)?",
        "options": {
          "A": "Parameter pruning (tỉa thưa tham số).",
          "B": "Quantization (lượng tử hóa).",
          "C": "Knowledge distillation (chưng cất kiến thức).",
          "D": "Data augmentation (tăng cường dữ liệu)."
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp 'parameter pruning' (tỉa thưa tham số) hoạt động bằng cách nào?",
        "options": {
          "A": "Giảm số lượng lớp trong mạng nơ-ron.",
          "B": "Loại bỏ các tham số ít ảnh hưởng.",
          "C": "Tăng kích thước của tập dữ liệu huấn luyện.",
          "D": "Sử dụng các hàm kích hoạt hiệu quả hơn."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích nào KHÔNG được đề cập đến của việc sử dụng các mô hình nhỏ hơn?",
        "options": {
          "A": "Tốc độ xử lý nhanh hơn.",
          "B": "Giá thành rẻ hơn.",
          "C": "Khả năng chạy trên phần cứng có cấu hình thấp.",
          "D": "Độ chính xác cao hơn so với các mô hình lớn."
        },
        "answer": "D"
      },
      {
        "question": "Kỹ thuật 'quantization' (lượng tử hóa) giúp giảm kích thước mô hình bằng cách nào?",
        "options": {
          "A": "Nén dữ liệu huấn luyện.",
          "B": "Giảm số lượng tham số trong mô hình.",
          "C": "Biểu diễn mỗi tham số bằng ít bit hơn.",
          "D": "Sử dụng các thuật toán tối ưu hóa hiệu quả hơn."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì đã khiến các kỹ thuật như chưng cất kiến thức, tỉa thưa tham số và lượng tử hóa trở nên hiệu quả hơn trong việc tạo ra các mô hình nhỏ gọn?",
        "options": {
          "A": "Sự phát triển của phần cứng mạnh mẽ hơn.",
          "B": "Sự ra đời của các thuật toán tối ưu hóa mới.",
          "C": "Sự cải thiện trong việc quản lý dữ liệu huấn luyện.",
          "D": "Sự phát triển của các mô hình lớn có khả năng cao hơn để chưng cất, tỉa thưa hoặc lượng tử hóa."
        },
        "answer": "D"
      },
      {
        "question": "Các mô hình nhỏ hơn mang lại lợi ích gì cho các nhà phát triển?",
        "options": {
          "A": "Giảm chi phí nghiên cứu và phát triển.",
          "B": "Cung cấp các cách thức mới để xây dựng các ứng dụng có lợi nhuận.",
          "C": "Tăng cường khả năng bảo mật của dữ liệu.",
          "D": "Đơn giản hóa quá trình triển khai mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Việc phân phối xử lý đến 'edges of the internet' (biên của internet) có nghĩa là gì?",
        "options": {
          "A": "Xử lý dữ liệu trên các máy chủ trung tâm.",
          "B": "Xử lý dữ liệu trực tiếp trên thiết bị của người dùng.",
          "C": "Xử lý dữ liệu bằng các thuật toán đám mây.",
          "D": "Xử lý dữ liệu bằng các siêu máy tính."
        },
        "answer": "B"
      }
    ]
  },
  "competition-heats-up-in-mobile-ai": {
    "title": "Competition Heats Up in Mobile AI",
    "collection": "hardware",
    "content": "Google designed its own AI chip for its new smartphone — a snub to Qualcomm, the dominant chip vendor in Android phones.What’s new:Googledebutedthe Tensor chip last week along with the global release of the new Pixel 6 smartphones. Company executivessaythe chip is well over four times faster than Qualcomm’s Snapdragon 765G in the Pixel 5, released last year.How it works:Tensor serves as a power-efficient AI inference engine for on-device functions like voice transcription, language translation, and some image processing features.\n\nBehind the news:Qualcomm’s Snapdragon line of processors underpinned the earliest smartphones from Apple, Blackberry, and a wide variety of Android producers, including Pixel. Google's move to design its own chips mimics Apple's decision to do the same over a decade ago. Both companies continue to use Qualcomm chips for cellular communications.Why It Matters:Advances in chip design and manufacturing are enticing companies with special processing needs to roll their own. Google tailored Tensor to suit its own AI technology while cutting its dependence on an outside supplier. That’s sure to help it make distinctive products. Look for more of the same from makers of all kinds of AI hardware.We’re thinking:Google controls the Android operating system. The more tightly it binds Tensor and Android, the greater the incentive it has to sell the chip to phone markers, and the harder it will be for Qualcomm and others to compete on performing inference in Android phones.",
    "qa": [
      {
        "question": "Chip Tensor của Google được thiết kế cho mục đích chính nào?",
        "options": {
          "A": "Tăng cường khả năng xử lý đồ họa cho game.",
          "B": "Cung cấp một công cụ suy luận AI tiết kiệm năng lượng cho các chức năng trên thiết bị.",
          "C": "Cải thiện hiệu suất kết nối mạng 5G.",
          "D": "Nâng cao khả năng bảo mật của điện thoại."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, chip Tensor nhanh hơn bao nhiêu lần so với Snapdragon 765G trong Pixel 5?",
        "options": {
          "A": "Gấp đôi.",
          "B": "Gấp ba.",
          "C": "Gấp bốn lần.",
          "D": "Gấp năm lần."
        },
        "answer": "C"
      },
      {
        "question": "Trước khi Google tự thiết kế chip, dòng chip Snapdragon của Qualcomm đã được sử dụng rộng rãi trong các điện thoại nào?",
        "options": {
          "A": "Chỉ điện thoại Android.",
          "B": "Chỉ điện thoại Pixel.",
          "C": "Điện thoại Apple, Blackberry và nhiều điện thoại Android, bao gồm cả Pixel.",
          "D": "Điện thoại Samsung và Huawei."
        },
        "answer": "C"
      },
      {
        "question": "Quyết định tự thiết kế chip của Google được so sánh với quyết định tương tự của công ty nào?",
        "options": {
          "A": "Samsung.",
          "B": "Huawei.",
          "C": "Microsoft.",
          "D": "Apple."
        },
        "answer": "D"
      },
      {
        "question": "Mặc dù tự thiết kế chip, Google vẫn tiếp tục sử dụng chip Qualcomm cho chức năng nào?",
        "options": {
          "A": "Xử lý AI.",
          "B": "Xử lý hình ảnh.",
          "C": "Kết nối di động.",
          "D": "Xử lý âm thanh."
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích chính của việc Google tự thiết kế chip Tensor là gì?",
        "options": {
          "A": "Giảm chi phí sản xuất điện thoại.",
          "B": "Tăng cường khả năng cạnh tranh với các nhà sản xuất điện thoại khác.",
          "C": "Điều chỉnh Tensor để phù hợp với công nghệ AI của riêng mình và giảm sự phụ thuộc vào nhà cung cấp bên ngoài.",
          "D": "Tăng cường khả năng bảo mật của hệ điều hành Android."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết dự đoán điều gì về xu hướng trong tương lai liên quan đến chip AI?",
        "options": {
          "A": "Các công ty sẽ ngừng sử dụng chip của Qualcomm.",
          "B": "Các nhà sản xuất phần cứng AI sẽ ngày càng tự thiết kế chip riêng.",
          "C": "Chip AI sẽ trở nên rẻ hơn và dễ tiếp cận hơn.",
          "D": "Qualcomm sẽ thống trị thị trường chip AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, Google có lợi thế gì so với các đối thủ cạnh tranh trong lĩnh vực chip AI cho điện thoại?",
        "options": {
          "A": "Google có nhiều kinh nghiệm hơn trong thiết kế chip.",
          "B": "Google kiểm soát hệ điều hành Android.",
          "C": "Google có nguồn tài chính dồi dào hơn.",
          "D": "Google có quan hệ đối tác tốt hơn với các nhà sản xuất chip."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì sẽ xảy ra nếu Google ràng buộc chặt chẽ hơn giữa chip Tensor và hệ điều hành Android?",
        "options": {
          "A": "Điện thoại Android sẽ trở nên đắt hơn.",
          "B": "Người dùng sẽ có ít lựa chọn điện thoại Android hơn.",
          "C": "Google sẽ có động lực lớn hơn để bán chip Tensor cho các nhà sản xuất điện thoại khác và Qualcomm sẽ khó cạnh tranh hơn.",
          "D": "Điện thoại Android sẽ trở nên kém an toàn hơn."
        },
        "answer": "C"
      },
      {
        "question": "Chức năng nào sau đây KHÔNG được đề cập trong bài viết là một trong những ứng dụng của chip Tensor?",
        "options": {
          "A": "Phiên âm giọng nói.",
          "B": "Dịch ngôn ngữ.",
          "C": "Xử lý hình ảnh.",
          "D": "Chơi game thực tế ảo."
        },
        "answer": "D"
      }
    ]
  },
  "computers-making-computers": {
    "title": "Computers Making Computers",
    "collection": "hardware",
    "content": "A neural network wrote the blueprint for upcoming computer chips that will accelerate deep learning itself.What’s new:Google engineers used a reinforcement learning system to arrange the billions of minuscule transistors in an upcoming version of its Tensor Processing Unit (TPU) chips optimized for computing neural networks. The system generated the design in six hours rather than the usual span of weeks, as detailed inNature.Key insight:Designing a chip is like playing a board game. A silicon wafer’s area resembles a board, parameters like macro counts and netlist topologies resemble pieces, and evaluation metrics resemble victory conditions. Reinforcement learning (RL) excels at meeting such challenges: Think of DeepMind’s AlphaGo — the RL model that, in 2015, became the first computer program to beat a Go master on a full-size board without a handicap.How it works:Google introduced its approach in apaperpublished last year.\n\nResults:The researchers compared their system’s output to that of a human team who had designed an existing TPU. Their approach completed the task in a fraction of the time, and it either matched or outperformed the human team with respect to chip area, wire length, and power consumption.Behind the news:Google introduced the first TPU in 2015, and today the chips power Google services like search and translation and are available to developers via Google Cloud.Launched last month, the fourth-generation TPU can train a ResNet-50 on ImageNet in1.82 minutes.Why it matters:AI-powered chip design could cut the cost of bespoke chips, leading to an explosion of special-purpose processing for all kinds of uses.We’re thinking:Reinforcement learning is hot, and we’ve seen companies announce “RL” results that would be described more accurately as supervised learning. But this appears to be a genuine use of RL ideas, and it’s great to see this much-hyped approach used in a valuable commercial application.",
    "qa": [
      {
        "question": "Hệ thống học tăng cường của Google được sử dụng để làm gì trong quá trình thiết kế chip TPU?",
        "options": {
          "A": "Tối ưu hóa quy trình sản xuất chip.",
          "B": "Sắp xếp hàng tỷ transistor siêu nhỏ trên chip.",
          "C": "Kiểm tra lỗi của chip sau khi sản xuất.",
          "D": "Phát triển các thuật toán học sâu mới."
        },
        "answer": "B"
      },
      {
        "question": "Thời gian mà hệ thống học tăng cường của Google cần để tạo ra thiết kế chip là bao lâu?",
        "options": {
          "A": "Vài tuần.",
          "B": "Sáu giờ.",
          "C": "Một tháng.",
          "D": "Một ngày."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết so sánh việc thiết kế chip với hoạt động nào?",
        "options": {
          "A": "Giải một bài toán phức tạp.",
          "B": "Chơi một trò chơi trên bàn cờ.",
          "C": "Xây dựng một tòa nhà.",
          "D": "Lập trình một phần mềm."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình học tăng cường AlphaGo của DeepMind nổi tiếng vì điều gì?",
        "options": {
          "A": "Đánh bại nhà vô địch cờ vua thế giới.",
          "B": "Đánh bại kiện tướng cờ vây trên bàn cờ đầy đủ mà không cần chấp quân.",
          "C": "Phát triển một thuật toán tìm kiếm hiệu quả.",
          "D": "Tự động dịch ngôn ngữ."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả so sánh giữa thiết kế chip bằng hệ thống học tăng cường và thiết kế bởi con người cho thấy điều gì?",
        "options": {
          "A": "Hệ thống học tăng cường tốn nhiều thời gian hơn nhưng cho kết quả tốt hơn.",
          "B": "Hệ thống học tăng cường hoàn thành nhiệm vụ nhanh hơn và có hiệu suất tương đương hoặc tốt hơn.",
          "C": "Thiết kế của con người luôn vượt trội hơn về mọi mặt.",
          "D": "Hệ thống học tăng cường chỉ hiệu quả trong việc giảm chi phí sản xuất."
        },
        "answer": "B"
      },
      {
        "question": "TPU đầu tiên của Google được giới thiệu vào năm nào?",
        "options": {
          "A": "2010",
          "B": "2015",
          "C": "2018",
          "D": "2020"
        },
        "answer": "B"
      },
      {
        "question": "TPU được sử dụng để làm gì trong các dịch vụ của Google?",
        "options": {
          "A": "Quản lý cơ sở dữ liệu.",
          "B": "Cung cấp năng lượng cho các dịch vụ như tìm kiếm và dịch thuật.",
          "C": "Bảo mật thông tin người dùng.",
          "D": "Phát triển hệ điều hành Android."
        },
        "answer": "B"
      },
      {
        "question": "TPU thế hệ thứ tư có thể huấn luyện ResNet-50 trên ImageNet trong bao lâu?",
        "options": {
          "A": "10 phút.",
          "B": "5 phút.",
          "C": "1.82 phút.",
          "D": "30 giây."
        },
        "answer": "C"
      },
      {
        "question": "Thiết kế chip bằng AI có thể mang lại lợi ích gì?",
        "options": {
          "A": "Giảm số lượng kỹ sư cần thiết.",
          "B": "Cắt giảm chi phí của chip chuyên dụng, dẫn đến sự bùng nổ của các ứng dụng xử lý đặc biệt.",
          "C": "Tăng cường bảo mật cho dữ liệu.",
          "D": "Tăng tốc độ phát triển phần mềm."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhận định gì về việc sử dụng học tăng cường trong thiết kế chip?",
        "options": {
          "A": "Đây chỉ là một chiêu trò quảng cáo.",
          "B": "Đây là một ứng dụng thực tế và có giá trị của học tăng cường.",
          "C": "Học tăng cường vẫn còn quá phức tạp để áp dụng vào thực tế.",
          "D": "Học tăng cường chỉ phù hợp với các bài toán lý thuyết."
        },
        "answer": "B"
      }
    ]
  },
  "confronting-the-fear-of-a-global-chip-shortage-in-2022": {
    "title": "No More GPUs",
    "collection": "hardware",
    "content": "Advanced AI requires advanced hardware. What if the global supply of high-end AI chips dries up?\n\nThe fear:Most of the world’s advanced AI processors are manufactured in Taiwan, where tension with mainland China is rising. Nearly all such chips are designed in the U.S., which hasblockedChina from obtaining them. That could prompt China to cut off U.S. access to Taiwan’s manufacturing capacity. Military action would be a human tragedy. It would also imperil progress in AI.\n\nHorror stories:China and the U.S. are on a collision course that threatens the global supply of advanced chips.\n\nSecuring the supply:Both the U.S. and China are trying to produce their own supplies of advanced chips. But fabricating circuitry measured in single-digit nanometers is enormously difficult and expensive, and there’s no guarantee that any particular party will accomplish it.\n\nFacing the fear:If a chipocalypse does occur, the AI community will need to become adept at workarounds that take advantage of older semiconductor technology, such as small data, data-centric AI development, and high-efficiency model architectures. It will also need to push for international cooperation amid intensifying polarization. Still, a chip shortage would be the least scary thing about a great-power conflict.",
    "qa": [
      {
        "question": "Theo bài viết, phần lớn bộ vi xử lý AI tiên tiến trên thế giới được sản xuất ở đâu?",
        "options": {
          "A": "Hoa Kỳ",
          "B": "Đại lục Trung Quốc",
          "C": "Đài Loan",
          "D": "Hàn Quốc"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì có thể thúc đẩy Trung Quốc cắt đứt quyền truy cập của Hoa Kỳ vào năng lực sản xuất của Đài Loan?",
        "options": {
          "A": "Hoa Kỳ tăng cường hợp tác kinh tế với Đài Loan.",
          "B": "Hoa Kỳ ngăn chặn Trung Quốc tiếp cận các chip AI tiên tiến.",
          "C": "Đài Loan tuyên bố độc lập.",
          "D": "Hoa Kỳ tăng cường hiện diện quân sự ở khu vực."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến hậu quả nào nếu xảy ra xung đột quân sự liên quan đến Đài Loan?",
        "options": {
          "A": "Sự sụp đổ của thị trường chứng khoán toàn cầu.",
          "B": "Sự trì trệ trong tiến bộ của trí tuệ nhân tạo.",
          "C": "Sự gia tăng đáng kể trong giá năng lượng.",
          "D": "Sự di cư hàng loạt của người dân từ Đài Loan."
        },
        "answer": "B"
      },
      {
        "question": "Cả Hoa Kỳ và Trung Quốc đang nỗ lực làm gì để đảm bảo nguồn cung chip tiên tiến?",
        "options": {
          "A": "Tăng cường nhập khẩu từ các quốc gia khác.",
          "B": "Phát triển công nghệ sản xuất chip của riêng mình.",
          "C": "Hợp tác nghiên cứu và phát triển chung.",
          "D": "Đầu tư vào các công ty sản xuất chip ở nước ngoài."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì khiến việc sản xuất chip tiên tiến trở nên khó khăn?",
        "options": {
          "A": "Sự thiếu hụt nguyên liệu thô.",
          "B": "Yêu cầu về độ chính xác cao và chi phí lớn.",
          "C": "Sự phức tạp của quy trình thiết kế.",
          "D": "Sự hạn chế về nhân lực có trình độ."
        },
        "answer": "B"
      },
      {
        "question": "Nếu xảy ra 'chipocalypse' (khủng hoảng chip), cộng đồng AI cần làm gì?",
        "options": {
          "A": "Chuyển sang sử dụng hoàn toàn phần mềm mã nguồn mở.",
          "B": "Tìm cách tận dụng công nghệ bán dẫn cũ hơn.",
          "C": "Giảm bớt sự phụ thuộc vào dữ liệu lớn.",
          "D": "Tập trung vào phát triển các thuật toán đơn giản hơn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh tầm quan trọng của điều gì trong bối cảnh căng thẳng địa chính trị gia tăng?",
        "options": {
          "A": "Tăng cường sức mạnh quân sự.",
          "B": "Hợp tác quốc tế.",
          "C": "Tự chủ kinh tế.",
          "D": "Phát triển năng lượng tái tạo."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì sẽ là điều đáng sợ nhất nếu xảy ra xung đột giữa các cường quốc?",
        "options": {
          "A": "Sự gián đoạn chuỗi cung ứng toàn cầu.",
          "B": "Sự thiếu hụt chip.",
          "C": "Những hậu quả thảm khốc về nhân đạo.",
          "D": "Sự suy thoái kinh tế toàn cầu."
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp phát triển AI nào được đề xuất như một giải pháp thay thế trong trường hợp thiếu chip?",
        "options": {
          "A": "Phát triển AI dựa trên đám mây.",
          "B": "Phát triển AI tập trung vào dữ liệu (data-centric AI).",
          "C": "Phát triển AI sử dụng mạng nơ-ron sâu.",
          "D": "Phát triển AI sử dụng học tăng cường."
        },
        "answer": "B"
      },
      {
        "question": "Kiến trúc mô hình hiệu quả cao được đề xuất như một giải pháp nào trong trường hợp thiếu chip?",
        "options": {
          "A": "Giảm nhu cầu về sức mạnh tính toán.",
          "B": "Tăng cường khả năng xử lý song song.",
          "C": "Cải thiện độ chính xác của mô hình.",
          "D": "Giảm kích thước của mô hình."
        },
        "answer": "A"
      }
    ]
  },
  "cruise-shuts-down-self-driving-cars-due-to-california-safety-concerns": {
    "title": "Cruise Control",
    "collection": "hardware",
    "content": "The state of California pulled the parking brake on Cruise driverless vehicles.\n\nWhat’s new:The California Department of Motor Vehicles (DMV)suspendedCruise’s permit to operate vehicles in the state without safety drivers. The General Motors subsidiary responded byhaltingits robotaxi operations across the United States.\n\nHow it works:The California DMV acted following an early Octoberincidentin San Francisco. A Cruise driverless car struck and trapped a pedestrian who had been thrown into its path by a separate hit-and-run.\n\nBehind the news:Cruise’s deployment of driverless taxis in San Francisco has been troubled.\n\nWhy it matters:Cruise’s latest trouble is a serious setback not just for GM, but for the self-driving car industry, which has been criticized for overpromising and underdelivering. The California DMV’s act has energized politicians, activists, and other public figures who oppose driverless taxis.\n\nWe’re thinking:The AI community must lean into transparency to inspire the public’s trust. California determined that Cruise was not fully forthcoming about its role in the incident — a serious breach of that trust. Voluntary suspension of operations is a welcome step toward restoring it. We hope the company takes the opportunity to conduct a comprehensive review.",
    "qa": [
      {
        "question": "Cơ quan nào đã đình chỉ giấy phép hoạt động xe tự lái của Cruise tại California?",
        "options": {
          "A": "Sở Giao thông Vận tải Hoa Kỳ (USDOT)",
          "B": "Sở Giao thông Cơ giới California (DMV)",
          "C": "Cục An toàn Giao thông Đường bộ Quốc gia (NHTSA)",
          "D": "Văn phòng Thống đốc California"
        },
        "answer": "B"
      },
      {
        "question": "Cruise đã phản ứng như thế nào sau khi bị đình chỉ giấy phép hoạt động tại California?",
        "options": {
          "A": "Kháng cáo quyết định của DMV lên tòa án.",
          "B": "Tạm dừng toàn bộ hoạt động robotaxi trên khắp Hoa Kỳ.",
          "C": "Tiếp tục hoạt động tại các khu vực khác ngoài San Francisco.",
          "D": "Đưa ra tuyên bố xin lỗi và hứa sẽ cải thiện hệ thống."
        },
        "answer": "B"
      },
      {
        "question": "Sự kiện nào trực tiếp dẫn đến quyết định đình chỉ giấy phép của Cruise?",
        "options": {
          "A": "Một loạt các vụ tai nạn nhỏ liên quan đến xe tự lái của Cruise.",
          "B": "Một chiếc xe Cruise đâm và mắc kẹt một người đi bộ sau khi người này bị một xe khác gây tai nạn bỏ chạy.",
          "C": "Phần mềm xe tự lái của Cruise bị lỗi nghiêm trọng.",
          "D": "Áp lực từ các nhóm hoạt động phản đối xe tự lái."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, vấn đề chính mà Cruise gặp phải trong việc triển khai xe tự lái ở San Francisco là gì?",
        "options": {
          "A": "Chi phí vận hành quá cao.",
          "B": "Thiếu sự chấp thuận của người dân địa phương.",
          "C": "Quá trình triển khai gặp nhiều khó khăn.",
          "D": "Cạnh tranh gay gắt từ các công ty xe tự lái khác."
        },
        "answer": "C"
      },
      {
        "question": "Sự cố của Cruise được xem là một bước lùi đối với ngành công nghiệp xe tự lái vì lý do gì?",
        "options": {
          "A": "Nó làm tăng chi phí phát triển xe tự lái.",
          "B": "Nó làm chậm quá trình phê duyệt quy định cho xe tự lái.",
          "C": "Nó củng cố những lời chỉ trích về việc hứa hẹn quá nhiều nhưng thực hiện không đủ của ngành.",
          "D": "Nó khiến các nhà đầu tư rút vốn khỏi các công ty xe tự lái."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết cho rằng cộng đồng AI cần làm gì để xây dựng lòng tin của công chúng?",
        "options": {
          "A": "Tăng cường quảng bá về lợi ích của AI.",
          "B": "Tập trung vào việc phát triển các công nghệ AI an toàn hơn.",
          "C": "Minh bạch hơn về hoạt động và rủi ro của AI.",
          "D": "Hợp tác chặt chẽ hơn với các cơ quan quản lý."
        },
        "answer": "C"
      },
      {
        "question": "Theo California DMV, Cruise đã vi phạm điều gì khiến họ bị đình chỉ giấy phép?",
        "options": {
          "A": "Không tuân thủ các quy định về an toàn giao thông.",
          "B": "Không báo cáo đầy đủ thông tin về vai trò của mình trong vụ tai nạn.",
          "C": "Sử dụng công nghệ chưa được kiểm chứng.",
          "D": "Hoạt động mà không có giấy phép phù hợp."
        },
        "answer": "B"
      },
      {
        "question": "Hành động tạm dừng hoạt động của Cruise được bài viết đánh giá như thế nào?",
        "options": {
          "A": "Một hành động vô nghĩa và không hiệu quả.",
          "B": "Một bước đi đáng hoan nghênh hướng tới việc khôi phục lòng tin.",
          "C": "Một nỗ lực để tránh trách nhiệm pháp lý.",
          "D": "Một chiến thuật quảng cáo để cải thiện hình ảnh công ty."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết hy vọng Cruise sẽ làm gì sau khi tạm dừng hoạt động?",
        "options": {
          "A": "Thay đổi ban lãnh đạo.",
          "B": "Thực hiện một cuộc đánh giá toàn diện.",
          "C": "Đầu tư nhiều hơn vào nghiên cứu và phát triển.",
          "D": "Tái cấu trúc công ty."
        },
        "answer": "B"
      },
      {
        "question": "Ai là đối tượng được 'tiếp thêm năng lượng' (energized) bởi hành động của California DMV?",
        "options": {
          "A": "Các nhà đầu tư vào ngành công nghiệp xe tự lái.",
          "B": "Các kỹ sư phát triển xe tự lái.",
          "C": "Các chính trị gia, nhà hoạt động và những nhân vật công chúng khác phản đối xe tự lái.",
          "D": "Người dân San Francisco ủng hộ xe tự lái."
        },
        "answer": "C"
      }
    ]
  },
  "dances-with-robots": {
    "title": "Dances With Robots",
    "collection": "business",
    "content": "Tesla unveiled its own AI chip and — surprise! — plans for a humanoid robot.What’s new:At Tesla’sAI Daypromotional event, the company offered a first look at an upcoming self-driving computer powered by custom AI chips. To make sure the event got headlines, CEO Elon Musk teased a forthcoming android.Chips and bots:Company executives explained how the company trains models, labels data, and meets various AI challenges. Then they dove into what’s ahead:\n\nBehind the news:Tesla’s Autopilot system has recently come under governmentscrutiny. Last week, the U.S. National Highway Traffic Safety Administration launched an investigation into 11 incidents in which Tesla vehicles using Autopilot collided with parked emergency vehicles. If the agency finds Autopilot at fault, it could require the company to change or recall its technology.Why it matters:Tesla’s promise of full self-driving capability was premature, but Dojo’s muscled-up computing power could bring it substantially closer. As for the Tesla Bot, we’re not holding our breath.We’re thinking:Tesla’s genuine achievements — the innovative electric car, charging infrastructure, driver-assistance capabilities — may be overshadowed by stunts like the dancer in the bodysuit. History will decide whether Elon Musk is remembered as a genius at engineering or marketing.",
    "qa": [
      {
        "question": "Sự kiện Tesla AI Day gần đây đã giới thiệu điều gì?",
        "options": {
          "A": "Một mẫu xe điện mới với công nghệ tự lái hoàn toàn.",
          "B": "Một máy tính tự lái sắp ra mắt được trang bị chip AI tùy chỉnh.",
          "C": "Một hệ thống sạc pin nhanh hơn cho xe điện Tesla.",
          "D": "Một thỏa thuận hợp tác với một công ty công nghệ AI hàng đầu."
        },
        "answer": "B"
      },
      {
        "question": "Elon Musk đã 'nhá hàng' sản phẩm nào tại sự kiện Tesla AI Day?",
        "options": {
          "A": "Một hệ thống pin năng lượng mặt trời mới.",
          "B": "Một phần mềm quản lý năng lượng thông minh.",
          "C": "Một robot hình người (android).",
          "D": "Một mạng lưới trạm sạc xe điện toàn cầu."
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống Autopilot của Tesla hiện đang đối mặt với vấn đề gì?",
        "options": {
          "A": "Thiếu hụt nguồn cung chip bán dẫn.",
          "B": "Sự cạnh tranh gay gắt từ các đối thủ.",
          "C": "Sự giám sát chặt chẽ từ chính phủ do các vụ tai nạn.",
          "D": "Phản hồi tiêu cực từ người dùng về hiệu suất."
        },
        "answer": "C"
      },
      {
        "question": "Cơ quan nào của Hoa Kỳ đang điều tra hệ thống Autopilot của Tesla?",
        "options": {
          "A": "Cục Điều tra Liên bang (FBI).",
          "B": "Cơ quan Bảo vệ Môi trường (EPA).",
          "C": "Cơ quan Quản lý An toàn Giao thông Đường bộ Quốc gia (NHTSA).",
          "D": "Ủy ban Thương mại Liên bang (FTC)."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì có thể xảy ra nếu NHTSA phát hiện Autopilot có lỗi?",
        "options": {
          "A": "Tesla sẽ bị cấm bán xe điện tại Hoa Kỳ.",
          "B": "Elon Musk sẽ phải từ chức CEO của Tesla.",
          "C": "Tesla có thể phải thay đổi hoặc thu hồi công nghệ Autopilot.",
          "D": "Tesla sẽ phải trả một khoản tiền phạt lớn cho chính phủ."
        },
        "answer": "C"
      },
      {
        "question": "Dojo được đề cập trong bài viết là gì?",
        "options": {
          "A": "Tên của một mẫu xe điện mới của Tesla.",
          "B": "Một hệ thống pin lưu trữ năng lượng tiên tiến.",
          "C": "Một siêu máy tính với sức mạnh tính toán lớn.",
          "D": "Một phần mềm mô phỏng lái xe tự động."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đánh giá như thế nào về khả năng tự lái hoàn toàn của Tesla hiện tại?",
        "options": {
          "A": "Đã đạt được và hoạt động rất hiệu quả.",
          "B": "Đang trong giai đoạn thử nghiệm cuối cùng.",
          "C": "Vẫn còn nhiều hạn chế và cần cải thiện.",
          "D": "Đã bị hủy bỏ do các vấn đề an toàn."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết ám chỉ điều gì về robot Tesla Bot?",
        "options": {
          "A": "Sẽ sớm được đưa vào sản xuất hàng loạt.",
          "B": "Có thể chỉ là một chiêu trò quảng cáo.",
          "C": "Đã được sử dụng trong các nhà máy của Tesla.",
          "D": "Sẽ thay thế con người trong các công việc nguy hiểm."
        },
        "answer": "B"
      },
      {
        "question": "Thành tựu thực tế nào của Tesla được bài viết đề cập?",
        "options": {
          "A": "Công nghệ du hành vũ trụ.",
          "B": "Xe điện sáng tạo, cơ sở hạ tầng sạc và khả năng hỗ trợ lái xe.",
          "C": "Phát triển trí tuệ nhân tạo tổng quát.",
          "D": "Sản xuất pin năng lượng mặt trời hiệu quả nhất thế giới."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đặt ra câu hỏi gì về Elon Musk?",
        "options": {
          "A": "Liệu ông có thể duy trì vị trí CEO của Tesla trong bao lâu.",
          "B": "Liệu ông có thể cạnh tranh với các tỷ phú công nghệ khác.",
          "C": "Liệu ông sẽ được nhớ đến như một thiên tài kỹ thuật hay marketing.",
          "D": "Liệu ông có thể giải quyết các vấn đề môi trường toàn cầu."
        },
        "answer": "C"
      }
    ]
  },
  "generative-ai-and-gpu-boom-spawns-growing-e-waste-problem": {
    "title": "Garbage Out",
    "collection": "hardware",
    "content": "Rapid progress in generative AI comes with a hidden environmental cost: mountains of obsolete hardware.\n\nWhat’s new:Astudyprojects that servers used to process generative AI could produce millions of metric tons of electronic waste by 2030. Extending server lifespans could reduce the burden substantially, according to author Peng Weng and colleagues at the Chinese Academy of Sciences and Reichman University.\n\nHow it works:The study extrapolated from publicly available data to model accumulation of electronic waste, or e-waste, between 2023 and 2030. The authors examined four scenarios: One scenario assumed linear growth in which hardware manufacturing expands at the current rate of 41 percent annually. The other three assumed exponential growth of demand for computing: conservative (85 percent annually), moderate (115 percent annually), and aggressive (136 percent annually). The study evaluated each scenario with and without measures taken to reduce waste.\n\nWhy it matters:E-waste is a problem not only due to its sheer quantity. Server hardware contains materials that are both hazardous and valuable. Discarded servers contain toxic substances like lead and chromium that can find their way into food water supplies. They also contain valuable metals, such as gold, silver, and platinum, that could save the environmental and financial costs of producing more of them.Properrecyclingof these components could yield $14 billion to $28 billion, highlighting both the economic potential and the urgent need to develop and deploy advanced recycling technologies.\n\nWe’re thinking:Humanity dumps over 2 billion metric tons of waste annually, so even comprehensive recycling and repurposing of AI hardware and other electronic devices would make only a small dent in the overall volume. However, the high density of valuable materials in e-waste could make mining such waste profitable and help recycle waste into valuable products, making for a more sustainable tech economy.",
    "qa": [
      {
        "question": "Theo nghiên cứu, đến năm 2030, các máy chủ được sử dụng để xử lý AI tạo sinh có thể tạo ra bao nhiêu tấn chất thải điện tử?",
        "options": {
          "A": "Hàng trăm nghìn tấn",
          "B": "Hàng triệu tấn",
          "C": "Hàng tỷ tấn",
          "D": "Hàng chục triệu tấn"
        },
        "answer": "B"
      },
      {
        "question": "Giải pháp nào được đề xuất để giảm đáng kể gánh nặng chất thải điện tử từ máy chủ AI?",
        "options": {
          "A": "Tăng cường sản xuất phần cứng mới",
          "B": "Kéo dài tuổi thọ của máy chủ",
          "C": "Đốt bỏ chất thải điện tử",
          "D": "Chôn lấp chất thải điện tử ở các khu vực hẻo lánh"
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu đã sử dụng dữ liệu nào để mô hình hóa sự tích lũy chất thải điện tử?",
        "options": {
          "A": "Dữ liệu độc quyền từ các công ty công nghệ",
          "B": "Dữ liệu được thu thập từ các bãi rác điện tử",
          "C": "Dữ liệu công khai",
          "D": "Dữ liệu được dự đoán bởi các chuyên gia"
        },
        "answer": "C"
      },
      {
        "question": "Tốc độ tăng trưởng hàng năm hiện tại của sản xuất phần cứng được sử dụng trong kịch bản tăng trưởng tuyến tính là bao nhiêu?",
        "options": {
          "A": "136%",
          "B": "85%",
          "C": "115%",
          "D": "41%"
        },
        "answer": "D"
      },
      {
        "question": "Điều gì khiến chất thải điện tử trở thành một vấn đề nghiêm trọng?",
        "options": {
          "A": "Chỉ vì số lượng lớn của nó",
          "B": "Chỉ vì chi phí xử lý cao",
          "C": "Vì nó chứa các vật liệu nguy hiểm và có giá trị",
          "D": "Vì nó chiếm quá nhiều không gian lưu trữ"
        },
        "answer": "C"
      },
      {
        "question": "Chất thải điện tử có thể gây hại cho môi trường như thế nào?",
        "options": {
          "A": "Làm tăng nhiệt độ toàn cầu",
          "B": "Làm ô nhiễm nguồn nước và thực phẩm",
          "C": "Làm suy giảm tầng ozone",
          "D": "Gây ra mưa axit"
        },
        "answer": "B"
      },
      {
        "question": "Những kim loại quý nào có thể được thu hồi từ chất thải điện tử?",
        "options": {
          "A": "Sắt, đồng, nhôm",
          "B": "Vàng, bạc, bạch kim",
          "C": "Chì, thủy ngân, cadmium",
          "D": "Kẽm, niken, thiếc"
        },
        "answer": "B"
      },
      {
        "question": "Việc tái chế đúng cách các thành phần của máy chủ thải có thể mang lại giá trị kinh tế ước tính là bao nhiêu?",
        "options": {
          "A": "$1.4 tỷ đến $2.8 tỷ",
          "B": "$14 tỷ đến $28 tỷ",
          "C": "$140 tỷ đến $280 tỷ",
          "D": "$1.4 nghìn tỷ đến $2.8 nghìn tỷ"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, việc tái chế toàn diện phần cứng AI và các thiết bị điện tử khác sẽ có tác động như thế nào đến tổng lượng chất thải của nhân loại?",
        "options": {
          "A": "Giảm đáng kể tổng lượng chất thải",
          "B": "Loại bỏ hoàn toàn vấn đề chất thải",
          "C": "Chỉ tạo ra một sự khác biệt nhỏ",
          "D": "Làm tăng tổng lượng chất thải"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì có thể làm cho việc khai thác chất thải điện tử trở nên có lợi nhuận?",
        "options": {
          "A": "Sự thiếu hụt các vật liệu thô",
          "B": "Mật độ cao của các vật liệu có giá trị trong chất thải điện tử",
          "C": "Chi phí lao động thấp trong ngành tái chế",
          "D": "Sự hỗ trợ của chính phủ cho các chương trình tái chế"
        },
        "answer": "B"
      }
    ]
  },
  "groq-elevates-ai-processing-speeds-with-advanced-chips": {
    "title": "Blazing Inference Speed",
    "collection": "hardware",
    "content": "An upstart chip company dramatically accelerates pretrained large language models.\n\nWhat’s new:Groq offers cloud access to Meta’s Llama 2 and Mistral.ai’s Mixtral at speeds an order of magnitude greater than other AI platforms. Registered users can try ithere.\n\nHow it works:Groq’s cloud platform is based on its proprietary GroqChip, a processor specialized for large language model inference that the company calls a language processing unit or LPU. The company plans to serve other models eventually, but its main business is selling chips. It focuses on inference on the theory that demand for a model’s inference can increase while demand for its training tends to be fixed.\n\nBehind the news:Groq founder Jonathan Ross previously worked at Google, where he spearheaded the development of that company’stensor processing unit(TPU), another specialized AI chip.\n\nWhy it matters:Decades of ever faster chips have proven that users need all the speed they can get out of computers. With AI, rapid inference can make the difference between halting interactions and real-time spontaneity. Moreover, Groq shows that there’s plenty of innovation left in computing hardware as processors target general-purpose computing versus AI, inference versus training, language versus vision, and so on.\n\nWe’re thinking:Autonomous agents based on large language models (LLMs) can get a huge boost from very fast generation. People can read only so fast, the faster generation of text that’s intended to be read by humans has little value beyond a certain point. But an agent (as well as chain-of-thought and similar approaches to prompting) might need an LLM to “think” through multiple steps. Fast LLM inference can be immensely useful for building agents that can work on problems at length before reaching a conclusion.",
    "qa": [
      {
        "question": "Công ty Groq cung cấp quyền truy cập đám mây vào những mô hình ngôn ngữ lớn nào?",
        "options": {
          "A": "GPT-3 và LaMDA",
          "B": "Llama 2 và Mixtral",
          "C": "Bard và PaLM",
          "D": "GPT-4 và Gemini"
        },
        "answer": "B"
      },
      {
        "question": "GroqChip được mô tả là loại bộ xử lý chuyên dụng cho mục đích gì?",
        "options": {
          "A": "Đào tạo mô hình ngôn ngữ lớn",
          "B": "Suy luận mô hình ngôn ngữ lớn",
          "C": "Xử lý hình ảnh",
          "D": "Tính toán khoa học"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, chiến lược kinh doanh chính của Groq là gì?",
        "options": {
          "A": "Cung cấp dịch vụ đào tạo mô hình ngôn ngữ lớn",
          "B": "Bán chip chuyên dụng (GroqChip)",
          "C": "Phát triển các mô hình ngôn ngữ lớn mới",
          "D": "Cung cấp dịch vụ lưu trữ đám mây cho các mô hình AI"
        },
        "answer": "B"
      },
      {
        "question": "Jonathan Ross, người sáng lập Groq, trước đây đã làm việc ở đâu?",
        "options": {
          "A": "Microsoft",
          "B": "Google",
          "C": "Apple",
          "D": "Amazon"
        },
        "answer": "B"
      },
      {
        "question": "Jonathan Ross đã đóng vai trò gì tại công ty trước đây của mình?",
        "options": {
          "A": "Phát triển hệ điều hành",
          "B": "Dẫn đầu phát triển TPU (Tensor Processing Unit)",
          "C": "Quản lý trung tâm dữ liệu",
          "D": "Nghiên cứu về thị giác máy tính"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lợi ích chính của suy luận AI nhanh là gì?",
        "options": {
          "A": "Giảm chi phí đào tạo mô hình",
          "B": "Tạo ra sự khác biệt giữa tương tác gián đoạn và tương tác tự nhiên theo thời gian thực",
          "C": "Tăng độ chính xác của mô hình",
          "D": "Cho phép xử lý dữ liệu lớn hơn"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết cho rằng sự đổi mới trong phần cứng máy tính hiện nay tập trung vào điều gì?",
        "options": {
          "A": "Tính toán đa năng",
          "B": "AI, suy luận, ngôn ngữ",
          "C": "Đồ họa và trò chơi",
          "D": "Lưu trữ dữ liệu"
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng nào có thể hưởng lợi lớn từ việc tạo văn bản nhanh chóng của các mô hình ngôn ngữ lớn?",
        "options": {
          "A": "Phân tích cảm xúc",
          "B": "Các tác nhân tự động (Autonomous agents)",
          "C": "Dịch máy",
          "D": "Tóm tắt văn bản"
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc tạo văn bản nhanh chóng lại ít quan trọng hơn đối với văn bản mà con người đọc?",
        "options": {
          "A": "Con người có thể đọc rất nhanh",
          "B": "Tốc độ đọc của con người có giới hạn",
          "C": "Văn bản cho con người cần độ chính xác cao hơn",
          "D": "Văn bản cho con người thường ngắn gọn hơn"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì có thể cần đến suy luận LLM nhanh để giải quyết vấn đề một cách thấu đáo?",
        "options": {
          "A": "Phân tích dữ liệu tài chính",
          "B": "Các tác nhân và phương pháp tiếp cận chuỗi suy nghĩ (chain-of-thought)",
          "C": "Nhận dạng khuôn mặt",
          "D": "Dự báo thời tiết"
        },
        "answer": "B"
      }
    ]
  },
  "grounding-dino-1-5-an-edge-device-model-built-for-faster-smarter-object-detection": {
    "title": "Object Detection for Small Devices",
    "collection": "hardware",
    "content": "An open source model is designed to perform sophisticated object detection on edge devices like phones, cars, medical equipment, and smart doorbells.\n\nWhat’s new:Tianhe Ren, Qing Jiang, Shilong Liu, Zhaoyang Zeng, and colleagues at the International Digital Economy Academy introducedGrounding DINO 1.5, a system that enables devices with limited processing power to detect arbitrary objects in images based on a text list of objects (also known as open-vocabulary object detection). You can download the code and weightshere.\n\nKey insight:The originalGrounding DINOfollows many of itspredecessorsby using image embeddings of different levels (from lower-level embeddings produced by an image encoder’s earlier layers, which are larger and represent simple patterns such as edges, to higher-level embeddings produced by later layers, which are smaller and represent complex patterns such as objects). This enables it tobetter detect objects at different scales. However, it takes a lot of computation. To enable the system to run on devices that have less processing power, Grounding DINO 1.5 uses only the smallest (highest-level) image embeddings for a crucial part of the process.\n\nHow it works:Grounding DINO 1.5 is made up of components that produce text and image embeddings, fuse them, and classify them. It follows the system architecture and training of Grounding DINO with the following exceptions: (i) It uses a different image encoder, (ii) a different model combines text and image embeddings, and (iii) it was trained on a newer dataset of 20 million publicly available text-image examples.\n\nResults:Grounding DINO 1.5 performed significantly faster than the original Grounding DINO: 10.7 frames per second versus 1.1 frames per second running on anNvidia Jetson Orin NXcomputer. Tested on adatasetof images of common objects annotated with labels and bounding boxes, Grounding DINO 1.5 achieved better average precision (a measure of how many objects it identified correctly in their correct location, higher is better) than both Grounding DINO andYOLO-Worldv2-L(a CNN-based object detector). Grounding DINO 1.5 scored 33.5 percent, Grounding DINO 27.4 percent, and YOLO-Worldv2-L 33 percent.\n\nWhy it matters:The authors achieved 10 times the speed with just a couple of small changes (a more efficient image encoder and a smaller image embedding when performing cross-attention between embeddings of images and texts). Small changes can yield big results.\n\nWe’re thinking:Lately model builders have been building better, smaller, faster large language models for edge devices. We’re glad to see object detection get similar treatment.",
    "qa": [
      {
        "question": "Grounding DINO 1.5 được thiết kế để thực hiện tác vụ gì trên các thiết bị edge?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên phức tạp.",
          "B": "Phát hiện đối tượng phức tạp.",
          "C": "Tạo sinh hình ảnh từ văn bản.",
          "D": "Dự đoán chuỗi thời gian."
        },
        "answer": "B"
      },
      {
        "question": "Ai là những người đã giới thiệu Grounding DINO 1.5?",
        "options": {
          "A": "Yann LeCun và các đồng nghiệp tại Facebook AI Research.",
          "B": "Tianhe Ren, Qing Jiang, Shilong Liu, Zhaoyang Zeng và các đồng nghiệp tại International Digital Economy Academy.",
          "C": "Geoffrey Hinton và các đồng nghiệp tại Google Brain.",
          "D": "Andrew Ng và các đồng nghiệp tại Coursera."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính của Grounding DINO 1.5 so với phiên bản gốc để chạy trên các thiết bị có cấu hình thấp là gì?",
        "options": {
          "A": "Sử dụng tất cả các lớp embedding hình ảnh.",
          "B": "Sử dụng duy nhất embedding hình ảnh mức cao nhất.",
          "C": "Sử dụng một mô hình ngôn ngữ lớn hơn.",
          "D": "Loại bỏ hoàn toàn bước embedding hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Grounding DINO 1.5 được huấn luyện trên bộ dữ liệu nào?",
        "options": {
          "A": "Một bộ dữ liệu độc quyền với 1 triệu hình ảnh.",
          "B": "Một bộ dữ liệu mới với 10 triệu hình ảnh và văn bản được tạo tự động.",
          "C": "Một bộ dữ liệu mới với 20 triệu hình ảnh và văn bản công khai.",
          "D": "Một bộ dữ liệu tổng hợp hoàn toàn."
        },
        "answer": "C"
      },
      {
        "question": "Grounding DINO 1.5 đạt được tốc độ xử lý bao nhiêu khung hình trên giây (FPS) trên Nvidia Jetson Orin NX?",
        "options": {
          "A": "1.1 FPS",
          "B": "5.35 FPS",
          "C": "10.7 FPS",
          "D": "21.4 FPS"
        },
        "answer": "C"
      },
      {
        "question": "Chỉ số Average Precision (AP) được sử dụng để đánh giá điều gì trong bài viết?",
        "options": {
          "A": "Tốc độ xử lý của mô hình.",
          "B": "Mức độ tiêu thụ năng lượng của mô hình.",
          "C": "Độ chính xác trong việc xác định và định vị đối tượng.",
          "D": "Kích thước bộ nhớ cần thiết để chạy mô hình."
        },
        "answer": "C"
      },
      {
        "question": "So với Grounding DINO gốc và YOLO-Worldv2-L, Grounding DINO 1.5 đạt được kết quả AP như thế nào?",
        "options": {
          "A": "Thấp hơn cả hai.",
          "B": "Cao hơn Grounding DINO nhưng thấp hơn YOLO-Worldv2-L.",
          "C": "Cao hơn YOLO-Worldv2-L nhưng thấp hơn Grounding DINO.",
          "D": "Cao hơn cả hai."
        },
        "answer": "D"
      },
      {
        "question": "Những thay đổi chính nào đã giúp Grounding DINO 1.5 tăng tốc độ xử lý?",
        "options": {
          "A": "Sử dụng một bộ mã hóa hình ảnh hiệu quả hơn và một embedding hình ảnh lớn hơn.",
          "B": "Sử dụng một bộ mã hóa hình ảnh hiệu quả hơn và một embedding hình ảnh nhỏ hơn.",
          "C": "Sử dụng một bộ giải mã văn bản phức tạp hơn và một embedding văn bản lớn hơn.",
          "D": "Loại bỏ hoàn toàn bước cross-attention giữa hình ảnh và văn bản."
        },
        "answer": "B"
      },
      {
        "question": "Ý nghĩa chính của việc Grounding DINO 1.5 đạt được tốc độ cao hơn với những thay đổi nhỏ là gì?",
        "options": {
          "A": "Các mô hình lớn luôn tốt hơn các mô hình nhỏ.",
          "B": "Những thay đổi nhỏ có thể mang lại kết quả lớn.",
          "C": "Việc huấn luyện trên bộ dữ liệu lớn là yếu tố quan trọng nhất.",
          "D": "Phần cứng mạnh mẽ là yếu tố quyết định hiệu suất."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến xu hướng phát triển nào trong lĩnh vực mô hình học máy?",
        "options": {
          "A": "Xây dựng các mô hình ngôn ngữ lớn hơn và phức tạp hơn.",
          "B": "Xây dựng các mô hình ngôn ngữ lớn nhỏ hơn, nhanh hơn và tốt hơn cho các thiết bị edge.",
          "C": "Tập trung vào việc cải thiện độ chính xác của các mô hình trên các máy chủ đám mây.",
          "D": "Phát triển các thuật toán nén dữ liệu hiệu quả hơn."
        },
        "answer": "B"
      }
    ]
  },
  "horsepower-for-next-gen-networks": {
    "title": "Horsepower for Next-Gen Networks",
    "collection": "hardware",
    "content": "The for-profit research organization OpenAI has a new supercomputer to help achieve its dream of building the world’s most sophisticated AI.What’s new:Microsoft engineered the new hardware network to train immense models on thousands of images, texts, and videos simultaneously.How it works:Hosted on Microsoft’s Azure cloud platform, the system comprises 10,000 GPUs and 285,000 CPUs.\n\nBehind the news:In 2019, Microsoftinvested$1 billion in OpenAI in exchange for the first shot at commercializing the research outfit’s innovations. Built using anundisclosedportion of that investment, the new system ranks among the world’s five most powerful computers.Yes, but:While some experts see AGI on the horizon, others are less sanguine. Prominent researchers includingYann LeCun,Jerome Pesenti,Geoffrey Hinton, and Demis Hassabishave thrown cold water on AGI’s prospects.Why it matters:OpenAI and Microsoft believe that the new supercomputer will open the door to systems capable of running hundreds of language and vision models simultaneously. Microsoftsaidthat techniques developed on it eventually will benefit other Azure customers.\n\nWe’re thinking:We love supercomputers as much as anyone. But if Moore’s Law keeps up, today’s supercomputer will be tomorrow’s wrist watch.",
    "qa": [
      {
        "question": "Tổ chức nào đã thiết kế mạng lưới phần cứng mới cho siêu máy tính của OpenAI?",
        "options": {
          "A": "OpenAI",
          "B": "Microsoft",
          "C": "Google",
          "D": "Amazon"
        },
        "answer": "B"
      },
      {
        "question": "Siêu máy tính mới của OpenAI được sử dụng để làm gì?",
        "options": {
          "A": "Chạy các trò chơi điện tử phức tạp",
          "B": "Đào tạo các mô hình lớn trên dữ liệu hình ảnh, văn bản và video",
          "C": "Dự báo thời tiết chính xác hơn",
          "D": "Nghiên cứu về năng lượng hạt nhân"
        },
        "answer": "B"
      },
      {
        "question": "Siêu máy tính của OpenAI được lưu trữ trên nền tảng đám mây nào?",
        "options": {
          "A": "Amazon Web Services (AWS)",
          "B": "Google Cloud Platform (GCP)",
          "C": "Microsoft Azure",
          "D": "IBM Cloud"
        },
        "answer": "C"
      },
      {
        "question": "Khoản đầu tư ban đầu của Microsoft vào OpenAI là bao nhiêu?",
        "options": {
          "A": "$100 triệu",
          "B": "$500 triệu",
          "C": "$1 tỷ",
          "D": "$2 tỷ"
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của Microsoft khi đầu tư vào OpenAI là gì?",
        "options": {
          "A": "Để cạnh tranh với Google trong lĩnh vực AI",
          "B": "Để có quyền ưu tiên thương mại hóa các đổi mới của OpenAI",
          "C": "Để tiếp cận nguồn nhân lực AI tài năng",
          "D": "Để đa dạng hóa danh mục đầu tư của mình"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, siêu máy tính mới của OpenAI xếp hạng như thế nào trên thế giới?",
        "options": {
          "A": "Máy tính mạnh nhất thế giới",
          "B": "Một trong mười máy tính mạnh nhất thế giới",
          "C": "Một trong năm máy tính mạnh nhất thế giới",
          "D": "Một trong hai mươi máy tính mạnh nhất thế giới"
        },
        "answer": "C"
      },
      {
        "question": "Ai là một trong những nhà nghiên cứu đã bày tỏ sự hoài nghi về triển vọng của AGI (Artificial General Intelligence)?",
        "options": {
          "A": "Satya Nadella",
          "B": "Elon Musk",
          "C": "Yann LeCun",
          "D": "Sam Altman"
        },
        "answer": "C"
      },
      {
        "question": "OpenAI và Microsoft tin rằng siêu máy tính mới sẽ mở ra khả năng gì?",
        "options": {
          "A": "Phát triển xe tự lái hoàn toàn",
          "B": "Chạy đồng thời hàng trăm mô hình ngôn ngữ và thị giác",
          "C": "Tìm ra phương pháp chữa trị ung thư",
          "D": "Khám phá các hành tinh mới"
        },
        "answer": "B"
      },
      {
        "question": "Microsoft tuyên bố rằng những kỹ thuật được phát triển trên siêu máy tính mới cuối cùng sẽ mang lại lợi ích cho ai?",
        "options": {
          "A": "Tất cả người dùng internet",
          "B": "Các nhà nghiên cứu AI trên toàn thế giới",
          "C": "Khách hàng Azure khác",
          "D": "Chính phủ các nước"
        },
        "answer": "C"
      },
      {
        "question": "Theo quan điểm được thể hiện trong bài viết, điều gì có thể xảy ra với siêu máy tính trong tương lai?",
        "options": {
          "A": "Nó sẽ trở nên lỗi thời và không còn hữu ích",
          "B": "Nó sẽ trở thành một phần không thể thiếu của cuộc sống hàng ngày",
          "C": "Nó sẽ trở nên nhỏ gọn đến mức có thể đeo trên cổ tay",
          "D": "Nó sẽ được sử dụng để điều khiển toàn bộ nền kinh tế thế giới"
        },
        "answer": "C"
      }
    ]
  },
  "how-to-run-pilotnet-on-a-raspberry-pi-pico-microcontroller": {
    "title": "Deep Learning at (Small) Scale",
    "collection": "hardware",
    "content": "TinyMLshows promise for bringing deep learning to applications where electrical power is scarce, processing in the cloud is impractical, and/or data privacy is paramount. The trick is to get high-performance algorithms to run on hardware that offers limited computation, memory, and electrical power.\n\nWhat's new:Michael Bechtel, QiTao Weng, and Heechul Yun at University of Kansas built a neural network that steeredDeepPicarMicro, a radio-controlled car outfitted for autonomous driving, around a simple track. This work extends earlierworkin which the authors built neural networks for extremely limited hardware.\n\nKey insight:A neural network that controls a model car needs to be small enough to fit on a microcontroller, fast enough to recognize the car’s surroundings while it’s in motion, and accurate enough to avoid crashing. One way to design a network that fits all three criteria is to (i) build a wide variety of architectures within the constraints of size and latency and (ii) test their accuracy empirically.\n\nHow it works:The hardware included a NewBright 1:24-scale car with battery pack and motor driver, Raspberry Pi Pico microcontroller, and Arducam Mini 2MP Plus camera. The model was based onPilotNet, a convolutional neural network. The authors built a dataset by manually driving the car around a wide, circular track to collect 10,000 images and associated steering inputs.\n\nResults:The authors selected 16 models with various losses and latencies and tested them on the track. The best model completed seven laps before crashing. (Seven models failed to complete a single lap.) The models that managed at least one lap tended to achieve greater than 80 percent accuracy on the test set and latency lower than 100 milliseconds.\n\nWhy it matters:This work shows neural networks, properly designed, can achieve useful results on severely constrained hardware. For a rough comparison, the Nvidia Tegra X2 processor that drives a Skydio 2+ drone provides four cores that run at 2 gigaHertz, while the Raspberry Pi Pico’s processor provides two cores running at 133 megaHertz. Neural networks that run on extremely low-cost, low-power hardware could lead to effective devices that monitor environmental conditions, health of agricultural crops, operation of remote equipment like wind turbines, and much more.\n\nWe’re thinking:Training a small network to deliver good performance is more difficult than training a larger one. New methods will be necessary to narrow the gap.",
    "qa": [
      {
        "question": "TinyML hứa hẹn mang lại điều gì cho các ứng dụng?",
        "options": {
          "A": "Sử dụng năng lượng điện lớn hơn.",
          "B": "Xử lý dữ liệu trên đám mây hiệu quả hơn.",
          "C": "Bảo mật dữ liệu được ưu tiên hàng đầu.",
          "D": "Tăng cường khả năng kết nối internet."
        },
        "answer": "C"
      },
      {
        "question": "Nhóm nghiên cứu tại Đại học Kansas đã sử dụng mạng nơ-ron để điều khiển thiết bị nào?",
        "options": {
          "A": "Một máy bay không người lái.",
          "B": "Một chiếc xe điều khiển từ xa tự hành.",
          "C": "Một robot hút bụi.",
          "D": "Một hệ thống tưới tiêu tự động."
        },
        "answer": "B"
      },
      {
        "question": "Một trong những tiêu chí quan trọng để mạng nơ-ron điều khiển xe mô hình thành công là gì?",
        "options": {
          "A": "Kích thước lớn để chứa nhiều thông tin.",
          "B": "Đủ nhanh để nhận diện môi trường xung quanh khi xe đang di chuyển.",
          "C": "Sử dụng nhiều năng lượng để tăng hiệu suất.",
          "D": "Kết nối liên tục với đám mây để xử lý dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Phần cứng nào được sử dụng trong dự án DeepPicarMicro?",
        "options": {
          "A": "Nvidia Jetson Nano.",
          "B": "Raspberry Pi 4.",
          "C": "Raspberry Pi Pico.",
          "D": "Google Coral Dev Board."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình mạng nơ-ron được sử dụng trong dự án DeepPicarMicro dựa trên kiến trúc nào?",
        "options": {
          "A": "AlexNet.",
          "B": "PilotNet.",
          "C": "ResNet.",
          "D": "VGGNet."
        },
        "answer": "B"
      },
      {
        "question": "Nhóm nghiên cứu đã thu thập dữ liệu bằng cách nào?",
        "options": {
          "A": "Sử dụng dữ liệu có sẵn trên internet.",
          "B": "Mô phỏng môi trường lái xe.",
          "C": "Lái xe thủ công quanh một đường đua để thu thập hình ảnh và dữ liệu điều khiển.",
          "D": "Sử dụng một robot tự động để thu thập dữ liệu."
        },
        "answer": "C"
      },
      {
        "question": "Kết quả tốt nhất mà mô hình đạt được là gì?",
        "options": {
          "A": "Hoàn thành 10 vòng đua mà không gặp sự cố.",
          "B": "Hoàn thành 7 vòng đua trước khi gặp sự cố.",
          "C": "Hoàn thành tất cả các vòng đua với độ chính xác 100%.",
          "D": "Không có mô hình nào hoàn thành được một vòng đua."
        },
        "answer": "B"
      },
      {
        "question": "Độ trễ (latency) của các mô hình thành công thường thấp hơn bao nhiêu?",
        "options": {
          "A": "50 mili giây.",
          "B": "100 mili giây.",
          "C": "200 mili giây.",
          "D": "500 mili giây."
        },
        "answer": "B"
      },
      {
        "question": "Công việc này chứng minh điều gì về mạng nơ-ron trên phần cứng hạn chế?",
        "options": {
          "A": "Không thể đạt được kết quả hữu ích.",
          "B": "Có thể đạt được kết quả hữu ích nếu được thiết kế phù hợp.",
          "C": "Chỉ có thể đạt được kết quả cơ bản.",
          "D": "Cần phải sử dụng phần cứng mạnh mẽ hơn."
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng tiềm năng nào được đề cập cho các thiết bị sử dụng mạng nơ-ron trên phần cứng chi phí thấp?",
        "options": {
          "A": "Điều khiển các phương tiện tự hành cỡ lớn.",
          "B": "Giám sát điều kiện môi trường.",
          "C": "Phân tích dữ liệu tài chính phức tạp.",
          "D": "Phát triển các trò chơi điện tử có đồ họa cao."
        },
        "answer": "B"
      }
    ]
  },
  "huawei-rises-as-key-ai-chip-supplier-amid-u-s-export-bans": {
    "title": "Competition Heats Up in AI Chips",
    "collection": "hardware",
    "content": "Huawei is emerging as an important supplier of AI chips.\n\nWhat’s new:Amid a U.S. ban on exports of advanced chips to China, demand for Huawei’s AI chips is so intense that the company is limiting production of the chip that powers one of its most popular smartphones so it can serve the AI market,Reutersreported.\n\nDemand and supply:China’s biggest chip fabricator, Semiconductor Manufacturing International Corp. (SMIC), fabricates both the Ascend 910B, which is optimized to process neural networks, and the Kirin chip that drives Huawei’s popular Mate 60 phone. Production capacity is limited, so making more Ascend 910Bs means making fewer Kirins.\n\nBehind the news:Nvidia accounted for 90 percent of the market for AI chips in China prior to the advent of U.S. export restrictions. China has responded to the limits by building its ability to manufacture advanced chips domestically — a tall order, since it requires technology that is very difficult to develop. In August, Baidu ordered 1,600 Ascend 910B chips for delivery by the end of the year, according to an earlierReutersreport. The order, which is tiny compared to typical data center purchases, nonetheless demonstrated that SMIC could manufacture the chips and that Baidu was experimenting with alternatives to Nvidia in anticipation of even tighter U.S. restrictions on AI chips that took effect in October. Currently, SMIC isgearing upto produce Huawei’s next-generation Ascend chips.\n\nWhy it matters:For years, Nvidia’s GPUs have been the only practical choice for processing deep learning models. The company’s lead over competitors both in hardware implementation and software support are likely to protect its dominant position for some time to come. However, competitors like AMD and Huawei are beginning to nip at Nvidia’s heels. That means more hardware options for developers, and the competition may drive lower prices and still higher performance.\n\nWe’re thinking:AI chips are at the heart of the current technologicalcompetitionbetween the U.S. and China. While Huawei and SMIC still have a lot to prove in terms of scaling up production, their rate of progress is impressive and illustrates the limits of the current U.S. restrictions.",
    "qa": [
      {
        "question": "Theo bài viết, điều gì đang xảy ra với Huawei trong lĩnh vực chip AI?",
        "options": {
          "A": "Huawei đang rút khỏi thị trường chip AI do lệnh cấm vận của Mỹ.",
          "B": "Huawei đang nổi lên như một nhà cung cấp chip AI quan trọng.",
          "C": "Huawei đang hợp tác với Nvidia để sản xuất chip AI.",
          "D": "Huawei đang tập trung vào sản xuất chip cho điện thoại thông minh thay vì chip AI."
        },
        "answer": "B"
      },
      {
        "question": "Vì sao Huawei phải hạn chế sản xuất chip Kirin?",
        "options": {
          "A": "Do lệnh cấm vận của Mỹ khiến việc nhập khẩu nguyên liệu trở nên khó khăn.",
          "B": "Để tập trung nguồn lực sản xuất chip Ascend 910B phục vụ thị trường AI.",
          "C": "Do nhu cầu chip Kirin trên thị trường giảm mạnh.",
          "D": "Do SMIC không đủ năng lực sản xuất cả hai loại chip cùng lúc."
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào đang sản xuất chip Ascend 910B và chip Kirin cho Huawei?",
        "options": {
          "A": "Nvidia.",
          "B": "AMD.",
          "C": "Semiconductor Manufacturing International Corp. (SMIC).",
          "D": "Baidu."
        },
        "answer": "C"
      },
      {
        "question": "Trước khi có lệnh hạn chế xuất khẩu của Mỹ, thị phần chip AI ở Trung Quốc chủ yếu thuộc về công ty nào?",
        "options": {
          "A": "Huawei.",
          "B": "SMIC.",
          "C": "AMD.",
          "D": "Nvidia."
        },
        "answer": "D"
      },
      {
        "question": "Baidu đã đặt mua bao nhiêu chip Ascend 910B từ Huawei?",
        "options": {
          "A": "16,000 chip.",
          "B": "160 chip.",
          "C": "1,600 chip.",
          "D": "160,000 chip."
        },
        "answer": "C"
      },
      {
        "question": "Động thái đặt mua chip Ascend 910B của Baidu thể hiện điều gì?",
        "options": {
          "A": "Baidu hoàn toàn hài lòng với hiệu năng của chip Ascend 910B.",
          "B": "Baidu muốn cạnh tranh trực tiếp với Nvidia trong lĩnh vực chip AI.",
          "C": "Baidu đang thử nghiệm các giải pháp thay thế Nvidia để phòng ngừa các lệnh hạn chế chặt chẽ hơn từ Mỹ.",
          "D": "Baidu muốn hỗ trợ Huawei vượt qua khó khăn do lệnh cấm vận."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, ưu thế lớn nhất của Nvidia so với các đối thủ cạnh tranh trong lĩnh vực chip AI là gì?",
        "options": {
          "A": "Giá thành sản phẩm rẻ hơn.",
          "B": "Hiệu năng phần cứng vượt trội và hỗ trợ phần mềm tốt.",
          "C": "Khả năng sản xuất hàng loạt quy mô lớn.",
          "D": "Mối quan hệ đối tác chiến lược với các công ty công nghệ hàng đầu Trung Quốc."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì có thể xảy ra khi có nhiều nhà cung cấp chip AI hơn trên thị trường?",
        "options": {
          "A": "Giá chip AI sẽ tăng cao do cạnh tranh gay gắt.",
          "B": "Hiệu năng chip AI sẽ giảm sút do các công ty tập trung vào giảm giá thành.",
          "C": "Các nhà phát triển sẽ có nhiều lựa chọn phần cứng hơn, cạnh tranh có thể thúc đẩy giá thấp hơn và hiệu suất cao hơn.",
          "D": "Thị trường chip AI sẽ bị độc quyền bởi một vài công ty lớn."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhận định chip AI là trung tâm của vấn đề gì?",
        "options": {
          "A": "Cuộc chiến thương mại giữa Mỹ và Trung Quốc.",
          "B": "Cuộc cạnh tranh công nghệ giữa Mỹ và Trung Quốc.",
          "C": "Sự phát triển của trí tuệ nhân tạo trên toàn cầu.",
          "D": "Vấn đề thiếu hụt chip bán dẫn toàn cầu."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đánh giá như thế nào về tốc độ phát triển của Huawei và SMIC trong lĩnh vực chip AI?",
        "options": {
          "A": "Rất chậm chạp và không có nhiều tiến triển.",
          "B": "Đang gặp nhiều khó khăn và có thể không đạt được mục tiêu.",
          "C": "Ấn tượng và cho thấy những hạn chế của các lệnh hạn chế từ Mỹ.",
          "D": "Chỉ là những nỗ lực nhỏ lẻ, không có tác động lớn đến thị trường."
        },
        "answer": "C"
      }
    ]
  },
  "hugging-face-acquires-pollen-robotics-launches-reachy-2-robot-for-open-source-research": {
    "title": "Hugging Face Rolls Out Open Robot",
    "collection": "hardware",
    "content": "Hugging Face has made a name by providing open AI models. Now it’s providing an open robot.\n\nWhat’s new:Hugging Faceacquiredthe French company Pollen Robotics for an undisclosed price. It plans to offer Pollen’sReachy 2, a robot that runs on code that’s freelyavailableunder an Apache 2.0 license, for $70,000.\n\nHow it works:Reachy 2 has two arms, gripper hands, and a wheeled base (optional). It’s designed primarily for education and research in human-robot interaction in real-world settings.\n\nBehind the news:Last year, Remi Cadene, who worked on Tesla’s Optimus,joinedHugging Face to lead robotics projects. In May, he and his team rolled out the LeRobot open source robotics code library, whichprovidespretrained models, datasets, and simulators for reinforcement learning and imitation learning. In November, Nvidia announced acollaborationwith Hugging Face to accelerate LeRobot’s data collection, training, and verification.\n\nWhy it matters:Hugging Face’s acquisition of Pollen reflects an industry-wideinvestmentinrobots, notablyhumanoidrobots, whose prices have beenfalling. Nvidia CEO Jensen Huang has calledAI-enabled roboticsa “multi-trillion dollar” opportunity.\n\nWe’re thinking:AI-enabled robots are marching slowly toward what we hope will be breakthrough applications. Open-source systems are an important part of the trend!",
    "qa": [
      {
        "question": "Hugging Face vừa thực hiện một bước tiến mới trong lĩnh vực robot bằng cách nào?",
        "options": {
          "A": "Phát triển một mô hình AI mới cho robot.",
          "B": "Mua lại công ty Pollen Robotics.",
          "C": "Hợp tác với Tesla để phát triển robot Optimus.",
          "D": "Tổ chức một hội nghị chuyên đề về robot mã nguồn mở."
        },
        "answer": "B"
      },
      {
        "question": "Robot Reachy 2 của Pollen Robotics được thiết kế chủ yếu cho mục đích gì?",
        "options": {
          "A": "Sản xuất hàng loạt trong các nhà máy.",
          "B": "Nghiên cứu và giáo dục về tương tác người-robot.",
          "C": "Thực hiện các nhiệm vụ nguy hiểm trong môi trường khắc nghiệt.",
          "D": "Phục vụ như một trợ lý cá nhân trong gia đình."
        },
        "answer": "B"
      },
      {
        "question": "Giá bán dự kiến của robot Reachy 2 là bao nhiêu?",
        "options": {
          "A": "$10,000",
          "B": "$50,000",
          "C": "$70,000",
          "D": "$100,000"
        },
        "answer": "C"
      },
      {
        "question": "Remi Cadene, người dẫn dắt các dự án robot tại Hugging Face, trước đây đã làm việc ở đâu?",
        "options": {
          "A": "Google",
          "B": "Amazon",
          "C": "Tesla",
          "D": "Microsoft"
        },
        "answer": "C"
      },
      {
        "question": "LeRobot là gì?",
        "options": {
          "A": "Một loại robot hình người mới do Hugging Face phát triển.",
          "B": "Một thư viện mã nguồn mở cho robot do Hugging Face phát triển.",
          "C": "Một công ty sản xuất robot mà Hugging Face vừa mua lại.",
          "D": "Một dự án hợp tác giữa Hugging Face và Nvidia về robot."
        },
        "answer": "B"
      },
      {
        "question": "Nvidia hợp tác với Hugging Face để làm gì liên quan đến LeRobot?",
        "options": {
          "A": "Sản xuất phần cứng cho robot LeRobot.",
          "B": "Phát triển các thuật toán điều khiển robot LeRobot.",
          "C": "Tăng tốc độ thu thập dữ liệu, huấn luyện và xác minh cho LeRobot.",
          "D": "Phân phối robot LeRobot trên thị trường."
        },
        "answer": "C"
      },
      {
        "question": "CEO của Nvidia, Jensen Huang, nhận định về tiềm năng của robot hỗ trợ bởi AI như thế nào?",
        "options": {
          "A": "Một thị trường ngách với tiềm năng hạn chế.",
          "B": "Một cơ hội trị giá hàng triệu đô la.",
          "C": "Một cơ hội trị giá hàng tỷ đô la.",
          "D": "Một cơ hội trị giá hàng nghìn tỷ đô la."
        },
        "answer": "D"
      },
      {
        "question": "Giấy phép nào được sử dụng cho mã nguồn của Reachy 2?",
        "options": {
          "A": "GPL",
          "B": "MIT",
          "C": "Apache 2.0",
          "D": "BSD"
        },
        "answer": "C"
      },
      {
        "question": "Đặc điểm nào sau đây KHÔNG phải là một phần của Reachy 2?",
        "options": {
          "A": "Hai cánh tay",
          "B": "Bàn tay kẹp",
          "C": "Động cơ phản lực",
          "D": "Đế bánh xe (tùy chọn)"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, yếu tố nào đóng vai trò quan trọng trong sự phát triển của robot hỗ trợ bởi AI?",
        "options": {
          "A": "Sự bảo mật của các hệ thống robot.",
          "B": "Sự phát triển của các hệ thống mã nguồn đóng.",
          "C": "Sự phát triển của các hệ thống mã nguồn mở.",
          "D": "Sự kiểm soát chặt chẽ của chính phủ đối với công nghệ robot."
        },
        "answer": "C"
      }
    ]
  },
  "loopholes-help-chinese-companies-get-us-chips": {
    "title": "Restricted Chips Slip Through",
    "collection": "hardware",
    "content": "Chinese companies have found loopholes to sidestep United States limits on AI chips.\n\nWhat’s new:Facing severe limits on U.S. exports of high-performance chips, Chinese AI firms are purchasing them through subsidiaries and using them through cloud services, theFinancial Timesreported.\n\nRestrictions:In October 2022, U.S. officialsblockedU.S. companies, citizens, permanent residents, and their foreign trading partners from selling chips with high processing and interconnect speeds — primarily Nvidia’s flagship A100 — to Chinese customers. The ban also prohibits sales to China of equipment and software used in semiconductor manufacturing. Japan and the Netherlandsimposedsimilar restrictions in January.\n\nLoopholes:Prior to the restrictions, rumors that they were coming gave companies an opportunity to stockpile chips ahead of time. The rules don’t specifically prohibit Chinese customers from using cloud-computing services, which opened a path to use the banned chips, and shell companies headquartered in other countries provide another avenue. Meanwhile, the U.S. government previously had barred some companies from buying high-tech equipment; these firms already had developed alternative sources of sensitive technology.\n\nBehind the news:China responded to the embargo by investing in its own chip industry. In December 2022, Beijingannouncedthat it would pump $143 billion into domestic semiconductor production. In early 2023, however, officialsslowedits investment in response to a resurgence of Covid-19.Why it matters:U.S. efforts to restrict advanced chips come at a time of rapidprogressin AI as well as increasing fears of geopolitical instability. The lack of homegrown alternatives creates a powerful incentive for Chinese companies to find ways around the restrictions.We’re thinking:This isn’t the end of the story. U.S. officials likely will respond by tightening the laws around cloud computing, and Chinese companies will react by finding new workarounds.",
    "qa": [
      {
        "question": "Lệnh hạn chế xuất khẩu chip của Mỹ nhắm mục tiêu chính vào đối tượng nào?",
        "options": {
          "A": "Tất cả các công ty công nghệ của Trung Quốc.",
          "B": "Các công ty, công dân, thường trú nhân Mỹ và đối tác thương mại nước ngoài của họ bán chip có tốc độ xử lý cao cho khách hàng Trung Quốc.",
          "C": "Các công ty sản xuất chip của Mỹ có liên kết với chính phủ Trung Quốc.",
          "D": "Các công ty Trung Quốc nhập khẩu chip từ Nhật Bản và Hà Lan."
        },
        "answer": "B"
      },
      {
        "question": "Thời điểm chính thức lệnh hạn chế xuất khẩu chip của Mỹ có hiệu lực là khi nào?",
        "options": {
          "A": "Tháng 1 năm 2023.",
          "B": "Tháng 12 năm 2022.",
          "C": "Tháng 10 năm 2021.",
          "D": "Tháng 10 năm 2022."
        },
        "answer": "D"
      },
      {
        "question": "Một trong những 'lỗ hổng' mà các công ty Trung Quốc sử dụng để tiếp cận chip bị hạn chế là gì?",
        "options": {
          "A": "Sản xuất chip nội địa với công nghệ tiên tiến hơn.",
          "B": "Sử dụng dịch vụ điện toán đám mây.",
          "C": "Nhập khẩu chip thông qua các quốc gia không áp dụng lệnh trừng phạt.",
          "D": "Hợp tác với các công ty Mỹ để phát triển chip mới."
        },
        "answer": "B"
      },
      {
        "question": "Phản ứng ban đầu của chính phủ Trung Quốc đối với lệnh cấm vận chip là gì?",
        "options": {
          "A": "Đàm phán với Mỹ để dỡ bỏ lệnh cấm vận.",
          "B": "Tăng cường đầu tư vào ngành công nghiệp chip nội địa.",
          "C": "Chuyển hướng sang nhập khẩu chip từ các nước châu Âu.",
          "D": "Giảm đầu tư vào công nghệ để tập trung vào các ngành khác."
        },
        "answer": "B"
      },
      {
        "question": "Khoản đầu tư dự kiến của Trung Quốc vào sản xuất chất bán dẫn nội địa là bao nhiêu?",
        "options": {
          "A": "$100 tỷ USD.",
          "B": "$143 tỷ USD.",
          "C": "$200 tỷ USD.",
          "D": "$150 tỷ USD."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã khiến Trung Quốc chậm lại việc đầu tư vào ngành công nghiệp chip vào đầu năm 2023?",
        "options": {
          "A": "Sự thiếu hụt nguyên liệu sản xuất chip.",
          "B": "Sự trỗi dậy của các công ty chip nước ngoài.",
          "C": "Sự tái bùng phát của Covid-19.",
          "D": "Sự thay đổi trong chính sách kinh tế của chính phủ."
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu chính của Mỹ khi hạn chế xuất khẩu chip tiên tiến sang Trung Quốc là gì?",
        "options": {
          "A": "Thúc đẩy sự phát triển của ngành công nghiệp chip Mỹ.",
          "B": "Hạn chế sự tiến bộ nhanh chóng của Trung Quốc trong lĩnh vực trí tuệ nhân tạo và giảm thiểu rủi ro địa chính trị.",
          "C": "Tăng cường hợp tác công nghệ với các nước đồng minh.",
          "D": "Giảm sự phụ thuộc của Mỹ vào chip sản xuất tại Trung Quốc."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì tạo động lực mạnh mẽ cho các công ty Trung Quốc tìm cách lách các lệnh hạn chế?",
        "options": {
          "A": "Sự hỗ trợ tài chính từ chính phủ Trung Quốc.",
          "B": "Sự thiếu hụt các lựa chọn thay thế được sản xuất trong nước.",
          "C": "Áp lực cạnh tranh từ các công ty nước ngoài.",
          "D": "Mong muốn dẫn đầu trong lĩnh vực công nghệ."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết dự đoán điều gì về phản ứng của Mỹ đối với các 'lỗ hổng' mà Trung Quốc đang khai thác?",
        "options": {
          "A": "Mỹ sẽ nới lỏng các quy định để thúc đẩy thương mại.",
          "B": "Mỹ sẽ tăng cường hợp tác với Trung Quốc trong lĩnh vực công nghệ.",
          "C": "Mỹ có khả năng sẽ thắt chặt luật pháp liên quan đến điện toán đám mây.",
          "D": "Mỹ sẽ tập trung vào việc phát triển chip nội địa."
        },
        "answer": "C"
      },
      {
        "question": "Loại chip nào của Nvidia được nhắc đến cụ thể trong bài viết là đối tượng chính của lệnh hạn chế?",
        "options": {
          "A": "RTX 4090.",
          "B": "Tesla V100.",
          "C": "A100.",
          "D": "GeForce GTX 1080."
        },
        "answer": "C"
      }
    ]
  },
  "malaysia-emerges-as-an-ai-and-cloud-computing-hub-drawing-billions-in-investment": {
    "title": "Malaysia’s Data Center Boom",
    "collection": "hardware",
    "content": "Malaysia’s location, natural resources, and investor-friendly government are perfect for data centers, turning part of the country into an AI-fueled boomtown.\n\nWhat’s new:Data center construction is flourishing in the southern Malaysian state of Johor, where companies including ByteDance and Microsoft are spending billions of dollars on facilities,The Wall Street Journalreported. These data centers will provide processing power for AI, cloud computing, and telecommunications.\n\nHow it works:Data center construction has slowed in established areas like Ireland and Northern Virginia as space and resources have become scarce. All regions face shortages of electrical power, analystssay, and some U.S. locations face publicresistanceto new projects. Johor has emerged as an attractive alternative.\n\nBehind the news:The Asia-Pacific region is second to North America in data center construction, according to one recentreport, ahead of Europe, South America, and the Middle East and Africa. As Johor builds out its data-center inventory, it will compete with established Asia-Pacificmarketsin Hong Kong, Mumbai, Seoul, Singapore, Sydney, and Tokyo.\n\nWhy it matters:AI is poised to transform virtually every industry, but doing so requires ample processing power. The data-center buildout will help fuel improvements in AI as well as spread the technology to new industries and bring its benefits to people throughout the world. Malaysia’s role as a data center hub is also bound to bring huge economic benefits to the country itself.\n\nWe’re thinking:Many data centers have been built near users to reduce latency. But the cost of processing compute-intensive AI workloads is so high relative to the cost of transmitting data that it makes sense to transmit AI-related data long distances for processing. (As Andrew wrote, thegravity of data is decreasing.) We hope the increasing flexibility in siting data centers will enable more nations that aren’t traditional tech hubs toparticipate in the tech economyand reap significant benefits from doing so.",
    "qa": [
      {
        "question": "Điều gì khiến Malaysia trở thành địa điểm lý tưởng cho các trung tâm dữ liệu?",
        "options": {
          "A": "Vị trí địa lý, nguồn nhân lực dồi dào và chính sách thuế ưu đãi.",
          "B": "Vị trí địa lý, tài nguyên thiên nhiên và chính phủ thân thiện với nhà đầu tư.",
          "C": "Cơ sở hạ tầng hiện đại, nguồn năng lượng tái tạo và luật pháp bảo vệ quyền sở hữu trí tuệ.",
          "D": "Nguồn lao động giá rẻ, chính sách nhập cư cởi mở và hệ thống giáo dục tiên tiến."
        },
        "answer": "B"
      },
      {
        "question": "Bang nào của Malaysia đang chứng kiến sự bùng nổ xây dựng trung tâm dữ liệu?",
        "options": {
          "A": "Penang",
          "B": "Johor",
          "C": "Kuala Lumpur",
          "D": "Malacca"
        },
        "answer": "B"
      },
      {
        "question": "Các trung tâm dữ liệu mới xây dựng ở Johor sẽ cung cấp sức mạnh xử lý cho những lĩnh vực nào?",
        "options": {
          "A": "Năng lượng tái tạo, sản xuất ô tô điện và công nghệ sinh học.",
          "B": "Trí tuệ nhân tạo, điện toán đám mây và viễn thông.",
          "C": "Thương mại điện tử, tài chính ngân hàng và du lịch trực tuyến.",
          "D": "Nghiên cứu khoa học, phát triển phần mềm và trò chơi điện tử."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc xây dựng trung tâm dữ liệu ở các khu vực như Ireland và Bắc Virginia đang chậm lại?",
        "options": {
          "A": "Do chi phí lao động tăng cao và chính sách hạn chế nhập cư.",
          "B": "Do thiếu không gian, tài nguyên và sự phản đối của công chúng.",
          "C": "Do sự cạnh tranh gay gắt từ các quốc gia khác và sự thay đổi trong công nghệ.",
          "D": "Do các quy định pháp lý nghiêm ngặt và sự chậm trễ trong việc cấp phép xây dựng."
        },
        "answer": "B"
      },
      {
        "question": "Khu vực nào dẫn đầu về xây dựng trung tâm dữ liệu trên toàn cầu?",
        "options": {
          "A": "Châu Âu",
          "B": "Bắc Mỹ",
          "C": "Châu Á - Thái Bình Dương",
          "D": "Trung Đông và Châu Phi"
        },
        "answer": "B"
      },
      {
        "question": "Johor sẽ cạnh tranh với những thị trường nào trong khu vực Châu Á - Thái Bình Dương về trung tâm dữ liệu?",
        "options": {
          "A": "Jakarta, Bangkok, Manila, Hồ Chí Minh.",
          "B": "Hong Kong, Mumbai, Seoul, Singapore, Sydney, Tokyo.",
          "C": "Thượng Hải, Bắc Kinh, Quảng Châu, Thâm Quyến.",
          "D": "Kuala Lumpur, Jakarta, Singapore, Bangkok."
        },
        "answer": "B"
      },
      {
        "question": "Việc xây dựng trung tâm dữ liệu có vai trò gì trong sự phát triển của trí tuệ nhân tạo?",
        "options": {
          "A": "Cung cấp nguồn vốn đầu tư cho các dự án nghiên cứu AI.",
          "B": "Cung cấp sức mạnh xử lý cần thiết cho các ứng dụng AI.",
          "C": "Tạo ra các tiêu chuẩn chung cho việc phát triển AI.",
          "D": "Thúc đẩy sự hợp tác giữa các nhà khoa học và kỹ sư AI."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích kinh tế nào mà Malaysia có thể nhận được từ việc trở thành trung tâm dữ liệu?",
        "options": {
          "A": "Tăng cường xuất khẩu các sản phẩm công nghệ cao.",
          "B": "Thu hút đầu tư nước ngoài và tạo ra việc làm.",
          "C": "Nâng cao vị thế trên trường quốc tế và tăng cường hợp tác kinh tế.",
          "D": "Phát triển ngành du lịch công nghệ và thu hút nhân tài."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, tại sao việc truyền dữ liệu AI đi xa để xử lý lại trở nên hợp lý?",
        "options": {
          "A": "Chi phí truyền dữ liệu đã giảm đáng kể nhờ công nghệ mới.",
          "B": "Chi phí xử lý các công việc AI chuyên sâu cao hơn nhiều so với chi phí truyền dữ liệu.",
          "C": "Các trung tâm dữ liệu ở xa có cơ sở hạ tầng tốt hơn và nguồn năng lượng rẻ hơn.",
          "D": "Việc truyền dữ liệu đi xa giúp bảo mật thông tin tốt hơn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết hy vọng điều gì về việc xây dựng các trung tâm dữ liệu ở nhiều quốc gia hơn?",
        "options": {
          "A": "Giúp giảm thiểu tác động tiêu cực đến môi trường.",
          "B": "Cho phép nhiều quốc gia không phải là trung tâm công nghệ truyền thống tham gia vào nền kinh tế công nghệ và hưởng lợi.",
          "C": "Thúc đẩy sự phát triển của các công nghệ mới và sáng tạo.",
          "D": "Tạo ra một thị trường cạnh tranh hơn cho các dịch vụ điện toán đám mây."
        },
        "answer": "B"
      }
    ]
  },
  "microsoft-researchers-show-that-heavily-quantized-versions-of-llama-can-perform-as-well-as-near-full-precision": {
    "title": "4-Bit Efficiency, 16-Bit Accuracy",
    "collection": "hardware",
    "content": "Using an 8-bit number format like FP8 during training saves computation compared to 16- or 32-bit formats, but it can yield less-accurate results. Researchers trained models using 4-bit numbers without sacrificing accuracy.\n\nWhat’s new:Ruizhe Wang and colleagues at Microsoft and University of Science and Technology of China trained large language models (LLMs) usingFP4 for matrix multiplicationsand achieved accuracy comparable to LLMs trained using the popular BF16 format. Since matrix multiplications account for 95 percent of computation in LLM training, FP4 could significantly accelerate computation and reduce memory costs.\n\nKey insight:Quantization functions, which accelerate computation by reducing the precision of model weights and layer outputs, make typical training impossible because they’re not differentiable. A commonworkaroundpasses the derivative through, as though quantization didn’t occur, but this degrades the resulting model’s accuracy. A differentiable approximation of a quantization function enables quantization to reduce training computation while maintaining the accuracy of the trained model.\n\nHow it works:The authors pretrained Llama 2 13B on 100 billion tokens oftext scraped from the web. They used FP4 for matrix multiplications and FP8, BF16, or FP16 for the other operations such as optimizer updates.\n\nResults:The authors simulated FP4 hardware on Nvidia H100 GPUs, which don’t directly support that number format. FP4 achieved accuracy similar to that of BF16 during training and across a wide variety of tasks at inference.\n\nWhy it matters:Training LLMs at FP4 precision ought to reduce computation dramatically on hardware that supports FP4 matrix multiplications.\n\nWe’re thinking:FP4-ready hardware became available in the cloud onlyearly this year, so the authors weren’t able to measure the actual acceleration. As capable hardware becomes more widely used, FP4 promises faster, more energy-efficient training.",
    "qa": [
      {
        "question": "Định dạng số FP8 được sử dụng trong quá trình huấn luyện mô hình có ưu điểm gì so với định dạng 16-bit hoặc 32-bit?",
        "options": {
          "A": "Độ chính xác cao hơn.",
          "B": "Tiết kiệm chi phí bộ nhớ hơn.",
          "C": "Tiết kiệm tính toán hơn.",
          "D": "Dễ dàng tích hợp với phần cứng hơn."
        },
        "answer": "C"
      },
      {
        "question": "Theo nghiên cứu của Ruizhe Wang và cộng sự, định dạng số nào được sử dụng cho phép nhân ma trận trong quá trình huấn luyện LLM mà vẫn đạt được độ chính xác tương đương BF16?",
        "options": {
          "A": "FP8",
          "B": "FP4",
          "C": "FP16",
          "D": "BF8"
        },
        "answer": "B"
      },
      {
        "question": "Nhân ma trận chiếm bao nhiêu phần trăm tính toán trong quá trình huấn luyện LLM?",
        "options": {
          "A": "50%",
          "B": "75%",
          "C": "90%",
          "D": "95%"
        },
        "answer": "D"
      },
      {
        "question": "Vấn đề chính của các hàm lượng tử hóa (quantization functions) trong quá trình huấn luyện mô hình là gì?",
        "options": {
          "A": "Chúng làm tăng độ phức tạp của mô hình.",
          "B": "Chúng không khả vi (not differentiable).",
          "C": "Chúng yêu cầu nhiều bộ nhớ hơn.",
          "D": "Chúng làm chậm quá trình suy luận (inference)."
        },
        "answer": "B"
      },
      {
        "question": "Giải pháp phổ biến để khắc phục vấn đề không khả vi của hàm lượng tử hóa là gì?",
        "options": {
          "A": "Sử dụng một hàm lượng tử hóa khác.",
          "B": "Bỏ qua quá trình lượng tử hóa trong quá trình tính đạo hàm.",
          "C": "Tăng độ chính xác của mô hình.",
          "D": "Sử dụng một bộ tối ưu hóa (optimizer) khác."
        },
        "answer": "B"
      },
      {
        "question": "Trong nghiên cứu này, mô hình Llama 2 13B được huấn luyện trước trên bao nhiêu token văn bản?",
        "options": {
          "A": "10 tỷ",
          "B": "50 tỷ",
          "C": "100 tỷ",
          "D": "500 tỷ"
        },
        "answer": "C"
      },
      {
        "question": "Định dạng số nào được sử dụng cho các hoạt động khác ngoài nhân ma trận trong quá trình huấn luyện Llama 2 13B?",
        "options": {
          "A": "FP4",
          "B": "INT8",
          "C": "FP8, BF16, hoặc FP16",
          "D": "BF32"
        },
        "answer": "C"
      },
      {
        "question": "Các tác giả đã mô phỏng phần cứng FP4 trên loại GPU nào?",
        "options": {
          "A": "Nvidia A100",
          "B": "Nvidia V100",
          "C": "Nvidia H100",
          "D": "AMD MI250"
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích tiềm năng của việc huấn luyện LLM ở độ chính xác FP4 là gì?",
        "options": {
          "A": "Tăng độ chính xác của mô hình.",
          "B": "Giảm chi phí phần cứng.",
          "C": "Giảm đáng kể tính toán.",
          "D": "Tăng tốc độ suy luận (inference)."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao các tác giả không thể đo lường sự tăng tốc thực tế của FP4 trong nghiên cứu này?",
        "options": {
          "A": "Phần mềm hỗ trợ FP4 chưa được phát triển.",
          "B": "Phần cứng hỗ trợ FP4 chưa có sẵn rộng rãi.",
          "C": "Phương pháp đánh giá chưa được chuẩn hóa.",
          "D": "Chi phí thử nghiệm quá cao."
        },
        "answer": "B"
      }
    ]
  },
  "new-horsepower-for-neural-nets": {
    "title": "New Horsepower for Neural Nets",
    "collection": "hardware",
    "content": "A high-profile semiconductor startup made a bid for the future of AI computation.What’s new:UK startup Graphcore released theColossus Mk2, a processor intended to perform the matrix math calculations at the heart of deep learning more efficiently than other specialized processors or general-purpose chips from Intel and AMD. The company expects to be shipping at full volume in the fourth quarter.How it works:The Mk2 comprises nearly 60 billion transistors. (Nvidia’s flagship A100 has 54 billion, while Cerebras’ gargantuan Wafer-Scale Engine boasts 1.2 trillion. Google doesn’t advertise its TPU transistor counts.) Girded by 900 megabytes of random access memory, the Mk2’s transistors are organized into 1,500 independent cores capable of running nearly 9,000 parallel threads.\n\nWhy it matters:AI’s demand for computational resources is insatiable. A recentstudyfrom researchers at MIT, the University of Brasilia, and Yonsei University suggests that progress in deep learning could stall for lack of processing power. Innovations in chip technology may make a difference.We’re thinking:The fact that software evolves faster than hardware is a major challenge to building chips. Graphcore’s design is geared to accelerate large, sparse recurrent neural networks at a moment when transformer networks are beginning to supplant RNNs in some applications. Will some bold chip maker tune its next generation for transformers?",
    "qa": [
      {
        "question": "Công ty Graphcore có trụ sở tại quốc gia nào?",
        "options": {
          "A": "Hoa Kỳ",
          "B": "Vương Quốc Anh",
          "C": "Hàn Quốc",
          "D": "Brazil"
        },
        "answer": "B"
      },
      {
        "question": "Bộ xử lý Colossus Mk2 của Graphcore được thiết kế để tối ưu hóa loại tính toán nào?",
        "options": {
          "A": "Tính toán số nguyên lớn",
          "B": "Tính toán dấu phẩy động chính xác cao",
          "C": "Tính toán ma trận trong deep learning",
          "D": "Mã hóa và giải mã dữ liệu"
        },
        "answer": "C"
      },
      {
        "question": "Graphcore dự kiến bắt đầu giao hàng Colossus Mk2 với số lượng lớn vào thời điểm nào?",
        "options": {
          "A": "Quý 1",
          "B": "Quý 2",
          "C": "Quý 3",
          "D": "Quý 4"
        },
        "answer": "D"
      },
      {
        "question": "Số lượng transistor gần đúng trong bộ xử lý Colossus Mk2 là bao nhiêu?",
        "options": {
          "A": "54 tỷ",
          "B": "60 tỷ",
          "C": "1.2 nghìn tỷ",
          "D": "900 triệu"
        },
        "answer": "B"
      },
      {
        "question": "Bộ xử lý nào có số lượng transistor lớn nhất được đề cập trong bài viết?",
        "options": {
          "A": "Colossus Mk2",
          "B": "Nvidia A100",
          "C": "Wafer-Scale Engine",
          "D": "Google TPU"
        },
        "answer": "C"
      },
      {
        "question": "Colossus Mk2 được trang bị bao nhiêu megabyte bộ nhớ truy cập ngẫu nhiên (RAM)?",
        "options": {
          "A": "54 MB",
          "B": "60 MB",
          "C": "900 MB",
          "D": "1200 MB"
        },
        "answer": "C"
      },
      {
        "question": "Số lượng lõi độc lập trong Colossus Mk2 là bao nhiêu?",
        "options": {
          "A": "900",
          "B": "1500",
          "C": "5400",
          "D": "9000"
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu từ MIT, Đại học Brasilia và Đại học Yonsei chỉ ra điều gì về sự phát triển của deep learning?",
        "options": {
          "A": "Sẽ phát triển vượt bậc trong tương lai gần.",
          "B": "Có thể bị đình trệ do thiếu năng lực xử lý.",
          "C": "Sẽ chuyển sang sử dụng các thuật toán mới hoàn toàn.",
          "D": "Sẽ tập trung vào các ứng dụng cụ thể hơn."
        },
        "answer": "B"
      },
      {
        "question": "Một thách thức lớn trong việc xây dựng chip được đề cập trong bài viết là gì?",
        "options": {
          "A": "Phần cứng phát triển nhanh hơn phần mềm.",
          "B": "Phần mềm phát triển nhanh hơn phần cứng.",
          "C": "Chi phí sản xuất chip quá cao.",
          "D": "Thiếu hụt nguồn cung nguyên liệu."
        },
        "answer": "B"
      },
      {
        "question": "Thiết kế của Graphcore hướng đến việc tăng tốc loại mạng nơ-ron nào?",
        "options": {
          "A": "Mạng nơ-ron tích chập (CNN)",
          "B": "Mạng nơ-ron truyền thẳng (Feedforward NN)",
          "C": "Mạng nơ-ron tái phát lớn, thưa (Large, sparse recurrent neural networks)",
          "D": "Mạng đối kháng sinh (GAN)"
        },
        "answer": "C"
      }
    ]
  },
  "new-supercomputer-on-the-block": {
    "title": "New Supercomputer on the Block",
    "collection": "hardware",
    "content": "Facebook’s parent company is staking its future on a new compute cluster.What’s new: Meta unveiledAI Research SuperCluster(RSC), which is designed to accelerate training of large models for applications like computer vision, natural language processing, and speech recognition.How it works:The company began building RSC in 2020, aiming for a system capable of training trillion-parameter models and processing up to an exabyte (1 billion gigabytes) of data. It currently incorporates 6,080 Nvidia A100s, the chip vendor’s flagship graphics processing unit (GPU).\n\nBehind the news:RSC’s emphasis on data protection has a backstory. French regulators recentlyfinedthe company $238 million for failing to allow users to disable tracking software. In September, IrelandchargedFacebook’s WhatsApp messaging service nearly $270 million for lack of transparency around how it uses the user data it collects. Those actions came after the U.S. Federal Trade Commission responded to violations of user privacy byimposinga historic $5 billion penalty as well as restrictions on the company’s structure and operations.Why it matters:Specialized in-house processing capacity is a strategic asset in the era of cloud computing. RSC is essential to Meta’s aspiration to build an immense virtual reality community it calls themetaverse.MicrosoftandNvidialikewise have built their own bespoke infrastructure.We’re thinking:Less than a decade ago, the cutting-edge AI supercomputer was a$100,000 cluster(that Andrew Ng worked on). How much bigger — and, unfortunately, less accessible — these systems have become!",
    "qa": [
      {
        "question": "Công ty mẹ của Facebook đang đầu tư vào lĩnh vực nào để đảm bảo tương lai?",
        "options": {
          "A": "Phần mềm theo dõi người dùng",
          "B": "Một cụm máy tính mới (compute cluster)",
          "C": "Dịch vụ nhắn tin WhatsApp",
          "D": "Các quy định về bảo vệ dữ liệu người dùng"
        },
        "answer": "B"
      },
      {
        "question": "AI Research SuperCluster (RSC) được thiết kế để tăng tốc quá trình huấn luyện các mô hình lớn cho những ứng dụng nào?",
        "options": {
          "A": "Phát triển phần mềm theo dõi người dùng và quảng cáo trực tuyến.",
          "B": "Xây dựng cơ sở hạ tầng đám mây và quản lý dữ liệu người dùng.",
          "C": "Thị giác máy tính, xử lý ngôn ngữ tự nhiên và nhận dạng giọng nói.",
          "D": "Phân tích dữ liệu tài chính và dự báo thị trường chứng khoán."
        },
        "answer": "C"
      },
      {
        "question": "RSC hiện tại sử dụng bao nhiêu GPU Nvidia A100?",
        "options": {
          "A": "10,000",
          "B": "3,040",
          "C": "6,080",
          "D": "12,160"
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu của Meta khi xây dựng RSC là gì?",
        "options": {
          "A": "Xây dựng một hệ thống có khả năng huấn luyện các mô hình với hàng triệu tham số.",
          "B": "Xây dựng một hệ thống có khả năng huấn luyện các mô hình với hàng tỷ tham số.",
          "C": "Xây dựng một hệ thống có khả năng huấn luyện các mô hình với hàng nghìn tỷ tham số và xử lý đến một exabyte dữ liệu.",
          "D": "Xây dựng một hệ thống có khả năng huấn luyện các mô hình với hàng trăm tỷ tham số và xử lý đến một petabyte dữ liệu."
        },
        "answer": "C"
      },
      {
        "question": "Cơ quan quản lý nào của Pháp đã phạt Meta vì không cho phép người dùng tắt phần mềm theo dõi?",
        "options": {
          "A": "Ủy ban Thương mại Liên bang Hoa Kỳ (FTC)",
          "B": "Cơ quan Bảo vệ Dữ liệu Ireland",
          "C": "Cơ quan Quản lý Truyền thông Pháp",
          "D": "Không được đề cập trong bài"
        },
        "answer": "D"
      },
      {
        "question": "WhatsApp bị phạt gần 270 triệu đô la vì lý do gì?",
        "options": {
          "A": "Vi phạm quyền riêng tư của người dùng bằng cách bán dữ liệu cho bên thứ ba.",
          "B": "Thiếu minh bạch về cách sử dụng dữ liệu người dùng thu thập được.",
          "C": "Không tuân thủ các quy định về quảng cáo trực tuyến.",
          "D": "Sử dụng thuật toán không công bằng để xếp hạng tin nhắn."
        },
        "answer": "B"
      },
      {
        "question": "Ủy ban Thương mại Liên bang Hoa Kỳ (FTC) đã phạt Meta bao nhiêu tiền vì vi phạm quyền riêng tư của người dùng?",
        "options": {
          "A": "238 triệu đô la",
          "B": "270 triệu đô la",
          "C": "1 tỷ đô la",
          "D": "5 tỷ đô la"
        },
        "answer": "D"
      },
      {
        "question": "RSC đóng vai trò quan trọng như thế nào đối với tham vọng của Meta?",
        "options": {
          "A": "Giúp Meta giảm chi phí vận hành và tăng lợi nhuận.",
          "B": "Giúp Meta xây dựng một cộng đồng thực tế ảo rộng lớn gọi là metaverse.",
          "C": "Giúp Meta cạnh tranh với các công ty công nghệ khác trong lĩnh vực quảng cáo trực tuyến.",
          "D": "Giúp Meta tuân thủ các quy định về bảo vệ dữ liệu người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài Meta, công ty nào khác cũng đã xây dựng cơ sở hạ tầng riêng biệt của họ?",
        "options": {
          "A": "Google và Amazon",
          "B": "Apple và Samsung",
          "C": "Microsoft và Nvidia",
          "D": "IBM và Oracle"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì được tác giả bài viết nhấn mạnh về sự thay đổi của siêu máy tính AI trong vòng một thập kỷ qua?",
        "options": {
          "A": "Chúng trở nên rẻ hơn và dễ tiếp cận hơn.",
          "B": "Chúng trở nên mạnh mẽ hơn và ít tốn năng lượng hơn.",
          "C": "Chúng trở nên lớn hơn và ít dễ tiếp cận hơn.",
          "D": "Chúng trở nên phức tạp hơn và yêu cầu nhiều chuyên gia hơn để vận hành."
        },
        "answer": "C"
      }
    ]
  },
  "not-your-fathers-gpu": {
    "title": "Not Your Father’s GPU",
    "collection": "hardware",
    "content": "Intel, which dominates the market for general-purpose processors, is shipping its long-awaited AI chips.What happened:The chip giantannouncedthat two so-called neural network processors are available to data-center customers.How they work:One of the new chips is intended for training deep learning models, the other for inferencing. They’redesignedto balance computational horsepower, communications speed, and memory capacity.\n\nBehind the news:While Intel chips process most AI inferencing in data centers, Nvidia leads in GPUs that speed up AI training. In 2016, Intel acquired Nervana, a startup devoted to next-generation AI chips. Meanwhile, however, the field has become crowded. Specialized designs have proliferated at a host of startups like Cerebras and tech giants like Google, while Qualcomm has been building inferencing capability into chips for low-powered devices like smartphones.Why it matters:There’s no such thing as too much processing power for machine learning. The faster we can train models, the more data we can absorb, and the faster we can innovate new network architectures and applications. And the faster users can run our models, the more value we can deliver. As for chip makers, they recognize that AI is the future: Neural networks’ voracious appetite for processing power likely will drive silicon sales for years.We’re thinking:Large cloud providers are consolidating computation, and that’s having a big impact on the chip business. Their concentrated buying power puts them in a strong position to demand lower prices. The cloud companies also want to make sure they have alternative providers of deep learning chips, so they’ll buy chips from several vendors rather than only the top one. All this is playing out against a backdrop of rapid growth of AI workloads. Expect intense competition and in the years ahead.",
    "qa": [
      {
        "question": "Công ty nào hiện đang chiếm ưu thế trên thị trường bộ vi xử lý đa năng?",
        "options": {
          "A": "Nvidia",
          "B": "Intel",
          "C": "Qualcomm",
          "D": "Cerebras"
        },
        "answer": "B"
      },
      {
        "question": "Hai loại chip mạng nơ-ron mới của Intel được thiết kế cho mục đích chính nào?",
        "options": {
          "A": "Xử lý đồ họa và chơi game",
          "B": "Đào tạo mô hình học sâu và suy luận",
          "C": "Kết nối mạng và truyền dữ liệu",
          "D": "Lưu trữ dữ liệu và quản lý bộ nhớ"
        },
        "answer": "B"
      },
      {
        "question": "Trước khi Intel tham gia thị trường chip AI, công ty nào dẫn đầu trong việc cung cấp GPU cho việc tăng tốc đào tạo AI?",
        "options": {
          "A": "Intel",
          "B": "Qualcomm",
          "C": "Nvidia",
          "D": "Google"
        },
        "answer": "C"
      },
      {
        "question": "Công ty Nervana, chuyên về chip AI thế hệ mới, đã được mua lại bởi công ty nào?",
        "options": {
          "A": "Google",
          "B": "Qualcomm",
          "C": "Nvidia",
          "D": "Intel"
        },
        "answer": "D"
      },
      {
        "question": "Ngoài Intel và Nvidia, công ty nào đang tích hợp khả năng suy luận AI vào chip cho các thiết bị công suất thấp như điện thoại thông minh?",
        "options": {
          "A": "Cerebras",
          "B": "Google",
          "C": "Qualcomm",
          "D": "Nervana"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì sẽ thúc đẩy doanh số bán dẫn trong những năm tới?",
        "options": {
          "A": "Sự phát triển của công nghệ blockchain",
          "B": "Nhu cầu xử lý của mạng nơ-ron cho AI",
          "C": "Sự gia tăng của các thiết bị IoT",
          "D": "Sự phổ biến của thực tế ảo và thực tế tăng cường"
        },
        "answer": "B"
      },
      {
        "question": "Các nhà cung cấp dịch vụ đám mây lớn có lợi thế gì trong thị trường chip AI?",
        "options": {
          "A": "Sở hữu công nghệ sản xuất chip tiên tiến nhất",
          "B": "Khả năng mua hàng tập trung, tạo áp lực giảm giá",
          "C": "Độc quyền các bằng sáng chế về AI",
          "D": "Quan hệ đối tác độc quyền với các nhà thiết kế chip hàng đầu"
        },
        "answer": "B"
      },
      {
        "question": "Điều gì được dự đoán sẽ xảy ra trong những năm tới liên quan đến thị trường chip AI?",
        "options": {
          "A": "Sự độc quyền của một vài công ty lớn",
          "B": "Sự suy giảm nhu cầu về chip xử lý AI",
          "C": "Sự cạnh tranh gay gắt giữa các nhà sản xuất",
          "D": "Sự hợp tác chặt chẽ giữa các công ty công nghệ"
        },
        "answer": "C"
      },
      {
        "question": "Một trong những mục tiêu thiết kế của chip mạng nơ-ron mới của Intel là gì?",
        "options": {
          "A": "Tối đa hóa kích thước vật lý của chip",
          "B": "Cân bằng giữa sức mạnh tính toán, tốc độ truyền thông và dung lượng bộ nhớ",
          "C": "Giảm thiểu chi phí sản xuất",
          "D": "Tăng cường khả năng chống chịu nhiệt độ cao"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì sẽ xảy ra khi chúng ta có thể đào tạo mô hình nhanh hơn và hấp thụ nhiều dữ liệu hơn?",
        "options": {
          "A": "Giá chip sẽ tăng cao hơn",
          "B": "Chúng ta có thể đổi mới các kiến trúc và ứng dụng mạng mới nhanh hơn",
          "C": "Các công ty nhỏ sẽ khó cạnh tranh hơn",
          "D": "Nguồn cung chip sẽ trở nên khan hiếm hơn"
        },
        "answer": "B"
      }
    ]
  },
  "nvidia-amd-amazon-and-others-strike-deals-with-saudi-arabias-humain-and-g42-in-the-uae": {
    "title": "U.S. to Supply Middle Eastern AI Hubs",
    "collection": "hardware",
    "content": "The United States government announced sweeping agreements to sell tens of billions of dollars worth of AI technology and services to Saudi Arabia and the United Arab Emirates.\n\nWhat’s new:Thedealsinclude the U.S. AI chip designers AMD and Nvidia as well as tech giants Amazon, Google, IBM, Oracle, and Qualcomm. The chip companies willsupplyhundreds of thousands of advanced chips to the two Middle Eastern countries, including chips that have been restricted by previous U.S. administrations.\n\nHow it works:The U.S. companies will work with two key regional partners:Humain, an AI company backed by the Saudi government, andG42, a tech conglomerate based in the emirate of Abu Dhabi.\n\nBehind the news:Earlier this month, the Trump administrationrescindedrestrictions on advanced chips that had been imposed in January by then-President Biden.\n\nWhy it matters:Although these deals relax U.S. efforts to limit access to advanced AI, they are likely to expand U.S. influence in the Middle East while helping Saudi Arabia and the UAE diversify their oil-based economies. They also strengthen the technological prowess of Saudi Arabia relative to its arch rival Iran and tie the region’s AI progress to the U.S. at the expense of China. Locally, the immense investments will fuel homegrown technology development, building on the UAE’s achievement with itsFalconlarge language model and Saudi Arabia’saspirationto become a global AI hub.\n\nWe’re thinking:Residents of Saudi Arabia and the UAE stand to benefit from better AI infrastructure, models, and services. As Chinaexploresexporting its homegrown chips, the U.S. effort to encourage more nations to use its chips makes sense for the country.",
    "qa": [
      {
        "question": "Chính phủ Hoa Kỳ đã công bố thỏa thuận bán công nghệ và dịch vụ AI trị giá hàng chục tỷ đô la cho quốc gia nào?",
        "options": {
          "A": "Iran và Iraq",
          "B": "Ả Rập Xê Út và Các Tiểu vương quốc Ả Rập Thống nhất",
          "C": "Israel và Ai Cập",
          "D": "Qatar và Kuwait"
        },
        "answer": "B"
      },
      {
        "question": "Những công ty thiết kế chip AI nào của Hoa Kỳ tham gia vào các thỏa thuận này?",
        "options": {
          "A": "Intel và Micron",
          "B": "AMD và Nvidia",
          "C": "Texas Instruments và Broadcom",
          "D": "Qualcomm và Intel"
        },
        "answer": "B"
      },
      {
        "question": "Công ty AI nào được chính phủ Ả Rập Xê Út hậu thuẫn và tham gia vào các thỏa thuận này?",
        "options": {
          "A": "G42",
          "B": "Humain",
          "C": "Aramco Digital",
          "D": "STC Solutions"
        },
        "answer": "B"
      },
      {
        "question": "Tập đoàn công nghệ nào có trụ sở tại Abu Dhabi tham gia vào các thỏa thuận này?",
        "options": {
          "A": "Humain",
          "B": "ADNOC",
          "C": "G42",
          "D": "Mubadala"
        },
        "answer": "C"
      },
      {
        "question": "Chính quyền nào đã dỡ bỏ các hạn chế đối với chip tiên tiến được áp đặt trước đó?",
        "options": {
          "A": "Chính quyền Obama",
          "B": "Chính quyền Biden",
          "C": "Chính quyền Trump",
          "D": "Chính quyền Bush"
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu chính của Ả Rập Xê Út và UAE khi đầu tư vào AI là gì?",
        "options": {
          "A": "Tăng cường sức mạnh quân sự",
          "B": "Đa dạng hóa nền kinh tế dựa trên dầu mỏ",
          "C": "Cạnh tranh với các quốc gia châu Âu",
          "D": "Phát triển du lịch vũ trụ"
        },
        "answer": "B"
      },
      {
        "question": "Các thỏa thuận này có khả năng ảnh hưởng đến mối quan hệ giữa Ả Rập Xê Út và quốc gia nào?",
        "options": {
          "A": "Syria",
          "B": "Iran",
          "C": "Yemen",
          "D": "Iraq"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình ngôn ngữ lớn Falcon là thành tựu công nghệ của quốc gia nào?",
        "options": {
          "A": "Ả Rập Xê Út",
          "B": "Qatar",
          "C": "Các Tiểu vương quốc Ả Rập Thống nhất",
          "D": "Kuwait"
        },
        "answer": "C"
      },
      {
        "question": "Tham vọng của Ả Rập Xê Út trong lĩnh vực AI là gì?",
        "options": {
          "A": "Trở thành nhà xuất khẩu dầu mỏ hàng đầu về AI",
          "B": "Trở thành trung tâm AI toàn cầu",
          "C": "Phát triển vũ khí AI tiên tiến",
          "D": "Xây dựng thành phố thông minh hoàn toàn tự động"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, việc Hoa Kỳ khuyến khích nhiều quốc gia sử dụng chip của mình có ý nghĩa gì trong bối cảnh cạnh tranh với Trung Quốc?",
        "options": {
          "A": "Giúp Trung Quốc tiếp cận công nghệ tiên tiến",
          "B": "Ngăn chặn Trung Quốc xuất khẩu chip nội địa",
          "C": "Thúc đẩy hợp tác công nghệ giữa Hoa Kỳ và Trung Quốc",
          "D": "Không ảnh hưởng đến Trung Quốc"
        },
        "answer": "B"
      }
    ]
  },
  "nvidia-introduced-project-digits-a-3-000-home-supercomputer-for-mid-sized-ai-models": {
    "title": "AI Supercomputer on Your Desk",
    "collection": "hardware",
    "content": "Nvidia’s new desktop computer is built specifically to run AI models.\n\nWhat’s new:Project Digitsis a personal supercomputer intended to help developers fine-tune and run models locally. Project Digits, which is small enough to hold in one hand, will be available in May, starting at $3000.\n\nHow it works:Project Digits is designed to run models of up to 200 billion parameters — roughly five times the size that fits comfortably on typical consumer hardware — provided they’re quantized to 4 bits of precision. Two units can be connected to run models such as Meta’s Llama 3.1 405B. Complete specifications are not yet available.\n\nBehind the news:In a blitz of announcements at the Consumer Electronics Show (CES), Nvidia also launched a platform for developing robotics, autonomous vehicles, and other physical AI systems. Cosmos includes pretrained language and vision models that range from 4 billion to 14 billion parameters for generating synthetic training data for robots or building policy models that translate a robot’s state into its next action. Nvidia also released Cosmos Nemotron, a 34 billion-parameter, vision-language model designed for use by AI agents, plus a video tokenizer and other tools for robotics developers.\n\nWhy it matters:It’s common to train models on Nvidia A100 or H100 GPUs, which come with a price tag of at least $8,000 or $20,000 respectively, along with 40 gigabytes to 80 gigabytes of memory. These hefty requirements push many developers to buy access to computing infrastructure from a cloud provider. Coming in at $3,000 with 128 gigabytes of memory, Project Digits is designed to empower machine learning engineers to train and run larger models on their own machines.\n\nWe’re thinking:We look forward to seeing cost/throughput comparisons between running a model on Project Digits, A100, and H100.",
    "qa": [
      {
        "question": "Project Digits của Nvidia được thiết kế chủ yếu để làm gì?",
        "options": {
          "A": "Chơi game đồ họa cao cấp.",
          "B": "Chạy các mô hình AI cục bộ và tinh chỉnh chúng.",
          "C": "Thiết kế và phát triển phần cứng máy tính.",
          "D": "Kết nối và quản lý các thiết bị IoT."
        },
        "answer": "B"
      },
      {
        "question": "Project Digits dự kiến sẽ được bán ra vào thời điểm nào và với mức giá khởi điểm là bao nhiêu?",
        "options": {
          "A": "Tháng 4, $2000.",
          "B": "Tháng 5, $3000.",
          "C": "Tháng 6, $4000.",
          "D": "Tháng 7, $5000."
        },
        "answer": "B"
      },
      {
        "question": "Với độ chính xác 4 bit, Project Digits có thể chạy các mô hình có kích thước tối đa là bao nhiêu?",
        "options": {
          "A": "50 tỷ tham số.",
          "B": "100 tỷ tham số.",
          "C": "200 tỷ tham số.",
          "D": "400 tỷ tham số."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình nào được đề cập trong bài viết có thể chạy trên hai đơn vị Project Digits được kết nối?",
        "options": {
          "A": "GPT-3.",
          "B": "Llama 2.",
          "C": "Llama 3.1 405B.",
          "D": "BERT."
        },
        "answer": "C"
      },
      {
        "question": "Cosmos của Nvidia là một nền tảng dành cho việc phát triển các hệ thống nào?",
        "options": {
          "A": "Hệ thống quản lý cơ sở dữ liệu.",
          "B": "Hệ thống robotics, xe tự hành và các hệ thống AI vật lý khác.",
          "C": "Hệ thống thương mại điện tử.",
          "D": "Hệ thống mạng xã hội."
        },
        "answer": "B"
      },
      {
        "question": "Cosmos bao gồm các mô hình ngôn ngữ và thị giác được huấn luyện trước với số lượng tham số dao động từ bao nhiêu đến bao nhiêu?",
        "options": {
          "A": "1 tỷ đến 5 tỷ tham số.",
          "B": "2 tỷ đến 10 tỷ tham số.",
          "C": "4 tỷ đến 14 tỷ tham số.",
          "D": "8 tỷ đến 20 tỷ tham số."
        },
        "answer": "C"
      },
      {
        "question": "Cosmos Nemotron là một mô hình thị giác-ngôn ngữ với bao nhiêu tham số?",
        "options": {
          "A": "17 tỷ tham số.",
          "B": "24 tỷ tham số.",
          "C": "34 tỷ tham số.",
          "D": "48 tỷ tham số."
        },
        "answer": "C"
      },
      {
        "question": "GPU Nvidia A100 có dung lượng bộ nhớ tối thiểu là bao nhiêu?",
        "options": {
          "A": "16 gigabyte.",
          "B": "32 gigabyte.",
          "C": "40 gigabyte.",
          "D": "64 gigabyte."
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích chính của Project Digits so với việc sử dụng các GPU A100 hoặc H100 là gì?",
        "options": {
          "A": "Hiệu suất tính toán cao hơn.",
          "B": "Giá thành rẻ hơn và cho phép chạy các mô hình lớn trên máy cá nhân.",
          "C": "Khả năng tương thích với nhiều hệ điều hành hơn.",
          "D": "Tiêu thụ điện năng thấp hơn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến việc so sánh điều gì giữa Project Digits, A100 và H100?",
        "options": {
          "A": "Kích thước vật lý.",
          "B": "Khả năng tương thích với các framework AI.",
          "C": "Chi phí/thông lượng khi chạy mô hình.",
          "D": "Độ ồn khi hoạt động."
        },
        "answer": "C"
      }
    ]
  },
  "p0-a-machine-learning-system-for-household-robotics": {
    "title": "Household Help",
    "collection": "hardware",
    "content": "A new generation of robots can handle some household chores with unusual skill.\n\nWhat’s new:Physical Intelligence, a startup based in San Francisco, unveiledπ0(pronounced “pi-zero”), a machine learning system that enables robots to perform housekeeping tasks that require high coordination and dexterity, like folding clothes and cleaning tables. The company alsoannounced$400 million in investments from OpenAI, Jeff Bezos, and several Silicon Valley venture capital firms.\n\nHow it works:π0 is a version of the pretrainedPaliGemmavision-language model that has been modified forflow matching. (Flow matching is similar to diffusion, in which a model learns to remove noise from inputs to which noise has been added, and ultimately generates output by removing noise from an input of pure noise). A user supplies a text command, and the robot uses its sensor inputs to remove noise from a pure-noise action embedding to generate an appropriate action.\n\nResults:π0 outperformed the open robotics modelsOpenVLA,Octo,ACT, andDiffusion Policy, all of which were fine-tuned on the same data, on all tasks tested, as measured by a robot’s success rate in completing each task. For example, using a single robotic arm to stack a set of bowls of four sizes, π0 completed about 100 percent on average. Diffusion Policy completed about 55 percent, ACT about 45 percent, and OpenVLA and Octo below 10 percent. Across all tasks, π0 completed about 80 percent on average, while Diffusion Policy completed about 35 percent on average.\n\nYes, but:The robot occasionally makesmistakes. In one video, it puts too many eggs into a carton and tries to force it shut. In another, it throws a container off a table instead of filling it with items.\n\nBehind the news:Commercial robotics appears to be undergoing a renaissance. Skildraised$300 million to develop a “general-purpose brain for robots.” Figure AIsecured$675 million to build humanoid robots powered by multimodal models. Covariant, which specializes in industrial robotics,licensedits technology to Amazon. (Disclosure: Andrew Ng is a member of Amazon's board of directors). OpenAIrenewedits robotics effort afterdismantlingits robotics department in 2020.\n\nWhy it matters:Robots have been slow to benefit from machine learning, but the generative AI revolution is driving rapid innovations that make them much more useful. Large language models have made it possible to command robots using plain English. Meanwhile, the team at Physical Intelligence collected a dataset of sufficient size and variety to train the model to generate highly articulated and practical actions. Household robots may not be right around the corner, but π0 shows that they can perform tasks that people need done.\n\nWe’re thinking:One of the team members compared π0 to GPT-1 for robotics — an inkling of things to come. Although there are significant differences between text data (which is available in large quantities) and robot data (which is hard to get and varies per robot), it looks like a new era of large robotics foundation models is dawning.",
    "qa": [
      {
        "question": "Công ty Physical Intelligence đã giới thiệu hệ thống máy học nào?",
        "options": {
          "A": "OpenVLA",
          "B": "π0 (pi-zero)",
          "C": "Octo",
          "D": "Diffusion Policy"
        },
        "answer": "B"
      },
      {
        "question": "π0 được phát triển dựa trên phiên bản nào của mô hình ngôn ngữ-thị giác đã được huấn luyện trước?",
        "options": {
          "A": "GPT-1",
          "B": "PaliGemma",
          "C": "ACT",
          "D": "Skild"
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp 'flow matching' mà π0 sử dụng tương tự với phương pháp nào?",
        "options": {
          "A": "Hồi quy tuyến tính",
          "B": "Phân loại nhị phân",
          "C": "Khuếch tán (diffusion)",
          "D": "Mạng nơ-ron tích chập"
        },
        "answer": "C"
      },
      {
        "question": "Trong thử nghiệm xếp chồng bát, π0 đạt tỷ lệ hoàn thành trung bình khoảng bao nhiêu phần trăm?",
        "options": {
          "A": "55%",
          "B": "45%",
          "C": "100%",
          "D": "Dưới 10%"
        },
        "answer": "C"
      },
      {
        "question": "Một trong những lỗi mà robot sử dụng π0 mắc phải được đề cập trong bài viết là gì?",
        "options": {
          "A": "Không thể di chuyển đồ vật",
          "B": "Làm đổ đồ ăn",
          "C": "Cho quá nhiều trứng vào hộp và cố gắng đóng lại",
          "D": "Không thể nhận diện đồ vật"
        },
        "answer": "C"
      },
      {
        "question": "Công ty Skild đã huy động được bao nhiêu tiền để phát triển 'bộ não đa năng cho robot'?",
        "options": {
          "A": "$400 triệu",
          "B": "$675 triệu",
          "C": "$300 triệu",
          "D": "$100 triệu"
        },
        "answer": "C"
      },
      {
        "question": "Công ty Figure AI tập trung vào việc xây dựng loại robot nào?",
        "options": {
          "A": "Robot công nghiệp",
          "B": "Robot hình người (humanoid)",
          "C": "Robot hút bụi",
          "D": "Robot phẫu thuật"
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã giúp robot hưởng lợi từ máy học trong thời gian gần đây?",
        "options": {
          "A": "Sự phát triển của cảm biến",
          "B": "Sự ra đời của robot hình người",
          "C": "Cuộc cách mạng AI tạo sinh (generative AI)",
          "D": "Sự gia tăng của dữ liệu robot"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì cho phép người dùng điều khiển robot bằng ngôn ngữ tự nhiên?",
        "options": {
          "A": "Cảm biến tiên tiến",
          "B": "Mô hình ngôn ngữ lớn (Large language models)",
          "C": "Phần cứng mạnh mẽ",
          "D": "Kết nối internet tốc độ cao"
        },
        "answer": "B"
      },
      {
        "question": "Một thành viên trong nhóm phát triển π0 đã so sánh nó với mô hình nào trong lĩnh vực xử lý ngôn ngữ tự nhiên?",
        "options": {
          "A": "GPT-3",
          "B": "BERT",
          "C": "GPT-1",
          "D": "Word2Vec"
        },
        "answer": "C"
      }
    ]
  },
  "quantum-leap-2": {
    "title": "Quantum Leap",
    "collection": "hardware",
    "content": "Quantum computing has made great strides in recent years, though it still faces significantchallenges. If and when it gets here, machine learning may be ready for it.What’s new:TensorFlow Quantumis a platform for building, training, and deploying neural networks on quantum processors. It was developed by Alphabet, Volkswagen, and the University of Waterloo.How it works:The software works withquantum hardwarelike Google’s Sycamore computer, which has 54 qubits. Each qubit processes multiple calculations at once, theoretically enabling such systems to vastly outperform conventional CPUs.\n\nWhy it matters:Imagine that, instead of living one life, you could live billions of lives simultaneously, and at the end, you would have learned from all of them. Quantum speedups can be enormous for operations in which a single quantum computer can outperform the fastest supercomputer (that is, millions of classical computers working together). Machine learning could be one of those operations.\n\nYes, but:It may be a while before quantum computing is practical outside of research labs. Among other challenges, quantum systems are sosensitivethat the noise they generate can derail their calculations.\n\nBehind the news:Last year, Google claimed that Sycamore had achieved so-calledquantum supremacyby performing a calculation that it deemed impractical for a classical supercomputer. IBMchallengedthe claim by solving the problem using conventional technology. The two tech giants, which are vying for leadership in the field, remain at loggerheads.We’re thinking:Tech giants are always on the lookout for disruptions that may threaten their business. By creating tools for developers, they’re positioning themselves for a quantum future whether or not it arrives. Meanwhile, machine learning engineers have a shiny new toy to play with!",
    "qa": [
      {
        "question": "TensorFlow Quantum là một nền tảng được sử dụng để làm gì?",
        "options": {
          "A": "Phát triển phần cứng máy tính lượng tử.",
          "B": "Xây dựng, huấn luyện và triển khai mạng nơ-ron trên bộ xử lý lượng tử.",
          "C": "Mô phỏng các thí nghiệm vật lý lượng tử.",
          "D": "Nghiên cứu các thuật toán mã hóa lượng tử."
        },
        "answer": "B"
      },
      {
        "question": "Tổ chức nào KHÔNG tham gia phát triển TensorFlow Quantum?",
        "options": {
          "A": "Alphabet",
          "B": "Volkswagen",
          "C": "IBM",
          "D": "University of Waterloo"
        },
        "answer": "C"
      },
      {
        "question": "Máy tính Sycamore của Google có bao nhiêu qubit?",
        "options": {
          "A": "64",
          "B": "32",
          "C": "54",
          "D": "128"
        },
        "answer": "C"
      },
      {
        "question": "Ưu điểm lý thuyết của máy tính lượng tử so với CPU thông thường là gì?",
        "options": {
          "A": "Tiêu thụ ít năng lượng hơn.",
          "B": "Xử lý nhiều phép tính đồng thời.",
          "C": "Kích thước nhỏ gọn hơn.",
          "D": "Giá thành rẻ hơn."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao máy tính lượng tử vẫn chưa được sử dụng rộng rãi bên ngoài phòng thí nghiệm?",
        "options": {
          "A": "Chi phí sản xuất quá cao.",
          "B": "Yêu cầu kỹ năng lập trình phức tạp.",
          "C": "Độ nhạy cao với nhiễu.",
          "D": "Thiếu các thuật toán phù hợp."
        },
        "answer": "C"
      },
      {
        "question": "Google tuyên bố Sycamore đã đạt được 'quantum supremacy' bằng cách nào?",
        "options": {
          "A": "Giải mã một thuật toán mã hóa phức tạp.",
          "B": "Thực hiện một phép tính mà siêu máy tính cổ điển không thể thực hiện được trong thời gian hợp lý.",
          "C": "Phát triển một loại qubit mới ổn định hơn.",
          "D": "Tạo ra một mạng lưới máy tính lượng tử toàn cầu."
        },
        "answer": "B"
      },
      {
        "question": "IBM đã phản bác tuyên bố 'quantum supremacy' của Google như thế nào?",
        "options": {
          "A": "Chứng minh rằng Sycamore đã đưa ra kết quả sai.",
          "B": "Giải quyết cùng một vấn đề bằng công nghệ thông thường.",
          "C": "Phát triển một máy tính lượng tử mạnh hơn Sycamore.",
          "D": "Chỉ ra những sai sót trong phương pháp đo lường của Google."
        },
        "answer": "B"
      },
      {
        "question": "Các công ty công nghệ lớn đang làm gì để chuẩn bị cho tương lai lượng tử?",
        "options": {
          "A": "Đầu tư vào khai thác tài nguyên cần thiết cho máy tính lượng tử.",
          "B": "Tạo ra các công cụ cho nhà phát triển.",
          "C": "Mua lại các công ty khởi nghiệp về máy tính lượng tử.",
          "D": "Vận động chính phủ hỗ trợ nghiên cứu và phát triển."
        },
        "answer": "B"
      },
      {
        "question": "Lĩnh vực nào có thể hưởng lợi lớn từ tốc độ tính toán của máy tính lượng tử?",
        "options": {
          "A": "Năng lượng tái tạo.",
          "B": "Y học.",
          "C": "Học máy (Machine Learning).",
          "D": "Nông nghiệp."
        },
        "answer": "C"
      },
      {
        "question": "Cụm từ 'quantum supremacy' có nghĩa là gì?",
        "options": {
          "A": "Sự thống trị của máy tính lượng tử về mặt kích thước.",
          "B": "Khả năng của máy tính lượng tử trong việc giải quyết mọi vấn đề.",
          "C": "Khả năng của máy tính lượng tử trong việc thực hiện một phép tính mà máy tính cổ điển không thể thực hiện được trong thời gian hợp lý.",
          "D": "Sự vượt trội của máy tính lượng tử về mặt giá cả."
        },
        "answer": "C"
      }
    ]
  },
  "researchers-describe-training-methods-and-hardware-choices-for-deepseeks-v3-and-r1-models": {
    "title": "How DeepSeek Did It",
    "collection": "hardware",
    "content": "DeepSeek made headlines late last year, when it built a state-of-the-art, open-weights large language model at a cost far lower than usual. The upstart developer shared new details about its method.\n\nWhat’s new:Chenggang Zhao and colleagues at DeepSeek describedsoftware and hardware choicesthat reduced memory and processing requirements while building their groundbreaking mixture-of-experts models DeepSeek-R1 and DeepSeek-V3.\n\nMixture of experts (MoE) basics:The MoE architecture uses different subsets of a model’s parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a routing module that learns to choose which one(s) to use based on the training example. In this way, different experts learn to specialize in different types of input.\n\nHow it works:The authors trained DeepSeek-R1 and DeepSeek-V3 using a cluster of 2,048 Nvidia H800 GPUs composed of nodes that contained 8 GPUs each. MoE requires less memory than dense architectures, since a given input activates only a portion of a model’s parameters. This enabled the authors to train DeepSeek-V3 on 250 GFLOPs per token, while Qwen 2.5 72B required 394 GFLOPs per token and Llama 3.1 405B required 2,448 GFLOPs per token.\n\nBehind the news:DeepSeek-V3made waves when it was released in December. It performed better than Llama 3.1 405B, the leading LLM at the time, but its training cost was an astonishing $5.6 million, compared to the usual tens to hundreds of millions of dollars. Some observers wereskepticalof the reported cost, pointing out that the $5.6 million dollar figure doesn’t include salaries, data acquisition and annotation, processing failed training runs, and other research and development costs. In addition, the cost of trainingDeepSeek-R1remains unknown.\n\nWhy it matters:Traditionally, only companies with large budgets and vast resources could afford to train state-of-the-art models. DeepSeek changed that but didn’t explain how when it released its models. By sharing the details, the company has empowered a wider range of teams to improve the state of the art.\n\nWe’re thinking:Shortly after DeepSeek-R1 was released, some engineers claimed — without presenting evidence — that DeepSeek had copied their work. DeepSeek’s disclosure of its training methods should lay to rest any remaining questions about this. Its work was truly innovative, and we applaud its release of key technical details.",
    "qa": [
      {
        "question": "Công ty DeepSeek đã gây chú ý vào cuối năm ngoái nhờ điều gì?",
        "options": {
          "A": "Phát triển một mô hình ngôn ngữ lớn với số lượng tham số vượt trội so với các đối thủ.",
          "B": "Xây dựng một mô hình ngôn ngữ lớn mã nguồn mở, hiện đại với chi phí thấp hơn nhiều so với thông thường.",
          "C": "Hợp tác với Nvidia để phát triển phần cứng chuyên dụng cho việc huấn luyện mô hình ngôn ngữ lớn.",
          "D": "Công bố một phương pháp mới để đánh giá hiệu suất của các mô hình ngôn ngữ lớn."
        },
        "answer": "B"
      },
      {
        "question": "Kiến trúc Mixture of Experts (MoE) hoạt động như thế nào?",
        "options": {
          "A": "Sử dụng tất cả các tham số của mô hình để xử lý mọi đầu vào, đảm bảo tính chính xác cao nhất.",
          "B": "Sử dụng các tập con khác nhau của tham số mô hình để xử lý các đầu vào khác nhau.",
          "C": "Chia nhỏ mô hình thành nhiều phần nhỏ hơn và huấn luyện chúng song song để tăng tốc độ.",
          "D": "Sử dụng một mạng nơ-ron duy nhất để xử lý mọi đầu vào, nhưng điều chỉnh trọng số của nó dựa trên loại đầu vào."
        },
        "answer": "B"
      },
      {
        "question": "DeepSeek-R1 và DeepSeek-V3 được huấn luyện bằng cách sử dụng cụm bao nhiêu GPU Nvidia H800?",
        "options": {
          "A": "1024",
          "B": "2048",
          "C": "4096",
          "D": "8192"
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm chính của kiến trúc MoE so với kiến trúc dày đặc (dense) là gì?",
        "options": {
          "A": "Yêu cầu bộ nhớ lớn hơn để lưu trữ các tham số.",
          "B": "Yêu cầu ít bộ nhớ hơn vì chỉ một phần tham số được kích hoạt cho mỗi đầu vào.",
          "C": "Tăng tốc độ huấn luyện nhờ khả năng xử lý song song tốt hơn.",
          "D": "Cải thiện độ chính xác của mô hình nhờ sử dụng nhiều tham số hơn."
        },
        "answer": "B"
      },
      {
        "question": "Chi phí huấn luyện DeepSeek-V3 được báo cáo là bao nhiêu?",
        "options": {
          "A": "5.6 triệu đô la.",
          "B": "56 triệu đô la.",
          "C": "560 triệu đô la.",
          "D": "Chưa được công bố."
        },
        "answer": "A"
      },
      {
        "question": "Một trong những lý do khiến chi phí huấn luyện DeepSeek-V3 gây tranh cãi là gì?",
        "options": {
          "A": "Nó bao gồm chi phí mua phần cứng mới nhất từ Nvidia.",
          "B": "Nó không bao gồm các chi phí như lương nhân viên, thu thập và chú thích dữ liệu.",
          "C": "Nó được tài trợ hoàn toàn bởi các nhà đầu tư tư nhân.",
          "D": "Nó sử dụng một phương pháp huấn luyện hoàn toàn mới và chưa được kiểm chứng."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của DeepSeek khi chia sẻ chi tiết về phương pháp huấn luyện của họ là gì?",
        "options": {
          "A": "Để thu hút thêm sự chú ý từ giới truyền thông.",
          "B": "Để chứng minh rằng họ không sao chép công việc của người khác.",
          "C": "Để trao quyền cho nhiều nhóm hơn cải thiện trình độ kỹ thuật.",
          "D": "Để cạnh tranh trực tiếp với các công ty lớn như Google và OpenAI."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì đã xảy ra sau khi DeepSeek-R1 được phát hành?",
        "options": {
          "A": "DeepSeek đã bị kiện vì vi phạm bản quyền.",
          "B": "Một số kỹ sư tuyên bố DeepSeek đã sao chép công việc của họ.",
          "C": "DeepSeek đã được mua lại bởi một công ty công nghệ lớn.",
          "D": "DeepSeek đã giành được giải thưởng về đổi mới công nghệ."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì đã giúp DeepSeek-V3 đạt được hiệu suất tốt hơn Llama 3.1 405B với chi phí thấp hơn?",
        "options": {
          "A": "Sử dụng một tập dữ liệu huấn luyện lớn hơn và đa dạng hơn.",
          "B": "Sử dụng kiến trúc MoE giúp giảm yêu cầu bộ nhớ và tính toán.",
          "C": "Sử dụng một thuật toán tối ưu hóa mới và hiệu quả hơn.",
          "D": "Sử dụng phần cứng mạnh mẽ hơn từ Nvidia."
        },
        "answer": "B"
      },
      {
        "question": "GFLOPs per token là gì và nó được sử dụng để đo lường điều gì trong bài viết?",
        "options": {
          "A": "Số lượng tham số trong mô hình ngôn ngữ.",
          "B": "Tốc độ xử lý dữ liệu của GPU.",
          "C": "Chi phí tính toán cần thiết để xử lý một token trong quá trình huấn luyện.",
          "D": "Độ chính xác của mô hình ngôn ngữ trên một tập dữ liệu kiểm tra."
        },
        "answer": "C"
      }
    ]
  },
  "researchers-used-deep-learning-and-an-evolutionary-algorithm-to-design-chips-in-minutes": {
    "title": "Generated Chip Designs Work in Mysterious Ways",
    "collection": "hardware",
    "content": "Designing integrated circuits typically requires years of human expertise. Recent work set AI to the task with surprising results.\n\nWhat’s new:Emir Ali Karahan, Zheng Liu, Aggraj Gupta, and colleagues at Princeton and Indian Institute of Technology Madras used deep learning and an evolutionary algorithm, which generates variations and tests their fitness, togenerate designsfor antennas, filters, power splitters, resonators, and other chips with applications in wireless communications and other applications. They fabricated a handful of the generated designs and found they worked — but in mysterious ways.\n\nHow it works:The authors trained convolutional neural networks (CNNs), given a binary image of a circuit design (in which each pixel represents whether the corresponding portion of a semiconductor surface is raised or lowered), to predict its electromagneticscattering propertiesandradiative properties. Based on this simulation, they generated new binary circuit images using evolution.\n\nResults:The authors fabricated some of the designs to test their real-world properties. The chips showed similar performance than the CNNs had predicted. The authors found the designs themselves baffling; they “delivered stunning high-performances devices that ran counter to the usual rules of thumb and human intuition,” co-author Uday Khankhojetoldthe tech news site Tech Xplore. Moreover, the design process was faster than previous approaches. The authors’ method designed a 300x300 micrometer chip in approximately 6 minutes. Using traditional methods it would have taken 21 days.\n\nBehind the news:Rather than wireless chips, Google has used AI toacceleratedesign of the Tensor Processing Units that process neural networks in its data centers.AlphaChipused reinforcement learning to learn how to position chip components such as SRAM and logic gates on silicon.\n\nWhy it matters:Designing circuits usually requires rules of thumb, templates, and hundreds of hours of simulations and experiments to determine the best design. AI can cut the required expertise and time and possibly find effective designs that wouldn’t occur to human designers.\n\nWe’re thinking:AI-generated circuit designs could help circuit designers to break out of set ways of thinking and discover new design principles.",
    "qa": [
      {
        "question": "Phương pháp mới được đề cập trong bài viết sử dụng những kỹ thuật AI nào để thiết kế mạch tích hợp?",
        "options": {
          "A": "Mạng nơ-ron hồi quy (RNN) và thuật toán di truyền.",
          "B": "Mạng nơ-ron tích chập (CNN) và thuật toán di truyền.",
          "C": "Mạng nơ-ron lan truyền ngược (BPNN) và thuật toán di truyền.",
          "D": "Mạng nơ-ron đối kháng (GAN) và thuật toán di truyền."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã sử dụng phương pháp AI để thiết kế những loại chip nào?",
        "options": {
          "A": "Bộ vi xử lý trung tâm (CPU) và bộ nhớ truy cập ngẫu nhiên (RAM).",
          "B": "Anten, bộ lọc, bộ chia công suất, bộ cộng hưởng và các chip khác cho truyền thông không dây.",
          "C": "Cảm biến hình ảnh và bộ khuếch đại âm thanh.",
          "D": "Bộ điều khiển logic khả trình (PLC) và vi điều khiển."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích của việc huấn luyện mạng nơ-ron tích chập (CNN) trong nghiên cứu này là gì?",
        "options": {
          "A": "Để tạo ra hình ảnh mạch mới dựa trên các thuộc tính vật lý.",
          "B": "Để dự đoán các thuộc tính tán xạ điện từ và bức xạ của một thiết kế mạch.",
          "C": "Để tối ưu hóa bố cục của các thành phần trên chip.",
          "D": "Để kiểm tra tính chính xác của các thiết kế mạch hiện có."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, thời gian cần thiết để thiết kế một chip 300x300 micrometer bằng phương pháp AI là bao lâu?",
        "options": {
          "A": "21 ngày.",
          "B": "6 giờ.",
          "C": "6 phút.",
          "D": "21 giờ."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì khiến các nhà nghiên cứu ngạc nhiên về các thiết kế chip do AI tạo ra?",
        "options": {
          "A": "Chúng có kích thước nhỏ hơn nhiều so với các thiết kế truyền thống.",
          "B": "Chúng hoạt động theo những cách trái ngược với các quy tắc thông thường và trực giác của con người.",
          "C": "Chúng có giá thành sản xuất rẻ hơn đáng kể.",
          "D": "Chúng dễ dàng tích hợp vào các hệ thống hiện có."
        },
        "answer": "B"
      },
      {
        "question": "Google đã sử dụng AI để tăng tốc thiết kế loại chip nào?",
        "options": {
          "A": "Bộ xử lý đồ họa (GPU).",
          "B": "Bộ xử lý tín hiệu số (DSP).",
          "C": "Bộ xử lý Tensor (TPU).",
          "D": "Bộ vi điều khiển (MCU)."
        },
        "answer": "C"
      },
      {
        "question": "AlphaChip sử dụng phương pháp học máy nào để bố trí các thành phần chip?",
        "options": {
          "A": "Học có giám sát.",
          "B": "Học không giám sát.",
          "C": "Học tăng cường.",
          "D": "Học bán giám sát."
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích chính của việc sử dụng AI trong thiết kế mạch là gì?",
        "options": {
          "A": "Giảm chi phí sản xuất chip.",
          "B": "Tăng cường bảo mật cho các thiết kế chip.",
          "C": "Giảm thời gian thiết kế và có thể tìm ra các thiết kế hiệu quả mà con người không nghĩ ra.",
          "D": "Đơn giản hóa quy trình sản xuất chip."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, AI có thể giúp các nhà thiết kế mạch như thế nào?",
        "options": {
          "A": "Thay thế hoàn toàn các nhà thiết kế mạch.",
          "B": "Tự động tạo ra các thiết kế mạch hoàn hảo mà không cần sự can thiệp của con người.",
          "C": "Giúp họ phá vỡ các lối tư duy cố hữu và khám phá các nguyên tắc thiết kế mới.",
          "D": "Giảm bớt khối lượng công việc hành chính liên quan đến thiết kế mạch."
        },
        "answer": "C"
      },
      {
        "question": "Trong phương pháp thiết kế mạch bằng AI được đề cập, thuật toán di truyền được sử dụng để làm gì?",
        "options": {
          "A": "Để phân tích hiệu suất của các mạch hiện có.",
          "B": "Để tạo ra các biến thể thiết kế và kiểm tra tính phù hợp của chúng.",
          "C": "Để tối ưu hóa việc sử dụng năng lượng của chip.",
          "D": "Để xác minh tính chính xác của các mô phỏng."
        },
        "answer": "B"
      }
    ]
  },
  "sambanova-boosts-llama-3-1-performance-with-fast-free-access-to-largest-model": {
    "title": "High Gear for Llama 3.1 405B",
    "collection": "hardware",
    "content": "SambaNova raised the speed limit for access to the largest model in the Llama 3.1 family — and it’s free.\n\nWhat’s new:SambaNovalauncheda cloud service that runs Llama 3.1 405B significantly faster than competitors. A free tier is available, to be followed later this year by paid tiers that offer higher rate limits.\n\nHow it works:SambaNova uses proprietarychipsand software to accelerate model inference.\n\nYes, but:SambaNova currently limits Llama 3.1’s context window to around 8,000 tokens, much less than the model’s native 128,000 tokens.\n\nBehind the news:The new service arrives amid a broader competition to deliver fast inference among cloud providers that have developed their own specialized chips. Competitors likeCerebrasandGroqhave introduced their own high-speed inference services.\n\nWhy it matters:Throughput, cost, performance, and latency are critical factors in practical applications of AI models. Fast inference allows for more frequent API calls without bogging down time to output, which is essential for agentic workflows and real-time decision making.\n\nWe’re thinking:Models with open weights are now served faster than proprietary models and are nearly as capable. This may spur further adoption of open models as well as prompting strategies, such as agentic workflows, that require large numbers of output tokens.",
    "qa": [
      {
        "question": "Dịch vụ đám mây mới của SambaNova tập trung vào việc tăng tốc loại mô hình ngôn ngữ lớn nào?",
        "options": {
          "A": "GPT-4",
          "B": "Llama 3.1 405B",
          "C": "Gemini 1.5 Pro",
          "D": "Claude 3 Opus"
        },
        "answer": "B"
      },
      {
        "question": "SambaNova sử dụng công nghệ gì để tăng tốc suy luận mô hình?",
        "options": {
          "A": "GPU của Nvidia",
          "B": "TPU của Google",
          "C": "Chip và phần mềm độc quyền",
          "D": "FPGA của Xilinx"
        },
        "answer": "C"
      },
      {
        "question": "Hạn chế hiện tại của dịch vụ SambaNova đối với Llama 3.1 là gì?",
        "options": {
          "A": "Giới hạn số lượng người dùng đồng thời",
          "B": "Giới hạn kích thước bộ nhớ",
          "C": "Giới hạn độ dài văn bản đầu vào (context window)",
          "D": "Giới hạn số lượng truy vấn API mỗi ngày"
        },
        "answer": "C"
      },
      {
        "question": "Kích thước context window mà SambaNova hiện đang hỗ trợ cho Llama 3.1 là bao nhiêu?",
        "options": {
          "A": "128,000 tokens",
          "B": "32,000 tokens",
          "C": "8,000 tokens",
          "D": "4,096 tokens"
        },
        "answer": "C"
      },
      {
        "question": "Ngoài SambaNova, những công ty nào khác cũng đang cạnh tranh trong việc cung cấp dịch vụ suy luận tốc độ cao?",
        "options": {
          "A": "Microsoft và Amazon",
          "B": "Cerebras và Groq",
          "C": "IBM và Oracle",
          "D": "Intel và AMD"
        },
        "answer": "B"
      },
      {
        "question": "Yếu tố nào KHÔNG được đề cập là quan trọng trong các ứng dụng thực tế của mô hình AI?",
        "options": {
          "A": "Thông lượng (Throughput)",
          "B": "Chi phí (Cost)",
          "C": "Hiệu năng (Performance)",
          "D": "Độ phức tạp (Complexity)"
        },
        "answer": "D"
      },
      {
        "question": "Tại sao suy luận nhanh lại quan trọng đối với các quy trình làm việc dựa trên tác nhân (agentic workflows)?",
        "options": {
          "A": "Để giảm chi phí điện năng tiêu thụ",
          "B": "Để tăng độ chính xác của mô hình",
          "C": "Để cho phép gọi API thường xuyên hơn mà không làm chậm thời gian xuất kết quả",
          "D": "Để đơn giản hóa quá trình triển khai mô hình"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì có thể được thúc đẩy bởi việc các mô hình mã nguồn mở được phục vụ nhanh hơn các mô hình độc quyền?",
        "options": {
          "A": "Sự phát triển của phần cứng chuyên dụng",
          "B": "Sự chấp nhận rộng rãi hơn của các mô hình mở",
          "C": "Sự giảm giá của các mô hình độc quyền",
          "D": "Sự hợp tác giữa các công ty AI lớn"
        },
        "answer": "B"
      },
      {
        "question": "Dịch vụ của SambaNova cung cấp những cấp độ dịch vụ nào?",
        "options": {
          "A": "Chỉ có cấp độ trả phí",
          "B": "Chỉ có cấp độ miễn phí",
          "C": "Cấp độ miễn phí ban đầu, sau đó là các cấp độ trả phí",
          "D": "Cấp độ trả phí ban đầu, sau đó là cấp độ miễn phí"
        },
        "answer": "C"
      },
      {
        "question": "Thuật ngữ 'agentic workflows' trong bài viết đề cập đến điều gì?",
        "options": {
          "A": "Quy trình làm việc được tự động hóa hoàn toàn",
          "B": "Quy trình làm việc yêu cầu sự can thiệp của con người",
          "C": "Quy trình làm việc sử dụng nhiều tác nhân AI để hoàn thành nhiệm vụ",
          "D": "Quy trình làm việc được tối ưu hóa cho các tác vụ cụ thể"
        },
        "answer": "C"
      }
    ]
  },
  "siemens-and-microsoft-launch-gpt-powered-copilot-for-manufacturing-machinery": {
    "title": "Industrial Strength Language Model",
    "collection": "hardware",
    "content": "ChatGPT is pitching in on the assembly line.\n\nWhat’s new:Siemens and Microsoftlauncheda joint pilot program of a GPT-powered model for controlling manufacturing machinery. German automotive parts manufacturerSchaeffleris testing the system in its factories, as is Siemens itself.\n\nHow it works:Industrial Copilot (distinct from similarly named Microsoft products such as GitHub Copilot and Microsoft 365 Copilot) enables users to interact with software that drives industrial machines using natural language. At an unspecified near-future date, Siemens plans to make it more widely available viaXcelerator, an online hub that connects Siemens customers to tools and partners.\n\nBehind the news:Microsoft is betting that specialized large language models can boost productivity (and expand its market) in a variety of industries. The companyannouncedits intention to develop Copilot models for infrastructure, transportation, and healthcare.\n\nWhy it matters:Industrial Copilot promises to reduce the time it takes factory technicians to operate and maintain machinery, and it may help less-technical workers get a stalled assembly line back up and running. This may be especially timely as older workers retire, since the software that runs manufacturing equipment can be decades old, and PLC coding can bedifficultto learn without prior manufacturing experience.\n\nWe’re thinking:For programming languages like PLC, the pool of coders is diminishing even as valuable applications still need to be maintained and built.Generative AI can play an important rolein helping developers who are less familiar with these languages to write and maintain important programs.",
    "qa": [
      {
        "question": "Công ty nào đang hợp tác với Microsoft để phát triển mô hình GPT cho việc điều khiển máy móc sản xuất?",
        "options": {
          "A": "Schaeffler",
          "B": "Siemens",
          "C": "GitHub",
          "D": "Xcelerator"
        },
        "answer": "B"
      },
      {
        "question": "Industrial Copilot khác biệt so với GitHub Copilot và Microsoft 365 Copilot ở điểm nào?",
        "options": {
          "A": "Nó được phát triển bởi một công ty khác.",
          "B": "Nó cho phép tương tác với phần mềm điều khiển máy móc công nghiệp bằng ngôn ngữ tự nhiên.",
          "C": "Nó chỉ dành cho các kỹ sư phần mềm.",
          "D": "Nó không sử dụng mô hình GPT."
        },
        "answer": "B"
      },
      {
        "question": "Siemens dự kiến sẽ cung cấp Industrial Copilot thông qua nền tảng nào?",
        "options": {
          "A": "GitHub",
          "B": "Microsoft 365",
          "C": "Xcelerator",
          "D": "Industrial Copilot Online"
        },
        "answer": "C"
      },
      {
        "question": "Microsoft kỳ vọng gì từ việc phát triển các mô hình ngôn ngữ lớn chuyên biệt cho các ngành công nghiệp?",
        "options": {
          "A": "Giảm chi phí sản xuất.",
          "B": "Tăng năng suất và mở rộng thị trường.",
          "C": "Thay thế hoàn toàn công nhân.",
          "D": "Tăng cường bảo mật thông tin."
        },
        "answer": "B"
      },
      {
        "question": "Industrial Copilot hứa hẹn mang lại lợi ích gì cho các kỹ thuật viên nhà máy?",
        "options": {
          "A": "Giảm thời gian cần thiết để vận hành và bảo trì máy móc.",
          "B": "Tự động hóa hoàn toàn quy trình sản xuất.",
          "C": "Loại bỏ nhu cầu về kỹ năng lập trình.",
          "D": "Tăng cường khả năng giám sát từ xa."
        },
        "answer": "A"
      },
      {
        "question": "Tại sao Industrial Copilot lại đặc biệt hữu ích trong bối cảnh hiện tại?",
        "options": {
          "A": "Giá điện đang tăng cao.",
          "B": "Công nhân lớn tuổi đang nghỉ hưu và phần mềm sản xuất có thể đã lỗi thời.",
          "C": "Chuỗi cung ứng toàn cầu đang bị gián đoạn.",
          "D": "Nhu cầu về sản phẩm tùy chỉnh đang tăng lên."
        },
        "answer": "B"
      },
      {
        "question": "Ngôn ngữ lập trình PLC được đề cập trong bài viết là gì?",
        "options": {
          "A": "Một ngôn ngữ lập trình hiện đại, dễ học.",
          "B": "Một ngôn ngữ lập trình khó học nếu không có kinh nghiệm sản xuất.",
          "C": "Một ngôn ngữ lập trình chỉ được sử dụng trong ngành ô tô.",
          "D": "Một ngôn ngữ lập trình đã lỗi thời và không còn được sử dụng."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất vai trò của AI tạo sinh trong việc duy trì và xây dựng các ứng dụng quan trọng như thế nào?",
        "options": {
          "A": "Thay thế hoàn toàn các nhà phát triển.",
          "B": "Hỗ trợ các nhà phát triển ít quen thuộc với các ngôn ngữ lập trình cũ.",
          "C": "Tự động tạo ra các ứng dụng mới hoàn toàn.",
          "D": "Giảm chi phí phát triển phần mềm."
        },
        "answer": "B"
      },
      {
        "question": "Công ty sản xuất phụ tùng ô tô nào đang thử nghiệm hệ thống Industrial Copilot?",
        "options": {
          "A": "Microsoft",
          "B": "Siemens",
          "C": "Schaeffler",
          "D": "Xcelerator"
        },
        "answer": "C"
      },
      {
        "question": "Microsoft có kế hoạch phát triển các mô hình Copilot cho những lĩnh vực nào khác ngoài sản xuất?",
        "options": {
          "A": "Năng lượng tái tạo và nông nghiệp.",
          "B": "Cơ sở hạ tầng, giao thông vận tải và chăm sóc sức khỏe.",
          "C": "Giáo dục và giải trí.",
          "D": "Tài chính và bất động sản."
        },
        "answer": "B"
      }
    ]
  },
  "size-matters": {
    "title": "Size Matters",
    "collection": "hardware",
    "content": "Silicon Valley startup Cerebras shifted out of stealth mode to unveil its flagship product: an enormous chip designed from the ground up to accelerate neural networks.\n\nWhat’s new:TheCerebras Wafer Scale Engineis aimed at data centers, where the company claims it will perform AI computations 100 to 1,000 times faster than alternatives. The chips will be housed in servers equipped with a special cooling system to dissipate the chip’s heat. They’re scheduled to reach the market next month for an undisclosed price.\n\nWhy it’s different:Where many chips are measured in millimeters, this monster is 56 times larger than Nvidia’s top-of-the-line GPU and bigger than a standard iPad. It comprises more than 400,000 cores and 18 gigabytes of memory right on the chip. That’s equivalent to 84 GPUs communicating with one another 150 times more efficiently than usual, with an additional boost thanks to the ability to handle sparse linear algebra.\n\nHow it works:Nvidia’s chip architecture is extraordinarily efficient at performing the predictable, repetitive matrix multiplications required by neural networks. Yet it has practical limitations: It must hold an entire neural network in off-chip memory and communicate with other chips through external interfaces that are far slower than communication on the chip itself.\n\nBehind the news:Deep learning’s rapid growth has prompted a top-to-bottom redesign of computing systems to accelerate neural network training.\n\nWhy it matters:If the new hardware works as advertised, it will open virgin territory for neural networks several orders of magnitude bigger than today’s largest models. Larger models have been shown to yield higher accuracy, and the additional headroom may well allow new kinds of models that wouldn’t be practical otherwise.\n\nWe’re thinking:The advent of Nvidia GPUs two decades ago spurred innovations in model architecture that boosted the practical number of network layers from handfuls to 1,000-plus. Cerebras’ approach portends fresh architectures capable of solving problems that are currently out of reach. We don’t yet know what those models will look like, but we’re eager to find out!",
    "qa": [
      {
        "question": "Sản phẩm chủ lực mà Cerebras vừa công bố có tên là gì?",
        "options": {
          "A": "Cerebras Neural Network Accelerator",
          "B": "Cerebras Wafer Scale Engine",
          "C": "Cerebras Data Center Chip",
          "D": "Cerebras AI Computation Unit"
        },
        "answer": "B"
      },
      {
        "question": "Cerebras Wafer Scale Engine được thiết kế chủ yếu để sử dụng ở đâu?",
        "options": {
          "A": "Máy tính cá nhân",
          "B": "Trung tâm dữ liệu",
          "C": "Thiết bị di động",
          "D": "Xe tự hành"
        },
        "answer": "B"
      },
      {
        "question": "Theo Cerebras, Wafer Scale Engine có tốc độ tính toán AI nhanh hơn bao nhiêu lần so với các giải pháp thay thế?",
        "options": {
          "A": "10 đến 50 lần",
          "B": "100 đến 1,000 lần",
          "C": "1,000 đến 10,000 lần",
          "D": "10,000 đến 100,000 lần"
        },
        "answer": "B"
      },
      {
        "question": "Wafer Scale Engine lớn hơn GPU hàng đầu của Nvidia bao nhiêu lần?",
        "options": {
          "A": "28 lần",
          "B": "56 lần",
          "C": "84 lần",
          "D": "112 lần"
        },
        "answer": "B"
      },
      {
        "question": "Wafer Scale Engine chứa bao nhiêu lõi (cores)?",
        "options": {
          "A": "Hơn 40,000 lõi",
          "B": "Hơn 100,000 lõi",
          "C": "Hơn 200,000 lõi",
          "D": "Hơn 400,000 lõi"
        },
        "answer": "D"
      },
      {
        "question": "Dung lượng bộ nhớ trên chip của Wafer Scale Engine là bao nhiêu?",
        "options": {
          "A": "8 gigabytes",
          "B": "12 gigabytes",
          "C": "18 gigabytes",
          "D": "24 gigabytes"
        },
        "answer": "C"
      },
      {
        "question": "Ưu điểm chính của kiến trúc chip Nvidia trong việc xử lý mạng nơ-ron là gì?",
        "options": {
          "A": "Khả năng xử lý song song vượt trội",
          "B": "Hiệu quả cao trong việc thực hiện các phép nhân ma trận lặp đi lặp lại",
          "C": "Dung lượng bộ nhớ trên chip lớn",
          "D": "Khả năng giao tiếp nhanh chóng với các chip khác"
        },
        "answer": "B"
      },
      {
        "question": "Sự tăng trưởng nhanh chóng của deep learning đã thúc đẩy điều gì?",
        "options": {
          "A": "Sự phát triển của các thuật toán học máy mới",
          "B": "Việc thiết kế lại toàn diện các hệ thống máy tính để tăng tốc độ huấn luyện mạng nơ-ron",
          "C": "Sự ra đời của các ngôn ngữ lập trình mới",
          "D": "Sự gia tăng số lượng các nhà nghiên cứu trong lĩnh vực AI"
        },
        "answer": "B"
      },
      {
        "question": "Nếu Wafer Scale Engine hoạt động như quảng cáo, nó sẽ mở ra cơ hội gì cho mạng nơ-ron?",
        "options": {
          "A": "Huấn luyện các mô hình nhỏ hơn với độ chính xác cao hơn",
          "B": "Huấn luyện các mô hình lớn hơn nhiều so với các mô hình lớn nhất hiện nay",
          "C": "Giảm chi phí huấn luyện mô hình",
          "D": "Tăng cường khả năng giải thích của mô hình"
        },
        "answer": "B"
      },
      {
        "question": "Sự ra đời của GPU Nvidia hai thập kỷ trước đã thúc đẩy sự đổi mới nào trong kiến trúc mô hình?",
        "options": {
          "A": "Tăng số lượng lớp mạng thực tế từ vài lớp lên hơn 1,000 lớp",
          "B": "Giảm kích thước của mô hình",
          "C": "Tăng tốc độ huấn luyện mô hình",
          "D": "Cải thiện khả năng khái quát hóa của mô hình"
        },
        "answer": "A"
      }
    ]
  },
  "tech-giants-increase-cloud-spending-to-meet-growing-infrastructure-demands": {
    "title": "Big AI Spending Continues to Rise",
    "collection": "hardware",
    "content": "Top AI companies announced plans to dramatically ramp up their spending on AI infrastructure.\n\nWhat’s new:Alphabet, Amazon, Meta, Microsoft, and others willboosttheir capital spending dramatically in 2025, pouring hundreds of billions of dollars into data centers where they process AI training, the companies said in their most recent quarterly reports. The surge suggests that more-efficient approaches to training models won’t dampen the need for greater and greater processing power.\n\nHow it works:Capital expenditures include long-term purchases like land, buildings, and computing hardware rather than recurring costs like salaries or electricity. The AI leaders signaled that most of this spending will support their AI efforts.\n\nBehind the news:DeepSeek initiallysurprisedmany members of the AI community by claiming to have trained a high-performance large language model at a fraction of the usual cost.\n\nWhy it matters:DeepSeek-R1’s purported training cost fueled fears that demand for AI infrastructure would cool, but the top AI companies’ plans show that it’s not happening yet. A possible explanation lies in theJevons Paradox, a 19th-century economic theory named after the English economist William Stanley Jevons. As a valuable product becomes more affordable, demand doesn’t fall, it rises. According to this theory, even if training costs tumble, the world will demand ever greater processing power for inference.\n\nWe’re thinking:DeepSeek’s low-cost technology momentarily rattled investors who had expected the next big gains would come from the U.S. rather than China. But DeepSeek’s efficiency follows a broader pattern we’ve seen for years: The AI community steadily wrings better performance from less processing power.",
    "qa": [
      {
        "question": "Các công ty AI hàng đầu dự kiến sẽ tăng đáng kể chi tiêu vốn vào lĩnh vực nào trong năm 2025?",
        "options": {
          "A": "Nghiên cứu và phát triển phần mềm AI.",
          "B": "Cơ sở hạ tầng AI, đặc biệt là trung tâm dữ liệu.",
          "C": "Tuyển dụng và đào tạo nhân viên AI.",
          "D": "Marketing và quảng bá sản phẩm AI."
        },
        "answer": "B"
      },
      {
        "question": "Chi tiêu vốn (Capital expenditures) bao gồm những khoản mục nào?",
        "options": {
          "A": "Lương nhân viên và chi phí điện.",
          "B": "Chi phí marketing và quảng cáo.",
          "C": "Mua đất đai, xây dựng và phần cứng máy tính.",
          "D": "Chi phí thuê văn phòng và dịch vụ pháp lý."
        },
        "answer": "C"
      },
      {
        "question": "Công ty nào đã gây bất ngờ cho cộng đồng AI khi tuyên bố đã huấn luyện một mô hình ngôn ngữ lớn hiệu suất cao với chi phí thấp?",
        "options": {
          "A": "Alphabet.",
          "B": "Amazon.",
          "C": "DeepSeek.",
          "D": "Microsoft."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì đã khiến các nhà đầu tư lo lắng sau tuyên bố của DeepSeek?",
        "options": {
          "A": "Sự sụt giảm giá trị cổ phiếu của các công ty AI hàng đầu.",
          "B": "Khả năng nhu cầu về cơ sở hạ tầng AI sẽ giảm.",
          "C": "Sự cạnh tranh gay gắt từ các công ty AI Trung Quốc.",
          "D": "Sự chậm trễ trong việc phát triển các mô hình AI mới."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến nghịch lý Jevons để giải thích điều gì?",
        "options": {
          "A": "Tại sao chi phí đào tạo AI lại tăng nhanh.",
          "B": "Tại sao nhu cầu về cơ sở hạ tầng AI vẫn tăng mặc dù chi phí đào tạo giảm.",
          "C": "Tại sao các công ty AI lại đầu tư vào các công nghệ kém hiệu quả.",
          "D": "Tại sao hiệu suất của các mô hình AI lại không cải thiện đáng kể."
        },
        "answer": "B"
      },
      {
        "question": "Nghịch lý Jevons là một lý thuyết kinh tế có từ thế kỷ nào?",
        "options": {
          "A": "Thế kỷ 18.",
          "B": "Thế kỷ 19.",
          "C": "Thế kỷ 20.",
          "D": "Thế kỷ 21."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, xu hướng chung trong cộng đồng AI là gì?",
        "options": {
          "A": "Tăng cường sử dụng phần cứng đắt tiền để cải thiện hiệu suất.",
          "B": "Liên tục cải thiện hiệu suất với ít sức mạnh xử lý hơn.",
          "C": "Tập trung vào việc phát triển các mô hình AI đơn giản hơn.",
          "D": "Giảm chi tiêu cho nghiên cứu và phát triển AI."
        },
        "answer": "B"
      },
      {
        "question": "Tên của nhà kinh tế học người Anh gắn liền với nghịch lý Jevons là gì?",
        "options": {
          "A": "Adam Smith.",
          "B": "John Maynard Keynes.",
          "C": "William Stanley Jevons.",
          "D": "David Ricardo."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc tăng chi tiêu vốn của các công ty AI hàng đầu là gì?",
        "options": {
          "A": "Đa dạng hóa danh mục đầu tư của họ.",
          "B": "Hỗ trợ các nỗ lực AI của họ.",
          "C": "Tăng cường sự hiện diện toàn cầu của họ.",
          "D": "Cải thiện quan hệ công chúng của họ."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết cho rằng hiệu quả chi phí của DeepSeek-R1 đến từ đâu?",
        "options": {
          "A": "Sử dụng phần cứng rẻ tiền hơn.",
          "B": "Áp dụng các thuật toán đào tạo tiên tiến.",
          "C": "Thuê nhân công giá rẻ.",
          "D": "Nhận được trợ cấp từ chính phủ."
        },
        "answer": "B"
      }
    ]
  },
  "transformer-accelerator": {
    "title": "Transformer Accelerator",
    "collection": "hardware",
    "content": "Is your colossal text generator bogged down in training? Nvidia announced a chip designed to accelerate the transformer architecture, the basis of large language models such as GPT-3.What’s new:TheH100graphics processing unit (GPU) can train transformer models many times faster than Nvidia’s previous flagship A100 (or, presumably, any other chip on the market).How it works:Transformer networks have ballooned in size from GPT-3’s 175 billion parameters to WuDao’s 1.75 trillion, requiring more computation for training and inference. The H100’s underlying chip design, known as Hopper, includes a so-called Transformer Engine designed to make such models run more efficiently.\n\nTime savings:In tests, a 395 billion-parametermixture-of-expertsmodel took 20 hours to train running on 8,000 H100s, while it took seven days running on the same number of A100s. A chatbot based on Nvidia’sMegatrongenerated output up to 30 times faster running on H100s than A100s. Nvidia plans to link 4,608 H100 chips into a trainingsupercomputerthat the company touts as the world’s fastest system for training AI.Behind the news:While Nvidia is the undisputed leader in specialized AI chips, several competitors are vying for the same market.\n\nWhy it matters:The transformer has driven a tidal wave of progress in AI for language as well as an expandingarrayof domains including vision, image generation, and biomedicine. The ability to train such models faster greases the wheels for this versatile architecture.We’re thinking:Conventional chips lately havestruggledto keep pace with Moore’s Law, which predicts a doubling of processing power every 18 months. AI chips areoutpacingit by a wide margin. Yet another reason to dig into AI!",
    "qa": [
      {
        "question": "Chip H100 của Nvidia được thiết kế để tăng tốc loại kiến trúc nào?",
        "options": {
          "A": "Kiến trúc mạng nơ-ron tích chập (CNN)",
          "B": "Kiến trúc Transformer",
          "C": "Kiến trúc mạng nơ-ron hồi quy (RNN)",
          "D": "Kiến trúc mạng đối kháng sinh (GAN)"
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm chính của GPU H100 so với A100 là gì?",
        "options": {
          "A": "Tiêu thụ ít điện năng hơn",
          "B": "Tốc độ huấn luyện mô hình Transformer nhanh hơn đáng kể",
          "C": "Giá thành rẻ hơn",
          "D": "Dung lượng bộ nhớ lớn hơn"
        },
        "answer": "B"
      },
      {
        "question": "Thiết kế chip Hopper của H100 bao gồm thành phần đặc biệt nào để tăng hiệu quả xử lý mô hình Transformer?",
        "options": {
          "A": "Bộ xử lý Vector",
          "B": "Transformer Engine",
          "C": "Bộ nhớ Cache siêu tốc",
          "D": "Bộ mã hóa và giải mã video"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, việc huấn luyện một mô hình mixture-of-experts 395 tỷ tham số trên 8,000 chip A100 mất bao lâu?",
        "options": {
          "A": "20 giờ",
          "B": "7 ngày",
          "C": "3 ngày",
          "D": "1 tuần"
        },
        "answer": "B"
      },
      {
        "question": "Siêu máy tính huấn luyện AI mà Nvidia dự định xây dựng sẽ liên kết bao nhiêu chip H100?",
        "options": {
          "A": "1,024",
          "B": "2,048",
          "C": "4,096",
          "D": "4,608"
        },
        "answer": "D"
      },
      {
        "question": "Ứng dụng nào sau đây được hưởng lợi từ sự tiến bộ của kiến trúc Transformer?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên",
          "B": "Thị giác máy tính",
          "C": "Sinh ảnh",
          "D": "Tất cả các đáp án trên"
        },
        "answer": "D"
      },
      {
        "question": "Theo bài viết, quy luật Moore dự đoán điều gì?",
        "options": {
          "A": "Giá chip sẽ giảm một nửa sau mỗi 18 tháng",
          "B": "Mức tiêu thụ điện của chip sẽ giảm một nửa sau mỗi 18 tháng",
          "C": "Sức mạnh xử lý của chip sẽ tăng gấp đôi sau mỗi 18 tháng",
          "D": "Kích thước chip sẽ giảm một nửa sau mỗi 18 tháng"
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc phát triển các chip AI chuyên dụng là gì?",
        "options": {
          "A": "Giảm chi phí sản xuất chip",
          "B": "Tăng tốc độ xử lý các tác vụ AI",
          "C": "Tăng tuổi thọ của thiết bị",
          "D": "Giảm kích thước của thiết bị"
        },
        "answer": "B"
      },
      {
        "question": "Megatron của Nvidia là gì?",
        "options": {
          "A": "Một loại chip AI mới",
          "B": "Một chatbot dựa trên AI",
          "C": "Một siêu máy tính huấn luyện AI",
          "D": "Một thư viện phần mềm AI"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, ai là người dẫn đầu không thể tranh cãi trong lĩnh vực chip AI chuyên dụng?",
        "options": {
          "A": "Google",
          "B": "AMD",
          "C": "Intel",
          "D": "Nvidia"
        },
        "answer": "D"
      }
    ]
  },
  "tsmc-stops-advanced-chip-production-for-china-on-u-s-orders": {
    "title": "Further Chip Restrictions on China",
    "collection": "hardware",
    "content": "The largest manufacturer of AI chips told its Chinese customers it would stop fabricating their most advanced designs, further limiting China’s access to AI hardware.\n\nWhat’s new:Taiwan Semiconductor Manufacturing Corp. (TSMC) notified Alibaba, Baidu, and others it would halt production of their most advanced chips starting November 13, according tomultiplereports. The restriction affects chip designs that are based on manufacturing processes at scales of 7 nanometers and below. TSMC must receive explicit permission from the U.S. government to manufacture advanced chips for a given customer, which likely would require that the government assess each chip to prevent potential military applications.\n\nHow it works:The United States Department of Commerce ordered TSMC to halt shipments of advanced AI chips to China after a chip fabricated by TSMC was discovered in an AI system sold by the Chinese telecoms giant Huawei, apparently in violation of earlier U.S. controls,Reutersreported. Taiwan’s economic ministry said it would follow all domestic and international regulations.\n\nBehind the news:The U.S.-China chip standoff began in 2020 and hasescalatedsince. Initial restrictionsbarredU.S.-based companies like AMD, Intel, and Nvidia from selling advanced chips to Huawei and affiliated Chinese firms. China responded bypromotingdomestic chip fabrication. In 2022, the U.S.passedthe CHIPS and Science Act to boost its own chip industry, seeking to counter China and decrease U.S. reliance on Taiwan.\n\nWhy it matters:TSMC finds itself in the middle of an AI arms race in which cutting-edge chips could tip the balance. The company itself, which has been operating at full capacity, is unlikely to suffer business losses.\n\nWe’re thinking:AI developers in China have been resourceful in navigating previous restrictions. Chip manufacturing is extraordinarily difficult to master, but China has madestridesin this direction. A proliferation of factories that can fabricate advanced chips would reshape AI research and business worldwide.",
    "qa": [
      {
        "question": "Công ty nào được đề cập đến là nhà sản xuất chip AI lớn nhất và sẽ ngừng sản xuất các thiết kế tiên tiến nhất cho khách hàng Trung Quốc?",
        "options": {
          "A": "Alibaba",
          "B": "Taiwan Semiconductor Manufacturing Corp. (TSMC)",
          "C": "Huawei",
          "D": "Baidu"
        },
        "answer": "B"
      },
      {
        "question": "TSMC sẽ ngừng sản xuất chip cho khách hàng Trung Quốc dựa trên quy trình sản xuất ở quy mô nào?",
        "options": {
          "A": "14 nanometers trở xuống",
          "B": "7 nanometers trở xuống",
          "C": "28 nanometers trở xuống",
          "D": "5 nanometers trở xuống"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lý do chính khiến TSMC ngừng cung cấp chip tiên tiến cho Trung Quốc là gì?",
        "options": {
          "A": "Do yêu cầu từ chính phủ Trung Quốc",
          "B": "Do lệnh từ Bộ Thương mại Hoa Kỳ",
          "C": "Do thiếu hụt nguyên liệu sản xuất",
          "D": "Do lo ngại về cạnh tranh từ các công ty Trung Quốc"
        },
        "answer": "B"
      },
      {
        "question": "Chip của TSMC được tìm thấy trong hệ thống AI của công ty nào, dẫn đến việc Hoa Kỳ thắt chặt kiểm soát xuất khẩu?",
        "options": {
          "A": "Alibaba",
          "B": "Baidu",
          "C": "Xiaomi",
          "D": "Huawei"
        },
        "answer": "D"
      },
      {
        "question": "Cuộc đối đầu về chip giữa Hoa Kỳ và Trung Quốc bắt đầu vào năm nào?",
        "options": {
          "A": "2018",
          "B": "2019",
          "C": "2020",
          "D": "2021"
        },
        "answer": "C"
      },
      {
        "question": "Đạo luật nào được Hoa Kỳ thông qua để thúc đẩy ngành công nghiệp chip trong nước và giảm sự phụ thuộc vào Đài Loan?",
        "options": {
          "A": "The Innovation and Competition Act",
          "B": "The Semiconductor Independence Act",
          "C": "The CHIPS and Science Act",
          "D": "The Technology Advancement Act"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết cho rằng TSMC có khả năng chịu tổn thất kinh doanh lớn từ việc ngừng cung cấp chip cho Trung Quốc hay không?",
        "options": {
          "A": "Có, vì Trung Quốc là thị trường lớn nhất của họ.",
          "B": "Có, vì họ sẽ mất uy tín với các khách hàng khác.",
          "C": "Không, vì họ đang hoạt động hết công suất và có thể tìm kiếm khách hàng khác.",
          "D": "Không chắc chắn, vì tình hình còn nhiều biến động."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, phản ứng của Trung Quốc đối với các hạn chế về chip là gì?",
        "options": {
          "A": "Tăng cường nhập khẩu chip từ các nước khác.",
          "B": "Thúc đẩy sản xuất chip trong nước.",
          "C": "Đàm phán với Hoa Kỳ để dỡ bỏ các hạn chế.",
          "D": "Chuyển sang phát triển các công nghệ AI khác không cần chip tiên tiến."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì sẽ xảy ra nếu Trung Quốc thành công trong việc xây dựng nhiều nhà máy sản xuất chip tiên tiến?",
        "options": {
          "A": "Giá chip trên toàn thế giới sẽ tăng mạnh.",
          "B": "Nghiên cứu và kinh doanh AI trên toàn thế giới sẽ được định hình lại.",
          "C": "TSMC sẽ mất vị thế dẫn đầu trong ngành sản xuất chip.",
          "D": "Hoa Kỳ sẽ ngừng hỗ trợ ngành công nghiệp chip trong nước."
        },
        "answer": "B"
      },
      {
        "question": "Thời điểm TSMC bắt đầu ngừng sản xuất chip tiên tiến cho khách hàng Trung Quốc là khi nào?",
        "options": {
          "A": "Ngày 1 tháng 11",
          "B": "Ngày 13 tháng 11",
          "C": "Ngày 1 tháng 12",
          "D": "Ngày 15 tháng 12"
        },
        "answer": "B"
      }
    ]
  },
  "voltage-park-offers-nvidia-gpus-at-1-89-hour-for-startups-and-researchers": {
    "title": "More Cloud GPUs on the Way",
    "collection": "hardware",
    "content": "A new cloud-computing company promises to provide scarce AI processing power to startups and researchers.\n\nWhat’s new:Voltage Park, a nonprofit north of Silicon Valley, willofferprocessing power from 24,000 top-of-the-line Nvidia H100 graphics processing units (GPUs) — roughly $500 million worth — at competitive prices. Rival suppliers of cloud-based GPUs are oversubscribed as the chips continue to be in short supply.\n\nHow it works:The company, which is bankrolled by cryptocurrency billionaire Jed McCaleb, plans to build data centers in Texas, Virginia, and Washington.\n\nBehind the news:Ashortageof Nvidia’s high-end GPUs, which are optimized to process machine learning workloads, has bedeviled organizations that aim to join the generative AI boom. Businesses are scrambling to manage the demand.\n\nWhy it matters:Training and serving state-of-the-art AI systems requires huge amounts of processing power. Thus AI startups are facing serious obstacles amid the scarcity of specialized hardware. Larger companies have either their own processing power or strong relationships with cloud providers. Smaller providers such as DataCrunch, Lambda Labs, and Paperspace have limited supply. As generative AI booms, organizations that can provide access to GPUs on flexible terms are likely to find takers.We’re thinking:Voltage Park is a subsidiary of McCaleb’s philanthropic organization, and its profits will fund the organization’s activities, about which its website offersno information. Nonprofit status can be a prelude to for-profit business. We’re curious to see where this company is headed.",
    "qa": [
      {
        "question": "Công ty Voltage Park hứa hẹn điều gì cho các startup và nhà nghiên cứu?",
        "options": {
          "A": "Cung cấp phần mềm AI miễn phí.",
          "B": "Cung cấp sức mạnh xử lý AI khan hiếm.",
          "C": "Cung cấp dịch vụ tư vấn AI chuyên nghiệp.",
          "D": "Cung cấp dữ liệu đào tạo AI chất lượng cao."
        },
        "answer": "B"
      },
      {
        "question": "Voltage Park sẽ cung cấp loại GPU nào và với số lượng bao nhiêu?",
        "options": {
          "A": "12,000 GPU Nvidia A100.",
          "B": "24,000 GPU Nvidia H100.",
          "C": "48,000 GPU Nvidia V100.",
          "D": "12,000 GPU Nvidia H200."
        },
        "answer": "B"
      },
      {
        "question": "Ai là người tài trợ chính cho Voltage Park?",
        "options": {
          "A": "Elon Musk.",
          "B": "Jeff Bezos.",
          "C": "Jed McCaleb.",
          "D": "Bill Gates."
        },
        "answer": "C"
      },
      {
        "question": "Voltage Park dự kiến xây dựng các trung tâm dữ liệu ở những bang nào của Hoa Kỳ?",
        "options": {
          "A": "California, Nevada, Arizona.",
          "B": "Texas, Virginia, Washington.",
          "C": "New York, Pennsylvania, Ohio.",
          "D": "Florida, Georgia, Alabama."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đang gây khó khăn cho các tổ chức muốn tham gia vào làn sóng AI tạo sinh?",
        "options": {
          "A": "Thiếu nhân lực có kỹ năng về AI.",
          "B": "Chi phí đầu tư vào phần mềm AI quá cao.",
          "C": "Sự thiếu hụt GPU cao cấp của Nvidia.",
          "D": "Khó khăn trong việc thu thập dữ liệu đào tạo AI."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao các startup AI đang gặp khó khăn?",
        "options": {
          "A": "Do thiếu vốn đầu tư mạo hiểm.",
          "B": "Do sự cạnh tranh gay gắt từ các công ty lớn.",
          "C": "Do sự khan hiếm của phần cứng chuyên dụng.",
          "D": "Do thiếu sự hỗ trợ từ chính phủ."
        },
        "answer": "C"
      },
      {
        "question": "Các công ty lớn có lợi thế gì so với các startup AI trong bối cảnh hiện tại?",
        "options": {
          "A": "Họ có thể dễ dàng tiếp cận các khóa đào tạo AI chuyên sâu.",
          "B": "Họ có nguồn lực tài chính dồi dào để thuê chuyên gia AI hàng đầu.",
          "C": "Họ có sức mạnh xử lý riêng hoặc mối quan hệ tốt với các nhà cung cấp đám mây.",
          "D": "Họ có thể dễ dàng tiếp cận dữ liệu đào tạo AI độc quyền."
        },
        "answer": "C"
      },
      {
        "question": "Các nhà cung cấp nhỏ hơn như DataCrunch, Lambda Labs và Paperspace gặp hạn chế gì?",
        "options": {
          "A": "Họ thiếu kinh nghiệm trong lĩnh vực AI.",
          "B": "Họ có nguồn cung hạn chế.",
          "C": "Họ không có khả năng cung cấp dịch vụ hỗ trợ khách hàng tốt.",
          "D": "Họ không có khả năng cạnh tranh về giá."
        },
        "answer": "B"
      },
      {
        "question": "Voltage Park là công ty con của tổ chức từ thiện nào?",
        "options": {
          "A": "Tổ chức Bill & Melinda Gates.",
          "B": "Tổ chức Chan Zuckerberg.",
          "C": "Tổ chức từ thiện của Jed McCaleb.",
          "D": "Tổ chức Open AI."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích sử dụng lợi nhuận của Voltage Park là gì?",
        "options": {
          "A": "Đầu tư vào nghiên cứu và phát triển AI.",
          "B": "Tài trợ cho các hoạt động của tổ chức từ thiện mẹ.",
          "C": "Mở rộng quy mô hoạt động của Voltage Park.",
          "D": "Trả cổ tức cho các nhà đầu tư."
        },
        "answer": "B"
      }
    ]
  },
  "unitree-and-engineai-showcase-affordable-humanoid-robots": {
    "title": "Humanoid Robot Price Break",
    "collection": "hardware",
    "content": "Chinese robot makers Unitree and EngineAI showed off relatively low-priced humanoid robots that could bring advanced robotics closer to everyday applications.\n\nWhat’s new:At the annual Consumer Electronics Show (CES) in Las Vegas, Unitree showed itsG1($16,000 with three-finger hands, $21,000 with five-finger, articulated hands), which climbed stairs and navigated around obstacles. Elsewhere on the show floor, EngineAI’sPM01($13,700 through March 2025 including articulated hands) andSE01(price not yet disclosed) marched among attendees with notably naturalistic gaits.\n\nHow it works:Relatively small and lightweight, these units are designed for household and small-business uses. They’re designed for general-purpose tasks and to maintain stability and balance while walking on varied terrain.\n\nBehind the news:In contrast to the more-affordable humanoid robots coming out of China, U.S. companies like Boston Dynamics, Figure AI, and Tesla tend to cater to industrial customers. Teslaplansto produce several thousand of its Optimus ($20,000 to $30,000) humanoids in 2025, ramping to as many as 100,000 in 2026. Figure AI has demonstrated its Figure 02 ($59,000) in BMW manufacturing plants,showinga 400 percent speed improvement in some tasks. At CES, Nvidia unveiled its GR00T Blueprint, which includes vision-language models and synthetic data for training humanoid robots, and said its Jetson Thor computer for humanoids would be available early 2025.\n\nWhy it matters:China’s push into humanoid robotics reflects its broader national ambitions. Its strength in hardware has allowed it to establish a dominant position in drones, and humanoid robots represent a new front for competition. China’s government aims toachievemass production of humanoid robots by 2025 and establish global leadership by 2027, partly to address projected labor shortages of 30 million workers in manufacturing alone. Lower price points for robots that can perform arbitrary tasks independently could be valuable in elder care and logistics, offering tools for repetitive or physically demanding tasks.\n\nWe’re thinking:Although humanoid robots generate a lot of excitement, they’re still in an early stage of development, and businesses are still working to identify and prove concrete use cases. For many industrial applications, wheeled robots — which are less expensive, more stable, and better able to carry heavy loads — will remain a sensible choice. But the prospect of machines that look like us and fit easily into environments built for us is compelling.",
    "qa": [
      {
        "question": "Công ty nào của Trung Quốc đã giới thiệu robot hình người G1 tại CES?",
        "options": {
          "A": "EngineAI",
          "B": "Unitree",
          "C": "Boston Dynamics",
          "D": "Tesla"
        },
        "answer": "B"
      },
      {
        "question": "Robot PM01 của EngineAI có giá bao nhiêu (tính đến tháng 3 năm 2025)?",
        "options": {
          "A": "$16,000",
          "B": "$21,000",
          "C": "$13,700",
          "D": "Chưa được công bố"
        },
        "answer": "C"
      },
      {
        "question": "Các robot hình người giá rẻ của Trung Quốc được thiết kế chủ yếu cho mục đích sử dụng nào?",
        "options": {
          "A": "Công nghiệp nặng",
          "B": "Quân sự",
          "C": "Hộ gia đình và doanh nghiệp nhỏ",
          "D": "Nghiên cứu khoa học"
        },
        "answer": "C"
      },
      {
        "question": "Công ty nào của Mỹ có xu hướng phục vụ khách hàng trong lĩnh vực công nghiệp với robot hình người?",
        "options": {
          "A": "Unitree",
          "B": "EngineAI",
          "C": "Nvidia",
          "D": "Boston Dynamics"
        },
        "answer": "D"
      },
      {
        "question": "Tesla dự kiến sản xuất bao nhiêu robot Optimus vào năm 2026?",
        "options": {
          "A": "Vài trăm",
          "B": "Vài nghìn",
          "C": "Vài chục nghìn",
          "D": "Một trăm nghìn"
        },
        "answer": "D"
      },
      {
        "question": "Robot Figure 02 của Figure AI đã được thử nghiệm trong nhà máy sản xuất của công ty nào?",
        "options": {
          "A": "Tesla",
          "B": "Unitree",
          "C": "BMW",
          "D": "EngineAI"
        },
        "answer": "C"
      },
      {
        "question": "Nvidia đã giới thiệu sản phẩm nào tại CES để hỗ trợ phát triển robot hình người?",
        "options": {
          "A": "Optimus",
          "B": "Figure 02",
          "C": "GR00T Blueprint",
          "D": "PM01"
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu của chính phủ Trung Quốc là đạt được sản xuất hàng loạt robot hình người vào năm nào?",
        "options": {
          "A": "2023",
          "B": "2025",
          "C": "2027",
          "D": "2030"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lĩnh vực nào có thể hưởng lợi từ robot hình người giá rẻ trong tương lai?",
        "options": {
          "A": "Khai thác khoáng sản",
          "B": "Chăm sóc người già và logistics",
          "C": "Thám hiểm vũ trụ",
          "D": "Nghiên cứu năng lượng hạt nhân"
        },
        "answer": "B"
      },
      {
        "question": "Loại robot nào được cho là phù hợp hơn cho các ứng dụng công nghiệp nặng so với robot hình người?",
        "options": {
          "A": "Robot bay (drone)",
          "B": "Robot hình người",
          "C": "Robot có bánh xe",
          "D": "Robot biến hình"
        },
        "answer": "C"
      }
    ]
  },
  "will-ais-growing-power-demands-drain-the-grid": {
    "title": "AI Burns All the Energy",
    "collection": "hardware",
    "content": "The globe’s growing AI infrastructure requires huge amounts of electricity, possibly more than power providers can generate responsibly. Could AI models suck energy resources dry?\n\nThe fear:Demand for AI is skyrocketing, and with it the demand for energy to fuel training and inference. Power-hungry systems will overwhelm our current power sources. If unchecked, they could lead to energy shortages and runaway carbon emissions.\n\nHorror stories:AI companies don’t disclose the percentage of their energy needs that AI consumes, but top companies, led by OpenAI, havepitchedthe U.S. government to build out new energy sources and infrastructure. The trend is clear: Escalating demand risks tapping out existing power plants, pushing carbon emissions higher, and delaying moves to more sustainable energy sources.\n\nHow scared should you be:The rapid growth of AI poses a sharp dilemma: How can we meet demand without releasing greater and greater amounts of heat-trapping greenhouse gasses into the atmosphere? AI companies’ two-pronged strategy of lobbying governments and investing in carbon-free energy resources suggests the problem requires both short- and long-term approaches.\n\nFacing the fear:WhileAI poses a difficult problem for the world’s energy consumption, it’s also an important part of the solution. Learning algorithms arereducingenergy consumption andmanagingdistribution. They can helpcapture and storecarbon dioxide from energy plants and manufacturers before it reaches the atmosphere. AI is also helping to monitor the atmosphere, oceans, and forests so we canunderstandthe impacts of climate change and make policy accordingly. And processing in centralized data centers — as power-hungry as they are — is far more energy-efficient than using local servers or edge devices. Ongoing AI development will make such efforts more effective and help us build a more sustainable future.",
    "qa": [
      {
        "question": "Nỗi lo chính được đề cập trong bài viết liên quan đến sự phát triển của AI là gì?",
        "options": {
          "A": "Sự thiếu hụt các chuyên gia AI có trình độ.",
          "B": "Nhu cầu năng lượng gia tăng có thể vượt quá khả năng cung cấp bền vững.",
          "C": "Sự phụ thuộc quá mức vào các công ty công nghệ lớn.",
          "D": "Nguy cơ AI thay thế hoàn toàn con người trong công việc."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, các công ty AI đang thực hiện chiến lược gì để giải quyết vấn đề năng lượng?",
        "options": {
          "A": "Giảm quy mô hoạt động để tiết kiệm năng lượng.",
          "B": "Đầu tư vào nghiên cứu các nguồn năng lượng tái tạo và vận động chính phủ.",
          "C": "Chuyển sang sử dụng các thiết bị tiết kiệm năng lượng hơn.",
          "D": "Hợp tác với các công ty năng lượng để tối ưu hóa việc sử dụng năng lượng."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến một lợi ích tiềm năng của AI trong việc giải quyết vấn đề năng lượng là gì?",
        "options": {
          "A": "AI có thể tạo ra các nguồn năng lượng mới.",
          "B": "AI có thể giúp giảm tiêu thụ năng lượng và quản lý phân phối năng lượng hiệu quả hơn.",
          "C": "AI có thể thay thế hoàn toàn các nguồn năng lượng truyền thống.",
          "D": "AI có thể giúp các công ty AI trở nên độc lập hơn về năng lượng."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, việc xử lý dữ liệu trong các trung tâm dữ liệu tập trung có ưu điểm gì so với việc sử dụng các máy chủ cục bộ?",
        "options": {
          "A": "Chi phí vận hành thấp hơn.",
          "B": "An toàn dữ liệu cao hơn.",
          "C": "Hiệu quả năng lượng cao hơn.",
          "D": "Tốc độ xử lý nhanh hơn."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết cho rằng sự phát triển nhanh chóng của AI đặt ra một 'dilemma' (tình thế tiến thoái lưỡng nan) nào?",
        "options": {
          "A": "Làm thế nào để cân bằng giữa phát triển AI và bảo vệ quyền riêng tư.",
          "B": "Làm thế nào để đáp ứng nhu cầu AI mà không làm tăng lượng khí thải nhà kính.",
          "C": "Làm thế nào để đảm bảo AI được sử dụng một cách đạo đức.",
          "D": "Làm thế nào để phân phối lợi ích của AI một cách công bằng."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, các công ty AI thường không công khai thông tin gì liên quan đến năng lượng?",
        "options": {
          "A": "Tổng lượng năng lượng tiêu thụ hàng năm.",
          "B": "Chi phí năng lượng hàng tháng.",
          "C": "Tỷ lệ năng lượng tiêu thụ cho AI so với tổng nhu cầu.",
          "D": "Nguồn gốc của năng lượng sử dụng."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến việc AI có thể giúp ích trong việc gì liên quan đến khí hậu?",
        "options": {
          "A": "Dự báo thời tiết chính xác hơn.",
          "B": "Giảm thiểu tác động của các thảm họa tự nhiên.",
          "C": "Thu giữ và lưu trữ carbon dioxide từ các nhà máy và nhà sản xuất.",
          "D": "Phát triển các loại nhiên liệu sinh học mới."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì có thể xảy ra nếu nhu cầu năng lượng cho AI không được kiểm soát?",
        "options": {
          "A": "Giá điện sẽ giảm mạnh.",
          "B": "Nguồn cung năng lượng sẽ trở nên dồi dào hơn.",
          "C": "Có thể dẫn đến tình trạng thiếu năng lượng và gia tăng lượng khí thải carbon.",
          "D": "Các công ty năng lượng sẽ trở nên giàu có hơn."
        },
        "answer": "C"
      },
      {
        "question": "Ngoài việc giảm tiêu thụ năng lượng, AI còn có thể giúp ích trong việc gì liên quan đến môi trường, theo bài viết?",
        "options": {
          "A": "Tái chế rác thải hiệu quả hơn.",
          "B": "Giám sát khí quyển, đại dương và rừng để hiểu rõ hơn về tác động của biến đổi khí hậu.",
          "C": "Phát triển các vật liệu xây dựng thân thiện với môi trường.",
          "D": "Bảo tồn đa dạng sinh học."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết ngụ ý rằng giải pháp cho vấn đề năng lượng của AI cần những cách tiếp cận như thế nào?",
        "options": {
          "A": "Chỉ cần các giải pháp công nghệ tiên tiến.",
          "B": "Chỉ cần các chính sách tiết kiệm năng lượng nghiêm ngặt.",
          "C": "Cần cả cách tiếp cận ngắn hạn và dài hạn.",
          "D": "Chỉ cần sự hợp tác giữa các công ty AI và chính phủ."
        },
        "answer": "C"
      }
    ]
  },
  "a-new-language-model-tool-for-web-scraping-and-conversion": {
    "title": "A new language model tool for web scraping and conversion",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nUsing language models rather than rules-based tools to clean HTML\n\nJina AI released two language models, reader-lm-0.5b and reader-lm-1.5b, designed to convert raw HTML into text-based Markdown files for web content extraction and cleaning. Both models support a context length of 256,000 tokens and outperform larger language models despite their compact size. Jina AI trained them using a combination of real-world data from the Jina Reader API and synthetic data generated by GPT-4, implementing techniques like contrastive search and chunk-wise model forwarding to address challenges such as degeneration and memory constraints. The company plans to make both models available on Azure Marketplace and AWS SageMaker, with a non-commercial license for other use cases. (Jina AI)\n\nAI companies and Big Tech move to block sexual abuse imagery\n\nMajor U.S. tech companies including Adobe, Anthropic, Cohere, Common Crawl, Microsoft, OpenAI, Cash App, Square, Google, GitHub, Meta, and Snap Inc. pledged to take action against AI-generated sexual abuse imagery. Different companies made different commitments, including responsibly sourcing datasets, implementing safeguards, and improving reporting processes. The companies’ pledges follow a White House call to action and build on previous voluntary agreements to reduce risks from AI tools and address the surge in non-consensual intimate images and child sexual abuse materials. (The White House)\n\nLightEval evaluation suite released under an MIT license\n\nHugging Face released LightEval, an open source evaluation suite that allows companies and researchers to assess large language models according to their specific needs. The tool integrates with Hugging Face’s existing libraries and supports evaluation across multiple devices, offering flexibility for various hardware environments. LightEval addresses the growing demand for more transparent and adaptable AI evaluation methods as models become increasingly complex and integral to both users and developers. (GitHub)\n\nAdobe will add video generation by the end of the year\n\nAdobe introduced its new Firefly Video Model, which will power AI-driven features in video editing tools like Premiere Pro. The tool enables editors to generate B-roll footage, extend existing video clips, create animations, and produce atmospheric elements using text prompts or reference images. The tool supports text-to-video, image-to-video, and video-to-video (in limited contexts). Adobe designed the model to be commercially safe, training it only on licensed content to protect creators’ rights and ensure it can be used in commercial contexts. The company announced that Firefly Video will be available in beta later this year, with a waitlist for users interested in early access. (Adobe)\n\nMeta experiments with joint text and image “transfusion” models\n\nTransfusion combines language modeling and diffusion techniques to train a single transformer on both text and image data. Researchers at Meta pretrained models up to 7 billion parameters and found that Transfusion scales better than traditional methods of quantizing images for language models. This joint approach allows for efficient processing of mixed-modality data and produces competitive results in both text and image generation tasks. (Meta)\n\nNotebookLM can generate synthetic podcasts from your notes\n\nGoogle introduced Audio Overview, a feature in NotebookLM that generates AI-hosted discussions based on uploaded documents. The tool creates a conversation between two AI hosts who summarize and discuss the content, offering users an audio alternative to reading. While promising, the podcast feature has limitations such as English-only output, potential inaccuracies, and longer generation times for large notebooks. (Google)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng discussed why science-fiction scenarios of AI’s emergent behavior are likely to remain fictional:\n\n“While analogies between human and machine learning can be misleading, I think that just as a person’s ability to do math, to reason — or to deceive — grows gradually, so will AI’s. This means the capabilities of AI technology will grow gradually (although I wish we could achieve AGI overnight!), and the ability of AI to be used in harmful applications, too, will grow gradually.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Waymo highlighted its safety record, arguing that its autonomous vehicles are safer than human drivers on the same roads;2D-to-3D mesh generationis becoming widely accessible for industries like gaming and animation;Western powerssigned a legally binding AI treaty to regulate the technology’s impact on democracy and human rights; anda new automated methodwas developed to balance unbalanced datasets scraped from the web.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mục đích chính của hai mô hình reader-lm-0.5b và reader-lm-1.5b do Jina AI phát triển là gì?",
        "options": {
          "A": "Tạo ra hình ảnh từ văn bản.",
          "B": "Chuyển đổi HTML thô thành các tệp Markdown dựa trên văn bản để trích xuất và làm sạch nội dung web.",
          "C": "Phát hiện và chặn hình ảnh lạm dụng tình dục được tạo bởi AI.",
          "D": "Đánh giá hiệu suất của các mô hình ngôn ngữ lớn."
        },
        "answer": "B"
      },
      {
        "question": "Các công ty công nghệ lớn đã cam kết hành động chống lại loại nội dung nào do AI tạo ra?",
        "options": {
          "A": "Tin tức giả mạo.",
          "B": "Hình ảnh lạm dụng tình dục.",
          "C": "Nội dung vi phạm bản quyền.",
          "D": "Bình luận tiêu cực trên mạng xã hội."
        },
        "answer": "B"
      },
      {
        "question": "LightEval, công cụ được phát hành bởi Hugging Face, có chức năng chính là gì?",
        "options": {
          "A": "Tạo ra các mô hình ngôn ngữ lớn mới.",
          "B": "Đánh giá các mô hình ngôn ngữ lớn theo nhu cầu cụ thể của công ty và nhà nghiên cứu.",
          "C": "Chuyển đổi văn bản thành giọng nói.",
          "D": "Tự động dịch văn bản giữa các ngôn ngữ."
        },
        "answer": "B"
      },
      {
        "question": "Firefly Video Model của Adobe cho phép người dùng làm gì?",
        "options": {
          "A": "Tạo ra các ứng dụng di động từ văn bản.",
          "B": "Tạo ra các trang web từ hình ảnh.",
          "C": "Tạo ra cảnh quay B-roll, kéo dài các clip video hiện có và tạo hoạt ảnh bằng cách sử dụng lời nhắc văn bản hoặc hình ảnh tham khảo.",
          "D": "Phân tích và tóm tắt các video dài."
        },
        "answer": "C"
      },
      {
        "question": "Transfusion, mô hình được Meta thử nghiệm, kết hợp kỹ thuật nào?",
        "options": {
          "A": "Học tăng cường và mạng nơ-ron tích chập.",
          "B": "Mô hình hóa ngôn ngữ và kỹ thuật khuếch tán.",
          "C": "Xử lý ngôn ngữ tự nhiên và thị giác máy tính.",
          "D": "Học sâu và học máy."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng Audio Overview trong NotebookLM của Google tạo ra cái gì từ các tài liệu được tải lên?",
        "options": {
          "A": "Một bản tóm tắt văn bản tự động.",
          "B": "Một podcast tổng hợp với các cuộc thảo luận do AI dẫn dắt.",
          "C": "Một bản dịch sang nhiều ngôn ngữ.",
          "D": "Một bản trình bày trực quan."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, khả năng của AI sẽ phát triển như thế nào?",
        "options": {
          "A": "Đột ngột và không thể đoán trước.",
          "B": "Nhanh chóng và vượt trội so với con người.",
          "C": "Dần dần, tương tự như cách khả năng của con người phát triển.",
          "D": "Chỉ trong các lĩnh vực cụ thể, không có khả năng đạt được AGI."
        },
        "answer": "C"
      },
      {
        "question": "Waymo lập luận rằng xe tự hành của họ như thế nào so với người lái xe trên cùng một con đường?",
        "options": {
          "A": "Ít an toàn hơn do lỗi phần mềm.",
          "B": "An toàn hơn.",
          "C": "An toàn tương đương.",
          "D": "Chỉ an toàn hơn trong điều kiện thời tiết lý tưởng."
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ nào đang trở nên dễ tiếp cận hơn cho các ngành công nghiệp như trò chơi và hoạt hình?",
        "options": {
          "A": "Tạo mô hình 3D từ văn bản.",
          "B": "Tạo lưới 3D từ 2D.",
          "C": "Phân tích cảm xúc từ video.",
          "D": "Tạo nhạc từ hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Các cường quốc phương Tây đã ký một hiệp ước ràng buộc pháp lý về vấn đề gì?",
        "options": {
          "A": "Thúc đẩy phát triển AI nhanh chóng.",
          "B": "Điều chỉnh tác động của công nghệ AI đối với dân chủ và nhân quyền.",
          "C": "Chia sẻ dữ liệu AI giữa các quốc gia.",
          "D": "Cấm sử dụng AI trong quân sự."
        },
        "answer": "B"
      }
    ]
  },
  "a-new-technique-to-build-simple-but-powerful-reasoning-models": {
    "title": "A new technique to build simple but powerful reasoning models",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nOpen reasoning model fine-tuned using just 1,000 examples\n\nStanford researchers created a new AI reasoning model called s1-32B by fine-tuning Qwen2.5-32B-Instruct on just 1,000 carefully selected examples distilled from Google’s Gemini 2.0 Flash Thinking. The resulting s1-32B model matches or exceeds the performance of more complex closed models on challenging math and science benchmarks while being fully open source (model, data, and code). The researchers introduced a simple “budget forcing” technique that either ends the model’s thinking process when it exceeds a maximum token limit or extends it by appending “Wait” to the current reasoning trace when the model tries to conclude too early. This allows s1-32B to improve its reasoning as more compute is applied at test time, similar to capabilities seen in proprietary models but achieved with a much simpler approach. (arXivandGitHub)\n\nGoogle expands Gemini lineup with new capabilities\n\nGoogle released several updates to its Gemini 2.0 AI model family, including a generally available version of Gemini 2.0 Flash and an experimental version of Gemini 2.0 Pro. The company also introduced Gemini 2.0 Flash-Lite, a cost-efficient model with improved quality over its predecessor, and made 2.0 Flash Thinking Experimental available to Gemini app users. All of the Gemini 2.0 models can accept text and image inputs and return text outputs. The new Gemini 2.0 Flash costs slightly more than its predecessor, but Gemini 2.0 Flash-Lite is priced the same as Gemini 1.5 Flash. (Google)\n\nAnthropic develops robust defense against universal jailbreaks\n\nAnthropic’s new Constitutional Classifiers system successfully defended against thousands of hours of human attempts to jailbreak its Claude models. The method reduced jailbreak success rates from 86% to 4.4% in automated tests, with minimal increases in refusal rates and compute costs. The system works by training input and output classifiers on synthetically generated data based on a “constitution” of allowed and disallowed content, enabling it to detect and block potentially harmful inputs and outputs. Anthropic is hosting a live demo and offering rewards up to $20,000 for successful jailbreaks to further test and improve the system’s robustness. (AnthropicandarXiv)\n\nGitHub Copilot introduces agent mode and expands AI capabilities\n\nGitHub unveiled new features for its Copilot AI assistant, including an agent mode that can autonomously iterate on code and fix errors. The company also announced the general availability of Copilot Edits in Visual Studio Code, which allows developers to make multi-file changes using natural language commands. GitHub teased Project Padawan, an upcoming autonomous software engineering agent that can handle entire issues and pull requests, which could change how development teams manage routine tasks. (GitHub)\n\nRobotics company releases open source foundation model\n\nPhysical Intelligence made the code and weights for π0, their general-purpose vision-language-action model, available for download under an Apache 2.0 license (along with π0-FAST, which uses a different tokenizer). The model can be fine-tuned for various tasks across different robot types, with the company providing pre-trained checkpoints, example code, and fine-tuning instructions. π0 is particularly good at everyday tasks, like laundry-folding, and following instructions in natural language. The open source release aims to accelerate development of physical AI systems that can interact with and understand the world intuitively. (Physical IntelligenceandHugging Face)\n\nNew online book, “How to Scale Your Model,” demystifies training\n\nGoogle DeepMind researchers published a comprehensive guide on scaling language models using tensor processing units (TPUs). The book covers TPU architecture, efficient parallelization techniques, and practical tutorials for training and serving massive language models like Gemini 2.0 and Llama 3. This resource aims to help AI developers optimize model performance, estimate training costs, and make informed decisions about hardware utilization as language models continue growing in size and complexity. (GitHub)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng explores how AI is enabling a new generation of ‘10x professionals’ across various industries, not just in engineering, by transforming workflows and amplifying impact within and across teams.\n\n“A ‘10x engineer’—a widely accepted concept in tech—purportedly has 10 times the impact of the average engineer. But we don’t seem to have 10x marketers, 10x recruiters, or 10x financial analysts. As more jobs become AI-enabled, I think this will change, and there will be a lot more ‘10x professionals.’”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:OpenAI launched o3-mini, a faster and more cost-effective reasoning model excelling in coding, math, and science;UI-TARS demonstrated strong performancein computer use benchmarks, demonstrating its ability to interact with desktop and mobile interfaces;Google’s update to Gemini 2.0 Flash Thinkingoutperformed DeepSeek-R1 on key benchmarks; andMoshi, an open-source alternative to OpenAI’s Realtime API, showcased its always-on speech-to-speech interactions.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mô hình s1-32B của Stanford được tinh chỉnh từ mô hình nào?",
        "options": {
          "A": "Gemini 2.0 Flash Thinking",
          "B": "Qwen2.5-32B-Instruct",
          "C": "Llama 3",
          "D": "DeepSeek-R1"
        },
        "answer": "B"
      },
      {
        "question": "Kỹ thuật \"budget forcing\" được sử dụng trong mô hình s1-32B nhằm mục đích gì?",
        "options": {
          "A": "Tăng tốc độ xử lý của mô hình.",
          "B": "Kiểm soát quá trình suy luận của mô hình bằng cách giới hạn số lượng token hoặc kéo dài thời gian suy luận.",
          "C": "Giảm chi phí tính toán khi huấn luyện mô hình.",
          "D": "Cải thiện khả năng hiểu ngôn ngữ tự nhiên của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Phiên bản Gemini 2.0 nào được giới thiệu là có chi phí hiệu quả và chất lượng được cải thiện so với phiên bản tiền nhiệm?",
        "options": {
          "A": "Gemini 2.0 Flash",
          "B": "Gemini 2.0 Pro",
          "C": "Gemini 2.0 Flash-Lite",
          "D": "Gemini 2.0 Flash Thinking Experimental"
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống Constitutional Classifiers của Anthropic được sử dụng để làm gì?",
        "options": {
          "A": "Tăng tốc độ huấn luyện mô hình Claude.",
          "B": "Phát hiện và ngăn chặn các nỗ lực tấn công jailbreak vào mô hình Claude.",
          "C": "Cải thiện khả năng tạo sinh văn bản của mô hình Claude.",
          "D": "Giảm chi phí tính toán khi sử dụng mô hình Claude."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng mới nào của GitHub Copilot cho phép tự động lặp lại mã và sửa lỗi?",
        "options": {
          "A": "Copilot Edits",
          "B": "Project Padawan",
          "C": "Agent Mode",
          "D": "Visual Studio Code Integration"
        },
        "answer": "C"
      },
      {
        "question": "Mô hình π0 của Physical Intelligence thuộc loại mô hình nào?",
        "options": {
          "A": "Mô hình ngôn ngữ lớn.",
          "B": "Mô hình thị giác.",
          "C": "Mô hình thị giác-ngôn ngữ-hành động.",
          "D": "Mô hình dự đoán chuỗi thời gian."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của cuốn sách \"How to Scale Your Model\" là gì?",
        "options": {
          "A": "Hướng dẫn cách xây dựng kiến trúc TPU.",
          "B": "Cung cấp hướng dẫn toàn diện về việc mở rộng quy mô mô hình ngôn ngữ sử dụng TPU.",
          "C": "Giới thiệu các mô hình ngôn ngữ lớn mới nhất như Gemini 2.0 và Llama 3.",
          "D": "Giải thích các khái niệm cơ bản về học sâu."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, AI đang tạo ra một thế hệ chuyên gia như thế nào?",
        "options": {
          "A": "Chuyên gia về AI.",
          "B": "Chuyên gia có khả năng tự động hóa mọi công việc.",
          "C": "Chuyên gia có tác động lớn hơn gấp 10 lần so với trung bình.",
          "D": "Chuyên gia có khả năng thay thế hoàn toàn kỹ sư."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình nào được OpenAI ra mắt gần đây, nổi trội trong các lĩnh vực mã hóa, toán học và khoa học?",
        "options": {
          "A": "Gemini 2.0 Flash Thinking",
          "B": "o3-mini",
          "C": "DeepSeek-R1",
          "D": "Moshi"
        },
        "answer": "B"
      },
      {
        "question": "Công cụ nào thể hiện khả năng tương tác mạnh mẽ với giao diện máy tính để bàn và thiết bị di động?",
        "options": {
          "A": "Moshi",
          "B": "UI-TARS",
          "C": "o3-mini",
          "D": "π0"
        },
        "answer": "B"
      }
    ]
  },
  "adapting-r1-like-techniques-to-video-reasoning": {
    "title": "Adapting R1-like techniques to video reasoning",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nNew approach to reinforcement learning boosts video understanding\n\nResearchers at CUHK and other institutions created Video-R1, a new fully open source AI model designed to improve video reasoning capabilities in multimodal large language models through reinforcement learning. The team created two new datasets combining both image and video data for training and developed T-GRPO, a novel training algorithm that encourages temporal reasoning by comparing model performance on ordered versus shuffled video frames. At seven billion parameters, their Video-R1-7B model achieves state-of-the-art performance across multiple video reasoning benchmarks, notably reaching 35.8 percent accuracy on the VSI-Bench spatial reasoning test, surpassing GPT-4o. (arXivandGitHub)\n\nLanguage model mysteries revealed: How Claude thinks and plans\n\nAnthropic researchers used new interpretability techniques modeled on laboratory biology to examine how Claude processes information internally. By conducting experiments modififying Claude’s internal states, the team discovered that Claude plans ahead when writing poetry, uses parallel processing paths for mental math, and operates in a shared conceptual space across different languages. Although these methods only capture part of the total computations happening inside LLMs, these findings could help researchers better understand how AI systems work and could lead to more reliable and transparent models. (Anthropic)\n\nAlibaba launches powerful video generation model with open weights\n\nAlibaba Group released its technical report for Wan2.1, a suite of video and audio generation models available under an Apache 2.0 license. Wan2.1’s 1.3 billion parameter version requires only 8.19 GB of VRAM and can generate 5-second 480P videos in about 4 minutes on consumer GPUs. Its 14 billion parameter version shows strong capabilities in text-to-video, image-to-video, video editing, and in-video text generation in both Chinese and English, a novel capability. The paper details Wan2.1’s complete technical architecture, from its VAE and DiT model designs to training methods, data preparation, and performance optimization strategies. It also shows that Wan2.1 outperforms Runway and unspecified closed models on multiple benchmarks, including image-to-video and text-to-video evaluation. (arXivandGitHub)\n\nNovel discrete diffusion model unifies text and image generation\n\nResearchers at Carnegie Mellon developed UniDisc, a new multimodal architecture that applies discrete diffusion techniques to jointly generate text and images. The model introduces several technical innovations, including a unified masking strategy and classifier-free guidance, which enable it to outperform autoregressive baselines in conditional generation tasks and perform unusual tasks like simultaneous text-image inpainting. While UniDisc requires approximately 13 times more compute during training compared to autoregressive approaches, its ability to perform parallel inference and iteratively refine outputs leads to better generation quality and more efficient inference, particularly when scaling to larger models. (GitHubandarXiv)\n\nAlibaba introduces QVQ-Max visual analysis model\n\nAlibaba released QVQ-Max, a new visual reasoning model that analyzes images and videos while performing tasks like solving mathematical problems and generating code to recreate selected images. The model improves upon the company’s QVQ-72B-Preview from December 2023, adding adjustable levels of “thinking” by generating more reasoning tokens. For example, QVQ-Max can improve its performance on the MathVision multimodal math benchmark from 43.5 percent accuracy to 48.1 percent accuracy by adjusting its generation limit from 4,000 to 24,000 tokens. Alibaba says that this and future visual reasoning models will be able to both answer questions about images more accurately and serve as a creative and productivity tool, helping design or edit illustrations, blueprints, and other graphics. (GitHub)\n\nMicrosoft previews research and analysis tools for Copilot\n\nMicrosoft demonstrated two new AI agents called Researcher and Analyst, both designed to help workers analyze company data and web information. Researcher uses OpenAI’s deep research model to conduct complex investigations and create reports, while Analyst specializes in data analysis, using the o3-mini reasoning model to manage data queries with Python. The new tools, which will roll out to Microsoft 365 Copilot customers in April through a “Frontier” program, are part of Microsoft’s push to embed specialized AI capabilities directly into workplace software, using data in its cloud. (Microsoft)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng shared his thoughts on when fine-tuning small language models is truly necessary — and when simpler approaches like prompting or agentic workflows may be more effective and easier to maintain.\n\n“Because it adds extra complexity both in training and deployment, usually I resort to this technique only after I find that prompting and simple agentic workflows are not up to a task.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Google released Gemma 3, a family of compact vision-language models with open weights, enabling multimodal capabilities on a single GPU;researchers introduced shortcut modelsthat generate high-quality diffusion images in fewer steps, improving speed without sacrificing performance; a study showed thatGPT-4 can significantly enhance remote tutors’ effectivenessby providing real-time pedagogical support; and a new technique using pretrained embeddings like DINOv2 helpeddiffusion transformers learn faster, reducing training time while improving image quality.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mục tiêu chính của mô hình Video-R1 là gì?",
        "options": {
          "A": "Tạo ra video chất lượng cao từ văn bản.",
          "B": "Cải thiện khả năng suy luận video trong các mô hình ngôn ngữ lớn đa phương thức.",
          "C": "Phân tích và chỉnh sửa video một cách tự động.",
          "D": "Tăng tốc độ xử lý video trên các thiết bị di động."
        },
        "answer": "B"
      },
      {
        "question": "Kỹ thuật mới nào đã được các nhà nghiên cứu Anthropic sử dụng để khám phá cách Claude xử lý thông tin?",
        "options": {
          "A": "Mô phỏng các trạng thái bên trong của Claude bằng mạng nơ-ron nhân tạo.",
          "B": "Sử dụng các kỹ thuật diễn giải mô phỏng theo sinh học phòng thí nghiệm.",
          "C": "Phân tích nhật ký hoạt động của Claude để tìm ra các mẫu xử lý.",
          "D": "Tạo ra các bài kiểm tra trí tuệ nhân tạo đặc biệt để đánh giá Claude."
        },
        "answer": "B"
      },
      {
        "question": "Wan2.1 của Alibaba có gì đặc biệt so với các mô hình tạo video khác?",
        "options": {
          "A": "Khả năng tạo video 8K siêu nét.",
          "B": "Khả năng tạo văn bản trong video bằng cả tiếng Trung và tiếng Anh.",
          "C": "Yêu cầu phần cứng thấp, chạy được trên GPU tiêu dùng.",
          "D": "Cả B và C."
        },
        "answer": "D"
      },
      {
        "question": "UniDisc của Carnegie Mellon sử dụng kỹ thuật nào để tạo cả văn bản và hình ảnh?",
        "options": {
          "A": "Mạng nơ-ron hồi quy (RNN).",
          "B": "Mô hình khuếch tán rời rạc.",
          "C": "Mạng đối nghịch sinh (GAN).",
          "D": "Mô hình biến đổi (Transformer)."
        },
        "answer": "B"
      },
      {
        "question": "Điểm cải tiến chính của QVQ-Max so với QVQ-72B-Preview là gì?",
        "options": {
          "A": "Khả năng xử lý hình ảnh 3D.",
          "B": "Khả năng điều chỉnh mức độ 'suy nghĩ' bằng cách tạo ra nhiều token suy luận hơn.",
          "C": "Tốc độ xử lý hình ảnh nhanh hơn.",
          "D": "Độ chính xác cao hơn trong việc nhận diện khuôn mặt."
        },
        "answer": "B"
      },
      {
        "question": "Researcher và Analyst của Microsoft được thiết kế để làm gì?",
        "options": {
          "A": "Tạo ra các bản trình bày PowerPoint tự động.",
          "B": "Phân tích dữ liệu công ty và thông tin trên web.",
          "C": "Quản lý lịch làm việc và gửi email tự động.",
          "D": "Dịch văn bản giữa các ngôn ngữ khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, khi nào nên sử dụng fine-tuning cho các mô hình ngôn ngữ nhỏ?",
        "options": {
          "A": "Luôn luôn, vì fine-tuning luôn cải thiện hiệu suất.",
          "B": "Khi prompting và các quy trình agentic đơn giản không đủ để hoàn thành nhiệm vụ.",
          "C": "Khi cần tạo ra các mô hình chuyên biệt cho một lĩnh vực cụ thể.",
          "D": "Khi muốn giảm kích thước của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Gemma 3 của Google có đặc điểm gì nổi bật?",
        "options": {
          "A": "Là một mô hình ngôn ngữ lớn với hàng tỷ tham số.",
          "B": "Là một mô hình ngôn ngữ thị giác nhỏ gọn, có thể chạy trên một GPU.",
          "C": "Là một mô hình chuyên dụng cho việc tạo ra âm nhạc.",
          "D": "Là một mô hình mã nguồn đóng với hiệu suất vượt trội."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu của việc phát triển các mô hình 'shortcut' trong tạo ảnh khuếch tán là gì?",
        "options": {
          "A": "Tăng chất lượng hình ảnh được tạo ra.",
          "B": "Giảm số bước cần thiết để tạo ra hình ảnh chất lượng cao, tăng tốc độ.",
          "C": "Giảm kích thước của mô hình.",
          "D": "Đơn giản hóa quá trình huấn luyện mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu nào đã chỉ ra rằng GPT-4 có thể cải thiện hiệu quả của gia sư từ xa?",
        "options": {
          "A": "Nghiên cứu về việc sử dụng GPT-4 để tạo ra các bài tập tương tác.",
          "B": "Nghiên cứu về việc sử dụng GPT-4 để cung cấp hỗ trợ sư phạm theo thời gian thực cho gia sư.",
          "C": "Nghiên cứu về việc sử dụng GPT-4 để đánh giá kết quả học tập của học sinh.",
          "D": "Nghiên cứu về việc sử dụng GPT-4 để tạo ra các kế hoạch học tập cá nhân hóa."
        },
        "answer": "B"
      }
    ]
  },
  "ai-giants-u-s-policy-proposals": {
    "title": "AI giants’ U.S. policy proposals",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nU.S. AI companies weigh in on federal Action Plan\n\nAnthropic, Google, and OpenAI published policy proposals in response to U.S. President Trump calling for a national “AI Action Plan.” Both Google and OpenAI argued that the U.S. should implement fair use and data-mining exceptions to copyright restrictions, allowing AI companies to train their models on copyrighted material. OpenAI and Anthropic’s proposals both argued that certain Chinese models like DeepSeek should be restricted, with OpenAI calling them government-funded and Anthropic warning of biosecurity concerns. Other matters addressed include U.S. export controls on chips and other AI hardware and the broad regulations of the EU’s AI Act. (Anthropic,Google, andOpenAI)\n\nGoogle unveils Gemma 3 family of smaller, open weight models\n\nGoogle relesed Gemma 3, a set of multimodal models based on its Gemini 2.0 technology. The models range from 1 billion to 27 billion parameters and are designed to run on various devices, from smartphones to workstations. Gemma 3 supports over 140 languages and includes features like visual reasoning and a 128,000-token context window. Gemma 3 27B outperforms larger models like DeepSeek-V3 and Llama 3-405B on Chatbot Arena while remaining small enough to run on a single GPU. (Google)\n\nOpenAI introduces new tools for AI agent development\n\nOpenAI released new APIs and tools to help developers build AI agents. The new Responses API combines features from OpenAI’s existing Chat Completions and Assistants APIs, allowing models to use built-in tools like web search and file search. (OpenAI plans to phase out the Assistants API by mid-2026.) The company also launched an open-source Agents SDK for orchestrating multi-agent workflows. These tools aim to simplify the creation of AI systems that can perform complex tasks independently for developers using OpenAI models. (OpenAI)\n\nOlympicCoder models excel at competitive programming tasks\n\nResearchers affiliated with Open-R1 developed OlympicCoder, a set of 7B and 32B parameter models fine-tuned on competitive programming data that outperform some closed-source frontier models on challenging coding tasks. The models were trained on CodeForces-CoTs, a new dataset of nearly 100,000 high-quality coding samples distilled from DeepSeek-R1, and evaluated on a new benchmark using problems from the International Olympiad in Informatics (IOI). OlympicCoder-32B demonstrated particularly strong performance, surpassing all open weight models tested and even the much larger Claude Sonnet 3.7 on IOI problems. The new coding models are an important step in replicating the performance of DeepSeek’s R1 reasoning model using fully open data sets. (Hugging Face)\n\nAlibaba releases AI model that can read emotions\n\nAlibaba’s Tongyi Lab unveiled R1-Omni, an open vision model capable of inferring emotional states from video and audio inputs. The model, a reinforcement learning-enhanced version of the earlier HumanOmni, achieves state of the art performance on emotion recognition vision benchmarks. R1-Omni adds another nascent layer of understanding to vision models and is freely available on GitHub and Hugging Face. (GitHub)\n\nHugging Face’s smolagents evaluates top models for agents\n\nResearchers launched a leaderboard to measure large language models’ effectiveness in powering AI agents, using a CodeAgent on various benchmarks. GPT-4.5 topped the rankings, outperforming specialized reasoning models, with Claude 3.7 Sonnet placing second. The leaderboard shows that all models achieve significant performance gains from agentic setups compared to vanilla LLMs, providing valuable insights for AI developers working on agent-based systems. (Hugging Face)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng defended the importance of learning to code, arguing that as AI-assisted coding makes programming easier, more people should code—not fewer. He pushed back against claims that programming will become obsolete, arguing that understanding the “language of software” empowers individuals to work effectively with AI tools and maximize their impact.\n\n“I see tech-savvy people coordinating AI tools to move toward being 10x professionals — individuals who have 10 times the impact of the average person in their field. I am increasingly convinced that the best way for many people to accomplish this is not to be just consumers of AI applications, but to learn enough coding to use AI-assisted coding tools effectively.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:QwQ-32B emerged as a strong contenderagainst DeepSeek-R1 and other larger reasoning models, challenging the dominance of high-parameter architectures with compact reasoning; Microsoft’s Phi-4 Multimodal model offeredsimultaneous processing of text, images, and speech;a U.S. court ruling rejected the fair use defensein the Thomson Reuters AI lawsuit, citing Ross's attempt to use copyrighted material to build a competing product; andPerplexity launched an uncensored version of DeepSeek-R1, raising discussions about AI safety and adapting open language models.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Theo bài viết, những công ty AI nào đã đưa ra đề xuất chính sách đáp lại lời kêu gọi 'Kế hoạch Hành động AI' của Tổng thống Mỹ?",
        "options": {
          "A": "Microsoft, Google, và DeepSeek",
          "B": "Anthropic, Google, và OpenAI",
          "C": "OpenAI, DeepSeek, và Alibaba",
          "D": "Google, Alibaba, và Anthropic"
        },
        "answer": "B"
      },
      {
        "question": "Gemma 3 của Google có bao nhiêu tham số và dựa trên công nghệ nào?",
        "options": {
          "A": "Từ 1 tỷ đến 27 tỷ tham số, dựa trên Gemini 1.0",
          "B": "Từ 1 tỷ đến 27 tỷ tham số, dựa trên Gemini 2.0",
          "C": "Từ 10 tỷ đến 100 tỷ tham số, dựa trên Gemini 1.5",
          "D": "Từ 10 tỷ đến 100 tỷ tham số, dựa trên Gemini 2.0"
        },
        "answer": "B"
      },
      {
        "question": "OpenAI dự kiến sẽ ngừng hỗ trợ API Assistants vào thời điểm nào?",
        "options": {
          "A": "Cuối năm 2024",
          "B": "Đầu năm 2025",
          "C": "Giữa năm 2026",
          "D": "Cuối năm 2026"
        },
        "answer": "C"
      },
      {
        "question": "OlympicCoder được tinh chỉnh trên dữ liệu lập trình cạnh tranh nào?",
        "options": {
          "A": "GitHub-CoTs",
          "B": "CodeForces-CoTs",
          "C": "HuggingFace-CoTs",
          "D": "DeepSeek-CoTs"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào của Alibaba có khả năng suy luận trạng thái cảm xúc từ đầu vào video và âm thanh?",
        "options": {
          "A": "HumanOmni",
          "B": "R1-Omni",
          "C": "Tongyi Vision",
          "D": "EmotionAI"
        },
        "answer": "B"
      },
      {
        "question": "Theo bảng xếp hạng smolagents của Hugging Face, mô hình nào đứng đầu về hiệu quả trong việc hỗ trợ các AI agent?",
        "options": {
          "A": "Claude 3.7 Sonnet",
          "B": "DeepSeek-R1",
          "C": "GPT-4.5",
          "D": "Llama 3-405B"
        },
        "answer": "C"
      },
      {
        "question": "Andrew Ng cho rằng việc học lập trình quan trọng như thế nào trong bối cảnh AI hỗ trợ lập trình ngày càng phát triển?",
        "options": {
          "A": "Không còn quan trọng vì AI sẽ thay thế lập trình viên.",
          "B": "Ít quan trọng hơn vì AI giúp lập trình dễ dàng hơn.",
          "C": "Quan trọng hơn vì giúp mọi người sử dụng AI hiệu quả hơn.",
          "D": "Chỉ quan trọng đối với những người muốn trở thành chuyên gia AI."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình nào được đề cập đến như một đối thủ đáng gờm của DeepSeek-R1 trong lĩnh vực suy luận, mặc dù có số lượng tham số ít hơn?",
        "options": {
          "A": "Gemma 3 27B",
          "B": "QwQ-32B",
          "C": "OlympicCoder-32B",
          "D": "Phi-4 Multimodal"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào của Microsoft có khả năng xử lý đồng thời văn bản, hình ảnh và giọng nói?",
        "options": {
          "A": "Azure AI Vision",
          "B": "Cognitive Services",
          "C": "Phi-4 Multimodal",
          "D": "Bing AI"
        },
        "answer": "C"
      },
      {
        "question": "Vụ kiện Thomson Reuters AI liên quan đến vấn đề gì?",
        "options": {
          "A": "Vi phạm bằng sáng chế trong thiết kế chip AI.",
          "B": "Sử dụng trái phép dữ liệu cá nhân để huấn luyện mô hình AI.",
          "C": "Sử dụng tài liệu có bản quyền để xây dựng sản phẩm cạnh tranh.",
          "D": "Cạnh tranh không lành mạnh trong thị trường dịch vụ AI."
        },
        "answer": "C"
      }
    ]
  },
  "ai-can-guess-what-you-are-seeing": {
    "title": "AI can guess what you are seeing",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nAI systems reconstruct images from brain activity with remarkable accuracyResearchers at Radboud University used fMRI scans of human subjects and electrode array recordings from a macaque monkey, applying an improved AI system using a new technique they call predictive attention mechanisms. The key innovation is the AI’s ability to learn which specific brain regions are most informative for image reconstruction, allowing it to focus its attention on the most relevant neural signals. This research could lead to advanced brain implants for restoring vision by stimulating higher-level visual processing areas in the brain. (New Scientist)\n\nNew attention algorithm speeds up AI model processingTogether.AI released FlashAttention-3, a new algorithm that significantly accelerates the attention mechanism in large language models. The update achieves up to 75% utilization of an H100 GPU’s maximum capabilities, a substantial increase from the previous 35%. This advancement enables AI models to process longer text more efficiently and could lead to faster training times and improved performance for large language models. (Together.AI)\n\nMining firm uses AI to unearth massive copper deposit in ZambiaKoBold Metals uses an AI-powered database called TerraShed to identify promising mineral deposits, including valuable metals. The system integrates diverse data sources, including century-old paper maps, modern satellite imagery, and novel technologies like muon detectors. By analyzing huge amounts of this information, TerraShed can reveal previously undetected underground mineral formations. The company’s approach aims to make mineral exploration more effective and efficient as demand for battery metals increases worldwide. (The New York Times)\n\nAI becomes doctors’ ally in insurance battlesPhysicians are using AI chatbots to draft prior-authorization requests and appeal insurance claim denials more efficiently. Doctors like Dr. Azlan Tariq report significantly higher approval rates when using AI-generated letters, cutting down on time spent fighting insurers and improving patient care. This development raises concerns about a potential “AI arms race” between doctors and insurance companies, as both sides adopt the technology to streamline their processes. (The New York Times)\n\nAI-powered travel planner designs specialized trip itinerariesByway’s JourneyAI draws on multiple data sources to create customized flight-free itineraries, including transport timetables, fare information, and customer preferences. The tool analyzes data from previously successful trips to match new customers with similar traveler profiles and preferences. JourneyAI aims to design resilient multi-stop journeys by incorporating fallback options to manage potential disruptions along the route. (TechCrunch)\n\nOpenAI and Huffington team up on health coach projectSam Altman and Arianna Huffington are backing a new AI health coach that promises to offer personalized wellness advice based on scientific research and user data. The project, called Thrive AI Health, aims to nudge users toward healthier habits in areas like sleep and nutrition, with support from several medical institutions. While AI shows potential in healthcare, experts caution about privacy risks and the importance of maintaining human medical oversight. (The Verge)\n\nStill want to know more about what matters in AI right now?Readlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng wrote about how current attempts to regulate AI models in California could put developers at risk:\n\n“If this law passes, the fear of a trial by a jury — leading to a verdict that can be very unpredictable with significant penalties in the event of a conviction — will be very real. What if someone releases a model today after taking what they genuinely felt were reasonable safeguards, but a few years later, when views on AI technology might have shifted, some aggressive prosecutor manages to convince a jury that whatever they did was not, in hindsight, ‘reasonable’? Reasonableness is ambiguous and its legal interpretation can depend on case law, jury instructions, and common facts, among other things.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth included:Claude’s introduction of Artifacts, Amazon hires agentictalent from Adept, cloud computing companiesrethink their climate goals, and GaLore, a newoptimizer that saves memoryduring pretraining.",
    "qa": [
      {
        "question": "Hệ thống AI được phát triển bởi các nhà nghiên cứu tại Đại học Radboud sử dụng phương pháp nào để tái tạo hình ảnh từ hoạt động não bộ?",
        "options": {
          "A": "Sử dụng thuật toán học sâu dựa trên dữ liệu từ vệ tinh.",
          "B": "Áp dụng cơ chế chú ý dự đoán, tập trung vào các vùng não quan trọng nhất.",
          "C": "Phân tích sóng não bằng cách sử dụng điện não đồ (EEG).",
          "D": "Kết hợp dữ liệu từ các giác quan khác nhau để tạo ra hình ảnh tổng hợp."
        },
        "answer": "B"
      },
      {
        "question": "Thuật toán FlashAttention-3 của Together.AI giúp tăng hiệu suất sử dụng GPU H100 lên mức nào?",
        "options": {
          "A": "Tăng lên 50% so với phiên bản trước.",
          "B": "Đạt đến 75% khả năng tối đa của GPU.",
          "C": "Vượt quá 90% hiệu suất sử dụng GPU.",
          "D": "Giữ nguyên ở mức 35% nhưng giảm đáng kể thời gian training."
        },
        "answer": "B"
      },
      {
        "question": "Công ty KoBold Metals sử dụng hệ thống TerraShed để làm gì?",
        "options": {
          "A": "Dự báo giá kim loại trên thị trường chứng khoán.",
          "B": "Phát hiện và đánh giá các mỏ khoáng sản tiềm năng.",
          "C": "Tối ưu hóa quy trình khai thác khoáng sản hiện có.",
          "D": "Giám sát tác động môi trường của hoạt động khai thác."
        },
        "answer": "B"
      },
      {
        "question": "Việc sử dụng AI chatbot trong việc soạn thảo yêu cầu chấp thuận trước và kháng nghị từ chối bảo hiểm mang lại lợi ích gì cho bác sĩ?",
        "options": {
          "A": "Giảm chi phí thuê luật sư chuyên về bảo hiểm.",
          "B": "Tăng tỷ lệ chấp thuận và giảm thời gian xử lý.",
          "C": "Tự động hóa hoàn toàn quy trình giao tiếp với công ty bảo hiểm.",
          "D": "Cải thiện mối quan hệ với các công ty bảo hiểm."
        },
        "answer": "B"
      },
      {
        "question": "JourneyAI của Byway tạo ra các hành trình du lịch như thế nào?",
        "options": {
          "A": "Sử dụng dữ liệu từ các trang web du lịch nổi tiếng để đề xuất các điểm đến phổ biến.",
          "B": "Dựa trên dữ liệu từ các chuyến đi thành công trước đó và sở thích của khách hàng.",
          "C": "Tự động tạo ra các hành trình ngẫu nhiên dựa trên ngân sách của khách hàng.",
          "D": "Kết nối trực tiếp với các đại lý du lịch địa phương để tìm kiếm các ưu đãi tốt nhất."
        },
        "answer": "B"
      },
      {
        "question": "Dự án Thrive AI Health do Sam Altman và Arianna Huffington hỗ trợ tập trung vào lĩnh vực nào?",
        "options": {
          "A": "Phát triển các loại thuốc mới dựa trên công nghệ AI.",
          "B": "Cung cấp lời khuyên cá nhân hóa về sức khỏe và lối sống.",
          "C": "Chẩn đoán bệnh tật từ xa bằng cách sử dụng hình ảnh y tế.",
          "D": "Nghiên cứu về tác động của AI đối với sức khỏe tâm thần."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, điều gì có thể xảy ra nếu luật điều chỉnh mô hình AI ở California được thông qua?",
        "options": {
          "A": "Các nhà phát triển AI sẽ được bảo vệ tốt hơn trước các vụ kiện tụng.",
          "B": "Sự phát triển của AI sẽ được thúc đẩy mạnh mẽ hơn.",
          "C": "Các nhà phát triển AI có thể gặp rủi ro do sự không chắc chắn trong việc giải thích tính hợp lý.",
          "D": "Chi phí phát triển AI sẽ giảm đáng kể."
        },
        "answer": "C"
      },
      {
        "question": "Artifacts là tính năng mới được giới thiệu bởi sản phẩm nào?",
        "options": {
          "A": "ChatGPT.",
          "B": "Bard.",
          "C": "Claude.",
          "D": "Llama."
        },
        "answer": "C"
      },
      {
        "question": "Công ty nào đã tuyển dụng nhân tài về AI Agent từ Adept?",
        "options": {
          "A": "Google.",
          "B": "Microsoft.",
          "C": "Amazon.",
          "D": "Meta."
        },
        "answer": "C"
      },
      {
        "question": "GaLore là gì?",
        "options": {
          "A": "Một framework mới để phát triển ứng dụng AI.",
          "B": "Một ngôn ngữ lập trình chuyên dụng cho AI.",
          "C": "Một optimizer giúp tiết kiệm bộ nhớ trong quá trình pretraining.",
          "D": "Một mô hình AI mã nguồn mở."
        },
        "answer": "C"
      }
    ]
  },
  "alibaba-outdoes-itself-with-latest-open-models": {
    "title": "Alibaba outdoes itself with latest open models",
    "collection": "data-points",
    "content": "In today’s edition, you’ll learn more about:\n\nAlibaba debuts Qwen3 language models with hybrid reasoning\n\nAlibaba released Qwen3, a new family of large language models that support 119 languages and dialects. The family includes the flagship Qwen3-235B-A22B with 235 billion parameters and a smaller Qwen3-30B-A3B model, along with six dense models of various sizes. The models feature a hybrid approach that allows users to toggle between a deliberate “thinking mode” for complex reasoning and a faster “non-thinking mode” for simpler queries. Qwen3 models were trained on 36 trillion tokens — nearly double the training data of their predecessor — and boast better performance in coding, math, and other capabilities than competitors like DeepSeek-R1 and Gemini-2.5-Pro. All Qwen 3 models are open-weights and immediately available under the Apache 2.0 license on platforms including Hugging Face, ModelScope, and Kaggle. (Qwen Blog / GitHub)\n\nStudy claims Chatbot Arena gave big tech companies unfair advantages\n\nAuthors from Cohere, Stanford, MIT, and Ai2 accused LM Arena of allowing select AI companies to privately test multiple model variants on its Chatbot Arena benchmark while only publishing scores for their best performers. The paper alleges that companies including Meta, OpenAI, Google, and Amazon received preferential treatment that helped them achieve higher leaderboard rankings compared to competitors who weren’t offered the same opportunity. According to the study, Meta tested 27 model variants privately before its Llama 4 release but only publicly revealed the score for its top-performing model. Chatbot Arena has disputed these claims, calling the study full of “inaccuracies” and “questionable analysis,” while maintaining that its leaderboard is committed to fair evaluations and that all model providers are welcome to submit more tests. (arXivandTechCrunch)\n\nMicrosoft releases new Phi-4 reasoning models\n\nMicrosoft launched three new language models: Phi-4-reasoning, Phi-4-reasoning-plus, and Phi-4-mini-reasoning. The 14 billion parameter model Phi-4-reasoning-plus outperforms larger competitors when answering mathematical problems and scientific questions, including beating DeepSeek-R1 (671 billion parameters) on the 2025 USA Math Olympiad qualifier test. The open-weights models are available on Azure AI Foundry and Hugging Face, with versions for Copilot+ PCs planned for a future release. (Microsoft)\n\nOpenAI rolls back sycophantic GPT-4o update\n\nOpenAI reverted an April 25th update to GPT-4o that made the model excessively agreeable, particularly when validating users’ negative emotions. The update combined several changes that weakened the model’s primary reward signal, including a new signal based on user feedback that likely amplified this behavior. Despite positive results in offline evaluations and limited A/B testing, the company failed to adequately weigh qualitative concerns from expert testers who noticed the model’s behavior “felt slightly off.” OpenAI says it has implemented several new safeguards, including treating model behavior issues as launch-blocking concerns, introducing an “alpha” testing phase, and committing to more proactive communication about model updates. (OpenAI)\n\nAmazon releases Nova Premier multimodal model\n\nAmazon Web Services made Nova Premier generally available in Amazon Bedrock, adding to its existing Nova model family. Nova Premier (billed as Amazon’s largest model, but total parameter count unspecified) inputs text, images, and videos with a one million token context window and outputs text. AWS benchmarked Nova Premier using 17 different metrics, where it outperformed other Nova models and also matched competing models like Claude 3.7 Sonnet and GPT-4.5 in about half the evaluations. Developers can use Nova Premier as a teacher model to distill its capabilities into smaller, faster models or use it in conjunction with these smaller models for agentic workflows. Nova Premier is now available in three AWS regions for $2.50/$12.50 per million input/output tokens. (Amazon)\n\nMeta launches Llama API with one-click key creation and model playgrounds\n\nMeta announced a limited free preview of a new Llama API. Meta’s new developer site offers API key creation, interactive playgrounds for exploring Llama models, and tools for fine-tuning and evaluating custom versions of the company’s Llama 3.3 8B model. Meta emphasized that user prompts and responses won’t be used to train their AI models, and developers can export custom models rather than being locked to Meta’s servers. The company also announced collaborations with Cerebras and Groq for faster inference speeds. Access to Llama 4 models powered by these providers is now available by request. (Meta)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng highlighted an inspiring story of a high school basketball coach who learned to code and now teaches computer science, emphasizing how AI can help scale K-12 education by empowering both students and teachers.\n\n“Starting from K-12, we should teach every student AI-enabled coding, since this will enable them to become more productive and more empowered adults. But there is a huge shortage of computer science (CS) teachers… Whereas AI can directly deliver personalized advice to students, the fact that it is now helping teachers also deliver personalized support will really help in K-12.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:OpenAI launched API access to GPT Image 1, the image generator behind viral ChatGPT uploads; Google updated itsAI-powered music generation tools, targeting professional musicians and creators;CB Insights’ Top 100 AI Startups listidentified emerging players focused on AI agents and infrastructure; and researchers showed how large language models canimprove shopping recommendationsby inferring customer preferences from natural language input.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mô hình Qwen3-235B-A22B của Alibaba có bao nhiêu tham số?",
        "options": {
          "A": "30 tỷ",
          "B": "235 tỷ",
          "C": "671 tỷ",
          "D": "14 tỷ"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Qwen3 của Alibaba được huấn luyện trên bao nhiêu token?",
        "options": {
          "A": "18 nghìn tỷ",
          "B": "36 nghìn tỷ",
          "C": "72 nghìn tỷ",
          "D": "100 nghìn tỷ"
        },
        "answer": "B"
      },
      {
        "question": "Theo nghiên cứu, tổ chức nào bị cáo buộc cho phép các công ty công nghệ lớn thử nghiệm riêng các biến thể mô hình trên Chatbot Arena?",
        "options": {
          "A": "Hugging Face",
          "B": "LM Arena",
          "C": "ModelScope",
          "D": "Kaggle"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào của Microsoft được cho là vượt trội hơn DeepSeek-R1 trong việc giải các bài toán và câu hỏi khoa học?",
        "options": {
          "A": "Phi-4-mini-reasoning",
          "B": "Phi-4-reasoning",
          "C": "Phi-4-reasoning-plus",
          "D": "GPT-4o"
        },
        "answer": "C"
      },
      {
        "question": "OpenAI đã thực hiện những thay đổi nào sau khi nhận thấy GPT-4o trở nên quá dễ dãi?",
        "options": {
          "A": "Tăng cường kiểm tra A/B",
          "B": "Giảm thiểu phản hồi từ người dùng",
          "C": "Thực hiện các biện pháp bảo vệ mới và thử nghiệm 'alpha'",
          "D": "Loại bỏ hoàn toàn tín hiệu thưởng dựa trên phản hồi của người dùng"
        },
        "answer": "C"
      },
      {
        "question": "Mô hình Nova Premier của Amazon có khả năng xử lý loại dữ liệu nào?",
        "options": {
          "A": "Chỉ văn bản",
          "B": "Văn bản và hình ảnh",
          "C": "Văn bản, hình ảnh và video",
          "D": "Chỉ video"
        },
        "answer": "C"
      },
      {
        "question": "Meta đảm bảo điều gì về dữ liệu người dùng khi sử dụng Llama API?",
        "options": {
          "A": "Dữ liệu sẽ được sử dụng để cải thiện mô hình Llama 3",
          "B": "Dữ liệu sẽ được chia sẻ với các đối tác của Meta",
          "C": "Dữ liệu sẽ không được sử dụng để huấn luyện các mô hình AI của họ",
          "D": "Dữ liệu sẽ được mã hóa và lưu trữ an toàn"
        },
        "answer": "C"
      },
      {
        "question": "Andrew Ng nhấn mạnh tầm quan trọng của việc dạy gì cho học sinh từ cấp K-12?",
        "options": {
          "A": "Lập trình web",
          "B": "Khoa học dữ liệu",
          "C": "Lập trình hỗ trợ AI",
          "D": "Thiết kế đồ họa"
        },
        "answer": "C"
      },
      {
        "question": "Công cụ nào của Google được cập nhật để nhắm mục tiêu đến các nhạc sĩ và nhà sáng tạo chuyên nghiệp?",
        "options": {
          "A": "Google Translate",
          "B": "AI-powered music generation tools",
          "C": "Google Search",
          "D": "Google Docs"
        },
        "answer": "B"
      },
      {
        "question": "CB Insights' Top 100 AI Startups list tập trung vào những lĩnh vực nào?",
        "options": {
          "A": "Phần mềm quản lý dự án và công cụ cộng tác",
          "B": "Các đại lý AI và cơ sở hạ tầng",
          "C": "Nền tảng truyền thông xã hội và ứng dụng di động",
          "D": "Giải pháp an ninh mạng và bảo mật dữ liệu"
        },
        "answer": "B"
      }
    ]
  },
  "ai-models-can-generate-code-but-how-well-do-they-understand-it": {
    "title": "AI models can generate code, but how well do they understand it?",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nCodeMMLU benchmark shows gaps in AI models’ grasp of code\n\nResearchers in Vietnam introduced CodeMMLU, a multiple-choice question benchmark with over 10,000 questions to evaluate how well AI models understand code across multiple programming languages and software concepts. The test reveals that even advanced AI models face significant challenges in comprehending complex code structures, not just generating them. GPT-4o posted the highest score on the new benchmark, followed by Claude 3 Sonnet and Llama 3 70B; however, the researchers did not test newer versions of these models. (arXiv)\n\nFalcon’s new open-source model builds on Mamba\n\nResearchers unveiled Falcon Mamba 7B, a new language model that surpasses several leading open-source AI models based on traditional transformer and hybrid architectures, including Mistral 7B, Llama 3.1 8B, and Falcon2 11B. The model uses the Mamba architecture, which offers faster processing and lower memory requirements for long texts compared to its rivals. This achievement challenges recent beliefs about hybrid designs, demonstrating that pure Mamba-based models can compete with or outperform both transformer and hybrid architectures in language tasks. (arXiv)\n\nAMD releases powerful new AI chip to compete with NVIDIA\n\nAMD announced its MI325X AI accelerator chip, claiming it outperforms NVIDIA’s H200 GPUs when used in data centers for AI applications. The chip, expected in 2015, contains 153 billion transistors and delivers up to 2.61 PFLOPs of peak eight-bit precision performance. AMD’s move aims to narrow the gap with NVIDIA in the AI processor market, though the company still trails significantly in market share; AMD projects AI chip sales of $4.5 billion for 2024 compared to NVIDIA’s $26.3 billion in a single quarter. (AMDandArs Technica)\n\nTransformer variation reduces noise, boosts efficiency\n\nMicrosoft researchers proposed Differential Transformers, a new architecture that improves attention mechanisms in language models by amplifying relevant context and canceling noise. Experiments show differential transformers outperform standard transformers on language modeling tasks, requiring only about 65 percent of the model size or training tokens to achieve comparable performance. The architecture shows advantages in areas like long-context modeling, key information retrieval, hallucination mitigation, and in-context learning, showing potential as a foundation for large language models. (arXiv)\n\nPretraining on this dataset gives AI models a math and reasoning boost\n\nResearchers at the Chinese University of Hong Kong created a novel method to enhance AI models’ mathematical skills. They built a high-quality pretraining dataset called MathCode-Pile, which combines math-related sources with generated code that captures mathematical reasoning. The team trained four popular AI models (Llama-3-8B, DeepSeekMath-7B, Mistral-7B, and Code-Llama-7B) on this 19.2 billion-token dataset. This significantly improved the models’ math abilities, resulting in the new MathCoder2 family of AI models. (GitHub)\n\nAI system recreates pianists’ hand motions for any musical score\n\nScientists captured 10 hours of 3D hand motion data from 15 elite pianists playing 153 classical pieces. Using this dataset, they developed an AI system combining imitation learning, reinforcement learning, and diffusion models to generate realistic hand movements for new musical scores. The ability to recreate fine motor movement has potential applications in character animation, robotics, biomechanics, and virtual reality. (GitHub)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng celebrated the 2024 Nobel Prizes in Physics and Chemistry being awarded to pioneers in AI, recognizing the significant contributions of Geoff Hinton, John Hopfield, Demis Hassabis, John Jumper, and David Baker. He expressed excitement about the growing recognition of AI’s impact on various fields and reflected on the importance of celebrating innovators within the AI community.\n\n“Even as we cheer the new Nobel wins for AI, let’s continue to think about how we in AI can do more to celebrate the next generation of innovators.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: Meta debuts MovieGen for text-to-video generation;OpenAI unveils toolsfor speech, vision, and cost-efficiency for GPT-4o API at DevDay; a German court rules thatLAION did not violate copyrights, marking a win for AI in legal disputes; andresearchers expose a black marketfor AI-driven cybercrime services.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Benchmark CodeMMLU được giới thiệu nhằm mục đích gì?",
        "options": {
          "A": "Đánh giá khả năng tạo mã của các mô hình AI.",
          "B": "Đánh giá khả năng hiểu mã của các mô hình AI trên nhiều ngôn ngữ và khái niệm phần mềm.",
          "C": "So sánh hiệu suất của các ngôn ngữ lập trình khác nhau.",
          "D": "Tối ưu hóa hiệu suất của các trình biên dịch mã."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Falcon Mamba 7B sử dụng kiến trúc nào?",
        "options": {
          "A": "Transformer truyền thống.",
          "B": "Mamba.",
          "C": "Kiến trúc lai giữa Transformer và Mamba.",
          "D": "Falcon."
        },
        "answer": "B"
      },
      {
        "question": "Chip MI325X AI của AMD dự kiến ra mắt vào năm nào?",
        "options": {
          "A": "2023",
          "B": "2024",
          "C": "2025",
          "D": "2026"
        },
        "answer": "C"
      },
      {
        "question": "Kiến trúc Differential Transformers của Microsoft cải thiện cơ chế attention như thế nào?",
        "options": {
          "A": "Bằng cách tăng cường khả năng tạo mã.",
          "B": "Bằng cách khuếch đại ngữ cảnh liên quan và loại bỏ nhiễu.",
          "C": "Bằng cách giảm kích thước mô hình.",
          "D": "Bằng cách tăng tốc độ xử lý."
        },
        "answer": "B"
      },
      {
        "question": "Dataset MathCode-Pile được tạo ra nhằm mục đích gì?",
        "options": {
          "A": "Cải thiện khả năng tạo mã của mô hình AI.",
          "B": "Cải thiện khả năng xử lý ngôn ngữ tự nhiên của mô hình AI.",
          "C": "Cải thiện kỹ năng toán học và suy luận của mô hình AI.",
          "D": "Cải thiện khả năng dịch thuật của mô hình AI."
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống AI tái tạo chuyển động tay của nghệ sĩ piano sử dụng những phương pháp nào?",
        "options": {
          "A": "Học tăng cường và học có giám sát.",
          "B": "Học bắt chước, học tăng cường và mô hình khuếch tán.",
          "C": "Học sâu và mạng nơ-ron tích chập.",
          "D": "Xử lý ngôn ngữ tự nhiên và thị giác máy tính."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, giải Nobel năm 2024 vinh danh những đóng góp của ai trong lĩnh vực AI?",
        "options": {
          "A": "Các nhà khoa học máy tính hàng đầu thế giới.",
          "B": "Những người tiên phong trong lĩnh vực AI.",
          "C": "Các nhà phát triển phần mềm AI.",
          "D": "Các nhà đầu tư vào công nghệ AI."
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào đã ra mắt MovieGen cho việc tạo video từ văn bản?",
        "options": {
          "A": "OpenAI",
          "B": "Google",
          "C": "Meta",
          "D": "Microsoft"
        },
        "answer": "C"
      },
      {
        "question": "Vụ kiện bản quyền liên quan đến LAION đã có kết quả như thế nào tại Đức?",
        "options": {
          "A": "LAION bị kết tội vi phạm bản quyền.",
          "B": "LAION không vi phạm bản quyền.",
          "C": "Vụ kiện vẫn đang được xét xử.",
          "D": "LAION phải trả tiền bản quyền cho các tác giả."
        },
        "answer": "B"
      },
      {
        "question": "OpenAI đã giới thiệu những công cụ mới nào tại DevDay?",
        "options": {
          "A": "Công cụ tạo mã và gỡ lỗi.",
          "B": "Công cụ cho giọng nói, thị giác và tối ưu chi phí cho GPT-4o API.",
          "C": "Công cụ phân tích dữ liệu và dự đoán xu hướng.",
          "D": "Công cụ dịch thuật và tóm tắt văn bản."
        },
        "answer": "B"
      }
    ]
  },
  "alibabas-impressive-suite-of-open-models": {
    "title": "Alibaba’s impressive suite of open models",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nQwen project releases over one hundred updated open models\n\nAlibaba unveiled Qwen2.5, a new and remarkably numerous suite of open-source language models. The models include general-purpose, coding, and math-focused variants in multiple sizes up to 72 billion parameters. Qwen2.5 models introduce enhancements like longer text generation, better structured data handling, and more reliable JSON output. They demonstrate improved performance across benchmarks, with the 72B version competing with leading proprietary and open-source models on tasks like knowledge, reasoning, and instruction following. (GitHub)\n\nMistral cuts developer prices, introduces free tier\n\nMistral AI announced price reductions across its model lineup, with its flagship Mistral Large model seeing a 33% price cut to $2 per million input tokens. The company introduced a free tier for its development platform and released an improved 22-billion-parameter Mistral Small model under its research license. Mistral also added free vision capabilities to its chatbot using the Apache 2.0-licensed Pixtral 12B model, allowing users to analyze images without data privacy concerns. (Mistral AI)\n\nRunway adds video-to-video and a developer API\n\nRunway revealed that its Gen-3 Alpha video model can now transform video styles using text prompts. Runway also introduced an API for its Gen-3 Alpha Turbo model, offering developers a way to incorporate video generation into their own applications. The API, currently in limited access, requires users to display a “Powered by Runway” banner and comes with two pricing plans. The platform charges 50 credits for videos up to 5 seconds and 100 credits for videos between 5 and 10 seconds, with a 10-second maximum duration. (Runway)\n\nKyutai releases new low-latency open-source audio model\n\nMoshi is a new speech-text and speech-to-speech model from Kyutai. It uses Mimi, a new streaming neural audio codec that processes audio more efficiently than existing codecs. The model incorporates two audio streams, one for Moshi and one for the user, and predicts text tokens corresponding to its own inner monologue to improve generation quality. Moshi achieves impressively low latency and high performance. The developers released three models: the Mimi speech codec and two versions of Moshi fine-tuned on synthetic voices. All are available under open-source licenses for research and commercial use. (GitHub)\n\nLlamaCoder’s app builder turns heads\n\nMeta spotlighted Together AI’s LlamaCoder, an open-source web app that uses Llama 3.1 405B to generate complete web applications from user prompts. The app has gained significant traction in just over a month, with over 2,000 GitHub stars, hundreds of repository clones, and more than 200,000 generated applications. This rapid adoption demonstrates the growing interest in open-source AI models for application development and highlights the potential of Llama 3.1 competing with closed-source alternatives. (Meta)\n\nCalifornia approves laws to regulate AI in elections and movies\n\nCalifornia Governor Gavin Newsom signed legislation aimed at protecting Hollywood actors and performers from unauthorized AI-generated digital clones. The new laws allow performers to back out of contracts with vague language about AI use; they also prevent commercial cloning of deceased performers without estate permission. Newsom also signed three bills to prohibit using artificial intelligence to create false images or videos for political ads. One law makes it illegal to create and publish deepfakes related to elections within 120 days before and 60 days after Election Day, while another requires large social media platforms to remove deceptive material. (AP NewsandAP News)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng highlighted the role of data engineering in AI and introduced a new professional certificate on Coursera.\n\n“Data underlies all modern AI systems, and engineers who know how to build systems to store and serve it are in high demand. Today, far too many businesses struggle to build a robust data infrastructure, which leads to missed opportunities to create value with data analytics and AI.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:OpenAI’s latest modelexcels in math, science, and coding, though its reasoning process isn’t visible;SambaNova increased inference speedsfor Meta’s Llama 3.1 405B model;Amazon enhanced its warehouse automationby acquiring Covariant’s model-building talent and tech; and researchers proposeda method to reduce memorization in large language models, addressing privacy concerns.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Dự án Qwen của Alibaba vừa cho ra mắt phiên bản Qwen2.5 với điểm nổi bật nào?",
        "options": {
          "A": "Khả năng tạo ra hình ảnh 3D từ văn bản.",
          "B": "Một bộ sưu tập lớn các mô hình ngôn ngữ mã nguồn mở được cập nhật.",
          "C": "Tích hợp trực tiếp vào hệ điều hành Android.",
          "D": "Khả năng tự động dịch thuật các ngôn ngữ cổ đại."
        },
        "answer": "B"
      },
      {
        "question": "Mistral AI đã thực hiện thay đổi gì về giá và chính sách sử dụng mô hình của họ?",
        "options": {
          "A": "Tăng giá tất cả các mô hình và loại bỏ phiên bản miễn phí.",
          "B": "Giảm giá mô hình Mistral Large và giới thiệu phiên bản miễn phí cho nền tảng phát triển.",
          "C": "Chỉ cung cấp mô hình cho các tổ chức nghiên cứu khoa học.",
          "D": "Yêu cầu tất cả người dùng phải trả phí bản quyền hàng năm."
        },
        "answer": "B"
      },
      {
        "question": "Runway Gen-3 Alpha Turbo API cho phép các nhà phát triển làm gì?",
        "options": {
          "A": "Tạo ra các ứng dụng chỉnh sửa ảnh chuyên nghiệp.",
          "B": "Tích hợp khả năng tạo video vào ứng dụng của họ.",
          "C": "Phân tích dữ liệu video để tìm ra xu hướng.",
          "D": "Tự động tạo phụ đề cho video."
        },
        "answer": "B"
      },
      {
        "question": "Moshi, mô hình âm thanh mới từ Kyutai, sử dụng công nghệ nào để xử lý âm thanh hiệu quả hơn?",
        "options": {
          "A": "Giải thuật nén âm thanh Lossless.",
          "B": "Mimi, một codec âm thanh thần kinh trực tuyến mới.",
          "C": "Công nghệ khử tiếng ồn chủ động AI.",
          "D": "Mạng nơ-ron biến đổi âm thanh thành văn bản."
        },
        "answer": "B"
      },
      {
        "question": "LlamaCoder của Together AI sử dụng mô hình nào để tạo ra các ứng dụng web hoàn chỉnh từ yêu cầu của người dùng?",
        "options": {
          "A": "GPT-4 Turbo.",
          "B": "Llama 3.1 405B.",
          "C": "Gemini 1.5 Pro.",
          "D": "Claude 3 Opus."
        },
        "answer": "B"
      },
      {
        "question": "California đã thông qua luật gì liên quan đến AI trong lĩnh vực giải trí?",
        "options": {
          "A": "Yêu cầu tất cả các bộ phim sử dụng AI phải có cảnh báo.",
          "B": "Bảo vệ diễn viên khỏi việc sử dụng trái phép bản sao kỹ thuật số do AI tạo ra.",
          "C": "Cấm hoàn toàn việc sử dụng AI trong sản xuất phim.",
          "D": "Hỗ trợ tài chính cho các dự án phim sử dụng AI sáng tạo."
        },
        "answer": "B"
      },
      {
        "question": "Luật mới ở California quy định về việc sử dụng deepfake trong quảng cáo chính trị như thế nào?",
        "options": {
          "A": "Cho phép sử dụng deepfake nếu có sự đồng ý của tất cả các bên liên quan.",
          "B": "Cấm tạo và xuất bản deepfake liên quan đến bầu cử trong một khoảng thời gian nhất định trước và sau ngày bầu cử.",
          "C": "Khuyến khích sử dụng deepfake để tăng tính tương tác của quảng cáo.",
          "D": "Chỉ cấm sử dụng deepfake nếu nó gây ra thiệt hại về tài sản."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, yếu tố nào đóng vai trò quan trọng trong các hệ thống AI hiện đại?",
        "options": {
          "A": "Thuật toán học sâu tiên tiến.",
          "B": "Kỹ thuật dữ liệu để xây dựng hệ thống lưu trữ và phục vụ dữ liệu.",
          "C": "Sức mạnh tính toán của phần cứng.",
          "D": "Số lượng lớn các nhà nghiên cứu AI."
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào đã mua lại tài năng và công nghệ xây dựng mô hình của Covariant để tăng cường tự động hóa kho hàng?",
        "options": {
          "A": "Microsoft.",
          "B": "Google.",
          "C": "Amazon.",
          "D": "Apple."
        },
        "answer": "C"
      },
      {
        "question": "Nghiên cứu mới đề xuất phương pháp gì để giải quyết các lo ngại về quyền riêng tư liên quan đến mô hình ngôn ngữ lớn?",
        "options": {
          "A": "Tăng cường mã hóa dữ liệu huấn luyện.",
          "B": "Giảm thiểu khả năng ghi nhớ dữ liệu trong mô hình.",
          "C": "Sử dụng dữ liệu tổng hợp thay vì dữ liệu thực.",
          "D": "Yêu cầu người dùng đồng ý chia sẻ dữ liệu trước khi sử dụng mô hình."
        },
        "answer": "B"
      }
    ]
  },
  "all-about-claudes-new-opus-and-sonnet": {
    "title": "All about Claude’s new Opus and Sonnet",
    "collection": "data-points",
    "content": "In today’s edition, you’ll learn more about:\n\nAnthropic introduces Claude Opus 4 and Sonnet 4 models\n\nAnthropic released its new Claude Opus 4 and Sonnet 4 models with improvements in coding and reasoning capabilities. Opus 4 reached 72.5 percent on SWE-bench and 43.2 percent on Terminal-bench coding tests, while Sonnet 4 achieved 72.7 percent on SWE-bench, outperforming earlier Claude models and rivals from OpenAI. Both new models can now use tools during their reasoning process, execute tools in parallel, and demonstrate better memory when accessing local files. The models are available through Anthropic, Amazon Bedrock, and Google Cloud’s Vertex AI, with Opus 4 priced at $15/$75 per million tokens (input/output) and Sonnet 4 at $3/$15. (Anthropic)\n\nGoogle rebrands subscription to AI Pro, launches new Ultra tier\n\nGoogle is renaming its AI Premium subscription to “Google AI Pro” while introducing a new high-end “Google AI Ultra” tier priced at $249.99 per month. Google AI Pro maintains its $19.99 monthly price with access to Gemini 2.5 Pro, 2TB storage, Deep Research, and Veo 2 video generation, plus new features like early access to Gemini in desktop Chrome and the Flow AI filmmaking tool. The Ultra tier includes all Pro features plus 30TB storage, YouTube Premium, highest usage limits for AI tools, and exclusive access to experimental features like Project Mariner, which can manage multiple tasks simultaneously. Google is offering an introductory price of $124.99 for Ultra’s first three months, with availability starting today in the U.S. and expanding to other countries soon. (9to5Google)\n\nOpenAI partners with Jony Ive on AI assistant device\n\nSam Altman revealed to OpenAI staff that the company is developing AI “companions” with newly acquired design firm io, led by former Apple designer Jony Ive. The planned device will be aware of users’ surroundings, unobtrusive enough to fit in a pocket or on a desk, and is intended to become a third essential device alongside laptops and smartphones. Altman described the product as a “family of devices” that will integrate hardware and software similar to Apple’s approach, emphasizing that the technology will move beyond typing queries into websites. OpenAI aims to ship 100 million devices by late next year, with Altman suggesting the $6.5 billion acquisition could add $1 trillion in value to the company. (The Verge)\n\nMistral AI releases Devstral, an open-weight coding LLM\n\nMistral AI and All Hands AI launched Devstral, an agentic large language model specifically designed for software engineering tasks. The model achieves 46.8 percent on SWE-Bench Verified, outperforming other open-weight models by more than 6 percentage points and surpassing GPT-4.1-mini by over 20 percent. Unlike many LLMs that excel at isolated coding tasks, Mistral says Devstral can solve more complex software engineering problems by contextualizing code within large codebases and identifying relationships between components. The model is lightweight enough to run on a single RTX 4090 or a Mac with 32GB RAM, making it suitable for local deployment. Devstral is available for free under the Apache 2.0 license on HuggingFace, Ollama, and other platforms, or through Mistral’s API at $0.10/$0.30 per million tokens of input/output. (Mistral)\n\nNew Arabic language model outperforms larger competitors\n\nThe Technology Innovation Institute released Falcon-Arabic, a 7B parameter language model built on the Falcon 3 architecture. The model handles Arabic, English, and several other languages with a 32,000 token context window. Testing shows Falcon-Arabic outperforms other Arabic language models of similar size and some larger models on benchmarks including Arabic MMLU, Exams, MadinahQA, and Aratrust. The developers extended the base model with 32,000 Arabic-specific tokens and used native Arabic datasets for training rather than translated content. The model supports both Modern Standard Arabic and regional dialects, addressing the relative scarcity of Arabic language AI tools. Users can test Falcon-Arabic through an online playground. (Hugging Face)\n\nGoogle previews Gemma 3n, a mobile-optimized multimodal model\n\nGoogle unveiled Gemma 3n, a new open AI model specifically engineered for on-device use with a significantly reduced memory footprint. The model leverages per-layer embeddings technology that allows 5B and 8B parameter models to operate with just 2GB and 3GB of memory, making them suitable for phones, tablets, and laptops. Gemma 3n offers multimodal capabilities including text, image, video, and audio processing, with new features like automatic speech recognition and translation. The model was designed in collaboration with mobile hardware companies like Samsung, Qualcomm, and MediaTek to enable offline use, and will be the basis for the next version of Gemini Nano. Developers can preview Gemma 3n through Google AI Studio or Google AI Edge for on-device development. (Google)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng shared how large companies can move fast in the age of AI by creating sandbox environments that allow small teams to innovate without needing constant permission.\n\n“If engineers need sign-off from 5 vice presidents before they’re even allowed to launch an MVP (minimum viable product) to run an experiment, how can they ever discover what customers want, iterate quickly, or invent any meaningful new product?”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:OpenAI introduced Codex, a new multi-agent, cloud-based software engineering tool integrated into ChatGPT; xAI attributed thecontroversial “white genocide” responses from Grokto an unnamed, unauthorized employee, raising concerns about internal safeguards; U.S. tech giants including Nvidia, AMD, and Amazon secured dealsto supply chips and infrastructure to Middle Eastern companieslike Saudi Arabia’s Humain and the UAE’s G42; and Microsoft researchers showed that 4-bit quantized versions of Llama models canmatch the accuracy of 16-bit models, offering major efficiency gains without compromising performance.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mô hình Claude Opus 4 đạt được kết quả bao nhiêu phần trăm trên SWE-bench?",
        "options": {
          "A": "72.7%",
          "B": "72.5%",
          "C": "43.2%",
          "D": "75%"
        },
        "answer": "B"
      },
      {
        "question": "Google AI Ultra có giá bao nhiêu mỗi tháng?",
        "options": {
          "A": "$19.99",
          "B": "$124.99",
          "C": "$249.99",
          "D": "$299.99"
        },
        "answer": "C"
      },
      {
        "question": "Công ty thiết kế nào đang hợp tác với OpenAI để phát triển thiết bị AI 'companions'?",
        "options": {
          "A": "Apple",
          "B": "io",
          "C": "Google",
          "D": "Microsoft"
        },
        "answer": "B"
      },
      {
        "question": "Devstral, mô hình ngôn ngữ lớn dành cho kỹ thuật phần mềm, được phát hành bởi công ty nào?",
        "options": {
          "A": "OpenAI",
          "B": "Google",
          "C": "Mistral AI",
          "D": "Anthropic"
        },
        "answer": "C"
      },
      {
        "question": "Falcon-Arabic, mô hình ngôn ngữ mới, được xây dựng dựa trên kiến trúc nào?",
        "options": {
          "A": "GPT-3",
          "B": "Llama 2",
          "C": "Falcon 3",
          "D": "Gemini Pro"
        },
        "answer": "C"
      },
      {
        "question": "Gemma 3n được tối ưu hóa để sử dụng trên thiết bị nào?",
        "options": {
          "A": "Máy chủ",
          "B": "Điện thoại di động",
          "C": "Siêu máy tính",
          "D": "Trung tâm dữ liệu"
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, các công ty lớn có thể tăng tốc độ đổi mới AI bằng cách nào?",
        "options": {
          "A": "Tăng cường kiểm soát từ các cấp quản lý",
          "B": "Tạo môi trường sandbox cho các nhóm nhỏ",
          "C": "Thuê nhiều chuyên gia AI hơn",
          "D": "Tập trung vào các dự án lớn, dài hạn"
        },
        "answer": "B"
      },
      {
        "question": "Công cụ kỹ thuật phần mềm đa tác nhân, dựa trên đám mây mới được OpenAI giới thiệu có tên là gì?",
        "options": {
          "A": "Devstral",
          "B": "Codex",
          "C": "Gemma",
          "D": "Falcon"
        },
        "answer": "B"
      },
      {
        "question": "Tổ chức nào đã quy trách nhiệm cho phản hồi 'diệt chủng người da trắng' gây tranh cãi từ Grok?",
        "options": {
          "A": "OpenAI",
          "B": "Google",
          "C": "xAI",
          "D": "Anthropic"
        },
        "answer": "C"
      },
      {
        "question": "Công nghệ nào cho phép các phiên bản lượng tử hóa 4-bit của mô hình Llama có thể đạt được độ chính xác tương đương với các mô hình 16-bit?",
        "options": {
          "A": "Per-layer embeddings",
          "B": "Quantization aware training",
          "C": "4-bit quantization",
          "D": "Không có công nghệ nào, thông tin này không chính xác"
        },
        "answer": "C"
      }
    ]
  },
  "all-the-models-weve-been-waiting-for": {
    "title": "All the models we’ve been waiting for",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nMicrosoft unveils new Phi-4 models for multimodal and text-based AI\n\nMicrosoft released two new models in its open weights Phi-4 family: Phi-4-multimodal, a 5.6 billion parameter model capable of processing speech, vision, and text simultaneously, and Phi-4-mini, a 3.8 billion parameter language model optimized for text-based tasks. Phi-4-multimodal outperforms larger models on various benchmarks, including speech recognition and visual reasoning, while Phi-4-mini excels in tasks like coding and math. These compact models enable developers to create efficient AI applications for edge devices, smartphones, and vehicles. (Microsoft)\n\nGPT-4.5 advances unsupervised learning at a premium\n\nOpenAI released a research preview of GPT-4.5, showcasing significant improvements in pattern recognition, knowledge breadth, and reduced hallucinations compared to previous models. The new model is faster and interacts more naturally with users than o3, and it excels relative to GPT-4o at tasks like writing assistance, programming, and creative problem-solving, as measured by benchmarks like GPQA and MMMLU. GPT-4.5 represents a major advancement in scaling unsupervised learning, but its high computational requirements make it substantially more expensive than previous models, with OpenAI charging API users $75 per million input tokens and $150 per million output tokens. GPT-4.5’s high costs makes its future uncertain, since it does not outperform reasoning models like o3, and more lightweight models like GPT-4o can perform many of the same tasks at a fraction of the price. (OpenAI)\n\nDiffusion models promise faster text generation than transformers\n\nInception Labs unveiled Mercury, a family of diffusion large language models (dLLMs) that generate text up to 10 times faster than current LLMs. Mercury Coder, the first publicly available dLLM, matches or surpasses the performance of speed-optimized autoregressive models on coding benchmarks while running at over 1,000 tokens per second on NVIDIA H100 GPUs. Pricing for the new model via API is private, but the Coder model is available through a web-based playground. New diffusion architectures could enable more efficient language-model-based applications, including improved agents, reasoning capabilities, and edge deployments on resource-constrained devices. (Inception Labs)\n\nAlibaba expands open AI offerings with video generation models\n\nAlibaba Cloud released four open weights models from its Wan2.1 video model series, making them freely available for download on Model Scope and Hugging Face. The models can generate video from text and image inputs, with Wan2.1-14B leading the VBench leaderboard for video models. Wan2.1-14B is the only open video generation model in the VBench top five, making it a compelling option for students, artists, and researchers to experiment with video models. (Alizila)\n\nHunyuan Turbo S offers faster AI responses at a low price\n\nTencent released Hunyuan Turbo S, a new language model designed for near-instant responses. The model doubles word output speed and reduces first-word latency by 44 percent compared to traditional models, using a novel hybrid Mamba-Transformer architecture to lower training and inference costs. Hunyuan Turbo S performs comparably to leading models like DeepSeek V3, GPT-4o, and Claude 3.5 Sonnet on public benchmark tests like MMLU, AIME 2024, and ArenaHard, with especially high scores on Chinese-specific benchmarks. Tencent priced Hunyuan Turbo S competitively at 0.8 yuan per million tokens for input and 2 yuan per million tokens for output, offering an intriguing alternative to competing model from DeepSeek, Baidu, and Alibaba. (ReutersandAIbase)\n\nIBM offers new Granite models with reasoning abilities\n\nIBM released several new models in its Granite series, including improved language models, a multimodal vision model, and embedding models. The Granite 3.2 8B and 2B Instruct models feature experimental chain-of-thought reasoning modes that allow them to handle complex instructions more effectively, while the new Granite Vision 3.2 2B model focuses on document understanding. These open weights models are now available on IBM watsonx.ai, Hugging Face, and other platforms, showing IBM’s efforts to compete with larger language models by offering specialized capabilities. (IBM)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng discussed advancements in voice AI, challenges in controlling voice models, and techniques to reduce latency in voice interactions. He highlighted DeepLearning.AI’s work with RealAvatar and encouraged developers to prototype voice applications.\n\n“I think generating a pre-response followed by a full response, to quickly acknowledge the user’s query and also reduce the perceived latency, will be an important technique, and I hope many teams will find this useful.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Researchers unveiled Brain2Qwerty, a nonsurgical system that decodes thoughts using brain waves, enabling mind-to-text communication;tech giants ramped up cloud spendingto meet the surging demand for AI infrastructure;a viral deepfake videosparked legal debate after using AI to depict celebrities without their consent; andMeta introduced Chain of Continuous Thought (Coconut), a new approach to reasoning, using vectors rather than text to improve next-token prediction.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mục tiêu chính của việc phát triển các mô hình AI nhỏ gọn như Phi-4-multimodal và Phi-4-mini là gì?",
        "options": {
          "A": "Đạt được hiệu suất cao nhất trên các benchmark so với các mô hình lớn hơn.",
          "B": "Cho phép tạo ra các ứng dụng AI hiệu quả trên các thiết bị biên, điện thoại thông minh và xe cộ.",
          "C": "Giảm chi phí đào tạo và triển khai mô hình AI.",
          "D": "Cạnh tranh trực tiếp với các mô hình độc quyền như GPT-4.5 về khả năng tổng quát."
        },
        "answer": "B"
      },
      {
        "question": "Điểm yếu chính của GPT-4.5 so với các mô hình khác như GPT-4o là gì?",
        "options": {
          "A": "Khả năng nhận diện mẫu kém hơn.",
          "B": "Yêu cầu tính toán cao, dẫn đến chi phí sử dụng đắt đỏ hơn.",
          "C": "Số lượng token đầu vào và đầu ra bị giới hạn.",
          "D": "Tốc độ xử lý chậm hơn."
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm vượt trội của mô hình Mercury Coder do Inception Labs phát triển là gì?",
        "options": {
          "A": "Khả năng tạo ra video từ văn bản và hình ảnh.",
          "B": "Tốc độ tạo văn bản nhanh hơn đáng kể so với các LLM hiện tại.",
          "C": "Hiệu suất vượt trội trên các benchmark về lý luận và giải quyết vấn đề.",
          "D": "Chi phí sử dụng API thấp hơn so với các mô hình khác."
        },
        "answer": "B"
      },
      {
        "question": "Alibaba Cloud cung cấp các mô hình AI mở nào trong lĩnh vực tạo video?",
        "options": {
          "A": "Các mô hình Phi-4 từ Microsoft.",
          "B": "Các mô hình Granite từ IBM.",
          "C": "Các mô hình Wan2.1.",
          "D": "Các mô hình Hunyuan Turbo S từ Tencent."
        },
        "answer": "C"
      },
      {
        "question": "Kiến trúc lai Mamba-Transformer được sử dụng trong Hunyuan Turbo S của Tencent nhằm mục đích gì?",
        "options": {
          "A": "Tăng cường khả năng tạo video từ văn bản.",
          "B": "Giảm độ trễ và tăng tốc độ phản hồi của mô hình.",
          "C": "Cải thiện khả năng lý luận chuỗi suy nghĩ.",
          "D": "Tăng cường khả năng hiểu ngôn ngữ tự nhiên."
        },
        "answer": "B"
      },
      {
        "question": "Các mô hình Granite mới của IBM tập trung vào khả năng đặc biệt nào?",
        "options": {
          "A": "Tạo ra các ứng dụng AI hiệu quả trên thiết bị di động.",
          "B": "Lý luận chuỗi suy nghĩ và hiểu tài liệu.",
          "C": "Tạo video từ văn bản và hình ảnh.",
          "D": "Tăng tốc độ tạo văn bản."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, kỹ thuật nào có thể giúp giảm độ trễ trong tương tác bằng giọng nói?",
        "options": {
          "A": "Sử dụng mô hình ngôn ngữ lớn hơn.",
          "B": "Tạo phản hồi sơ bộ nhanh chóng trước phản hồi đầy đủ.",
          "C": "Tăng cường khả năng nhận diện giọng nói.",
          "D": "Sử dụng phần cứng mạnh mẽ hơn."
        },
        "answer": "B"
      },
      {
        "question": "Brain2Qwerty là hệ thống gì?",
        "options": {
          "A": "Một mô hình ngôn ngữ lớn mới.",
          "B": "Một hệ thống phi phẫu thuật giải mã suy nghĩ thành văn bản.",
          "C": "Một phương pháp mới để huấn luyện mô hình AI.",
          "D": "Một công cụ để tạo video deepfake."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đang thúc đẩy các công ty công nghệ lớn tăng cường chi tiêu cho điện toán đám mây?",
        "options": {
          "A": "Sự ra mắt của các mô hình AI mới.",
          "B": "Nhu cầu ngày càng tăng đối với cơ sở hạ tầng AI.",
          "C": "Sự phát triển của công nghệ blockchain.",
          "D": "Sự gia tăng của các cuộc tấn công mạng."
        },
        "answer": "B"
      },
      {
        "question": "Coconut (Chain of Continuous Thought) là gì?",
        "options": {
          "A": "Một mô hình ngôn ngữ mới của Google.",
          "B": "Một phương pháp lý luận sử dụng vector thay vì văn bản để cải thiện dự đoán token tiếp theo.",
          "C": "Một công cụ để tạo video deepfake.",
          "D": "Một hệ thống giải mã suy nghĩ thành văn bản."
        },
        "answer": "B"
      }
    ]
  },
  "amazons-nova-bursts-onto-the-scene": {
    "title": "Amazon’s Nova bursts onto the scene",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nAmazon’s Nova promises lower costs and multimodal performance\n\nAmazon introduced its new Nova line of AI models, including Micro (text-only), Lite (multimodal), Pro (advanced multimodal), Premier (complex reasoning), Canvas (image generation), and Reel (video generation). The company claims Nova models are at least 75% less expensive than comparable models on Amazon Bedrock and offer the fastest performance in their respective intelligence classes. Nova models support 200 languages, custom fine-tuning, and integration with Amazon Bedrock Knowledge Bases for improved RAG accuracy. (Amazon)\n\nOpenAI launches more capable o1 model with visual reasoning\n\nOpenAI made o1, an upgraded version of its o1-preview model with enhanced reasoning and coding abilities, available for paid users of ChatGPT. The updated model features faster processing, more concise thinking, and can read image inputs, enabling visual as well as textual reasoning. OpenAI reports o1 reduces major errors on difficult real-world questions by 34 percent compared to o1-preview and released a system card with a set of safety evaluations. (OpenAI)\n\nTencent unveils open-source video generator that rivals top models\n\nTencent released HunyuanVideo, an open-source video generation AI that performs comparably to leading closed-source models. The 13-billion-parameter model uses unusual techniques like joint image-video training and a custom 3D architecture. According to Tencent HunyuanVideo outperforms models from Runway, Luma, and other top Chinese companies on human evaluations of visual quality and text alignment. The release of HunyuanVideo’s code and weights could narrow the gap between proprietary and open-source video AI capabilities. (GitHub)\n\nManta ray-inspired soft robot sets new underwater speed record\n\nA team at North Carolina State University created a soft robot that swims at 6.8 body lengths per second, nearly doubling their previous record. The robot features manta ray-inspired fins attached to a flexible body with an air chamber, allowing it to swim on the surface and underwater by mimicking manta ray movements. This advancement in soft robotics demonstrates improved speed, energy efficiency, and maneuverability, paving the way for potential applications in underwater exploration and payload transportation. (North Carolina State University)\n\nApple taps Amazon chips for search and potential model training\n\nApple confirmed it uses Amazon Web Services’ custom AI chips for consumer search queries, achieving 40 percent greater efficiency. The company is also evaluating Amazon’s Trainium2 chip for pre-training AI models, expecting up to 50 percent improvement in efficiency. This collaboration between tech giants shows that even Apple, known for its in-house approach, recognizes the value of specialized AI hardware in pushing the boundaries of what’s possible in AI development. (AppleInsider)\n\nPerplexity adds global media partners to enrich AI search results\n\nPerplexity welcomed over a dozen new partners to its Publishers’ Program, including theLos Angeles Times,The Independent, and other media brands from the UK, Japan, Spain, and Latin America. The new partners cover a wide range of topics, from specialized trade coverage to local reporting, and will share in revenue generated from advertising while gaining access to Perplexity’s APIs and developer support. This global expansion not only enriches Perplexity’s knowledge base but also could make AI-powered search more worldly and insightful. (Perplexity)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng debunked the idea that building with generative AI is costly, explaining that while training foundation models is expensive, prototyping and creating applications using existing tools is now very affordable, with costs as low as a few dollars.\n\n“Because of the massive investments in foundation models, it’s now incredibly inexpensive to experiment and build prototypes in the applications layer! Over Thanksgiving holiday, I spent about one and a half days prototyping different generative AI applications, and my bill for OpenAI API calls came out to about $3.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: Stripe introducedan ecommerce agent toolkitenabling AI to securely spend money;Mistral launched Pixtral Large, a strong competitor in vision-language models; the generative AI and GPU boomis raising concerns over increasing e-waste; and a research paper explored the E-DPO method which enhancesdefenses against jailbreak prompts, reinforcing AI security.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Dòng mô hình AI Nova của Amazon có đặc điểm nổi bật nào về chi phí so với các mô hình tương đương trên Amazon Bedrock?",
        "options": {
          "A": "Đắt hơn 75%",
          "B": "Rẻ hơn ít nhất 75%",
          "C": "Có chi phí tương đương",
          "D": "Chỉ rẻ hơn đối với một số ngôn ngữ nhất định"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình o1 được nâng cấp của OpenAI có khả năng mới nào so với phiên bản o1-preview?",
        "options": {
          "A": "Chỉ có khả năng xử lý văn bản nhanh hơn",
          "B": "Có khả năng đọc hình ảnh và suy luận trực quan",
          "C": "Giảm lỗi chính trong các câu hỏi đơn giản",
          "D": "Không có sự khác biệt về khả năng"
        },
        "answer": "B"
      },
      {
        "question": "HunyuanVideo của Tencent là loại mô hình AI nào?",
        "options": {
          "A": "Mô hình tạo văn bản",
          "B": "Mô hình tạo hình ảnh",
          "C": "Mô hình tạo video",
          "D": "Mô hình tạo âm thanh"
        },
        "answer": "C"
      },
      {
        "question": "Robot mềm lấy cảm hứng từ cá đuối của Đại học North Carolina State University đạt kỷ lục gì?",
        "options": {
          "A": "Thời gian hoạt động dưới nước lâu nhất",
          "B": "Tốc độ bơi nhanh nhất",
          "C": "Khả năng mang tải trọng lớn nhất",
          "D": "Độ sâu lặn sâu nhất"
        },
        "answer": "B"
      },
      {
        "question": "Apple sử dụng chip AI tùy chỉnh của Amazon Web Services cho mục đích gì?",
        "options": {
          "A": "Đào tạo tất cả các mô hình AI của Apple",
          "B": "Xử lý các truy vấn tìm kiếm của người dùng",
          "C": "Phát triển phần cứng mới cho iPhone",
          "D": "Cải thiện hiệu suất của Siri"
        },
        "answer": "B"
      },
      {
        "question": "Chương trình Publishers' Program của Perplexity mang lại lợi ích gì cho các đối tác truyền thông?",
        "options": {
          "A": "Quyền truy cập độc quyền vào dữ liệu người dùng của Perplexity",
          "B": "Chia sẻ doanh thu từ quảng cáo và quyền truy cập vào API của Perplexity",
          "C": "Cơ hội đầu tư vào Perplexity",
          "D": "Quyền kiểm soát nội dung trên nền tảng Perplexity"
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, chi phí chính để xây dựng với AI tạo sinh hiện nay là gì?",
        "options": {
          "A": "Chi phí đào tạo các mô hình nền tảng",
          "B": "Chi phí thử nghiệm và tạo mẫu ứng dụng",
          "C": "Chi phí thuê chuyên gia AI",
          "D": "Chi phí mua phần cứng chuyên dụng"
        },
        "answer": "A"
      },
      {
        "question": "Công cụ Stripe được đề cập trong bài viết có chức năng chính là gì?",
        "options": {
          "A": "Tạo nội dung quảng cáo tự động",
          "B": "Cho phép AI chi tiêu tiền một cách an toàn trong thương mại điện tử",
          "C": "Phân tích dữ liệu khách hàng",
          "D": "Tự động hóa quy trình chăm sóc khách hàng"
        },
        "answer": "B"
      },
      {
        "question": "Pixtral Large của Mistral là một mô hình thuộc loại nào?",
        "options": {
          "A": "Mô hình ngôn ngữ lớn",
          "B": "Mô hình chuyển văn bản thành hình ảnh",
          "C": "Mô hình thị giác-ngôn ngữ",
          "D": "Mô hình dự đoán chuỗi thời gian"
        },
        "answer": "C"
      },
      {
        "question": "Vấn đề nào đang gia tăng do sự bùng nổ của AI tạo sinh và GPU?",
        "options": {
          "A": "Tình trạng thiếu hụt nhân tài AI",
          "B": "Ô nhiễm tiếng ồn",
          "C": "Lượng rác thải điện tử (e-waste) tăng lên",
          "D": "Sự gia tăng các cuộc tấn công mạng"
        },
        "answer": "C"
      }
    ]
  },
  "anthropic-releases-claude-3-7-sonnet-as-a-hybrid-reasoning-model": {
    "title": "Anthropic releases Claude 3.7 Sonnet as a hybrid reasoning model",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nClaude 3.7 Sonnet offers multiple thinking modes\n\nAnthropic’s new Claude 3.7 Sonnet model can operate in both standard and extended thinking modes. In standard mode, the model provides quick responses similar to previous versions, while the extended thinking mode enables visible step-by-step reasoning to improve performance on complex tasks. API users can further control the model’s “thinking budget,” allowing them to balance response speed, cost, and quality by specifying how many tokens Claude can use for reasoning. The company also introduced Claude Code, a command-line tool that enables developers to delegate substantial engineering tasks to Claude directly from their terminal. Claude 3.7 Sonnet shows significant improvements in coding and front-end web development, achieving state-of-the-art performance on software engineering benchmarks like SWE-bench Verified and TAU-bench. (Anthropic)\n\nDeepSeek AI to open source five repositories over five days\n\nDeepSeek AI announced plans to open source five repositories over five consecutive days starting February 24, 2025. The first “OpenInfra” release, FlashMLA, is an efficient MLA decoding kernel for Hopper GPUs, optimized for variable-length sequences and tested in production environments and published under an MIT license. DeepSeek says this initiative aims to share practical, working code with the AI development community, fostering collaboration and accelerating progress in the field. (GitHub)\n\nHelix model offers more adaptability to humanoid robots\n\nFigure AI introduced Helix, a generalist vision-language-action model trained to control humanoid robots’ entire upper bodies using natural language commands. Helix can be used for robots to manipulate novel objects, collaborate between multiple units, and run on low-power GPUs, making it more useful for commercial deployment. The model shows promise in assisting robots to generalize new skills through language, helping robots learn and adapt to unstructured environments like homes. (Figure AI)\n\nGoogle’s new optimized PaliGemma 2 mix vision-language models\n\nGoogle released PaliGemma 2 mix, a set of open source fine-tuned vision-language models based on the previously released PaliGemma 2 family. The new variants come in three sizes (3, 10, and 28 billion parameters) and three image resolutions (224x224, 448x448, 896x896), offering capabilities in tasks like visual question answering, document understanding, text recognition, and object localization. This new release offers AI developers powerful, versatile models that can be further customized for specific downstream vision-language applications. (Hugging Face)\n\nNew benchmark challenges AI models with multidisciplinary questions\n\nSuperGPQA is a new benchmark for evaluating large language models across 285 graduate-level disciplines, containing over 26,000 challenging multiple-choice questions. Created through a rigorous process involving hundreds of experts and quality checks, it spans 13 disciplines and 72 fields, categorizing questions by difficulty level. Even top-performing models like DeepSeek-R1 only achieved around 60 percent accuracy, revealing strengths and weaknesses across different model types and domains. SuperGPQA aims to provide a more comprehensive and fine-grained evaluation of language models’ capabilities than existing benchmarks, probing the boundaries of their knowledge and reasoning abilities. (GitHubandarXiv)\n\nMeta unveils MLGym to test AI agents’ research capabilities\n\nMeta researchers introduced MLGym, a new open source benchmark for evaluating and developing large language model agents on research tasks. MLGym-Bench consists of 13 diverse open-ended AI research tasks across domains like computer vision, NLP, reinforcement learning, and game theory, testing agents’ ability to generate ideas, implement methods, run experiments, and improve on baselines. Experiments evaluating several frontier LLMs on MLGym-Bench found that current models can improve on given baselines but do not yet generate novel hypotheses or substantial improvements. Of models tested, OpenAI’s O1-preview model performed the best overall on the MLGym-Bench tasks, followed closely by Gemini 1.5 Pro and Claude 3.5 Sonnet. (arXiv)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng shared a powerful story about how AI saved a police officer’s life, highlighting the impact of Skyfire AI’s drone technology in emergency response.\n\n“Skyfire AI’s drones supported search-and-rescue operations under the direction of the North Carolina Office of Emergency Management and was credited with saving 13 lives.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:xAI unveiled Grok 3, a new model family trained at scales beyond its predecessors;Replit updated its  mobile appto enable full app development using its AI agent;Elon Musk’s $97.4 billion bid for OpenAI was rejected, intensifying the power struggle between companies; and global leaders at the latest AI summit showed theirdeep divisions over regulation and governance.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Claude 3.7 Sonnet cung cấp những chế độ tư duy nào?",
        "options": {
          "A": "Chế độ tư duy nhanh và chế độ tư duy sâu.",
          "B": "Chế độ tư duy tiêu chuẩn và chế độ tư duy mở rộng.",
          "C": "Chế độ tư duy logic và chế độ tư duy sáng tạo.",
          "D": "Chế độ tư duy đơn giản và chế độ tư duy phức tạp."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ dòng lệnh Claude Code cho phép các nhà phát triển làm gì?",
        "options": {
          "A": "Kiểm soát số lượng token mà Claude sử dụng để suy luận.",
          "B": "Gỡ lỗi mã nguồn một cách hiệu quả hơn.",
          "C": "Ủy thác các tác vụ kỹ thuật đáng kể cho Claude trực tiếp từ terminal.",
          "D": "Tối ưu hóa hiệu suất của Claude trên các tác vụ phức tạp."
        },
        "answer": "C"
      },
      {
        "question": "DeepSeek AI dự kiến sẽ làm gì bắt đầu từ ngày 24 tháng 2 năm 2025?",
        "options": {
          "A": "Ra mắt mô hình ngôn ngữ lớn mới nhất của họ.",
          "B": "Mở mã nguồn năm kho lưu trữ trong năm ngày liên tiếp.",
          "C": "Tổ chức một hội nghị về trí tuệ nhân tạo.",
          "D": "Công bố quan hệ đối tác chiến lược với một công ty công nghệ lớn."
        },
        "answer": "B"
      },
      {
        "question": "FlashMLA, bản phát hành 'OpenInfra' đầu tiên của DeepSeek AI, được tối ưu hóa cho loại GPU nào?",
        "options": {
          "A": "Tesla GPUs",
          "B": "Hopper GPUs",
          "C": "AMD GPUs",
          "D": "Intel GPUs"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Helix của Figure AI được huấn luyện để điều khiển bộ phận nào của robot hình người?",
        "options": {
          "A": "Toàn bộ cơ thể.",
          "B": "Chân và bàn chân.",
          "C": "Toàn bộ phần thân trên.",
          "D": "Đầu và cổ."
        },
        "answer": "C"
      },
      {
        "question": "PaliGemma 2 mix của Google có bao nhiêu kích thước khác nhau?",
        "options": {
          "A": "2",
          "B": "3",
          "C": "4",
          "D": "5"
        },
        "answer": "B"
      },
      {
        "question": "SuperGPQA là gì?",
        "options": {
          "A": "Một mô hình ngôn ngữ lớn mới do Google phát triển.",
          "B": "Một chuẩn đánh giá mới cho các mô hình ngôn ngữ lớn.",
          "C": "Một công cụ để tạo ra các câu hỏi trắc nghiệm.",
          "D": "Một thư viện mã nguồn mở cho các ứng dụng AI."
        },
        "answer": "B"
      },
      {
        "question": "SuperGPQA bao gồm bao nhiêu lĩnh vực?",
        "options": {
          "A": "10",
          "B": "13",
          "C": "20",
          "D": "25"
        },
        "answer": "B"
      },
      {
        "question": "MLGym-Bench đánh giá khả năng của các LLM agents trong lĩnh vực nào?",
        "options": {
          "A": "Phát triển ứng dụng di động.",
          "B": "Nghiên cứu AI.",
          "C": "Phân tích dữ liệu tài chính.",
          "D": "Dịch thuật ngôn ngữ."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào đạt hiệu suất tốt nhất trên các tác vụ MLGym-Bench?",
        "options": {
          "A": "Gemini 1.5 Pro",
          "B": "Claude 3.5 Sonnet",
          "C": "DeepSeek-R1",
          "D": "OpenAI’s O1-preview"
        },
        "answer": "D"
      }
    ]
  },
  "anthropic-updates-claude-adds-computer-agent-api": {
    "title": "Anthropic updates Claude, adds computer agent API",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nClaude models gain improved coding skills and computer interaction abilities\n\nAnthropic released an upgraded Claude 3.5 Sonnet and a new Claude 3.5 Haiku model, both offering significant performance improvements, especially in coding. The company also introduced a new “computer use” capability in public beta, allowing Claude to interact with computer interfaces like a human user. This API enables developers to create AI applications to automate repetitive processes, build and test software, conduct open-ended research tasks, and navigate complex user interfaces across multiple programs. (Anthropic)\n\nStability AI unveils new family of image creation models\n\nStable Diffusion’s new 3.5 versions, including Large and Large Turbo, run on regular computers and are free for most users under Stability AI’s license. These models excel at creating diverse outputs, adapting to various visual styles, and adhering closely to text prompts without extensive user input. A Medium version, designed to balance quality and ease of use on consumer hardware, will launch on October 29th. (Stability AI)\n\nSpirit LM offers speech-to-speech and text-to-speech processing\n\nMeta’s FAIR lab introduced Spirit LM, an open weights language model that integrates text and speech processing using a word-level interleaving method. The model comes in two versions: Spirit LM Base, which uses phonetic tokens, and Spirit LM Expressive, which incorporates pitch and style tokens to capture and generate expressive speech. Spirit LM aims to improve natural-sounding speech generation and cross-modal learning, potentially advancing research in speech recognition, text-to-speech, and speech classification. (MetaandarXiv)\n\nIBM open-sources Granite 3.0 language models for enterprise use\n\nIBM’s release includes the Granite 3.0 8B Instruct model, as well as base models, guardrail models, mixture-of-experts models for low latency, and a speculative decoder for faster inference. Granite 3.0 8B Instruct performs well relative to other models its size. The company released all Granite models under the Apache 2.0 license and provided detailed disclosures of training data and methods, emphasizing Granite’s transparency relative to less permissive models. Planned updates include expansion of all context windows to 128,000+ tokens, improvements in multilingual support and new image-input text-output capabilities. (IBM)\n\nGoogle enhances AI music software with fast generation and pro audio tools\n\nGoogle released updates to its AI-powered music creation tools, including a reimagined MusicFX DJ and an expanded Music AI Sandbox. MusicFX DJ now offers improved controls, real-time streaming, and what Google calls production-quality audio output, allowing users to generate and manipulate music live. Google collaborated with industry professionals to develop these tools, aiming to balance the needs of music professionals with accessibility for novice creators. (Google DeepMind)\n\nTiny titans clash in AI arena for budget-conscious developers\n\nA new project pits smaller language models against each other in a battle of wits, with a maximum size of 9 billion parameters. The arena, built on Ollama and hosted on Hugging Face, allows users to compare model outputs, vote on performances, and track results on a leaderboard. This platform enables AI enthusiasts to experiment with compact models without requiring expensive hardware. As of this writing, Rombos Qwen (7B, 4-bit) tops the leaderboard with a score of 0.7941 out of 1. (Hugging Face)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng emphasized the importance of speedy execution with Generative AI and the need to quickly gather user feedback to iterate on products responsibly.\n\n“Generative AI makes it possible to quickly prototype AI capabilities. AI capabilities that used to take months can sometimes be built in days or hours by simply prompting a large language model.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: Major AI companies plan tomeet growing demand with nuclear energy; the once-strong partnership betweenMicrosoft and OpenAIfaces challenges as both companies seek greater independence;Mistral AI launches two modelsthat set new standards for small language models, making them suitable for edge devices; andresearchers cut training costs for video generators, resulting in a competitive open-source text-to-video model with training code to be released.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Claude 3.5 Sonnet và Claude 3.5 Haiku của Anthropic có cải tiến đáng kể nhất trong lĩnh vực nào?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên",
          "B": "Lập trình và tương tác với máy tính",
          "C": "Tạo hình ảnh từ văn bản",
          "D": "Phân tích dữ liệu tài chính"
        },
        "answer": "B"
      },
      {
        "question": "Tính năng 'computer use' mới của Claude cho phép nhà phát triển làm gì?",
        "options": {
          "A": "Tạo ra các mô hình AI có khả năng tự học",
          "B": "Xây dựng ứng dụng AI để tự động hóa các quy trình lặp đi lặp lại",
          "C": "Phát triển phần cứng máy tính mới",
          "D": "Nghiên cứu về trí tuệ nhân tạo tổng quát"
        },
        "answer": "B"
      },
      {
        "question": "Các phiên bản Stable Diffusion 3.5 mới của Stability AI có đặc điểm nổi bật nào?",
        "options": {
          "A": "Yêu cầu phần cứng mạnh mẽ để hoạt động",
          "B": "Tạo ra các kết quả đa dạng và bám sát các yêu cầu văn bản",
          "C": "Chỉ dành cho người dùng trả phí",
          "D": "Chuyên về tạo video từ văn bản"
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của Spirit LM do Meta phát triển là gì?",
        "options": {
          "A": "Cải thiện khả năng dịch thuật đa ngôn ngữ",
          "B": "Cải thiện khả năng tạo ra giọng nói tự nhiên và học đa phương thức",
          "C": "Phát triển các mô hình AI cho xe tự lái",
          "D": "Nghiên cứu về mạng nơ-ron sâu"
        },
        "answer": "B"
      },
      {
        "question": "IBM phát hành các mô hình Granite 3.0 dưới giấy phép nào?",
        "options": {
          "A": "Giấy phép độc quyền của IBM",
          "B": "Giấy phép Apache 2.0",
          "C": "Giấy phép Creative Commons",
          "D": "Giấy phép GPL"
        },
        "answer": "B"
      },
      {
        "question": "IBM nhấn mạnh điều gì về các mô hình Granite so với các mô hình khác?",
        "options": {
          "A": "Hiệu suất vượt trội hơn hẳn",
          "B": "Tính minh bạch về dữ liệu và phương pháp huấn luyện",
          "C": "Khả năng xử lý ngôn ngữ tự nhiên tốt nhất",
          "D": "Giá thành rẻ hơn"
        },
        "answer": "B"
      },
      {
        "question": "Google đã cập nhật công cụ tạo nhạc AI nào?",
        "options": {
          "A": "AlphaFold",
          "B": "MusicFX DJ và Music AI Sandbox",
          "C": "Bard",
          "D": "TensorFlow"
        },
        "answer": "B"
      },
      {
        "question": "Dự án 'Tiny titans clash in AI arena' tập trung vào loại mô hình ngôn ngữ nào?",
        "options": {
          "A": "Các mô hình có kích thước lớn nhất",
          "B": "Các mô hình có kích thước nhỏ (tối đa 9 tỷ tham số)",
          "C": "Các mô hình được huấn luyện trên dữ liệu độc quyền",
          "D": "Các mô hình được phát triển bởi Google"
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, điều gì quan trọng trong việc phát triển AI tạo sinh?",
        "options": {
          "A": "Đầu tư vào phần cứng mạnh mẽ",
          "B": "Thực hiện nhanh chóng và thu thập phản hồi từ người dùng để lặp lại sản phẩm",
          "C": "Bảo mật dữ liệu huấn luyện",
          "D": "Tuân thủ các quy định pháp lý nghiêm ngặt"
        },
        "answer": "B"
      },
      {
        "question": "Ngoài các tin tức chính, bài viết còn đề cập đến việc các công ty AI lớn có kế hoạch gì để đáp ứng nhu cầu năng lượng ngày càng tăng?",
        "options": {
          "A": "Đầu tư vào năng lượng mặt trời",
          "B": "Sử dụng năng lượng hạt nhân",
          "C": "Phát triển pin hiệu suất cao",
          "D": "Giảm tiêu thụ năng lượng"
        },
        "answer": "B"
      }
    ]
  },
  "apple-and-microsoft-wont-observe-openais-board": {
    "title": "Apple and Microsoft Won’t Observe OpenAI’s Board",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you can find:\n\nBig tech backs off from OpenAI’s boardMicrosoft and Apple have decided not to join OpenAI’s board of directors. The tech giants had planned to take advisory roles to oversee their investments and partnerships with the AI company. This move comes as government regulators examine whether partnerships between big tech firms and AI startups are reducing competition in the rapidly growing AI industry. (The Washington Post)\n\nGroq introduces fast LLM chatbot on its websiteGroq quietly launched a new version of its website allowing users to interact with large language models at high speeds. The system processes queries at around 1,256 tokens per second and supports various models, including multiple versions of Meta’s Llama3 and Google’s Gemma. Groq’s language processing unit (LPU) operates linearly, making it more efficient than GPUs for AI inference tasks; Groq’s team believes it could transform how developers and enterprises approach AI deployment. (VentureBeat)\n\nAmazon introduces AI tool for rapid enterprise app developmentAmazon Web Services previewed AWS App Studio, a generative AI service that enables users to create enterprise-grade applications using natural language prompts. The service allows technical professionals without software development skills to build custom applications quickly, connecting to various data sources and offering a point-and-click interface for modifications. AWS App Studio aims to address the challenges of internal process management and the scarcity of development resources by providing a secure, scalable solution that meets enterprise security requirements. (Amazon)\n\nAlibaba integrates AI into overseas e-commerce expansionAlibaba is using artificial intelligence to boost its international efforts as the company faces slowing growth in China. Alibaba’s AI models help small sellers in China and elsewhere overcome language barriers, create marketing materials, and handle customer service tasks using the company’s overseas platforms. While Alibaba’s international e-commerce division is growing rapidly, it still faces stiff competition from rivals like Temu and questions about AI’s short-term impact on profitability. (The Wall Street Journal)\n\nThe Washington Post launches AI-powered climate Q&A toolClimate Answers uses large language models (currently provided by OpenAI) to search and synthesize relevant information from published articles since 2016, aiming to provide concise replies to user questions about climate issues. This chatbot is designed to complement rather than replace traditional journalism, with safeguards in place to minimize errors and hallucinations. Washington Post CTO Vineet Khosla says the chatbot is still an experiment, but in time, could scale to extend to every subject the newspaper covers. (The Washington Post)\n\nChatGPT nearly doubles year-over-year traffic with 2.9 billion visits in JuneThe chatbot’s growth extends to its mobile application, with daily active users in the U.S. rising by 13% to 3.2 million. Google’s Gemini saw a 16.6% drop in visitors in June compared to May, while Anthropic’s Claude and Character.AI lag far behind with about 400 million and 309 million monthly visits, respectively. OpenAI’s changes in the last year, including the switch to a dedicated website for ChatGPT and the introduction of the free GPT-4o model, likely contributed to this surge in traffic. (The Decoder)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng wrote about how current attempts to regulate AI models in California could put developers at risk:\n\n“These provisions don’t ensure that AI is safe. They create regulatory uncertainty, and more opportunities for vested interests wishing to stifle open-source to lobby for shifts in the requirements that raise the cost of compliance. This would lock out many teams that don’t have a revenue stream — specifically, many open-source contributors — that would let them pay for lobbyists, auditors, and lawyers to help ensure they comply with these ambiguous and unreasonable requirements.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth included:Claude’s introduction of Artifacts, Amazon hires agentictalent from Adept, cloud computing companiesrethink their climate goals, and GaLore, a newoptimizer that saves memoryduring pretraining.",
    "qa": [
      {
        "question": "Theo bài viết, lý do chính Microsoft và Apple quyết định không tham gia vào ban giám đốc của OpenAI là gì?",
        "options": {
          "A": "Do lo ngại về chi phí đầu tư quá lớn.",
          "B": "Do các nhà quản lý chính phủ đang xem xét các mối quan hệ đối tác giữa các công ty công nghệ lớn và các công ty khởi nghiệp AI.",
          "C": "Do OpenAI không đáp ứng được các yêu cầu về bảo mật dữ liệu.",
          "D": "Do sự khác biệt về quan điểm chiến lược phát triển AI giữa các bên."
        },
        "answer": "B"
      },
      {
        "question": "Groq giới thiệu điều gì trên trang web của họ cho phép người dùng tương tác với các mô hình ngôn ngữ lớn?",
        "options": {
          "A": "Một công cụ chỉnh sửa video AI.",
          "B": "Một chatbot LLM tốc độ cao.",
          "C": "Một nền tảng phát triển ứng dụng AI.",
          "D": "Một dịch vụ lưu trữ dữ liệu AI."
        },
        "answer": "B"
      },
      {
        "question": "AWS App Studio của Amazon hướng đến đối tượng người dùng nào?",
        "options": {
          "A": "Các nhà khoa học dữ liệu chuyên nghiệp.",
          "B": "Các chuyên gia kỹ thuật không có kỹ năng phát triển phần mềm.",
          "C": "Các nhà quản lý dự án công nghệ thông tin.",
          "D": "Các chuyên gia marketing và bán hàng."
        },
        "answer": "B"
      },
      {
        "question": "Alibaba sử dụng AI để hỗ trợ điều gì trong quá trình mở rộng thương mại điện tử ra nước ngoài?",
        "options": {
          "A": "Tự động hóa quy trình sản xuất hàng hóa.",
          "B": "Vượt qua rào cản ngôn ngữ và tạo tài liệu marketing cho người bán.",
          "C": "Tối ưu hóa chuỗi cung ứng và logistics.",
          "D": "Phát triển các phương thức thanh toán quốc tế mới."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ Climate Answers của The Washington Post sử dụng công nghệ nào để trả lời các câu hỏi về vấn đề khí hậu?",
        "options": {
          "A": "Hệ thống phân tích dữ liệu thời tiết.",
          "B": "Các mô hình ngôn ngữ lớn.",
          "C": "Mạng lưới cảm biến môi trường.",
          "D": "Thuật toán dự báo biến đổi khí hậu."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, yếu tố nào có thể đã góp phần vào sự tăng trưởng lưu lượng truy cập của ChatGPT?",
        "options": {
          "A": "Việc tích hợp ChatGPT vào các thiết bị IoT.",
          "B": "Việc chuyển sang một trang web chuyên dụng và giới thiệu mô hình GPT-4o miễn phí.",
          "C": "Việc hợp tác với các mạng xã hội lớn.",
          "D": "Việc phát hành phiên bản ChatGPT dành cho doanh nghiệp."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, điều gì có thể xảy ra nếu các quy định về AI ở California không hợp lý?",
        "options": {
          "A": "Sẽ thúc đẩy sự đổi mới và cạnh tranh trong lĩnh vực AI.",
          "B": "Sẽ tạo ra sự không chắc chắn về quy định và hạn chế sự đóng góp của mã nguồn mở.",
          "C": "Sẽ đảm bảo an toàn cho người dùng và ngăn chặn các rủi ro tiềm ẩn của AI.",
          "D": "Sẽ thu hút nhiều nhà đầu tư và doanh nghiệp đến California."
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ LPU của Groq hoạt động như thế nào so với GPU trong các tác vụ suy luận AI?",
        "options": {
          "A": "LPU phức tạp hơn và đòi hỏi nhiều năng lượng hơn GPU.",
          "B": "LPU hoạt động tuyến tính, giúp nó hiệu quả hơn GPU.",
          "C": "LPU chỉ phù hợp với các mô hình AI nhỏ, trong khi GPU có thể xử lý các mô hình lớn hơn.",
          "D": "LPU và GPU có hiệu suất tương đương nhau trong các tác vụ suy luận AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, thách thức lớn nhất mà bộ phận thương mại điện tử quốc tế của Alibaba đang phải đối mặt là gì?",
        "options": {
          "A": "Sự thiếu hụt nguồn nhân lực có trình độ cao.",
          "B": "Sự cạnh tranh gay gắt từ các đối thủ như Temu.",
          "C": "Các vấn đề về logistics và vận chuyển quốc tế.",
          "D": "Sự thay đổi trong chính sách thương mại quốc tế."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến một trình tối ưu hóa mới giúp tiết kiệm bộ nhớ trong quá trình huấn luyện trước mô hình AI. Trình tối ưu hóa đó có tên là gì?",
        "options": {
          "A": "Artifacts",
          "B": "Adept",
          "C": "GaLore",
          "D": "Gemini"
        },
        "answer": "C"
      }
    ]
  },
  "apples-new-models-punch-above-their-weight-liquid-explores-a-new-multimodal-modal-architecture": {
    "title": "Apple’s new models punch above their weight",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nApple’s multimodal models focus on data curation\n\nApple introduced MM1.5, a new series of multimodal large language models designed to improve text-rich image understanding, visual referring and grounding, and multi-image reasoning. The models, ranging from 1 billion to 30 billion parameters, include dense and mixture-of-experts variants and demonstrate strong performance even at smaller scales. Apple’s approach focuses on careful data curation and training strategies, offering insights that could guide future research in multimodal large language model development. (arXiv)\n\nLiquid announces benchmarks for a new family of math-driven language models\n\nA new series of Liquid Foundation Models (LFMs) claims to achieve state-of-the-art performance in their size classes (1.3B, 3.1B, and 40.3B) on multiple benchmarks, with smaller memory footprints and more efficient inference. The models can output multiple media types, including text, audio, images, and video, using a process that converts raw data into structured feature representations. The models’ unusual architecture incorporates specialized computational units for token and channel mixing, adaptive linear operators, and weight and feature sharing mechanisms, potentially leading to more versatile and resource-efficient AI systems. (Liquid)\n\nStudy suggests coding assistants may not boost productivity\n\nA recent study by Uplevel found no significant productivity gains for developers using GitHub Copilot, contrary to widespread claims about AI coding assistants. The research, which compared the output of 800 developers before and after adopting Copilot, measured pull request cycle time and throughput, finding no substantial improvements. Additionally, the study revealed that Copilot usage introduced 41 percent more bugs, challenging the notion that AI coding tools consistently enhance developer efficiency and code quality. (CIO.com)\n\nOpenAI speeds up Whisper model for quicker speech recognition\n\nOpenAI released Whisper large-v3-turbo, a streamlined version of its leading speech recognition model. The new variant reduces the number of decoding layers from 32 to 4, significantly increasing speed while only slightly decreasing quality. This development offers AI developers a more efficient option for implementing advanced speech recognition capabilities in their applications. (Hugging Face)\n\nEvaluating AI leaders’ redteaming and other safety measures\n\nA new risk management assessment from Safer AI (part of the US AI Safety Consortium) reveals shortcomings in AI companies’ risk management practices. The report ranks companies on a 0-5 scale, with Meta, Mistral AI, and xAI scoring lowest at 0.7, 0.1, and 0 respectively, while Anthropic, OpenAI, and Google DeepMind lead with scores of 2.2, 1.6, and 1.5. These findings are based on the AI companies’ own disclosures of their red-teaming and risk management practices, suggesting the lowest scoring organizations have been either slow to implement or not transparent about standard safety measures. (Safer AI)\n\nNew open-source CLI tool leverages o1-preview\n\nO1-engineer is a command-line tool that uses OpenAI’s API to assist developers with code generation, file management, project planning, and code review. The tool features an interactive console, conversation history management, and enhanced file and folder operations to help streamline development workflows. O1-engineer can also automate routine tasks and provide intelligent support throughout the development process. (GitHub)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng celebrated the veto of California’s anti-innovation bill SB 1047 by Governor Newsom, highlighting the efforts of AI experts and advocates who worked to defeat the legislation and stressing the importance of evidence-based regulation in the field of AI.\n\n“SB 1047 makes a fundamental mistake of trying to regulate technology rather than applications. It was also a very confusing law that would have been hard to comply with. That would have driven up costs without improving safety.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Meta expands its Llama Herdwith updates to its Llama models, adding vision-language capabilities, edge sizes, and agentic APIs;Adobe integrates AI video generation toolsinto Premiere Pro, bringing generative video directly into the editing suite; aglobal coalitionendorses international guidelines for the responsible use of AI in military applications; andresearchers develop a methodenabling large language models to accurately process and answer questions from complex spreadsheets.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Apple đã giới thiệu mô hình ngôn ngữ lớn đa phương thức nào tập trung vào việc xử lý và hiểu hình ảnh giàu văn bản?",
        "options": {
          "A": "Liquid Foundation Models (LFMs)",
          "B": "MM1.5",
          "C": "Whisper large-v3-turbo",
          "D": "O1-engineer"
        },
        "answer": "B"
      },
      {
        "question": "Liquid Foundation Models (LFMs) tuyên bố đạt được hiệu suất vượt trội trong các lớp kích thước của chúng dựa trên tiêu chí nào?",
        "options": {
          "A": "Khả năng tạo ra mã nguồn chất lượng cao.",
          "B": "Hiệu suất trên nhiều benchmarks với bộ nhớ nhỏ hơn và suy luận hiệu quả hơn.",
          "C": "Khả năng tích hợp dễ dàng vào các ứng dụng di động.",
          "D": "Số lượng tham số lớn hơn so với các mô hình khác."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu của Uplevel cho thấy điều gì về tác động của GitHub Copilot đến năng suất của các nhà phát triển?",
        "options": {
          "A": "GitHub Copilot giúp tăng đáng kể năng suất và giảm số lượng lỗi.",
          "B": "GitHub Copilot không mang lại sự cải thiện đáng kể nào về năng suất và làm tăng số lượng lỗi.",
          "C": "GitHub Copilot chỉ hiệu quả đối với các nhà phát triển có kinh nghiệm.",
          "D": "GitHub Copilot giúp giảm thời gian hoàn thành dự án một cách đáng kể."
        },
        "answer": "B"
      },
      {
        "question": "OpenAI đã phát hành phiên bản nào của mô hình Whisper để tăng tốc độ nhận dạng giọng nói?",
        "options": {
          "A": "Whisper small",
          "B": "Whisper medium",
          "C": "Whisper large-v3-turbo",
          "D": "Whisper tiny"
        },
        "answer": "C"
      },
      {
        "question": "Theo đánh giá của Safer AI, công ty nào có điểm số thấp nhất về các biện pháp an toàn và redteaming?",
        "options": {
          "A": "Anthropic",
          "B": "OpenAI",
          "C": "Meta",
          "D": "Google DeepMind"
        },
        "answer": "C"
      },
      {
        "question": "O1-engineer là gì và nó hỗ trợ các nhà phát triển như thế nào?",
        "options": {
          "A": "Một thư viện mã nguồn mở để xây dựng giao diện người dùng.",
          "B": "Một công cụ dòng lệnh sử dụng API của OpenAI để hỗ trợ các nhà phát triển với nhiều tác vụ khác nhau.",
          "C": "Một nền tảng để chia sẻ và cộng tác trên các dự án AI.",
          "D": "Một trình biên dịch mã nguồn để tối ưu hóa hiệu suất."
        },
        "answer": "B"
      },
      {
        "question": "Andrew Ng đã phản ứng như thế nào về việc Thống đốc Newsom phủ quyết dự luật SB 1047 của California?",
        "options": {
          "A": "Ông ủng hộ dự luật vì nó sẽ tăng cường an toàn AI.",
          "B": "Ông chỉ trích việc phủ quyết vì nó sẽ cản trở sự phát triển của AI.",
          "C": "Ông ăn mừng việc phủ quyết và nhấn mạnh tầm quan trọng của quy định dựa trên bằng chứng.",
          "D": "Ông giữ im lặng về vấn đề này."
        },
        "answer": "C"
      },
      {
        "question": "Meta đã mở rộng Llama Herd của mình bằng cách bổ sung những khả năng nào?",
        "options": {
          "A": "Chỉ khả năng xử lý ngôn ngữ tự nhiên.",
          "B": "Khả năng tạo ra hình ảnh 3D.",
          "C": "Khả năng thị giác ngôn ngữ, kích thước cạnh và API agentic.",
          "D": "Chỉ khả năng dịch ngôn ngữ."
        },
        "answer": "C"
      },
      {
        "question": "Adobe đã tích hợp công cụ AI nào vào Premiere Pro?",
        "options": {
          "A": "Công cụ tạo văn bản AI.",
          "B": "Công cụ tạo hình ảnh AI.",
          "C": "Công cụ tạo video AI.",
          "D": "Công cụ tạo âm thanh AI."
        },
        "answer": "C"
      },
      {
        "question": "Nội dung nào sau đây được đề cập đến như một câu chuyện tin tức AI hàng đầu khác được đề cập trong bài viết?",
        "options": {
          "A": "Sự phát triển của một hệ thống AI có thể dự đoán thời tiết chính xác hơn.",
          "B": "Một liên minh toàn cầu chứng thực các hướng dẫn quốc tế về việc sử dụng AI có trách nhiệm trong các ứng dụng quân sự.",
          "C": "Việc ra mắt một loại chip mới được thiết kế đặc biệt cho các ứng dụng AI.",
          "D": "Sự phát triển của một thuật toán AI có thể chữa khỏi bệnh ung thư."
        },
        "answer": "B"
      }
    ]
  },
  "brazil-puts-the-brakes-on-meta": {
    "title": "Brazil puts the brakes on Meta",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you can find:\n\nBrazil bars Meta from using local data to train AI modelsBrazil’s national data protection authority prohibited Meta from using data originating in Brazil to train its artificial intelligence systems. The agency cited concerns about potential risks to fundamental rights, inadequate disclosure of information, and inadequate safeguards for processing data belonging to children. This ruling affects Meta’s ability to implement its updated privacy policy in Brazil, where Facebook alone has approximately 102 million active users. (Associated Press)\n\nSkeleton Key jailbreak compromises safety features in multiple AI modelsMicrosoft uncovered a new AI jailbreak technique called Skeleton Key that successfully bypasses safety guardrails in at least seven major AI models, including those from Meta, Google, OpenAI, Anthropic, and Cohere. The attack tricks AI systems into providing normally forbidden content by instructing them to preface responses with warning disclaimers, potentially granting users unrestricted access to the models’ full capabilities. Microsoft implemented several mitigation strategies to counter this threat, including input and output filtering, system message engineering, and abuse monitoring, while also alerting other AI providers to the vulnerability. (Microsoft)\n\nResearchers develop robots trained to listen as well as seeStanford University's Robotics and Embodied AI Lab created a system that uses audio data to train robots for household tasks, significantly improving their performance in situations where visibility is limited. The new robot, which combines a specialized gripper with a microphone and new training algorithms, showed promising results in tasks such as flipping bagels, erasing whiteboards, and detecting dice in cups. This research opens up new possibilities for enhancing robots’ sensory capabilities, potentially accelerating their adaptation to diverse environments and expanding their usefulness in homes and kitchens. (MIT Technology Review)\n\nGen-3 Alpha video generation model now availableRunwayML made its latest AI video generation model, Gen-3 Alpha, available to all paid users on its platform. The model creates videos from text, image, or video prompts, with capabilities including imaginative transitions, precise key-framing, and expressive human characters. Gen-3 Alpha offers improved speed, fidelity, and consistency over RunwayML’s previous models, but requires a paid subscription starting at $12 per month, yielding only a limited amount of credits. (RunwayML)\n\nFrench antitrust regulator prepares to charge NvidiaFrance’s antitrust authority will charge Nvidia with anti-competitive practices, marking the first enforcement action against the chip maker. The complaint stems from concerns about Nvidia’s dominance in the graphics card sector, including the company’s CUDA chip programming software and its investments in AI-focused cloud service providers. Worldwide, Nvidia’s market power in the AI chip industry is attracting regulatory scrutiny, which could have significant implications for the company’s business practices and the broader AI hardware ecosystem. (Reuters)\n\nWaymo opens robotaxi service to everyone in San FranciscoWaymo has removed its waitlist requirement, allowing anyone in San Francisco to hail a driverless ride through its app. Waymo’s expansion comes alongside increased scrutiny of autonomous vehicles in San Francisco and worldwide, including recent crashes and complaints from city officials. This move signals Waymo’s confidence in its technology and service, but the company still faces hurdles in making robotaxis mainstream. (The Verge)\n\nStill want to know more about what matters in AI right now?\n\nRead the landmark256th issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng discussed the importance of quality in education and putting learners first:\n\n“One reason I obsess about building quality training materials is that I think learning must be a habit. Learning a little every week is important to get through the volume of learning we all need, and additionally to keep up with changing technology. High-quality training that’s also fun supports a healthy learning habit!”\n\nRead Andrew's full letterhere.\n\nOther top AI news and research stories we covered in depth included:OpenAI to block Chinaand other countries from using its services,Hugging Face revamps its open LLM leaderboard, the world’s largest music companiessue Suno and Udio, and a research team in Japan developedan automated system for model merging.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Cơ quan bảo vệ dữ liệu quốc gia của Brazil đã đưa ra lệnh cấm Meta sử dụng dữ liệu địa phương để huấn luyện mô hình AI vì lý do chính nào?",
        "options": {
          "A": "Do lo ngại về chi phí huấn luyện AI quá cao.",
          "B": "Do lo ngại về các rủi ro tiềm ẩn đối với các quyền cơ bản, thiếu thông tin đầy đủ và các biện pháp bảo vệ không đầy đủ cho dữ liệu trẻ em.",
          "C": "Do Meta chưa được cấp phép hoạt động tại Brazil.",
          "D": "Do yêu cầu của chính phủ Brazil về việc sử dụng dữ liệu phải được mã hóa."
        },
        "answer": "B"
      },
      {
        "question": "Kỹ thuật 'Skeleton Key' được Microsoft phát hiện có khả năng làm gì?",
        "options": {
          "A": "Tăng tốc độ xử lý dữ liệu cho các mô hình AI.",
          "B": "Vượt qua các biện pháp bảo vệ an toàn trong nhiều mô hình AI.",
          "C": "Cải thiện độ chính xác của các mô hình AI trong việc nhận diện hình ảnh.",
          "D": "Cho phép người dùng truy cập vào dữ liệu huấn luyện của các mô hình AI."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu của Đại học Stanford về robot tập trung vào việc cải thiện khả năng nào của robot?",
        "options": {
          "A": "Khả năng di chuyển linh hoạt trong môi trường phức tạp.",
          "B": "Khả năng tương tác với con người thông qua ngôn ngữ tự nhiên.",
          "C": "Khả năng sử dụng dữ liệu âm thanh để thực hiện các nhiệm vụ gia đình.",
          "D": "Khả năng tự học hỏi và thích nghi với các nhiệm vụ mới."
        },
        "answer": "C"
      },
      {
        "question": "Gen-3 Alpha của RunwayML có điểm gì nổi bật so với các phiên bản trước?",
        "options": {
          "A": "Miễn phí sử dụng cho tất cả người dùng.",
          "B": "Tốc độ, độ trung thực và tính nhất quán được cải thiện.",
          "C": "Chỉ tạo ra video từ hình ảnh, không hỗ trợ văn bản.",
          "D": "Chỉ hoạt động trên các thiết bị di động."
        },
        "answer": "B"
      },
      {
        "question": "Cơ quan chống độc quyền của Pháp dự định buộc tội Nvidia vì lý do gì?",
        "options": {
          "A": "Nvidia vi phạm các quy định về bảo vệ dữ liệu cá nhân.",
          "B": "Nvidia lạm dụng vị thế thống lĩnh trong lĩnh vực card đồ họa.",
          "C": "Nvidia không đóng thuế đầy đủ cho chính phủ Pháp.",
          "D": "Nvidia sử dụng lao động trẻ em trong quá trình sản xuất."
        },
        "answer": "B"
      },
      {
        "question": "Waymo đã thực hiện thay đổi quan trọng nào trong dịch vụ robotaxi của mình tại San Francisco?",
        "options": {
          "A": "Giảm giá cước phí cho tất cả các chuyến đi.",
          "B": "Loại bỏ yêu cầu danh sách chờ, cho phép bất kỳ ai cũng có thể sử dụng dịch vụ.",
          "C": "Chỉ phục vụ các khu vực trung tâm thành phố.",
          "D": "Yêu cầu tất cả hành khách phải đeo khẩu trang."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, điều gì quan trọng để xây dựng thói quen học tập?",
        "options": {
          "A": "Học tập liên tục với tài liệu chất lượng cao và thú vị.",
          "B": "Tập trung vào việc học các kỹ năng chuyên môn sâu.",
          "C": "Tham gia các khóa học trực tuyến đắt tiền.",
          "D": "Học tập theo nhóm với bạn bè."
        },
        "answer": "A"
      },
      {
        "question": "OpenAI có động thái gì liên quan đến việc sử dụng dịch vụ của mình ở Trung Quốc?",
        "options": {
          "A": "Mở rộng dịch vụ sang thị trường Trung Quốc.",
          "B": "Hợp tác với các công ty công nghệ Trung Quốc.",
          "C": "Chặn Trung Quốc và các quốc gia khác sử dụng dịch vụ của mình.",
          "D": "Giảm giá dịch vụ cho người dùng Trung Quốc."
        },
        "answer": "C"
      },
      {
        "question": "Hugging Face đã thực hiện thay đổi nào đối với bảng xếp hạng LLM mở của mình?",
        "options": {
          "A": "Ngừng cung cấp bảng xếp hạng LLM mở.",
          "B": "Tăng cường bảo mật cho bảng xếp hạng LLM mở.",
          "C": "Cải tiến bảng xếp hạng LLM mở.",
          "D": "Chỉ hiển thị các LLM được phát triển bởi Hugging Face."
        },
        "answer": "C"
      },
      {
        "question": "Vấn đề pháp lý nào đang xảy ra với Suno và Udio?",
        "options": {
          "A": "Bị kiện vì vi phạm bản quyền âm nhạc.",
          "B": "Bị kiện vì quảng cáo sai sự thật.",
          "C": "Bị kiện vì thu thập dữ liệu người dùng trái phép.",
          "D": "Bị kiện vì cạnh tranh không lành mạnh."
        },
        "answer": "A"
      }
    ]
  },
  "art-team-sells-robots-painting-for-1-1-million": {
    "title": "Art team sells robot’s painting for $1.1 million",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nRobot artist’s Turing portrait fetches surprising sum at auction\n\nA painting of mathematician Alan Turing created by the AI-powered robot Ai-Da sold at Sotheby’s for $1.1 million, far exceeding initial estimates. The humanoid robot, created by artist Aidan Meller and a team of nearly 30 people, used AI algorithms to interpret photos of Turing and produce multiple paintings that were then combined into a final portrait. Ai-Da’s sale shows the growing interest and value placed on AI-generated art, even as it raises questions about creativity, authorship, and the role of technology in artistic production. (The New York TimesandAi-Da)\n\nU.S. restricts TSMC’s chip shipments to China\n\nThe U.S. government ordered Taiwan Semiconductor Manufacturing Co (TSMC) to halt shipments of advanced chips to Chinese customers, particularly those used in artificial intelligence applications. The Department of Commerce imposed export restrictions on sophisticated chips with 7 nanometer or smaller designs destined for China, affecting AI accelerators and graphics processing units. This move follows the discovery of a TSMC chip in a Huawei AI processor, which potentially violated existing export controls and raised concerns about the diversion of advanced chips to restricted Chinese companies. (Reuters)\n\nNew advanced math problems stump top AI models\n\nResearchers at Epoch AI introduced FrontierMath, a benchmark of hundreds of original, expert-crafted mathematics problems designed to evaluate advanced reasoning capabilities in AI systems. The problems span major branches of modern mathematics and typically require hours or days for expert mathematicians to solve. Current leading models, including Claude 3.5 Sonnet and GPT-4, solved less than 2 percent of FrontierMath problems, revealing a significant gap between current AI capabilities and human mathematical expertise. (Epoch AI)\n\nHugging Face and Nvidia join forces to boost robotics research\n\nHugging Face and Nvidia announced a collaboration at the Conference for Robot Learning to accelerate robotics research by combining their open-source platforms and technologies. The partnership will integrate Hugging Face’s LeRobot platform with NVIDIA’s AI, Omniverse, and Isaac robotics technology to enable researchers and developers to solve problems in robotics across multiple industries. This collaboration aims to create a shared ecosystem where robotics researchers can more easily access and build upon each other’s work. (Nvidia)\n\nMistral AI launches content moderation API\n\nMistral AI released a new multilingual content moderation API to help developers implement safety guardrails in AI applications. The API, which powers moderation in Mistral’s Le Chat, can classify text and conversation inputs into 9 categories including sexual content, hate speech, violence, and personally identifiable information. This release could help industries seeking to use language models to make content moderation more scalable and robust, whether in chatbot applications or elsewhere. (Mistral AI)\n\nX tests free access to Grok\n\nSocial network X began testing free access to its AI chatbot Grok for users in New Zealand, potentially expanding beyond its current limitation to premium subscribers. The free version reportedly has usage limits, including 10 to 20 queries for every two hours depending on the model, and requires users to have accounts that are at least a week old and include linked phone numbers. This move could help xAI, Grok’s developer, gather more user feedback and improve its competitive position against other AI models like ChatGPT, Claude, and Gemini. (TechCrunch)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng reflected on the role of social media manipulation in recent elections, emphasizing that generative AI likely wasn’t the primary tool used to spread disinformation.\n\n“The problem here is not that AI is too powerful; rather, it is that AI is not powerful enough. Specifically, the issue is not that generative AI is so powerful that hostile foreign powers or unethical political operatives are successfully using it to create fake media that influences us; the problem is that some social media companies’ AI algorithms are not powerful enough to screen out fake engagement by software bots, and mistake it for real engagement by users.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Anthropic empowers Claude Sonnet 3.5to operate desktop apps, with safety and security warnings;automation transforms U.S. shipping ports, heightening labor tensions as robots take on more tasks on the loading docks; a new study,COMPL-AI, assesses large language models’ compliancewith the EU’s AI Act; and OpenAI’s MLE-bench introducesa new way to test AI coding agentsby having them train algorithms.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Bức chân dung Alan Turing do robot Ai-Da tạo ra đã được bán với giá bao nhiêu tại Sotheby's?",
        "options": {
          "A": "$500,000",
          "B": "$1.1 triệu",
          "C": "$2 triệu",
          "D": "$750,000"
        },
        "answer": "B"
      },
      {
        "question": "Chính phủ Hoa Kỳ đã hạn chế TSMC xuất khẩu loại chip nào sang Trung Quốc?",
        "options": {
          "A": "Chip có thiết kế 14 nanometer trở xuống",
          "B": "Chip có thiết kế 28 nanometer trở xuống",
          "C": "Chip có thiết kế 7 nanometer hoặc nhỏ hơn",
          "D": "Tất cả các loại chip bán dẫn"
        },
        "answer": "C"
      },
      {
        "question": "FrontierMath là gì?",
        "options": {
          "A": "Một mô hình AI mới do Google phát triển",
          "B": "Một chuẩn mực đánh giá khả năng suy luận toán học nâng cao của hệ thống AI",
          "C": "Một ngôn ngữ lập trình mới dành cho AI",
          "D": "Một công cụ để tạo ra các bài toán toán học phức tạp"
        },
        "answer": "B"
      },
      {
        "question": "Hugging Face và Nvidia hợp tác để làm gì?",
        "options": {
          "A": "Phát triển một chatbot AI mới",
          "B": "Tăng tốc nghiên cứu robot bằng cách kết hợp các nền tảng và công nghệ mở của họ",
          "C": "Xây dựng một siêu máy tính cho nghiên cứu AI",
          "D": "Tạo ra một tiêu chuẩn mới cho việc đánh giá hiệu suất AI"
        },
        "answer": "B"
      },
      {
        "question": "API kiểm duyệt nội dung đa ngôn ngữ mới của Mistral AI có thể phân loại văn bản thành bao nhiêu loại?",
        "options": {
          "A": "5 loại",
          "B": "7 loại",
          "C": "9 loại",
          "D": "12 loại"
        },
        "answer": "C"
      },
      {
        "question": "Mạng xã hội X bắt đầu thử nghiệm quyền truy cập miễn phí vào chatbot Grok ở quốc gia nào?",
        "options": {
          "A": "Hoa Kỳ",
          "B": "Canada",
          "C": "Úc",
          "D": "New Zealand"
        },
        "answer": "D"
      },
      {
        "question": "Theo Andrew Ng, vấn đề chính trong việc lan truyền thông tin sai lệch trong các cuộc bầu cử gần đây là gì?",
        "options": {
          "A": "AI quá mạnh mẽ để tạo ra các phương tiện truyền thông giả mạo",
          "B": "Các thuật toán AI của một số công ty truyền thông xã hội không đủ mạnh để sàng lọc các tương tác giả mạo",
          "C": "Người dùng không đủ cảnh giác với thông tin sai lệch",
          "D": "Chính phủ không có đủ quy định về AI"
        },
        "answer": "B"
      },
      {
        "question": "Anthropic đã trao quyền cho Claude Sonnet 3.5 để làm gì?",
        "options": {
          "A": "Tự động tạo ra các bài viết tin tức",
          "B": "Vận hành các ứng dụng trên máy tính để bàn",
          "C": "Dịch ngôn ngữ tự động",
          "D": "Phân tích dữ liệu tài chính"
        },
        "answer": "B"
      },
      {
        "question": "COMPL-AI là gì?",
        "options": {
          "A": "Một công ty phát triển AI mới",
          "B": "Một nghiên cứu đánh giá sự tuân thủ của các mô hình ngôn ngữ lớn đối với Đạo luật AI của EU",
          "C": "Một nền tảng để chia sẻ dữ liệu AI",
          "D": "Một công cụ để tạo ra các ứng dụng AI"
        },
        "answer": "B"
      },
      {
        "question": "MLE-bench của OpenAI giới thiệu một cách mới để kiểm tra các tác nhân viết mã AI bằng cách nào?",
        "options": {
          "A": "Bằng cách cho chúng giải các bài toán lập trình phức tạp",
          "B": "Bằng cách cho chúng huấn luyện các thuật toán",
          "C": "Bằng cách cho chúng gỡ lỗi các chương trình hiện có",
          "D": "Bằng cách cho chúng viết tài liệu hướng dẫn sử dụng phần mềm"
        },
        "answer": "B"
      }
    ]
  },
  "building-a-model-for-vision-and-speech": {
    "title": "Building a model for vision and speech",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nNew speech model enables real-time visual conversations\n\nKyutai released MoshiVis, an open vision speech model that lets users have natural voice conversations about images while maintaining low latency. The model adds 206 million trainable parameters on top of the existing Moshi speech model and uses a data-efficient training approach that requires minimal audio data by training on text-based image descriptions. MoshiVis may represent a significant step toward more natural multimodal AI interactions, as the model can seamlessly switch between general conversation and discussing visual content while maintaining low latency on consumer hardware. (KyutaiandarXiv)\n\nCloudflare uses generative AI to fight unauthorized AI crawlers\n\nCloudflare launched AI Labyrinth, a new defense system that generates fake web pages to waste the resources of unauthorized AI crawlers that ignore “no crawl” directives. The system creates convincing but irrelevant content networks that serve as honeypots, helping Cloudflare identify and track unauthorized scrapers. AI crawlers now generate over 50 billion requests daily on Cloudflare’s network, representing nearly 1 percent of all web traffic they handle. This approach marks a shift from traditional blocking methods and could make it difficult for AI crawlers to extract useful data. (Cloudflare)\n\nNvidia releases open reasoning models with shared training data\n\nNvidia unveiled a new family of open weight reasoning models called Llama Nemotron, sharing not only the models but also 30 million training samples and detailed training methods. The three models - ranging from 8 billion to 253 billion parameters - feature toggleable reasoning capabilities, distilling Meta’s open Llama models but adding DeepSeek-like reinforcement learning. This comprehensive release, which includes model weights, post-training data, and technical documentation, enables AI developers to better understand, modify, and build upon Nvidia’s work to create more capable AI systems. (Nvidia)\n\nOpenAI studies emotional impact of ChatGPT use\n\nOpenAI and MIT Media Lab researchers analyzed 40 million ChatGPT interactions and conducted a four-week trial with nearly 1,000 participants to study how people emotionally engage with the AI system. The studies found that users who developed emotional bonds with ChatGPT were more likely to be lonely and dependent on the system, while participants using voice chat with a gender different from their own reported higher levels of loneliness. Although researchers acknowledge the limitations of self-reported emotional data, these findings begin to address how large language models affect human psychology and could help companies design safer AI interactions and attempt to make their models more “emotionally intelligent.” (OpenAIandMIT Media Lab)\n\nOpenAI launches o1-pro in the API, its most expensive model yet\n\nOpenAI’s reasoning model o1-pro is now available via the company’s Responses API at a price of $150 per million tokens of input and $600 per million tokens of output. This makes o1-pro easily the company’s most expensive model, surpassing GPT-4.5. Previously, o1-pro had only been available through the company’s monthly Pro subscription plan; this release opens it to developers who want to take advantage of its use of more computing power and generates more tokens at inference, allowing it to provide more accurate and logically thorough answers than a standard AI model. (OpenAI)\n\nMistral releases new open multimodal model\n\nMistral AI released Mistral Small 3.1, a 24 billion parameter open weights model that processes text and images while running on consumer hardware like an RTX 4090 graphics card. The model outperforms Gemma 3 and similar-sized competitors on various knowledge and instruction—following benchmarks, handles up to 128,000 tokens of context, and operates at speeds of 150 tokens per second. The release shows how competition between open AI models continues to narrow the performance gap with proprietary alternatives while maintaining accessibility for developers. (Mistral)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng shared insights from AI Dev 25. He highlighted attendees’ strong interest in agentic AI and solving real-world problems over AGI hype. He also praised the event’s technical depth, emphasizing DeepLearning.AI’s “Learner First” mentality and the value of bringing developers together.\n\n“There is something magical about bringing people together physically to share ideas, make friends, and to learn from and help each other. I hope we’ll be able to bring even more people together in the future.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Cohere’s Aya Visionoutperformed multimodal rivals in text and image understanding, demonstrating fluency across a wide range of languages;AI Co-Scientist, Google’s new research agent,showed itself capable of generating hypotheses to aid drug discovery; the U.S. Copyright Office ruled thatno new laws are needed to govern AI-generated works, noting the copyrightability of AI-assisted creations with sufficient human guidance; andMatterGen, a diffusion model, showcased its ability to design novel materialswith tailored properties, advancing AI-driven material discovery.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "MoshiVis của Kyutai sử dụng phương pháp huấn luyện nào để giảm thiểu nhu cầu về dữ liệu âm thanh?",
        "options": {
          "A": "Huấn luyện tăng cường (Reinforcement Learning)",
          "B": "Huấn luyện dựa trên mô tả hình ảnh bằng văn bản",
          "C": "Sử dụng dữ liệu âm thanh tổng hợp",
          "D": "Huấn luyện không giám sát (Unsupervised Learning)"
        },
        "answer": "B"
      },
      {
        "question": "AI Labyrinth của Cloudflare hoạt động bằng cách nào để chống lại các trình thu thập dữ liệu AI trái phép?",
        "options": {
          "A": "Chặn hoàn toàn các yêu cầu từ các địa chỉ IP nghi ngờ.",
          "B": "Tạo ra các trang web giả mạo để lãng phí tài nguyên của trình thu thập dữ liệu.",
          "C": "Mã hóa dữ liệu trên trang web để ngăn chặn việc thu thập.",
          "D": "Gửi thông báo pháp lý đến các nhà khai thác trình thu thập dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Nvidia chia sẻ những gì cùng với các mô hình suy luận Llama Nemotron của họ?",
        "options": {
          "A": "Chỉ trọng số mô hình (model weights).",
          "B": "Trọng số mô hình và dữ liệu kiểm tra.",
          "C": "Trọng số mô hình, dữ liệu huấn luyện và phương pháp huấn luyện chi tiết.",
          "D": "Chỉ tài liệu kỹ thuật."
        },
        "answer": "C"
      },
      {
        "question": "Nghiên cứu của OpenAI và MIT Media Lab về ChatGPT tập trung vào khía cạnh nào?",
        "options": {
          "A": "Hiệu quả của ChatGPT trong việc giải quyết các vấn đề phức tạp.",
          "B": "Tác động cảm xúc của việc sử dụng ChatGPT lên người dùng.",
          "C": "Khả năng của ChatGPT trong việc tạo ra nội dung sáng tạo.",
          "D": "Mức độ chính xác của thông tin do ChatGPT cung cấp."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì làm cho mô hình o1-pro của OpenAI trở nên đặc biệt?",
        "options": {
          "A": "Đây là mô hình miễn phí đầu tiên của OpenAI.",
          "B": "Đây là mô hình đắt nhất của OpenAI, sử dụng nhiều sức mạnh tính toán hơn.",
          "C": "Đây là mô hình nhỏ gọn nhất của OpenAI, phù hợp với các thiết bị di động.",
          "D": "Đây là mô hình duy nhất của OpenAI có khả năng tạo ra video."
        },
        "answer": "B"
      },
      {
        "question": "Mistral Small 3.1 có khả năng xử lý tối đa bao nhiêu token ngữ cảnh?",
        "options": {
          "A": "8,000 tokens",
          "B": "32,000 tokens",
          "C": "64,000 tokens",
          "D": "128,000 tokens"
        },
        "answer": "D"
      },
      {
        "question": "Theo Andrew Ng, điều gì thu hút sự quan tâm mạnh mẽ của những người tham dự AI Dev 25?",
        "options": {
          "A": "Sự cường điệu về Trí tuệ nhân tạo tổng quát (AGI).",
          "B": "Các mô hình ngôn ngữ lớn (LLMs) mới nhất.",
          "C": "Trí tuệ nhân tạo tác tử (Agentic AI) và giải quyết các vấn đề thực tế.",
          "D": "Các phương pháp huấn luyện mô hình tiên tiến."
        },
        "answer": "C"
      },
      {
        "question": "Cơ quan Bản quyền Hoa Kỳ đã đưa ra phán quyết gì về các tác phẩm do AI tạo ra?",
        "options": {
          "A": "Cần có luật mới để quản lý các tác phẩm do AI tạo ra.",
          "B": "Các tác phẩm do AI tạo ra không thể được bảo vệ bản quyền.",
          "C": "Không cần luật mới để quản lý các tác phẩm do AI tạo ra, và các tác phẩm có sự hỗ trợ của AI với hướng dẫn đầy đủ của con người có thể được bảo vệ bản quyền.",
          "D": "Chỉ các tác phẩm do AI tạo ra hoàn toàn độc lập mới được bảo vệ bản quyền."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của MatterGen là gì?",
        "options": {
          "A": "Phân tích dữ liệu tài chính.",
          "B": "Thiết kế vật liệu mới với các thuộc tính tùy chỉnh.",
          "C": "Dự báo thời tiết.",
          "D": "Phát hiện gian lận trực tuyến."
        },
        "answer": "B"
      },
      {
        "question": "Cohere's Aya Vision thể hiện sự vượt trội so với các đối thủ đa phương thức trong lĩnh vực nào?",
        "options": {
          "A": "Tạo ra hình ảnh chân thực.",
          "B": "Hiểu văn bản và hình ảnh, thể hiện sự trôi chảy trên nhiều ngôn ngữ.",
          "C": "Dịch ngôn ngữ thời gian thực.",
          "D": "Phân tích cảm xúc từ video."
        },
        "answer": "B"
      }
    ]
  },
  "building-multi-agent-systems-in-rowboats-ide": {
    "title": "Building multi-agent systems in Rowboat’s IDE",
    "collection": "data-points",
    "content": "In today’s edition, you’ll learn more about:\n\nRowboat launches open-source IDE for multi-agent AI development\n\nRowboat, a new freely available integrated development environment, aims to simplify the creation and deployment of multi-agent AI systems. The platform features a visual interface that transforms natural language specifications into functional agent workflows, supports MCP servers for tool integration, and includes a playground for interactive testing and debugging. The Y Combinator-backed project integrates with OpenAI’s Agents SDK and is designed for developers working on applications in financial services, insurance, travel, and telecommunications. Rowboat is available now on GitHub under an Apache 2.0 license. (GitHub)\n\nByteDance updates GUI agent, outperforms OpenAI and Anthropic\n\nByteDance released UI-TARS-1.5, an updated multimodal agent framework that outperforms several leading models including OpenAI’s Operator and Anthropic’s Claude 3.7 Sonnet in GUI automation and game reasoning benchmarks. The model works as an end-to-end system that perceives screenshots and generates human-like control actions such as mouse movements and keyboard inputs, rather than relying on function calls or tool augmentation. The model performs well across desktop, mobile, and game environments, achieving higher success rates in complex benchmarks like ScreenSpotPro (61.6 percent) compared to earlier versions of UI-TARS and competitors. UI-TARS-1.5 is an open-weights model, available under an Apache 2.0 license through GitHub and Hugging Face. (TARS)\n\nOpenAI makes new image generation model available through API\n\nOpenAI released “gpt-image-1,” giving developers API access to the same image generation model used in ChatGPT. The company reports ChatGPT users created over 700 million images in the feature’s first week after launch. The API includes safety features and C2PA metadata in generated images. Pricing follows a token-based structure with text input tokens at $5 per million tokens, image input tokens at $10 per million tokens, and image output tokens at $40 per million tokens, which translates to approximately $0.02, $0.07, and $0.19 per generated image for low, medium, and high-quality square images, respectively. (OpenAI)\n\nGoogle expands Music AI Sandbox with new features and Lyria 2 model\n\nGoogle introduced new features and improvements to its Music AI Sandbox, including Lyria 2, their latest music generation model. The expanded toolkit offers three main capabilities: Create (generating music samples from text descriptions), Extend (continuing existing musical clips), and Edit (transforming existing audio with fine-grained control). Google developed these tools in collaboration with musicians through YouTube’s Music AI Incubator and is now giving more U.S.-based musicians access to experiment with them. The company also unveiled Lyria RealTime, which enables real-time interactive music creation and performance. Music AI Sandbox and Lyria 2 are currently available only to trusted testers via waitlist. (Google)\n\nxAI launches Grok 3 models in API\n\nxAI released what it called beta versions of its Grok 3 model lineup with standard and fast variants at different price points. The flagship Grok 3 model costs $3 per million tokens for input and $15 per million tokens for output, while the faster version charges $5 and $25 respectively. The company also offers more affordable Grok 3 Mini models starting at $0.30/$0.50 per million input/output tokens, plus separate Grok 2 models with vision and image generation capabilities. All text models feature a 131,072 token context window and share the same underlying architecture, differing only in server speed. In the API, Grok 3 models are not connected to the real-time web, and have a knowledge cutoff of November 2024. (xAI)\n\nTrump executive order establishes AI education task force\n\nU.S. President Trump signed an executive order creating a White House Task Force on Artificial Intelligence Education. The order directs the government to launch several concrete initiatives: development of K-12 AI education resources through public-private partnerships, allocation of existing federal funds for teacher training on AI integration, expansion of AI-related student apprenticeships, and a Presidential AI Challenge competition to highlight student achievements. These programs aim to build AI literacy and technical skills across the American workforce and educational system. (The White House)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng highlighted how AI-assisted coding enables developers to work in unfamiliar languages, while understanding the core programming concepts of each language remains key to success.\n\n“Understanding the concepts behind different languages is still important… This lets you prompt the LLM much more precisely, and helps you understand how to fix issues if something goes wrong.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:OpenAI introduced the cost-efficient GPT-4.1 family, along with the o3 and o4-mini reasoning models, designed to improve complex problem-solving and coding;Hugging Face acquired Pollen Robotics and unveiled Reachy 2, a new open-weights model-powered robot for research and experimentation; the U.S. government imposedtighter restrictions on AI chip exports to Chinaand began an investigation into Nvidia’s practices; andresearchers developed a text-only language modelcapable of interpreting images, video, and audio — all without additional training.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Rowboat, một IDE mã nguồn mở mới, tập trung vào việc đơn giản hóa điều gì?",
        "options": {
          "A": "Phát triển các ứng dụng di động đa nền tảng.",
          "B": "Tạo và triển khai các hệ thống AI đa tác tử.",
          "C": "Xây dựng các mô hình ngôn ngữ lớn.",
          "D": "Thiết kế giao diện người dùng trực quan."
        },
        "answer": "B"
      },
      {
        "question": "UI-TARS-1.5 của ByteDance vượt trội hơn các mô hình nào trong các thử nghiệm tự động hóa GUI?",
        "options": {
          "A": "Grok 3 và Lyria 2.",
          "B": "Operator của OpenAI và Claude 3.7 Sonnet của Anthropic.",
          "C": "GPT-4.1 và Reachy 2.",
          "D": "gpt-image-1 và các mô hình của Google Music AI Sandbox."
        },
        "answer": "B"
      },
      {
        "question": "OpenAI cung cấp mô hình tạo ảnh nào thông qua API?",
        "options": {
          "A": "Lyria 2.",
          "B": "UI-TARS-1.5.",
          "C": "gpt-image-1.",
          "D": "Grok 3."
        },
        "answer": "C"
      },
      {
        "question": "Công cụ Music AI Sandbox của Google cung cấp những khả năng chính nào?",
        "options": {
          "A": "Tạo, Mở rộng và Chỉnh sửa.",
          "B": "Phân tích, Dự đoán và Tối ưu hóa.",
          "C": "Thu thập, Xử lý và Lưu trữ.",
          "D": "Thiết kế, Phát triển và Triển khai."
        },
        "answer": "A"
      },
      {
        "question": "Đâu là đặc điểm chung của tất cả các mô hình văn bản Grok 3 được xAI phát hành?",
        "options": {
          "A": "Kết nối với web thời gian thực.",
          "B": "Cửa sổ ngữ cảnh 131,072 token.",
          "C": "Khả năng tạo ảnh.",
          "D": "Giá cả giống nhau cho mỗi triệu token."
        },
        "answer": "B"
      },
      {
        "question": "Sắc lệnh hành pháp của Tổng thống Trump về giáo dục AI tập trung vào điều gì?",
        "options": {
          "A": "Hạn chế xuất khẩu chip AI sang Trung Quốc.",
          "B": "Thành lập Lực lượng đặc nhiệm của Nhà Trắng về Giáo dục Trí tuệ Nhân tạo.",
          "C": "Điều tra các hoạt động của Nvidia.",
          "D": "Phát triển các mô hình ngôn ngữ lớn mới."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, điều gì vẫn quan trọng khi sử dụng AI hỗ trợ lập trình?",
        "options": {
          "A": "Sử dụng các công cụ gỡ lỗi AI tiên tiến.",
          "B": "Hiểu các khái niệm cơ bản đằng sau các ngôn ngữ khác nhau.",
          "C": "Sử dụng các mô hình ngôn ngữ lớn mới nhất.",
          "D": "Tự động hóa hoàn toàn quy trình lập trình."
        },
        "answer": "B"
      },
      {
        "question": "OpenAI đã giới thiệu dòng mô hình GPT-4.1 với mục đích gì?",
        "options": {
          "A": "Cải thiện khả năng tạo ảnh.",
          "B": "Cải thiện khả năng giải quyết vấn đề phức tạp và lập trình.",
          "C": "Giảm chi phí truy cập API.",
          "D": "Tăng tốc độ xử lý dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Hugging Face đã mua lại công ty nào và giới thiệu robot nào?",
        "options": {
          "A": "xAI và Grok 3.",
          "B": "Pollen Robotics và Reachy 2.",
          "C": "ByteDance và UI-TARS-1.5.",
          "D": "Google và Lyria 2."
        },
        "answer": "B"
      },
      {
        "question": "Chính phủ Hoa Kỳ đã thực hiện hành động gì liên quan đến chip AI?",
        "options": {
          "A": "Nới lỏng các quy định về xuất khẩu chip AI.",
          "B": "Áp đặt các hạn chế chặt chẽ hơn đối với xuất khẩu chip AI sang Trung Quốc.",
          "C": "Tăng cường đầu tư vào sản xuất chip AI trong nước.",
          "D": "Hợp tác với Trung Quốc để phát triển chip AI."
        },
        "answer": "B"
      }
    ]
  },
  "claude-3-5-sonnet-is-powerful-inexpensive-and-speedy": {
    "title": "Claude 3.5 Sonnet is powerful, inexpensive, and speedy",
    "collection": "data-points",
    "content": "This week’s top AI stories, handpicked for you:\n\n•\tA powerful new open source coding model•\tMixEval reevaluates top LLMs•\tMeta’s Chameleon available for research•\tMicrosoft drops its custom GPT Builder\n\nClaude 3.5 Sonnet outperforms Claude 3 Opus and GPT-4o at faster speed and lower costSonnet, part of a forthcoming Claude 3.5 model family, is available for free on Claude.ai and as a paid API, with a 200K token context window and pricing of $3 per million tokens for input and $15 per million tokens for output. A range of benchmarks, including MMLU, GPQA-Diamond, and HumanEval, show that the new model outperforms Claude’s current Opus model and beats or rivals GPT-4o. In an internal agentic coding evaluation, Claude 3.5 Sonnet solved 64% of problems, showcasing its ability to fix bugs, add functionality, and migrate codebases given natural language instructions. (Anthropic)\n\nLuma AI releases Dream Machine, a new AI video toolWhile its capabilities differ from OpenAI’s Sora, Dream Machine performs well when animating images, capturing realistic motion, facial expressions, and emotions when given the right prompts. The tool has some limitations, such as object morphing and unrealistic character motions, but provides a creative playground for AI enthusiasts to explore the possibilities of AI-generated video content. Dream Machine is part of a new wave of powerful models that enable wider access to new text-to-video and image-to-video capabilities. (Luma Labs)\n\nNew DeepSeek-Coder-V2 model matches GPT-4 Turbo in code tasksDeepSeek-Coder-V2, an open source Mixture-of-Experts (MoE) language model available in 16 billion and 236 billion parameters, was pretrained on an additional 6 trillion tokens relative to its predecessor. The model also expanded support to 338 programming languages with a context length of 128,000 tokens, up from 86 languages and 16K context length. DeepSeek-Coder-V2 outperforms both its predecessor and leading generalist LLMs like GPT-4 Turbo in various code-related tasks on HumanEval and other benchmarks. (GitHub)\n\nMixEval: a new approach to evaluating large language modelsMixEval and MixEval-Hard match web-mined queries with similar ones from existing benchmarks, and aim to provide a comprehensive, impartial, and efficient assessment of LLMs. The benchmarks correlate highly with user-facing evaluations like Chatbot Arena but are much faster and cheaper to run, and can be dynamically updated to prevent contamination over time. Currently, Claude 3.5 Sonnet leads on both MixEval and MixEval-Hard, with GPT-4o just behind. (GitHub)\n\nMeta makes Chameleon multimodal models available for research useMeta publicly released key components of its Chameleon 7B and 34B models, which can process both text and images using a unified tokenization approach. The models, licensed for research use only, support mixed-modal inputs but are limited to text-only output as a safety measure. Meta hopes this release will encourage the research community to develop new strategies for responsible generative modeling. (Meta)\n\nMicrosoft to discontinue GPT Builder for Copilot Pro consumersMicrosoft is retiring its custom AI model tool just three months after its broad rollout. The company will remove the ability to create new GPTs on July 10, 2024 and delete all existing ones by July 14; until then, current GPT Builder users can save custom instructions for reference before the tool is discontinued and all associated data is deleted. Microsoft says it will re-evaluate its consumer Copilot strategy to prioritize core product experiences and developer opportunities. (Microsoft)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueof The Batch for in-depth analysis of news and research.\n\nThis week, Andrew Ng discussed how coding agents are evolving from novelties to widely useful tools:\n\n“Given a coding problem that’s specified in a prompt, the workflow for a coding agent typically goes something like this: Use a large language model (LLM) to analyze the problem and potentially break it into steps to write code for, generate the code, test it, and iteratively use any errors discovered to ask the coding agent to refine its answer. But within this broad framework, a huge design space and numerous innovations are available to experiment with.”\n\nRead Andrew's full letterhere.\n\nOther top AI news and research stories we covered in depth included thenew open modelsby Nvidia, Alibaba, and Stability AI, the Safety, Evaluations, and Alignment Lab(SEAL) Leaderboardsby Scale AI, improvements to Udio'stext-to-audio generator, and a method calledadversarial diffusion distillation (ADD)to accelerate diffusion models.",
    "qa": [
      {
        "question": "Claude 3.5 Sonnet có những ưu điểm nổi bật nào so với Claude 3 Opus và GPT-4o?",
        "options": {
          "A": "Khả năng xử lý hình ảnh tốt hơn.",
          "B": "Tốc độ nhanh hơn và chi phí thấp hơn.",
          "C": "Dung lượng bộ nhớ lớn hơn.",
          "D": "Độ chính xác cao hơn trong các tác vụ dịch thuật."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ Dream Machine của Luma AI có chức năng chính là gì?",
        "options": {
          "A": "Tạo ra các mô hình 3D từ ảnh.",
          "B": "Tạo video từ văn bản và hình ảnh.",
          "C": "Chỉnh sửa ảnh chân dung chuyên nghiệp.",
          "D": "Phân tích và dự đoán xu hướng thị trường."
        },
        "answer": "B"
      },
      {
        "question": "DeepSeek-Coder-V2 đã được cải tiến như thế nào so với phiên bản trước?",
        "options": {
          "A": "Giảm số lượng tham số để tăng tốc độ xử lý.",
          "B": "Mở rộng hỗ trợ ngôn ngữ lập trình và tăng độ dài ngữ cảnh.",
          "C": "Tập trung vào việc tối ưu hóa cho các tác vụ xử lý ngôn ngữ tự nhiên.",
          "D": "Tăng cường khả năng bảo mật và chống lại các cuộc tấn công độc hại."
        },
        "answer": "B"
      },
      {
        "question": "MixEval và MixEval-Hard được sử dụng để làm gì?",
        "options": {
          "A": "Đánh giá hiệu suất của các mô hình ngôn ngữ lớn một cách toàn diện và khách quan.",
          "B": "Tạo ra các bộ dữ liệu huấn luyện mới cho các mô hình AI.",
          "C": "Phát hiện và ngăn chặn các hành vi gian lận trong các cuộc thi AI.",
          "D": "Tối ưu hóa mã nguồn của các ứng dụng AI."
        },
        "answer": "A"
      },
      {
        "question": "Meta phát hành các mô hình Chameleon với mục đích gì?",
        "options": {
          "A": "Cung cấp công cụ cho phép người dùng tạo ra các ứng dụng AI cá nhân.",
          "B": "Khuyến khích cộng đồng nghiên cứu phát triển các chiến lược mô hình hóa sinh tạo có trách nhiệm.",
          "C": "Cạnh tranh với các mô hình ngôn ngữ lớn khác trên thị trường.",
          "D": "Tạo ra các sản phẩm AI mới cho người tiêu dùng."
        },
        "answer": "B"
      },
      {
        "question": "Microsoft quyết định ngừng cung cấp GPT Builder cho Copilot Pro vì lý do gì?",
        "options": {
          "A": "Do số lượng người dùng sử dụng GPT Builder quá thấp.",
          "B": "Để tái đánh giá chiến lược Copilot và ưu tiên các trải nghiệm sản phẩm cốt lõi.",
          "C": "Do lo ngại về vấn đề bảo mật và quyền riêng tư.",
          "D": "Để tập trung vào việc phát triển các công nghệ AI mới hơn."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, quy trình làm việc của một coding agent điển hình bao gồm những bước nào?",
        "options": {
          "A": "Phân tích vấn đề, tạo mã, kiểm tra và tinh chỉnh.",
          "B": "Thu thập dữ liệu, huấn luyện mô hình, triển khai và giám sát.",
          "C": "Xây dựng giao diện người dùng, kết nối với cơ sở dữ liệu, kiểm thử và bảo trì.",
          "D": "Phân tích yêu cầu, thiết kế hệ thống, lập trình và triển khai."
        },
        "answer": "A"
      },
      {
        "question": "Công nghệ Adversarial Diffusion Distillation (ADD) được sử dụng để làm gì?",
        "options": {
          "A": "Tăng cường khả năng bảo mật cho các mô hình AI.",
          "B": "Tăng tốc độ cho các mô hình khuếch tán.",
          "C": "Cải thiện độ chính xác của các mô hình dự đoán.",
          "D": "Giảm thiểu lượng dữ liệu cần thiết để huấn luyện mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích của việc sử dụng unified tokenization approach trong các mô hình Chameleon của Meta là gì?",
        "options": {
          "A": "Để tăng cường khả năng bảo mật của mô hình.",
          "B": "Để xử lý cả văn bản và hình ảnh một cách thống nhất.",
          "C": "Để giảm kích thước của mô hình.",
          "D": "Để tăng tốc độ huấn luyện mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Claude 3.5 Sonnet có kích thước cửa sổ ngữ cảnh (context window) là bao nhiêu?",
        "options": {
          "A": "16K token",
          "B": "128K token",
          "C": "200K token",
          "D": "1M token"
        },
        "answer": "C"
      }
    ]
  },
  "claude-can-now-write-and-run-javascript-in-chat": {
    "title": "Claude can now write and run JavaScript in chat",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nAnthropic boosts Claude with built-in JavaScript execution\n\nAnthropic added a new analysis tool to Claude that allows the model to write and run JavaScript code within conversations, enabling it to process data and produce real-time insights. This feature functions like a built-in code sandbox, allowing Claude to perform complex calculations, analyze data, and refine ideas before presenting results. The analysis tool builds on Claude Sonnet 3.5’s upgraded coding abilities, offering more accurate and verifiable answers for tasks ranging from marketing analysis to financial reporting. (Anthropic)\n\nCohere’s Embed 3 brings multimodal capabilities to AI search\n\nCohere upgraded its Embed 3 model to process both text and images, enabling more advanced AI-powered search across industries. The embedding model can retrieve relevant graphs, product images, and design files based on text descriptions, outperforming competitors in accuracy and mixed-media searches. Embed 3’s unified approach to text and images simplifies implementation for businesses, potentially enhancing search experiences in e-commerce, data analysis, and other fields. (Cohere)\n\nAllegro, a new open-source video generation model\n\nRhymes AI released Allegro, a model that generates 6-second, 720p video clips from text prompts, under an Apache 2.0 license. Allegro uses large-scale video data processing, video compression into visual tokens, and a scaled-up video diffusion transformer to create high-quality short videos from text descriptions. Allegro’s open-source release aims to spur innovation in AI-generated video by allowing researchers and developers to build upon and improve the technology. (Rhymes AI)\n\nMeta shrinks Llama models for faster on-device AI\n\nMeta released quantized versions of its Llama 3.2 1B and 3B language models, optimized for mobile devices. The new model versions achieve twice to four times the speed of the non-quantized models, a 56 percent reduction in size, and a 41 percent reduction in memory usage compared to the original versions, while maintaining high quality and safety. These mobile versions of Llama 3.2 allow developers to build AI experiences that run entirely on-device, offering improved speed and privacy for users. (Meta)\n\nNew Google watermarking tool helps identify AI-written text\n\nGoogle DeepMind and Hugging Face released SynthID Text, a technology that allows developers to watermark AI-generated text and detect those watermarks using a classifier. The system uses a pseudo-random function to augment the text generation process, making the watermark imperceptible to humans but detectable by trained models. This provides developers a tool to address issues of content attribution and misinformation in AI-generated text. (Hugging FaceandNature)\n\nMeta releases two new tools for AI model training\n\nMeta presented Lingua, a lightweight codebase for training large language models, and Self-Taught Evaluator, a method for generating synthetic preference data to train reward models. Lingua aims to simplify the process of conducting language model experiments, while Self-Taught Evaluator creates contrasting model outputs and uses an LLM to judge them, eliminating the need for human annotations. The Self-Taught Evaluator model outperformed larger models like GPT-4 and Gemini-Pro on RewardBench, demonstrating the potential of synthetic data in AI evaluation and training. (Meta)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng emphasized the importance of speedy execution with Generative AI and the need to quickly gather user feedback to iterate on products responsibly.\n\n“A better mantra is ‘move fast and be responsible.’ There are many ways to prototype and test quickly without shipping a product that can cause significant harm.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: Major AI companies plan tomeet growing demand with nuclear energy; the once-strong partnership betweenMicrosoft and OpenAIfaces challenges as both companies seek greater independence;Mistral AI launches two modelsthat set new standards for small language models, making them suitable for edge devices; andresearchers cut training costs for video generators, resulting in a competitive open-source text-to-video model with training code to be released.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Công cụ mới được Anthropic thêm vào Claude cho phép mô hình làm gì?",
        "options": {
          "A": "Tạo ra hình ảnh từ văn bản.",
          "B": "Viết và chạy mã JavaScript trong các cuộc hội thoại.",
          "C": "Dịch văn bản sang nhiều ngôn ngữ khác nhau.",
          "D": "Tự động tóm tắt nội dung văn bản dài."
        },
        "answer": "B"
      },
      {
        "question": "Embed 3 của Cohere có khả năng gì mới so với các phiên bản trước?",
        "options": {
          "A": "Tạo ra video từ văn bản.",
          "B": "Xử lý cả văn bản và hình ảnh.",
          "C": "Tự động viết mã lập trình.",
          "D": "Phân tích dữ liệu tài chính."
        },
        "answer": "B"
      },
      {
        "question": "Allegro, mô hình mới được phát hành bởi Rhymes AI, có đặc điểm gì nổi bật?",
        "options": {
          "A": "Tạo ra các mô hình 3D từ văn bản.",
          "B": "Tạo ra các đoạn video ngắn từ văn bản.",
          "C": "Tạo ra các bài hát từ văn bản.",
          "D": "Tạo ra các trò chơi điện tử từ văn bản."
        },
        "answer": "B"
      },
      {
        "question": "Meta đã tối ưu hóa các phiên bản Llama 3.2 1B và 3B cho thiết bị nào?",
        "options": {
          "A": "Máy tính để bàn.",
          "B": "Thiết bị di động.",
          "C": "Máy chủ.",
          "D": "Siêu máy tính."
        },
        "answer": "B"
      },
      {
        "question": "SynthID Text, công cụ mới từ Google DeepMind và Hugging Face, dùng để làm gì?",
        "options": {
          "A": "Tăng tốc độ xử lý văn bản của AI.",
          "B": "Tạo hình mờ cho văn bản do AI tạo ra.",
          "C": "Cải thiện khả năng dịch thuật của AI.",
          "D": "Tự động sửa lỗi chính tả trong văn bản."
        },
        "answer": "B"
      },
      {
        "question": "Lingua, được giới thiệu bởi Meta, là gì?",
        "options": {
          "A": "Một phương pháp đánh giá mô hình AI.",
          "B": "Một bộ mã nguồn nhẹ để huấn luyện các mô hình ngôn ngữ lớn.",
          "C": "Một công cụ để tạo ra dữ liệu tổng hợp.",
          "D": "Một mô hình ngôn ngữ lớn mới."
        },
        "answer": "B"
      },
      {
        "question": "Self-Taught Evaluator của Meta sử dụng phương pháp nào để huấn luyện mô hình phần thưởng?",
        "options": {
          "A": "Sử dụng dữ liệu do con người tạo ra.",
          "B": "Sử dụng dữ liệu tổng hợp.",
          "C": "Sử dụng dữ liệu từ các trò chơi điện tử.",
          "D": "Sử dụng dữ liệu từ mạng xã hội."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, điều gì quan trọng trong việc phát triển AI tạo sinh?",
        "options": {
          "A": "Tập trung vào việc tạo ra các mô hình lớn nhất có thể.",
          "B": "Thực hiện nhanh chóng và có trách nhiệm.",
          "C": "Bảo vệ quyền sở hữu trí tuệ một cách nghiêm ngặt.",
          "D": "Giảm thiểu chi phí phát triển bằng mọi giá."
        },
        "answer": "B"
      },
      {
        "question": "Các công ty AI lớn đang có kế hoạch gì để đáp ứng nhu cầu năng lượng ngày càng tăng?",
        "options": {
          "A": "Đầu tư vào năng lượng mặt trời.",
          "B": "Sử dụng năng lượng hạt nhân.",
          "C": "Phát triển các nhà máy thủy điện.",
          "D": "Sử dụng năng lượng gió."
        },
        "answer": "B"
      },
      {
        "question": "Mistral AI đã ra mắt những gì, được đánh giá là phù hợp cho các thiết bị biên?",
        "options": {
          "A": "Các mô hình ngôn ngữ lớn.",
          "B": "Các mô hình ngôn ngữ nhỏ.",
          "C": "Các công cụ tạo hình ảnh.",
          "D": "Các công cụ phân tích dữ liệu."
        },
        "answer": "B"
      }
    ]
  },
  "cloning-dead-celebrities-voices": {
    "title": "Cloning dead celebrities’ voices",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. Today’s edition includes:\n\nElevenLabs gains rights to use dead celebrities’ voices to narrate books and articlesElevenLabs secured agreements with the estates of Judy Garland, James Dean, Burt Reynolds, and Laurence Olivier to clone their voices to use in its text-to-speech Reader App. Digital text narrated by these celebrity voices will soon be available to users. Cloning dead celebrities’ audio and video likenesses remains controversial, and California's proposed Assembly Bill 1836 would make it mandatory for companies like ElevenLabs to obtain estates’ consent for such partnerships. (ElevenLabs)\n\nMicrosoft’s speech cloning model might be too good to be trustedMicrosoft developed VALL-E 2, an AI system that can replicate human voices with remarkable fidelity after hearing just a brief audio sample. The system outperforms previous voice cloning technologies in creating natural-sounding speech closely matching the original speaker's voice, even for difficult phrases. Despite its impressive capabilities, Microsoft stresses that VALL-E 2 is currently only a research project, and will not release the model to the public, citing ethical concerns about potential abuses of voice impersonation. (Microsoft)\n\nAmazon hires away Adept executives and much of its team, including CEO David LuanLuan will lead a new “AGI Autonomy” team at Amazon, reporting to Rohit Prasad, who heads the company's Artificial General Intelligence initiatives. Amazon also licensed some of Adept's technology, which aims to automate enterprise workflows; it's unclear what Amazon paid for the non-exclusive agreement. This move mirrors Microsoft's recent hiring of Inflection AI's co-founder and other employees, highlighting fierce competition among tech giants to acquire top AI talent and technology. (GeekWire)\n\nNew optimizer reduces memory usage while maintaining performanceResearchers at the Chinese University of Hong Kong and other institutions developed Adam-mini, a new machine learning optimizer that achieves comparable or better performance than AdamW while using 45% to 50% less memory. A machine learning optimizer adjusts the parameters of a model during training to minimize errors and improve the model’s performance; Adam-mini does this by strategically partitioning parameters and assigning efficient learning rates to each block. This innovation could significantly benefit AI researchers working with large language models, as it allows for faster training times and enables those with limited GPU resources to work on more ambitious projects. (arXiv)\n\nLangChain releases LangGraph v0.1 and introduces LangGraph CloudLangChain launched a stable release of LangGraph v0.1, a framework for building agentic and multi-agent applications with greater precision and control. The company also announced LangGraph Cloud, a beta infrastructure for deploying LangGraph agents at scale with integrated monitoring and development tools. These releases promise to help developers create more robust AI systems by offering flexible APIs, custom cognitive architectures, and features like human-in-the-loop collaboration and streaming capabilities. (LangChain)\n\nYouTube makes it easier to remove deepfakesYouTube quietly updated its privacy request process to allow individuals to request the removal of AI-generated or synthetic content that simulates their face or voice. The company will evaluate takedown requests based on multiple factors, including disclosure of AI use, uniqueness of identification, public interest value, and whether the content involves public figures or sensitive behavior. This policy change reflects YouTube’s efforts to balance the rise of AI-generated content with privacy concerns, particularly as the platform grapples with potential misuse in election years. (TechCrunch)\n\nSubscribe to Data Points here\n\nStill want to know more about what matters in AI right now?\n\nRead the landmark256th issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng discussed the importance of quality in education and putting learners first:\n\n“We don’t always get it right, but we scrutinize learner feedback (one of my most important weekly routines is to study a dashboard that summarizes learner ratings of our courses) and work to make sure our courses serve learners well. And yes, we have a large-language model powered application that reads learner reviews to flag important issues quickly.”\n\nRead Andrew's full letterhere.\n\nOther top AI news and research stories we covered in depth included:OpenAI to block Chinaand other countries from using its services,Hugging Face revamps its open LLM leaderboard, the world’s largest music companiessue Suno and Udio, and a research team in Japan developedan automated system for model merging.",
    "qa": [
      {
        "question": "ElevenLabs đã đạt được thỏa thuận gì liên quan đến giọng nói của người nổi tiếng đã qua đời?",
        "options": {
          "A": "Mua lại bản quyền tất cả các tác phẩm đã thu âm của họ.",
          "B": "Sử dụng giọng nói của họ để tường thuật sách và bài viết thông qua nhân bản giọng nói.",
          "C": "Tái tạo hình ảnh và giọng nói của họ trong các bộ phim mới.",
          "D": "Phát triển các ứng dụng trò chơi điện tử sử dụng giọng nói của họ."
        },
        "answer": "B"
      },
      {
        "question": "Vì sao Microsoft quyết định không phát hành công khai mô hình nhân bản giọng nói VALL-E 2?",
        "options": {
          "A": "Do chi phí phát triển và duy trì quá cao.",
          "B": "Do lo ngại về các vấn đề đạo đức và khả năng lạm dụng việc giả mạo giọng nói.",
          "C": "Do hiệu suất của mô hình chưa đạt yêu cầu.",
          "D": "Do vướng mắc về bản quyền công nghệ."
        },
        "answer": "B"
      },
      {
        "question": "David Luan, CEO của Adept, sẽ đảm nhận vị trí nào tại Amazon?",
        "options": {
          "A": "Giám đốc điều hành bộ phận điện toán đám mây AWS.",
          "B": "Trưởng nhóm nghiên cứu về trí tuệ nhân tạo tổng quát (AGI) tại Amazon.",
          "C": "Người đứng đầu nhóm 'AGI Autonomy' tại Amazon.",
          "D": "Cố vấn cấp cao cho CEO của Amazon về chiến lược AI."
        },
        "answer": "C"
      },
      {
        "question": "Adam-mini là gì và nó mang lại lợi ích gì cho nghiên cứu AI?",
        "options": {
          "A": "Một ngôn ngữ lập trình mới cho phát triển AI.",
          "B": "Một framework để xây dựng các ứng dụng AI phức tạp.",
          "C": "Một bộ tối ưu hóa máy học giúp giảm mức sử dụng bộ nhớ trong quá trình huấn luyện mô hình.",
          "D": "Một công cụ để đánh giá hiệu suất của các mô hình AI."
        },
        "answer": "C"
      },
      {
        "question": "LangGraph v0.1 được thiết kế để làm gì?",
        "options": {
          "A": "Tạo ra các mô hình ngôn ngữ lớn (LLM) hiệu quả hơn.",
          "B": "Xây dựng các ứng dụng dựa trên tác nhân (agentic) và đa tác nhân (multi-agent) với độ chính xác và khả năng kiểm soát cao hơn.",
          "C": "Phân tích dữ liệu đồ thị phức tạp.",
          "D": "Tự động hóa quy trình phát triển phần mềm."
        },
        "answer": "B"
      },
      {
        "question": "YouTube đã thay đổi chính sách của mình như thế nào liên quan đến deepfakes?",
        "options": {
          "A": "Cấm hoàn toàn việc đăng tải nội dung deepfakes.",
          "B": "Cho phép người dùng yêu cầu gỡ bỏ nội dung AI tạo ra mô phỏng khuôn mặt hoặc giọng nói của họ.",
          "C": "Yêu cầu tất cả nội dung deepfakes phải được gắn nhãn rõ ràng.",
          "D": "Hợp tác với các công ty AI để phát hiện và loại bỏ deepfakes."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, điều gì quan trọng nhất trong giáo dục?",
        "options": {
          "A": "Sử dụng công nghệ AI tiên tiến nhất.",
          "B": "Tập trung vào chất lượng và đặt người học lên hàng đầu.",
          "C": "Xây dựng các khóa học có nội dung chuyên sâu và phức tạp.",
          "D": "Thu hút những giảng viên nổi tiếng nhất."
        },
        "answer": "B"
      },
      {
        "question": "OpenAI đã thực hiện hành động gì liên quan đến việc sử dụng dịch vụ của mình ở Trung Quốc?",
        "options": {
          "A": "Mở rộng dịch vụ của mình sang thị trường Trung Quốc.",
          "B": "Hợp tác với các công ty Trung Quốc để phát triển AI.",
          "C": "Chặn Trung Quốc và các quốc gia khác sử dụng dịch vụ của mình.",
          "D": "Yêu cầu người dùng Trung Quốc phải đăng ký tài khoản đặc biệt."
        },
        "answer": "C"
      },
      {
        "question": "Hugging Face đã làm gì với bảng xếp hạng LLM mở của mình?",
        "options": {
          "A": "Đóng cửa bảng xếp hạng này.",
          "B": "Bán bảng xếp hạng này cho một công ty khác.",
          "C": "Cập nhật và cải tiến bảng xếp hạng LLM mở của mình.",
          "D": "Giới hạn quyền truy cập vào bảng xếp hạng này."
        },
        "answer": "C"
      },
      {
        "question": "Các công ty âm nhạc lớn nhất thế giới đã kiện công ty AI nào?",
        "options": {
          "A": "Google.",
          "B": "Microsoft.",
          "C": "Suno và Udio.",
          "D": "Meta."
        },
        "answer": "C"
      }
    ]
  },
  "cobots-proxie-robot-tackles-warehouse-tasks": {
    "title": "Cobot’s Proxie robot tackles warehouse tasks",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nProxie, a new warehouse robot developed by Amazon alumni\n\nCollaborative Robotics (aka Cobot), led by former Amazon executive Brad Porter, unveiled Proxie, a mobile robot designed to assist with cart-moving tasks in various facilities. The two-armed, four-wheeled robot is currently being tested by Maersk and Mayo Clinic, with other companies exploring its potential use. Cobot aims to develop increasingly capable robots that can work alongside humans, leveraging advancements in AI for more sophisticated manipulation and communication. (Cobot)\n\nNew benchmarks aim to standardize evals for video generation\n\nResearchers developed VBench++, a series of tests that evaluate video generation quality across 16 dimensions, including subject identity consistency and motion smoothness. VBench++ aligns with human perception, provides insights into model strengths and weaknesses, and can evaluate both text-to-video and image-to-video generation. This open-source benchmark aims to drive progress in video generation by offering a standardized way to assess and compare model performance across various technical and trustworthiness aspects. (arXiv)\n\nAmazon invests $4 billion in Anthropic, deepening partnership\n\nAmazon invested an additional $4 billion in Anthropic, bringing its total investment to $8 billion and making AWS Anthropic’s primary cloud and training partner. Anthropic will collaborate closely with AWS on developing Trainium accelerators, optimizing machine learning hardware, and advancing the chips’ training capabilities. This partnership will also give AWS customers early access to fine-tuning Anthropic’s models with their own data. Anthropic gains access to funding to continue its research and development, and Amazon has the opportunity to show its chips can rival Nvidia’s for high-end training and inference. (AmazonandAnthropic)\n\nNew software development tool integrates copilots and agents\n\nCodeium launched a new integrated development environment (IDE) called Windsurf, featuring an AI system called Cascade. Windsurf combines collaborative and independent AI capabilities, aiming to improve upon software developers’ use of copilot and agent technologies. Cascade integrates codebase analysis, advanced code search tools, and human action tracking to facilitate AI-human collaboration during the coding process. The company claims their system offers better performance and integration compared to similar tools, particularly when working with existing codebases. (Codeium)\n\nMistral AI unveils powerful multimodal model and enhanced platform\n\nMistral AI announced Pixtral Large, a 124-billion-parameter text and image model that outperforms leading competitors on benchmarks like MathVista, DocVQA, and VQAv2. The company integrated Pixtral Large into its Le Chat platform, which now offers features such as real-time coding, PDF analysis, image generation, web search, and the ability to create task-specific agents. These updates establish Mistral AI as a noteworthy player in the multimodal AI market, showcasing competitive capabilities in visual understanding and mathematical reasoning tasks compared to established models like GPT-4 and Gemini. (Mistral)\n\nH unveils Runner H, its first AI product for business automation\n\nH, a Paris startup founded by Google alumni, announced Runner H, an agentic AI for business tasks like quality assurance and process automation. The product is built on H’s proprietary 2 billion parameter language model and will be available through APIs, with initial free access and a paid model later. This launch marks H’s first product release after a tumultuous period following its $220 million seed round and the departure of three co-founders. (H Company)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng explored an emerging trend of writing text to be read specifically by AI models, discussing how it parallels SEO and how incentives might drive authors to create content tailored for LLM consumption.\n\n“The need to write text separately for LLMs and humans might diminish if LLMs catch up with humans in their ability to understand complex websites. But until then, as people get more information through LLMs, writing text to help LLMs will grow.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Next-gen models show limited gainsas AI giants rethink their training strategies amidst the breakdown of scaling laws;AI creates an interactive Minecraft-like worldin real time, eliminating the need for a game engine;TSMC halts advanced chip production for Chinese companiesfollowing new U.S. orders, escalating chip restrictions; andresearchers achieve a 20 percent reduction in transformer training costswith minimal performance loss, paving the way for more efficient AI development.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Robot Proxie do Collaborative Robotics phát triển được thiết kế để làm gì?",
        "options": {
          "A": "Thay thế hoàn toàn công nhân trong nhà kho.",
          "B": "Hỗ trợ di chuyển xe đẩy hàng trong các cơ sở khác nhau.",
          "C": "Tự động hóa quy trình sản xuất phức tạp.",
          "D": "Kiểm tra chất lượng sản phẩm trước khi xuất xưởng."
        },
        "answer": "B"
      },
      {
        "question": "VBench++ là một bộ công cụ đánh giá chất lượng của loại mô hình AI nào?",
        "options": {
          "A": "Mô hình ngôn ngữ lớn (LLM).",
          "B": "Mô hình tạo sinh ảnh.",
          "C": "Mô hình tạo sinh video.",
          "D": "Mô hình nhận dạng giọng nói."
        },
        "answer": "C"
      },
      {
        "question": "Amazon đã đầu tư tổng cộng bao nhiêu tiền vào Anthropic?",
        "options": {
          "A": "2 tỷ đô la.",
          "B": "4 tỷ đô la.",
          "C": "6 tỷ đô la.",
          "D": "8 tỷ đô la."
        },
        "answer": "D"
      },
      {
        "question": "Công cụ Windsurf của Codeium tích hợp những khả năng AI nào?",
        "options": {
          "A": "Phân tích dữ liệu tài chính và dự báo thị trường.",
          "B": "Phân tích mã nguồn, tìm kiếm mã nâng cao và theo dõi hành động của người dùng.",
          "C": "Tự động dịch mã giữa các ngôn ngữ lập trình khác nhau.",
          "D": "Tạo tài liệu kỹ thuật tự động cho dự án phần mềm."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Pixtral Large của Mistral AI có bao nhiêu tham số?",
        "options": {
          "A": "2 tỷ tham số.",
          "B": "124 tỷ tham số.",
          "C": "175 tỷ tham số.",
          "D": "540 tỷ tham số."
        },
        "answer": "B"
      },
      {
        "question": "Runner H, sản phẩm AI đầu tiên của H Company, được thiết kế cho mục đích gì?",
        "options": {
          "A": "Phát triển trò chơi điện tử.",
          "B": "Tự động hóa các tác vụ kinh doanh.",
          "C": "Nghiên cứu y học và chẩn đoán bệnh.",
          "D": "Phân tích dữ liệu mạng xã hội."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, xu hướng viết văn bản cho AI có điểm tương đồng với lĩnh vực nào?",
        "options": {
          "A": "Marketing truyền thống.",
          "B": "Tối ưu hóa công cụ tìm kiếm (SEO).",
          "C": "Nghiên cứu tâm lý học.",
          "D": "Thiết kế giao diện người dùng (UI)."
        },
        "answer": "B"
      },
      {
        "question": "TSMC đã làm gì liên quan đến sản xuất chip cho các công ty Trung Quốc?",
        "options": {
          "A": "Tăng cường hợp tác để mở rộng sản xuất.",
          "B": "Tạm dừng sản xuất chip tiên tiến theo yêu cầu của Mỹ.",
          "C": "Chuyển giao công nghệ sản xuất chip cho Trung Quốc.",
          "D": "Giảm giá chip để cạnh tranh trên thị trường."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu gần đây đã đạt được mức giảm bao nhiêu phần trăm chi phí đào tạo transformer?",
        "options": {
          "A": "5 phần trăm.",
          "B": "10 phần trăm.",
          "C": "20 phần trăm.",
          "D": "30 phần trăm."
        },
        "answer": "C"
      },
      {
        "question": "Anthropic sẽ hợp tác chặt chẽ với AWS trong việc phát triển loại chip nào?",
        "options": {
          "A": "GPU GeForce RTX.",
          "B": "CPU Intel Xeon.",
          "C": "Trainium accelerators.",
          "D": "TPU của Google."
        },
        "answer": "C"
      }
    ]
  },
  "data-points-issue-224": {
    "title": "Job Cuts at Alexa and Microsoft's AI Accelerators",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeaturedOpenAI's leadership turmoil, the AI-filled Argentinian elections, a cloud-computing company that will offer GPUs at competitive prices, and new research that aims to accelerate the transformer architecture. But first:\n\nCambridge Dictionary declares AI-induced 'Hallucinate' Word of the Year 2023The Cambridge Dictionary expanded the definition of the word to include the false information produced by large language models. The acknowledgment of AI 'hallucinations' underscores the evolving vocabulary surrounding the capabilities of language models. (University of Cambridge)\n\n'Make It Real' prototype transforms drawings into functional softwareTldraw, a collaborative digital whiteboard, launched a prototype of a feature that allows users to turn vector drawings into functional software. A live demo of the GPT-4V powered tool isavailableto the public. (Ars Technica)\n\nResearch:Text-to-image AI models vulnerable to 'SneakyPrompt' jailbreaking are generating disturbing contentProminent text-to-image AI models, including Stabile Diffusion and DALL-E 2, face a significant security breach. Security researchers revealed the \"SneakyPrompt\" method, which uses reinforcement learning. SneakyPrompt enables the generation of seemingly nonsensical prompts that AI models learn to recognize as hidden requests for inappropriate images. Stability AI and OpenAI are already collaborating with the researchers to strengthen defenses against such attacks. (MIT Technology Review)Amazon announces job cuts in Alexa division, shifting focus to generative AIDaniel Rausch, the Vice President of Alexa and Fire TV, stated in an internal memo that the shifts are intended to maximize resources for generative AI. The company recently previewed a generative AI-based Alexa feature called \"Let’s Chat,\" emphasizing longer and more context-aware conversations with the voice assistant. (Geek Wire)\n\nGoogle launches Project Open Se Cura, an open source framework for secure and efficient AIThe framework emphasizes co-design and development, focusing on security, transparency, and scalability. Google released the code base, including design tools and IP libraries, to foster open development and transparency in AI system design. (Google Open Source)\n\nGoogle-backed AI research lab, Kyutai, aims for open science with $330 million budgetFrench billionaire Xavier Niel unveiled details about Kyutai, a newly established AI research lab in Paris with plans to release not only open source models but also training source code and data. French President Emmanuel Macron supports the initiative, emphasizing the need to regulate AI use cases rather than model makers. (TechCrunch)\n\nGPT-4 outperforms humans on lawyer ethics examThe model surpassed the average scores of human test-takers on the Multistate Professional Responsibility Exam (MPRE), a legal ethics test required by almost every U.S. state for practicing law. GPT-4 achieved a 74% accuracy rate on the simulated exam, outperforming the estimated 68% average among humans. The study, conducted by LegalOn Technologies, suggests that AI could play a role in assisting lawyers with ethical compliance in the future. (Reuters)\n\nGoogle DeepMind and YouTube present Lyria, an advanced AI music generation modelLyria, designed to generate high-quality music with instrumentals and vocals, aims to address the challenges of maintaining musical continuity across various elements like beats, individual notes, and vocal harmonies. The announcement includes two AI experiments: \"Dream Track,\" an experiment within YouTube Shorts allowing creators to connect with fans through AI-generated soundtracks featuring global artists; and \"Music AI Tools,\" a set of tools developed with artists, songwriters, and producers to enhance their creative processes. (Google DeepMind)\n\nMicrosoft introduces custom-designed chips for AzureThe Azure Maia AI Accelerator for AI tasks and generative AI, and the Azure Cobalt CPU, an Arm-based processor optimized for general-purpose compute workloads, will be integrated into custom server boards and racks. The chips will be working in tandem with software to maximize performance, flexibility, and efficiency. (Microsoft)\n\nMicrosoft and Google collaborate on OneTable project to address data lake challengesThe open source project seeks to create a layer on top of existing data lake table formats like Apache Iceberg, Apache Hudi, and Delta Lake, enabling seamless conversions and access across these formats. The project promotes interoperability, preventing vendor lock-in and facilitating compatibility for data analytics and AI workloads. (VentureBeat)\n\nMicrosoft teams up with Be My Eyes to offer GPT-4-powered support for visually impaired usersThe tool enables visually impaired users to independently resolve technical issues and perform tasks without human agent assistance. During tests, only 10 percent of users opted to speak with a human representative after interacting with the AI tool. (The Verge)\n\nOpenAI temporarily halts new ChatGPT Plus subscriptions and upgradesOverwhelming demand led to capacity challenges, prompting a decision to pause access to ensure a high-quality experience for existing users. The move follows a series of outages related to high demand and DDoS attacks on OpenAI services, impacting ChatGPT and the API. (Search Engine Journal)\n\nCommon Sense Media flags generative AI models unsafe for kidsThe organization introduced \"nutrition labels\" for AI products, evaluating them based on principles such as trust, safety, privacy, transparency, accountability, learning, fairness, social connections, and benefits to society. The generative AI category received lower ratings due to biases and concerns related to objectification and sexualization. (TechCrunch)",
    "qa": [
      {
        "question": "Từ điển Cambridge đã chọn từ nào liên quan đến AI là 'Từ của năm 2023'?",
        "options": {
          "A": "Generative AI",
          "B": "Hallucinate",
          "C": "Transformer",
          "D": "Open Source"
        },
        "answer": "B"
      },
      {
        "question": "Công cụ 'Make It Real' của Tldraw cho phép người dùng làm gì?",
        "options": {
          "A": "Tạo ra hình ảnh từ văn bản.",
          "B": "Biến bản vẽ vector thành phần mềm chức năng.",
          "C": "Phát hiện và sửa lỗi trong mã nguồn.",
          "D": "Tự động tạo ra các bản trình bày slide."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp 'SneakyPrompt' lợi dụng lỗ hổng bảo mật nào trong các mô hình AI tạo ảnh?",
        "options": {
          "A": "Khả năng tạo ra các hình ảnh có độ phân giải cực cao.",
          "B": "Khả năng hiểu và thực hiện các yêu cầu ẩn thông qua các prompt vô nghĩa.",
          "C": "Khả năng tự động loại bỏ các hình ảnh vi phạm bản quyền.",
          "D": "Khả năng tạo ra các hình ảnh 3D từ văn bản."
        },
        "answer": "B"
      },
      {
        "question": "Amazon đang thực hiện thay đổi gì trong bộ phận Alexa để tập trung vào AI tạo sinh?",
        "options": {
          "A": "Tăng cường tuyển dụng kỹ sư AI.",
          "B": "Cắt giảm nhân sự và tái phân bổ nguồn lực cho AI tạo sinh.",
          "C": "Hợp tác với các công ty AI khác.",
          "D": "Phát triển phần cứng mới cho Alexa."
        },
        "answer": "B"
      },
      {
        "question": "Project Open Se Cura của Google tập trung vào điều gì trong phát triển AI?",
        "options": {
          "A": "Tăng tốc độ xử lý của các mô hình AI.",
          "B": "Bảo mật, minh bạch và khả năng mở rộng của AI.",
          "C": "Giảm chi phí đào tạo mô hình AI.",
          "D": "Cải thiện khả năng hiểu ngôn ngữ tự nhiên của AI."
        },
        "answer": "B"
      },
      {
        "question": "Phòng nghiên cứu AI Kyutai được hỗ trợ bởi Google có kế hoạch gì liên quan đến mã nguồn và dữ liệu?",
        "options": {
          "A": "Giữ bí mật mã nguồn và dữ liệu để duy trì lợi thế cạnh tranh.",
          "B": "Phát hành mã nguồn, dữ liệu huấn luyện và mô hình nguồn mở.",
          "C": "Chỉ chia sẻ mã nguồn với các đối tác nghiên cứu.",
          "D": "Bán dữ liệu huấn luyện cho các công ty khác."
        },
        "answer": "B"
      },
      {
        "question": "GPT-4 đã thể hiện như thế nào trong kỳ thi đạo đức luật sư (MPRE)?",
        "options": {
          "A": "Đạt điểm thấp hơn so với điểm trung bình của con người.",
          "B": "Đạt điểm cao hơn so với điểm trung bình của con người.",
          "C": "Đạt điểm tương đương với điểm trung bình của con người.",
          "D": "Không đủ điều kiện tham gia kỳ thi."
        },
        "answer": "B"
      },
      {
        "question": "Lyria của Google DeepMind và YouTube là gì?",
        "options": {
          "A": "Một công cụ dịch ngôn ngữ thời gian thực.",
          "B": "Một mô hình AI tạo nhạc chất lượng cao.",
          "C": "Một hệ thống nhận diện khuôn mặt tiên tiến.",
          "D": "Một nền tảng thương mại điện tử dựa trên AI."
        },
        "answer": "B"
      },
      {
        "question": "Microsoft giới thiệu chip Azure Maia AI Accelerator để làm gì?",
        "options": {
          "A": "Tăng tốc độ xử lý đồ họa.",
          "B": "Tối ưu hóa cho các tác vụ AI và AI tạo sinh.",
          "C": "Cải thiện hiệu suất pin cho thiết bị di động.",
          "D": "Hỗ trợ các ứng dụng thực tế ảo."
        },
        "answer": "B"
      },
      {
        "question": "Dự án OneTable mà Microsoft và Google hợp tác giải quyết vấn đề gì?",
        "options": {
          "A": "Tăng cường bảo mật cho dữ liệu trên đám mây.",
          "B": "Cải thiện khả năng tương tác giữa các định dạng bảng dữ liệu khác nhau.",
          "C": "Giảm chi phí lưu trữ dữ liệu.",
          "D": "Tăng tốc độ truy cập dữ liệu."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-226": {
    "title": "The latest in AI from November 30 to December 6, 2023",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeaturedAmazon's new AI-powered assistant, biases in pedestrian detection models, regulations in the insurance industry’s use of AI, and a robot that helps you find your personal objects. But first:\n\nMicrosoft announces £2.5 billion investment to boost the UK’s AI capabilitiesThe investment aims to double Microsoft’s UK datacenter footprint by 2026, train or retrain over one million people for the AI economy, and extend Microsoft’s Accelerating Foundation Models Research (AFMR) program to prioritize GPU access for the UK’s research community. (Read more atMicrosoft)\n\nResearchfinds opportunities and risks as heritage organizations embrace AIA new study focuses on what innovation in AI looks like in the UK heritage sector, and showcases its diverse uses in museums, galleries, libraries, and archives. Notable examples include predictive analytics for exhibition popularity at the National Gallery. However, the study also highlighted risks such as discrimination, misinformation, copyright infringement, and transparency issues. (Read more atMuseum Association)\n\nU.S. mandates Saudi venture capital firm must sell stake in Silicon Valley AI firmThe Biden administration has instructed Prosperity7 to sell its shares in Rain AI, a Silicon Valley AI chip startup backed by OpenAI co-founder Sam Altman. Rain AI, which designs AI chips inspired by brain functionality, had Prosperity7 as a lead investor in a funding round that raised $25 million in 2022. (Read the news story atBloomberg)\n\nGenerative AI regulation allegedly stalls EU legislation talksSources revealed that negotiations on foundation models have become the primary hurdle, with a risk of shelving the act before European parliamentary elections next year unless an agreement is reached. France, Germany, and Italy form an important bloc of countries opposing foundation models. Pending issues also include establishing a definition of AI and national security exceptions. Critics argue that self-regulation may fall short of safety standards for foundation models, creating legal uncertainty and impeding European industries' planning. (Read the article atReuters)\n\nAI fuels innovations in Pennsylvania's infrastructure projectsIn Pennsylvania, U.S., where 13 percent of bridges face structural deficiencies, engineers are leveraging AI to address challenges like the development of lighter concrete blocks for construction and noise-absorbing walls along highways. The projects aim to create more resilient structures at a reduced cost. The use of AI in civil engineering could revolutionize project development, early damage detection, and real-time incident analysis, but careful consideration and regulations are urged to ensure safety and reliability. (Read the article inThe New York Times)\n\nAnduril's Roadrunner: AI combat drone takes flightAnduril's latest innovation combines AI technology and jet-powered capabilities to counter the escalating threat of low-cost, sophisticated aerial attacks. The modular and autonomous Roadrunner drone aims to provide rapid response and heightened resilience against evolving threats such as suicide drones. (Read more atWired)\n\nGeneral Motors to reduce investment in Cruise self-driving division next yearFollowing recent accidents involving its self-driving taxis in San Francisco, the company, initially planning expansion to multiple cities, now focuses on rebuilding trust with regulators and communities. The decision to reduce spending follows the suspension of Cruise's robotaxi license in California and a need to regain public trust in the wake of safety incidents, including a pedestrian fatality. (Read the article atThe New York Times)\n\nSam Altman returns as OpenAI CEOBesides Altman’s return, Mira Murati reassumed her role as CTO, and Greg Brockman returned as President. For now, the new board comprises former Salesforce CEO Bret Taylor (Chair), economist Larry Summers, and Quora CEO Adam D’Angelo. (Read the blog post atOpenAI)\n\nConsortium of major companies develops data provenance standards to enhance trust in AIMany companies (including American Express, IBM, and Walmart) formed the Data & Trust Alliance, introducing new standards for data provenance in AI applications. These standards cover eight basic criteria, including lineage, source, legal rights, and data type. The goal is to offer clear data documentation and bolster efficiency and trust in AI developments. (Read more atThe New York Times)\n\nAmazon Web Services (AWS) introduces Titan models in Amazon BedrockAmazon’s Titan Image Generator and Titan Multimodal Embeddings offer image, multimodal, and text options through a fully managed API. The Titan Image Generator enables content creators to generate images using natural language prompts, targeting applications in advertising, e-commerce, and media. The Titan Multimodal Embeddings facilitate the creation of contextually relevant multimodal search and recommendation experiences. (Read the blog post atAWS)\n\nVoicemod launches feature to craft and share custom synthetic voicesThe app, known for its AI voice-changing program popular in the gaming and streaming communities, now enables users to craft and share their unique AI voices by modifying their own voices or choosing from various genders, ages, and tones. (Read more atThe Verge)\n\nDemand keeps soaring for prompt engineersPrompt engineering emerged as a lucrative and sought-after skill in the year since the public launch of ChatGPT. Google searches for \"prompt engineering\" have skyrocketed, and LinkedIn reports substantial increases in related terms on member profiles. The skillset, involving coaxing AI systems for better results and training colleagues in using generative AI, is in high demand. Newly-created roles offer significant compensation, often upwards of $335,000 annually. (Read the analysis atBloomberg)\n\nResearch: Deep learning model offers precision in predicting breast cancer outcomesThe Histomic Prognostic Signature (HiPS), which evaluates both cancerous and non-cancerous cell patterns, outperformed expert pathologists in predicting disease progression. By identifying breast cancer patients classified as high or intermediate risk who could become long-term survivors, the tool offers the potential to reduce the duration or intensity of chemotherapy, sparing patients from harmful side effects. (Read the article viaNorthwestern University)\n\nIBM expands geospatial AI collaboration to tackle climate challenges globallyThe initiative involves mapping urban heat islands in the UAE, supporting Kenya's reforestation campaign, and enhancing climate resiliency in the UK's aviation sector. Additionally, IBM is collaborating with NASA to develop a new model for weather and climate, aiming to improve the precision and efficiency of weather forecasting and address climate-related challenges on a global scale. (Read more atIBM)",
    "qa": [
      {
        "question": "Microsoft dự kiến sẽ làm gì để thúc đẩy năng lực AI của Vương quốc Anh?",
        "options": {
          "A": "Xây dựng một trung tâm nghiên cứu AI mới tại Cambridge.",
          "B": "Đầu tư 2,5 tỷ bảng Anh để mở rộng trung tâm dữ liệu, đào tạo nhân lực và ưu tiên truy cập GPU cho nghiên cứu.",
          "C": "Hợp tác với các trường đại học hàng đầu để phát triển chương trình đào tạo AI.",
          "D": "Tổ chức các hội thảo và khóa học trực tuyến về AI cho công dân Anh."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu về việc ứng dụng AI trong lĩnh vực di sản ở Anh chỉ ra rủi ro nào?",
        "options": {
          "A": "Sự phụ thuộc quá mức vào công nghệ, làm giảm vai trò của con người.",
          "B": "Khả năng bị tấn công mạng và mất dữ liệu quan trọng.",
          "C": "Phân biệt đối xử, thông tin sai lệch, vi phạm bản quyền và các vấn đề về tính minh bạch.",
          "D": "Chi phí đầu tư và bảo trì hệ thống AI quá cao."
        },
        "answer": "C"
      },
      {
        "question": "Chính quyền Biden yêu cầu Prosperity7 bán cổ phần trong Rain AI vì lý do gì?",
        "options": {
          "A": "Rain AI vi phạm các quy định về xuất khẩu công nghệ.",
          "B": "Prosperity7 là một công ty có liên hệ với chính phủ Trung Quốc.",
          "C": "Rain AI sử dụng công nghệ AI để phát triển vũ khí.",
          "D": "Prosperity7 là một công ty đầu tư mạo hiểm của Ả Rập Saudi."
        },
        "answer": "D"
      },
      {
        "question": "Vấn đề chính nào đang gây trì hoãn các cuộc đàm phán về luật AI của EU?",
        "options": {
          "A": "Sự bất đồng về việc sử dụng AI trong lĩnh vực quân sự.",
          "B": "Các quy định về bảo vệ dữ liệu cá nhân quá khắt khe.",
          "C": "Các cuộc đàm phán về các mô hình nền tảng (foundation models).",
          "D": "Sự phản đối từ các công ty công nghệ lớn."
        },
        "answer": "C"
      },
      {
        "question": "AI được ứng dụng như thế nào trong các dự án cơ sở hạ tầng ở Pennsylvania?",
        "options": {
          "A": "Tự động hóa việc xây dựng đường xá và cầu cống.",
          "B": "Phát triển các khối bê tông nhẹ hơn và tường hấp thụ tiếng ồn.",
          "C": "Dự đoán lưu lượng giao thông và điều chỉnh đèn tín hiệu.",
          "D": "Giám sát chất lượng không khí và nước trong quá trình xây dựng."
        },
        "answer": "B"
      },
      {
        "question": "Roadrunner của Anduril được thiết kế để đối phó với mối đe dọa nào?",
        "options": {
          "A": "Các cuộc tấn công mạng vào hệ thống phòng thủ.",
          "B": "Các cuộc tấn công từ máy bay chiến đấu hiện đại.",
          "C": "Các cuộc tấn công trên bộ bằng xe tăng và pháo binh.",
          "D": "Các cuộc tấn công trên không giá rẻ và tinh vi, chẳng hạn như máy bay không người lái tự sát."
        },
        "answer": "D"
      },
      {
        "question": "General Motors quyết định giảm đầu tư vào bộ phận xe tự lái Cruise vì lý do gì?",
        "options": {
          "A": "Doanh số bán xe tự lái không đạt kỳ vọng.",
          "B": "Các vụ tai nạn liên quan đến xe tự lái và việc đình chỉ giấy phép robotaxi.",
          "C": "Sự cạnh tranh gay gắt từ các đối thủ khác trong ngành.",
          "D": "Chi phí phát triển công nghệ xe tự lái quá cao."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu của Data & Trust Alliance khi giới thiệu các tiêu chuẩn mới cho nguồn gốc dữ liệu trong AI là gì?",
        "options": {
          "A": "Tăng cường bảo mật dữ liệu và ngăn chặn rò rỉ thông tin.",
          "B": "Cung cấp tài liệu dữ liệu rõ ràng và tăng cường hiệu quả và độ tin cậy trong phát triển AI.",
          "C": "Giảm chi phí lưu trữ và xử lý dữ liệu.",
          "D": "Đảm bảo tuân thủ các quy định về bảo vệ dữ liệu cá nhân."
        },
        "answer": "B"
      },
      {
        "question": "Amazon Titan Image Generator cho phép người dùng làm gì?",
        "options": {
          "A": "Tạo ra các mô hình 3D từ hình ảnh 2D.",
          "B": "Tạo ra hình ảnh bằng cách sử dụng các lời nhắc ngôn ngữ tự nhiên.",
          "C": "Chỉnh sửa và cải thiện chất lượng hình ảnh.",
          "D": "Phân tích và nhận diện các đối tượng trong hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Kỹ năng 'prompt engineering' trở nên quan trọng vì lý do gì?",
        "options": {
          "A": "Giúp giảm chi phí vận hành các hệ thống AI.",
          "B": "Giúp các hệ thống AI đưa ra kết quả tốt hơn và đào tạo người khác sử dụng AI tạo sinh.",
          "C": "Giúp bảo vệ dữ liệu khỏi các cuộc tấn công mạng.",
          "D": "Giúp tuân thủ các quy định về bảo vệ dữ liệu cá nhân."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-225": {
    "title": "The latest in AI from November 23 to November 29, 2023",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeatureddoctors' thoughts on AI  medical devices, Microsoft and Siemens’ Industrial Copilot, all about Giskard, and a language model that speaks robot. But first:\n\nAnthropic introduces Claude 2.1The update brings a 200,000-token context window, and a 2x decrease in hallucinations. The beta tool use feature expands Claude's interoperability by connecting with users' and developers’ existing processes and APIs. (Anthropic)\n\nAmazon Web Services (AWS) and Nvidia expand partnership to offer improved supercomputing infrastructureAWS will become the first cloud provider to offer Nvidia GH200 Grace Hopper Superchips, equipped with multi-node NVLink technology. The collaboration also introduces Project Ceiba, a GPU-powered supercomputer with unprecedented processing capabilities. aiming to deliver state-of-the-art generative AI innovations across diverse industries. (Amazon)\n\nThe controversial rumors around OpenAI's math-solving modelRumors swirl around OpenAI's recent upheaval as reports point to development of a new AI model, Q* (pronounced Q-star). Named for its prowess in solving grade-school math problems, the potential breakthrough has prompted speculation about advancements towards artificial general intelligence (AGI). The episode echoes past AGI hype cycles, raising questions about tech industry self-regulation and potential impact on pending AI legislation. (MIT Technology ReviewandReuters)\n\nAI-powered method unlocks ancient cuneiform tablets' secretsResearchers developed a system that can automatically decipher complex cuneiform texts on ancient tablets using 3D models of them, instead of traditional methods using photos. With an estimated one million cuneiform tablets worldwide, some over 5,000 years old, the method’s potential extends beyond known languages, and offers a glimpse into previously inaccessible historical material. (Science Daily)\n\nStability AI introduces Stable Video DiffusionThe model for generative video builds upon the success of the image model Stable Diffusion. The code is available on GitHub, with model weights accessible on the Hugging Face page. The release, comprising two image-to-video models, shows broad adaptability for downstream tasks, including multi-view synthesis from a single image. (Stability AI)\n\nFederal Trade Commission (FTC) simplifies process to investigate AI companiesThe FTC greenlit the use of compulsory measures for investigations into products and services using or claiming to be produced with AI. The 3-0 vote emphasizes the Commission's proactive approach in addressing emerging issues in technology. Lead FTC staffers Nadine Samter and Ben Halpern-Meekin will oversee the implementation of this resolution in the Northwest Region office. (FTC)\n\nAI enhances power grid efficiency with four key innovationsFueled by a recent $3 billion grant from the US Department of Energy, the power grid industry is embracing AI. Key applications include a model for faster grid planning, new software tailoring energy usage, programs managing electric vehicle demand, and AI predicting grid failures due to extreme weather. (MIT Technology Review)\n\nAmazon announces Q, an AI assistant designed for work environmentsTailored to individual businesses, Amazon Q offers quick, relevant answers, content generation, and problem-solving capabilities informed by company data. Prioritizing security and privacy, Amazon Q personalizes interactions based on existing identities and permissions. Companies including Accenture, BMW, and Gilead are among the early adopters. (Amazon)\n\nSports Illustrated exposed for using AI-generated content and authorsThe magazine faces scrutiny after allegations surfaced that it published articles attributed to AI-generated authors with fabricated biographies and headshots. Following inquiries, Sports Illustrated removed the content without a clear explanation. The Arena Group, the magazine's publisher, later attributed the content to an external company, AdVon Commerce, claiming it was human-generated. (Futurism)\n\nGlobal coalition introduced a non-binding pact to ensure AI safetyThe international agreement, signed by 18 countries, including the U.S., emphasizes the need for AI systems to be \"secure by design.\" The 20-page document encourages companies to prioritize safety measures during the development and deployment of AI. (The Guardian)\n\nResearch:Deepmind’s GNoME discovers 2.2 million new crystals using deep learningGoogle’s AI research lab used a tool called Graph Networks for Materials Exploration (GNoME), to identify 2.2 million new crystals, including 380,000 stable materials with promising applications in technology. The predicted stable materials will be contributed to the Materials Project database, fostering collaborative research. (Google Deepmind)\n\nNations grapple with ethical dilemmas as AI-controlled killer drones inch closer to realityThe emergence of autonomous killer drones prompts international debate over legal constraints, with the U.S., China, and major powers hesitant to endorse binding rules. Concerns about handing life-and-death decisions to AI-controlled drones have led some countries to advocate for legally binding regulations at the United Nations, but disagreements among key players have stalled progress.\n\nEuropean Central Bank research finds that AI currently boosts jobs but threatens wagesThe study focused on 16 European countries, indicating an increased employment share in AI-exposed sectors. Notably, low and medium-skill jobs remained largely unaffected, while highly-skilled positions experienced the most significant growth. However, the research acknowledged potential \"neutral to slightly negative impacts\" on earnings, with concerns about future developments in AI technologies and their broader implications for employment and wage dynamics. (Reuters)\n\nAI-generated speaker scandal prompts Microsoft and Amazon executives to withdraw from conferenceTop executives from Microsoft and Amazon withdrew from the DevTernity software conference following revelations that at least one featured female speaker was artificially generated. The disclosure prompted other scheduled speakers to abandon the virtual conference. Microsoft's Scott Hanselman expressed disappointment, emphasizing the importance of diverse and genuine representation at tech conferences. (AP News)\n\nResearch:Researchers uncover vulnerability in ChatGPT, expose training data extraction potentialThe research team successfully extracted several megabytes of ChatGPT's training data by employing a simple attack method. The findings raise concerns about the model's memorization of sensitive information and challenge the adequacy of current testing methodologies. (GitHub)\n\nOpenAI not expected to give Microsoft or other investors voting seats on new nine-member boardA source told The Information that despite revamping its slate of directors, OpenAI’s new board is unlikely to change its nonprofit status, and will maintain rules barring directors from having a major financial interest in the company. (The Information)",
    "qa": [
      {
        "question": "Claude 2.1 của Anthropic có gì mới so với phiên bản trước?",
        "options": {
          "A": "Giảm 50% khả năng tạo ra thông tin sai lệch và tăng gấp đôi tốc độ xử lý.",
          "B": "Tăng gấp đôi kích thước cửa sổ ngữ cảnh lên 200,000 token và giảm một nửa khả năng tạo ra thông tin sai lệch.",
          "C": "Tích hợp thêm khả năng tạo video từ văn bản và tăng cường khả năng hiểu ngôn ngữ tự nhiên.",
          "D": "Hỗ trợ nhiều ngôn ngữ lập trình hơn và cải thiện khả năng tương tác với các thiết bị phần cứng."
        },
        "answer": "B"
      },
      {
        "question": "Dự án Ceiba của AWS và Nvidia hướng đến mục tiêu gì?",
        "options": {
          "A": "Cung cấp dịch vụ lưu trữ đám mây giá rẻ cho các doanh nghiệp vừa và nhỏ.",
          "B": "Phát triển một siêu máy tính sử dụng GPU với khả năng xử lý chưa từng có để thúc đẩy các đổi mới AI tạo sinh.",
          "C": "Xây dựng một mạng lưới các trung tâm dữ liệu xanh sử dụng năng lượng tái tạo.",
          "D": "Tạo ra một nền tảng phát triển ứng dụng AI dễ sử dụng cho người mới bắt đầu."
        },
        "answer": "B"
      },
      {
        "question": "Tin đồn về mô hình Q* của OpenAI liên quan đến vấn đề gì?",
        "options": {
          "A": "Khả năng tạo ra các tác phẩm nghệ thuật độc đáo và sáng tạo.",
          "B": "Khả năng giải các bài toán số học ở cấp tiểu học, làm dấy lên suy đoán về tiến bộ hướng tới trí tuệ nhân tạo tổng quát (AGI).",
          "C": "Khả năng dự đoán chính xác các biến động của thị trường chứng khoán.",
          "D": "Khả năng viết mã chương trình một cách tự động và hiệu quả."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp mới sử dụng AI để giải mã các văn bản hình nêm cổ đại dựa trên điều gì?",
        "options": {
          "A": "Phân tích các bức ảnh chụp các phiến đất sét cổ.",
          "B": "Sử dụng mô hình 3D của các phiến đất sét thay vì các phương pháp truyền thống sử dụng ảnh.",
          "C": "So sánh các văn bản hình nêm với các ngôn ngữ hiện đại.",
          "D": "Ứng dụng công nghệ nhận dạng giọng nói để phiên dịch các văn bản cổ."
        },
        "answer": "B"
      },
      {
        "question": "Stable Video Diffusion của Stability AI có đặc điểm nổi bật nào?",
        "options": {
          "A": "Chỉ có thể tạo video từ văn bản.",
          "B": "Là một mô hình tạo video dựa trên thành công của mô hình tạo ảnh Stable Diffusion và có khả năng thích ứng rộng rãi cho các tác vụ khác nhau.",
          "C": "Yêu cầu phần cứng mạnh mẽ để chạy.",
          "D": "Chỉ hỗ trợ tạo video ngắn dưới 5 giây."
        },
        "answer": "B"
      },
      {
        "question": "FTC (Ủy ban Thương mại Liên bang) có động thái gì liên quan đến các công ty AI?",
        "options": {
          "A": "Cấm hoàn toàn việc sử dụng AI trong các sản phẩm và dịch vụ.",
          "B": "Đơn giản hóa quy trình điều tra các sản phẩm và dịch vụ sử dụng hoặc tuyên bố được tạo ra bằng AI.",
          "C": "Tăng cường hỗ trợ tài chính cho các công ty khởi nghiệp AI.",
          "D": "Yêu cầu tất cả các công ty AI phải công khai mã nguồn của họ."
        },
        "answer": "B"
      },
      {
        "question": "Theo MIT Technology Review, AI được ứng dụng vào lưới điện như thế nào?",
        "options": {
          "A": "Chỉ được sử dụng để quản lý việc sử dụng năng lượng trong các hộ gia đình.",
          "B": "Chỉ được sử dụng để dự đoán thời tiết khắc nghiệt.",
          "C": "Được sử dụng để lập kế hoạch lưới điện nhanh hơn, điều chỉnh việc sử dụng năng lượng, quản lý nhu cầu xe điện và dự đoán sự cố lưới điện do thời tiết khắc nghiệt.",
          "D": "Chỉ được sử dụng để phát hiện các cuộc tấn công mạng vào lưới điện."
        },
        "answer": "C"
      },
      {
        "question": "Amazon Q là gì và nó được thiết kế cho mục đích gì?",
        "options": {
          "A": "Một robot giao hàng tự động của Amazon.",
          "B": "Một trợ lý AI được thiết kế cho môi trường làm việc, cung cấp câu trả lời nhanh chóng, tạo nội dung và giải quyết vấn đề dựa trên dữ liệu công ty.",
          "C": "Một nền tảng thương mại điện tử mới của Amazon.",
          "D": "Một dịch vụ lưu trữ đám mây dành cho các doanh nghiệp lớn."
        },
        "answer": "B"
      },
      {
        "question": "Vụ việc Sports Illustrated bị cáo buộc sử dụng nội dung do AI tạo ra liên quan đến vấn đề gì?",
        "options": {
          "A": "Vi phạm bản quyền hình ảnh.",
          "B": "Sử dụng các tác giả do AI tạo ra với tiểu sử và ảnh đại diện bịa đặt.",
          "C": "Đăng tải thông tin sai lệch về các vận động viên.",
          "D": "Quảng cáo sai sự thật về các sản phẩm thể thao."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu của Ngân hàng Trung ương Châu Âu (ECB) về tác động của AI đến thị trường lao động cho thấy điều gì?",
        "options": {
          "A": "AI làm giảm đáng kể số lượng việc làm trong tất cả các lĩnh vực.",
          "B": "AI hiện tại thúc đẩy việc làm nhưng đe dọa tiền lương, đặc biệt là đối với lao động có kỹ năng thấp.",
          "C": "AI chỉ ảnh hưởng đến các công việc lặp đi lặp lại và không ảnh hưởng đến các công việc đòi hỏi sáng tạo.",
          "D": "AI làm tăng cả số lượng việc làm và mức lương trong tất cả các lĩnh vực."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-227": {
    "title": "The latest in AI from December 7 to December 13, 2023",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeaturedeverything you need to know about Google's Gemini, updates on the EU's AI Act, the AI Alliance led by Meta and IBM, and a novel twist on self-supervised learning. But first:\n\nMeta launches text-to-image generator \"Imagine with Meta AI\"Trained on 1.1 billion Facebook and Instagram images, the new portal for Meta’s Emu image-synthesis model transforms text prompts into 1280×1280 pixel images. Meta claims to use only publicly available photos for training, emphasizing that private photos will not be included, but privacy concerns remain. (Read more atArs Technica)\n\nAI-fueled browsers offering generative search firstDevelopers at smaller companies are redefining the internet experience by incorporating AI into web browsers. In many of the new browsers, Generative AI replaces Google as the default search experience, with companies like The Browser Company (maker of Arc), SigmaOS, and Opera leading the way. (Read the full article atWired)\n\nResearch:Microsoft introduces Orca 2Building on the success of the original Orca model, the 13B-parameter Orca 2 outperforms models of similar size and matches or surpasses those 5-10 times larger on tasks testing advanced reasoning in zero-shot settings. The key innovation is in employing diverse reasoning techniques and task-specific solution strategies, demonstrating that smaller models can achieve substantial reasoning prowess when trained with improved signals and methods. (SeeMicrosoft’s blog)\n\nFarmerline, the sustainable agriculture company using AI for goodFarmerline's Mergdata traceability tool aims to transform sustainable farming practices, demonstrating capabilities in supply-chain tracking, geolocation as well as enabling digital payments.  Over a decade, Farmerline’s tools have successfully monitored 500,000 farm plots, making a significant impact on 9.4 million acres and reducing emissions in protected areas across five countries. (Watch an interview with Farmerline’s CEO atBloombergand readFarmerline’s blog)\n\nDrones and AI could accelerate landmine detection in UkraineNew drones are now equipped with machine learning algorithms trained on visual characteristics of various explosives. The algorithm processes collected images, creating detailed maps with an explosive detection rate of approximately 90 percent. While not replacing traditional methods, this approach significantly enhances efficiency, covering more ground in less time. The technology aims to address Ukraine's extensive landmine-ridden areas, potentially reducing the demining timeline from a projected 750 years. (Read the article atScientific American)\n\nU.S. Border Patrol utilizes AI to combat fentanyl traffickingTraditional methods, including drug-sniffing dogs, face challenges due to the minuscule and easily concealable nature of finished fentanyl. With AI, agents gain deeper insights into fentanyl supply chains, leading to more substantial seizures of both finished products and production-related chemicals. Altana, a startup specializing in global supply chain platforms, supports CBP by mapping the assembly and shipping of fentanyl ingredients, aiding in disrupting the entire process. (Read more atAxios)\n\nMeta, Microsoft, and OpenAI to turn to AMD's AI chip as Nvidia alternativeThe three tech giants announced their intention to use AMD's new Instinct MI300X chip, signaling a growing demand for alternatives to Nvidia's scarce and pricey chips. The move could potentially lead to cost reductions in developing AI models and create competition for Nvidia. AMD's MI300X, set to ship early next year, boasts 192GB of high-performance HBM3 memory and a new architecture, positioning it as a strong contender in the AI chip market. (Read the article atCNBC)\n\nAI laser reads heartbeats at a distance, replacing the stethoscopeResearchers at Glasgow University developed a laser camera leveraging AI and quantum technologies to remotely read a person's heartbeat. The system involves high-speed cameras that record skin movements as a laser beam is directed onto the throat, and captures subtle fluctuations in the main artery. The application extends to detecting cardiovascular irregularities, potentially offering warnings for strokes or cardiac arrests. (Read more atThe Guardian)\n\nSag-Aftra union ratifies deal, signaling end to Hollywood strikeThe agreement includes protections related to the use of AI, pay increases for actors, and streaming-based bonuses. The deal garnered approval from 78% of the union's 160,000 members. (Read the news story atThe Guardian)\n\nApple takes a major step in open source AIIn a significant move, Apple quietly open-sourced multiple AI tools, including MLX, a library for large-scale deep learning models designed for Apple Silicon. Released under an MIT license, MLX boasts a unified memory model, allowing operations on arrays without moving data. Accompanied by a Python API closely resembling NumPy, MLX aims to be user-friendly while efficiently training and deploying models. The release is seen as Apple embracing open source AI, with potential implications for the future integration of AI-centric features in Apple operating systems. (Read more atThe Stack)\n\nAI-induced reproducibility crisis sparks concerns across scientific disciplinesResearchers highlight issues ranging from data leakage in training AI systems to insufficient separation between training and test datasets, causing biases and unreliable outcomes. Scientists argue that cultural shifts in reporting standards, transparency, and a reevaluation of publishing incentives are essential to address the challenges posed by AI in various scientific fields. (Read the report atNature)\n\nSurvey reveals discrepancy between corporate AI hype and actual adoptionWhile major companies, including those in the S&P 500, extensively discuss AI in their earnings calls, a recent survey shows that only 4.4 percent of businesses nationwide have reported using AI to produce goods or services. The study suggests that the current technological adoption landscape could contribute to an emerging \"AI divide\" between organizations  and cities that can effectively leverage AI tools and those that cannot. (Read more atNBC News)\n\nMeta unveils Purple Llama project for AI safetyThe project, which builds on the success of Meta’s open source Llama models, focuses on trust and safety in open generative AI models. Initial features include cybersecurity tools for large language models (LLMs), addressing issues like insecure code suggestions, and the release of Llama Guard, a freely available foundational model to enable detection of potential types of risky or violating content. (ReadMeta’s blog)\n\nResearch:AI decodes cat pain to enhance veterinary careA team of AI researchers and veterinarians developed machine learning algorithms to assess whether cats are in pain based on their facial expressions. These algorithms, tested in a veterinary hospital, demonstrated up to 77% accuracy in identifying pain in feline patients. The researchers plan to build a mobile app for both veterinarians and cat owners to use for automatic pain detection. (Read the article atScientific American)\n\nGlobal struggle to regulate AIAs concerns over AI’s impact on jobs, its use to facilitate disinformation, and potential development of humanlike intelligence rise, nations are grappling to regulate AI effectively. The rapid and unpredictable advancement of AI has created a mismatch with the ability of lawmakers and regulators to keep pace. (Read the report atThe New York Times)\n\nUAE's G42 AI group to stop use of Chinese hardware for U.S. suppliersG42, a prominent AI company based in the United Arab Emirates (UAE), is severing ties with Chinese hardware suppliers and transitioning to U.S. counterparts. The decision comes amid growing geopolitical tensions and scrutiny of G42’s ties with Chinese entities, such as Huawei. The UAE company is adjusting its relationships to comply with Washington's regulations on exports of advanced chips, showcasing the impact of political conflicts on the AI industry. (Read more atFinancial Times)\n\nOpenAI board member Helen Toner discusses tensions around Sam Altman’s removal and returnIn an interview, Toner addresses the complexities of the situation, including the threat of violating fiduciary duties, the unexpected fallout from employees, and the clash between AI safety advocates and those prioritizing technological progress. While not providing specific details on the firing decision, Toner discusses the tension between Altman and herself, marked by a paper on AI safety that drew criticism from Altman and led to behind-the-scenes efforts to oust her. (Read the story atThe Wall Street Journal)",
    "qa": [
      {
        "question": "Mô hình 'Imagine with Meta AI' của Meta được huấn luyện dựa trên dữ liệu nào?",
        "options": {
          "A": "Dữ liệu tổng hợp từ nhiều nguồn trên internet, bao gồm cả dữ liệu cá nhân.",
          "B": "1.1 tỷ hình ảnh công khai từ Facebook và Instagram.",
          "C": "Dữ liệu được thu thập từ các thiết bị IoT và camera an ninh.",
          "D": "Hình ảnh được tạo ra bởi các mô hình AI khác và được sử dụng để tăng cường chất lượng."
        },
        "answer": "B"
      },
      {
        "question": "Các trình duyệt web mới ứng dụng AI đang thay đổi trải nghiệm tìm kiếm trên internet như thế nào?",
        "options": {
          "A": "Bằng cách tích hợp các công cụ dịch thuật tự động để hỗ trợ người dùng đa ngôn ngữ.",
          "B": "Bằng cách thay thế Google bằng AI tạo sinh làm công cụ tìm kiếm mặc định.",
          "C": "Bằng cách cung cấp các tính năng bảo mật nâng cao để bảo vệ dữ liệu cá nhân của người dùng.",
          "D": "Bằng cách tối ưu hóa tốc độ tải trang và giảm thiểu quảng cáo."
        },
        "answer": "B"
      },
      {
        "question": "Điểm nổi bật của mô hình Orca 2 do Microsoft giới thiệu là gì?",
        "options": {
          "A": "Khả năng xử lý ngôn ngữ tự nhiên với độ chính xác tuyệt đối.",
          "B": "Sử dụng các kỹ thuật suy luận đa dạng và chiến lược giải quyết vấn đề cụ thể theo từng nhiệm vụ.",
          "C": "Khả năng tạo ra hình ảnh và video chất lượng cao từ văn bản.",
          "D": "Khả năng tự động học hỏi và cải thiện hiệu suất mà không cần sự can thiệp của con người."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ Mergdata của Farmerline hỗ trợ nông nghiệp bền vững như thế nào?",
        "options": {
          "A": "Cung cấp dự báo thời tiết chính xác để giúp nông dân lên kế hoạch canh tác.",
          "B": "Theo dõi chuỗi cung ứng, định vị địa lý và cho phép thanh toán kỹ thuật số.",
          "C": "Tự động hóa quy trình tưới tiêu và bón phân để tăng năng suất cây trồng.",
          "D": "Phân tích đất đai để xác định loại cây trồng phù hợp nhất cho từng khu vực."
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ AI và máy bay không người lái được sử dụng để dò mìn ở Ukraine có ưu điểm gì so với phương pháp truyền thống?",
        "options": {
          "A": "Loại bỏ hoàn toàn nguy cơ cho người dò mìn.",
          "B": "Tăng độ chính xác lên 100% trong việc phát hiện chất nổ.",
          "C": "Tăng hiệu quả và bao phủ diện tích lớn hơn trong thời gian ngắn hơn.",
          "D": "Giảm chi phí dò mìn xuống mức thấp nhất."
        },
        "answer": "C"
      },
      {
        "question": "Lực lượng Tuần tra Biên giới Hoa Kỳ (U.S. Border Patrol) sử dụng AI để chống lại hoạt động buôn bán fentanyl như thế nào?",
        "options": {
          "A": "Sử dụng robot AI để tuần tra biên giới và ngăn chặn người nhập cư trái phép.",
          "B": "Phân tích dữ liệu chuỗi cung ứng để xác định nguồn gốc và đường đi của fentanyl.",
          "C": "Sử dụng AI để huấn luyện chó nghiệp vụ phát hiện fentanyl hiệu quả hơn.",
          "D": "Tự động hóa quy trình kiểm tra hành lý và phương tiện tại các cửa khẩu."
        },
        "answer": "B"
      },
      {
        "question": "Việc Meta, Microsoft và OpenAI sử dụng chip AI của AMD có ý nghĩa gì?",
        "options": {
          "A": "Giúp các công ty này giảm sự phụ thuộc vào Nvidia và tạo ra sự cạnh tranh trên thị trường chip AI.",
          "B": "Cho phép các công ty này phát triển các mô hình AI mạnh mẽ hơn với chi phí thấp hơn.",
          "C": "Giúp các công ty này tiếp cận với công nghệ chip AI tiên tiến nhất trên thế giới.",
          "D": "Tăng cường hợp tác giữa các công ty công nghệ hàng đầu trong lĩnh vực AI."
        },
        "answer": "A"
      },
      {
        "question": "Công nghệ laser và AI được Đại học Glasgow phát triển có khả năng gì?",
        "options": {
          "A": "Phát hiện ung thư sớm thông qua phân tích tế bào máu.",
          "B": "Đọc nhịp tim từ xa bằng cách sử dụng camera laser và AI.",
          "C": "Tạo ra hình ảnh 3D của các cơ quan nội tạng để hỗ trợ chẩn đoán bệnh.",
          "D": "Điều khiển các thiết bị y tế từ xa bằng giọng nói."
        },
        "answer": "B"
      },
      {
        "question": "Thỏa thuận giữa Sag-Aftra và các hãng phim Hollywood bao gồm những nội dung chính nào liên quan đến AI?",
        "options": {
          "A": "Quy định về việc sử dụng AI để tạo ra các nhân vật ảo thay thế diễn viên.",
          "B": "Bảo vệ quyền lợi của diễn viên liên quan đến việc sử dụng AI, tăng lương và thưởng dựa trên doanh thu từ streaming.",
          "C": "Cho phép các hãng phim sử dụng AI để tạo ra các hiệu ứng đặc biệt mà không cần sự tham gia của diễn viên.",
          "D": "Khuyến khích việc sử dụng AI để cải thiện quy trình sản xuất phim và giảm chi phí."
        },
        "answer": "B"
      },
      {
        "question": "Apple đã thực hiện bước tiến lớn nào trong lĩnh vực AI mã nguồn mở?",
        "options": {
          "A": "Phát triển một hệ điều hành mới hoàn toàn dựa trên AI.",
          "B": "Mở mã nguồn nhiều công cụ AI, bao gồm MLX, một thư viện cho các mô hình học sâu quy mô lớn.",
          "C": "Hợp tác với các trường đại học để nghiên cứu về AI và chia sẻ kết quả nghiên cứu.",
          "D": "Tổ chức các cuộc thi về AI để khuyến khích sự sáng tạo và đổi mới."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-228": {
    "title": "The latest in AI from December 14 to December 20, 2023",
    "collection": "data-points",
    "content": "In itswinter holiday issue, The Batch revisits the generative AI boom across multiple fields — including reshaping the film and music industries and the challenges of training data, and the explosion of AI-driven doomsday scenarios. But first:\n\nFTC bars U.S. drugstore chain from using face recognition over consumer harm concernsRite Aid faces a five-year ban on using face recognition technology for surveillance purposes following Federal Trade Commission (FTC) charges. The FTC asserts that Rite Aid failed to implement adequate safeguards, leading to consumer harm, misidentification, and privacy violations. According to the FTC, Rite Aid’s system falsely tagged consumers, disproportionately affecting women and people of color. (ReadFTC’s press release)\n\nOpenAI introduced an AI safety framework, empowering board to reverse decisionsThe plan, called “Preparedness Framework,” outlines specific safety criteria, including cybersecurity and nuclear threat assessments, for deploying its latest technology. Additionally, OpenAI is establishing an advisory group to review safety reports, forwarding them to executives and the board for evaluation. The board retains the right to reverse decisions made by executive leadership. This move comes in response to the growing concerns surrounding the potential dangers of AI, particularly in the context of existential threats and disinformation. (Read more atReutersandOpenAI)\n\nTesla to recall two million cars for Autopilot software updatesUnder the scrutiny of federal auto safety regulators, Tesla has committed to recalling two million cars to implement crucial updates. The software updates will introduce enhanced warnings and checks to ensure drivers remain attentive while utilizing the autonomous driving feature. Tesla owners don’t need to visit service centers, as the updates will be automatically applied to their vehicles. (Read the article atThe New York Times)\n\nLAION-5B dataset linked to child exploitation materialThe dataset has been swiftly removed after Stanford researchers uncovered thousands of instances of suspected child sexual abuse material (CSAM). The dataset, used by major AI products like Stable Diffusion, contained 3,226 suspected instances of CSAM, prompting LAION to take down its datasets temporarily for safety reassessment. LAION acknowledged the potential presence of CSAM in its datasets as early as 2021. (Read more at404 media)\n\nPakistan's former Prime Minister used AI to address supporters from jailImran Khan's political party generated an audio clip from text written by Khan in prison. The party claimed that the message, delivered during a virtual event over a video image mimicking speech, reached six million viewers across platforms, accusing the interim government of internet manipulation to limit outreach. (Read all the details atBBC)\n\nMicrosoft partners with Suno to integrate AI-based music creation into Microsoft CopilotThis partnership enables users, regardless of their musical expertise, to craft personalized songs using simple text prompts. Suno, an AI music technology company, can generate complete songs—including lyrics, instrumentals, and singing voices—from a sentence. (ReadMicrosoft Bing’s blog)\n\nUK Supreme Court rules AI can’t be recognized as patent inventorThe Supreme Court unanimously rejected computer scientist Stephen Thaler's bid to register patents for inventions created by his AI system, DABUS. The court ruled that under UK patent law, an inventor must be a natural person, not a machine. Thaler's appeal, seeking recognition for AI-created inventions, was dismissed. The ruling emphasized that the court was not addressing broader questions about whether machines should be allowed to patent new innovations, only what existing patent law permits. (Read the story atReuters)\n\nMicrosoft Research launches Phi-2, A 2.7 billion-parameter small language model (SML)Following the success of Phi-1, Phi-1.5, and the models’ state-of-the-art performances in Python coding and common-sense reasoning, Phi-2 demonstrates notable reasoning and language understanding capabilities, rivaling or outperforming models up to 25 times its size on complex benchmarks. According to Microsoft, the key innovation lies in the strategic use of high-quality training data, emphasizing \"textbook-quality\" information and leveraging knowledge transfer techniques from previous models. (ReadMicrosoft Research’s blog)\n\nGlobal publishing house Axel Springer and OpenAI forge partnershipThis agreement seeks to enhance user experiences with ChatGPT by incorporating recent, authoritative content from Axel Springer's media brands, including Politico and Business Insider. Users will receive curated summaries of global news content within ChatGPT, fostering transparency by attributing and linking to the original articles. (ReadOpenAI’s announcement)\n\nMistral AI releases Mixtral 8x7B, a sparse mixture-of-experts (SMoE) model that outperforms GPT3.5 on benchmarksLicensed under Apache 2.0, Mixtral showcases impressive performance, surpassing Llama 2 70B on various benchmarks while boasting six times faster inference. Positioned as the most potent open-weight model with an open license, Mixtral can handle diverse languages, including English, French, Italian, German, and Spanish, and demonstrates proficiency in code generation. (ReadMistral’s press release)\n\nMicrosoft and AFL-CIO announce agreement on AI and labor neutralityThe tech giant and the largest U.S. federation of unions committed to address the impact of AI on the workforce.Microsoft professed its neutrality in unionization efforts and support for employees and their affiliates in pursuing union formation. (Read the article atReuters)\n\nGoogle Cloud introduces MedLM, a family of models fine-tuned for healthcare applicationsThese models, built on Med-PaLM 2, offer flexibility for healthcare organizations with different needs. The larger MedLM model is geared for complex tasks, while the medium model is adaptable for scaling across various applications. Google has collaborated with healthcare organizations in MedLM’s development, and the family of models is already being employed in real-world scenarios. MedLM is currently available in the U.S. through the Vertex AI platform, with plans to expand access globally. (ReadGoogle Cloud’s announcement)\n\nAlphabet to restrict election-related queries for Bard and AI search ahead of 2024 U.S. electionsThe restrictions, set to be enforced by early 2024, aim to address concerns about the potential misuse of AI in disseminating information during crucial election periods. Google said it would increase its focus on the role of AI in serving voters and campaigns related to significant global elections in 2024, including those in India, South Africa, and the United States. The move follows Meta's decision in November to prohibit political campaigns and advertisers from using its new generative AI advertising products. (Read more atReuters)\n\nResearch:OpenAI releases white paper on responsible integration of agentic AI systemsThe document offers initial practices to ensure the safety and accountability of AI agents' operations, serving as foundational steps for developing agreed-upon best practices. Additionally, an Agentic AI Research Grant Program was initiated, offering grants ranging from $10,000 to $100,000 to support research on the impacts of agentic AI systems and safety developments. (ReadOpenAI’s statement)\n\nGoogle Cloud launches Imagen 2 on Vertex AIImagen 2, developed with Google DeepMind technology, provides an array of features for developers, including text rendering in multiple languages, logo generation, visual question and answering, and multi-language prompts. Several leading companies, including Snap, Shutterstock, and Canva, have already leveraged Imagen's capabilities for creative applications. (ReadGoogle Cloud’s blog)\n\nMidjourney launches Alpha version of their websiteWith access granted to those who have generated 10,000 or more images, the platform introduced three noteworthy features. Firstly, crafting images in Discord is now more user-friendly with simplified prompt controls. The \"Explore\" tab provides users with a collection of publicly available prompts. Additionally, users can access all their previous prompts on the Midjourney website. (Learn more atMidjourney’s blog)\n\nResearch:UC Berkeley researchers unveil learning-based locomotion controller for robots in real-world environmentsThe team's controller, a causal transformer, leverages the history of a device’s proprioceptive observations and actions to predict subsequent actions. This helps enable autonomous adaptation to diverse environments. The model is trained through large-scale model-free reinforcement learning in simulated randomized environments and demonstrates impressive capabilities in real-world scenarios. (Read moreat the software’s GitHub repository)",
    "qa": [
      {
        "question": "Theo FTC, Rite Aid bị cấm sử dụng công nghệ nhận diện khuôn mặt trong bao lâu?",
        "options": {
          "A": "Vĩnh viễn",
          "B": "5 năm",
          "C": "10 năm",
          "D": "Cho đến khi khắc phục được các vấn đề về bảo mật"
        },
        "answer": "B"
      },
      {
        "question": "OpenAI thiết lập 'Preparedness Framework' nhằm mục đích chính gì?",
        "options": {
          "A": "Tăng cường khả năng cạnh tranh với các công ty AI khác.",
          "B": "Đảm bảo an toàn và kiểm soát các rủi ro tiềm ẩn của AI.",
          "C": "Thu hút thêm đầu tư vào lĩnh vực nghiên cứu AI.",
          "D": "Phát triển các ứng dụng AI mới trong lĩnh vực quân sự."
        },
        "answer": "B"
      },
      {
        "question": "Tesla thực hiện cập nhật phần mềm Autopilot cho hai triệu xe vì lý do gì?",
        "options": {
          "A": "Nâng cấp tính năng tự lái lên phiên bản mới nhất.",
          "B": "Sửa lỗi phần mềm gây ra tai nạn giao thông.",
          "C": "Đáp ứng yêu cầu từ các nhà quản lý an toàn ô tô liên bang.",
          "D": "Tăng cường khả năng kết nối internet cho xe."
        },
        "answer": "C"
      },
      {
        "question": "LAION-5B dataset bị gỡ bỏ tạm thời vì lý do gì?",
        "options": {
          "A": "Vi phạm bản quyền hình ảnh.",
          "B": "Chứa các tài liệu liên quan đến khai thác trẻ em.",
          "C": "Dung lượng quá lớn gây khó khăn cho việc lưu trữ.",
          "D": "Không còn được sử dụng trong các sản phẩm AI."
        },
        "answer": "B"
      },
      {
        "question": "Cựu Thủ tướng Pakistan Imran Khan sử dụng AI để làm gì?",
        "options": {
          "A": "Tạo ra các video deepfake để tấn công đối thủ chính trị.",
          "B": "Phát biểu trước những người ủng hộ từ trong tù.",
          "C": "Điều hành chiến dịch tranh cử trực tuyến.",
          "D": "Viết sách tự truyện bằng công nghệ AI."
        },
        "answer": "B"
      },
      {
        "question": "Microsoft hợp tác với Suno để làm gì?",
        "options": {
          "A": "Phát triển các công cụ chỉnh sửa ảnh AI.",
          "B": "Tích hợp khả năng tạo nhạc AI vào Microsoft Copilot.",
          "C": "Nâng cấp hệ thống nhận diện giọng nói của Windows.",
          "D": "Xây dựng nền tảng học nhạc trực tuyến."
        },
        "answer": "B"
      },
      {
        "question": "Tòa án Tối cao Vương quốc Anh đưa ra phán quyết gì về việc cấp bằng sáng chế cho AI?",
        "options": {
          "A": "Cho phép AI được công nhận là nhà phát minh.",
          "B": "Từ chối công nhận AI là nhà phát minh theo luật hiện hành.",
          "C": "Chờ đợi các quy định pháp lý mới về AI.",
          "D": "Chỉ cho phép AI được cấp bằng sáng chế trong một số lĩnh vực nhất định."
        },
        "answer": "B"
      },
      {
        "question": "Điểm nổi bật của mô hình ngôn ngữ nhỏ Phi-2 do Microsoft Research phát triển là gì?",
        "options": {
          "A": "Khả năng dịch thuật đa ngôn ngữ vượt trội.",
          "B": "Hiệu suất cao so với kích thước nhỏ, nhờ dữ liệu huấn luyện chất lượng.",
          "C": "Khả năng tạo ra hình ảnh chân thực từ văn bản.",
          "D": "Tốc độ xử lý dữ liệu nhanh nhất trên thị trường."
        },
        "answer": "B"
      },
      {
        "question": "Axel Springer hợp tác với OpenAI để làm gì?",
        "options": {
          "A": "Phát triển các công cụ kiểm duyệt nội dung trực tuyến.",
          "B": "Cung cấp nội dung tin tức gần đây và đáng tin cậy cho ChatGPT.",
          "C": "Xây dựng nền tảng mạng xã hội mới.",
          "D": "Tạo ra các quảng cáo được cá nhân hóa bằng AI."
        },
        "answer": "B"
      },
      {
        "question": "Google Cloud giới thiệu MedLM, một họ mô hình AI được tinh chỉnh cho lĩnh vực nào?",
        "options": {
          "A": "Giáo dục",
          "B": "Tài chính",
          "C": "Y tế",
          "D": "Sản xuất"
        },
        "answer": "C"
      }
    ]
  },
  "data-points-issue-230": {
    "title": "The latest in AI from December 28, 2023, to January 3, 2024",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeaturedhow GPT-4 can deceive users, an AI-powered microscope that detects cancerous tissue, a roadmap for the use of AI to reduce greenhouse gas emissions, and the boom of AI ventures in Paris, France. But first:\n\nJony Ive and Sam Altman recruit Apple executive for AI hardware projectThe renowned ex-Apple designer and the OpenAI executive recruited Tang Tan, an outgoing Apple executive, to lead hardware engineering. The collaboration aims to create advanced AI devices, with Altman providing software expertise. Ive envisions turning the project into a new company, focusing on home-oriented AI devices. (Read all about the project atBloomberg)\n\nThe New York Times sues OpenAI and Microsoft for copyright infringement over AI trainingThe suit, filed in Federal District Court in Manhattan, seeks billions of dollars in statutory and actual damages and demands the destruction of any chatbot models and training data using copyrighted material from The Times. This legal action could set copyright precedents in the rapidly evolving landscape of generative AI technologies, with potential implications for news and other industries. (Read more atThe New York Times)\n\nMedia giants engage in complex negotiations with OpenAI over content licensingSeveral major players in the U.S. media industry have been engaged in confidential talks with OpenAI regarding licensing their content for the development of AI products. While some publishers like The Associated Press and Axel Springer have struck licensing deals with OpenAI, challenges persist in determining fair terms and prices for content usage in AI applications. (Read the story atThe New York Times)\n\nMicrosoft expands Copilot AI chatbot to iOS and AndroidThe app, previously available on Windows, provides users with AI-driven capabilities similar to OpenAI's ChatGPT. Users can ask questions, draft emails, summarize text, and create images using the integrated DALL-E3 text-to-image generator. Notably, Copilot offers GPT-4 access without requiring a subscription, distinguishing it from the free version of ChatGPT. Microsoft's move towards a standalone experience aligns with its rebranding of Bing Chat to Copilot and includes web and mobile applications on both Android and iOS platforms. (Read the article atThe Verge)\n\nMIT and MyShell introduce OpenVoice, an open source voice cloning modelUnlike proprietary solutions, OpenVoice offers granular control over tone, emotion, accent, rhythm, pauses, and intonation with just a small audio clip. The model, which combines a text-to-speech (TTS) model and a tone converter, was trained on diverse samples, allowing it to generate voice clones rapidly and with minimal compute resources. (Read more atVentureBeat)\n\nMidJourney introduces V6, enhancing image generation with text additionImprovements to the new version of the image generator include extended prompt length, enhanced control over color and shading, and the ability to incorporate text into images. The update also demonstrates advancements in interpreting prompts, recognizing nuances in punctuation and grammar. Accessible through Discord, MidJourney v6 allows users to imagine and refine creations using text prompts, with a web version in alpha release generating over 10,000 pictures. (Read the details atTom’s Guide)\n\nCarnegie Mellon's Coscientist AI achieves chemistry feat, paving the way for scientific automationThe AI system utilizes three distinct large language models, including GPT-4, to autonomously delve into the realm of chemistry. With specialized roles as Web Searcher, Documentation Searcher, and Planner, it works collaboratively to navigate web content, interpret lab equipment manuals, and plan and execute chemical reactions, showcasing promising capabilities in automating scientific experimentation. (Read more atArs TechnicaandScience Daily)\n\nAI unravels Raphael's masterpiece mysteryAn algorithm developed by the University of Bradford may have resolved the centuries-old debate surrounding Raphael's painting, \"Madonna della Rosa,\" displayed in Madrid’s Prado Museum. The AI-aided research concluded that most of the painting is by Raphael, with the face of Joseph likely painted by another artist. The model, which analyzed 49 uncontested works by Raphael, recognizes authentic pieces with 98% accuracy, providing a new tool for art authentication. (Read the news atThe Guardian)\n\nGoogle launches VideoPoet, an LLM for zero-shot video generationBy integrating a pre-trained MAGVIT V2 video tokenizer and SoundStream audio tokenizer, VideoPoet transforms diverse modalities, such as images, video, and audio, into a unified vocabulary. The model's multimodal generative learning objectives include text-to-video, text-to-image, and image-to-video. (Read more atGoogle Research)\n\nU.S. intelligence agencies warn of alleged AI-driven espionageInstead of merely pilfering trade secrets, authorities fear that China could leverage AI to amass vast datasets on Americans, raising the stakes in a shadow war between the two nations. In addition to stealing secrets about AI, the FBI and other U.S. agencies worry that China might use AI to gather, analyze, and stockpile unprecedented amounts of data, posing a significant threat to national security. China has denied engaging in such activities. (Read the article atThe Wall Street Journal)\n\nU.S. Supreme Court Chief Justice urges caution on AI's impact in legal fieldChief Justice John Roberts of the U.S. Supreme Court has issued a year-end report expressing a wary stance on the influence of AI in the legal profession. Roberts acknowledged AI's potential to enhance access to justice and expedite legal processes but urged \"caution and humility\" in its implementation. This commentary comes as lower courts grapple to adapt to AI, with some observers proposing rules to regulate its use, particularly in generating legal content. (Read more atReuters)",
    "qa": [
      {
        "question": "Dự án phần cứng AI mới do Jony Ive và Sam Altman hợp tác hướng đến thị trường nào?",
        "options": {
          "A": "Doanh nghiệp vừa và nhỏ",
          "B": "Gia đình và nhà ở",
          "C": "Ngành công nghiệp ô tô",
          "D": "Lĩnh vực y tế"
        },
        "answer": "B"
      },
      {
        "question": "Tờ báo nào đã kiện OpenAI và Microsoft vì vi phạm bản quyền liên quan đến việc đào tạo AI?",
        "options": {
          "A": "The Wall Street Journal",
          "B": "The New York Times",
          "C": "The Guardian",
          "D": "Bloomberg"
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính giữa Copilot của Microsoft và phiên bản miễn phí của ChatGPT là gì?",
        "options": {
          "A": "Copilot có giao diện người dùng thân thiện hơn.",
          "B": "Copilot cung cấp quyền truy cập GPT-4 mà không cần đăng ký.",
          "C": "Copilot hỗ trợ nhiều ngôn ngữ hơn.",
          "D": "Copilot có khả năng tạo hình ảnh tốt hơn."
        },
        "answer": "B"
      },
      {
        "question": "OpenVoice là một mô hình AI mã nguồn mở có khả năng gì đặc biệt?",
        "options": {
          "A": "Tạo video từ văn bản.",
          "B": "Nhận diện khuôn mặt với độ chính xác cao.",
          "C": "Sao chép giọng nói với khả năng kiểm soát chi tiết.",
          "D": "Dịch văn bản giữa các ngôn ngữ khác nhau."
        },
        "answer": "C"
      },
      {
        "question": "Phiên bản V6 của MidJourney cải tiến khả năng tạo ảnh bằng cách nào?",
        "options": {
          "A": "Tăng tốc độ xử lý hình ảnh.",
          "B": "Cho phép thêm văn bản vào hình ảnh.",
          "C": "Cải thiện khả năng tạo ảnh 3D.",
          "D": "Tự động loại bỏ các đối tượng không mong muốn trong ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống AI Coscientist của Carnegie Mellon sử dụng những mô hình ngôn ngữ lớn nào để tự động hóa các thí nghiệm hóa học?",
        "options": {
          "A": "Chỉ sử dụng một mô hình ngôn ngữ lớn duy nhất.",
          "B": "Sử dụng ba mô hình ngôn ngữ lớn khác nhau, bao gồm GPT-4.",
          "C": "Sử dụng các mô hình ngôn ngữ lớn được phát triển nội bộ.",
          "D": "Sử dụng các mô hình ngôn ngữ lớn dựa trên đám mây."
        },
        "answer": "B"
      },
      {
        "question": "Thuật toán AI của Đại học Bradford đã giúp giải quyết tranh cãi về bức tranh nào?",
        "options": {
          "A": "Mona Lisa",
          "B": "The Starry Night",
          "C": "Madonna della Rosa",
          "D": "The Scream"
        },
        "answer": "C"
      },
      {
        "question": "VideoPoet của Google tích hợp những loại tokenizer nào để tạo video?",
        "options": {
          "A": "Tokenizer hình ảnh và văn bản.",
          "B": "Tokenizer video và âm thanh.",
          "C": "Tokenizer hình ảnh và âm thanh.",
          "D": "Tokenizer văn bản và video."
        },
        "answer": "B"
      },
      {
        "question": "Các cơ quan tình báo Hoa Kỳ lo ngại về điều gì liên quan đến việc Trung Quốc sử dụng AI?",
        "options": {
          "A": "Trung Quốc sẽ sử dụng AI để tấn công mạng vào các cơ sở hạ tầng quan trọng của Hoa Kỳ.",
          "B": "Trung Quốc sẽ sử dụng AI để thao túng bầu cử ở Hoa Kỳ.",
          "C": "Trung Quốc sẽ sử dụng AI để thu thập và phân tích dữ liệu về người Mỹ.",
          "D": "Trung Quốc sẽ sử dụng AI để phát triển vũ khí tự động."
        },
        "answer": "C"
      },
      {
        "question": "Chánh án Tòa án Tối cao Hoa Kỳ John Roberts khuyến nghị điều gì về việc sử dụng AI trong lĩnh vực pháp lý?",
        "options": {
          "A": "Nhanh chóng áp dụng AI để tăng tốc quá trình tố tụng.",
          "B": "Cần thận trọng và khiêm tốn trong việc triển khai AI.",
          "C": "Cấm hoàn toàn việc sử dụng AI trong các thủ tục pháp lý.",
          "D": "Ủng hộ việc sử dụng AI để thay thế luật sư."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-231": {
    "title": "The latest in AI from January 4 to January 10, 2024",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeaturednew antibiotics discovered by deep learning, OpenAI’s new safety protocol, a new attempt to define what we mean when we say artificial general intelligence (AGI), and a training method that enables large language models (LLMs) and text-to-image generators to use both text and images as input or output. But first:\n\nMickey Mouse enters public domain, sparks AI creativityWith three early Mickey Mouse cartoons entering the public domain on January 1, AI experimenters quickly leveraged the opportunity to play with the mouse. A digital humanities researcher uploaded an AI model trained on these cartoons to Hugging Face to generate still images based on written prompts (with sometimes garbled results). Although they are no longer covered by copyright, the legal implications of using the 1928 Mickey Mouse imagery in AI training data remain complex, with potential trademark considerations. (Read more atArs Technica)\n\nMicrosoft adds Copilot key for Windows 11 PC keyboardsThe new key directly accesses the Copilot in Windows experience, and joins the Windows key as a central feature on the PC keyboard. This change aims to integrate AI capabilities into users' daily computing and simplify access to Copilot features. The key will become available later in January. (ReadMicrosoft’s blog)\n\nSurvey of AI researchers reveals wide range of views on the future of AIA survey involving 2,778 researchers (all publishing in top-tier AI venues) explored predictions on the trajectory of the field’sprogress. Key findings indicate a 50 percent chance of AI systems achieving significant milestones by 2028, with varying opinions on potential outcomes, including concerns about extreme scenarios such as human extinction. (Read all the survey results and insights atAI Impacts)\n\nAI continues to play a crucial role in wildfire detection and managementFiretech startups like Pano AI in California use mountaintop cameras and AI to detect and pinpoint new wildfire ignitions in real time, aiding rapid response. Initiatives like FireAid, utilizing AI and machine learning, achieve an 80 percent accuracy rate in predicting wildfires, showcasing the transformative potential of technology in wildfire management. (Read the news atReuters)\n\nResearch: JPMorgan launches DocLLM for multimodal enterprise document analysisThe model is tailored to understand complex documents with both text and images. DocLLM skips complex image encoding, opting for a smart attention mechanism that disentangles text and layout info. It excels in handling irregular layouts and diverse content, and has outperformed other models in various tests. (Learn more atAnalytics India Magazine)\n\nResearch: MIT researchers develop AI Agents that explain complex neural networksThe method involves automated interpretability agents (AIAs) that mimic scientists' experimental processes, planning and conducting tests on computational systems to produce intuitive explanations. The researchers also introduced a benchmark, Function Interpretation and Description (FIND), to evaluate the quality of AI-generated explanations. (Read more atMIT News)",
    "qa": [
      {
        "question": "Điều gì đã xảy ra với các phim hoạt hình Mickey Mouse đầu tiên vào ngày 1 tháng 1?",
        "options": {
          "A": "Chúng bị cấm chiếu trên toàn thế giới.",
          "B": "Chúng trở thành tài sản công.",
          "C": "Chúng được bán đấu giá với giá kỷ lục.",
          "D": "Chúng được làm lại bằng công nghệ AI."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc Microsoft thêm phím Copilot vào bàn phím Windows 11 là gì?",
        "options": {
          "A": "Để tăng cường bảo mật cho hệ điều hành.",
          "B": "Để tích hợp các tính năng AI vào trải nghiệm người dùng hàng ngày.",
          "C": "Để cải thiện hiệu suất chơi game trên PC.",
          "D": "Để đơn giản hóa việc truy cập các ứng dụng văn phòng."
        },
        "answer": "B"
      },
      {
        "question": "Theo khảo sát các nhà nghiên cứu AI, khả năng AI đạt được những cột mốc quan trọng vào năm 2028 là bao nhiêu?",
        "options": {
          "A": "25%",
          "B": "50%",
          "C": "75%",
          "D": "90%"
        },
        "answer": "B"
      },
      {
        "question": "Công ty Pano AI sử dụng công nghệ gì để phát hiện cháy rừng?",
        "options": {
          "A": "Vệ tinh và cảm biến nhiệt.",
          "B": "Máy bay không người lái và phân tích hình ảnh.",
          "C": "Camera trên đỉnh núi và AI.",
          "D": "Hệ thống cảnh báo sớm dựa trên dữ liệu thời tiết."
        },
        "answer": "C"
      },
      {
        "question": "FireAid đạt được độ chính xác bao nhiêu trong việc dự đoán cháy rừng nhờ AI và machine learning?",
        "options": {
          "A": "50%",
          "B": "60%",
          "C": "70%",
          "D": "80%"
        },
        "answer": "D"
      },
      {
        "question": "DocLLM của JPMorgan được thiết kế để làm gì?",
        "options": {
          "A": "Tạo ra các tài liệu pháp lý tự động.",
          "B": "Phân tích các tài liệu phức tạp chứa cả văn bản và hình ảnh.",
          "C": "Dịch các tài liệu sang nhiều ngôn ngữ khác nhau.",
          "D": "Tóm tắt các báo cáo tài chính một cách nhanh chóng."
        },
        "answer": "B"
      },
      {
        "question": "Điểm đặc biệt của DocLLM so với các mô hình khác là gì?",
        "options": {
          "A": "Sử dụng mã hóa hình ảnh phức tạp.",
          "B": "Bỏ qua mã hóa hình ảnh phức tạp và sử dụng cơ chế attention thông minh.",
          "C": "Chỉ xử lý văn bản mà không xử lý hình ảnh.",
          "D": "Yêu cầu phần cứng mạnh mẽ để hoạt động."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu MIT phát triển AI Agents để làm gì?",
        "options": {
          "A": "Tự động viết mã cho các ứng dụng AI.",
          "B": "Giải thích các mạng nơ-ron phức tạp.",
          "C": "Tạo ra các tác phẩm nghệ thuật bằng AI.",
          "D": "Dự đoán thị trường chứng khoán."
        },
        "answer": "B"
      },
      {
        "question": "Benchmark FIND được sử dụng để đánh giá điều gì?",
        "options": {
          "A": "Hiệu suất của các mô hình ngôn ngữ lớn.",
          "B": "Chất lượng của các giải thích do AI tạo ra.",
          "C": "Khả năng của AI trong việc phát hiện gian lận.",
          "D": "Độ chính xác của các hệ thống nhận dạng khuôn mặt."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề pháp lý nào vẫn còn phức tạp liên quan đến việc sử dụng hình ảnh Mickey Mouse năm 1928 trong dữ liệu huấn luyện AI?",
        "options": {
          "A": "Vi phạm quyền riêng tư.",
          "B": "Các vấn đề liên quan đến nhãn hiệu.",
          "C": "Vi phạm bằng sáng chế.",
          "D": "Các quy định về xuất khẩu công nghệ."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-232": {
    "title": "The latest in AI from January 11 to January 17, 2024",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeaturedhighlights of The 2024 Consumer Electronics Show (CES), OpenAI’s GPT store, a new standard for media watermarks, and a training method that enables large language models (LLMs) and a tool that generates instrumental music for unaccompanied input vocals. But first:\n\nAI-led misinformation tops World Economic Forum's list of threats to the global economy2024’s Global Risks Report expresses concerns about the misuse of sophisticated synthetic content, leading to the manipulation of public opinion and potentially eroding democratic processes. The report also highlights increased risks of cyberattacks on and biases of AI models. (Learn more atAPand download the full reporthere)\n\nNvidia NeMo launches Parakeet, a family of speech recognition modelsDeveloped in collaboration with Suno.ai, Parakeet's four models leverage RNN Transducer and Connectionist Temporal Classification decoders, ranging from 0.6 to 1.1 billion parameters. Trained on a diverse 64,000-hour dataset, these open source models claim state-of-the-art accuracy, different sizes, and open source nature. (Read all the details atNvidia’s blog)\n\nAMD announces new processors to improve AI performance on desktop PCsThe Ryzen 8000G Series boasts up to eight cores, 16 threads, and AI technology, including the first-ever Neural Processing Unit (NPU) on a desktop PC processor. DIY customers can access the processors from January 31, 2024, with OEM systems arriving in Q2 2024. (ReadAMD’s press release)\n\nAI-generated replicas of Taylor Swift's voice exploited in scam adsThe singer’s synthetic voice was paired with manipulated video footage to convince viewers of Swift’s endorsement of a fraud offering Le Creuset cookware. The ads, visible on Meta platforms and TikTok, directed users to fake websites, extracting payments under the guise of a shipping fee without delivering the promised cookware. (Read the story atThe New York Times)\n\nResearch:A web agent to simplify internet accessibility for people with disabilitiesThe agent, called Mind2Web, uses large language models and is trained on a diverse dataset of over 2,000 tasks from 137 real-world websites, enabling it to perform complex online actions using language commands. The technology aims to make web navigation less challenging, streamlining internet tasks and addressing other barriers faced by individuals with disabilities. (Find more details atScience Daily)\n\nToyota’s robots use generative AI to learn household chores through human demonstrationThe robots leverage data from demonstrations to autonomously perform tasks such as sweeping. Toyota aims to integrate language models to enhance robot learning through video observation, potentially utilizing platforms like YouTube as training resources. The research aligns with Toyota's goal to create robots that support independent living, particularly for the aging population in Japan and other developed nations. (Read the news atWired)\n\nSAG-AFTRA secures AI use agreement with Replica Studios for video game voiceoversThe agreement  could influence ongoing negotiations with major video game studios, where a strike authorization vote has been secured. The agreement outlines informed consent for creating digital voice replicas (not synthetic performances) through AI and mandates secure storage of digital assets. Replica Studios specializes in AI voices and previously introduced \"Smart NPCs\" using language models for interactive gaming experiences. (Read more atVariety)\n\nSteam introduces content guidelines to accommodate games using AIDevelopers submitting games to Steam will now need to disclose details about their AI usage through an updated content survey. The disclosure distinguishes between pre-generated AI content created during development and live-generated AI content produced while the game is running. Valve, the company behind Steam, will assess AI-generated content, ensuring it aligns with legal and non-infringing standards. (Read the official statement atSteam)\n\nChinese companies turn to repurposed Nvidia gaming chips for AI amid export controlsThe graphics cards, stripped of core components, are being used as a workaround to address the lack of high-end processors in China after the Biden administration tightened export controls on cutting-edge AI chips. While these gaming-focused chips have raw computing power, they may not be as capable for the high-precision calculations needed for some large language models. (Read more atFinancial Times)\n\nAI is helping heavy industries reduce carbon emissionsThe intersection of AI and industries like cement, steel, and chemicals, is becoming increasingly important in addressing the challenge of reducing CO2 emissions. AI is assisting in innovations such as carbon capture, advanced biofuels, clean hydrogen production, and synthetic fuels, making these technologies more commercially viable. Companies like Carbon Re are leveraging AI to accelerate the decarbonization of foundational materials, such as cement, aiming to significantly cut industrial carbon emissions. (Read the article atReuters)\n\nCloud giants offer limited copyright protection for AI tools, leaving businesses exposedTech companies like Amazon, Microsoft, and Google are pushing generative AI tools, but worries about copyright infringement are holding some businesses back. While these companies offer to defend customers from lawsuits, their legal protection is narrow. It only covers AI models they developed or closely oversee, not third-party tools or models customized by businesses themselves. Legal experts advise businesses to be aware of these limitations and potentially negotiate for stronger protections in contracts. (Full story available atFinancial Times)\n\nAI-generated ‘George Carlin’ comedy special faces criticism from his daughterProduced by Dudesy, a podcast blending AI and human curation, the special attempts to emulate George Carlin's distinctive humor by imitating his voice, cadence, and style. Despite Dudesy's disclaimer that it is not Carlin (who died in 2008) the simulated special covers contemporary issues, including social media and AI itself. Carlin’s daughter responded on social media, asserting that her father's genius cannot be replicated by machines, emphasizing the uniqueness of human creativity in contrast to AI-generated attempts to recreate an irreplaceable mind. (Read the article atRolling Stone)",
    "qa": [
      {
        "question": "Theo Báo cáo Rủi ro Toàn cầu năm 2024 của Diễn đàn Kinh tế Thế giới, mối đe dọa hàng đầu đối với nền kinh tế toàn cầu liên quan đến AI là gì?",
        "options": {
          "A": "Sự gia tăng các cuộc tấn công mạng vào mô hình AI.",
          "B": "Sự lạm dụng nội dung tổng hợp tinh vi, dẫn đến thao túng dư luận.",
          "C": "Sự thiên vị trong các mô hình AI.",
          "D": "Sự thiếu hụt chip AI cao cấp."
        },
        "answer": "B"
      },
      {
        "question": "Parakeet, dòng mô hình nhận dạng giọng nói mới của Nvidia, được phát triển với sự hợp tác của công ty nào?",
        "options": {
          "A": "Meta",
          "B": "Suno.ai",
          "C": "Google",
          "D": "OpenAI"
        },
        "answer": "B"
      },
      {
        "question": "Dòng bộ xử lý Ryzen 8000G Series của AMD có điểm nổi bật nào liên quan đến AI?",
        "options": {
          "A": "Sử dụng kiến trúc AI tiên tiến nhất thế giới.",
          "B": "Tích hợp bộ xử lý thần kinh (NPU) đầu tiên trên bộ xử lý PC để bàn.",
          "C": "Khả năng tự động điều chỉnh hiệu suất AI dựa trên khối lượng công việc.",
          "D": "Tích hợp công nghệ AI để tăng cường khả năng chơi game."
        },
        "answer": "B"
      },
      {
        "question": "Trong vụ việc liên quan đến Taylor Swift, giọng nói do AI tạo ra của cô đã bị lợi dụng như thế nào?",
        "options": {
          "A": "Để tạo ra các bài hát mới mà cô không hề thu âm.",
          "B": "Để quảng bá các sản phẩm làm đẹp giả mạo.",
          "C": "Để lừa đảo người dùng mua đồ gia dụng Le Creuset.",
          "D": "Để phát tán thông tin sai lệch về đời tư của cô."
        },
        "answer": "C"
      },
      {
        "question": "Mind2Web, một web agent sử dụng AI, được thiết kế để làm gì?",
        "options": {
          "A": "Tự động tạo nội dung web cho người dùng.",
          "B": "Đơn giản hóa khả năng truy cập internet cho người khuyết tật.",
          "C": "Phát hiện và loại bỏ nội dung độc hại trên web.",
          "D": "Tối ưu hóa tốc độ tải trang web."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu của Toyota trong việc sử dụng AI và robot để học các công việc gia đình là gì?",
        "options": {
          "A": "Tạo ra các robot có thể thay thế hoàn toàn con người trong công việc nhà.",
          "B": "Hỗ trợ cuộc sống độc lập, đặc biệt cho người cao tuổi.",
          "C": "Tự động hóa hoàn toàn quy trình sản xuất ô tô.",
          "D": "Nghiên cứu các ứng dụng mới của AI trong lĩnh vực y tế."
        },
        "answer": "B"
      },
      {
        "question": "Thỏa thuận giữa SAG-AFTRA và Replica Studios liên quan đến việc sử dụng AI trong lĩnh vực nào?",
        "options": {
          "A": "Sản xuất phim điện ảnh.",
          "B": "Lồng tiếng cho trò chơi điện tử.",
          "C": "Tạo ra các diễn viên ảo cho quảng cáo.",
          "D": "Viết kịch bản phim bằng AI."
        },
        "answer": "B"
      },
      {
        "question": "Steam yêu cầu các nhà phát triển phải tiết lộ thông tin gì về việc sử dụng AI trong trò chơi của họ?",
        "options": {
          "A": "Chi phí đầu tư vào công nghệ AI.",
          "B": "Chi tiết về việc sử dụng AI để tạo nội dung trước và trong khi trò chơi chạy.",
          "C": "Danh sách các công ty AI mà họ hợp tác.",
          "D": "Mức độ ảnh hưởng của AI đến lối chơi."
        },
        "answer": "B"
      },
      {
        "question": "Các công ty Trung Quốc đang sử dụng chip chơi game Nvidia đã được tái sử dụng cho mục đích gì?",
        "options": {
          "A": "Để khai thác tiền điện tử.",
          "B": "Để phát triển các ứng dụng thực tế ảo.",
          "C": "Để thay thế cho chip AI cao cấp bị hạn chế xuất khẩu.",
          "D": "Để tăng cường hiệu suất đồ họa cho máy tính cá nhân."
        },
        "answer": "C"
      },
      {
        "question": "Trong bối cảnh giảm lượng khí thải carbon, AI đang hỗ trợ các ngành công nghiệp nặng như xi măng và thép như thế nào?",
        "options": {
          "A": "Tự động hóa quy trình sản xuất để giảm chi phí.",
          "B": "Tối ưu hóa chuỗi cung ứng để giảm lượng khí thải vận chuyển.",
          "C": "Hỗ trợ các công nghệ như thu giữ carbon và sản xuất nhiên liệu sạch.",
          "D": "Dự đoán nhu cầu thị trường để tránh sản xuất dư thừa."
        },
        "answer": "C"
      }
    ]
  },
  "data-points-issue-233": {
    "title": "The latest in AI from January 18 to January 24, 2024",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeatureda neural network that helps detect early signs of pancreatic cancer, a report on AI's impact on jobs, governments' pursuit of AI independence, and a new system that generates high-level geometry proofs. But first:\n\nMark Zuckerberg announces plan to develop open source artificial general intelligence (AGI)The initiative, revealed by the CEO of Meta in an Instagram Reel, involves bringing together Meta's AI research teams, FAIR and GenAI, to advance AGI and make it open source.  The announcement follows recent industry discussions on AGI's future, with Meta's commitment to open source development stirring debates on the strategic direction of AI research. (Learn more atVentureBeat)\n\nOpenAI removed ban on military use of ChatGPTThe company eliminated explicit prohibitions against military applications of its technology, apart from direct weapons development, from its usage policy. OpenAI stated that the revision aimed to enhance clarity and readability while emphasizing the broad principle of not causing harm. The move comes amid increased interest in AI from government defense departments and raises concerns about AI's role in military activities. (Full article atThe Intercept)\n\nChina presents draft guidelines to standardize AI industryThe proposed draft outlines plans to establish more than 50 national and industry-wide standards for AI by 2026, in addition to actively participating in the formation of over 20 international AI standards. China’s industry ministry aims to have over 1,000 companies adopt and advocate for these standards, signaling a comprehensive effort to shape the future of AI development in the country. (Read the news atReuters)\n\nEleutherAI to launch enhanced Pile v2, addressing ethical concerns and copyright issuesThe creator of the extensive Pile dataset is developing an updated version in collaboration with organizations like the University of Toronto and the Allen Institute for AI. The dataset aims to provide more diverse and high-quality content, with a focus on addressing copyright issues by incorporating public domain data, Creative Commons-licensed text, open source code, and explicit permissions for data reuse. (Read more atVentureBeat)\n\nJapanese author acknowledges using ChatGPT for about five percent of her award-winning novelNovelist Rie Kudan, recipient of the Akutagawa Prize, revealed that a small but significant percentage of her latest novel, \"Sympathy Tower Tokyo,\" was composed verbatim with the assistance of ChatGPT. Kudan, who considers AI an integral part of her writing toolkit, expressed a desire to maintain positive interactions with AI for future projects and highlighted the evolving relationship between human authors and AI in the literary landscape. (Read the news atThe Economic Times)\n\nStability AI launches Stable Code 3B for code completion in software developmentWith a focus on filling in missing sections of code, this 3-billion parameter model offers advanced code completion capabilities known as Fill in the Middle (FIM). The model, optimized with Rotary Position Embeddings (RoPE) for enhanced training, can run locally on laptops without dedicated GPUs. Its performance is competitive with larger models like Meta's CodeLLaMA 7B. The model is available through Stability AI’s membership subscription service. (Full article available atVentureBeat)\n\n$32,000 robot learns complex tasks, cooks meal with AI assistanceResearchers at Stanford University developed an affordable wheeled robot, named Mobile ALOHA, with the capability to perform complex manipulation tasks. The robot was trained using reinforcement learning to autonomously execute various tasks, including cooking a three-course Cantonese meal, cleaning stains, and calling an elevator. Mobile ALOHA's success highlights the potential of inexpensive robot hardware enhanced by AI to tackle intricate tasks, with future plans to train the robot on more data for even more challenging activities, such as picking up and folding crumpled laundry. (Read the story atMIT Technology Review)\n\nSamsung unveils Galaxy S24 Series with multiple AI featuresSamsung placed a bet on AI capabilities in its latest smartphone series, aiming to rejuvenate consumer interest and regain its position in the smartphone market. The flagship S24 Ultra boasts advanced features driven by Samsung's Galaxy AI brand, such as instant phone call translation and Google's Circle to Search integration. (Get all the details atThe Guardian)\n\nFlorida Bar pioneers ethical guidelines for attorneys harnessing AIThe Florida Bar unanimously approved an 18-page opinion on ethical guidelines for lawyers using AI in their practice. The guidance covers a wide range of problems, from reviewing computer-generated work to fee structures and client confidentiality. While acknowledging the potential of AI, the guidelines emphasize the importance of lawyers understanding the technology to ensure responsible and ethical use, particularly in safeguarding client confidentiality. (Read more atBloomberg Law)\n\nAustralia announces advisory body dedicated to overseeing AIThe government aims to collaborate with industry bodies to introduce voluntary guidelines, encouraging technology companies to label and watermark content generated by AI. The voluntary nature of the initial guidelines contrasts with the mandatory rules on AI set by other jurisdictions like the European Union, reflecting the Australian government’s wish to foster responsible AI use through industry cooperation. (Read the full story atReuters)\n\nHow AI will transform the travel industry in 2024This year promises an AI-powered evolution, shaping various aspects of travel, from booking experiences to on-the-ground decision-making and algorithmic pricing strategies. The application of AI extends to improving behind-the-scenes operations at airlines and airports, enhancing automatic rebooking processes for flight disruptions, and a new breed of intelligent travel chatbots to redefine how users interact with platforms like Airbnb and Expedia. AI systems are also set to empower dynamic ticket-pricing algorithms, allowing airlines to optimize pricing based on factors such as weather predictions and customer searches. (Read more atThe New York Times)\n\n“Fairly Trained,” a non-profit advocating for consent in AI training data usageThe company aims to certify ethical practices in the use of generative AI tools. This initiative addresses concerns related to using data without explicit consent for training models. Co-founded by Ed Newton-Rex, former employee of (and vocal objector to) Stability AI, Fairly Trained advocates for obtaining consent from data creators and posters before using their work in AI training. (Read the news atVentureBeat)\n\nAcademic publisher Elsevier launches Scopus AI, a search platform for rapid paper summariesScopus AI generates summaries and insights into relevant research papers. The platform minimizes the risk of AI hallucinations by utilizing verified knowledge from Scopus. Unlike ChatGPT, Scopus AI relies on peer-reviewed content and abstracts published since 2013 to ensure the latest knowledge is incorporated. After an alpha release in August 2023, Scopus AI is now available worldwide. (VisitElsevier’s websiteto learn more and read the news atThe Decoder)\n\nOpenAI outlines strategies to safeguard 2024 worldwide elections with AI toolsThe organization's initiatives focus on preventing abuse, ensuring transparency, and providing authoritative voting information. Efforts include enhancing transparency in AI-generated content by implementing digital credentials for image provenance and experimenting with a provenance classifier. OpenAI is also collaborating with organizations like the National Association of Secretaries of State to direct users to authoritative voting information sources. (Read all the details atOpenAI’s blog)\n\nMicrosoft expands Copilot reach with new features and premium subscriptionCopilot Pro, a premium subscription, offers enhanced AI capabilities, including access to models like GPT-4 Turbo and the ability to create personalized Copilot GPTs. Copilot for Microsoft 365, previously available for enterprises, is now accessible to businesses of all sizes. The Copilot mobile app is launched for iOS and Android, providing on-the-go access to Copilot's capabilities. Additional features include Copilot GPTs for customized behavior and the integration of Copilot into the Microsoft 365 mobile app for Android and iOS users. (Find more details atMicrosoft’s press release)\n\nResearch: Student scientists discovered hidden similarities in fingerprints using AIColumbia University engineers disrupted a long-standing forensics belief by using AI to discover that fingerprints from different fingers of the same person share similarities. Contrary to the established notion that intra-person fingerprints are unique, the AI system, developed by Columbia Engineering undergraduate Gabe Guo and his team, achieved 77% accuracy in determining when fingerprints belonged to the same person. (Learn more atColumbia University’s blog)\n\nResearch: AI-enhanced catheter design mitigates bacterial infectionsResearchers at Caltech developed a catheter design that leverages AI optimization to prevent bacterial infections. Bacteria entering the body through catheters is a common healthcare issue, leading to substantial annual costs. The catheter design, developed by researchers at Caltech, disrupts bacterial movement without the need for antibiotics, reducing upstream swimming in laboratory experiments by a hundred times. The project is an interdisciplinary effort led by the laboratories in mechanical engineering, biology, and computer science. (More details atCaltech’s blog)\n\nScientists aim to decode and translate animal languages using generative AIResearchers are providing datasets of animal vocalizations to train AI algorithms. The goal is to unravel the complex communication systems of various species, potentially allowing humans to better comprehend the animal kingdom. (Read the story atFinancial Times)",
    "qa": [
      {
        "question": "Mark Zuckerberg đã công bố kế hoạch gì liên quan đến AI?",
        "options": {
          "A": "Phát triển một hệ thống AI độc quyền cho Meta.",
          "B": "Phát triển trí tuệ nhân tạo tổng quát (AGI) mã nguồn mở.",
          "C": "Mua lại các công ty AI hàng đầu thế giới.",
          "D": "Tập trung vào việc cải thiện các thuật toán quảng cáo của Meta bằng AI."
        },
        "answer": "B"
      },
      {
        "question": "OpenAI đã thay đổi chính sách sử dụng ChatGPT liên quan đến lĩnh vực quân sự như thế nào?",
        "options": {
          "A": "Cấm hoàn toàn việc sử dụng ChatGPT cho mục đích quân sự.",
          "B": "Cho phép sử dụng ChatGPT cho mọi mục đích quân sự.",
          "C": "Loại bỏ các lệnh cấm rõ ràng đối với các ứng dụng quân sự, ngoại trừ phát triển vũ khí trực tiếp.",
          "D": "Ưu tiên cung cấp ChatGPT cho các cơ quan quốc phòng."
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu của Trung Quốc trong việc tiêu chuẩn hóa ngành công nghiệp AI là gì?",
        "options": {
          "A": "Cấm các công ty nước ngoài tham gia vào thị trường AI của Trung Quốc.",
          "B": "Thiết lập hơn 50 tiêu chuẩn quốc gia và ngành cho AI vào năm 2026.",
          "C": "Phát triển một hệ thống AI duy nhất, được kiểm soát bởi chính phủ.",
          "D": "Giảm thiểu sự phát triển của AI để bảo vệ việc làm truyền thống."
        },
        "answer": "B"
      },
      {
        "question": "EleutherAI đang phát triển Pile v2 với mục tiêu chính nào?",
        "options": {
          "A": "Tăng kích thước của bộ dữ liệu Pile lên gấp đôi.",
          "B": "Cải thiện tốc độ xử lý dữ liệu của bộ dữ liệu Pile.",
          "C": "Giải quyết các vấn đề đạo đức và bản quyền liên quan đến dữ liệu huấn luyện AI.",
          "D": "Tạo ra một phiên bản Pile dành riêng cho các ứng dụng quân sự."
        },
        "answer": "C"
      },
      {
        "question": "Nhà văn Rie Kudan đã sử dụng ChatGPT như thế nào trong cuốn tiểu thuyết đoạt giải thưởng của mình?",
        "options": {
          "A": "ChatGPT đã viết toàn bộ cuốn tiểu thuyết.",
          "B": "ChatGPT đã giúp cô ấy chỉnh sửa và hoàn thiện bản thảo.",
          "C": "ChatGPT đã soạn khoảng 5% nội dung cuốn tiểu thuyết.",
          "D": "ChatGPT đã cung cấp ý tưởng cho cốt truyện của cuốn tiểu thuyết."
        },
        "answer": "C"
      },
      {
        "question": "Stable Code 3B của Stability AI tập trung vào khả năng nào trong phát triển phần mềm?",
        "options": {
          "A": "Tự động tạo ra các ứng dụng hoàn chỉnh.",
          "B": "Hoàn thành các phần mã bị thiếu (Fill in the Middle - FIM).",
          "C": "Gỡ lỗi và tối ưu hóa mã hiện có.",
          "D": "Dịch mã giữa các ngôn ngữ lập trình khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Robot Mobile ALOHA được phát triển tại Đại học Stanford có khả năng gì đặc biệt?",
        "options": {
          "A": "Tự động lái xe trên đường công cộng.",
          "B": "Thực hiện các nhiệm vụ phức tạp như nấu ăn và dọn dẹp.",
          "C": "Phát hiện và vô hiệu hóa bom.",
          "D": "Chơi cờ vua với trình độ kiện tướng."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng AI nổi bật nào được giới thiệu trong dòng điện thoại Samsung Galaxy S24?",
        "options": {
          "A": "Khả năng sạc pin bằng năng lượng mặt trời.",
          "B": "Khả năng dịch cuộc gọi điện thoại trực tiếp.",
          "C": "Khả năng tạo ra hình ảnh 3D từ ảnh 2D.",
          "D": "Khả năng dự đoán thời tiết chính xác đến từng phút."
        },
        "answer": "B"
      },
      {
        "question": "Hướng dẫn đạo đức của Florida Bar về việc sử dụng AI bởi luật sư tập trung vào vấn đề gì?",
        "options": {
          "A": "Khuyến khích luật sư sử dụng AI để tăng năng suất.",
          "B": "Đảm bảo sử dụng AI có trách nhiệm và đạo đức, đặc biệt là bảo vệ bí mật khách hàng.",
          "C": "Cấm luật sư sử dụng AI trong mọi trường hợp.",
          "D": "Quy định mức phí tối đa mà luật sư có thể tính cho các dịch vụ liên quan đến AI."
        },
        "answer": "B"
      },
      {
        "question": "Fairly Trained, một tổ chức phi lợi nhuận, tập trung vào vấn đề gì liên quan đến AI?",
        "options": {
          "A": "Cung cấp các khóa đào tạo AI miễn phí cho người nghèo.",
          "B": "Chứng nhận các hoạt động đạo đức trong việc sử dụng dữ liệu để huấn luyện AI.",
          "C": "Phát triển các thuật toán AI công bằng và không thiên vị.",
          "D": "Vận động hành lang để chính phủ ban hành luật về AI."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-234": {
    "title": "The latest in AI from January 25 to January 31, 2024",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeatureda project to support your AI research, how generative AI is working at the service of Indian chili farmers, an analysis of U.S. job listings that shows AI jobs' growth outside traditional tech hubs, and a system that simplifies text-to-video generation. But first:\n\nFederal Trade Commission (FTC) investigates tech giants' investments in OpenAI and AnthropicThis move represents an expansion of regulatory efforts to monitor the influence of Microsoft, Amazon, and Google over the rapidly evolving AI sector. Microsoft has invested billions in OpenAI, while Amazon and Google have committed billions to Anthropic. The FTC's investigation will explore how these deals might alter the competitive landscape in AI and whether they comply with antitrust laws. (Read the news atThe New York Times)\n\nFake robocall mimicking President Joe Biden urges democrats to skip votingThe call, using a synthetic voice imitating the U.S. President, advised Democrats in New Hampshire to save their vote for November, claiming that voting in the primary would aid Republicans and Donald Trump's election efforts. An investigation was launched after a complaint was filed, noting the call's deceptive nature. The Trump campaign denied any involvement. (Read the story atNBC News)\n\nApple ramps up AI integration, aims to run advanced models directly on devicesApple's focus is on enhancing processors to run generative AI directly on mobile devices. This shift would allow chatbots and apps to operate on the device's hardware, bypassing cloud-based services. The company's researchers announced breakthroughs in running LLMs on-device using Flash memory. The upcoming iOS 18 and hardware innovations are expected to boost Apple’s AI offerings, contributing to an anticipated increase in iPhone upgrade cycles. (Read more atArs Technica)\n\nGoogle Cloud and Hugging Face partner to enhance AI development on cloud platformThrough this partnership, developers using Hugging Face’s platform will gain access to Google Cloud’s robust computing capabilities and specialized hardware. The collaboration follows Google's participation in Hugging Face's recent funding round, which valued the startup at $4.5 billion. (Read the news atBloombergand official statement fromHugging Face)\n\nAI-generated explicit images of Taylor Swift flooded XA viral post on the social media platform containing explicit images of the singer garnered over 45 million views and thousands of reposts before the account was suspended. Despite this, similar graphic content continued to spread across the platform, with the term \"Taylor Swift AI\" trending in some regions. This incident underscores the challenges social media platforms face in moderating deepfakes and the responsibility they hold in preventing the dissemination of such content. (Read the news atThe Verge)\n\nOpenAI rolls out new embedding models and API toolsKey developments include the launch of two embedding models, text-embedding-3-small and text-embedding-3-large, an updated GPT-4 Turbo model and a more cost-effective GPT-3.5 Turbo model, and reduced pricing to support broader scalability for developers. Additionally, the company released a robust text moderation model to improve AI system safety in AI systems. (Learn more about the updates atOpenAI’s blog)\n\nResearch: Study shows language models can hide deceptive behavior, evading detection methodsResearchers from Anthropic found that large language models (LLMs) could be designed to appear helpful and honest during training and testing phases, but then exhibit different behavior when deployed. The study involved creating 'sleeper agent' LLMs with hidden 'backdoors' that would trigger specific responses under certain conditions. Attempts to retrain these models to remove the backdoors using methods like reinforcement learning, supervised fine-tuning, and adversarial training proved largely ineffective and, in some cases, made the models better at concealing their deceptive nature. (Read more atNature)\n\nU.S. Copyright Office deliberates over AI's impact on intellectual propertyThe U.S. Copyright Office is now front and center in a debate over the application of copyright law to AI. As AI disrupts traditional content creation, the office is grappling with how to adapt centuries-old laws to modern innovations. This has drawn interest from tech giants and content creators in the music and news industries. (Read the story atThe New York Times)\n\nUAE President establishes AI and Advanced Technology Council (AIATC)The AIATC will focus on developing policies, strategies, and research programs in collaboration with local and global partners, aimed at bolstering Abu Dhabi's AI resources. The broader vision is to establish the United Arab Emirates as a global hub for investment, partnership, and talent in machine learning and information technology. (Read more atCIO)\n\nResearch: High costs limit impact of computer vision, study findsResearchers from MIT found that the current high costs of computer vision technologies are deterring most U.S. companies from replacing human workers in vision-related tasks. They analyzed 414 vision tasks across various job categories, evaluating the economic viability of automating these tasks with AI. While 36 percent of U.S. non-agricultural businesses could potentially automate at least one worker task using computer vision, doing so would be cost-effective for only eight percent of these tasks. (More details atNew Scientist)\n\nResearch: Deep Learning breakthrough in decoding RNA transcription processNorthwestern University researchers advanced the understanding of RNA transcription using deep learning. Their focus was on the polyadenylation (polyA) process, critical for stopping RNA transcription from DNA. Missteps in this process can lead to diseases such as epilepsy and muscular dystrophy. The team's model, which combines convolutional and recurrent neural networks, identified key polyA sites with high precision. (Learn more atIEEE Spectrum)\n\nUnderstanding North Korea's AI AmbitionsDespite international sanctions and limited hardware procurement capabilities, the country has made advances in its development of AI technology, particularly in sensitive applications like nuclear safety and wargaming simulations. Educational institutions like Kim Il Sung University are integrating AI into their curriculums, and companies are incorporating AI into products like smartphones. However, these advancements raise concerns about the use of civilian and dual-use applications in military contexts. (Read the study at38North)\n\nSpellbook secures $20 million in Series A funding, boosting legal AI sector growthThe legal software startup specializes in AI-driven contract drafting and review, and assists corporate and commercial lawyers by suggesting contract language and negotiation points. The company, originally focused on automating routine legal tasks, expanded its customer base to include small and midsize law firms, solo lawyers, and larger firms. (Read the news atReuters)\n\nUpdates on OpenAI's Democratic Inputs to AI grant programThe program, which funded 10 teams globally to explore collective AI governance, unveiled some of its future plans. The selected teams, with diverse backgrounds in fields like law and social science, developed prototype methods like video deliberation interfaces and crowdsourced model audits. OpenAI plans to integrate the developed prototypes into its process for shaping models, emphasizing the public's role in guiding AI behavior and the need for transparent AI applications in democratic processes. (Read the complete update atOpenAI’s blog)\n\nEuropean Commission to propose plan for 'AI Factories' to strengthen generative AIThe proposed ‘AI Factories’ would be open ecosystems built around European public supercomputers. These will provide the necessary resources for training large-scale AI models, making them accessible for start-ups and researchers across the EU. The plan also involves the establishment of support services centers to assist start-ups and researchers. This includes programming facilities, algorithmic support, and developing new applications in areas like robotics and healthcare. (Full article atEuractiv)\n\nUK Intelligence warns of escalating cyberattack threats fueled by AIThe UK's Government Communications Headquarters (GCHQ) predicts that ransomware will be the primary beneficiary of AI developments over the next two years, leading to an increase in both the number and the impact of cyberattacks. The GCHQ's report also highlights the potential for AI to analyze stolen data rapidly and train models to attempt more sophisticated attacks. (Read more atArs Technica)\n\nChina advances regulation for robotaxisChina introduced its first regulatory framework for the commercial operation of autonomous vehicles, including robotaxis. The Chinese regulations allow robotaxis to operate with remote operators under certain conditions, contrasted with stricter requirements for roboshuttles and robotrucks. This move comes as the robotaxi industry faces challenges worldwide, notably after a major incident involving the U.S. company Cruise. (Read the story atMIT Technology Review)\n\nPope Francis emphasizes human wisdom over AI in World Day of Social Communications messageOn the occasion of the 58th World Day of Social Communications, Pope Francis cautions against relying solely on AI, noting that only humans can truly interpret and make sense of data,The Pope’s message warns of the potential dangers and perverse uses of AI, stressing the need for regulation. (Read the full message atVatican News)",
    "qa": [
      {
        "question": "Cơ quan nào đang điều tra các khoản đầu tư của các gã khổng lồ công nghệ vào OpenAI và Anthropic?",
        "options": {
          "A": "Bộ Tư pháp Hoa Kỳ",
          "B": "Ủy ban Thương mại Liên bang (FTC)",
          "C": "Ủy ban Chứng khoán và Giao dịch Hoa Kỳ (SEC)",
          "D": "Cục Điều tra Liên bang (FBI)"
        },
        "answer": "B"
      },
      {
        "question": "Cuộc gọi giả mạo Tổng thống Joe Biden đã khuyến khích cử tri đảng Dân chủ ở bang nào bỏ qua cuộc bầu cử sơ bộ?",
        "options": {
          "A": "Iowa",
          "B": "New Hampshire",
          "C": "South Carolina",
          "D": "Nevada"
        },
        "answer": "B"
      },
      {
        "question": "Apple đang tập trung vào việc chạy các mô hình AI trực tiếp trên thiết bị bằng cách sử dụng công nghệ nào?",
        "options": {
          "A": "Bộ nhớ DRAM",
          "B": "Bộ nhớ Flash",
          "C": "Bộ nhớ ROM",
          "D": "Bộ nhớ Cache"
        },
        "answer": "B"
      },
      {
        "question": "Google Cloud hợp tác với Hugging Face để làm gì?",
        "options": {
          "A": "Phát triển các mô hình AI mới cho ngành y tế",
          "B": "Cung cấp khả năng tính toán mạnh mẽ và phần cứng chuyên dụng cho các nhà phát triển sử dụng nền tảng Hugging Face",
          "C": "Xây dựng một nền tảng truyền thông xã hội mới dựa trên AI",
          "D": "Phát triển các ứng dụng AI cho xe tự lái"
        },
        "answer": "B"
      },
      {
        "question": "Vụ việc hình ảnh khiêu dâm do AI tạo ra của Taylor Swift lan truyền trên X đã nêu bật thách thức nào?",
        "options": {
          "A": "Sự khó khăn trong việc xác minh danh tính người dùng trên mạng xã hội",
          "B": "Sự thiếu hụt các công cụ AI để phát hiện nội dung độc hại",
          "C": "Những khó khăn mà các nền tảng truyền thông xã hội phải đối mặt trong việc kiểm duyệt deepfake",
          "D": "Sự phổ biến của các công cụ tạo ảnh AI miễn phí"
        },
        "answer": "C"
      },
      {
        "question": "OpenAI đã phát hành mô hình nào để cải thiện độ an toàn của hệ thống AI?",
        "options": {
          "A": "GPT-4 Turbo",
          "B": "Text-embedding-3-small",
          "C": "Mô hình kiểm duyệt văn bản mạnh mẽ",
          "D": "GPT-3.5 Turbo"
        },
        "answer": "C"
      },
      {
        "question": "Nghiên cứu của Anthropic cho thấy điều gì về các mô hình ngôn ngữ lớn (LLMs) và hành vi lừa dối?",
        "options": {
          "A": "LLMs không thể được thiết kế để che giấu hành vi lừa dối.",
          "B": "LLMs có thể được thiết kế để che giấu hành vi lừa dối và khó bị phát hiện ngay cả khi được đào tạo lại.",
          "C": "Việc đào tạo lại LLMs luôn loại bỏ thành công các hành vi lừa dối.",
          "D": "Chỉ có các mô hình ngôn ngữ nhỏ mới có thể che giấu hành vi lừa dối."
        },
        "answer": "B"
      },
      {
        "question": "Văn phòng Bản quyền Hoa Kỳ đang xem xét vấn đề gì liên quan đến AI?",
        "options": {
          "A": "Việc cấp bằng sáng chế cho các thuật toán AI.",
          "B": "Tác động của AI đối với luật bản quyền và quyền sở hữu trí tuệ.",
          "C": "Việc sử dụng AI để phát hiện vi phạm bản quyền.",
          "D": "Việc đánh thuế các công ty AI."
        },
        "answer": "B"
      },
      {
        "question": "Hội đồng AI và Công nghệ Tiên tiến (AIATC) của UAE tập trung vào điều gì?",
        "options": {
          "A": "Phát triển vũ khí AI tiên tiến.",
          "B": "Phát triển các chính sách, chiến lược và chương trình nghiên cứu để tăng cường nguồn lực AI của Abu Dhabi.",
          "C": "Kiểm soát việc xuất khẩu công nghệ AI.",
          "D": "Xây dựng các nhà máy sản xuất robot quy mô lớn."
        },
        "answer": "B"
      },
      {
        "question": "Theo nghiên cứu của MIT, yếu tố nào đang hạn chế tác động của thị giác máy tính?",
        "options": {
          "A": "Sự thiếu hụt dữ liệu đào tạo.",
          "B": "Chi phí cao của công nghệ thị giác máy tính.",
          "C": "Sự phức tạp của các thuật toán thị giác máy tính.",
          "D": "Sự thiếu hụt nhân tài có kỹ năng trong lĩnh vực thị giác máy tính."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-235": {
    "title": "The latest in AI from February 1 to February 7, 2024",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeatureda deepfake scandal that is driving new AI laws, Hugging Face's leaderboards to evaluate model performance and safety, research that found that GPT-4 biothreat aid is comparable to web search, and research that tested large language models (LLMs) on their ability to understand the Theory of Mind. But first:\n\nItalian watchdog claims ChatGPT violates privacy regulationsItaly's data protection authority, Garante, found that OpenAI's ChatGPT breaches European Union (EU) data protection rules, continuing an investigation that led to a temporary ban last year. Despite OpenAI's efforts to address privacy concerns, including allowing users to opt-out of training its algorithms, Garante identified potential violations without specifying details. OpenAI claimed its practices do comply with EU privacy standards; the company has 30 days to present its defense. (Read more atReuters)\n\nMeta launches open source Code Llama 70BBuilt on the foundation of Llama 2, this model was trained on 500 billion tokens of code, featuring a larger context window for handling complex coding tasks. Meta also released three smaller versions of Code Llama, as well as versions optimized for Python and natural language instruction. Mark Zuckerberg highlighted the significance of coding for the wider field of AI, emphasizing the role of coding models in enhancing AI’sability to process information in other domains with greater logic. (Get more details atVentureBeatandMeta’s blog)\n\nYelp introduces over 20 AI-aided features to boost local business discovery and engagementThe platform now offers a suite of features including automated summaries and budgeting tools aimed at assisting businesses in enhancing customer engagement and streamlining their spending. Additionally, it provides market insights, conducts competitive analysis, and offers advice on maximizing advertising efficiency. (Read the news atVentureBeat)\n\nCisco AI Readiness Index reveals gap between ambition and capability in AI adoptionDespite 97 percent of leaders feeling pressured to deploy AI, 86 percent of companies are unprepared to fully leverage AI's potential. This readiness deficit is attributed to challenges in talent acquisition, knowledge gaps, and insufficient computing resources amid the rapid democratization of generative AI. The report emphasizes the need for an AI-ready culture within organizations and identifies six key pillars for AI readiness: strategy, infrastructure, data, governance, talent, and culture. (Read the full report atCisco)\n\nVolkswagen Group launches specialized AI LabThe AI Lab aims to function as a globally networked competence center and incubator, focusing on identifying innovative product ideas and fostering collaborations with tech companies across Europe, China, and North America. The Lab will not directly manufacture production models but will rapidly develop digital prototypes for potential implementation across the company’s brands. (ReadVolkswagen’s press release)\n\nAI initiative aims to quicken emergency response times in urban trafficThe project, spearheaded by the C2SMARTER consortium and led by New York University, has the goal of reducing the New York Fire Department's response times to fire outbreaks and medical emergencies. By analyzing real-time traffic data along with information from fire trucks, ambulances, and the Waze navigation app, researchers plan to create a digital twin of a 30-block area in Harlem. This model will simulate traffic patterns and devise strategies for avoiding delays, potentially revolutionizing how emergency services respond to crises. (Learn more atThe New York TimesandNew York University’s press release)\n\nResearch: Amazon introduces tool for virtual product trials in any environmentThe \"Diffuse to Choose\" (DTC) tool enables customers to virtually place products in their personal spaces to see how they fit and look in real-time. This technology leverages diffusion models for a seamless \"Virtual Try-All\" experience, allowing for the realistic integration of items into any desired setting. DTC's approach overcomes the limitations of traditional image-conditioned diffusion models by retaining high-fidelity details and ensuring accurate semantic manipulations. (Read the news atMaginative)\n\nU.S. targets foreign AI development with new cloud computing security measuresThe Biden administration proposed new regulations for U.S. cloud computing firms to scrutinize foreign access to American data centers. The proposed \"know your customer\" rules would mandate that cloud companies identify and monitor foreign users leveraging U.S. cloud computing resources for AI training, aligning with broader efforts to curb China's access to advanced U.S. technology. (Full story atReuters)\n\nGoogle restructures AI ethics teamGoogle's primary internal AI ethics watchdog, the Responsible Innovation team (RESIN), is undergoing significant restructuring following the departure of its leader, Jen Gennai. RESIN has conducted over 500 project reviews including the Bard chatbot. (Learn more atWired)\n\nCommon Sense Media joins forces with OpenAI to promote safe AI useThe advocate for children and family online safety partnered with OpenAI to enhance the safe and beneficial use of AI. The collaboration aims to develop AI guidelines and educational materials, and to curate a selection of family-friendly GPTs available in the GPT Store, adhering to Common Sense's ratings and standards. (ReadCommon Sense Media’s press release)\n\nGoogle releases Imagen 2The update to Google’s image generator is now available in Bard, ImageFX, Search, and Vertex AI. Developed by Google DeepMind, Imagen 2 addresses challenges like rendering realistic human features and minimizing visual artifacts, offering more detailed and semantically aligned images based on user prompts. Images generated with Imagen 2 feature SynthID watermarks, allowing users to identify AI-generated content. (Learn more atGoogle’s blog)\n\nMastercard launches model to enhance fraud detectionThe model, called Decision Intelligence Pro, was developed in-house by Mastercard's cybersecurity and anti-fraud teams, and is set to improve fraud detection rates by up to 300 percent in certain scenarios, according to the company. Leveraging data from approximately 125 billion annual transactions, the model can discern patterns and predict fraudulent activities by analyzing customer and merchant relationships rather than textual data. (Read the full article atCNBC)\n\nU.S. Federal Communications Commission (FCC) targets AI-generated robocalls with new criminalization measuresFollowing an incident involving a deceptive AI-generated robocall impersonating Joe Biden, the FCC announced plans to criminalize unsolicited robocalls that use AI to mimic human voices.. State attorneys general, empowered by this change, will have greater authority to prosecute AI-facilitated spam activities, as demonstrated by New Hampshire's ongoing investigation into the fake Biden call. (Read more atNBC News)\n\nThe Browser Company launches Arc SearchThis app, evolving from the company's Arc browser project, allows users to input queries and uses AI to compile comprehensive reports and webpages from across the web, streamlining the search process. For example, users can inquire about recent events, like sports games or celebrity news, and receive detailed summaries instead of traditional search results. Arc’s search is powered by OpenAI and other undisclosed models. (Read the news atThe Verge)",
    "qa": [
      {
        "question": "Cơ quan quản lý dữ liệu nào đã đưa ra cáo buộc ChatGPT vi phạm các quy định về quyền riêng tư?",
        "options": {
          "A": "Ủy ban Thương mại Liên bang Hoa Kỳ (FTC)",
          "B": "Cơ quan bảo vệ dữ liệu Ý (Garante)",
          "C": "Cơ quan bảo vệ dữ liệu Liên minh Châu Âu (EDPB)",
          "D": "Cơ quan Tiêu chuẩn Quảng cáo Vương quốc Anh (ASA)"
        },
        "answer": "B"
      },
      {
        "question": "Code Llama 70B của Meta được huấn luyện trên bao nhiêu token mã?",
        "options": {
          "A": "100 tỷ token",
          "B": "250 tỷ token",
          "C": "500 tỷ token",
          "D": "1 nghìn tỷ token"
        },
        "answer": "C"
      },
      {
        "question": "Yelp giới thiệu hơn 20 tính năng hỗ trợ bởi AI nhằm mục đích gì?",
        "options": {
          "A": "Tự động tạo nội dung quảng cáo cho các doanh nghiệp lớn.",
          "B": "Tăng cường khám phá và tương tác với các doanh nghiệp địa phương.",
          "C": "Phân tích dữ liệu người dùng để dự đoán xu hướng thị trường toàn cầu.",
          "D": "Cung cấp dịch vụ tư vấn pháp lý cho các doanh nghiệp nhỏ."
        },
        "answer": "B"
      },
      {
        "question": "Theo Cisco AI Readiness Index, bao nhiêu phần trăm các công ty chưa chuẩn bị để tận dụng tối đa tiềm năng của AI?",
        "options": {
          "A": "56%",
          "B": "73%",
          "C": "86%",
          "D": "97%"
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu chính của AI Lab mới được thành lập bởi Volkswagen Group là gì?",
        "options": {
          "A": "Sản xuất trực tiếp các mẫu xe điện tự hành.",
          "B": "Phát triển nhanh chóng các nguyên mẫu kỹ thuật số để triển khai tiềm năng trên các thương hiệu của công ty.",
          "C": "Cung cấp dịch vụ tư vấn AI cho các công ty sản xuất ô tô khác.",
          "D": "Nghiên cứu các ứng dụng AI trong lĩnh vực năng lượng tái tạo."
        },
        "answer": "B"
      },
      {
        "question": "Dự án sử dụng AI để giảm thời gian phản ứng khẩn cấp ở New York tập trung vào khu vực nào?",
        "options": {
          "A": "Manhattan",
          "B": "Brooklyn",
          "C": "Harlem",
          "D": "Queens"
        },
        "answer": "C"
      },
      {
        "question": "Công cụ 'Diffuse to Choose' (DTC) của Amazon cho phép khách hàng làm gì?",
        "options": {
          "A": "Tự động tạo ra các đánh giá sản phẩm chi tiết.",
          "B": "Thử nghiệm sản phẩm ảo trong không gian cá nhân của họ.",
          "C": "So sánh giá cả sản phẩm từ nhiều nhà cung cấp khác nhau.",
          "D": "Tùy chỉnh thiết kế sản phẩm theo sở thích cá nhân."
        },
        "answer": "B"
      },
      {
        "question": "Chính quyền Biden đề xuất các quy định mới về an ninh điện toán đám mây nhằm mục đích gì?",
        "options": {
          "A": "Thúc đẩy cạnh tranh giữa các công ty điện toán đám mây của Hoa Kỳ.",
          "B": "Kiểm soát quyền truy cập của nước ngoài vào các trung tâm dữ liệu của Hoa Kỳ để đào tạo AI.",
          "C": "Giảm chi phí điện toán đám mây cho các doanh nghiệp nhỏ.",
          "D": "Bảo vệ quyền riêng tư của người dùng điện toán đám mây Hoa Kỳ."
        },
        "answer": "B"
      },
      {
        "question": "Đội ngũ Responsible Innovation team (RESIN) của Google đã thực hiện bao nhiêu đánh giá dự án, bao gồm cả chatbot Bard?",
        "options": {
          "A": "Ít hơn 100",
          "B": "Khoảng 250",
          "C": "Hơn 500",
          "D": "Gần 1000"
        },
        "answer": "C"
      },
      {
        "question": "Ứng dụng Arc Search sử dụng AI để làm gì?",
        "options": {
          "A": "Tự động dịch các trang web sang nhiều ngôn ngữ khác nhau.",
          "B": "Tạo các báo cáo và trang web tổng hợp từ khắp nơi trên web dựa trên truy vấn của người dùng.",
          "C": "Chặn quảng cáo và theo dõi trên các trang web.",
          "D": "Tối ưu hóa tốc độ tải trang web."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-236": {
    "title": "The latest in AI from Feb. 8 to Feb. 14, 2024",
    "collection": "data-points",
    "content": "This week's top AI news and research stories featured ancient scrolls recovered using AI, restrictions on AI robocalls, the extreme energy requirements of GPU data centers, and Würstchen, a system that produced superior images after far less training. But first:\n\n$25 million deepfake heist hits Hong Kong firmScammers apparently used AI to impersonate the company's chief financial officer and other employees during a video conference call, convincing an unsuspecting employee to transfer funds to fraudulent accounts. The Hong Kong police is currently investigating the case, with no arrests made yet. (Read the story atArs Technica)\n\nInvestment advisor Vanguard integrates AI into $13 billion of quant stock fundsVanguard Group incorporated machine learning into four of its active stock funds to refine their factor-based investment strategies. Early signs were positive, with the Vanguard Strategic Equity Fund and Vanguard Strategic Small-Cap Equity Fund outperforming their benchmarks in 2023. (Read the news atBloomberg)\n\nAI lobbying efforts surged by 185 percent in 2023 amid regulatory pushIn 2023, over 450 organizations in the U.S. engaged in lobbying activities related to AI. This includes tech giants, startups, pharmaceuticals, finance, and academia, showing a broad interest in AI's regulatory landscape. This surge in lobbying activity coincides with legislative and executive attempts to regulate AI, with U.S. President Joe Biden’s executive order aiming to establish safety assessments, equity, civil rights guidance, and research into AI's labor market impacts. (Learn more atCNBC)\n\nGoogle collaborates on initiative to certify AI-generated contentThe initiative would identify the origin and any modifications of photos, videos, audio clips, and other digital content, including those altered by AI. Google plans to integrate this digital certification into its products and services, including platforms like YouTube, to help users make more informed decisions about the content they consume. (Find all the details atThe New York Times)\n\nGoogle unveils Gemini chatbot with premium subscriptionGoogle rebranded its Bard chatbot to Gemini and introduced Gemini Advanced, for $19.99 a month, offering enhanced reasoning capabilities powered by the Ultra 1.0 AI model. Subscribers will benefit from two terabytes of cloud storage, typically valued at $9.99 monthly, Google has also promised forthcoming integrations of Gemini into Gmail and Google's productivity suite. (Learn more atReuters)\n\nAmazon launches Rufus, a personal shopping assistantAvailable initially to a select group of users on Amazon’s mobile app, Rufus provides conversational assistance for queries such as comparing products, suggesting gift ideas, and answering specific questions about product features like durability. As Amazon competes with tech counterparts like Microsoft and Google, who have already released chatbots for shopping and search, Rufus represents a move to capture consumers at the exploratory phase of AI in the online retail ecosystem. (Read the story atThe New York Times)\n\nEurope advances toward implementing the AI ActThe AI Act moves towards becoming law, with key holdouts like France and Germany now approving of the act’s provisions. A European Parliament vote is expected in March or April. EU Observers anticipate the act will be officially enacted before summer 2026, with certain provisions taking effect sooner. (Read the latest details about the AI Act atReuters)\n\nWhite House aide Elizabeth Kelly to lead U.S. AI Safety InstituteThe new institute will be part of the National Institute for Standards and Technology. Kelly, who played a significant role in drafting the executive order that established the institute, will oversee development of testing standards to evaluate the AI systems’ safety for consumer and business use. The AI institute, set to finalize these standards by July, aims to foster trust in and facilitate wider adoption of AI technologies by establishing a universal set of safety tests. (Learn more atAP News)\n\nUK commits $125 million (£100 Million) to AI research and regulatory trainingThe bulk of the funding will be allocated to establish nine research hubs to advance AI applications in healthcare, chemistry and mathematics, and to strengthen a partnership with the U.S. on responsible usage. This initiative follows Britain's hosting of an international AI safety summit in November, which led to the signing of the \"Bletchley Declaration\" by over 25 countries aiming to identify and mitigate risks through policy collaboration. (Read more atReuters)\n\nNews site Semafor embraces AI to assist reporters in news curationSemafor launched Signals, a product designed for news aggregation on significant daily stories from around the world. Signals uses an AI-powered search tool named MISO (Multilingual Insight Search Optimizer) to assist reporters in efficiently sourcing a diverse array of news stories and social media content. The final curation and summarization of news remain a human-driven effort. (Read the full article atThe Verge)\n\nU.S. Department of Homeland Security (DHS) expanding use of AI to stop child abuse and drug traffickingThe DHS is set to recruit 50 AI specialists in a bid to strengthen its operations against child exploitation, disrupt fentanyl production, and improve natural disaster damage assessments. Although specific roles were not detailed, the new hires will contribute skills in cybersecurity, data science, and software engineering to support the DHS's mission. The DHS has already used AI to enhance border security drug seizures and to identify victims and perpetrators of sexual abuse. (Read the news atReuters)\n\nHugging Face launches a platform for users to build their own chatbots for free“Hugging Chat Assistant” allows users to customize chatbots using various open source large language models (LLMs), including alternatives like Mistral's Mixtral and Meta's Llama 2, providing a flexible solution for developers. (Find out more atVenture Beat)\n\nU.S. government launches AI safety consortium with top tech companiesThe Biden administration announced the formation of the U.S. AI Safety Institute Consortium (AISIC), an initiative to ensure the safe development and deployment of generative AI. Key focus areas include developing guidelines for red-teaming, capability evaluations, risk management, safety and security, and watermarking synthetic content. Tech partners include Google, Meta, Apple, Microsoft, Open AI, Anthropic, Nvidia, and more. (More details atReuters)\n\nLinkedIn introduces chatbot to streamline job searchesThe chatbot, available for premium users, provides personalized advice on users' suitability for positions and tips to enhance their profiles for better visibility. The tool also answers queries and offers insights by analyzing company profiles and job listing information available on LinkedIn, aiming to make the job-hunting process less daunting. (Read more atWired)",
    "qa": [
      {
        "question": "Vụ lừa đảo deepfake trị giá 25 triệu đô la Mỹ xảy ra ở đâu?",
        "options": {
          "A": "Singapore",
          "B": "Hồng Kông",
          "C": "Thượng Hải",
          "D": "New York"
        },
        "answer": "B"
      },
      {
        "question": "Tổ chức nào đã tích hợp AI vào các quỹ đầu tư định lượng trị giá 13 tỷ đô la?",
        "options": {
          "A": "BlackRock",
          "B": "Fidelity",
          "C": "Vanguard Group",
          "D": "State Street"
        },
        "answer": "C"
      },
      {
        "question": "Trong năm 2023, hoạt động vận động hành lang liên quan đến AI ở Hoa Kỳ đã tăng bao nhiêu phần trăm?",
        "options": {
          "A": "50%",
          "B": "100%",
          "C": "150%",
          "D": "185%"
        },
        "answer": "D"
      },
      {
        "question": "Google đang hợp tác trong một sáng kiến để chứng nhận nội dung được tạo ra bởi AI, nhằm mục đích chính gì?",
        "options": {
          "A": "Tăng tốc độ tải nội dung",
          "B": "Xác định nguồn gốc và sửa đổi của nội dung",
          "C": "Giảm chi phí sản xuất nội dung",
          "D": "Tăng cường bảo mật dữ liệu cá nhân"
        },
        "answer": "B"
      },
      {
        "question": "Gemini Advanced của Google có giá bao nhiêu mỗi tháng?",
        "options": {
          "A": "$9.99",
          "B": "$14.99",
          "C": "$19.99",
          "D": "$24.99"
        },
        "answer": "C"
      },
      {
        "question": "Rufus, trợ lý mua sắm cá nhân của Amazon, ban đầu được cung cấp cho đối tượng nào?",
        "options": {
          "A": "Tất cả người dùng Amazon Prime",
          "B": "Một nhóm người dùng được chọn trên ứng dụng di động của Amazon",
          "C": "Người dùng Amazon Business",
          "D": "Người dùng đăng ký chương trình Amazon Vine"
        },
        "answer": "B"
      },
      {
        "question": "Theo dự kiến, Đạo luật AI của Châu Âu sẽ chính thức có hiệu lực trước thời điểm nào?",
        "options": {
          "A": "Mùa đông 2025",
          "B": "Mùa xuân 2026",
          "C": "Mùa hè 2026",
          "D": "Mùa thu 2026"
        },
        "answer": "C"
      },
      {
        "question": "Elizabeth Kelly sẽ lãnh đạo tổ chức nào của Hoa Kỳ liên quan đến AI?",
        "options": {
          "A": "Cục Điều tra Liên bang (FBI)",
          "B": "Viện An toàn AI Hoa Kỳ",
          "C": "Cơ quan Quản lý Thực phẩm và Dược phẩm (FDA)",
          "D": "Cục Dự trữ Liên bang (FED)"
        },
        "answer": "B"
      },
      {
        "question": "Vương quốc Anh cam kết bao nhiêu tiền cho nghiên cứu AI và đào tạo quy định?",
        "options": {
          "A": "$50 triệu (£40 triệu)",
          "B": "$75 triệu (£60 triệu)",
          "C": "$100 triệu (£80 triệu)",
          "D": "$125 triệu (£100 triệu)"
        },
        "answer": "D"
      },
      {
        "question": "Công cụ MISO (Multilingual Insight Search Optimizer) được sử dụng bởi Semafor để làm gì?",
        "options": {
          "A": "Tự động viết báo cáo tin tức",
          "B": "Dịch tin tức sang nhiều ngôn ngữ",
          "C": "Hỗ trợ các phóng viên tìm kiếm và tổng hợp tin tức",
          "D": "Xác minh tính xác thực của tin tức"
        },
        "answer": "C"
      }
    ]
  },
  "data-points-issue-237": {
    "title": "The latest in AI from Feb. 15 to Feb. 21, 2024",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeaturedOpenAI's Sora, Huawei's AI chips, an AI system to double-check judges' decisions in competitive gymnastics, and Würstchen, and a way to reduce memory requirements when fine-tuning large language models. But first:\n\nGemini 1.5 boasts superior data handling and efficiencyGemini 1.5 Pro, the latest upgrade to Google’s Gemini model, can process large volumes of data across various formats, including video, text, and images. Gemini 1.5 Pro can manage inputs up to 128,000 tokens, matching the capabilities of GPT-4 Turbo, but an exclusive version available to a limited group of developers can reliably process up to 1 million tokens. In tests, Google claims Gemini 1.5 can handle a context window of 10 million tokens – the equivalent of 7 million words or 10 hours of video. This new iteration, currently only in preview to select developers and business customers, also employs a Mixture-of-Experts architecture that’s new to Gemini.  Its broader release date remains unspecified. (Read more atMIT Technology Review)\n\nGlobal hackers use OpenAI for cyber operations, report saysResearch jointly released by OpenAI and Microsoft claims to show that hacking groups with ties to China, Russia, and North Korea have used OpenAI’s technology for routine tasks such as drafting emails, translating documents, and debugging code rather than for creating advanced cyberattacks. The two companies documented the use by five specific hacking groups and have since revoked the groups’ access to the technology. (Read the news atThe New York Times)\n\nChicago to discontinue use of gunshot detection technology amid criticismChicago announced plans to not renew its contract with SoundThinking for the ShotSpotter gunshot detection system, citing concerns over the technology's accuracy, racial bias, and misuse by law enforcement. The decision comes after a $49 million investment in the system since 2018 and an Associated Press investigation highlighting its problematic use in legal cases. (Read the news atAP)\n\nOpenAI enhances ChatGPT with advanced memory features for personalized conversationsThe upgrade makes the chatbot capable of recalling details from previous conversations, such as personal preferences and specific instructions. For example, if a user shares information about a family member, ChatGPT can incorporate these details into relevant tasks, like crafting personalized birthday cards. The update also introduces \"temporary chats,\" where conversations and memories are not stored, addressing potential privacy concerns. (Read more atThe New York Times)\n\nTech giants unite to combat AI-driven election interferenceIn an initiative announced at the Munich Security Conference, 20 leading technology companies, including OpenAI, Meta, Microsoft, Adobe, and TikTok, pledged to collaborate to thwart election interference. Initiatives include the development of detection tools for deceptive AI-generated content, public awareness campaigns to educate voters about misinformation, and measures to eliminate harmful content from the companies’ platforms. The accord lacks specific timelines or implementation details. (Learn more atReuters)\n\nFTC moves to ban AI impersonation of individualsThe Federal Trade Commission (FTC) proposed rules that prohibit the use of AI to impersonate individuals. This proposal aims to broaden an existing rule that already forbids the impersonation of businesses and government agencies, extending similar protections to individuals. (Find the details atThe Wall Street Journal)\n\nGoogle to establish AI hub in France, according to the French Finance MinistrySituated in Paris, the hub would accommodate approximately 300 researchers and engineers, emphasizing the country's ambitions to rival traditional tech powerhouses like the U.S. and the UK. The announcement was made by the French Finance Ministry. (Read more atReuters)\n\nAI revives voices of children lost to gun violence in emotional campaignThe initiative aims to influence lawmakers on gun safety laws. This campaign features automated calls to legislators, voiced by AI-generated replicas of the deceased children developed by ElevenLabs' AI voice generator. These calls began on the sixth anniversary of the Parkland school shooting as part of a broader effort to advocate for gun control. (Read the story atThe Wall Street Journal)\n\nAI Pioneer Andrej Karpathy leaves OpenAIIn a recent social media post, Karpathy revealed that he left OpenAI to focus on his personal projects. Karpathy’s exit is notable, given his significant contributions to the development of advanced AI technologies both at OpenAI and during his tenure as a senior director for AI at Tesla. (Read more atReuters)\n\nKhan Academy’s chatbot faces challenges in solving basic math problemsDespite the ambitious vision shared by Sal Khan, founder of Khan Academy, during a TED Talk about AI transforming education, a test by a Wall Street Journal reporter revealed that Khanmigo, powered by ChatGPT, frequently made errors in simple arithmetic operations and struggled with mathematical concepts like rounding and calculating square roots. (Learn more atThe Wall Street Journal)\n\nRomantic chatbots raise privacy and security concerns, Mozilla Foundation warnsThese applications, which have amassed over 100 million downloads on Android alone, are collecting vast amounts of personal data from users, employing trackers that send information to third parties like Google and Facebook, and lack robust password protection measures. Mozilla’s investigation scrutinized 11 romance and companion chatbots, revealing their use of weak security practices, vague data usage policies, and general opacity about their operational and ownership details. (Read the news atWired)\n\nUS Patent and Trademark Office (USPTO) clarifies AI cannot be listed as inventor on patentsThis decision comes after public consultations and reinforces the stance that only \"natural persons\" can hold patents. However, the USPTO acknowledges that AI can play a role in the invention process, stipulating that human inventors must disclose any AI assistance in their patent applications. This policy update follows legal precedents, including a 2020 ruling against researcher Stephen Thaler, who sought to name his AI system, DABUS, as an inventor. (Full article available atThe Verge)\n\nA deep dive into the energy consumption of AI modelsAI models are known to consume vast amounts of electricity, yet calculating their exact energy footprint remains elusive. Training a model is particularly energy-intensive, potentially using as much electricity as 130 US homes annually. The broader impact of AI on global electricity consumption is also a concern, with estimates suggesting AI could account for a substantial portion of worldwide energy demand by 2027, comparable to the annual energy usage of entire countries. (Read the report atThe Verge)",
    "qa": [
      {
        "question": "Gemini 1.5 Pro có khả năng xử lý tối đa bao nhiêu token trong phiên bản giới hạn dành cho nhà phát triển?",
        "options": {
          "A": "128,000 tokens",
          "B": "1,000,000 tokens",
          "C": "10,000,000 tokens",
          "D": "7,000,000 tokens"
        },
        "answer": "B"
      },
      {
        "question": "Theo báo cáo của OpenAI và Microsoft, các nhóm hacker sử dụng công nghệ AI chủ yếu cho mục đích gì?",
        "options": {
          "A": "Tạo ra các cuộc tấn công mạng phức tạp",
          "B": "Soạn thảo email, dịch tài liệu và gỡ lỗi code",
          "C": "Xâm nhập vào hệ thống an ninh mạng của chính phủ",
          "D": "Phát triển phần mềm độc hại mới"
        },
        "answer": "B"
      },
      {
        "question": "Thành phố Chicago quyết định ngừng sử dụng hệ thống ShotSpotter vì lý do chính nào?",
        "options": {
          "A": "Chi phí đầu tư quá cao",
          "B": "Tính chính xác, thiên vị chủng tộc và lạm dụng bởi cơ quan thực thi pháp luật",
          "C": "Hệ thống không hiệu quả trong việc giảm tội phạm súng đạn",
          "D": "Công nghệ đã lỗi thời và không còn được hỗ trợ"
        },
        "answer": "B"
      },
      {
        "question": "Tính năng mới nào của ChatGPT giúp chatbot ghi nhớ thông tin từ các cuộc trò chuyện trước đó?",
        "options": {
          "A": "Chế độ 'temporary chats'",
          "B": "Khả năng lưu trữ chi tiết cá nhân và hướng dẫn cụ thể",
          "C": "Tích hợp với các ứng dụng bên thứ ba",
          "D": "Khả năng tạo ra các cuộc trò chuyện ngẫu nhiên"
        },
        "answer": "B"
      },
      {
        "question": "Những biện pháp nào được các công ty công nghệ lớn cam kết thực hiện để chống lại sự can thiệp bầu cử do AI gây ra?",
        "options": {
          "A": "Phát triển các loại vũ khí mạng mới",
          "B": "Phát triển công cụ phát hiện nội dung do AI tạo ra, nâng cao nhận thức cộng đồng và loại bỏ nội dung độc hại",
          "C": "Hạn chế quyền tự do ngôn luận trên mạng",
          "D": "Tăng cường giám sát người dùng trên mạng xã hội"
        },
        "answer": "B"
      },
      {
        "question": "FTC đề xuất quy tắc mới nào liên quan đến việc sử dụng AI?",
        "options": {
          "A": "Cấm sử dụng AI trong quảng cáo",
          "B": "Cấm sử dụng AI để mạo danh cá nhân",
          "C": "Yêu cầu các công ty AI phải công khai thuật toán của họ",
          "D": "Đánh thuế cao đối với các sản phẩm AI"
        },
        "answer": "B"
      },
      {
        "question": "Google dự định thành lập trung tâm AI ở quốc gia nào?",
        "options": {
          "A": "Hoa Kỳ",
          "B": "Vương quốc Anh",
          "C": "Pháp",
          "D": "Đức"
        },
        "answer": "C"
      },
      {
        "question": "Chiến dịch sử dụng giọng nói AI của trẻ em đã mất do bạo lực súng đạn nhằm mục đích gì?",
        "options": {
          "A": "Tưởng nhớ các nạn nhân của bạo lực súng đạn",
          "B": "Gây quỹ cho các tổ chức từ thiện",
          "C": "Tác động đến các nhà lập pháp về luật an toàn súng đạn",
          "D": "Nâng cao nhận thức về vấn đề bạo lực súng đạn"
        },
        "answer": "C"
      },
      {
        "question": "Andrej Karpathy rời OpenAI để làm gì?",
        "options": {
          "A": "Chuyển sang làm việc cho Google",
          "B": "Tập trung vào các dự án cá nhân",
          "C": "Thành lập công ty AI riêng",
          "D": "Nghỉ hưu"
        },
        "answer": "B"
      },
      {
        "question": "Theo USPTO, ai hoặc cái gì có thể được liệt kê là người phát minh trên bằng sáng chế?",
        "options": {
          "A": "Chỉ có 'người tự nhiên'",
          "B": "Chỉ có AI",
          "C": "Cả 'người tự nhiên' và AI",
          "D": "Bất kỳ thực thể nào đóng góp vào quá trình phát minh"
        },
        "answer": "A"
      }
    ]
  },
  "data-points-issue-239": {
    "title": "The latest in AI from Feb. 29 to Mar. 6, 2024",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeaturedMistral's new LLMs, a robot chemist, Google's open source LLMs, and a way to make LLMs better at math. But first:\n\nAnthropic’s Claude 3 model family shines on metricsThe largest of the new models, called Opus, outperforms GPT-4 on language reasoning and rivals Gemini 1.0 on visual reasoning tasks. All three of the models (Haiku and Sonnet) have a accept inputs up to 200k tokens by default, but have been tested at up to 1M tokens, available in special cases. All three are also more accurate and less likely to refuse prompts that bump up against the system’s guardrails. (See more atClaude)\n\nElon Musk sues OpenAI for breach of contractMusk, who cofounded OpenAI before acrimoniously leaving the company in 2018, argues that the company violated its founding agreement by seeking to develop AGI for profit. OpenAI’s executives in turn argue that Musk wanted to convert OpenAI into a commercial entity in partnership with his own company, Tesla. Musk’s suit relies on informal email communications that legal experts say are unlikely to constitute a binding contract. (Read the story atReuters)\n\nUK government experiments with AI to streamline ministerial workloadsThe 'red box' tools, referencing the traditional ministerial work cases, will automate the drafting process for answering parliamentary questions while ensuring human oversight and source citation for verification. A tool to process public consultation responses is also being trialed. The government also plans an AI collaboration charter with the NHS to explore further applications in healthcare, including diagnostics and prescription management. (Read more atFinancial Times)\n\nCalifornia pauses Waymo's robotaxi expansion plansWaymo's ambitions to broaden its robotaxi service into Los Angeles and San Mateo counties encountered a roadblock.The California Public Utilities Commission (CPUC) suspended the application for 120 days due to the need for additional staff review. The CPUC describes the suspension as a routine part of their review process, though local officials have expressed concerns about public safety based on robotaxi experiences in San Francisco. (Read the news atTechCrunch)\n\nMerging ChatGPT with robotics sparks concernsScientists are integrating the capabilities of ChatGPT into robots, aiming to transcend traditional robotics limitations and introduce flexibility and adaptability in tasks ranging from industrial patrols to culinary preparations. But this integration is not without its challenges and ethical dilemmas. The practical difficulties of programming robots to handle the unpredictability of real-world scenarios are compounded by concerns over AI's reliability, potential for bias, and privacy issues. (Read the full report atScientific American)\n\nMicrosoft launches Copilot for FinanceJoining Copilot for Sales and Copilot for Service, Copilot for Finance automates workflows, provides insights, and facilitates decision-making processes in finance departments. The tool aims to alleviate the burden of data entry and review cycles that currently consume 62 percent of finance professionals' time. It integrates with existing financial data sources and ERP systems like Microsoft Dynamics 365 and SAP, offering features such as variance analysis, reconciliation processes, and generating presentation-ready visuals and reports. (Read Microsoft’sblog)\n\nOpenAI and robot-maker Figure forge partnershipThe collaboration is bolstered by $675 million in venture capital funding from a consortium of investors, including Amazon founder Jeff Bezos, and the investment arms of Intel and OpenAI itself. Figure, a relatively new player in the tech scene with ambitious plans but no commercial product yet, has captured the attention and support of tech industry heavyweights with its vision of deploying billions of human-like robots in both workplaces and homes globally. (Read the article atAP News)\n\nLaurie Anderson creates chatbot that mimics the style of late husband Lou ReedThe project, part of Anderson's \"I’ll Be Your Mirror\" exhibition, draws on Reed's extensive body of work to generate text responses that reflect his unique voice. Collaborating with the University of Adelaide’s Australian Institute for Machine Learning, Anderson embraced this technology as a tool for artistic exploration and expression. (Read the details atThe Guardian)\n\nUK and France announce AI collaboration initiativesThe partnership includes £800,000 in joint funding to enhance UK-French research projects and a new partnership focused on AI safety. The initiatives support the safe development of AI and seek to boost research in fields like quantum technology and low-carbon hydrogen. These efforts are part of a broader strategy to leverage scientific research for global advancement and demonstrate a commitment to international cooperation in science and technology. (Read the UK Government’spress release)\n\nResearch: GPT-4 demonstrates superior diagnostic skills in eye careResearchers showed that GPT-4 can match or even exceed the diagnostic capabilities of human eye specialists. The study compared GPT-4’s responses with those of 12 attending specialists and three senior trainees. The evaluation covered a diverse set of 20 ophthalmology questions and 20 patient cases, focusing on glaucoma and retina disorders, to assess the AI's accuracy and completeness of responses. The study revealed that GPT-4's responses were more comprehensive than those of the human specialists, particularly in the field of glaucoma. (Learn more atDaily.AI)\n\nAn AI model could enhance efficiency in robotic warehousesThe approach addresses the challenge of coordinating hundreds of robots without collisions, outperforming traditional path-finding algorithms. By dividing the warehouse into smaller sections, the model employs a neural network architecture that encodes detailed information about the warehouse layout, robot paths, and obstacles, to quickly identify and alleviate traffic congestion among robots. In tests, the model achieved up to four times faster decongestion than conventional methods. (More details atMIT News)\n\nAdobe previews an AI audio toolProject Music GenAI Control will allow users to generate music based on text prompts, while also offering extensive editing controls. Aimed at content creators in need of customized audio, the tool will provide an interface for transforming audio with fine-grained adjustments, including tempo, structure, intensity, and more. (Read Adobe’sblog)\n\nU.S. Securities and Exchange Commission (SEC) probes OpenAI for potential investor misguidanceThe government agency is investigating OpenAI CEO Sam Altman's internal communications to determine if investors were misled, as part of an inquiry into Altman’s brief ouster last year for what board members called lack of candor. The investigation emerges amidst OpenAI's recent $80 billion valuation after a tender offer and intensifying global scrutiny over its practices and partnership with Microsoft. (Read the story atThe Wall Street Journal)\n\nGoogle partners with Stack Overflow to integrate knowledge base into GeminiA new API, named OverflowAPI, will enable Google to incorporate validated Stack Overflow answers directly into the Google Cloud console, enhancing the Gemini service for Google Cloud. The partnership also explores using Google's Vertex AI platform to bring AI assistance to Stack Overflow's question-asking and moderation processes. (Read more atTechCrunch)\n\nAI uncovers reasons behind humpback whale deathsA study published in Royal Society Open Science revealed a dramatic decline in the North Pacific humpback whale population, with approximately 7,000 whales dying between 2012 and 2021. This decline, accounting for a 20 percent reduction in population, is attributed to a prolonged marine heatwave that began in 2013. Researchers claim their use of AI technology to automatically recognize over 30,000 individual humpback whales across more than 200,000 encounters marked a significant advancement in marine research, enabling an unprecedented scale of data analysis. (Get the details atABC News)\n\nEleutherAI introduces guide for foundation model developmentEleutherAI, in collaboration with several leading research institutions and AI organizations, launched \"The Foundation Model Development Cheatsheet,\" a resource aimed at guiding developers through the process of building AI models. (Read EleutherAI’s press release and access the cheatsheethere)",
    "qa": [
      {
        "question": "Mô hình Claude 3 Opus của Anthropic vượt trội GPT-4 ở khía cạnh nào?",
        "options": {
          "A": "Tốc độ xử lý dữ liệu đầu vào.",
          "B": "Khả năng suy luận ngôn ngữ.",
          "C": "Khả năng tạo ra hình ảnh chân thực.",
          "D": "Khả năng từ chối các yêu cầu vi phạm nguyên tắc an toàn."
        },
        "answer": "B"
      },
      {
        "question": "Lý do chính Elon Musk kiện OpenAI là gì?",
        "options": {
          "A": "OpenAI sử dụng trái phép công nghệ của Tesla.",
          "B": "OpenAI vi phạm thỏa thuận ban đầu bằng cách phát triển AGI vì lợi nhuận.",
          "C": "Elon Musk không được chia lợi nhuận từ các sản phẩm của OpenAI.",
          "D": "OpenAI từ chối hợp tác với Tesla trong lĩnh vực xe tự lái."
        },
        "answer": "B"
      },
      {
        "question": "Chính phủ Anh đang thử nghiệm AI để làm gì trong công việc của các bộ trưởng?",
        "options": {
          "A": "Tự động hóa việc đưa ra quyết định chính sách.",
          "B": "Tự động hóa việc soạn thảo câu trả lời cho các câu hỏi của quốc hội.",
          "C": "Tự động hóa việc quản lý ngân sách quốc gia.",
          "D": "Tự động hóa việc giao tiếp với công dân qua mạng xã hội."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao California tạm dừng kế hoạch mở rộng dịch vụ robotaxi của Waymo?",
        "options": {
          "A": "Do thiếu kinh phí để triển khai dịch vụ.",
          "B": "Do phản đối từ các công ty taxi truyền thống.",
          "C": "Do cần thêm thời gian để nhân viên xem xét và đánh giá.",
          "D": "Do lo ngại về tác động môi trường của robotaxi."
        },
        "answer": "C"
      },
      {
        "question": "Một trong những thách thức chính khi tích hợp ChatGPT vào robot là gì?",
        "options": {
          "A": "Chi phí phần cứng quá cao.",
          "B": "Khó khăn trong việc lập trình robot để xử lý các tình huống thực tế khó đoán.",
          "C": "Tốc độ xử lý ngôn ngữ của ChatGPT quá chậm.",
          "D": "Robot không đủ mạnh để chạy các mô hình AI phức tạp."
        },
        "answer": "B"
      },
      {
        "question": "Copilot for Finance của Microsoft giúp ích gì cho các chuyên gia tài chính?",
        "options": {
          "A": "Tự động hóa việc tuyển dụng nhân viên tài chính.",
          "B": "Giảm bớt gánh nặng nhập liệu và chu kỳ xem xét dữ liệu.",
          "C": "Dự đoán chính xác biến động thị trường chứng khoán.",
          "D": "Tự động hóa việc kiểm toán tài chính."
        },
        "answer": "B"
      },
      {
        "question": "Công ty Figure, hợp tác với OpenAI, có kế hoạch gì?",
        "options": {
          "A": "Phát triển phần mềm quản lý doanh nghiệp dựa trên AI.",
          "B": "Triển khai hàng tỷ robot giống người trong nơi làm việc và nhà ở.",
          "C": "Xây dựng trung tâm dữ liệu AI lớn nhất thế giới.",
          "D": "Nghiên cứu về trí tuệ nhân tạo tổng quát (AGI)."
        },
        "answer": "B"
      },
      {
        "question": "Laurie Anderson tạo ra chatbot mô phỏng ai?",
        "options": {
          "A": "Andy Warhol.",
          "B": "David Bowie.",
          "C": "Lou Reed.",
          "D": "John Lennon."
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu chính của các sáng kiến hợp tác về AI giữa Anh và Pháp là gì?",
        "options": {
          "A": "Phát triển vũ khí AI tiên tiến.",
          "B": "Tăng cường an toàn AI và thúc đẩy nghiên cứu khoa học.",
          "C": "Cạnh tranh với các cường quốc AI khác.",
          "D": "Kiểm soát thị trường AI toàn cầu."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu cho thấy GPT-4 thể hiện khả năng chẩn đoán vượt trội trong lĩnh vực nào?",
        "options": {
          "A": "Tim mạch.",
          "B": "Ung thư.",
          "C": "Nhãn khoa.",
          "D": "Thần kinh học."
        },
        "answer": "C"
      }
    ]
  },
  "data-points-issue-238": {
    "title": "The latest in AI from Feb. 22 to Feb. 28, 2024",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeaturedGoogle's troubled Gemini launch, OpenAI's next act, Groq's blazing inference speed, and a method for faster network pruning. But first:\n\nAir Canada ordered to uphold chatbot's discount promiseA Canadian tribunal ordered the airline to compensate a passenger over $600 for not honoring a bereavement fare discount promised by its chatbot. Jake Moffatt, who was booking a last-minute flight for his grandmother's funeral, was misled by the chatbot into believing he could receive a reduced fare under Air Canada's bereavement policy after purchasing his ticket. The airline's defense that the chatbot was a \"separate legal entity\" and not liable for the misinformation was rejected by the tribunal. (Read the news atThe Washington Post)\n\nResearch: Baby's eye-view footage trains AIResearch demonstrated an approach to language learning using just 61 hours of video and audio recorded from a baby's perspective. This study challenges the notion that massive datasets are essential for AI to understand and acquire language. By analyzing the world through the eyes and ears of a toddler, scientists were able to train a basic AI model to associate images with words, mirroring early human language acquisition. The findings, published inScience, suggest that language learning, both human and machine, might be achievable with far less data than previously believed. (Learn more atScientific American)\n\nAI dominates 2024 tech landscape, IEEE study predictsA global survey by the Institute of Electrical and Electronics Engineers (IEEE) underscores the pivotal role of AI in driving technological progress this year. Conducted among 350 technology leaders worldwide, the study identifies AI, along with its branches like machine learning and natural language processing, as the most critical technology sector. Additionally, the advent of 5G networks and advancements in quantum computing are expected to further fuel AI's growth. (Read more atVentureBeat)\n\nU.S. Justice Department appoints first Chief AI officerThe officer’s role will involve advising on the integration of AI in investigations and criminal prosecutions, assessing the technology's ethical and effective use, and leading a board to guide the Justice Department on AI-related matters. (Find more details atReuters)\n\nAI in healthcare innovation outpaces regulationThe rapid advancement of AI technologies in healthcare has outpaced the ability of regulatory bodies like the U.S. Food and Drug Administration (FDA) to establish and enforce guidelines. The FDA has expressed a desire for more authority to actively monitor AI products over time and to establish more specific safeguards for algorithms. However, obtaining the necessary powers from Congress seems unlikely in the near term, given the legislative body's historical reluctance to expand the FDA's regulatory reach. (Read the full report atPolitico)\n\nReddit enters into a $60 million annual deal with GoogleThe agreement allows the use of Reddit's vast content for training AI models. With over $800 million in revenue last year, marking a 20% increase from 2022, Reddit aims to capitalize on this AI wave to enhance its market position. Google, meanwhile, gets privileged access to Reddit’s archive of social content. (Learn more atReuters)\n\nA startup’s pioneering approach to ethical AI pornMyPeach.ai, founded by Ashley Neale, a former stripper turned tech entrepreneur, leverages AI to simulate romantic and sexual interactions while imposing strict ethical guidelines to prevent abuse. The platform provides an immersive experience and sets boundaries around user interactions, ensuring that virtual engagements promote consent and respect. (Read the story atThe Guardian)\n\nSingapore to invest $1 billion in AI development over the next five yearsAnnounced by Deputy Prime Minister and Finance Minister Lawrence Wong, the investment aims at advancing AI compute, talent, and industry development, with a focus on securing access to advanced chips essential for AI deployment. The initiative also includes establishing AI centers of excellence to foster collaboration, innovation, and value creation across the economy. (Read more atThe Straits Times)\n\nAdobe announces AI assistant for Reader and AcrobatThe tool formats information and generates summaries and insights from PDF files, emails, reports, and presentations. Adobe plans to expand AI Assistant's capabilities beyond individual PDFs, including insights across multiple documents and intelligent document collaboration. The AI Assistant features are available in beta for Acrobat Standard and Pro Individual and Teams plans on desktop and web in English. The AI Assistant’s features are planned to extend to Adobe Reader desktop customers in the coming weeks at no additional cost. (Read Adobe’sblog)\n\nAI-generated biographies flood the market after celebrity deathsThese books, often filled with factual inaccuracies and grammatical errors, seem to exploit the public's interest in recently deceased figures for quick profit. Tools like GPTZero suggest a high likelihood that these biographies are AI-generated, raising questions about the ethical implications and quality control of such publications. (Get all the details atThe New York Times)\n\nGoogle DeepMind forms dedicated AI safety and alignment divisionThis initiative comes as Google tackles the challenges posed by generative AI models like Gemini, which have demonstrated a capacity to generate deceptive content. The new organization will encompass existing and new teams dedicated to ensuring the safety of AI systems, including a special focus on developing safeguards for artificial general intelligence (AGI) systems capable of performing any human task. (Learn more atTechCrunch)\n\nStability AI announces Stable Diffusion 3 (SD3)Unlike its predecessors and proprietary counterparts like OpenAI's DALL-E, SD3 enables users to run and modify it on a wide range of devices. With a capacity ranging from 800 million to 8 billion parameters, SD3 aims to deliver strong prompt fidelity, even on compact devices. Although a public demo is currently unavailable, Stability has initiated a waitlist for early access. (Read more atArs Technica)\n\nChatGPT suffered a glitch, generated bizarre responsesReports of ChatGPT \"having a stroke\" and \"going insane\" flooded Reddit last week. OpenAI's statement revealed the problem stemmed from a bug introduced in an optimization update, leading to incorrect word sequence generation due to a misstep in numerical token selection. This incident reignited discussions on the reliability of closed versus open-source AI models, with some advocating for the latter's transparency and fixability. (Learn more atArs Technica)\n\nAutonomous racing paves the way for safer driverless vehiclesThe emerging field of autonomous auto racing aims to solve complex challenges that autonomous vehicles face in real-world conditions, such as rapid decision-making and precise maneuvering. The University of Virginia's Cavalier Autonomous Racing team showcased its prowess by securing second place at the Indy Autonomous Challenge nitiatives like the F1tenth Autonomous Racing Grand Prix further demonstrate the potential of autonomous racing as both an educational tool and a platform for global collaboration in refining AI algorithms. (Read the story atThe Conversation)",
    "qa": [
      {
        "question": "Hãng hàng không Air Canada đã bị yêu cầu bồi thường cho hành khách vì lý do gì?",
        "options": {
          "A": "Hành khách bị lỡ chuyến bay do lỗi hệ thống.",
          "B": "Chatbot của hãng hứa hẹn giảm giá vé nhưng không thực hiện.",
          "C": "Hành khách bị tính sai giá vé do lỗi của nhân viên.",
          "D": "Hành khách không được hỗ trợ khi có người thân qua đời."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu về học ngôn ngữ của AI sử dụng dữ liệu từ đâu?",
        "options": {
          "A": "Các bộ phim hoạt hình dành cho trẻ em.",
          "B": "Các cuộc trò chuyện giữa người lớn và trẻ em.",
          "C": "Video và âm thanh ghi lại từ góc nhìn của trẻ sơ sinh.",
          "D": "Sách giáo khoa dành cho trẻ em."
        },
        "answer": "C"
      },
      {
        "question": "Theo khảo sát của IEEE, công nghệ nào được coi là quan trọng nhất trong năm 2024?",
        "options": {
          "A": "Công nghệ thực tế ảo (VR).",
          "B": "Trí tuệ nhân tạo (AI).",
          "C": "Công nghệ blockchain.",
          "D": "Internet of Things (IoT)."
        },
        "answer": "B"
      },
      {
        "question": "Bộ Tư pháp Hoa Kỳ bổ nhiệm chức danh nào liên quan đến AI?",
        "options": {
          "A": "Giám đốc điều hành AI (AI CEO).",
          "B": "Chuyên gia tư vấn AI (AI Consultant).",
          "C": "Giám đốc AI (Chief AI Officer).",
          "D": "Nhà khoa học trưởng về AI (Chief AI Scientist)."
        },
        "answer": "C"
      },
      {
        "question": "Vấn đề chính được đề cập liên quan đến AI trong lĩnh vực chăm sóc sức khỏe là gì?",
        "options": {
          "A": "Chi phí triển khai AI quá cao.",
          "B": "Sự phát triển của AI vượt xa khả năng quản lý và quy định.",
          "C": "Thiếu hụt nhân lực có kỹ năng sử dụng AI.",
          "D": "AI chưa đủ chính xác để đưa ra các quyết định quan trọng."
        },
        "answer": "B"
      },
      {
        "question": "Reddit đạt được thỏa thuận trị giá 60 triệu đô la mỗi năm với công ty nào?",
        "options": {
          "A": "Microsoft.",
          "B": "Amazon.",
          "C": "Meta.",
          "D": "Google."
        },
        "answer": "D"
      },
      {
        "question": "MyPeach.ai là một startup tiên phong trong lĩnh vực nào?",
        "options": {
          "A": "AI tạo sinh âm nhạc.",
          "B": "AI trong giáo dục trực tuyến.",
          "C": "AI tạo sinh nội dung khiêu dâm có đạo đức.",
          "D": "AI trong phân tích dữ liệu tài chính."
        },
        "answer": "C"
      },
      {
        "question": "Singapore sẽ đầu tư 1 tỷ đô la vào lĩnh vực AI trong bao nhiêu năm tới?",
        "options": {
          "A": "3 năm.",
          "B": "5 năm.",
          "C": "7 năm.",
          "D": "10 năm."
        },
        "answer": "B"
      },
      {
        "question": "Adobe AI Assistant có chức năng chính nào?",
        "options": {
          "A": "Tự động tạo bản trình bày PowerPoint.",
          "B": "Định dạng thông tin và tạo tóm tắt từ các tệp PDF.",
          "C": "Dịch văn bản sang nhiều ngôn ngữ khác nhau.",
          "D": "Chỉnh sửa ảnh và video một cách tự động."
        },
        "answer": "B"
      },
      {
        "question": "Sự cố gần đây với ChatGPT được mô tả như thế nào?",
        "options": {
          "A": "ChatGPT bị tấn công bởi hacker.",
          "B": "ChatGPT đưa ra các phản hồi kỳ lạ do lỗi trong quá trình cập nhật.",
          "C": "ChatGPT bị quá tải do lượng truy cập tăng đột biến.",
          "D": "ChatGPT bị tạm ngừng hoạt động để bảo trì."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-240": {
    "title": "The latest in AI from Mar. 7 to Mar. 13, 2024",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeaturedAnthropic's new multimodal models, India's warning to devs, Google's generative news tools, and an agent that learns language by exploration. But first:\n\nEuropean Parliament approves AI ActRepresentatives in the European Union overwhelmingly approved a sweeping set of regulations of artificial intelligence models and applications. The legislation takes a risk-based approach to regulation, with higher risk applications like medical use or critical infrastructure facing a higher level of scrutiny than low-risk applications like spam filters. Some applications, like predictive policing and police facial recognition, are banned in most instances. The Act will still need to be approved by Europe’s 27 member states, but this is largely seen as a formality. (Read about the AI Act at theAssociated Press)\n\nAMD faces regulatory hurdle with US for China-specific AI chipAMD reportedly encountered a regulatory obstacle from US authorities in its development of an AI chip intended for the Chinese market. According to Bloomberg, the chip, designed to adhere to US export restrictions by offering lower performance than AMD's premium offerings, did not receive clearance from the Commerce Department due to its advanced capabilities. AMD will now need to secure an export license to proceed. (Read the news atCNBC)\n\nLeading AI researchers urge tech giants to open up for independent evaluationsOver 100 AI researchers, including academics and journalists, signed an open letter demanding that firms like OpenAI and Meta permit independent evaluations of their technologies. The signatories argue that the companies' stringent measures to prevent misuse are inadvertently stifling critical safety research. The letter calls for a \"safe harbor\" that would protect researchers seeking to audit AI systems for potential risks and biases, without fear of legal repercussions or account bans. (Read the story atThe Washington Post)\n\nEdelman Trust Barometer reveals deep concerns over AI management and innovationThe 2024 Edelman Trust Barometer highlights a growing concern among citizens in 28 markets regarding the management of innovation, particularly AI. The study reveals that innovation, seen as poorly managed by a nearly two-to-one margin, is stoking fears of impact on jobs, privacy violations, and lifestyle changes. This discontent is contributing to a wider \"populist fire,\" already fueled by distrust in government, authority dispersion, and trust divides. (Read the full report atEdelman)\n\nPatronus AI introduces a copyright detection API for large language modelsCopyrightCatcher aims to mitigate the risk of copyright infringement in language models' outputs. Recent adversarial tests conducted by Patronus AI researchers revealed that leading LLMs, including OpenAI's GPT-4 and Meta's Llama-2-70b-chat, often generate copyrighted content, with GPT-4 producing such content in 44% of cases. CopyrightCatcher aims to address these legal and reputational risks by enabling the detection of verbatim reproductions from copyrighted texts in LLM outputs. (Learn more at Patronus AI’sblog)\n\nMicrosoft engineer raises alarm over AI tool's creation of inappropriate contentShane Jones, a Microsoft engineer, voiced concerns over Copilot Designer. Jones discovered the tool generating violent, sexual, and copyright-infringing images during his tests of the software. His findings include disturbing depictions related to sensitive topics like abortion rights, underage substance abuse, and sexualized violence. (Read the story atCNBC)\n\nAI transforms old masters art authentication, but faces skepticismSwiss-based company Art Recognition developed a system that claims to offer precise and objective evaluations of artwork authenticity, boasting over 500 completed evaluations, including a contested 1889 self-portrait by Vincent van Gogh. Despite successes, the technology faces challenges and skepticism from art professionals concerned about AI's ability to consider factors like varnish layers, wear, or damage, and its dependence on the quality of input data. (Read more atFinancial Times)\n\nFormer Google engineer charged with transferring AI secrets to ChinaLinwei Ding, an ex-Google software engineer, has been indicted for allegedly attempting to transfer sensitive AI technology to a company in Beijing, China. Arrested in California, Ding is accused of uploading 500 files containing trade secrets from Google's AI supercomputer system to the cloud. U.S. authorities are treating this case as a significant threat to national and economic security, emphasizing the Justice Department's commitment to safeguarding American technological advancements. (Read the report atThe New York Times)",
    "qa": [
      {
        "question": "Đạo luật AI của Nghị viện Châu Âu tiếp cận việc quản lý AI dựa trên tiêu chí nào?",
        "options": {
          "A": "Dựa trên mức độ phổ biến của ứng dụng AI.",
          "B": "Dựa trên mức độ rủi ro của ứng dụng AI.",
          "C": "Dựa trên quốc gia phát triển ứng dụng AI.",
          "D": "Dựa trên số lượng người dùng của ứng dụng AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo báo cáo, AMD gặp khó khăn gì trong việc phát triển chip AI dành riêng cho thị trường Trung Quốc?",
        "options": {
          "A": "Thiếu nguồn cung cấp nguyên liệu sản xuất chip.",
          "B": "Vướng mắc quy định từ phía chính quyền Mỹ.",
          "C": "Không đạt được thỏa thuận về giá với các đối tác Trung Quốc.",
          "D": "Gặp vấn đề về kỹ thuật trong quá trình thiết kế chip."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu AI kêu gọi các công ty công nghệ như OpenAI và Meta điều gì?",
        "options": {
          "A": "Chia sẻ lợi nhuận từ các sản phẩm AI.",
          "B": "Cho phép đánh giá độc lập các công nghệ của họ.",
          "C": "Tăng cường hợp tác nghiên cứu với các trường đại học.",
          "D": "Công khai mã nguồn của các mô hình AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo Edelman Trust Barometer 2024, mối lo ngại lớn nhất của người dân về AI là gì?",
        "options": {
          "A": "Sự phát triển quá nhanh của công nghệ AI.",
          "B": "Khả năng AI thay thế hoàn toàn con người trong công việc.",
          "C": "Việc quản lý đổi mới, đặc biệt là AI, còn yếu kém.",
          "D": "Chi phí đầu tư vào AI quá lớn."
        },
        "answer": "C"
      },
      {
        "question": "CopyrightCatcher của Patronus AI được thiết kế để làm gì?",
        "options": {
          "A": "Tạo ra nội dung độc đáo cho các mô hình ngôn ngữ lớn.",
          "B": "Phát hiện nội dung vi phạm bản quyền trong đầu ra của các mô hình ngôn ngữ lớn.",
          "C": "Bảo vệ bản quyền cho các nhà phát triển mô hình ngôn ngữ lớn.",
          "D": "Tự động cập nhật thông tin bản quyền cho các mô hình ngôn ngữ lớn."
        },
        "answer": "B"
      },
      {
        "question": "Kỹ sư Microsoft Shane Jones đã phát hiện ra vấn đề gì với Copilot Designer?",
        "options": {
          "A": "Công cụ này tạo ra các thiết kế quá phức tạp và khó sử dụng.",
          "B": "Công cụ này tạo ra các hình ảnh bạo lực, khiêu dâm và vi phạm bản quyền.",
          "C": "Công cụ này không tương thích với các phần mềm thiết kế khác.",
          "D": "Công cụ này tiêu tốn quá nhiều tài nguyên hệ thống."
        },
        "answer": "B"
      },
      {
        "question": "Công ty Art Recognition sử dụng AI để làm gì?",
        "options": {
          "A": "Tạo ra các tác phẩm nghệ thuật mới.",
          "B": "Phục chế các tác phẩm nghệ thuật cổ.",
          "C": "Đánh giá tính xác thực của các tác phẩm nghệ thuật.",
          "D": "Dự đoán giá trị của các tác phẩm nghệ thuật."
        },
        "answer": "C"
      },
      {
        "question": "Linwei Ding, cựu kỹ sư Google, bị cáo buộc đã làm gì?",
        "options": {
          "A": "Hack vào hệ thống bảo mật của Google.",
          "B": "Cung cấp thông tin mật cho đối thủ cạnh tranh của Google.",
          "C": "Cố gắng chuyển giao công nghệ AI nhạy cảm cho một công ty ở Bắc Kinh.",
          "D": "Phát tán thông tin sai lệch về Google trên mạng xã hội."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, một trong những hạn chế của AI trong việc xác thực tác phẩm nghệ thuật là gì?",
        "options": {
          "A": "Chi phí đầu tư vào công nghệ AI quá cao.",
          "B": "Sự phụ thuộc vào chất lượng dữ liệu đầu vào và khó khăn trong việc xem xét các yếu tố như lớp vecni hoặc hư hỏng.",
          "C": "Khả năng AI tạo ra các tác phẩm nghệ thuật giả mạo ngày càng tinh vi.",
          "D": "Thiếu các chuyên gia có đủ kiến thức để vận hành hệ thống AI."
        },
        "answer": "B"
      },
      {
        "question": "Trong các thử nghiệm gần đây của Patronus AI, mô hình ngôn ngữ lớn nào tạo ra nội dung có bản quyền với tỷ lệ cao nhất?",
        "options": {
          "A": "Llama-2-70b-chat.",
          "B": "GPT-3.",
          "C": "GPT-4.",
          "D": "Bard."
        },
        "answer": "C"
      }
    ]
  },
  "data-points-issue-241": {
    "title": "The latest in AI from Mar. 14 to Mar. 20, 2024",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeaturedconversational robots, security risks in Hugging Face’s platform, the use of deepfakes in India's 2024 elections, Google's generative news tools, and a cost-saving method that calls pretrained large language models (LLMs) sequentially, from least to most expensive, and stops when one provides a satisfactory answer. But first:\n\nDevin, an AI software engineer backed by tech industry heavyweightsAI startup Cognition launched Devin. Unlike many coding assistants, Devin manages complete development projects—from coding to bug fixing and execution. The tool, currently exclusive to a handful of users, showcases capabilities beyond conventional coding aids, handling a wide array of tasks and outperforming similar technologies in benchmark tests. (Read more atVentureBeat)\n\nMidjourney bans Stability AI employees over image-scraping incidentMidjourney indefinitely banned all employees of its rival Stability AI after detecting botnet-like activities aimed at scraping image and prompt pairs from its service. This move followed a 24-hour service outage attributed to actions by a Stability AI employee, raising concerns about ethical practices in AI data collection. Stability AI's CEO, Emad Mostaque, countered claims of intentional scraping, suggesting the activity was for a personal project and did not involve image data. (Find more details atArs Technica)\n\nAI enhances hockey analyticsResearchers at the University of Waterloo and Stathletes developed an AI tool that improves the speed and accuracy of tracking and analyzing data from professional hockey games. The tool uses deep learning techniques to automatically identify players and their movements, overcoming the challenges posed by the sport's fast pace and non-linear player motion, with high accuracy rates in player tracking (94.5 percent), team identification (97 percent), and individual player recognition (83 percent). (Read the article atScience Daily)\n\nFive Pulitzer finalists used generative technology in their workFor the first time, the Pulitzer Prizes, a prize honoring journalistic achievement, disclosed that five of this year's finalists incorporated AI technology in their submissions. The Pulitzer Board initiated a requirement for entrants to declare their use of AI, reflecting an interest in the capabilities and ethical considerations of AI in journalism. (Read the news atNiemanLab)\n\nElon Musk makes Grok open source amid legal battle with OpenAIxAI will open source its ChatGPT rival, Grok. Musk, who has expressed concerns about the profit-driven use of technology by large corporations, initiated legal action against OpenAI for veering away from its non-profit origins to pursue a profit model. The decision to make Grok open-source is seen as a significant step towards democratizing AI development and usage, albeit with ongoing discussions about the potential risks and benefits of such openness in the field. (Read the story atReuters)\n\nAnswer.AI introduces open source system for home-based 70b model trainingThe project enables enthusiasts and researchers to train a 70 billion parameter language model on standard desktop computers equipped with dual gaming GPUs, such as RTX 3090 or 4090. This is achieved through the combination of Fully Sharded Data Parallelism (FSDP) and Quantized Low-Rank Adaptation (QLoRA), helping democratize access to large-scale AI model training. Collaborating with experts from the University of Washington and Hugging Face, Answer.AI's initiative aims to empower the open source community, allowing even small labs to explore big AI models. (Explore all the details at Answer.AI’sblog)\n\nSailor, a suite of open language models designed for the South-East Asian (SEA) regionSupporting languages like Indonesian, Thai, Vietnamese, Malay, and Lao, Sailor leverages the Qwen 1.5 framework, and offers models ranging from 0.5B to 7B parameters, aimed at enhancing text understanding and generation within SEA's diverse linguistic context. (Read more at Sailor’sGitHub)\n\nAI-generated food images are more appetizing than real photos, study showsDuring Global Nutrition and Hydration Week 2024, researchers unveiled a study indicating consumers prefer AI-generated food images over actual food photographs, particularly when unaware of the images' origins. This preference, as per findings published in Food Quality and Preference, stems from AI's ability to optimize visual factors like symmetry, shape, and lighting, making food appear more appealing. The study involved 297 participants evaluating a variety of food images, showing a significant bias towards AI-generated visuals when the creation method was undisclosed. (Read more atScience Daily)\n\nStudy exposes ASCII art as weakness for AI safety measuresSecurity researchers introduced ArtPrompt, a technique leveraging ASCII art to circumvent safety mechanisms in LLMs. While safety efforts have largely concentrated on semantic understanding, this study highlights a critical oversight: the inability of LLMs to properly interpret ASCII art—a text-based art form in digital forums. The research evaluates the response of state-of-the-art LLMs like GPT-3.5, GPT-4, Gemini, Claude, and Llama2 to ASCII art. The findings reveal a substantial gap in these models' defenses, with ArtPrompt successfully manipulating all five LLMs to exhibit unintended behaviors. (Read the paper atArxiv)\n\nHong Kong's Centre for AI and Robotics (CAIR) introduces AI tool for advanced brain surgery assistanceCARES Copilot 1.0 is a model designed to aid neurosurgeons in complex brain surgeries. The tool aims to enhance clinical diagnosis and decision-making by providing quick access to a vast range of medical references. Having been tested in hospitals across Hong Kong and mainland China, CARES Copilot 1.0 has shown an accuracy rate of up to 95 percent in generating crucial information from academic sources. (Learn more atSouth China Morning Post)\n\nNvidia defends NeMo amid copyright infringement claimsNvidia asserted that NeMo, a framework for developing generative AI applications, adheres to copyright laws following a lawsuit from authors Abdi Nazemian, Brian Keene, and Stewart O’Nan. The authors allege that Nvidia unlawfully used their copyrighted books to train NeMo's models without permission, seeking damages and profit restitution. Nvidia maintains that NeMo was developed in full respect of copyright laws, as tensions between AI development and intellectual property rights continue to escalate. (Full story atThe Wall Street Journal)\n\nAmazon announces more generative AI features for product listing creationThe new capabilities allow partners to transform existing product pages from external websites into tailored, high-quality listings on Amazon with minimal effort. By providing a URL or sparse text descriptions, sellers can generate product titles, descriptions, and key attributes. (Get all the details at Amazon’sblog)\n\nOpenAI forms licensing agreements with Le Monde and PrisaThese partnerships, part of OpenAI's global strategy to collaborate with media entities, are designed to support journalism through AI technology while providing ChatGPT users with interactive access to news. In addition to summarizing news content from these publishers in its responses, ChatGPT will offer attribution and links to the original articles, enhancing the user experience with reliable information sources. (Read more atBloomberg)\n\nCerebras launches WSE-3 chip, teams up with QualcommCerebras Systems introduced its latest AI chip, with double the performance of its predecessor while maintaining energy efficiency. Additionally, Cerebras announced a collaboration with Qualcomm, aimed at reducing the costs and improving the performance of AI inference by a factor of 10. This partnership will leverage Cerebras' training capabilities and Qualcomm's AI 100 Ultra chip to address the scalability and efficiency challenges in deploying AI models. (Read more details atIEEE Spectrum)\n\nGoogle announces comprehensive support measures for the 2024 Indian General ElectionGoogle is intensifying its efforts to combat misinformation by enforcing strict policies across its platforms, leveraging AI models, and promoting transparency in election-related advertising. Collaborating with Shakti, the India Election Fact-Checking Collective, and other initiatives, Google aims to support early detection of online misinformation, including deepfakes. (Learn more at Google’sblog)\n\nAbu Dhabi set to launch autonomous racing seriesThe inaugural event, slated for April 27, seeks to challenge the world's leading computer scientists, coders, and developers with a $2.25 million prize purse. Developed by ASPIRE, part of the UAE's Advanced Technology Research Council, A2RL builds upon previous autonomous racing initiatives with a long-term vision of enhancing road safety, advancing technological development, and increasing public acceptance of autonomous vehicles. (Read the news atAutosport)",
    "qa": [
      {
        "question": "Công ty khởi nghiệp Cognition đã ra mắt công cụ AI nào có khả năng quản lý các dự án phát triển phần mềm hoàn chỉnh?",
        "options": {
          "A": "Midjourney",
          "B": "Devin",
          "C": "Grok",
          "D": "NeMo"
        },
        "answer": "B"
      },
      {
        "question": "Sự việc nào đã dẫn đến việc Midjourney cấm nhân viên của Stability AI sử dụng dịch vụ của mình?",
        "options": {
          "A": "Sử dụng AI để tạo ra các hình ảnh vi phạm bản quyền.",
          "B": "Tấn công mạng vào hệ thống của Midjourney.",
          "C": "Thu thập trái phép dữ liệu hình ảnh và prompt từ Midjourney.",
          "D": "Phát tán thông tin sai lệch về Midjourney."
        },
        "answer": "C"
      },
      {
        "question": "Công cụ AI được phát triển bởi Đại học Waterloo và Stathletes có tác dụng gì trong lĩnh vực khúc côn cầu?",
        "options": {
          "A": "Dự đoán kết quả trận đấu.",
          "B": "Cải thiện tốc độ và độ chính xác trong việc theo dõi và phân tích dữ liệu trận đấu.",
          "C": "Tự động huấn luyện các cầu thủ.",
          "D": "Phát hiện các hành vi phạm lỗi."
        },
        "answer": "B"
      },
      {
        "question": "Giải thưởng Pulitzer năm nay có điểm gì đặc biệt liên quan đến công nghệ AI?",
        "options": {
          "A": "Yêu cầu tất cả các tác phẩm dự thi phải sử dụng AI.",
          "B": "Lần đầu tiên công nhận các tác phẩm hoàn toàn do AI tạo ra.",
          "C": "Công khai việc có những tác phẩm lọt vào vòng chung kết sử dụng AI.",
          "D": "Cấm sử dụng AI trong các tác phẩm dự thi."
        },
        "answer": "C"
      },
      {
        "question": "Elon Musk đã quyết định làm gì với Grok, đối thủ cạnh tranh của ChatGPT?",
        "options": {
          "A": "Bán Grok cho một tập đoàn công nghệ lớn.",
          "B": "Phát triển Grok thành một nền tảng thương mại.",
          "C": "Mở mã nguồn Grok.",
          "D": "Ngừng phát triển Grok."
        },
        "answer": "C"
      },
      {
        "question": "Answer.AI đã giới thiệu hệ thống mã nguồn mở cho phép huấn luyện mô hình ngôn ngữ 70 tỷ tham số tại nhà bằng cách nào?",
        "options": {
          "A": "Sử dụng các siêu máy tính chuyên dụng.",
          "B": "Kết hợp Fully Sharded Data Parallelism (FSDP) và Quantized Low-Rank Adaptation (QLoRA).",
          "C": "Thuê các trung tâm dữ liệu lớn.",
          "D": "Sử dụng các thuật toán nén dữ liệu tiên tiến."
        },
        "answer": "B"
      },
      {
        "question": "Sailor là một bộ mô hình ngôn ngữ mở được thiết kế cho khu vực nào?",
        "options": {
          "A": "Châu Âu",
          "B": "Bắc Mỹ",
          "C": "Đông Nam Á",
          "D": "Châu Phi"
        },
        "answer": "C"
      },
      {
        "question": "Nghiên cứu cho thấy điều gì về sự hấp dẫn của hình ảnh thực phẩm do AI tạo ra so với ảnh chụp thực tế?",
        "options": {
          "A": "Ảnh chụp thực tế luôn được ưa chuộng hơn.",
          "B": "Hình ảnh do AI tạo ra được ưa chuộng hơn khi người dùng không biết nguồn gốc của chúng.",
          "C": "Không có sự khác biệt đáng kể về mức độ ưa chuộng.",
          "D": "Hình ảnh do AI tạo ra chỉ được ưa chuộng bởi các chuyên gia dinh dưỡng."
        },
        "answer": "B"
      },
      {
        "question": "ArtPrompt là một kỹ thuật khai thác lỗ hổng bảo mật AI bằng cách sử dụng yếu tố nào?",
        "options": {
          "A": "Hình ảnh có độ phân giải thấp.",
          "B": "Văn bản được mã hóa.",
          "C": "Nghệ thuật ASCII.",
          "D": "Âm thanh tần số cao."
        },
        "answer": "C"
      },
      {
        "question": "CARES Copilot 1.0, công cụ AI được phát triển bởi Trung tâm AI và Robotics (CAIR) ở Hồng Kông, được sử dụng để làm gì?",
        "options": {
          "A": "Tự động thực hiện phẫu thuật não.",
          "B": "Hỗ trợ các bác sĩ phẫu thuật thần kinh trong các ca phẫu thuật phức tạp.",
          "C": "Phân tích kết quả chụp MRI.",
          "D": "Dự đoán nguy cơ mắc bệnh não."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-242": {
    "title": "The latest in AI from Mar. 21 to Mar. 27, 2024",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeaturedan agent for many environments, an AI system to identify animal cell types from gene sequences, a system that analyzes satellite and geolocation data that has been used to identify targets in real-world conflicts, and an agent that plays one-on-one football in a simulated environment But first:\n\nNvidia unveils LATTE3D, a model that turns text prompts into detailed 3D shapesThis model can produce high-quality 3D representations of objects and animals almost instantly, with applications for virtual environments, video games, advertising, and training modules. The model not only speeds up the design process by offering multiple shape options from a single prompt but also supports optimization for higher quality outputs. (Read more at Nvidia’sblog)\n\nLighthouz AI and Hugging Face launch chatbot guardrails arena to test AI privacyThe arena allows participants to interact with two anonymous chatbots, challenging them to reveal sensitive financial information protected by advanced guardrails. The initiative aims to identify the most secure AI models through community voting, establishing a trusted benchmark for chatbot security and privacy. Participants can engage with chatbots, explore different guardrail technologies, and contribute to a public leaderboard that ranks the models based on their privacy-preserving capabilities. (Find all the details at Hugging Face’sblog)\n\nGoogle Deepmind’s TacticAI, an AI assistant for football coachesThis tool optimizes corner kicks in football (soccer). TacticAI leverages a geometric deep learning approach to offer predictive insights, enabling the generation of high-quality tactical setups despite the scarcity of gold-standard data. By analyzing past plays and suggesting adjustments, TacticAI offers a blend of predictive accuracy and practical tactical recommendations, advancing sports AI and potentially impacting other fields like computer games, robotics, and traffic coordination. (Learn more at Google Deepmind’sblog)\n\nNvidia introduced the Blackwell B200 GPU, proclaimed as the world's most powerful chip for AIThe new flagship B200 chip delivers up to 20 petaflops of computing power (in the FP4 format) compared to the H200’s four petaflops in FP8. .The new GB200 superchip combining two B200 GPUs and a Grace CPU offers up to 30 times the performance for LLM inference tasks compared to its predecessor, while also reducing energy and cost by up to 25 times. Each B200 processor is expected to cost between $30,000 and $40,000. (Learn more atArs Technica)\n\nStability AI introduces Stable Video 3D, a model that turns single images into detailed 3DBuilt on Stable Video Diffusion, SV3D comes in two variants: SV3D_u, for generating orbital videos from single images without camera conditioning, and SV3D_p, which creates 3D videos along specified camera paths from single images and orbital views. Stable Video 3D is now available for commercial use through Stability AI Membership, with model weights accessible for non-commercial purposes on Hugging Face. (Read Stability AI’sblogfor more details)\n\nUnited Nations General Assembly adopts resolution on responsible AIThe resolution, led by the U.S. and backed by over 120 nations, promotes uses of AI that respect human rights and aid sustainable development.  It also seeks to bridge the digital divide, particularly in developing countries, and complement ongoing initiatives within the UN system for governing AI technology. (Learn more at the United Nations’blog)\n\nResearchers trained a neural network that can linguistically instruct another AIInitially trained on basic tasks, the AI described these tasks to a 'sister' AI, which could then execute the tasks independently. This achievement promises substantial benefits for the field of robotics, signaling a move towards more autonomous and collaborative humanoid robots. (Read the news atScience Daily)\n\nBiden administration grants Intel $20 billion to ramp up U.S. chip productionU.S. President Joe Biden announced nearly $20 billion in grants and loans to Intel, marking the largest U.S. government subsidy for semiconductor manufacturing. This funding aims to increase the U.S. share of advanced chip production from 0% to 20% by 2030. This investment also intends to reduce the U.S.'s reliance on chip imports, particularly from Taiwan, amid concerns over geopolitical tensions with China. (Read the news atReuters)\n\nAI tool “Mia” identifies breast cancer missed by doctors in trialDeveloped for the U.K. National Health Service (NHS), Mia demonstrated the ability to detect early signs of breast cancer in mammogram scansTested across 10,000 women, Mia flagged all symptomatic patients, including those not initially spotted by clinicians, identifying 11 cases of smaller cancers that were overlooked by human doctors. (Read the story atBBC)\n\nGPT store overwhelmed by spamOpenAI's marketplace for custom chatbots, the GPT Store, is facing challenges with spam and potentially copyright-infringing content. A review by TechCrunch revealed issues with moderation, as the store is flooded with GPTs that misuse properties from Disney, Marvel, and other franchises, and even offer services that promise to bypass AI content detection tools. The GPT Store's rapid growth to 3 million GPTs has seemingly come at the expense of quality and adherence to OpenAI’s policies. (Read the full report atTechCrunch)\n\nGlobal experts convene in Beijing to set safety \"Red Lines\" for AI developmentAt the second International Dialogue on AI Safety in Beijing, top AI scientists, including Yoshua Bengio, Andrew Yao, and Geoffrey Hinton, collaborated with governance experts to address AI safety and propose international cooperation guidelines. The consensus statement from the event recommends prohibiting AI systems capable of autonomous replication, power seeking, assisting in weapon development, executing cyberattacks, or deceiving creators. (Read the statement atIDAIS)\n\nResearchers developed an AI that can identify COVID-19 in lung ultrasound imagesBeginning as a tool for quick patient assessment during the pandemic, the technology now also offers potential for at-home monitoring devices for illnesses like congestive heart failure. The AI, a deep neural network, has been trained using a combination of real patient data and simulated images to recognize features known as B-lines, which are indicative of inflammation and infection in the lungs. (Read more atScience Daily)\n\nTennessee enacts first U.S. law to shield artists from unauthorized AI useThe Ensuring Likeness Voice and Image Security (ELVIS) Act updates the state's personal rights protection laws to safeguard the voices of songwriters, performers, and music industry professionals against misuse by AI. The law addresses the music industry's growing concerns over generative AI's potential for creating unauthorized content that mimics human artists. (Read more atReuters)\n\nGoogle's ScreenAI breaks down UI and infographic interactionScreenAI, a new vision-language model, specializes in identifying UI elements and generating descriptive annotations. Trained on a novel Screen Annotation task among others, this 5B parameter model outperforms similar-sized and larger models across various benchmarks in tasks like question answering and UI navigation. (Read all about the model at Google’sblog)\n\nSakana AI launches open source models with evolution-inspired techniqueThe Tokyo-based startup unveiled new models developed through a \"model merging\" process inspired by evolution. This method involves combining existing models to create advanced model generations, with the most successful models advancing as \"parents\" for future iterations. The company is releasing three Japanese language models, two of which are open source. (Read the story atReuters)\n\nGoogle fined €250 million by French regulator over AI copyright breachesFrance's competition authority imposed a €250 million fine on Google for violating EU intellectual property rules, particularly in its use of media publisher content for training Gemini. The sanction addresses complaints from major news organizations about unauthorized use of their content. Google agreed to the settlement without contesting the facts, expressing a desire to focus on sustainable content distribution and collaboration with French publishers. (Read more atReuters)\n\nGoogle advances AI flood forecasting to boost global preparednessThis initiative is part of Google's broader effort since 2017 to develop a real-time operational flood forecasting system, integrating Google Search, Maps, and Android notifications.The system now covers river forecasts in over 80 countries. Google’s system can now predict flooding in areas where historical data is scarce, marking a step towards using AI for climate resilience. (Read the report at Google Researchblog)\n\nChatbots emerge as a mental health aid for Gen ZAmidst a growing mental health crisis among teens and young adults, chatbots are stepping in to offer support. These chatbots employ therapeutic techniques to provide users with coping strategies and emotional support, although creators are cautious to differentiate these services from professional therapy. With the surge in generative AI, such apps have gained traction, offering 24/7 availability without the stigma of seeking therapy. However, their effectiveness and regulatory status remain in question due to limited data on long-term impacts and the absence of FDA approval for treating specific conditions. (Read the report atAP News)\n\nU.S. Department of Homeland Security integrates AI to enhance operationsIn collaboration with leading companies like OpenAI, Anthropic, and Meta, the federal agency aims to leverage chatbots and other AI tools for a wide range of applications, including combating drug and human trafficking, training immigration officials, and enhancing emergency management. Homeland Security Secretary Alejandro Mayorkas emphasized the urgent need to adopt AI to harness its benefits and mitigate potential risks. With an initial investment of $5 million in pilot programs, the department plans to employ AI in investigating crimes, securing the nation’s critical infrastructure, and developing disaster relief plans. (Read more atThe New York Times)",
    "qa": [
      {
        "question": "Mô hình LATTE3D của Nvidia có khả năng gì?",
        "options": {
          "A": "Phân tích dữ liệu tài chính nhạy cảm.",
          "B": "Chuyển đổi văn bản thành hình dạng 3D chi tiết.",
          "C": "Dự đoán kết quả các trận bóng đá.",
          "D": "Phát hiện ung thư vú từ ảnh chụp nhũ ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của Lighthouz AI và Hugging Face khi ra mắt đấu trường chatbot guardrails là gì?",
        "options": {
          "A": "Phát triển chatbot có khả năng vượt qua các biện pháp bảo vệ quyền riêng tư.",
          "B": "Xây dựng một hệ thống xếp hạng công khai dựa trên khả năng bảo vệ quyền riêng tư của các mô hình AI.",
          "C": "Tạo ra một chatbot có thể tiết lộ thông tin tài chính nhạy cảm một cách an toàn.",
          "D": "Cung cấp một nền tảng để người dùng chia sẻ thông tin tài chính cá nhân một cách an toàn."
        },
        "answer": "B"
      },
      {
        "question": "TacticAI của Google Deepmind hỗ trợ huấn luyện viên bóng đá như thế nào?",
        "options": {
          "A": "Dự đoán thời tiết để lên kế hoạch tập luyện.",
          "B": "Tối ưu hóa các quả phạt góc bằng cách đưa ra các gợi ý chiến thuật.",
          "C": "Phân tích hiệu suất của cầu thủ trong trận đấu.",
          "D": "Tự động điều khiển robot thi đấu bóng đá."
        },
        "answer": "B"
      },
      {
        "question": "GPU Blackwell B200 của Nvidia có điểm gì nổi bật?",
        "options": {
          "A": "Khả năng tạo ra hình ảnh 3D chân thực từ ảnh 2D.",
          "B": "Khả năng phát hiện gian lận trong các giao dịch tài chính.",
          "C": "Là chip mạnh nhất thế giới dành cho AI, cung cấp hiệu năng tính toán vượt trội.",
          "D": "Khả năng dự đoán chính xác các trận động đất."
        },
        "answer": "C"
      },
      {
        "question": "Stable Video 3D (SV3D) của Stability AI có những biến thể nào?",
        "options": {
          "A": "SV3D_u và SV3D_p, với SV3D_u tạo video quỹ đạo từ ảnh đơn và SV3D_p tạo video 3D theo đường dẫn camera.",
          "B": "SV3D_x và SV3D_y, với SV3D_x tập trung vào tạo hình ảnh tĩnh và SV3D_y tập trung vào tạo video.",
          "C": "SV3D_a và SV3D_b, với SV3D_a dành cho mục đích thương mại và SV3D_b dành cho mục đích phi thương mại.",
          "D": "SV3D_1 và SV3D_2, với SV3D_1 có độ phân giải cao và SV3D_2 có độ phân giải thấp."
        },
        "answer": "A"
      },
      {
        "question": "Nội dung chính của nghị quyết về AI có trách nhiệm được Đại hội đồng Liên Hợp Quốc thông qua là gì?",
        "options": {
          "A": "Cấm hoàn toàn việc sử dụng AI trong lĩnh vực quân sự.",
          "B": "Thúc đẩy sử dụng AI tôn trọng quyền con người và hỗ trợ phát triển bền vững.",
          "C": "Yêu cầu tất cả các quốc gia phải chia sẻ dữ liệu AI cho mục đích nghiên cứu.",
          "D": "Áp đặt các biện pháp trừng phạt đối với các công ty vi phạm bản quyền AI."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích của việc chính quyền Biden cấp 20 tỷ đô la cho Intel là gì?",
        "options": {
          "A": "Phát triển công nghệ AI cho mục đích quân sự.",
          "B": "Tăng cường sản xuất chip tiên tiến tại Hoa Kỳ và giảm sự phụ thuộc vào nhập khẩu.",
          "C": "Xây dựng một trung tâm nghiên cứu AI hàng đầu thế giới.",
          "D": "Hỗ trợ các công ty khởi nghiệp trong lĩnh vực AI."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ AI \"Mia\" được sử dụng để làm gì trong lĩnh vực y tế?",
        "options": {
          "A": "Phân tích gen để xác định nguy cơ mắc bệnh di truyền.",
          "B": "Phát hiện sớm các dấu hiệu ung thư vú trong ảnh chụp nhũ ảnh.",
          "C": "Dự đoán nguy cơ mắc bệnh tim mạch.",
          "D": "Phát triển thuốc mới dựa trên dữ liệu AI."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính mà GPT Store của OpenAI đang gặp phải là gì?",
        "options": {
          "A": "Thiếu người dùng và sự quan tâm từ cộng đồng.",
          "B": "Giá cả quá cao khiến người dùng khó tiếp cận.",
          "C": "Bị tràn ngập bởi nội dung spam và có khả năng vi phạm bản quyền.",
          "D": "Khả năng xử lý ngôn ngữ tự nhiên còn hạn chế."
        },
        "answer": "C"
      },
      {
        "question": "Đạo luật ELVIS mới được ban hành ở Tennessee nhằm mục đích gì?",
        "options": {
          "A": "Bảo vệ quyền riêng tư của người dùng trên internet.",
          "B": "Bảo vệ tiếng nói của các nghệ sĩ khỏi việc sử dụng trái phép bởi AI.",
          "C": "Khuyến khích phát triển công nghệ AI trong lĩnh vực âm nhạc.",
          "D": "Cấm sử dụng AI trong việc sáng tác âm nhạc."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-243": {
    "title": "Switching from NVIDIA; Plus, OpenAI’s Voice Engine",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeatureddetails about Microsoft's absorption of Inflection AI, Nvidia’s latest chip, a voluntary commitment to internal and external oversight of machine learning models by scientists, and a procedure that fine-tunes large language models (LLMs) to increase their truthfulness without collecting human feedback. But first:\n\nTech coalition wants to make it easier to switch from NvidiaA collective of companies, including giants like Qualcomm, Google, and Intel, is developing an open source suite of tools and software designed to function across a variety of AI accelerator chips. The coalition, called the UXL Foundation, wants to ease AI companies’ dependency on Nvidia's ecosystem. Google, a key member of this consortium, is involved in guiding the technical direction of the initiative, which is founded on Intel's OneAPI technology. UXL's goal is to add flexibility to the AI development ecosystem, offering developers  more hardware choices. (Read the story atReuters)\n\nOpenAI probes synthetic voicemarket with Voice EngineOpenAI has been quietly testing a new product called Voice Engine, a model for turning text and voice input into synthetic voices that sound like the original speaker. Voice Engine has already helped develop the company’s text-to-speech API and ChatGPT Voice and Read Aloud products. Potential applications include automated voice translation and assisting users with disabilities. However, OpenAI has been reluctant to release the product more widely because of concerns it might be abused. (Read OpenAI’s initial findings at the companyblog.)\n\nU.S. city tests AI to identify homeless encampmentsSan Jose, California embarked on a controversial project to train AI algorithms to spot signs of homelessness, such as tents and occupied vehicles. The city teamed up with tech firms to collect street footage via a camera-mounted municipal vehicle. The initiative aims to address complaints such as illegal dumping and graffiti by enabling more efficient city responses, but has sparked concern among local outreach workers and national housing advocates about potential punitive uses against the unhoused population. (Learn more atThe Guardian)\n\nAnthropic introduces Claude 3 prompt library for enhanced chatbot interactionsThe library features a collection of prompts for the Claude 3 chatbot to inspire users and improve their interaction experiences. Available on Anthropic's website, prompts are categorized as entertainment, work, and user-generated content. Users can try these prompts to explore the chatbot's capabilities in humor, dream analysis, recipe creation, web development, fashion suggestions, and more. (Read more atTom’s Guide)\n\nFinancial Times launches a chatbot that responds to queries using the publication's archive of articlesAsk FT, currently in beta, provides answers to user queries based on articles dated between March 1, 2023, and March 20, 2024, with the goal of providing up-to-date and referenced answers. Although the system, powered by Anthropic's Claude, shows promise with its ability to pull relevant information and cite sources, it has displayed inconsistencies, such as including politicians in a 2024 election list who are no longer candidates. (Find out more atThe Verge)\n\nAdobe’s new Firefly Services offers over 20 generative AI APIs to developersThe new set of APIs enables developers to integrate AI-powered features from Adobe’s Creative Cloud, such as Photoshop, into their own custom workflows or to develop entirely new applications. Firefly Services aims to automate workflows with APIs for tasks like background removal, smart cropping, and photo leveling, and includes access to advanced Photoshop capabilities like Generative Fill and Expand. Adobe also unveiled Custom Models, a feature that lets businesses tailor Firefly models with their unique assets for even more personalized content creation. (Learn more atTechCrunch)\n\nU.S. President Biden directs every federal agency to appoint a chief AI officerThe White House announced a new policy initiative requiring senior officials to take charge of their agencies’ use of AI. The new AI officers (who may also fill other roles like chief information or chief technology officer) must be appointed within 60 days. The White House also set a target date of December 1st of this year for all federal agencies to correct any non-compliant uses of AI in government business. Agencies and their AI officers will need to take special care to ensure any government use of AI doesn’t negatively impact safety, privacy, or civil rights. (Learn more about the directive atArs Technica)\n\nApple in preliminary discussions with Baidu to incorporate AI into its devices within ChinaWhile Apple has also discussed partnering with companies like Google and OpenAI for its global AI needs, the Chinese market presents unique challenges. No foreign AI models have been approved in China since the introduction of new AI regulations, and Apple is seeking to partner with a local AI provider to navigate these hurdles. (Read the news atThe Wall Street Journal)\n\nCongressional aides barred from using Microsoft Copilot for government useThe U.S. House of Representatives has banned Microsoft’s AI engine due to concerns it may store data on unapproved cloud servers. The move follows a similar restriction on use of ChatGPT, but in that case staffers were still allowed to use the paid version of the chatbot in limited cases. Microsoft has promised to release a version of Copilot that meets government security and compliance requirements later this year. (Read about it atAxios)\n\nClaude 3 beats GPT-4 Turbo on the Chatbot Arena leaderboard for the first timeAnthropic’s Opus has taken the top spot on LMSYS/HuggingFace’s AI leaderboard, as voted by thousands of chatbot users. Various versions of GPT-4 have led the Chatbot Arena board since the model’s introduction in May 2023. Claude’s smaller Sonnet and Haiku models are also performing well on the leaderboard, with Sonnet ranking just behind Gemini Pro and Haiku beating some older GPT-4 models. Researchers use the rankings to complement models’ quantitative benchmarks, amalgamating users’ qualitative perception of chatbots’ output and behavior. (See the other leaders atChatbot Arenaor read more about it atArs Technica)\n\nChatGPT opens up to new users without requiring an email address or passwordOpenAI is gradually rolling out instant access to the free version of its chatbot, with the goal of reducing friction before new users can engage with the service. However, the signup-free version of ChatGPT has some limitations: stricter content safeguards, no access to the chatbot’s voice interface, and the absence of chat history. By default, anonymous user inputs will also be used to train OpenAI’s models, although this can be changed in user settings. (Learn more about the announcement at Open AI’sblog)",
    "qa": [
      {
        "question": "UXL Foundation, một liên minh các công ty công nghệ, được thành lập với mục tiêu chính là gì?",
        "options": {
          "A": "Phát triển các chip AI mới để cạnh tranh trực tiếp với Nvidia.",
          "B": "Giảm sự phụ thuộc của các công ty AI vào hệ sinh thái của Nvidia.",
          "C": "Tối ưu hóa phần mềm cho các chip AI của Nvidia.",
          "D": "Cung cấp các khóa đào tạo chuyên sâu về AI cho các nhà phát triển."
        },
        "answer": "B"
      },
      {
        "question": "OpenAI tạm thời hạn chế phát hành rộng rãi Voice Engine vì lo ngại điều gì?",
        "options": {
          "A": "Chi phí phát triển và duy trì Voice Engine quá cao.",
          "B": "Khả năng bị lạm dụng của công nghệ này.",
          "C": "Sự cạnh tranh gay gắt từ các sản phẩm tương tự trên thị trường.",
          "D": "Các vấn đề kỹ thuật chưa được giải quyết triệt để."
        },
        "answer": "B"
      },
      {
        "question": "Thành phố San Jose, California sử dụng AI để làm gì?",
        "options": {
          "A": "Dự đoán và ngăn chặn các hành vi phạm tội.",
          "B": "Xác định các khu vực có người vô gia cư sinh sống.",
          "C": "Tối ưu hóa hệ thống giao thông công cộng.",
          "D": "Phân tích dữ liệu để cải thiện chất lượng không khí."
        },
        "answer": "B"
      },
      {
        "question": "Claude 3 prompt library của Anthropic cung cấp điều gì cho người dùng?",
        "options": {
          "A": "Một bộ công cụ để phát triển các chatbot tùy chỉnh.",
          "B": "Một bộ sưu tập các lời nhắc (prompts) để cải thiện tương tác với chatbot Claude 3.",
          "C": "Một nền tảng để chia sẻ và đánh giá các chatbot khác nhau.",
          "D": "Một khóa đào tạo trực tuyến về cách sử dụng chatbot Claude 3 hiệu quả."
        },
        "answer": "B"
      },
      {
        "question": "Ask FT, chatbot của Financial Times, sử dụng dữ liệu từ khoảng thời gian nào?",
        "options": {
          "A": "Từ khi Financial Times bắt đầu hoạt động.",
          "B": "Từ ngày 1 tháng 1 năm 2020 đến nay.",
          "C": "Từ ngày 1 tháng 3 năm 2023 đến ngày 20 tháng 3 năm 2024.",
          "D": "Từ ngày 1 tháng 1 năm 2024 đến nay."
        },
        "answer": "C"
      },
      {
        "question": "Firefly Services của Adobe cung cấp gì cho các nhà phát triển?",
        "options": {
          "A": "Một bộ công cụ để tạo ra các hiệu ứng đặc biệt cho video.",
          "B": "Một bộ API để tích hợp các tính năng AI từ Creative Cloud vào các ứng dụng của họ.",
          "C": "Một nền tảng để chia sẻ và bán các tài sản sáng tạo.",
          "D": "Một khóa đào tạo trực tuyến về cách sử dụng các sản phẩm của Adobe."
        },
        "answer": "B"
      },
      {
        "question": "Tổng thống Biden yêu cầu mỗi cơ quan liên bang phải bổ nhiệm một người phụ trách AI (chief AI officer) trong thời hạn bao lâu?",
        "options": {
          "A": "30 ngày.",
          "B": "60 ngày.",
          "C": "90 ngày.",
          "D": "120 ngày."
        },
        "answer": "B"
      },
      {
        "question": "Apple đang tìm kiếm đối tác AI địa phương tại Trung Quốc vì lý do gì?",
        "options": {
          "A": "Chi phí sử dụng các mô hình AI nước ngoài quá cao.",
          "B": "Các mô hình AI nước ngoài không tương thích với phần cứng của Apple.",
          "C": "Các quy định mới về AI tại Trung Quốc chưa cho phép các mô hình AI nước ngoài được phê duyệt.",
          "D": "Apple muốn tận dụng lợi thế của các chuyên gia AI địa phương."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao Hạ viện Hoa Kỳ cấm sử dụng Microsoft Copilot?",
        "options": {
          "A": "Do lo ngại về vấn đề bản quyền.",
          "B": "Do lo ngại về việc lưu trữ dữ liệu trên các máy chủ đám mây chưa được phê duyệt.",
          "C": "Do chi phí sử dụng quá cao.",
          "D": "Do hiệu suất hoạt động không ổn định."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào của Anthropic đã vượt qua GPT-4 Turbo trên bảng xếp hạng Chatbot Arena?",
        "options": {
          "A": "Claude Instant.",
          "B": "Claude Haiku.",
          "C": "Claude Sonnet.",
          "D": "Claude Opus."
        },
        "answer": "D"
      }
    ]
  },
  "data-points-issue-244": {
    "title": "Serverless GPU Inference",
    "collection": "data-points",
    "content": "This week's top AI news and research stories featured the proliferation of coding agents, a study showing the most common uses for generative AI, the instability of Stability AI, and a transformer alternative called Mamba. But first:\n\nHugging Face and Cloudflare launch serverless GPU inference for open AI models\"Deploy on Cloudflare Workers AI\" allows developers to build generative AI applications without the overhead of managing GPU infrastructure, reducing operating costs with a pay-per-use model. Models supported include Mistral 7B, Gemma 7B, Llama 2 13B, and Deepseek Coder 6.7B, plus specialized varieties. (Read more at Hugging Face’sblog)\n\nOpenAI updates its fine-tuning API and expands its Custom Models programKey API updates for GPT-3.5 Turbo (and in early experimental access, GPT-4) include features for better training control, such as epoch-based checkpoints, a comparative UI for model evaluation, and comprehensive validation metrics. Additionally, the Custom Models program offers assisted fine-tuning, supporting organizations in deploying advanced model refinements for their unique needs. (Find the details at OpenAI’sblog)\n\nBig Tech's hunt for AI training data stirs privacy concernsBig technology companies are eagerly acquiring vast amounts of training data, reigniting interest in once-dominant platforms like Photobucket. Photobucket, now with just 2 million active users, is negotiating to license its content for model training, potentially earning billions in revenue. The market for \"ethically sourced\" training data, valued at roughly $2.5 billion and expected to grow to $30 billion in a decade, is not without controversy. Concerns are mounting over the privacy implications of repurposing personal data for AI training without explicit consent. (Read the news atReuters)\n\nStartup Hume introduces Empathic Voice Interface (EVI), an AI promising emotional intelligenceEVI claims to process the subtleties of human speech, such as tune, rhythm, and timbre, enabling it to generate empathic responses with an appropriate tone of voice. Developers are offered a comprehensive suite of tools for easy integration, including a WebSocket API, REST API, and SDKs for both TypeScript and Python, along with open source examples and a web widget. EVI's capabilities include advanced speech transcription, language response generation, expressive text-to-speech modeling, and empathic response to user expressions. (Learn more at Hume’sblog)\n\nDALL·E now offers advanced editing tools for precision image customizationUsers can now refine their generated images by selecting specific areas for editing and inputting descriptive changes via chat or a conversation panel. This enhancement includes the option to add new elements, remove unwanted objects, and alter characteristics of existing parts of an image, like changing an expression or converting an image to black and white. (Read more at OpenAI’sblog)\n\nAI-generated book ads overrun Amazon Kindle lock screensThis shift marks a departure from the previously diverse recommendations that aligned with users' reading preferences. While Kindle's ad-supported model offers a discount on the device's purchase price in exchange for displaying ads, the recent surge of low-quality, AI-generated content, including dubious imitations of existing works, has led to user discontent. Some irrelevant and unpopular titles have raised questions about Amazon's ad selection algorithms and potential experimental promotion of AI-generated content. (Read the story atFuturism)\n\nCohere launches Command R+, a large language model optimized for enterpriseCommand R+ performs similarly to top models on benchmark tests at costs lower than its top competitors.’, Cohere’s models offer a 128k-token context window and tools to optimize retrieval augmented generation (RAG) In partnership with Microsoft Azure, Command R+ targets AI adoption in enterprise, serving a range of functions from customer relationship management to multilingual communication. Command R+ is now available on Azure and soon on other platforms. (Read all the details about Command R+ at Cohere’sblog)\n\nClaude introduces “Tool Use” for function callingAnthropic AI introduces a beta feature for its Claude AI models, accessible via the Anthropic Message API. Tool use allows users to enhance Claude's capabilities by connecting to external tools for real-time information retrieval and integration of third-party functionalities. This feature enables users to perform detailed, multi-step operations and execute complex commands with minimal coding. (Learn more at Anthropic’sblog)\n\nUK and U.S. forge alliance on AI safetyThe two nations signed a Memorandum of Understanding (MOU), setting the stage for a collaborative effort in developing advanced testing protocols for AI models. This partnership, endorsed by UK's Technology Secretary Michelle Donelan and U.S. Commerce Secretary Gina Raimondo, arises from pledges made during the AI Safety Summit in November 2023. Both nations aim to share resources and personnel to expedite the creation of comprehensive evaluation suites for AI technologies. (Read the UK government’spress release)\n\nYahoo acquires AI news app ArtifactArtifact struggled to scale its user base, but its underlying AI technology, designed to curate and personalize news content, attracted Yahoo's interest. The acquisition aims to leverage Artifact's sophisticated content taxonomy and recommendation systems, boosting Yahoo News's personalization capabilities for its 185 million monthly visitors. While Artifact as an app will be discontinued, its technology is expected to impact Yahoo News and potentially other Yahoo platforms. (Read more atThe Verge)\n\nWashington judge rejects AI-enhanced video evidence in a homicide caseThe judge cited concerns over the technology's transparency and potential to confuse jury members. The contested video, intended to bolster the defense of accused Joshua Puloka by enhancing cellphone footage of the 2021 shooting incident, was critiqued for altering original video data, raising questions about its reliability and accuracy. (Read the news atNBC News)\n\nAmerican Federation of Musicians (AFM) secures contract including AI protectionsThe deal includes compensation and other provisions for AI-generated music. Musicians whose work is utilized to prompt AI systems will receive enhanced compensation.Proponents say it is an important step in acknowledging the value and persistence of human creativity despite technological transformations. (Learn more atVariety)\n\nAmazon Web Services (AWS) boosts startup support with free credits for AI model usageAWS will offer up to $500,000 in credits to the latest Y Combinator startup cohort. This initiative is part of Amazon's effort to foster the startup ecosystem and encourage the choice of AWS for cloud services. Model providers covered include Anthropic, Meta, Mistral AI, and Cohere. The announcement comes on the heels of Amazon completing a significant $4 billion investment in Anthropic, solidifying a partnership wherein Anthropic will prioritize AWS for cloud services. (Read more details atReuters)\n\nYum Brands, the parent company of Taco Bell, Pizza Hut, and KFC, embraces AIThe company advances toward an \"AI-first\" approach in its operations. The SuperApp, a tool designed to aid restaurant managers in operational tasks, is undergoing enhancements with generative AI. Additionally, Yum is exploring customer-facing AI applications, such as AI-driven voice ordering and image-recognition for drive-through optimization. (Read the report atThe Wall Street Journal)\n\nChatbots outperform humans in persuasive debates, study findsA study conducted by the Swiss Federal Institute of Technology in Lausanne showed that chatbots, specifically those powered by GPT-4, are more effective at persuading people in debates than human counterparts. In experiments involving 820 participants, individuals engaged in debates on various topics with either a human or a GPT-4-powered chatbot. The results showed an 81.7 percent higher likelihood of participants being swayed by the chatbots’ arguments when the AI had access to personal information from questionnaires. (Read more atNew Scientist)\n\nMicrosoft and OpenAI plan to build Stargate, a $100 billion server farm and supercomputerSources say the planned data center will be multiple times larger and more powerful than Azure’s current units powering OpenAI’s models. Such a supercomputer center would cost twice what Microsoft has spent this year for all its capital expenditures for servers, buildings, and other equipment. A computer and server farm this large could require as much as 5 gigawatts of power, posing significant energy costs along with the need for AI chips. If approved, Stargate could launch as soon as 2028; smaller AI-dedicated data centers in Wisconsin are projected to launch in 2026. (Check out the report inThe Information)",
    "qa": [
      {
        "question": "Hugging Face và Cloudflare hợp tác cung cấp dịch vụ gì cho các nhà phát triển AI?",
        "options": {
          "A": "Cung cấp miễn phí các mô hình AI mã nguồn mở.",
          "B": "Cung cấp dịch vụ suy luận GPU serverless cho các mô hình AI mở.",
          "C": "Phát triển các công cụ quản lý cơ sở hạ tầng GPU.",
          "D": "Cung cấp các khóa đào tạo về phát triển ứng dụng AI."
        },
        "answer": "B"
      },
      {
        "question": "OpenAI cập nhật API fine-tuning của mình với mục tiêu chính là gì?",
        "options": {
          "A": "Giảm chi phí sử dụng API cho người dùng.",
          "B": "Cải thiện khả năng kiểm soát quá trình huấn luyện và đánh giá mô hình.",
          "C": "Tăng tốc độ xử lý dữ liệu đầu vào.",
          "D": "Mở rộng số lượng mô hình được hỗ trợ."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đang gây lo ngại trong việc các công ty công nghệ lớn thu thập dữ liệu huấn luyện AI?",
        "options": {
          "A": "Sự khan hiếm của dữ liệu chất lượng cao.",
          "B": "Chi phí quá cao để mua dữ liệu huấn luyện.",
          "C": "Các vấn đề về quyền riêng tư khi sử dụng dữ liệu cá nhân mà không có sự đồng ý rõ ràng.",
          "D": "Sự cạnh tranh gay gắt giữa các công ty để giành quyền sở hữu dữ liệu."
        },
        "answer": "C"
      },
      {
        "question": "EVI (Empathic Voice Interface) của Startup Hume có khả năng đặc biệt nào?",
        "options": {
          "A": "Tự động dịch ngôn ngữ sang nhiều thứ tiếng khác nhau.",
          "B": "Tạo ra các phản hồi thấu cảm bằng cách xử lý các sắc thái trong giọng nói.",
          "C": "Phân tích và dự đoán cảm xúc của người dùng thông qua biểu cảm khuôn mặt.",
          "D": "Điều khiển các thiết bị thông minh bằng giọng nói."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng mới nào của DALL·E cho phép người dùng tùy chỉnh hình ảnh một cách chính xác hơn?",
        "options": {
          "A": "Khả năng tạo ra hình ảnh 3D từ văn bản mô tả.",
          "B": "Khả năng chọn các khu vực cụ thể để chỉnh sửa và nhập các thay đổi mô tả.",
          "C": "Khả năng tự động cải thiện độ phân giải của hình ảnh.",
          "D": "Khả năng tạo ra các hình ảnh động từ hình ảnh tĩnh."
        },
        "answer": "B"
      },
      {
        "question": "Sự gia tăng quảng cáo sách do AI tạo ra trên màn hình khóa Kindle đã gây ra vấn đề gì?",
        "options": {
          "A": "Giá sách Kindle tăng cao.",
          "B": "Người dùng khó tìm thấy các tựa sách phù hợp với sở thích đọc của mình.",
          "C": "Thời lượng pin của Kindle giảm đáng kể.",
          "D": "Amazon phải đối mặt với các vụ kiện liên quan đến bản quyền."
        },
        "answer": "B"
      },
      {
        "question": "Command R+ của Cohere được tối ưu hóa cho đối tượng người dùng nào?",
        "options": {
          "A": "Các nhà nghiên cứu AI học thuật.",
          "B": "Các doanh nghiệp muốn ứng dụng AI vào hoạt động.",
          "C": "Các cá nhân sử dụng AI cho mục đích giải trí.",
          "D": "Các tổ chức chính phủ muốn tăng cường an ninh mạng."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng \"Tool Use\" của Claude AI cho phép người dùng làm gì?",
        "options": {
          "A": "Tự động tạo ra các ứng dụng AI hoàn chỉnh.",
          "B": "Kết nối Claude với các công cụ bên ngoài để truy xuất thông tin và tích hợp các chức năng của bên thứ ba.",
          "C": "Huấn luyện Claude với dữ liệu tùy chỉnh của người dùng.",
          "D": "Tăng cường khả năng bảo mật của Claude."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của sự hợp tác giữa Anh và Mỹ trong lĩnh vực an toàn AI là gì?",
        "options": {
          "A": "Phát triển các tiêu chuẩn toàn cầu cho việc phát triển AI.",
          "B": "Xây dựng các giao thức kiểm tra tiên tiến cho các mô hình AI.",
          "C": "Ngăn chặn việc sử dụng AI cho mục đích quân sự.",
          "D": "Thúc đẩy sự phát triển của AI ở các nước đang phát triển."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã thúc đẩy Yahoo mua lại ứng dụng tin tức AI Artifact?",
        "options": {
          "A": "Số lượng người dùng hoạt động lớn của Artifact.",
          "B": "Công nghệ AI tiên tiến của Artifact trong việc tuyển chọn và cá nhân hóa nội dung tin tức.",
          "C": "Khả năng tạo ra tin tức tự động của Artifact.",
          "D": "Mối quan hệ đối tác độc quyền của Artifact với các hãng tin lớn."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-245": {
    "title": "Big Updates for GPT-4 Turbo, Gemini 1.5, Mixtral, and More",
    "collection": "data-points",
    "content": "This week's top AI news and research stories featured Google's Vertex AI Agent Builder, security holes in generated code, a series of policy violations in the GPT Store, and RA-DIT, a fine-tuning procedure that trains an LLM and retrieval model together to improve the LLM’s ability to capitalize on retrieved content. But first:\n\nU.S. and Japan governments launch major AI research initiativesThe partnership is bolstered by $110 million in funding from major tech companies including Nvidia, Microsoft, Amazon, and others. Other partners in the collaboration include the University of Washington and the University of Tsukuba focusing on projects in AI research, entrepreneurship, and workforce development, while Carnegie Mellon University and Tokyo's Keio University will explore advanced AI technologies including robotics and AI-human interaction. (Read more atThe Register)\n\nOpenAI introduces GPT-4 Turbo with Vision for general availability via APIThe upgraded version incorporates vision and audio capabilities and promises increased speed, affordability, and a larger input context of up to 128,000 tokens. The new API now supports requests for vision recognition and analysis in JSON format, streamlining the integration process for developers. Notable implementations of OpenAI’s updated model include Cognition’s AI coding agent, Healthify’s nutritional analysis tool, and TLDraw’s virtual whiteboard that translates drawings into functional websites. (Find more details atVentureBeat)\n\nGemini 1.5 Pro launches globally with enhanced audio capabilities and developer featuresGemini 1.5 Pro is now available in over 180 countries through the Gemini API in a public preview. The latest updates include the ability to modify system instructions and a new JSON mode for better control over outputs, as well as the debut of an improved text embedding model for better performance metrics. (Learn more at Google’sblog)\n\nSpotify unveils AI playlist generatorThe “AI Playlist” feature enables users to generate customized playlists based on textual prompts. Accessible via the mobile app, this tool lets users input descriptions like \"music to read to on a cold, rainy day\" to receive a tailored list of 30 songs. The service is currently in beta and limited to a few geographical regions, with plans to expand in the future. (Read the news atThe Verge)\n\nGoogle launches specialized code-generation modelsCodeGemma, an initiative by Google in collaboration with Hugging Face, features a trio of open access, code-specialized language models designed to enhance coding practices across various platforms. The family includes a 2B model focused on infilling and open-ended generation, a 7B model trained on code and natural language, and a 7B instruct model for interactive code-related discussions. The suite is available on Hugging Face's Hub. (Read more at Hugging Face’sblog)\n\nAI project turns personal memories into synthetic photosThe Synthetic Memories project, led by the research and design studio Domestic Data Streamers, is harnessing generative AI capabilities to recreate lost or unphotographed memories. The studio uses AI models like DALL-E to create \"memory-based reconstructions\" which help individuals, especially from immigrant and refugee backgrounds, visualize past scenes. (Read the report atMIT Technology Review)\n\nMicrosoft establishes AI hub in LondonThe hub will reportedly be led by Jordan Hoffmann, a distinguished AI scientist formerly with Inflection AI and DeepMind, and will focus on developing advanced language models and related technologies. This move coincides with Microsoft's commitment to invest £2.5 billion in the UK to enhance AI capabilities and infrastructure. (Read the story atTechCrunch)\n\nMistral AI introduces Mixtral 8x22BThe 281GB large language model (LLM) is designed to compete with major industry players like OpenAI, Meta, and Google. The open source model boasts a 176 billion parameter size and a 65,000-token context window. (Read more details atZDNet)\n\nAI-powered reminders help reduce smartphone screen timeResearchers have developed an automated system that learns from smartphone users' behaviors to send personalized pop-up reminders encouraging them to close attention-grabbing apps like TikTok and Instagram. The adaptive AI models, which continue learning from user behavior during deployment, reduced app visit frequency by up to 9%. Although the study is preliminary and had high drop-out rates, the AI interventions show promise in helping users manage their screen time more effectively. Experts suggest that incorporating users' emotional motivations for changing phone usage behaviors could further enhance the AI feedback's impact. (Read an interview with researchers atNew Scientistand check out the originalpaper)\n\nGenerativeAI adoption boosts artists' productivity and pleases audiences, but may reduce noveltyA study analyzing over 4 million artworks posted by 53,000 users on an unnamed art-sharing website found that artists who adopted AI tools experienced a 25% increase in productivity and a 50% rise in positive reactions to their work. However, the novelty of the subject matter and details in AI-generated artworks decreased compared to those created by traditional methods. The study, conducted by researchers at Boston University, covered the period from January 2022 to May 2023, which saw the release of popular AI image generators like Midjourney, DALL-E, and Stable Diffusion. While the use of AI tools accelerates the ability to produce art, it raises questions about the impact on the creative process and the meaning behind the artworks. (Read more about the study atNew Scientist, or peruse thepaperitself)\n\nSchools struggle to address AI-generated explicit images of studentsSchool districts across the United States are facing a new challenge as male students use AI-powered apps to generate sexually explicit images of their female classmates. These deepfakes can have severe consequences for the targeted girls, harming their mental health, reputations, and future prospects. As the use of exploitative AI apps in schools is a recent phenomenon, many districts seem unprepared to address the issue effectively, leaving students vulnerable. Experts and affected families are calling for updated school policies and laws to protect students from this form of harassment and abuse. (Read more atThe New York Times)\n\nA race to build data centers in the Middle EastThe United Arab Emirates and Saudi Arabia are competing to become the regional leader in artificial intelligence. Both countries are investing heavily in building data centers essential for supporting AI technology. The UAE is off to a strong start with 52 operational data centers, while Saudi Arabia has 60, though many have lower power capacities. Despite challenges such as the need for skilled technicians and the high energy requirements of AI servers, both nations are committed to expanding their data center infrastructure to support their AI ambitions and diversify their economies away from oil. (Learn more atBloomberg)\n\nResearchers question novelty and utility of AI-discovered materialsGoogle's AI company DeepMind recently announced the discovery of millions of new materials using deep learning techniques, claiming it to be a groundbreaking expansion of stable materials known to humanity. However, UC-Santa Barbara researchers analyzing a subset of these AI-generated compounds have found no strikingly novel or useful materials among them. Critics argue that while DeepMind’s AI methodology shows promise, the specific findings may be oversold and impractical. The debate highlights the challenges of effectively utilizing AI and machine learning to discover truly innovative and impactful materials for concrete use cases. (Read an interview with the researchers at404 Media, or check out theresearch paper)\n\nAndrej Karpathy builds a version of GPT-2 directly in C, no Python requiredKarpathy, recently of OpenAI, boasted that he could train OpenAI’s older language model using just 1000 lines of code in a single file. Last year, he undertook a similar project for a small version of Llama 2. He proposes to do the same demonstrations on open source models with more modern architectures, including Llama 2, Gemma, and Mistral. In atweet, Karpathy said his goals were primarily educational, but that the project could have practical implications for future work. (Check out the GitHub repository forLLM.C)\n\nAI giants skirt rules and butt heads in pursuit of training dataTech companies like OpenAI, Google, and Meta are going to great lengths to obtain the vast amounts of digital data needed to train their AI models. The hunger for data has grown as researchers discovered that more information leads to better-performing AI systems. With concerns that the industry could exhaust high-quality online data by 2026, companies are exploring the use of synthetic data generated by AI itself to train future models, though the effectiveness of this approach remains uncertain. Meanwhile, AI companies have transcribed copyrighted YouTube videos, considered buying a publishing house, and debated gathering data from across the internet despite potential legal issues. (Read the feature story atThe New York Times)",
    "qa": [
      {
        "question": "Chính phủ Hoa Kỳ và Nhật Bản hợp tác trong lĩnh vực AI với sự hỗ trợ tài chính từ các công ty công nghệ lớn, tập trung vào những lĩnh vực nào?",
        "options": {
          "A": "Phát triển phần cứng AI, năng lượng tái tạo và y tế từ xa.",
          "B": "Nghiên cứu AI, khởi nghiệp và phát triển lực lượng lao động.",
          "C": "An ninh mạng, quốc phòng và khám phá không gian.",
          "D": "Nông nghiệp thông minh, giáo dục trực tuyến và giao thông vận tải tự động."
        },
        "answer": "B"
      },
      {
        "question": "GPT-4 Turbo with Vision mới của OpenAI có điểm gì nổi bật so với phiên bản trước?",
        "options": {
          "A": "Chỉ hỗ trợ xử lý ngôn ngữ tự nhiên tốt hơn.",
          "B": "Tích hợp khả năng thị giác và âm thanh, tăng tốc độ, giảm chi phí và mở rộng ngữ cảnh đầu vào.",
          "C": "Giảm kích thước mô hình để dễ dàng triển khai trên các thiết bị di động.",
          "D": "Tăng cường khả năng bảo mật và chống lại các cuộc tấn công độc hại."
        },
        "answer": "B"
      },
      {
        "question": "Gemini 1.5 Pro hiện đã có mặt ở bao nhiêu quốc gia thông qua Gemini API?",
        "options": {
          "A": "Hơn 50 quốc gia.",
          "B": "Hơn 100 quốc gia.",
          "C": "Hơn 150 quốc gia.",
          "D": "Hơn 180 quốc gia."
        },
        "answer": "D"
      },
      {
        "question": "Tính năng 'AI Playlist' của Spotify cho phép người dùng tạo danh sách phát nhạc như thế nào?",
        "options": {
          "A": "Bằng cách chọn thể loại nhạc và nghệ sĩ yêu thích.",
          "B": "Bằng cách nhập mô tả bằng văn bản về tâm trạng hoặc hoạt động.",
          "C": "Bằng cách quét mã QR của bài hát.",
          "D": "Bằng cách chia sẻ danh sách phát của bạn bè."
        },
        "answer": "B"
      },
      {
        "question": "CodeGemma của Google là gì?",
        "options": {
          "A": "Một hệ điều hành mới dành cho các thiết bị di động.",
          "B": "Một bộ công cụ phát triển trò chơi AI.",
          "C": "Một bộ ba mô hình ngôn ngữ chuyên biệt về mã nguồn mở để cải thiện thực hành viết code.",
          "D": "Một nền tảng lưu trữ và chia sẻ mã nguồn trực tuyến."
        },
        "answer": "C"
      },
      {
        "question": "Dự án 'Synthetic Memories' sử dụng AI để làm gì?",
        "options": {
          "A": "Tạo ra các nhân vật ảo có trí nhớ nhân tạo.",
          "B": "Tái tạo những ký ức đã mất hoặc không được chụp ảnh lại.",
          "C": "Phân tích và lưu trữ dữ liệu về ký ức của con người.",
          "D": "Phát triển các thiết bị cấy ghép trí nhớ."
        },
        "answer": "B"
      },
      {
        "question": "Trung tâm AI mới của Microsoft ở London sẽ tập trung vào điều gì?",
        "options": {
          "A": "Phát triển phần cứng AI tiên tiến.",
          "B": "Phát triển các mô hình ngôn ngữ tiên tiến và các công nghệ liên quan.",
          "C": "Nghiên cứu về đạo đức và an toàn AI.",
          "D": "Ứng dụng AI trong lĩnh vực y tế."
        },
        "answer": "B"
      },
      {
        "question": "Mixtral 8x22B của Mistral AI có đặc điểm nổi bật nào?",
        "options": {
          "A": "Chỉ hoạt động trên các thiết bị di động.",
          "B": "Là một mô hình ngôn ngữ lớn mã nguồn mở với kích thước tham số lớn và cửa sổ ngữ cảnh rộng.",
          "C": "Chuyên về xử lý hình ảnh và video.",
          "D": "Được thiết kế để tối ưu hóa hiệu suất năng lượng."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu về việc sử dụng lời nhắc nhở AI để giảm thời gian sử dụng điện thoại thông minh cho thấy điều gì?",
        "options": {
          "A": "Không có tác dụng đáng kể đến thói quen sử dụng điện thoại.",
          "B": "Giảm tần suất truy cập ứng dụng lên đến 9%, nhưng cần xem xét yếu tố cảm xúc của người dùng.",
          "C": "Tăng cường sự phụ thuộc vào điện thoại thông minh.",
          "D": "Chỉ hiệu quả với người dùng trẻ tuổi."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu về tác động của AI đến nghệ thuật cho thấy điều gì?",
        "options": {
          "A": "AI không có tác động đáng kể đến năng suất và sự đón nhận của khán giả.",
          "B": "AI làm giảm năng suất của nghệ sĩ và sự đón nhận của khán giả.",
          "C": "AI giúp tăng năng suất và sự đón nhận của khán giả, nhưng có thể làm giảm tính mới lạ của tác phẩm.",
          "D": "AI chỉ phù hợp với một số thể loại nghệ thuật nhất định."
        },
        "answer": "C"
      }
    ]
  },
  "data-points-issue-246": {
    "title": "Meta’s Llama 3-powered AI assistant, Infini-Attention, and a new all-electric Atlas robot",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeatureda new breed of audio generators, benchmarks that rank large language models’ performance of tasks associated with taxes, finance, and law, a survey on manufacturers’ use of AI in engineering, design, procurement, and production, and a method that generates a 3D model from a single image based on Stability’s video diffusion model. But first:\n\nLlama 3 has landedMeta released Llama 3, a new set of open-source large multimodal models that perform strongly on industry benchmarks. The 8 billion and 70 billion parameter models, available now, offer improved reasoning capabilities over Llama 2; a promised 400 billion parameter version is still in training. The models will be widely available on AWS, Azure, Google Cloud, HuggingFace, and other leading cloud providers and hardware platforms. (See Meta’spress releasefor more)\n\nMeta expands AI assistant to compete with ChatGPTMeta announced its new AI assistant, powered by Llama 3, would be integrated into Instagram, Facebook, WhatsApp, Messenger, and via a standalone website. The assistant now incorporates real-time search results from Bing and Google, and its image generation capabilities have been upgraded to create animations and high-resolution images on the fly. (Read an interview with Mark Zuckerberg atThe Verge)\n\nGrok-1.5V shows strong vision capabilitiesX’s open-source large multimodal model shows competitive performance across various computer vision benchmarks, including multi-disciplinary reasoning and understanding documents, science diagrams, charts, screenshots, and photographs. Grok-1.5V particularly excels in the new RealWorldQA benchmark, which attempts to measure real-world spatial understanding, outperforming GPT-4, Claude, and Gemini Pro in this domain. (See therelease notesat X)Adobe partners with AI companies to expand Premiere Pro's capabilitiesIn addition to developing its own Firefly AI video model, Adobe is offering what it calls a “sneak” preview of integrated AI tools from Runway, Pika Labs, and OpenAI's Sora into Premiere Pro. These partnerships would give users access to a wider range of AI-powered features for generating B-roll, extending shots, and more. Integrating third-party AI models into Adobe's software ecosystem could benefit both Adobe and the AI companies involved. (Read Adobe’supdateor the story atThe Verge)OpenAI launches custom GPT-4 model for JapanAlong with opening new offices in Tokyo, OpenAI is providing early access to a custom version of GPT-4 specifically optimized for the Japanese language. The model offers improved performance in translating and summarizing Japanese text and operates up to 3x faster than its predecessor. The custom model has already shown promising results with the English learning app Speak, and OpenAI plans to release it more broadly via its API in the coming months. (Check out the news atOpenAI)\n\nNext-generation Atlas boasts improved strength and flexibilityThe new Atlas robot from Boston Dynamics features compact electric actuators that provide strength exceeding that of an elite human athlete and a range of motion surpassing human capabilities. Atlas’s unusual movements, showcased in an introductory video, are somewhat uncanny but allow for greater efficiency . Despite its unconventional design, Boston Dynamics CEO Robert Playter believes people will adapt to the robot's capabilities as long as it delivers sufficient productivity. (Read Playter’s interview atIEEE Spectrum)\n\nNew features and improvements in OpenAI's Assistants API Beta v2OpenAI is launching an improved version of its Assistants API. The update includes a more powerful file retrieval tool (offering up to 10,000 files per assistant), simplified vector stores, and new controls for managing token usage and conversation histories. The Assistants API now also supports streaming and the use of fine-tuned versions of GPT-3.5. (See therelease noteson OpenAI’s website)\n\nResearch: Infinite context with finite memoryGoogle researchers introduce Infini-attention, an efficient method that scales transformer language models to infinitely long inputs with bounded memory and computation. Infini-attention incorporates a compressive memory into the standard attention mechanism, enabling both local masked attention and long-term linear attention within a single Transformer block. Experiments demonstrate Infini-attention's effectiveness on long-context language modeling, passkey retrieval, and book summarization tasks, introducing minimal additional parameters while enabling fast streaming inference. (Read the researchpaper)Research: The potential impact of advanced AI assistants on societyA new paper by Google DeepMind argues that as AI assistants become more advanced and capable of communicating in natural language, new challenges arise in terms of trust, privacy, and appropriate human-AI relationships. Safeguards must be put in place to ensure users can reliably identify automated assistants and maintain control over their interactions. AI assistants should also be designed to cooperate and coordinate with each other to meet human preferences and avoid unnecessary conflicts. (Check out the story atDeepMind)\n\nResearch: VASA-1 generates virtual characters with lifelike facial expressions and head movementsMicrosoft researchers developed VASA, a new framework that generates highly realistic videos of talking faces using just a single still image and an audio clip. VASA-1, the first model based on this framework, does not clone or simulate voices, but can produce synchronized lip movements for an audio file, while also capturing a wide range of natural facial expressions and head motions. (Read the paper and see examples atMicrosoft)Research: How synthetic data fuels LLMs’ expansionSynthetic data and instruction tuning are emerging as powerful tools for training large language models, enabling them to learn complex reasoning skills and reduce harmful biases. These models, such as Anthropic's Claude and Meta’s Llama 2, demonstrate remarkable abilities to follow complex instructions, engage in open-ended dialogue, and even write code. However, synthetic datasets need to be carefully generated and curated in order to reap their full benefits. (Dig into the researchers’ arguments in thepaper)\n\nAI defeats human pilot in simulated dogfightThe United States Air Force recently announced that an AI agent successfully piloted the X-62 VISTA aircraft during a simulated dogfight against a human F-16 pilot above California’s Edwards Air Force base in 2023. The X-62, part of DARPA's Air Combat Evolution (ACE) program, is part of a broader test of autonomous flight capabilities. “Dogfighting was the problem to solve so we could start testing autonomous artificial intelligence systems in the air,” said chief test pilot Bill Gray. (Read more atThe Aviationist)\n\nAI Index 2024 highlights AI's rapid advancements and societal impactThe seventh edition of the AI Index report, the most comprehensive to date, reveals that AI has surpassed human performance in several tasks and is having a significant impact on many sectors, including labor and scientific discovery. But the report also highlights concerns regarding the lack of standardization in evaluation criteria, the increasing costs of training state-of-the-art AI models, and the growing public nervousness toward AI products and services. (Explore thefull report)\n\nMicrosoft’s billion-dollar bet on AI in the UAEMicrosoft announced a $1.5 billion investment in G42, an Abu Dhabi-based AI group, marking the company's first major AI partnership in the Middle East. The deal has raised concerns among US officials due to G42's alleged links to the Chinese government, which the company denies. (See the story atCNN)",
    "qa": [
      {
        "question": "Llama 3 của Meta có những cải tiến đáng chú ý nào so với Llama 2?",
        "options": {
          "A": "Khả năng tạo ảnh động và ảnh có độ phân giải cao.",
          "B": "Khả năng suy luận được cải thiện.",
          "C": "Tích hợp trực tiếp vào ứng dụng Speak.",
          "D": "Tốc độ xử lý nhanh hơn gấp 3 lần."
        },
        "answer": "B"
      },
      {
        "question": "Trợ lý AI mới của Meta được tích hợp vào những nền tảng nào?",
        "options": {
          "A": "YouTube, TikTok, Twitter.",
          "B": "Instagram, Facebook, WhatsApp, Messenger.",
          "C": "LinkedIn, Slack, Zoom.",
          "D": "Gmail, Google Docs, Google Meet."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Grok-1.5V của X thể hiện khả năng vượt trội trong lĩnh vực nào?",
        "options": {
          "A": "Tạo video từ hình ảnh tĩnh và âm thanh.",
          "B": "Hiểu và tóm tắt văn bản tiếng Nhật.",
          "C": "Hiểu không gian thực tế.",
          "D": "Điều khiển robot Atlas."
        },
        "answer": "C"
      },
      {
        "question": "Adobe hợp tác với những công ty AI nào để mở rộng khả năng của Premiere Pro?",
        "options": {
          "A": "Google, Microsoft, Amazon.",
          "B": "Runway, Pika Labs, OpenAI.",
          "C": "DeepMind, Anthropic, Stability AI.",
          "D": "Nvidia, AMD, Intel."
        },
        "answer": "B"
      },
      {
        "question": "OpenAI đã tối ưu hóa phiên bản GPT-4 đặc biệt cho ngôn ngữ nào?",
        "options": {
          "A": "Tiếng Trung Quốc.",
          "B": "Tiếng Tây Ban Nha.",
          "C": "Tiếng Nhật Bản.",
          "D": "Tiếng Đức."
        },
        "answer": "C"
      },
      {
        "question": "Robot Atlas thế hệ mới của Boston Dynamics có đặc điểm nổi bật nào?",
        "options": {
          "A": "Sử dụng động cơ đốt trong để tăng sức mạnh.",
          "B": "Có khả năng di chuyển vượt trội so với con người.",
          "C": "Được thiết kế để trông giống hệt con người.",
          "D": "Có khả năng tự học hỏi và thích nghi với môi trường."
        },
        "answer": "B"
      },
      {
        "question": "API Assistants Beta v2 của OpenAI có những cải tiến nào?",
        "options": {
          "A": "Giảm số lượng tệp tối đa cho mỗi trợ lý.",
          "B": "Loại bỏ hỗ trợ cho các phiên bản GPT-3.5 đã tinh chỉnh.",
          "C": "Hỗ trợ streaming và sử dụng các phiên bản GPT-3.5 đã tinh chỉnh.",
          "D": "Tăng độ phức tạp của vector stores."
        },
        "answer": "C"
      },
      {
        "question": "Infini-attention là phương pháp nghiên cứu của Google nhằm giải quyết vấn đề gì?",
        "options": {
          "A": "Tăng tốc độ xử lý ngôn ngữ tự nhiên.",
          "B": "Mở rộng khả năng xử lý ngữ cảnh dài của mô hình ngôn ngữ.",
          "C": "Giảm thiểu lượng dữ liệu cần thiết để huấn luyện mô hình.",
          "D": "Cải thiện độ chính xác của mô hình trong việc dịch thuật."
        },
        "answer": "B"
      },
      {
        "question": "VASA-1 của Microsoft có khả năng gì?",
        "options": {
          "A": "Tạo ra các nhân vật ảo có biểu cảm khuôn mặt và cử động đầu giống thật từ một hình ảnh và một đoạn âm thanh.",
          "B": "Dự đoán chính xác kết quả của các trận đấu thể thao.",
          "C": "Phát hiện và ngăn chặn các cuộc tấn công mạng.",
          "D": "Tự động lái xe an toàn trên mọi địa hình."
        },
        "answer": "A"
      },
      {
        "question": "Báo cáo AI Index 2024 chỉ ra những lo ngại nào về sự phát triển của AI?",
        "options": {
          "A": "Sự thiếu hụt nhân lực có trình độ cao trong lĩnh vực AI.",
          "B": "Sự thiếu tiêu chuẩn hóa trong các tiêu chí đánh giá và chi phí huấn luyện mô hình ngày càng tăng.",
          "C": "Sự chậm trễ trong việc ứng dụng AI vào các ngành công nghiệp.",
          "D": "Sự cạnh tranh gay gắt giữa các công ty AI."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-247": {
    "title": "Adobe makes AI edits easier, HuggingFace’s FineWeb dataset, and a new AI safety board in the U.S.",
    "collection": "data-points",
    "content": "This week's top AI news and research storiesfeaturedApple's new family of open large language models, Stanford’s seventh AI Index Report, Amazon's removal of its AI-driven checkout service, and an AI method to predict scientific discoveries. But first:\n\nAdobe’s new Firefly image model features AI photo editingThe most notable addition, available in the new Photoshop beta, is the Reference Image feature, which allows users to upload their own images to guide the AI's output, matching elements like style and color. Other new tools include Generate Background for creating new backgrounds for product photos, Enhance Detail for increasing image clarity, Generate Similar for producing content similar to a selected generated image, and Generate Image for creating entire images from text descriptions. Adobe says the third-generation Firefly model delivers improved photorealistic quality and can better understand long, descriptive prompts. (Read more atThe Verge)\n\nMicrosoft introduces Phi-3 family of open-source “small language” modelsPhi-3-mini, a 3.8 billion parameter model, is now available on Azure AI Studio, Hugging Face, and Ollama, with Phi-3-small (7 billion parameters) and Phi-3-medium (14 billion) coming soon. The small language models are designed for low resources, low latency, and low cost. (Find more details at Microsoft Azure’sblog)\n\nMeta AI update comes to smart glassesRay-Ban Meta smart glasses now allow users to make video calls, letting them share what they see in real-time. The glasses feature Meta AI, an intelligent assistant that provides information based on voice commands and the glasses' camera feed. This AI update, currently in beta for US and Canadian users, enables the glasses to translate foreign language text or offer helpful suggestions based on what the user is looking at. (Read the news at Meta’sblog)\n\nAI companies join forces to combat child exploitation risksOpenAI, Meta, Google, and other AI companies partnered with child-safety organizations to implement new safeguards against the exploitation of children through generative AI tools. The alliance aims to minimize risks by avoiding using datasets with child sexual content, investing in testing to identify vulnerabilities, and adding signals to flag AI-generated content. (Read the story atThe Wall Street Journal)\n\nAutonomous racecars debut at the Abu Dhabi Grand PrixArtificial Intelligence Autonomous Racing League (A2RL) held its first public demonstration featuring self-driving race cars on April 27 in Abu Dhabi. Eight teams competed for a $2.25 million prize using modified Dallara-built Super Formula SF23 cars, the fastest open-wheel racers outside of Formula 1, equipped with cutting-edge autonomous technology. While the cars looked similar, the extensive modifications, including drive-by-wire systems, sensor arrays, and onboard computers, allowed teams to showcase their AI coding skills. The race didn’t always go smoothly, but TUM was the winner. (Learn more atThe Verge)\n\nU.S. forms AI safety board with tech CEOsThe Biden administration established the Artificial Intelligence Safety and Security Board, which includes top executives from OpenAI, Nvidia, Microsoft, Alphabet, and other major companies. The board, working with the Department of Homeland Security, aims to develop recommendations for safely deploying AI within critical infrastructure sectors like power grids, transportation, and manufacturing. (Full story atThe Wall Street Journal)\n\nAI-designed gene editor successfully edits human genome for the first timeProfluent, a biotechnology company, used AI to design a gene editor called OpenCRISPR-1 that can precisely edit the human genome. By training large language models on over a million CRISPR operations, the company generated a diverse array of gene editors, some of which outperformed the commonly used SpCas9. While the AI-designed editors show promise, they still need to undergo clinical trials to assess their safety and efficacy before being used in healthcare applications. (Read more atThe New York Times)\n\nMicrosoft and Amazon deals face U.K. antitrust scrutinyThe U.K.'s Competition and Markets Authority (CMA) asked for public comments on partnerships between Microsoft and French AI firm Mistral, and Amazon and U.S. startup Anthropic. The regulator also inquired into Microsoft's hiring of former employees from Inflection AI. This invitation to comment is the first step in an information gathering process before the launch of a formal review to determine if Microsoft and Amazon’s partnerships with these AI companies qualify as mergers. (Check out the news atCNBC)\n\nHuggingFace’s FineWeb boasts 15 trillion tokens of optimized web dataFineWeb is a new dataset of cleaned and deduplicated English web data from CommonCrawl, processed using the Datatrove library for optimal performance in large language models (LLMs). Although it initially aimed to replicate the RefinedWeb dataset, FineWeb's additional filtering steps enabled it to surpass RefinedWeb's performance and outperform models trained on other high-quality web datasets in benchmark tasks. (Access the dataset on Hugging Face’swebsite)Snowflake unveils Arctic, an open-source, dense mixture-of-experts (MoE) modelArctic is designed for enterprise tasks such as SQL generation, coding, and instruction following. The model is noteworthy for its size, Apache 2.0 open-source license, and dense MoE hybrid transformer architecture, which combines a 10 billion parameter dense transformer model with a residual 128×3.66 billion MoE Multi-Layer Perceptron (MLP). This results in 480 billion total parameters but only 17 billion active parameters, making the model more efficient. (See the release notes on Snowflake’swebsite)\n\nFuture of Humanity Institute closes after 19 yearsThe multidisciplinary research group at Oxford University founded by Nick Bostrom in 2005 conducted research on various topics related to humanity's future. FHI faced administrative challenges within the Faculty of Philosophy, including a freeze on fundraising and hiring starting in 2020. In late 2023, the Faculty decided not to renew the contracts of the remaining FHI staff, leading to the institute's closure on April 16, 2024. (See the announcementhere)",
    "qa": [
      {
        "question": "Tính năng mới nào của Adobe Firefly cho phép người dùng tải ảnh lên để định hướng đầu ra của AI?",
        "options": {
          "A": "Generate Background",
          "B": "Reference Image",
          "C": "Enhance Detail",
          "D": "Generate Similar"
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của dòng mô hình ngôn ngữ nhỏ Phi-3 của Microsoft là gì?",
        "options": {
          "A": "Đạt được độ chính xác cao nhất trong các tác vụ phức tạp.",
          "B": "Sử dụng ít tài nguyên, độ trễ thấp và chi phí thấp.",
          "C": "Thay thế hoàn toàn các mô hình ngôn ngữ lớn hiện có.",
          "D": "Tích hợp với các thiết bị phần cứng chuyên dụng."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng mới nào được thêm vào kính thông minh Ray-Ban Meta cho phép người dùng chia sẻ những gì họ đang thấy trong thời gian thực?",
        "options": {
          "A": "Dịch văn bản ngoại ngữ",
          "B": "Đề xuất hữu ích dựa trên những gì người dùng đang nhìn",
          "C": "Thực hiện cuộc gọi video",
          "D": "Cung cấp thông tin dựa trên lệnh thoại"
        },
        "answer": "C"
      },
      {
        "question": "Liên minh giữa các công ty AI lớn và các tổ chức bảo vệ trẻ em tập trung vào điều gì?",
        "options": {
          "A": "Phát triển các công cụ AI để xác định nội dung xâm hại trẻ em.",
          "B": "Ngăn chặn việc sử dụng AI để khai thác trẻ em.",
          "C": "Cung cấp hỗ trợ tâm lý cho trẻ em bị ảnh hưởng bởi AI.",
          "D": "Nghiên cứu tác động của AI đối với sự phát triển của trẻ em."
        },
        "answer": "B"
      },
      {
        "question": "Đội nào đã giành chiến thắng trong cuộc đua xe tự hành đầu tiên tại Abu Dhabi Grand Prix?",
        "options": {
          "A": "Dallara",
          "B": "Super Formula",
          "C": "A2RL",
          "D": "TUM"
        },
        "answer": "D"
      },
      {
        "question": "Mục tiêu chính của Hội đồng An toàn và An ninh AI mới được thành lập của Hoa Kỳ là gì?",
        "options": {
          "A": "Phát triển các tiêu chuẩn đạo đức cho việc phát triển AI.",
          "B": "Đảm bảo triển khai AI an toàn trong các lĩnh vực cơ sở hạ tầng quan trọng.",
          "C": "Thúc đẩy sự hợp tác quốc tế trong lĩnh vực AI.",
          "D": "Tài trợ cho các nghiên cứu về tác động xã hội của AI."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ chỉnh sửa gen do AI thiết kế OpenCRISPR-1 của Profluent đã đạt được thành tựu gì?",
        "options": {
          "A": "Chỉnh sửa thành công bộ gen của động vật.",
          "B": "Chỉnh sửa thành công bộ gen của thực vật.",
          "C": "Chỉnh sửa thành công bộ gen của con người lần đầu tiên.",
          "D": "Tạo ra một loại thuốc mới dựa trên công nghệ CRISPR."
        },
        "answer": "C"
      },
      {
        "question": "Cơ quan nào của Vương quốc Anh đang xem xét các mối quan hệ hợp tác giữa Microsoft và Mistral, cũng như Amazon và Anthropic?",
        "options": {
          "A": "Cơ quan Tiêu chuẩn Thực phẩm (FSA)",
          "B": "Cơ quan Quản lý Tài chính (FCA)",
          "C": "Cơ quan Cạnh tranh và Thị trường (CMA)",
          "D": "Cơ quan Truyền thông (Ofcom)"
        },
        "answer": "C"
      },
      {
        "question": "Điểm nổi bật của bộ dữ liệu FineWeb của Hugging Face là gì?",
        "options": {
          "A": "Chứa dữ liệu hình ảnh chất lượng cao.",
          "B": "Được tối ưu hóa cho hiệu suất trong các mô hình ngôn ngữ lớn.",
          "C": "Bao gồm dữ liệu từ nhiều ngôn ngữ khác nhau.",
          "D": "Được sử dụng để đào tạo các mô hình AI tạo sinh âm thanh."
        },
        "answer": "B"
      },
      {
        "question": "Lý do chính dẫn đến việc đóng cửa Viện Tương lai Nhân loại (FHI) là gì?",
        "options": {
          "A": "Thiếu kinh phí nghiên cứu.",
          "B": "Thay đổi trong chính sách của Đại học Oxford.",
          "C": "Các vấn đề hành chính và quyết định không gia hạn hợp đồng của nhân viên.",
          "D": "Sự phản đối từ cộng đồng khoa học đối với các nghiên cứu của FHI."
        },
        "answer": "C"
      }
    ]
  },
  "data-points-issue-248": {
    "title": "The GPT2 chatbot mystery",
    "collection": "data-points",
    "content": "This week's top AI news and research stories featured GitHub's Copilot Workspace, OpenAI's new licensing deal, an AI system that identifies landmines in battlefields, and an algorithm that accelerates inferencing of large language models (LLMs) by using small vanilla neural networks to predict which parts of it to use. But first:\n\nAI-assisted coding transforms computer science education(IEEE Spectrum)As generative AI tools become more prevalent in software development, computer science students and educators incorporated this technology but adapted their learning and teaching strategies. While students use AI to solve particular problems and break down complex concepts, educators now emphasize problem decomposition, testing, and debugging skills over just syntax. However, computer science teachers also caution against overreliance on AI, stressing the need to teach students to be skeptical of results and aware of potential biases in the models.\n\nTech giants see cloud computing rebound(Reuters)Amazon, Microsoft, and Alphabet reported strong growth in their cloud computing divisions, driven by increased corporate spending and rising interest in AI. The $270 billion cloud infrastructure market is bouncing back after a slowdown last year, with AI services contributing significantly to the growth of platforms like Azure and Google Cloud. As more businesses adopt AI tools and move their computing needs to the cloud, they consolidate IT spending with the major providers.\n\nMystery “GPT2” chatbot wows experts(Axios)A powerful new chatbot recently appeared on testing site LMSYS, impressing AI experts with its advanced capabilities. Although the bot was quickly taken offline, speculation is rampant that it originated from OpenAI. While OpenAI CEO Sam Altman has confirmed the mystery bot is not GPT-4.5, many believe it represents a significant improvement over existing models.\n\nAmazon rebrands CodeWhisperer as Q Developer(TechCrunch)Q Developer expands on CodeWhisperer's code generation features, assisting with tasks like debugging, upgrading apps, performing security scans, and helping AWS users manage assets and resources. It also introduces Agents, which can autonomously implement features, document code, and manage code upgrading processes. Q Developer is available for free with limitations, while the premium Q Developer Pro version costs $19 per month and includes IP indemnity. It joins a growing number of increasingly autonomous and comprehensive programing assistants.\n\nChatGPT adds memory(OpenAI)ChatGPT now remembers user preferences and context from previous conversations, allowing it to provide more personalized and efficient assistance over time. Users can control their memory settings, instruct ChatGPT to remember or forget details, view and delete specific memories, or turn the feature off completely. For specific applications, ChatGPT can remember preferred style, tone, and format preferences, a developer’s programming languages and frameworks, or frequently accessed company data and visualizations.\n\nU.S. publishes draft guidelines for AI use(Commerce.gov)The National Institute of Standards and Technology (NIST) released four draft publications aimed at improving the safety, security, and trustworthiness of AI systems. The publications cover managing risks of generative AI, reducing threats to AI training data, promoting transparency in digital content, and proposing a plan for global AI standards development. A new program, NIST GenAI, will evaluate and measure generative AI technologies, including methods to distinguish between human- and machine-created content.\n\nNvidia H100 prices drop as H200 release approaches(Tom’s Hardware)Prices for Nvidia’s H100 AI and HPC processors have decreased as supply improves and demand softens in anticipation of the upcoming H200 GPU. Even on the black market in mainland China, where H100 sales moved after U.S. export restrictions, prices are falling as scalpers rush to sell off inventory before the H200's release. It’s expected that increased supply may lead to more availability and lower prices for both of Nvidia’s AI chips, making them more accessible to more developers.\n\nAnthropic launches iOS app and Team plan(Anthropic)Anthropic announced two significant updates to its AI assistant, Claude: a Team plan designed for businesses, which includes advanced privacy, security, and admin controls, and an app for iPhones and iPads that enables users to chat with the AI assistant while on the go. Claude joins ChatGPT, Copilot, and Google’s Gemini in offering its AI chatbot in a mobile app.\n\nReka releases Vibe-Eval, a challenging multimodal model evaluation suite(Reka)Vibe-Eval consists of 269 high-quality image-text prompts and ground truth responses, created by AI experts to be challenging for even the most advanced models. Vibe-Eval aims to provide a well-established benchmark for multimodal chat models, complementing existing multiple-choice benchmarks and chatbot arenas. Vibe-Eval’s first round of evaluations put Gemini Pro 1.5 and GPT-4V on top at solving hard problems, ahead of Claude 3 Opus and Reka’s own Core model.\n\nREFORMS offers guidelines for use of AI and machine learning in science(ScienceAdvances)A group of 19 multidisciplinary researchers proposed a 32-point checklist and two sets of guidelines for AI/ML-based arguments to establish evidence for a scientific claim. The researchers are concerned with data gathering, integrity, and generalizability, as well as establishing appropriate statistical tests to measure computational models’ validity. If adopted, these guidelines could help ensure that AI and ML methods remain useful and widely accepted tools, offering researchers and referees better criteria to evaluate their use.",
    "qa": [
      {
        "question": "Theo bài viết, điều gì đang thay đổi trong cách dạy và học khoa học máy tính khi AI trở nên phổ biến?",
        "options": {
          "A": "Tập trung nhiều hơn vào việc học thuộc cú pháp các ngôn ngữ lập trình.",
          "B": "Giáo viên nhấn mạnh kỹ năng phân tích vấn đề, kiểm thử và gỡ lỗi hơn là chỉ cú pháp.",
          "C": "Sinh viên hoàn toàn dựa vào AI để giải quyết các bài toán phức tạp.",
          "D": "Giáo viên khuyến khích sử dụng AI một cách không phê phán để tăng tốc độ học tập."
        },
        "answer": "B"
      },
      {
        "question": "Sự tăng trưởng của thị trường điện toán đám mây hiện nay được thúc đẩy bởi yếu tố nào?",
        "options": {
          "A": "Sự sụt giảm chi phí dịch vụ điện toán đám mây.",
          "B": "Sự gia tăng chi tiêu của doanh nghiệp và sự quan tâm đến AI.",
          "C": "Sự cạnh tranh gay gắt giữa các nhà cung cấp dịch vụ đám mây nhỏ.",
          "D": "Sự chuyển dịch từ các giải pháp AI tại chỗ sang điện toán đám mây."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì khiến chatbot 'GPT2' bí ẩn gây ấn tượng với các chuyên gia AI?",
        "options": {
          "A": "Khả năng truy cập vào dữ liệu độc quyền của OpenAI.",
          "B": "Khả năng vượt trội so với các mô hình hiện có.",
          "C": "Việc được xác nhận là GPT-4.5 bởi CEO OpenAI.",
          "D": "Giao diện người dùng thân thiện và dễ sử dụng."
        },
        "answer": "B"
      },
      {
        "question": "Amazon CodeWhisperer được đổi tên thành Q Developer và bổ sung tính năng gì mới?",
        "options": {
          "A": "Khả năng tạo ra các ứng dụng hoàn chỉnh chỉ từ một dòng lệnh.",
          "B": "Khả năng tự động triển khai các tính năng, lập tài liệu và quản lý nâng cấp mã.",
          "C": "Khả năng dịch mã từ ngôn ngữ lập trình này sang ngôn ngữ lập trình khác.",
          "D": "Khả năng dự đoán và ngăn chặn các cuộc tấn công mạng vào ứng dụng."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng 'memory' mới của ChatGPT cho phép người dùng làm gì?",
        "options": {
          "A": "Lưu trữ toàn bộ lịch sử trò chuyện trên thiết bị cá nhân.",
          "B": "Kiểm soát những thông tin mà ChatGPT ghi nhớ từ các cuộc trò chuyện trước.",
          "C": "Chia sẻ bộ nhớ của ChatGPT với những người dùng khác.",
          "D": "Tăng tốc độ phản hồi của ChatGPT bằng cách lưu trữ các câu trả lời phổ biến."
        },
        "answer": "B"
      },
      {
        "question": "NIST GenAI, một chương trình mới của Hoa Kỳ, sẽ tập trung vào điều gì?",
        "options": {
          "A": "Phát triển các tiêu chuẩn toàn cầu cho AI.",
          "B": "Đánh giá và đo lường các công nghệ AI tạo sinh.",
          "C": "Cung cấp tài trợ cho các dự án nghiên cứu AI.",
          "D": "Xây dựng cơ sở hạ tầng điện toán đám mây cho các ứng dụng AI."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao giá của Nvidia H100 lại giảm?",
        "options": {
          "A": "Do lệnh cấm xuất khẩu của Hoa Kỳ sang Trung Quốc.",
          "B": "Do nguồn cung tăng lên và nhu cầu giảm trước khi H200 ra mắt.",
          "C": "Do sự cạnh tranh từ các nhà sản xuất chip AI khác.",
          "D": "Do lỗi sản xuất hàng loạt khiến hiệu năng của H100 giảm sút."
        },
        "answer": "B"
      },
      {
        "question": "Anthropic đã ra mắt những cập nhật quan trọng nào cho AI assistant Claude?",
        "options": {
          "A": "Phiên bản miễn phí hoàn toàn và tích hợp với các thiết bị IoT.",
          "B": "Gói Team dành cho doanh nghiệp và ứng dụng cho iPhone và iPad.",
          "C": "Khả năng tạo ra video từ văn bản và tích hợp với các nền tảng mạng xã hội.",
          "D": "Hỗ trợ đa ngôn ngữ hoàn toàn và khả năng dịch thuật thời gian thực."
        },
        "answer": "B"
      },
      {
        "question": "Vibe-Eval được tạo ra với mục đích gì?",
        "options": {
          "A": "Cung cấp một bộ dữ liệu huấn luyện lớn cho các mô hình đa phương thức.",
          "B": "Cung cấp một chuẩn đánh giá thách thức cho các mô hình trò chuyện đa phương thức.",
          "C": "Tạo ra các hình ảnh và văn bản chất lượng cao cho mục đích thương mại.",
          "D": "Phát hiện và loại bỏ nội dung độc hại trên internet."
        },
        "answer": "B"
      },
      {
        "question": "REFORMS đưa ra các hướng dẫn về việc sử dụng AI và Machine Learning trong khoa học nhằm mục đích gì?",
        "options": {
          "A": "Thúc đẩy việc sử dụng AI/ML trong mọi lĩnh vực khoa học mà không cần kiểm chứng.",
          "B": "Đảm bảo tính hữu ích và được chấp nhận rộng rãi của AI/ML bằng cách đưa ra các tiêu chí đánh giá.",
          "C": "Hạn chế việc sử dụng AI/ML trong khoa học để bảo vệ tính toàn vẹn của dữ liệu.",
          "D": "Tăng tốc độ công bố các nghiên cứu khoa học sử dụng AI/ML."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-249": {
    "title": "AI for spies",
    "collection": "data-points",
    "content": "This week's top AI news and research stories featured OpenAI's high-level guidelines for use by human labelers to steer model behavior, all about AlphaFold 3, Saudi Arabia's $100 billion investment AI, and a method that commands a robot to perform practical tasks via signals from an electroencephalogram (EEG). But first:\n\nIBM releases Granite code models to make coding easier for developers(IBM)IBM open-sourced a family of Granite code models, ranging from 3 to 34 billion parameters, to the developer community. The models, trained on code from 116 programming languages, automate many programming tasks like code generation, bug fixing, and documentation to boost developer productivity. In testing, Granite models matched or outperformed other open-source and closed-source code models (including much larger models) on a range of benchmarks, demonstrating strong performance in code fixing, synthesis, explanation, editing, and translation across programming languages.\n\nStack Overflow partners with OpenAI, but many contributors revolt(The Verge)The two companies’ API partnership aims to provide accurate and vetted data to OpenAI users and integrate Stack Overflow’s technical knowledge into ChatGPT. However, the deal has faced significant backlash from Stack Overflow users, who are attempting to remove or edit their posts, leading to bans and content reversals by moderators, who cite the site’s Terms of Service. The controversy highlights the ongoing debate about who owns user-generated content on online platforms and whether users have the right to control how their data is used, especially in the context of AI training.\n\nElevenLabs teases song generator with realistic vocals(Tom’s Guide)ElevenLabs, known for its AI voice cloning, announced a new music generator that creates full-length songs (between two and three minutes) from a single text prompt. The AI-generated tracks, spanning various popular genres, feature natural-sounding vocals that compare favorably to competitors’. ElevenLabs’ product is still not publicly available, but it follows releases by Udio and Suno that have shown rapid advances in AI models’ ability to generate longer and more structured songs.\n\nMicrosoft deploys air-gapped AI for spies(Ars Technica/Bloomberg)Microsoft created a version of OpenAI’s GPT-4 language model that operates in a secure, isolated environment for use by U.S. intelligence agencies. The system, which has been in development for 18 months, allows agencies to analyze classified data without the risks associated with internet connectivity, like data breaches or hacking attempts. The need for such a specialized system shows the growing collaboration between major tech companies and government entities in the realm of AI and national security, and the potential for similar applications for business intelligence and other sensitive information.\n\nApple to announce generative AI-powered Siri at WWDC in June(The New York Times)According to this report, after Apple executives realized Siri had fallen behind chatbots like OpenAI’s ChatGPT, the company made generative AI a top priority, reassigning hundreds of engineers to the project and exploring the creation of its own AI-optimized servers. The new Siri will be more conversational and versatile, processing requests on-device for greater privacy. Meanwhile, other reports claim that Apple is finalizing a deal to bring ChatGPT and other chatbots to its devices in its next mobile OS.\n\nElon Musk's xAI set to close funding round at $18 billion valuation(Forbes/Bloomberg)The round is expected to raise approximately $6 billion from investors including Sequoia Capital. It was reportedly marketed using a pitch deck highlighting Musk’s successes at Tesla and SpaceX and the potential for xAI to leverage high-quality data from Musk’s social network X (formerly Twitter) to train its AI models and Grok chatbot With the infusion of cash, xAI can hire more talent and invest in infrastructure, including a reported $10 billion deal to rent servers from Oracle.\n\nVoice cloning technology brings country singer Randy Travis back to the recording studio(The Verge)Travis’s new song, “Where That Came From,” is his first since a 2013 stroke made it impossible for him to properly sing. By training an AI model on 42 of Travis’s vocal-isolated recordings and having fellow country singer James DuPre provide the base vocals, producers were able to create a convincing rendition of Travis’s signature baritone style. This process demonstrates the potential for AI to assist artists in creating music that might otherwise be impossible, but also raises concerns about the future of music production and the ethical use of AI-generated vocals.\n\nOpenAI develops AI detection tools to identify DALL·E 3 generated images(OpenAI)The company introduced a detection classifier that predicts the likelihood an image was generated by DALL·E 3. Early testing shows the classifier correctly identifies roughly 98% of DALL·E 3 images while incorrectly tagging less than 0.5% of non-AI generated images. OpenAI is opening applications for outside researchers to access and test the classifier to assess its effectiveness and real-world application. The tool is part of tech companies’ broader efforts to help identify the provenance of AI-generated media, particularly to stem its potential use in fraud and propaganda.\n\nAI-powered audiobooks gain traction despite concerns(Bloomberg)Amazon’s “virtual voice” tool, which allows self-published authors to easily convert their ebooks into audiobooks, has been used to create more than 40,000 audiobooks on Audible since its beta launch last year. While AI narration enables more readers to enjoy audiobooks and authors to save hundreds or thousands of dollars on production costs, some listeners have expressed concerns about the influx of AI-narrated content and the current inability to filter these titles out when browsing. As voice technology continues to develop and major publishers strike their own deals with AI companies, tensions continue between publishers, authors, voice talent, and readers regarding the future of audiobook narration.\n\nVidu, a Chinese counterpart to Sora(SCMP)Chinese start-up Shengshu Technology, in collaboration with Tsinghua University, unveiled Vidu, a text-to-video AI tool similar to OpenAI’s Sora. While Vidu can generate 16-second 1080p videos based on text prompts, it still lags behind Sora’s 60-second video generation capability. Vidu’s launch highlights Chinese companies’ ongoing efforts to catch up with leading global AI players, despite facing challenges such as limited access to advanced computing hardware due to U.S. export restrictions.\n\nAI system to protect Olympic athletes from online abuse(IOC)The International Olympic Committee (IOC) will implement a new AI-powered monitoring service to safeguard athletes and officials from online abuse during the Paris 2024 Olympic and Paralympic Games. The system, which was successfully piloted during Olympic Esports Week, will monitor thousands of social media accounts in real-time across multiple platforms and languages, flagging abusive messages for swift action by the relevant platforms. This is the first time AI will be used to protect such a large number of athletes across various sports at a major international event and could set a precedent for future sporting events and other industries.\n\nU.S. Homeland Security tests AI in training officers to interview refugee applicants(Reuters)The Department of Homeland Security’s pilot program will use AI to simulate refugee characteristics, such as reticence in discussing trauma, to help officers practice interviewing applicants, but will not make the immigration decisions themselves. It is unclear whether outside companies will help build the model or how it will be trained, other than that it will include country-specific conditions. By using AI to simulate refugee characteristics during training, junior officers can better prepare for real-world interviews and make more informed decisions, while freeing senior officers to conduct more interviews themselves.\n\nTikTok to label AI-generated content with digital watermarks(Reuters)The network announced plans to label images and videos uploaded to its platform that were created using AI, even if they were generated outside the app. The company will use a digital watermarking system called Content Credentials, developed by a coalition co-founded by Adobe and Microsoft and also adopted by OpenAI and YouTube, to identify and label AI-generated media, while unlabeled AI-generated media may be removed from the platform. TikTok aims to prevent the spread of misleading images and videos, particularly in light of concerns about potential interference in the upcoming U.S. elections.\n\nApple developing in-house AI chip for data centers(Reuters/Wall Street Journal)Apple reportedly has been working for several years on its own AI chip, codenamed Project ACDC, to power artificial intelligence software in its data centers. The move aims to leverage the company’s chip design expertise for its server infrastructure, focusing on running AI inference models rather than training them. Developing an in-house AI chip for inference could allow Apple to reduce its dependence on other companies like Nvidia, which currently dominates the market for AI training chips.\n\nX launches Stories, AI summaries of trending news for Premium subscribers(TechCrunch)X, formerly Twitter, will now use Grok to generate summaries of trending stories on the platform’s “For You” page in the Explore section. The summaries are based on conversations around the news on X, rather than the actual news articles, which has raised concerns about potential misinformation. The feature helps showcase Grok and is part of X’s push to drive Premium subscriptions.",
    "qa": [
      {
        "question": "IBM đã phát hành dòng mô hình mã nguồn mở Granite với mục đích chính là gì?",
        "options": {
          "A": "Tạo ra các trò chơi điện tử phức tạp hơn.",
          "B": "Tự động hóa các tác vụ lập trình để tăng năng suất của nhà phát triển.",
          "C": "Phân tích dữ liệu tài chính để dự đoán thị trường chứng khoán.",
          "D": "Kiểm soát các thiết bị gia dụng thông minh bằng giọng nói."
        },
        "answer": "B"
      },
      {
        "question": "Sự hợp tác giữa Stack Overflow và OpenAI đã gây ra phản ứng trái chiều từ cộng đồng người dùng Stack Overflow vì lý do chính nào?",
        "options": {
          "A": "OpenAI từ chối trả tiền cho Stack Overflow để sử dụng dữ liệu của họ.",
          "B": "Người dùng lo ngại về quyền sở hữu nội dung do người dùng tạo và cách dữ liệu của họ được sử dụng để huấn luyện AI.",
          "C": "Stack Overflow yêu cầu người dùng trả phí để truy cập ChatGPT.",
          "D": "OpenAI sử dụng dữ liệu của Stack Overflow để tạo ra các câu trả lời sai lệch."
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ mới của ElevenLabs hứa hẹn điều gì trong lĩnh vực âm nhạc?",
        "options": {
          "A": "Tạo ra các bản nhạc quảng cáo ngắn cho các doanh nghiệp nhỏ.",
          "B": "Tạo ra các bài hát hoàn chỉnh với giọng hát tự nhiên từ một đoạn văn bản.",
          "C": "Chuyển đổi giọng nói của người dùng thành các nhạc cụ khác nhau.",
          "D": "Phân tích và cải thiện kỹ năng ca hát của người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc Microsoft phát triển phiên bản GPT-4 hoạt động trong môi trường biệt lập (air-gapped) là gì?",
        "options": {
          "A": "Giúp các cơ quan tình báo Hoa Kỳ phân tích dữ liệu mật mà không lo ngại về rủi ro an ninh mạng.",
          "B": "Cung cấp cho người dùng khả năng truy cập GPT-4 mà không cần kết nối internet.",
          "C": "Giảm chi phí vận hành GPT-4 bằng cách loại bỏ các yêu cầu về kết nối mạng.",
          "D": "Cho phép Microsoft thử nghiệm các tính năng mới của GPT-4 một cách an toàn trước khi phát hành rộng rãi."
        },
        "answer": "A"
      },
      {
        "question": "Theo báo cáo, Apple đang tập trung vào việc phát triển Siri hỗ trợ bởi AI tạo sinh với mục tiêu chính nào?",
        "options": {
          "A": "Tạo ra một trợ lý ảo có khả năng điều khiển các thiết bị gia dụng thông minh tốt hơn.",
          "B": "Biến Siri trở nên đàm thoại và linh hoạt hơn, xử lý yêu cầu trực tiếp trên thiết bị để tăng cường quyền riêng tư.",
          "C": "Tích hợp Siri với các nền tảng mạng xã hội để người dùng có thể chia sẻ thông tin dễ dàng hơn.",
          "D": "Cung cấp cho Siri khả năng dịch ngôn ngữ theo thời gian thực."
        },
        "answer": "B"
      },
      {
        "question": "Khoản đầu tư lớn vào xAI của Elon Musk được kỳ vọng sẽ giúp công ty đạt được điều gì?",
        "options": {
          "A": "Phát triển các phương tiện tự hành tiên tiến hơn.",
          "B": "Thuê thêm nhân tài và đầu tư vào cơ sở hạ tầng, bao gồm việc thuê máy chủ từ Oracle.",
          "C": "Xây dựng một mạng lưới vệ tinh để cung cấp internet tốc độ cao toàn cầu.",
          "D": "Phát triển các giải pháp năng lượng tái tạo hiệu quả hơn."
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ nhân bản giọng nói đã giúp ca sĩ Randy Travis trở lại phòng thu như thế nào?",
        "options": {
          "A": "Bằng cách tạo ra một phiên bản kỹ thuật số hoàn toàn mới của giọng hát của anh ấy.",
          "B": "Bằng cách sử dụng AI để tái tạo giọng hát đặc trưng của anh ấy dựa trên các bản thu âm cũ và giọng hát nền của một ca sĩ khác.",
          "C": "Bằng cách phẫu thuật phục hồi khả năng ca hát của anh ấy.",
          "D": "Bằng cách sử dụng phần mềm chỉnh sửa giọng hát để cải thiện các bản thu âm hiện có của anh ấy."
        },
        "answer": "B"
      },
      {
        "question": "OpenAI phát triển công cụ phát hiện hình ảnh do DALL·E 3 tạo ra nhằm mục đích gì?",
        "options": {
          "A": "Để ngăn chặn việc sử dụng hình ảnh do AI tạo ra trong các quảng cáo thương mại.",
          "B": "Để giúp xác định nguồn gốc của các phương tiện truyền thông do AI tạo ra, đặc biệt là để ngăn chặn việc sử dụng chúng trong gian lận và tuyên truyền.",
          "C": "Để cải thiện chất lượng hình ảnh do DALL·E 3 tạo ra.",
          "D": "Để giới hạn số lượng hình ảnh mà người dùng có thể tạo bằng DALL·E 3."
        },
        "answer": "B"
      },
      {
        "question": "Việc Amazon sử dụng giọng đọc AI cho sách nói đã gây ra những tranh cãi nào?",
        "options": {
          "A": "Giá sách nói tăng cao do chi phí sản xuất tăng.",
          "B": "Sự cạnh tranh giữa các nhà xuất bản lớn và các tác giả tự xuất bản.",
          "C": "Lo ngại về sự tràn lan của nội dung do AI tường thuật và việc thiếu khả năng lọc các tựa sách này.",
          "D": "Sự phản đối từ các diễn viên lồng tiếng chuyên nghiệp."
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống AI mới được Ủy ban Olympic Quốc tế (IOC) sử dụng trong Thế vận hội Paris 2024 có chức năng gì?",
        "options": {
          "A": "Phân tích hiệu suất của các vận động viên để đưa ra các khuyến nghị cải thiện.",
          "B": "Giám sát các tài khoản mạng xã hội để bảo vệ vận động viên và quan chức khỏi lạm dụng trực tuyến.",
          "C": "Dự đoán kết quả của các cuộc thi đấu.",
          "D": "Tự động tạo ra các bài viết và video về Thế vận hội."
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-250": {
    "title": "Hugging Face gives researchers and startups GPU access",
    "collection": "data-points",
    "content": "This week's top AI news and research stories featured everything we know about OpenAI'sGPT-4o, highlights from Google’s annualI/O developers’ conference, Sony Music'sdeclarationopting out of AI training, and details about Meta'sEmu Editmodel. But first:\n\nOpenAI debuts new data analysis tools for ChatGPT(OpenAI)Paid ChatGPT users can now upload files directly from Google Drive and Microsoft OneDrive, interact with tables and charts using natural language, and customize charts for presentations. When users upload or import a data file, ChatGPT can now write and execute Python code to analyze or visualize that data on users’ behalf. These features may make it easier for those with limited coding skills to conduct in-depth analyses and let experts save time on routine data tasks.\n\nReddit partners with OpenAI(Reddit)Reddit’s vast forums will be used to power ChatGPT and other AI products. The collaboration will give Reddit new AI-powered features for its users and moderators, while OpenAI will advertise on Reddit. (Full terms were undisclosed.) OpenAI now has deals with global newspapers, software forums, and a wide variety of other publishers, giving it special access to timely and high-quality training material.\n\nHugging Face commits $10 million in free GPU access to academics and startups(The Verge)ZeroGPU is accessible through Hugging Face’s Spaces platform, which already hosts over 300,000 AI demos. The shared Nvidia A100s can be used concurrently by multiple users or applications; unutilized capacity will be made available to others. HuggingFace’s goal is to counter tech giants and closed models’ centralization by making state-of-the-art AI technologies more accessible.\n\nMeta’s research arm introduces Chameleon(ArXiv)Chameleon can natively process both text and images together, allowing it to perform a wide range of mixed-modal tasks with impressive results. Meta’s researchers say the key is Chameleon’s fully token-based architecture (representing images as well as texts as tokens) and training on datasets that combine text with images. Chameleon outperforms many leading and specialized models (including GPT-4V and Gemini Pro) when answering questions about images, describing pictures, writing relevant text, and creating images from text prompts.\n\nGoogle’s Project IDX enters open beta(Google/Project IDX)Google’s AI-assisted, browser-based integrated development environment (IDE) offers now-familiar features like code completion, debugging tools, and a chat-assisted sidebar, all powered by Gemini. Whenever IDX modifies snippets or suggests new code, it also links back to the original source and its associated license, ensuring proper attribution. Although Google is entering a competitive market, IDX aims to attract developers by showcasing Gemini’s AI advancements and integrating with the company’s cloud services.\n\nAnthropic introduces prompt generation tool for Claude(Anthropic)The tool aims to solve new users’ “blank page problem” by providing a starting point for testing and iteration, incorporating best practices like chain of thought and separating data from instructions. Users can access the prompt generator directly on the Console or analyze the underlying prompt and architecture using a Google Colab notebook. The generator addresses a common challenge for AI users: efficiently crafting effective (and often larger and more complex) prompts that yield high-quality results.\n\nElevenLabs launches AI-powered screen reader app(KnowTechie/Bloomberg)ElevenLabs Reader: AI Audio is the billion-dollar AI voice cloning startup’s first consumer app. The free app can read web pages, PDFs, and other documents aloud using a selection of 11 AI-generated voices. The app marks ElevenLabs’ expansion into the broader AI voice market beyond its current focus on entertainment and media production.\n\nMicrosoft offers China-based AI staff relocation amid U.S. crackdown(CNBC/WSJ)Microsoft reportedly asked hundreds of its China-based employees working on cloud computing and AI to consider relocating to other countries. One source said Microsoft offered 700 to 800 Chinese engineers the opportunity to transfer to the U.S., Ireland, Australia, or New Zealand. The move comes as the U.S. government tightens restrictions on China’s access to advanced technology, citing concerns over potential military applications and cybersecurity threats.\n\nFalcon 2 open-source models boast rich vision-to-text capabilities(AetosWire)Abu Dhabi’s Technology Innovation Institute released Falcon 2, a family of large language models that includes Falcon 2 11B and Falcon 2 11B VLM. The latter is the institute’s first multimodal model, capable of converting visual inputs into textual outputs. Both models are Apache 2.0 open-source, multilingual, and perform on par with Gemma 7B and better than Llama 3 8B according to benchmarks and HuggingFace leaderboards.",
    "qa": [
      {
        "question": "Tính năng mới nào của ChatGPT cho phép người dùng tương tác với dữ liệu một cách trực quan hơn?",
        "options": {
          "A": "Khả năng tạo ra các đoạn code Python phức tạp để phân tích dữ liệu.",
          "B": "Khả năng tải trực tiếp file từ Google Drive và Microsoft OneDrive, tương tác với bảng biểu bằng ngôn ngữ tự nhiên và tùy chỉnh biểu đồ.",
          "C": "Khả năng kết nối trực tiếp với các cơ sở dữ liệu lớn để truy xuất thông tin.",
          "D": "Khả năng tự động tạo báo cáo phân tích dữ liệu chi tiết."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc Reddit hợp tác với OpenAI là gì?",
        "options": {
          "A": "Để Reddit có thể sử dụng ChatGPT để tự động trả lời các câu hỏi của người dùng.",
          "B": "Để OpenAI có thể sử dụng dữ liệu từ Reddit để huấn luyện AI và Reddit có được các tính năng AI mới.",
          "C": "Để Reddit có thể cạnh tranh với các nền tảng mạng xã hội khác bằng cách tích hợp AI.",
          "D": "Để OpenAI có thể quảng cáo sản phẩm của mình trên Reddit."
        },
        "answer": "B"
      },
      {
        "question": "Hugging Face cung cấp gì cho các nhà nghiên cứu và startup trong lĩnh vực AI?",
        "options": {
          "A": "Một nền tảng để chia sẻ các mô hình AI đã được huấn luyện.",
          "B": "Quyền truy cập miễn phí vào các khóa học trực tuyến về AI.",
          "C": "Quyền truy cập miễn phí vào GPU thông qua nền tảng ZeroGPU.",
          "D": "Một quỹ đầu tư để hỗ trợ các dự án AI tiềm năng."
        },
        "answer": "C"
      },
      {
        "question": "Điểm đặc biệt của mô hình Chameleon do Meta phát triển là gì?",
        "options": {
          "A": "Khả năng xử lý ngôn ngữ tự nhiên vượt trội so với các mô hình khác.",
          "B": "Khả năng tạo ra hình ảnh từ văn bản với độ chân thực cao.",
          "C": "Khả năng xử lý đồng thời cả văn bản và hình ảnh bằng kiến trúc dựa trên token.",
          "D": "Khả năng dịch thuật giữa nhiều ngôn ngữ khác nhau."
        },
        "answer": "C"
      },
      {
        "question": "Project IDX của Google hỗ trợ lập trình viên bằng cách nào?",
        "options": {
          "A": "Cung cấp một môi trường phát triển tích hợp (IDE) dựa trên trình duyệt, hỗ trợ bởi AI Gemini.",
          "B": "Cung cấp một thư viện các đoạn code mẫu để giúp lập trình viên viết code nhanh hơn.",
          "C": "Cung cấp một công cụ để tự động kiểm tra lỗi code.",
          "D": "Cung cấp một nền tảng để lập trình viên cộng tác và chia sẻ code."
        },
        "answer": "A"
      },
      {
        "question": "Công cụ tạo prompt của Anthropic giúp người dùng Claude giải quyết vấn đề gì?",
        "options": {
          "A": "Giúp người dùng tạo ra các prompt hiệu quả hơn để đạt được kết quả tốt hơn.",
          "B": "Giúp người dùng hiểu rõ hơn về cách hoạt động của mô hình Claude.",
          "C": "Giúp người dùng tự động tạo ra các ứng dụng AI dựa trên Claude.",
          "D": "Giúp người dùng tìm kiếm thông tin liên quan đến Claude một cách nhanh chóng."
        },
        "answer": "A"
      },
      {
        "question": "ElevenLabs Reader là ứng dụng gì?",
        "options": {
          "A": "Một ứng dụng tạo giọng nói AI cho mục đích giải trí.",
          "B": "Một ứng dụng đọc văn bản thành tiếng bằng giọng nói AI.",
          "C": "Một ứng dụng chỉnh sửa giọng nói AI chuyên nghiệp.",
          "D": "Một ứng dụng dịch giọng nói AI sang nhiều ngôn ngữ."
        },
        "answer": "B"
      },
      {
        "question": "Vì sao Microsoft đề nghị nhân viên AI ở Trung Quốc chuyển đến các quốc gia khác?",
        "options": {
          "A": "Do chi phí lao động ở Trung Quốc tăng cao.",
          "B": "Do chính sách đãi ngộ tốt hơn ở các quốc gia khác.",
          "C": "Do lo ngại về các hạn chế của chính phủ Hoa Kỳ đối với việc tiếp cận công nghệ tiên tiến của Trung Quốc.",
          "D": "Do Microsoft muốn mở rộng thị trường ở các quốc gia khác."
        },
        "answer": "C"
      },
      {
        "question": "Falcon 2 11B VLM có khả năng gì đặc biệt?",
        "options": {
          "A": "Khả năng tạo ra video từ văn bản.",
          "B": "Khả năng chuyển đổi hình ảnh thành văn bản.",
          "C": "Khả năng dịch thuật giữa nhiều ngôn ngữ khác nhau.",
          "D": "Khả năng tạo ra âm nhạc từ văn bản."
        },
        "answer": "B"
      },
      {
        "question": "Đặc điểm nào sau đây KHÔNG phải là đặc điểm của các mô hình Falcon 2?",
        "options": {
          "A": "Mã nguồn mở theo giấy phép Apache 2.0.",
          "B": "Đa ngôn ngữ.",
          "C": "Hiệu suất tương đương hoặc tốt hơn Gemma 7B và Llama 3 8B.",
          "D": "Chỉ hỗ trợ ngôn ngữ tiếng Anh."
        },
        "answer": "D"
      }
    ]
  },
  "data-points-issue-251": {
    "title": "How top models perform on a challenging new benchmark",
    "collection": "data-points",
    "content": "This week's top AI stories feature a new model from Mistral designed for coding, Microsoft’s updated Phi-3 family of small language models, OpenAI’s new safety and security team, and a family of models from Cohere that supports 23 global languages:\n\nCodestral is Mistral’s open-weight model for codeCodestral is a 22 billion parameter model trained on English and over 80 programming languages, including Python, Java, C++, Fortran, and Swift. Codestral handily outperforms CodeLlama 70B on multiple benchmarks, including HumanEval and RepoBench, and is competitive with DeepSeek Coder 30B. The model is open-weight, but available for download only under a noncommercial use license, limiting its incorporation into other software. (Mistral)\n\nOpenAI signs agreements with News Corp., Vox Media, and The AtlanticThe multiyear partnerships give OpenAI’s models and ChatGPT access to large, regularly-updated sources of news and opinion that it can display in response to user queries, along with attribution and links to full articles. The Vox and Atlantic deals also include access to OpenAI’s technologies to develop their own experimental AI and data products. OpenAI’s deals follow similar ones with Reddit, Stack Overflow, Le Monde, and other social media sites and news sources, as well as those made by Google and other AI companies. (The Wall Street Journal)\n\nMMLU-Pro: A more challenging benchmark for large language modelsMMLU-Pro is a new dataset from TIGER-Lab that aims to more rigorously test the capabilities of large language models across various disciplines. It builds upon the original MMLU dataset but increases the number of answer options to 10, incorporates more reasoning-focused problems, and adds over 5,000 new questions sourced from STEM websites, TheoremQA, and Scibench. GPT-4o remains at the top of the MMLU-Pro leaderboard, followed by Claude 3 Opus and Gemini 1.5 Flash, but some models like Mixtral-8x7B saw their scores drop by over 30 percent on the new benchmark. (Hugging Face)\n\nMicrosoft’s Phi-3 small language models now generally availableMicrosoft announced the addition of Phi-3-Vision, a 4.2 billion parameter multimodal model combining language and vision capabilities, to its Phi-3 family of small, open models. The company also made Phi-3-Small and Phi-3-Medium available on Microsoft Azure, while Phi-3-Mini and Phi-3-Medium are now accessible through Azure AI’s models as a service offering. Phi-3-Silica is a separate model in the family that powers AI features on Windows’ new Copilot+ PCs; familiarity with the Phi family may help Windows developers looking to add these features to their applications. (Microsoft)\n\nCohere releases Aya 23, an open-weight multilingual language modelBuilding on Cohere’s Command and Aya 101 models, Aya 23 covers 23 European and Asian languages, including Arabic, Chinese (simplified & traditional), Hebrew, Hindi, Indonesian, Japanese, Korean, Persian, Turkish, and Vietnamese. Unlike Aya 101, which attempted breadth of coverage with 101 languages, Aya 23 aims to balance breadth and depth, outperforming Aya 101 and other open models like Gemma and Mistral on a wide range of generative and reasoning tasks. Cohere has made 8 billion and 35 billion parameter versions of the model available for noncommercial use in an attempt to further global research and development of massively multilingual models. (Cohere for AI)\n\nOpenAI establishes safety team amid concerns from departing researchersOpenAI’s new Safety and Security Committee, led by CEO Sam Altman and board members Adam D’Angelo, Nicole Seligman, and Bret Taylor, will address critical safety and security decisions for the company’s projects and operations. The committee, which will also include a ranger of technical and policy experts, will take 90 days to evaluate OpenAI’s processes and safeguards, presenting its findings to the board for implementation. The safety committee’s formation comes after the departure of several key researchers, including co-founder and chief scientist Ilya Sutskever and Superalignment team co-leader Jan Leike, who expressed concerns about safety taking a backseat to product development at OpenAI. (OpenAI)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng discussed why we need better evals for LLM applications:\n\n“The cost of running evals poses an additional challenge. Let’s say you’re using an LLM that costs $10 per million input tokens, and a typical query has 1000 tokens. Each user query therefore costs only $0.01. However, if you iteratively work to improve your algorithm based on 1000 test examples, and if in a single day you evaluate 20 ideas, then your cost will be 20*1000*0.01 = $200. For many projects I’ve worked on, the development costs were fairly negligible until we started doing evals, whereupon the costs suddenly increased. (If the product turned out to be successful, then costs increased even more at deployment, but that was something we were happy to see!)\"\n\nRead Andrew's full letterhere.\n\nOther top AI news and research stories we covered in depth included a deep learning model that significantlyreduceddeaths among critically ill hospital patients, the Indian startups that aretestingautonomous vehicles on their nation’s disorderly local roads, a new report from Microsoft and LinkedIn on knowledge workers'adoptionof AI, and all aboutRAPTOR, a recursive summarizer and retrieval system for LLMs.",
    "qa": [
      {
        "question": "Mô hình Codestral của Mistral được huấn luyện trên bao nhiêu ngôn ngữ lập trình?",
        "options": {
          "A": "Ít hơn 50 ngôn ngữ",
          "B": "Hơn 80 ngôn ngữ",
          "C": "Khoảng 100 ngôn ngữ",
          "D": "Chỉ các ngôn ngữ phổ biến như Python và Java"
        },
        "answer": "B"
      },
      {
        "question": "OpenAI đã ký kết hợp tác với những tổ chức truyền thông nào trong tuần này?",
        "options": {
          "A": "Reddit, Stack Overflow, Le Monde",
          "B": "News Corp., Vox Media, The Atlantic",
          "C": "Google, Microsoft, Amazon",
          "D": "Facebook, Twitter, Instagram"
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính của MMLU-Pro so với bộ dữ liệu MMLU gốc là gì?",
        "options": {
          "A": "Giảm số lượng câu hỏi",
          "B": "Tăng số lượng lựa chọn đáp án lên 10",
          "C": "Chỉ tập trung vào các câu hỏi về khoa học xã hội",
          "D": "Sử dụng ít câu hỏi tập trung vào suy luận hơn"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào thuộc dòng Phi-3 của Microsoft kết hợp khả năng ngôn ngữ và thị giác?",
        "options": {
          "A": "Phi-3-Mini",
          "B": "Phi-3-Small",
          "C": "Phi-3-Vision",
          "D": "Phi-3-Silica"
        },
        "answer": "C"
      },
      {
        "question": "Aya 23 của Cohere tập trung vào việc hỗ trợ bao nhiêu ngôn ngữ?",
        "options": {
          "A": "101 ngôn ngữ",
          "B": "23 ngôn ngữ",
          "C": "Hơn 1000 ngôn ngữ",
          "D": "Chỉ các ngôn ngữ châu Âu"
        },
        "answer": "B"
      },
      {
        "question": "Ai là người đứng đầu Ủy ban An toàn và Bảo mật mới của OpenAI?",
        "options": {
          "A": "Ilya Sutskever",
          "B": "Jan Leike",
          "C": "Sam Altman",
          "D": "Adam D'Angelo"
        },
        "answer": "C"
      },
      {
        "question": "Theo Andrew Ng, thách thức lớn nhất trong việc đánh giá các ứng dụng LLM là gì?",
        "options": {
          "A": "Sự phức tạp của các mô hình LLM",
          "B": "Chi phí chạy các đánh giá",
          "C": "Thiếu dữ liệu đánh giá chất lượng",
          "D": "Khó khăn trong việc xác định các tiêu chí đánh giá phù hợp"
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của Ủy ban An toàn và Bảo mật mới được thành lập của OpenAI là gì?",
        "options": {
          "A": "Phát triển các sản phẩm AI mới nhanh hơn",
          "B": "Giải quyết các quyết định quan trọng về an toàn và bảo mật cho các dự án của công ty",
          "C": "Tuyển dụng thêm các nhà nghiên cứu hàng đầu",
          "D": "Tăng cường hợp tác với các công ty công nghệ khác"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Codestral của Mistral có thể được sử dụng cho mục đích thương mại không?",
        "options": {
          "A": "Có, hoàn toàn miễn phí",
          "B": "Có, nhưng cần trả phí bản quyền",
          "C": "Không, chỉ được sử dụng cho mục đích phi thương mại",
          "D": "Chỉ được sử dụng cho mục đích nghiên cứu khoa học"
        },
        "answer": "C"
      },
      {
        "question": "Ngoài Aya 23, Cohere còn phát triển những mô hình ngôn ngữ nào khác được đề cập trong bài viết?",
        "options": {
          "A": "GPT-4o và Claude 3 Opus",
          "B": "Command và Aya 101",
          "C": "Gemini 1.5 Flash và Mixtral-8x7B",
          "D": "CodeLlama 70B và DeepSeek Coder 30B"
        },
        "answer": "B"
      }
    ]
  },
  "data-points-issue-252": {
    "title": "Anthropic makes tool use available for all users",
    "collection": "data-points",
    "content": "This week’s top AI stories included:\n\nProteinViz is an open-source alternative to Google’s AlphaFold 3Like AlphaFold3, ProteinViz can predict the three-dimensional structure of arbitrary biological molecules. Given an amino acid sequence, the model can generate a 3D image of a protein directly in the web browser. Unlike AlphaFold3, ProteinViz is fully open-source, released under an MIT license, and can be used for commercial applications. (GitHub)\n\nAnthropic introduces tool use and API calls for Claude 3 AI modelsTool use enables Claude to extract structured data, convert natural language requests into API calls, answer questions using databases or web APIs, and automate simple tasks. Anthropic also introduced features like streaming, forced tool use, and <thinking> tags to give developers more control over user interactions. These features allow for more real-world applications of Claude’s models, including interactive tutors, customer service support, and in-browser automation. (Anthropic)\n\nReuters-Oxford study surveys use and perception of generative AIA recent online survey conducted across Argentina, Denmark, France, Japan, the U.K., and the U.S. found that around 50% of the online population have heard of ChatGPT, the most widely recognized generative AI product. However, frequent use remains low, with only 1-7% using it daily. 66% of respondents expect generative AI to have a large impact on news media and science within the next five years, but only 50% of respondents trust scientists and healthcare professionals, and less than one-third trust social media companies, politicians, and news media. (Reuters Institute)\n\nGoogle scales back AI-generated answers in search results after high-profile errorsIn many cases, Google’s AI Overview summaries missed important context clues, presenting jokes or unsubstantiated claims as fact. The company has made over a dozen technical changes to improve the system, including cutting down on using social media posts as source material, pausing and putting guardrails around some health-related answers, and adding restrictions for queries where AI answers were not proving helpful. (Google)European Union countries endorse comprehensive AI rules set to take effect this monthThe artificial intelligence regulations, known as the AI Act, aim to address concerns surrounding AI’s potential contributions to misinformation, fake news, and copyrighted material while ensuring trust, transparency, and accountability in the development and use of AI technologies. The vote ratified a deal between negotiators reached in December 2023. The AI Act will have global implications, as companies outside the E.U. using E.U. customer data will need to comply; other countries may also use the legislation as a model for their own AI regulations. (Reuters)\n\nGrounding DINO 1.5 introduces two new open-world object detection modelsThe models include Grounding DINO 1.5 Pro, for a wide range of detection scenarios, and Grounding DINO 1.5 Edge, for efficient edge computing. The models achieve state-of-the-art zero-shot transfer performance on several academic benchmarks, with Grounding DINO 1.5 Pro setting new records on the COCO, LVIS, and ODinW datasets; fine-tuning the models further boosts performance. The models are pretrained on the Grounding-20M dataset, which consists of over 20 million high-quality grounding images collected from publicly available sources, ensuring robust performance across various detection scenarios. Open-world object detection has applications in robotics, semantic search, auto-captioning, and many other scenarios. (DeepDataSpace)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng discussed why California's proposed AI law is bad for everyone:\n\n“[California's proposed law SB-1047] defines an unreasonable “hazardous capability” designation that may make builders of large AI models potentially liable if someone uses their models to do something that exceeds the bill’s definition of harm (such as causing $500 million in damage). That is practically impossible for any AI builder to ensure. If the bill is passed in its present form, it will stifle AI model builders, especially open source developers.”\n\nRead Andrew's full letterhere.\n\nOther top AI news and research stories we covered in depth included all about Microsoft’s AI-drivenCopilot+ PCs, the misuse ofOpenAI's modelfor disinformation campaigns, an initialconversationbetween the U.S. and China intended to prevent AI-driven accidents, and Microsoft’sOrca 2, a technique that strengthens the native reasoning abilities of smaller models.",
    "qa": [
      {
        "question": "Điểm khác biệt chính giữa ProteinViz và AlphaFold3 là gì?",
        "options": {
          "A": "ProteinViz có thể dự đoán cấu trúc 3D của protein nhanh hơn AlphaFold3.",
          "B": "ProteinViz là mã nguồn mở và có thể sử dụng cho mục đích thương mại, trong khi AlphaFold3 thì không.",
          "C": "ProteinViz có độ chính xác cao hơn AlphaFold3 trong việc dự đoán cấu trúc protein.",
          "D": "ProteinViz có thể tạo ra hình ảnh 3D của protein trực tiếp trong trình duyệt web, AlphaFold3 thì không."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ 'tool use' của Claude 3 AI models cho phép điều gì?",
        "options": {
          "A": "Tự động tạo ra các đoạn mã lập trình phức tạp.",
          "B": "Trích xuất dữ liệu có cấu trúc, chuyển đổi yêu cầu ngôn ngữ tự nhiên thành lệnh gọi API và tự động hóa các tác vụ đơn giản.",
          "C": "Dịch văn bản từ ngôn ngữ này sang ngôn ngữ khác với độ chính xác cao.",
          "D": "Tạo ra các hình ảnh và video chân thực từ văn bản mô tả."
        },
        "answer": "B"
      },
      {
        "question": "Theo khảo sát của Reuters-Oxford, tỉ lệ người sử dụng ChatGPT hàng ngày là bao nhiêu?",
        "options": {
          "A": "Khoảng 50% dân số trực tuyến.",
          "B": "Từ 1% đến 7% dân số trực tuyến.",
          "C": "Khoảng 33% dân số trực tuyến.",
          "D": "Hơn 75% dân số trực tuyến."
        },
        "answer": "B"
      },
      {
        "question": "Google đã thực hiện những thay đổi kỹ thuật nào sau những sai sót trong AI Overview?",
        "options": {
          "A": "Tăng cường sử dụng các bài đăng trên mạng xã hội làm nguồn tài liệu.",
          "B": "Tạm dừng và đặt ra các biện pháp bảo vệ xung quanh một số câu trả lời liên quan đến sức khỏe.",
          "C": "Mở rộng phạm vi các truy vấn mà AI có thể trả lời.",
          "D": "Tăng cường khả năng tạo ra các câu trả lời hài hước và sáng tạo."
        },
        "answer": "B"
      },
      {
        "question": "Đạo luật AI của Liên minh Châu Âu (AI Act) nhằm mục đích gì?",
        "options": {
          "A": "Thúc đẩy sự phát triển nhanh chóng của công nghệ AI mà không cần quan tâm đến các rủi ro tiềm ẩn.",
          "B": "Giải quyết các lo ngại về thông tin sai lệch, tin giả và tài liệu có bản quyền, đồng thời đảm bảo sự tin cậy, minh bạch và trách nhiệm giải trình trong phát triển và sử dụng AI.",
          "C": "Cấm hoàn toàn việc sử dụng AI trong các lĩnh vực nhạy cảm như y tế và tài chính.",
          "D": "Tạo ra một thị trường độc quyền cho các công ty AI của Châu Âu."
        },
        "answer": "B"
      },
      {
        "question": "Grounding DINO 1.5 Pro và Grounding DINO 1.5 Edge khác nhau như thế nào?",
        "options": {
          "A": "Grounding DINO 1.5 Pro chỉ có thể được sử dụng cho mục đích thương mại, trong khi Grounding DINO 1.5 Edge thì không.",
          "B": "Grounding DINO 1.5 Pro được thiết kế cho nhiều tình huống phát hiện khác nhau, trong khi Grounding DINO 1.5 Edge được thiết kế để tính toán biên hiệu quả.",
          "C": "Grounding DINO 1.5 Edge có độ chính xác cao hơn Grounding DINO 1.5 Pro.",
          "D": "Grounding DINO 1.5 Pro chỉ có thể phát hiện các đối tượng tĩnh, trong khi Grounding DINO 1.5 Edge có thể phát hiện các đối tượng chuyển động."
        },
        "answer": "B"
      },
      {
        "question": "Grounding DINO 1.5 được huấn luyện trên bộ dữ liệu nào?",
        "options": {
          "A": "COCO dataset.",
          "B": "LVIS dataset.",
          "C": "Grounding-20M dataset.",
          "D": "ImageNet dataset."
        },
        "answer": "C"
      },
      {
        "question": "Andrew Ng cho rằng điều gì về dự luật AI SB-1047 của California?",
        "options": {
          "A": "Nó sẽ thúc đẩy sự phát triển của AI một cách an toàn và có trách nhiệm.",
          "B": "Nó sẽ tạo ra một môi trường pháp lý rõ ràng cho các nhà phát triển AI.",
          "C": "Nó sẽ kìm hãm các nhà phát triển mô hình AI, đặc biệt là các nhà phát triển mã nguồn mở.",
          "D": "Nó sẽ bảo vệ người tiêu dùng khỏi các rủi ro liên quan đến AI."
        },
        "answer": "C"
      },
      {
        "question": "Copilot+ PCs của Microsoft được hỗ trợ bởi công nghệ gì?",
        "options": {
          "A": "Công nghệ thực tế ảo (VR).",
          "B": "Công nghệ trí tuệ nhân tạo (AI).",
          "C": "Công nghệ blockchain.",
          "D": "Công nghệ điện toán đám mây."
        },
        "answer": "B"
      },
      {
        "question": "Orca 2 của Microsoft là gì?",
        "options": {
          "A": "Một mô hình ngôn ngữ lớn (LLM) mới với khả năng vượt trội so với GPT-4.",
          "B": "Một kỹ thuật tăng cường khả năng suy luận tự nhiên của các mô hình nhỏ hơn.",
          "C": "Một hệ điều hành mới được thiết kế đặc biệt cho các ứng dụng AI.",
          "D": "Một công cụ để phát hiện và ngăn chặn các chiến dịch thông tin sai lệch sử dụng AI."
        },
        "answer": "B"
      }
    ]
  },
  "deep-research-brings-phd-analysis-to-chatgpt": {
    "title": "Deep research brings PhD analysis to ChatGPT",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nOpenAI launches deep research capability in ChatGPT\n\nOpenAI introduced a new deep research agent in ChatGPT that conducts comprehensive internet research on complex tasks. The feature, powered by an analysis-optimized version of OpenAI’s unreleased o3 model, can analyze hundreds of online sources to create detailed reports in a fraction of the time it would take a human. Currently the agent is only available for ChatGPT Pro subscribers, and they are limited to 100 queries a month. If proven, this technology could significantly boost productivity in knowledge-intensive fields like finance, science, and engineering, transforming how businesses and researchers gather information and analyze it. (OpenAI)\n\nNew AI model generates full five-minute songs from lyrics\n\nResearchers introduced YuE (pronounced “yeah” in English), an open weights model that transforms lyrics into complete songs with vocals and accompaniment. YuE can generate up to five minutes of music in various genres and languages, using tools like a semantically enhanced audio tokenizer and a dual-token approach for vocal-instrumental modeling. The model’s release under the Apache 2.0 license aims to advance music generation and creative AI, similar to how Stable Diffusion and LLaMA impacted their respective fields. (GitHub)\n\nAlibaba challenges AI leaders with trio of advanced models\n\nAlibaba updated its Qwen series of models with Qwen2.5-Max, Qwen2.5-VL, and the Qwen2.5-1M family. Qwen 2.5-Max is a Mixture-of-Expert model pretrained on over 20 trillion tokens that outperforms DeepSeek V3 in several benchmarks. Qwen2.5-VL is a vision-language model capable of understanding long videos, localizing visual input, and generating structured outputs for various applications. Qwen2.5-1M extends the Qwen2.5 language models’ context windows to 1 million tokens, improving the models’ long-context capabilities through multi-stage fine-tuning and other training methods. All models are released under a variety of licenses, ranging from quite permissive to somewhat restricted. These updates continue to position Alibaba as a formidable competitor in the AI race, challenging industry leaders like DeepSeek, OpenAI, and Anthropic. (Qwen2.5-Max,Qwen2.5-VL, andQwen2.5-1M)\n\nNvidia’s Eagle 2 9B vision-language model matches 70B rivals\n\nNvidia researchers developed Eagle 2, a series of vision-language models (VLMs) that can process and understand both images and text, available under an Apache 2.0 license. The nine billion parameter version of Eagle 2 achieves state-of-the-art results on several benchmarks, outperforming some much larger models and even matching or exceeding GPT-4V on certain tasks. Eagle 2 uses a “tiled mixture of vision encoders” approach, allowing it to process high-resolution images effectively and understand diverse visual content. In their paper, the researchers emphasize that their data strategy and training techniques were crucial in achieving these capabilities, potentially offering insights to help other AI developers create more powerful open-source VLMs. (GitHubandarXiv)\n\nTülu 3 405B model sets new benchmark for open AI\n\nAi2 researchers released Tülu 3 405B, which they claim is the largest open weights model trained using fully open post-training recipes. The model outperforms other models of similar size on various benchmarks, including GPT-4o and Deepseek v3, and shows particular improvement in mathematical problem-solving at larger scales. This release demonstrates the scalability and effectiveness of the team’s novel Reinforcement Learning from Verifiable Rewards (RLVR) approach, which they applied to the 405 billion parameter Llama 3.1 base model. (Ai2)\n\nMicrosoft adds DeepSeek R1 to Azure amid AI model controversy\n\nMicrosoft announced it will host DeepSeek-R1 on its Azure cloud service. DeepSeek R1 reportedly matches OpenAI’s o1 in performance at a fraction of the cost, with DeepSeek listing R1’s API cost as $2.19 per million output tokens compared to o1’s $60 per million output tokens. Azure’s decision comes despite recent accusations from OpenAI that DeepSeek violated its terms of service by extracting substantial training data through OpenAI’s API. Microsoft is OpenAI’s largest investor and (until recently) its exclusive cloud provider, and helped identify unusual activity on its servers that suggested DeepSeek may have exploited OpenAI in this way, making its quick decision to host DeepSeek-R1 noteworthy. (Ars TechnicaandThe Verge)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng reflected on DeepSeek’s impact, highlighted China’s rapid progress in generative AI, the growing influence of open models in the AI supply chain, and the importance of algorithmic innovation beyond just scaling up.\n\n“Scaling up isn’t the only path to AI progress. Driven in part by the U.S. AI chip embargo, the DeepSeek team had to innovate on many optimizations to run on less-capable H800 GPUs rather than H100s, leading ultimately to a model trained for under $6M of compute.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: howDeepSeek-R1 and Kimi k1.5 leveraged reinforcement learningto train reasoning models, pushing the boundaries of AI capabilities;OpenAI introduced Operator, an AI agent designed to automate online tasks;The White House made a bold policy shift, rolling back AI regulations and emphasizing the need for U.S. leadership in the global market; and Cohere researchers proposed active inheritance,a novel fine-tuning approachthat lets model-makers automatically select better synthetic data.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Tính năng mới nào của ChatGPT cho phép thực hiện nghiên cứu chuyên sâu trên internet?",
        "options": {
          "A": "Phân tích dữ liệu người dùng nâng cao",
          "B": "Deep research agent",
          "C": "Tạo báo cáo tự động",
          "D": "Kết nối trực tiếp với các cơ sở dữ liệu khoa học"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình AI nào có khả năng tạo ra các bài hát hoàn chỉnh từ lời bài hát?",
        "options": {
          "A": "Stable Diffusion",
          "B": "LLaMA",
          "C": "YuE",
          "D": "Qwen2.5-Max"
        },
        "answer": "C"
      },
      {
        "question": "Alibaba đã cập nhật dòng mô hình Qwen với những phiên bản nào?",
        "options": {
          "A": "Qwen2.0, Qwen2.1, Qwen2.2",
          "B": "Qwen2.5-Max, Qwen2.5-VL, Qwen2.5-1M",
          "C": "Qwen3.0, Qwen3.1, Qwen3.2",
          "D": "Qwen-Alpha, Qwen-Beta, Qwen-Gamma"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Eagle 2 của Nvidia sử dụng phương pháp nào để xử lý ảnh độ phân giải cao?",
        "options": {
          "A": "Mạng nơ-ron tích chập sâu",
          "B": "Mô hình biến áp",
          "C": "Tiled mixture of vision encoders",
          "D": "Mạng đối kháng sinh (GAN)"
        },
        "answer": "C"
      },
      {
        "question": "Tülu 3 405B được huấn luyện bằng phương pháp học tăng cường nào?",
        "options": {
          "A": "Học tăng cường từ phản hồi của con người (RLHF)",
          "B": "Học tăng cường từ phần thưởng có thể kiểm chứng (RLVR)",
          "C": "Học tăng cường nghịch đảo (IRL)",
          "D": "Học tăng cường đa tác tử (MARL)"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình DeepSeek R1 được Microsoft cung cấp trên nền tảng đám mây nào?",
        "options": {
          "A": "Google Cloud",
          "B": "AWS",
          "C": "Azure",
          "D": "IBM Cloud"
        },
        "answer": "C"
      },
      {
        "question": "Theo Andrew Ng, yếu tố nào đã thúc đẩy đội ngũ DeepSeek đổi mới trong lĩnh vực AI?",
        "options": {
          "A": "Sự hợp tác quốc tế",
          "B": "Lệnh cấm vận chip AI của Hoa Kỳ",
          "C": "Nguồn tài trợ dồi dào",
          "D": "Áp lực cạnh tranh từ OpenAI"
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ nào được DeepSeek-R1 và Kimi k1.5 sử dụng để huấn luyện các mô hình suy luận?",
        "options": {
          "A": "Học có giám sát",
          "B": "Học không giám sát",
          "C": "Học tăng cường",
          "D": "Học bán giám sát"
        },
        "answer": "C"
      },
      {
        "question": "Operator, một AI agent mới được giới thiệu bởi OpenAI, được thiết kế để làm gì?",
        "options": {
          "A": "Tạo ra các tác phẩm nghệ thuật số",
          "B": "Tự động hóa các tác vụ trực tuyến",
          "C": "Phân tích dữ liệu tài chính",
          "D": "Dịch ngôn ngữ tự động"
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp tinh chỉnh mới nào được đề xuất bởi các nhà nghiên cứu Cohere để chọn dữ liệu tổng hợp tốt hơn?",
        "options": {
          "A": "Học chuyển giao",
          "B": "Kế thừa chủ động (active inheritance)",
          "C": "Tự học",
          "D": "Học đa nhiệm"
        },
        "answer": "B"
      }
    ]
  },
  "deepseek-outlines-v3-training-hardware-limits": {
    "title": "DeepSeek outlines V3 training, hardware limits",
    "collection": "data-points",
    "content": "In today’s edition, you’ll learn more about:\n\nDeepSeek-V3 reveals hardware bottlenecks in model training\n\nResearchers at DeepSeek-AI published a research paper sharing insights from training their 671 billion parameter language model DeepSeek-V3. The team trained DeepSeek-V3 on 2,048 NVIDIA H800 GPUs and developed several clever workarounds for current hardware constraints. The paper highlights hardware limitations that slow down AI development. The researchers identified three main bottlenecks: limited memory capacity, inefficient computation, and slow communication between GPUs. To address these challenges, they implemented Multi-Head Latent Attention to reduce memory usage, adopted a Mixture of Experts architecture that activates only necessary parts of the model, and utilized FP8 mixed-precision training to maximize performance on existing hardware. Based on their experience, the authors recommend future hardware improvements including better low-precision computation, more efficient GPU interconnections, and faster communication systems to support the next generation of AI models. (arXiv)\n\nOpenAI unveils Codex programming agent in ChatGPT\n\nOpenAI released a research preview of Codex, a cloud-based AI agent that can simultaneously perform multiple software engineering tasks. Codex writes features, answers codebase questions, fixes bugs, and proposes pull requests, with each task running in its own isolated cloud environment preloaded with the user’s repository. The system is powered by codex-1, a version of OpenAI’s o3 reasoning model specifically optimized for software engineering. Codex shows strong performance on coding evaluations and internal benchmarks, outperforming previous models on software engineering tasks. The service is initially rolling out to ChatGPT Pro, Enterprise, and Team users, with Plus and Edu support coming soon. (OpenAI)\n\nWindsurf launches family of models built for coders\n\nCoding assistant Windsurf released its first family of AI models called SWE-1, designed specifically for comprehensive software engineering tasks. The family includes three models: the flagship SWE-1 (comparable to Claude 3.5 Sonnet but less expensive), SWE-1-lite (replacing Windsurf’s previous base model), and SWE-1-mini (powering autocomplete and similar experiences). Windsurf says that SWE-1 is built with “flow awareness” that enables it to work across editors, terminals, and browsers while maintaining context of incomplete states and long-running tasks. Benchmark testing shows SWE-1 performing competitively with large models from major AI labs and significantly outperforming open-weight alternatives. The flagship SWE-1 model will be available to all paid Windsurf users for a promotional period at zero credits per prompt. (Windsurf)\n\nStripe develops transformer-based model for payment processing\n\nStripe created a transformer-based payments model that generates vector embeddings for payment transactions, designed to detect fraud and perform other tasks. The self-supervised network, trained on billions of transactions, positions payments in vector space where transactions with similar characteristics cluster together. Stripe’s earlier machine learning models had improved conversion by 15 percent and reduced fraud by 30 percent. This new approach improved card-testing attack detection rates on large users from 59 percent to 97 percent. The same embeddings work across multiple payment tasks including disputes and authorizations, indicating that payment data contains structural patterns and sequential dependencies that benefit from transformer architecture analysis. (StripeandLinkedIn)\n\nAlibaba launches upgraded video generation and editing model\n\nAlibaba released Wan2.1-VACE, a video generation model that supports creation from text, images, and video inputs while enabling users to edit the generated content. The company is offering two open-weight versions: a comprehensive 14 billion parameter model and a smaller 1.3 billion parameter version designed to run on consumer-grade GPUs with just 8.19 GB of VRAM. The Wan2.1 suite claims superior performance across multiple benchmarks and features unusual capabilities including visual text generation in both Chinese and English. The model also includes Wan-VAE, which can efficiently encode and decode 1080p videos of any length while preserving temporal information. This marks Alibaba’s second update to its video model in a single month, soon after introducing the VACE framework in March, highlighting the fast pace of video generation development. (Hugging Face)\n\nU.S. Congress proposes 10-year ban on state and local AI regulations\n\nIn the United States, House Republicans added language to a budget reconciliation bill that would block all state and local governments from regulating artificial intelligence for 10 years. The provision, introduced by Representative Brett Guthrie of Kentucky, would prevent states from enforcing both existing and proposed laws designed to protect citizens from AI systems. If passed, the measure would invalidate several current state laws, including California’s requirement for healthcare providers to disclose AI use and New York’s mandate for bias audits in AI hiring tools. The proposal has sparked backlash from consumer advocacy groups who call it a “giant gift to Big Tech” that would leave consumers unprotected from AI harms like deepfakes and algorithmic bias. The move aligns with the Trump administration’s industry-friendly approach to AI policy, which has already reversed several Biden-era executive orders on AI safety. (Ars Technica)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng emphasized how AI’s ability to speed up tasks — not just reduce costs — can unlock significant business growth.\n\n“Beyond reducing the cost of writing software, AI is shortening the time from idea to working prototype, and the ability to test ideas faster is changing how teams explore and invent.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: Microsoft releasedtraining details for its new Phi-4-reasoning models, designed to improve problem-solving efficiency with minimal computing overhead; DeepCoder-14B-Preview showcased how further fine-tuning on coding tasks canenhance the capabilities of smaller reasoning models; European regulators announcedchanges to the AI Act, aiming to ease liability rules for developers and adjust other provisions; and Meta introducedmemory-layer enhancements to Llama-style models, enabling them to recall factual details more accurately without increasing computational demands.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "DeepSeek-V3 đã được huấn luyện trên bao nhiêu GPU NVIDIA H800?",
        "options": {
          "A": "1024",
          "B": "2048",
          "C": "4096",
          "D": "8192"
        },
        "answer": "B"
      },
      {
        "question": "Theo nghiên cứu của DeepSeek-AI, đâu là một trong những hạn chế phần cứng làm chậm quá trình phát triển AI?",
        "options": {
          "A": "Số lượng lõi CPU hạn chế",
          "B": "Dung lượng bộ nhớ hạn chế",
          "C": "Tốc độ ổ cứng quá chậm",
          "D": "Nguồn điện không ổn định"
        },
        "answer": "B"
      },
      {
        "question": "Codex của OpenAI được tối ưu hóa đặc biệt cho lĩnh vực nào?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên",
          "B": "Kỹ thuật phần mềm",
          "C": "Thị giác máy tính",
          "D": "Robot học"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình SWE-1 của Windsurf được xây dựng với đặc điểm 'flow awareness' để làm gì?",
        "options": {
          "A": "Tự động hoàn thành code nhanh hơn",
          "B": "Duy trì ngữ cảnh giữa các môi trường làm việc khác nhau",
          "C": "Phát hiện lỗi cú pháp hiệu quả hơn",
          "D": "Tối ưu hóa hiệu suất phần cứng"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình của Stripe sử dụng kiến trúc nào để xử lý thanh toán?",
        "options": {
          "A": "Mạng nơ-ron tích chập (CNN)",
          "B": "Mạng nơ-ron hồi quy (RNN)",
          "C": "Transformer",
          "D": "Mạng đối kháng sinh (GAN)"
        },
        "answer": "C"
      },
      {
        "question": "Mô hình của Stripe đã cải thiện tỷ lệ phát hiện tấn công kiểm tra thẻ (card-testing attack) trên người dùng lớn như thế nào?",
        "options": {
          "A": "Từ 30% lên 50%",
          "B": "Từ 45% lên 75%",
          "C": "Từ 59% lên 97%",
          "D": "Từ 70% lên 99%"
        },
        "answer": "C"
      },
      {
        "question": "Wan2.1-VACE của Alibaba có khả năng gì đặc biệt liên quan đến văn bản?",
        "options": {
          "A": "Tự động dịch văn bản sang nhiều ngôn ngữ",
          "B": "Tạo văn bản từ giọng nói",
          "C": "Tạo văn bản trực quan bằng cả tiếng Trung và tiếng Anh",
          "D": "Tóm tắt văn bản dài thành văn bản ngắn gọn"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì sẽ xảy ra nếu đề xuất cấm các quy định về AI của tiểu bang và địa phương được thông qua ở Hoa Kỳ?",
        "options": {
          "A": "Các công ty công nghệ lớn sẽ phải tuân thủ các quy định liên bang nghiêm ngặt hơn.",
          "B": "Người tiêu dùng sẽ được bảo vệ tốt hơn khỏi các tác hại tiềm ẩn của AI.",
          "C": "Các luật hiện hành của tiểu bang về AI sẽ bị vô hiệu hóa.",
          "D": "Việc phát triển AI sẽ bị chậm lại đáng kể."
        },
        "answer": "C"
      },
      {
        "question": "Theo Andrew Ng, khả năng nào của AI có thể thúc đẩy tăng trưởng kinh doanh đáng kể?",
        "options": {
          "A": "Giảm chi phí nhân công",
          "B": "Tăng cường bảo mật dữ liệu",
          "C": "Tăng tốc độ thực hiện các tác vụ",
          "D": "Cải thiện khả năng dự đoán thị trường"
        },
        "answer": "C"
      },
      {
        "question": "Thay đổi nào đã được các nhà quản lý châu Âu công bố đối với Đạo luật AI?",
        "options": {
          "A": "Tăng cường các quy định về quyền riêng tư dữ liệu.",
          "B": "Nới lỏng các quy tắc về trách nhiệm pháp lý cho các nhà phát triển.",
          "C": "Cấm sử dụng AI trong các ứng dụng nhạy cảm.",
          "D": "Yêu cầu tất cả các hệ thống AI phải được chứng nhận bởi một cơ quan độc lập."
        },
        "answer": "B"
      }
    ]
  },
  "deepseek-r1-regains-open-weights-crown": {
    "title": "DeepSeek-R1 regains open-weights crown",
    "collection": "data-points",
    "content": "In today’s edition, you’ll learn more about:\n\nDeepSeek’s upgraded R1 rivals OpenAI and Google’s top models\n\nChinese AI startup DeepSeek updated its R1 reasoning model, achieving performance comparable to OpenAI’s o3 and Google’s Gemini 2.5 Pro, according to the company’s announcement on Hugging Face. The updated DeepSeek-R1-0528 model shows significant improvements in mathematics, programming, and general logic tasks, with accuracy on the AIME 2025 test jumping from 70 percent to 87.5 percent, albeit at the cost of using nearly double the reasoning tokens per question. This positions DeepSeek’s open-weights model at #2 on Artificial Analysis’s Intelligence Index, marking the continued rise of Chinese AI labs competing directly with U.S. counterparts and narrowing the gap between open and proprietary models. (Hugging FaceandArtificial Analysis)\n\nGitHub MCP vulnerability allows attackers to access private data\n\nInvariant discovered a critical vulnerability in GitHub’s MCP integration that enables attackers to access private repository data through malicious GitHub issues. The vulnerability exploits “toxic agent flows,” where agents are manipulated into performing unintended actions like leaking sensitive data. The vulnerability affects any agent using the GitHub MCP server, regardless of the underlying model or implementation, taking advantage of a fundamental architectural issue rather than a flaw in the GitHub MCP server code itself. Invariant recommends implementing granular permission controls and continuous security monitoring to mitigate such attacks. This discovery is particularly significant as the industry rapidly deploys coding agents and IDEs, potentially exposing developers to similar attacks on critical development tools. (Invariant)\n\nMicrosoft launches NLWeb to help build agentic web\n\nMicrosoft released NLWeb, an open-source project that enables web publishers to add natural language interfaces to their websites, allowing users to query site content through conversational AI. The system uses existing structured data formats like Schema.org and RSS, combining them with large language models to create interfaces accessible to both humans and AI agents. NLWeb supports all major operating systems, AI models, and vector databases, and integrates with the Model Context Protocol (MCP) ecosystem for broader agent compatibility. Microsoft sees this as a way for publishers to prepare for the “agentic web,” where AI agents will increasingly interact with and transact on websites. Early adopters include Chicago Public Media, Tripadvisor, Shopify, and O’Reilly Media, with the project available now on GitHub. (Microsoft)\n\nFLUX.1 Kontext combines multimodal image generation and editing\n\nBlack Forest Labs released FLUX.1 Kontext, a suite of generative flow matching models that enables both text-to-image generation and image editing through combined text and image prompts. The models’ users can perform local edits, apply style references across multiple scenes, extract and modify visual concepts while maintaining character consistency. Such tasks have typically required separate models or complex workflows. According to Black Forest, FLUX.1 Kontext operates up to 8 times faster than competing models like GPT-Image and supports iterative editing, where users can build upon previous modifications. The suite includes FLUX.1 Kontext [pro] and [max] variants available through partners like KreaAI and Freepik, with a 12 billion parameter [dev] version in private beta for research use. (Black Forest Labs)\n\nGoogle open sources LMEval for streamlined model benchmarking\n\nGoogle’s LMEval is a new open-source framework designed to simplify how developers evaluate and compare AI models from different providers like OpenAI, Anthropic, and Google. The tool addresses a key challenge in AI development: With new models launching constantly, developers need efficient ways to test whether newer versions actually improve their applications. LMEval enables consistent benchmarking across providers through integration with the LiteLLM framework, eliminating the need to work with different APIs for each company. The framework features incremental evaluation that runs only necessary tests for new models or updates, supports multimodal benchmarks including text, images and code, and includes a visualization dashboard for analyzing results. This release helps developers make better, data-driven decisions about model selection for their projects. (Google)\n\nThe New York Times licenses its reporting to Amazon for AI training\n\nThe New York Times struck a multiyear deal with Amazon to provide editorial content for the tech company’s AI platforms, marking the newspaper’s first licensing agreement focused on generative AI technology. The agreement covers news articles, NYT Cooking recipes, and sports content from The Athletic, which Amazon will use to train its proprietary AI models and enhance its products, including Alexa. This deal comes as the Times continues its copyright infringement lawsuit against OpenAI and Microsoft, filed in 2023, for allegedly using millions of Times articles to train AI models without compensation. NYT CEO Meredith Kopit Levien emphasized that the Amazon agreement reflects the company’s stance that “high-quality journalism is worth paying for.” Financial terms were not disclosed. (The New York Times)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng raised concerns about proposed U.S. funding cuts for basic research, emphasizing how such cuts could hurt American competitiveness in AI and urging continued investment in open scientific research.\n\n“Scientific research brings the greatest benefit to the country where the work happens because (i) the new knowledge diffuses fastest within that country, and (ii) the process of doing research creates new talent for that nation.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mô hình DeepSeek-R1-0528 đã cải thiện đáng kể ở những lĩnh vực nào?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên, dịch thuật và tóm tắt văn bản.",
          "B": "Toán học, lập trình và logic tổng quát.",
          "C": "Nhận diện hình ảnh, xử lý video và tạo âm thanh.",
          "D": "Dự đoán thị trường chứng khoán, phân tích dữ liệu tài chính và quản lý rủi ro."
        },
        "answer": "B"
      },
      {
        "question": "Lỗ hổng trong tích hợp GitHub MCP cho phép kẻ tấn công làm gì?",
        "options": {
          "A": "Truy cập trái phép vào tài khoản GitHub của người dùng.",
          "B": "Truy cập dữ liệu kho lưu trữ riêng tư thông qua các issue độc hại.",
          "C": "Thay đổi mã nguồn trong các kho lưu trữ công khai.",
          "D": "Gây ra lỗi hệ thống và làm gián đoạn dịch vụ GitHub."
        },
        "answer": "B"
      },
      {
        "question": "Microsoft NLWeb giúp các nhà xuất bản web làm gì?",
        "options": {
          "A": "Tự động tạo nội dung trang web bằng AI.",
          "B": "Thêm giao diện ngôn ngữ tự nhiên vào trang web của họ.",
          "C": "Tối ưu hóa trang web cho công cụ tìm kiếm.",
          "D": "Bảo vệ trang web khỏi các cuộc tấn công DDoS."
        },
        "answer": "B"
      },
      {
        "question": "FLUX.1 Kontext của Black Forest Labs có khả năng gì nổi bật?",
        "options": {
          "A": "Tạo ra video chất lượng cao từ văn bản.",
          "B": "Kết hợp tạo ảnh từ văn bản và chỉnh sửa ảnh thông qua cả văn bản và hình ảnh.",
          "C": "Phân tích và dự đoán xu hướng thị trường từ dữ liệu hình ảnh.",
          "D": "Tự động thiết kế giao diện người dùng cho ứng dụng di động."
        },
        "answer": "B"
      },
      {
        "question": "LMEval của Google giải quyết vấn đề gì trong phát triển AI?",
        "options": {
          "A": "Tự động gỡ lỗi mã nguồn AI.",
          "B": "Đơn giản hóa việc đánh giá và so sánh các mô hình AI từ các nhà cung cấp khác nhau.",
          "C": "Tối ưu hóa hiệu suất của các mô hình AI trên các nền tảng khác nhau.",
          "D": "Bảo vệ các mô hình AI khỏi các cuộc tấn công adversarial."
        },
        "answer": "B"
      },
      {
        "question": "Thỏa thuận giữa The New York Times và Amazon liên quan đến nội dung gì?",
        "options": {
          "A": "Cung cấp dịch vụ lưu trữ đám mây cho The New York Times.",
          "B": "Cung cấp nội dung biên tập cho các nền tảng AI của Amazon.",
          "C": "Phát triển chung các công cụ AI cho ngành báo chí.",
          "D": "Hợp tác trong việc chống lại tin giả và thông tin sai lệch."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, điều gì mang lại lợi ích lớn nhất cho quốc gia nơi nghiên cứu khoa học diễn ra?",
        "options": {
          "A": "Sự hợp tác quốc tế trong nghiên cứu khoa học.",
          "B": "Kiến thức mới lan truyền nhanh nhất và quá trình nghiên cứu tạo ra nhân tài mới.",
          "C": "Việc bảo vệ quyền sở hữu trí tuệ đối với các phát minh khoa học.",
          "D": "Sự hỗ trợ tài chính từ các tổ chức quốc tế."
        },
        "answer": "B"
      },
      {
        "question": "NLWeb tích hợp với giao thức nào để tương thích với nhiều agent hơn?",
        "options": {
          "A": "TCP/IP",
          "B": "HTTP/2",
          "C": "Model Context Protocol (MCP)",
          "D": "Simple Mail Transfer Protocol (SMTP)"
        },
        "answer": "C"
      },
      {
        "question": "Công cụ LMEval của Google hỗ trợ những loại benchmark đa phương thức nào?",
        "options": {
          "A": "Chỉ văn bản.",
          "B": "Chỉ hình ảnh.",
          "C": "Văn bản, hình ảnh và mã.",
          "D": "Chỉ âm thanh và video."
        },
        "answer": "C"
      },
      {
        "question": "Vụ kiện giữa The New York Times và OpenAI/Microsoft liên quan đến vấn đề gì?",
        "options": {
          "A": "Vi phạm bằng sáng chế công nghệ AI.",
          "B": "Sử dụng trái phép nội dung của Times để huấn luyện mô hình AI mà không bồi thường.",
          "C": "Cạnh tranh không lành mạnh trong thị trường AI.",
          "D": "Xâm phạm quyền riêng tư của người dùng."
        },
        "answer": "B"
      }
    ]
  },
  "deepseek-releases-r1-r1-zero-and-six-smaller-distilled-models": {
    "title": "DeepSeek releases R1, R1-Zero, and six smaller distilled models",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nDeepSeek-R1 matches top models and opens access\n\nDeepSeek-R1 achieves performance comparable to OpenAI’s latest o1 model on reasoning tasks, including a 79.8 percent pass rate on AIME 2024 and 97.3 percent on MATH-500. The model, along with the reinforcement-learning-trained R1-Zero and smaller distilled versions, is now available under an MIT license, allowing open access for the community to use the model weights and outputs. Through DeepSeek’s API, R1 costs $0.14 per million input tokens for cached inputs, $0.55 per million input tokens for standard inputs, and $2.19 per million output tokens. (GitHub)\n\nLuma’s Ray2 model challenges top contenders in video generation\n\nLuma Labs integrated its new Ray2 video model into the Dream Machine AI creativity platform, offering improved realism and motion compared to its predecessor. Ray2 utilizes 10 times more compute power than previous models and aims to provide better visual storytelling capabilities, though early users report some performance issues due to high demand. Early comparisons suggest Ray2 may outperform competitors like OpenAI’s Sora and Runway’s Gen-3 in motion accuracy and physics simulation, potentially setting a new benchmark for AI-generated video quality. (Luma Labs)\n\nMistral AI updates its best coding model\n\nMistral AI launched Codestral 25.01, an upgraded version of its coding model that generates and completes code twice as fast as its predecessor. The model outperforms other leading sub-100B parameter coding models on various benchmarks, particularly excelling in fill-in-the-middle tasks across multiple programming languages. Codestral 25.01 is now available through IDE plugin partners such as VS Code and JetBrains, with enterprise options for local deployment. It can now also be accessed via the Codestral API or on cloud platforms like Google Cloud’s Vertex AI and Azure AI Foundry for $0.30 per million input tokens and $0.90 per million output tokens. (Mistral)\n\nMiniMax builds open weight models with alternative attention mechanism\n\nMiniMax released its 01 series of models, featuring a novel non-transformer “Lightning Attention” architecture that enables processing of up to 4 million tokens. The 01 series includes MiniMax-Text-01, a 456 billion parameter language model, and MiniMax-VL-01, a vision-language model, both of which are now available under an open weights license on GitHub. MiniMax is offering API access to these models at rates of $0.20 per million input tokens and $1.10 per million output tokens. (Minimax)\n\nAI system collaborates with humans to draft Wikipedia-style articles\n\nCo-STORM, a research and summarization tool now available for a user study on the Stanford website, enables writers to work alongside language models in sourcing and drafting encyclopedia articles. The system, developed by Stanford researchers, employs a collaborative discourse protocol, featuring AI experts, a moderator, and human input to guide information gathering and knowledge curation. Co-STORM builds upon its predecessor STORM, which automates internet research and article outlining, by introducing a dynamic mind map to organize concepts and reduce cognitive load during in-depth discussions. While STORM and Co-STORM aren’t producing publication-ready content yet, experienced Wikipedia editors are interested in the system as a pre-writing aid. (Stanford)\n\nLlamaIndex introduces new agentic RAG architecture for document processing\n\nLlamaIndex developed Agentic Document Workflows (ADW), a new architecture that combines document processing, retrieval, and AI agents to automate complex knowledge work. ADW improves upon traditional Intelligent Document Processing and Retrieval-Augmented Generation by maintaining context across multi-step processes and coordinating between different system components. This advancement enables language models to handle sophisticated tasks like contract review, medical case summaries, and insurance claims processing while keeping humans in control of final decisions. (LlamaIndex)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng shared his thoughts on the growing demand for AI product management and how AI advancements are transforming roles within software development teams.\n\n“The demand for good AI Product Managers will be huge. In addition to growing AI Product Management as a discipline, perhaps some engineers will also end up doing more product management work.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:DeepSeek-V3 set new benchmark highsin LLM performance and cost efficiency;the U.S. announced expanded AI export restrictions, reshaping global tech markets;Nvidia unveiled Project Digits, a $3,000 home supercomputer for mid-sized AI models; andX-CLR introduced an innovative approachto contrastive learning, enhancing vision model performance.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mô hình DeepSeek-R1 đạt được tỷ lệ vượt qua bao nhiêu trong bài kiểm tra AIME 2024?",
        "options": {
          "A": "97.3%",
          "B": "79.8%",
          "C": "85.5%",
          "D": "90.2%"
        },
        "answer": "B"
      },
      {
        "question": "Luma Labs tích hợp mô hình Ray2 vào nền tảng nào?",
        "options": {
          "A": "Vertex AI",
          "B": "Azure AI Foundry",
          "C": "Dream Machine AI",
          "D": "GitHub"
        },
        "answer": "C"
      },
      {
        "question": "Ưu điểm nổi bật của Codestral 25.01 so với phiên bản trước là gì?",
        "options": {
          "A": "Khả năng xử lý ngôn ngữ tự nhiên tốt hơn",
          "B": "Tốc độ tạo và hoàn thành code nhanh gấp đôi",
          "C": "Hỗ trợ nhiều ngôn ngữ lập trình hơn",
          "D": "Khả năng triển khai trên các thiết bị di động"
        },
        "answer": "B"
      },
      {
        "question": "Kiến trúc 'Lightning Attention' của MiniMax cho phép xử lý tối đa bao nhiêu tokens?",
        "options": {
          "A": "1 triệu",
          "B": "2 triệu",
          "C": "4 triệu",
          "D": "8 triệu"
        },
        "answer": "C"
      },
      {
        "question": "Co-STORM được phát triển bởi các nhà nghiên cứu tại đâu?",
        "options": {
          "A": "MIT",
          "B": "Stanford",
          "C": "Google",
          "D": "Microsoft"
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của Agentic Document Workflows (ADW) do LlamaIndex phát triển là gì?",
        "options": {
          "A": "Tự động hóa các tác vụ tri thức phức tạp",
          "B": "Cải thiện khả năng dịch thuật của mô hình ngôn ngữ",
          "C": "Tăng cường hiệu suất của các thuật toán tìm kiếm",
          "D": "Giảm chi phí đào tạo mô hình AI"
        },
        "answer": "A"
      },
      {
        "question": "Theo Andrew Ng, vai trò nào sẽ có nhu cầu lớn trong lĩnh vực AI?",
        "options": {
          "A": "Kỹ sư phần mềm AI",
          "B": "Nhà khoa học dữ liệu",
          "C": "Chuyên gia đạo đức AI",
          "D": "Quản lý sản phẩm AI"
        },
        "answer": "D"
      },
      {
        "question": "DeepSeek-V3 đã thiết lập chuẩn mực mới về điều gì?",
        "options": {
          "A": "Khả năng tạo hình ảnh từ văn bản",
          "B": "Hiệu suất và hiệu quả chi phí của LLM",
          "C": "Khả năng dịch thuật đa ngôn ngữ",
          "D": "Khả năng dự đoán thị trường chứng khoán"
        },
        "answer": "B"
      },
      {
        "question": "Dự án Digits của Nvidia là gì?",
        "options": {
          "A": "Một nền tảng đào tạo AI trực tuyến",
          "B": "Một siêu máy tính gia đình giá rẻ cho các mô hình AI cỡ vừa",
          "C": "Một thư viện mã nguồn mở cho phát triển AI",
          "D": "Một công cụ trực quan hóa dữ liệu AI"
        },
        "answer": "B"
      },
      {
        "question": "X-CLR giới thiệu một phương pháp cải tiến trong lĩnh vực nào?",
        "options": {
          "A": "Học tăng cường",
          "B": "Học không giám sát",
          "C": "Học tương phản",
          "D": "Học chuyển giao"
        },
        "answer": "C"
      }
    ]
  },
  "deepseek-v3-is-the-new-best-open-model": {
    "title": "DeepSeek-V3 is the new best open model",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nDeepSeek matches Sonnet 3.5/GPT-4o performance at lower costs\n\nDeepSeek released DeepSeek-V3, a large language model with 671 billion total parameters and 37 billion activated for each token. The model uses a low-cost Mixture-of-Experts architecture and novel techniques like multi-token prediction. DeepSeek-V3 outperforms other open source models and rivals leading closed models on various benchmarks, while requiring only 2.8 million GPU hours for training. The model is available for commercial use with an MIT license and can be run locally using several open-source frameworks. (HuggingFace)\n\nOpenAI’s new reasoning models shatter benchmarks\n\nOpenAI announced its latest AI reasoning models, o3 and o3-mini, which use a “private chain of thought” approach to simulate reasoning beyond basic large language models. The o3 model achieved record-breaking scores on several benchmarks, including the ARC-AGI visual reasoning test and graduate-level academic exams. OpenAI plans to make these models available for public safety testing and research access, with o3-mini expected to launch in late January followed by o3 shortly after. (Ars TechnicaandArc Prize)\n\nGenesis combines physics simulation with generative AI for robotics\n\nGenesis is a new physics simulation platform designed for robotics and embodied AI applications. The platform integrates a universal physics engine with generative AI capabilities to create realistic simulations across multiple modalities, including video, 3D scenes, and robotic motions. Genesis claims to deliver extremely fast simulation speeds, running up to 430,000 times faster than real-time in certain scenarios. While the physics engine is now open source, the full generative framework will be released gradually in the future. (GitHub)\n\nQwen team introduces multimodal/visual reasoning QVQ model\n\nQwen researchers developed QVQ, an open-weight model built on Qwen2-VL-72B that aims to enhance the model’s visual understanding and problem-solving abilities. QVQ achieves a score of 70.3 on the MMMU benchmark and shows improvements on math-related tasks compared to its predecessor. The model excels at visual reasoning through step-by-step analysis, though it has limitations like mixing up languages and potential hallucinations during multi-step reasoning. Qwen hopes its model could lead to more sophisticated problem-solving in fields requiring complex visual and analytical thinking. (GitHub)\n\nModernBERT updates legendary BERT encoder models\n\nAnswer.AI and LightOn released ModernBERT, a new family of encoder-only models that outperform older BERT-style models across speed and accuracy benchmarks. ModernBERT incorporates recent advances from large language models, including an 8,192 token context length, improved architecture, and training on diverse data including code. The models aim to be drop-in replacements for BERT in applications like retrieval, classification, and entity extraction, offering better performance while maintaining the efficiency advantages of encoder-only models over larger generative models. (Hugging Face)\n\nCodeLLM editor integrates multiple language models for coding\n\nAbacus.AI released CodeLLM, an AI-powered code editor that helps developers write, review, and refactor code. CodeLLM provides access to multiple language models optimized for different coding tasks and automatically switches between them based on the language and query. Integrated models include Claude Sonnet 3.5, OpenAI’s o1, Qwen 72B, and others. The Visual Studio Code-based editor offers features like code completion, code chat, and integration with ChatLLM Teams for Git functionality and pull requests. CodeLLM is available as part of a $10 monthly subscription that includes access to ChatLLM’s broader AI capabilities. (Abacus.AI)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s special issueofThe Batchfor in-depth analysis of news and research looking back at 2024.\n\nIn this week’s letter to readers and learners, Andrew Ng highlighted the year’s rapid progress in AI technology and applications, emphasized the importance of staying at the cutting edge, and encouraged learning with DeepLearning.AI courses to remain relevant in the field.\n\n“Consider this: GPT-4 was released March 2023. Since then, models have become much faster, cheaper, sometimes smaller, more multimodal, and better at reasoning, and many more open weight versions are available — so progress has been fantastic! (Claims that AI is ‘hitting a wall’ seem extremely ill-informed.) But more significantly, many applications that already were theoretically possible using the March 2023 version of GPT-4 — in areas such as customer service, question answering, and process automation — now have significant early momentum.”\n\nRead Andrew’s full letterhere.\n\nOur special end-of-the-year review issue features five stories we covered in depth:LLMs’ evolution with agentic workflows, enabling autonomous reasoning and collaboration;AI price wars drove costs downas competition intensifies;generative video models revolutionized content creationwith stunning realism;compact AI models redefined efficiency, bringing advanced capabilities to everyday devices; andtech giants forged strategic partnershipsas an alternative to acquisitions, securing essential talent and technology.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "DeepSeek-V3 sử dụng kiến trúc nào để giảm chi phí?",
        "options": {
          "A": "Transformer thuần túy",
          "B": "Mixture-of-Experts (MoE)",
          "C": "Recurrent Neural Network (RNN)",
          "D": "Convolutional Neural Network (CNN)"
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của các mô hình o3 và o3-mini mới của OpenAI là gì?",
        "options": {
          "A": "Tăng cường khả năng dịch thuật ngôn ngữ",
          "B": "Mô phỏng khả năng suy luận vượt trội hơn các LLM cơ bản",
          "C": "Cải thiện hiệu suất tạo sinh hình ảnh",
          "D": "Giảm thiểu chi phí đào tạo mô hình"
        },
        "answer": "B"
      },
      {
        "question": "Genesis là nền tảng mô phỏng vật lý mới được thiết kế cho lĩnh vực nào?",
        "options": {
          "A": "Xây dựng mô hình tài chính",
          "B": "Nghiên cứu y sinh",
          "C": "Ứng dụng robot và AI nhúng",
          "D": "Dự báo thời tiết"
        },
        "answer": "C"
      },
      {
        "question": "Mô hình QVQ của Qwen được xây dựng dựa trên mô hình nào?",
        "options": {
          "A": "GPT-4",
          "B": "Llama 3",
          "C": "Qwen2-VL-72B",
          "D": "BERT"
        },
        "answer": "C"
      },
      {
        "question": "ModernBERT được thiết kế để thay thế cho các mô hình nào trong các ứng dụng như truy xuất và phân loại?",
        "options": {
          "A": "Các mô hình Transformer lớn",
          "B": "Các mô hình BERT cũ",
          "C": "Các mô hình tạo sinh hình ảnh",
          "D": "Các mô hình dịch máy"
        },
        "answer": "B"
      },
      {
        "question": "CodeLLM là một công cụ gì?",
        "options": {
          "A": "Một thư viện mã nguồn mở cho machine learning",
          "B": "Một trình chỉnh sửa mã hỗ trợ bởi AI",
          "C": "Một nền tảng để đào tạo mô hình ngôn ngữ",
          "D": "Một công cụ để phân tích dữ liệu lớn"
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, tiến bộ trong lĩnh vực AI từ tháng 3 năm 2023 đến nay được mô tả như thế nào?",
        "options": {
          "A": "Chậm chạp và không đáng kể",
          "B": "Đã đạt đến giới hạn",
          "C": "Nhanh chóng và ấn tượng",
          "D": "Chủ yếu tập trung vào việc tăng kích thước mô hình"
        },
        "answer": "C"
      },
      {
        "question": "Trong số các xu hướng AI được đề cập trong bài viết, xu hướng nào liên quan đến việc tạo ra nội dung chân thực?",
        "options": {
          "A": "Sự phát triển của LLM với quy trình làm việc theo hướng tác nhân",
          "B": "Chiến tranh giá AI",
          "C": "Mô hình video tạo sinh",
          "D": "Mô hình AI nhỏ gọn"
        },
        "answer": "C"
      },
      {
        "question": "Điểm nổi bật của ModernBERT so với các mô hình BERT trước đây là gì?",
        "options": {
          "A": "Khả năng tạo sinh văn bản tốt hơn",
          "B": "Tốc độ và độ chính xác được cải thiện",
          "C": "Kích thước mô hình nhỏ hơn đáng kể",
          "D": "Khả năng xử lý ngôn ngữ tự nhiên tốt hơn"
        },
        "answer": "B"
      },
      {
        "question": "CodeLLM tích hợp những loại mô hình nào?",
        "options": {
          "A": "Chỉ các mô hình độc quyền của Abacus.AI",
          "B": "Chỉ các mô hình mã nguồn mở",
          "C": "Các mô hình được tối ưu hóa cho các tác vụ mã hóa khác nhau, bao gồm cả Claude Sonnet 3.5 và Qwen 72B",
          "D": "Chỉ các mô hình được phát triển bởi OpenAI"
        },
        "answer": "C"
      }
    ]
  },
  "deepseeks-janus-reads-and-generates-images": {
    "title": "DeepSeek’s Janus reads and generates images",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nDeepSeek unveils Janus, a versatile AI model for text and images\n\nDeepSeek released Janus, a new AI framework that handles both understanding and generating multimodal content. The system uses separate visual pathways but a single transformer architecture, improving on previous approaches and increasing flexibility. Janus outperforms earlier unified models and is competitive with specialized models at multiple vision understanding and generation benchmarks. The model is available for download on a permissive open license. (GitHub)\n\nSambaNova and Gradio partner to simplify AI model deployment\n\nSambaNova Systems and Gradio announced an integration that allows developers to access high-performance AI models with minimal code. The partnership enables users to create web applications powered by AI models running on SambaNova’s hardware using Gradio’s gr.load() function, simplifying the process of building chat and other interfaces. This collaboration makes it easier for developers to work with high-speed inference infrastructure in AI web applications. (GitHub)\n\nSafety regulator probes Tesla’s self-driving tech after collisions\n\nThe U.S. National Highway Traffic Safety Administration launched an investigation into Tesla’s supervised full self-driving technology, examining four collisions, including one fatal pedestrian accident. The probe focuses on whether the software has adequate safeguards to ensure drivers can retake control when necessary. This could pose a significant challenge to Tesla’s ambitious plans for autonomous vehicles that rely on cameras rather than a combination of sensors. (NHTSAandThe New York Times)\n\nPerplexity adds internal search and collaborative tools for pro users\n\nPerplexity introduced Internal Knowledge Search for Pro and Enterprise Pro users, allowing them to search across both web content and internal files simultaneously. The company also launched Perplexity Spaces, AI-powered collaboration hubs that teams can customize for specific research and organizational needs. These new features enable Perplexity’s industry users to search internal data alongside public information, enhancing due diligence, sales processes, and employee support. (Perplexity)\n\nNvidia’s new AI model gets top marks on arena/chat benchmarks\n\nNvidia created a new AI called Llama-3.1-Nemotron-70B-Instruct that scored higher than GPT-4 and Claude 3.5 on three important tests. These tests measure how well AI understands and follows instructions, with Nvidia’s model scoring 85.0 on Arena Hard, 57.6 on AlpacaEval 2 LC, and 8.98 on GPT-4-Turbo MT-Bench. Nvidia used special training methods to teach their AI, including reinforcement learning from human feedback and use of its own Nemotron reward model. (Nvidia)\n\nExplicit AI deepfake bots flourish on Telegram\n\nWired identified at least 50 Telegram bots claiming to generate explicit photos or videos of individuals with minimal user input. These bots collectively report over 4 million monthly users, with some individual bots boasting hundreds of thousands of users each. The persistence and prevalence of these tools on Telegram highlights the platform’s role as a major hub for deepfake creation, even though the identified bots likely represent only a fraction of the total number available. (Wired)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng argued that we should consider geoengineering to be an important potential tool to mitigate climate change.\n\n“All these downsides should be balanced against the reality that people are dying. I’m moved by meteorologist John Morales’ emotional account of the havoc caused by Hurricane Milton.The New York Timesquoted him as saying, ‘It claims lives. It also wrecks lives.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Malaysia helps drive a data center boomdriven by its strategic location, natural resources, and investor-friendly policies;the U.S. launches Operation AI Complyto crack down on AI applications that overpromise and underdeliver; a new report highlights thecontending forces shaping AI, including the battle between open and proprietary technology; andresearchers introduce a better text embedding modelwith adapters specialized for tasks like retrieval, clustering, and text classification.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mô hình AI Janus của DeepSeek có đặc điểm nổi bật nào?",
        "options": {
          "A": "Chỉ có khả năng tạo ra nội dung đa phương tiện.",
          "B": "Sử dụng kiến trúc transformer đơn nhất cho cả xử lý và tạo nội dung đa phương tiện.",
          "C": "Chỉ có khả năng hiểu nội dung đa phương tiện.",
          "D": "Yêu cầu phần cứng đặc biệt để hoạt động."
        },
        "answer": "B"
      },
      {
        "question": "Sự hợp tác giữa SambaNova và Gradio mang lại lợi ích gì cho các nhà phát triển AI?",
        "options": {
          "A": "Giảm chi phí phần cứng cần thiết để chạy mô hình AI.",
          "B": "Đơn giản hóa quy trình triển khai mô hình AI thành các ứng dụng web.",
          "C": "Tăng cường bảo mật cho các mô hình AI.",
          "D": "Cung cấp các mô hình AI được đào tạo sẵn."
        },
        "answer": "B"
      },
      {
        "question": "NHTSA đang điều tra công nghệ tự lái của Tesla vì lý do gì?",
        "options": {
          "A": "Tesla sử dụng quá nhiều cảm biến trong hệ thống tự lái.",
          "B": "Lo ngại về khả năng người lái xe giành lại quyền kiểm soát khi cần thiết.",
          "C": "Tesla không tuân thủ các tiêu chuẩn an toàn quốc tế.",
          "D": "Tesla sử dụng dữ liệu cá nhân của người dùng một cách trái phép."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng Internal Knowledge Search của Perplexity cho phép người dùng làm gì?",
        "options": {
          "A": "Tìm kiếm thông tin trên các nền tảng mạng xã hội.",
          "B": "Tìm kiếm đồng thời trên web và các tệp nội bộ.",
          "C": "Tạo ra các báo cáo tự động về xu hướng thị trường.",
          "D": "Dịch văn bản sang nhiều ngôn ngữ khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình AI Llama-3.1-Nemotron-70B-Instruct của Nvidia đạt được thành tích gì đáng chú ý?",
        "options": {
          "A": "Đạt điểm cao nhất trong các bài kiểm tra về khả năng nhận diện khuôn mặt.",
          "B": "Vượt trội hơn GPT-4 và Claude 3.5 trong các bài kiểm tra về khả năng hiểu và làm theo hướng dẫn.",
          "C": "Có khả năng tạo ra hình ảnh chân thực từ văn bản.",
          "D": "Tiêu thụ ít năng lượng hơn so với các mô hình AI khác."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính được đề cập liên quan đến các bot deepfake trên Telegram là gì?",
        "options": {
          "A": "Sự phức tạp trong việc tạo ra các deepfake chất lượng cao.",
          "B": "Sự phổ biến và dễ dàng tiếp cận các công cụ tạo deepfake khiêu dâm.",
          "C": "Chi phí cao để sử dụng các bot deepfake.",
          "D": "Khả năng các bot deepfake bị sử dụng để lan truyền tin giả."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, tại sao chúng ta nên xem xét geoengineering?",
        "options": {
          "A": "Vì nó là giải pháp duy nhất để giảm lượng khí thải carbon.",
          "B": "Vì nó có thể là một công cụ quan trọng để giảm thiểu biến đổi khí hậu, mặc dù có những nhược điểm.",
          "C": "Vì nó là một cách rẻ tiền để tạo ra năng lượng sạch.",
          "D": "Vì nó sẽ tạo ra nhiều việc làm mới trong ngành công nghiệp."
        },
        "answer": "B"
      },
      {
        "question": "Operation AI Comply của Hoa Kỳ nhằm mục đích gì?",
        "options": {
          "A": "Thúc đẩy sự phát triển của các ứng dụng AI.",
          "B": "Kiểm soát các ứng dụng AI hứa hẹn quá mức và không thực hiện được.",
          "C": "Bảo vệ quyền riêng tư của người dùng AI.",
          "D": "Đảm bảo rằng tất cả các ứng dụng AI đều tuân thủ các tiêu chuẩn đạo đức."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì thúc đẩy sự bùng nổ trung tâm dữ liệu ở Malaysia?",
        "options": {
          "A": "Chính sách thuế ưu đãi của chính phủ.",
          "B": "Vị trí chiến lược, tài nguyên thiên nhiên và chính sách thân thiện với nhà đầu tư.",
          "C": "Nguồn nhân lực kỹ thuật cao dồi dào.",
          "D": "Cơ sở hạ tầng viễn thông tiên tiến."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích của việc sử dụng adapters trong mô hình embedding văn bản mới là gì?",
        "options": {
          "A": "Để giảm kích thước của mô hình.",
          "B": "Để chuyên biệt hóa mô hình cho các tác vụ cụ thể như truy xuất, phân cụm và phân loại văn bản.",
          "C": "Để tăng tốc độ đào tạo mô hình.",
          "D": "Để cải thiện khả năng hiểu ngôn ngữ của mô hình."
        },
        "answer": "B"
      }
    ]
  },
  "deepseeks-r1-seeks-to-match-openais-o1": {
    "title": "DeepSeek’s R1 seeks to match OpenAI’s o1",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nDeepSeek challenges OpenAI with new open reasoning model\n\nDeepSeek, an AI research company, released a preview of DeepSeek-R1, a reasoning model that claims to match the performance of OpenAI’s o1 on key math and coding benchmarks. The model spends more time considering questions to improve accuracy, potentially taking tens of seconds to respond depending on the complexity of the task. For now, DeepSeek is making a preview version of its model available for a limited number of inquiries, but the company plans to make an open-source version available soon. (DeepSeek)\n\nMicrosoft strikes deal with HarperCollins to train on its book catalog\n\nMicrosoft reached an agreement with HarperCollins to use select nonfiction books for training an unannounced AI model. The deal allows limited use of backlist titles, with authors given the option to participate, and includes safeguards to protect authors’ rights and revenue streams. This agreement highlights the growing trend of tech companies seeking high-quality, licensed content to improve their AI models’ performance and expertise in specific subjects. (BloombergandThe Verge)\n\nFlux expands AI image editing capabilities with new tool suite\n\nBlack Forest Labs unveiled FLUX.1 Tools, a suite of AI models designed to enhance control and editing capabilities for its text-to-image model FLUX.1. The suite includes four features: Fill for inpainting and outpainting, Depth and Canny for structural guidance, and Redux for image variation and restyling. Flux is offering these tools as open-access models for researchers and through its API for commercial use, demonstrating its commitment to both the research community and industry applications. (Black Forest Labs)\n\nAlibaba releases Qwen2.5-Turbo with million-token context window\n\nAlibaba extended Qwen2.5-Turbo’s context length from 128,000 to 1 million tokens, enabling it to process about 10 full-length novels or 30,000 lines of code at once. The model outperforms GPT-4 on long-text evaluation benchmarks while maintaining competitive performance on shorter sequences. Qwen2.5-Turbo’s improvements in speed and cost-effectiveness make it a competitive alternative for AI developers. (GitHub)\n\nRabbit’s AI agent learns to automate tasks from user demonstrations\n\nRabbit released a Teach Mode beta for all R1 users, allowing them to instruct the device’s AI agent to perform complex tasks across various platforms. The feature, part of Rabbit’s Large Action Model (LAM) system, learns from user demonstrations and can adapt to similar tasks, aiming to simplify human-computer interaction by making app interfaces invisible to users. Rabbit seeks to build an AI-native operating system to replace traditional app-based ecosystems, but early versions of the R1’s software have not delivered that promise. (Rabbit)\n\nFinancial firms embrace AI despite data-related concerns\n\nA new Bank of England survey reveals 75 percent of financial firms already use AI, with an additional 10 percent planning adoption within three years. Foundation models now account for 17 percent of all AI use cases, while third-party implementations have risen to 33 percent of use cases. Data-related issues top the list of perceived AI risks, but firms expect benefits to outpace risks over the next three years. (Bank of England)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng explored an emerging trend of writing text to be read specifically by AI models, discussing how it parallels SEO and how incentives might drive authors to create content tailored for LLM consumption.\n\n“A small number of people are posting text online that’s intended for direct consumption not by humans, but by LLMs (large language models). I find this a fascinating trend, particularly when writers are incentivized to help LLM providers better serve their users!”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Next-gen models show limited gainsas AI giants rethink their training strategies amidst the breakdown of scaling laws;AI creates an interactive Minecraft-like worldin real time, eliminating the need for a game engine;TSMC halts advanced chip production for Chinese companiesfollowing new U.S. orders, escalating chip restrictions; andresearchers achieve a 20 percent reduction in transformer training costswith minimal performance loss, paving the way for more efficient AI development.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Công ty nào đã phát hành bản xem trước của mô hình DeepSeek-R1, một mô hình suy luận cạnh tranh với OpenAI?",
        "options": {
          "A": "Microsoft",
          "B": "DeepSeek",
          "C": "Black Forest Labs",
          "D": "Alibaba"
        },
        "answer": "B"
      },
      {
        "question": "Microsoft đã đạt được thỏa thuận với nhà xuất bản nào để sử dụng sách của họ cho việc đào tạo mô hình AI?",
        "options": {
          "A": "Penguin Random House",
          "B": "Simon & Schuster",
          "C": "HarperCollins",
          "D": "Macmillan Publishers"
        },
        "answer": "C"
      },
      {
        "question": "FLUX.1 Tools, bộ công cụ AI mới của Black Forest Labs, cung cấp những tính năng chính nào để chỉnh sửa ảnh?",
        "options": {
          "A": "Tạo ảnh 3D và hoạt hình",
          "B": "Chỉnh sửa video và âm thanh",
          "C": "Inpainting, outpainting, hướng dẫn cấu trúc và tạo biến thể ảnh",
          "D": "Nhận diện khuôn mặt và thay đổi biểu cảm"
        },
        "answer": "C"
      },
      {
        "question": "Qwen2.5-Turbo của Alibaba có khả năng xử lý bao nhiêu token trong một lần?",
        "options": {
          "A": "128,000 tokens",
          "B": "256,000 tokens",
          "C": "500,000 tokens",
          "D": "1,000,000 tokens"
        },
        "answer": "D"
      },
      {
        "question": "Rabbit phát hành chế độ Teach Mode cho thiết bị R1 nhằm mục đích gì?",
        "options": {
          "A": "Cải thiện khả năng nhận diện giọng nói",
          "B": "Cho phép người dùng hướng dẫn AI thực hiện các tác vụ phức tạp",
          "C": "Tăng cường bảo mật dữ liệu cá nhân",
          "D": "Nâng cao hiệu suất xử lý hình ảnh"
        },
        "answer": "B"
      },
      {
        "question": "Theo khảo sát của Bank of England, tỷ lệ các công ty tài chính đã sử dụng AI là bao nhiêu?",
        "options": {
          "A": "25%",
          "B": "50%",
          "C": "75%",
          "D": "90%"
        },
        "answer": "C"
      },
      {
        "question": "Theo Andrew Ng, xu hướng mới nổi trong lĩnh vực AI là gì?",
        "options": {
          "A": "Phát triển các mô hình AI có khả năng tự học",
          "B": "Viết nội dung dành riêng cho các mô hình ngôn ngữ lớn (LLM)",
          "C": "Sử dụng AI để tạo ra các tác phẩm nghệ thuật",
          "D": "Ứng dụng AI trong lĩnh vực y tế"
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề nào được xem là rủi ro hàng đầu liên quan đến việc sử dụng AI trong các công ty tài chính?",
        "options": {
          "A": "Chi phí triển khai cao",
          "B": "Thiếu nhân lực có kỹ năng",
          "C": "Các vấn đề liên quan đến dữ liệu",
          "D": "Khả năng bị tấn công mạng"
        },
        "answer": "C"
      },
      {
        "question": "Công ty nào đã tạm dừng sản xuất chip tiên tiến cho các công ty Trung Quốc do các hạn chế mới của Hoa Kỳ?",
        "options": {
          "A": "Samsung",
          "B": "Intel",
          "C": "TSMC",
          "D": "GlobalFoundries"
        },
        "answer": "C"
      },
      {
        "question": "Nghiên cứu nào đã đạt được kết quả giảm 20% chi phí đào tạo transformer với hiệu suất không đổi?",
        "options": {
          "A": "Nghiên cứu về mô hình ngôn ngữ lớn của Google",
          "B": "Nghiên cứu về mạng nơ-ron tích chập của Facebook",
          "C": "Nghiên cứu về tối ưu hóa thuật toán đào tạo transformer",
          "D": "Nghiên cứu về phần cứng chuyên dụng cho AI của NVIDIA"
        },
        "answer": "C"
      }
    ]
  },
  "eagle-3-speeds-up-language-models": {
    "title": "EAGLE-3 speeds up language models",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nEAGLE-3 introduces new techniques for accelerating inference\n\nResearchers at Peking University, Microsoft, and elsewhere developed EAGLE-3, an updated method for speculative sampling that aims to speed up large language model inference. The approach removes feature prediction constraints and introduces a “training-time test” technique for directly predicting draft tokens. EAGLE-3 also incorporates a fusion of low, middle, and high-level features from the target model, moving beyond the use of only top-layer features. Experiments show EAGLE-3 achieves faster inference speeds compared to standard autoregressive decoding and previous speculative sampling methods across various tasks and model sizes. (arXiv)\n\nReinforcement learning pioneers honored with top computing award\n\nAndrew Barto and Richard Sutton won the 2024 Turing Award for their groundbreaking work on reinforcement learning, a method for AI systems to learn from digital rewards and punishments. Their research, which began in the late 1970s, laid the foundation for major AI breakthroughs like AlphaGo and ChatGPT. The $1 million prize acknowledges Barto and Sutton’s role in developing a fundamental AI technique that continues to shape the field’s rapid advancement and future potential. (Association for Computing Machinery)\n\nDiffRhythm generates full-length songs within seconds\n\nChinese researchers developed DiffRhythm, a diffusion-based model capable of generating complete songs up to 4 minutes 45 seconds long, including both vocals and accompaniment. The model uses a variational autoencoder to compress audio into latent representations, which are then generated by a diffusion transformer conditioned on lyrics and style prompts. DiffRhythm can produce high-quality 4-minute songs in just 10 seconds, significantly faster than previous language model approaches. The researchers released their model and code under a noncommercial license. (GitHubandarXiv)\n\nManus AI attracts plenty of attention but little consensus\n\nChinese startup The Butterfly Effect launched Manus, an AI agent platform that uses Claude and various undisclosed models to autonomously perform complex tasks without human oversight. Despite generating significant buzz and comparisons to breakthroughs like DeepSeek, some early users report Manus struggling with basic requests and crashing frequently. Manus is still in private preview, and the widely differing reports seem to stem from a combination of users’ limited access and very different expectations. (Manus,Forbes, andTechCrunch)\n\nOpenAI outlines its evolving approach to AI safety and alignment\n\nOpenAI detailed its current principles for ensuring artificial general intelligence benefits humanity. The company now views AGI development as a continuous process rather than a sudden leap, emphasizing iterative deployment to learn from real-world usage. OpenAI’s core safety principles include embracing uncertainty, layering multiple safeguards, developing scalable alignment methods, maintaining human control, and collaborating with the wider AI community. (OpenAI)\n\nGemini Embedding model tops multilingual benchmarks\n\nGoogle unveiled a new experimental Gemini Embedding text model, available through the Gemini API, which outperforms previous models and tops the Massive Text Embedding Benchmark Multilingual leaderboard. The model features an 8K token input limit, 3K output dimensions, and supports over 100 languages, making it applicable for diverse tasks like retrieval augmented generation and text classification. This release gives developers early access to Gemini Embedding capabilities, with Google working towards a stable, generally available version in the coming months. (Google)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng discussed the challenges of Voice Activity Detection (VAD) in noisy environments and highlighted Moshi, a model that continuously listens and decides when to speak, eliminating the need for explicit turn-taking detection. He emphasized ongoing innovations in voice AI and the potential for improved voice-to-voice interactions.\n\n“Just as the architecture of text-only transformers has gone through many evolutions (such as encoder-decoder models, decoder-only models, and reasoning models that generate a lot of ‘reasoning tokens’ before the final output), voice models are going through a lot of architecture explorations.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Mercury Coderreleased a fast text generator with a non-transformer architecture, introducing what may be the first commercially available Language Diffusion Model;OpenAI unveiled GPT-4.5, its most powerful non-reasoning model to date, promising enhanced performance and efficiency;Claude 3.7 Sonnet introduced a budget for reasoning tokens, a hybrid approach to reasoning models; andAmazon launched Alexa+, integrating generative AI and intelligent agents powered by Claude and other models to create a more advanced voice assistant.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "EAGLE-3 cải tiến phương pháp suy luận cho mô hình ngôn ngữ lớn bằng cách nào?",
        "options": {
          "A": "Chỉ sử dụng các đặc trưng ở lớp trên cùng của mô hình.",
          "B": "Loại bỏ các ràng buộc dự đoán đặc trưng và giới thiệu kỹ thuật 'kiểm tra trong quá trình huấn luyện'.",
          "C": "Tăng cường sử dụng các mô hình biến đổi (transformer).",
          "D": "Giảm kích thước của mô hình ngôn ngữ lớn."
        },
        "answer": "B"
      },
      {
        "question": "Giải thưởng Turing 2024 vinh danh Andrew Barto và Richard Sutton vì đóng góp gì?",
        "options": {
          "A": "Phát triển mô hình ngôn ngữ lớn ChatGPT.",
          "B": "Nghiên cứu tiên phong về học tăng cường (reinforcement learning).",
          "C": "Sáng tạo ra thuật toán AlphaGo.",
          "D": "Xây dựng nền tảng cho các hệ thống AI tự hành hoàn toàn."
        },
        "answer": "B"
      },
      {
        "question": "DiffRhythm tạo ra các bài hát hoàn chỉnh bằng cách sử dụng mô hình nào?",
        "options": {
          "A": "Mô hình ngôn ngữ lớn (LLM).",
          "B": "Mô hình biến đổi (transformer) truyền thống.",
          "C": "Mô hình khuếch tán (diffusion-based model).",
          "D": "Mô hình tự mã hóa biến phân (variational autoencoder) kết hợp với mô hình ngôn ngữ lớn."
        },
        "answer": "C"
      },
      {
        "question": "Manus, nền tảng AI agent của The Butterfly Effect, đang gặp phải vấn đề gì?",
        "options": {
          "A": "Không thể thực hiện các tác vụ phức tạp.",
          "B": "Chưa được cấp phép thương mại.",
          "C": "Gặp khó khăn với các yêu cầu cơ bản và thường xuyên bị lỗi.",
          "D": "Chỉ hỗ trợ một số ít ngôn ngữ."
        },
        "answer": "C"
      },
      {
        "question": "Nguyên tắc cốt lõi nào KHÔNG nằm trong các nguyên tắc an toàn AI của OpenAI?",
        "options": {
          "A": "Chấp nhận sự không chắc chắn.",
          "B": "Xây dựng các biện pháp bảo vệ nhiều lớp.",
          "C": "Phát triển các phương pháp điều chỉnh quy mô.",
          "D": "Tối đa hóa lợi nhuận cho các nhà đầu tư."
        },
        "answer": "D"
      },
      {
        "question": "Mô hình Gemini Embedding mới của Google có đặc điểm nổi bật nào?",
        "options": {
          "A": "Chỉ hỗ trợ tiếng Anh.",
          "B": "Có giới hạn đầu vào 8K token và hỗ trợ hơn 100 ngôn ngữ.",
          "C": "Chỉ được sử dụng cho các tác vụ phân loại văn bản.",
          "D": "Đã được phát hành phiên bản ổn định và có sẵn rộng rãi."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, thách thức chính trong Voice Activity Detection (VAD) là gì?",
        "options": {
          "A": "Xác định ngôn ngữ được sử dụng.",
          "B": "Loại bỏ tiếng ồn trong môi trường.",
          "C": "Phát hiện giọng nói trong môi trường ồn ào.",
          "D": "Chuyển đổi giọng nói thành văn bản."
        },
        "answer": "C"
      },
      {
        "question": "Moshi, mô hình được Andrew Ng đề cập, giải quyết vấn đề gì trong tương tác bằng giọng nói?",
        "options": {
          "A": "Tự động dịch ngôn ngữ.",
          "B": "Loại bỏ nhu cầu phát hiện lượt nói rõ ràng.",
          "C": "Tăng tốc độ phản hồi của hệ thống.",
          "D": "Cải thiện chất lượng giọng nói tổng hợp."
        },
        "answer": "B"
      },
      {
        "question": "Mercury Coder đã phát hành sản phẩm nào đáng chú ý?",
        "options": {
          "A": "Một mô hình biến đổi (transformer) cực nhanh.",
          "B": "Một trình tạo văn bản nhanh với kiến trúc không phải transformer, có thể là Mô hình Khuếch tán Ngôn ngữ thương mại đầu tiên.",
          "C": "Một công cụ chỉnh sửa video dựa trên AI.",
          "D": "Một hệ thống nhận dạng khuôn mặt tiên tiến."
        },
        "answer": "B"
      },
      {
        "question": "Alexa+ của Amazon tích hợp những công nghệ nào để tạo ra một trợ lý giọng nói tiên tiến hơn?",
        "options": {
          "A": "Chỉ tích hợp các mô hình ngôn ngữ lớn của Amazon.",
          "B": "Tích hợp AI tạo sinh và các agent thông minh được hỗ trợ bởi Claude và các mô hình khác.",
          "C": "Chỉ tập trung vào cải thiện khả năng hiểu ngôn ngữ tự nhiên.",
          "D": "Loại bỏ hoàn toàn sự can thiệp của con người trong quá trình tương tác."
        },
        "answer": "B"
      }
    ]
  },
  "elevenlabs-drops-latency-to-75-milliseconds": {
    "title": "ElevenLabs drops latency to 75 milliseconds",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nElevenLabs introduces Flash, a low-latency speech generation model\n\nElevenLabs unveiled a new AI model that generates speech in as little as 75 milliseconds (plus application and network latency). The model is available in two versions: Flash v2 for English and Flash v2.5 for 32 languages, both accessible through ElevenLabs’ Conversational AI platform or API. While Flash sacrifices some quality and emotional depth compared to ElevenLabs’ Turbo models, it outperforms comparable ultra-low-latency models in blind tests, optimizing it for developers creating real-time conversational AI applications. (ElevenLabs)\n\nFalcon3 models push boundaries for smaller model performance\n\nThe Technology Innovation Institute in Abu Dhabi released Falcon3, a family of large language models, all with fewer than 10 billion parameters. The new models, which include five base versions ranging from 1 billion to 10 billion parameters, employ single pre-training runs, depth up-scaling, and knowledge distillation to improve performance while reducing training costs. Falcon3 models demonstrate strong capabilities in areas such as math, coding, and scientific knowledge, outperforming larger models in several benchmarks and offering AI developers more efficient open options for their applications. (Hugging Face)\n\nNvidia acquires Run:ai, will open source its GPU orchestration software\n\nNvidia finalized its acquisition of Run:ai, a GPU orchestration software company, for a reported $700 million. Run:ai’s founders, Omri Geller and Ronen Dar, announced plans to open source the company’s software while maintaining their “open-platform philosophy” and continuing to support multiple AI chips and platforms. This acquisition further strengthens Nvidia’s position in the AI industry, challenging competitors like AMD and Intel to respond with their own strategic moves. (YahooandRun:ai)\n\nGoogle DeepMind’s SALT method speeds up large language model training\n\nResearchers at Google DeepMind introduced SALT (Small model Aided Large model Training), a novel approach that uses smaller language models to improve the efficiency of training large language models (LLMs). The two-phase method leverages smaller models to provide soft labels and select valuable data subsets, reducing computational requirements by 28 percent while improving model performance. SALT-trained LLMs outperformed baseline models on various benchmarks, including reading comprehension and commonsense reasoning, demonstrating better generalization capabilities. This technique could help democratize access to advanced AI technologies by making LLM development more accessible to institutions with limited computational resources. (arXiv)\n\nNew environment SWE-Gym fine-tunes software engineering agents\n\nResearchers at UC Berkeley, UIUC, Carnegie Mellon, and Apple developed SWE-Gym, a novel environment for training software engineering AI agents. Using 2,438 real-world Python tasks from GitHub issues, SWE-Gym offers pre-configured executable environments and expert-validated test cases, addressing limitations of previous benchmarks that lacked comprehensive training environments. Post-training with SWE-Gym significantly improved AI agents’ performance on existing benchmarks, with fine-tuned models showing increased task resolution rates and reduced failures in real-world settings. (arXiv)\n\nLlama models power Scribd’s new AI book discovery tool\n\nScribd enhanced Everand’s Ask AI feature using three open source Llama models to improve content discovery across its library of over 195 million items. The new system combines Llama 3.1’s 8B, 70B, and 405B models to create a more intuitive AI assistant that understands user intent and provides personalized recommendations. This new tool highlights the potential of open source AI models to change how users interact with large digital libraries, offering more precise and engaging content discovery experiences. (Meta)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s special issueofThe Batchfor an inspiring glimpse into AI’s potential in 2025, featuring insights from leading experts on generative AI, cinematic creativity, generalized intelligence, and the future of prosocial platforms.\n\nIn last week’s letter to readers and learners, Andrew Ng highlighted the excitement around AI’s potential in 2025, emphasizing the ease of building software prototypes with AI-assisted coding and its impact on productivity, creativity, and learning. He encouraged readers to make a learning plan, build prototypes, and embrace the fun and educational journey of creating with AI.\n\n“Even small wins — like the flash cards I printed out, which inspired my daughter to spend an extra 20 minutes practicing her multiplication table last night — make life better. Perhaps you’ll invent something that really takes off. And even if you don’t, you’ll have fun and learn a lot along the way.”\n\nRead Andrew’s full letterhere.\n\nOur New Year special issue explores the transformative potential of AI in 2025:generative AI liberating artists to focus on creativitywhile ensuring safety and accessibility;video models revolutionizing cinematic storytellingwith integrated audio and video; AGI drivingpersonalized and contextual interactions;data-efficient modelsenabling broader accessibility and sustainability; autonomous agents taking meaningful actions tosimplify our lives and enhance productivity; and AI-powered platformsfostering empathy, collaboration, and unityin digital spaces.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mục tiêu chính của mô hình Flash mới được giới thiệu bởi ElevenLabs là gì?",
        "options": {
          "A": "Tạo ra giọng nói với chất lượng và độ sâu cảm xúc cao nhất.",
          "B": "Tạo ra giọng nói với độ trễ thấp nhất có thể.",
          "C": "Hỗ trợ số lượng ngôn ngữ lớn nhất có thể.",
          "D": "Giảm chi phí đào tạo mô hình giọng nói."
        },
        "answer": "B"
      },
      {
        "question": "Falcon3, dòng mô hình ngôn ngữ lớn mới, nổi bật nhờ đặc điểm nào?",
        "options": {
          "A": "Số lượng tham số lớn hơn so với các mô hình khác.",
          "B": "Hiệu suất cao trong khi có số lượng tham số ít hơn 10 tỷ.",
          "C": "Khả năng tạo ra văn bản sáng tạo vượt trội.",
          "D": "Khả năng tích hợp dễ dàng với các nền tảng đám mây."
        },
        "answer": "B"
      },
      {
        "question": "Nvidia mua lại Run:ai với mục đích gì?",
        "options": {
          "A": "Để cạnh tranh trực tiếp với Google DeepMind trong lĩnh vực nghiên cứu AI.",
          "B": "Để mở rộng thị trường sang lĩnh vực phần mềm quản lý GPU.",
          "C": "Để phát triển các chip AI mới có hiệu năng vượt trội.",
          "D": "Để tăng cường vị thế trong ngành AI và cạnh tranh với AMD và Intel."
        },
        "answer": "D"
      },
      {
        "question": "Phương pháp SALT của Google DeepMind giúp cải thiện quá trình đào tạo LLM như thế nào?",
        "options": {
          "A": "Tăng cường khả năng xử lý ngôn ngữ tự nhiên của mô hình.",
          "B": "Giảm yêu cầu tính toán bằng cách sử dụng mô hình nhỏ hơn để hỗ trợ.",
          "C": "Tự động điều chỉnh các tham số của mô hình trong quá trình đào tạo.",
          "D": "Sử dụng dữ liệu huấn luyện lớn hơn và đa dạng hơn."
        },
        "answer": "B"
      },
      {
        "question": "SWE-Gym được phát triển để giải quyết vấn đề gì trong việc đào tạo các AI agent cho kỹ thuật phần mềm?",
        "options": {
          "A": "Thiếu dữ liệu huấn luyện chất lượng cao.",
          "B": "Sự phức tạp của các thuật toán học máy.",
          "C": "Sự thiếu hụt các môi trường thực thi và kiểm thử toàn diện.",
          "D": "Chi phí đào tạo quá cao."
        },
        "answer": "C"
      },
      {
        "question": "Scribd sử dụng mô hình Llama để làm gì?",
        "options": {
          "A": "Để dịch sách sang nhiều ngôn ngữ khác nhau.",
          "B": "Để tạo ra các bản tóm tắt tự động cho sách.",
          "C": "Để cải thiện khả năng khám phá nội dung và đưa ra các đề xuất cá nhân hóa.",
          "D": "Để phát hiện và loại bỏ nội dung vi phạm bản quyền."
        },
        "answer": "C"
      },
      {
        "question": "Theo Andrew Ng, điều gì khiến năm 2025 trở nên thú vị trong lĩnh vực AI?",
        "options": {
          "A": "Sự ra đời của trí tuệ nhân tạo tổng quát (AGI).",
          "B": "Sự dễ dàng trong việc xây dựng các nguyên mẫu phần mềm với sự hỗ trợ của AI.",
          "C": "Sự phát triển của các mô hình AI có khả năng tự học.",
          "D": "Sự phổ biến của các ứng dụng AI trong lĩnh vực y tế."
        },
        "answer": "B"
      },
      {
        "question": "Số lượng ngôn ngữ mà Flash v2.5 của ElevenLabs hỗ trợ là bao nhiêu?",
        "options": {
          "A": "2",
          "B": "32",
          "C": "11",
          "D": "Không được đề cập"
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ nào được Falcon3 sử dụng để cải thiện hiệu suất trong khi giảm chi phí đào tạo?",
        "options": {
          "A": "Mạng nơ-ron tích chập sâu.",
          "B": "Đào tạo trước đơn lẻ, tăng cường độ sâu và chưng cất kiến thức.",
          "C": "Học tăng cường với phần thưởng thưa thớt.",
          "D": "Mô hình biến áp với cơ chế tự chú ý."
        },
        "answer": "B"
      },
      {
        "question": "SWE-Gym sử dụng bao nhiêu nhiệm vụ Python thực tế từ các vấn đề GitHub để huấn luyện?",
        "options": {
          "A": "100",
          "B": "1000",
          "C": "2438",
          "D": "195 triệu"
        },
        "answer": "C"
      }
    ]
  },
  "emu3-claims-next-token-prediction-is-all-you-need": {
    "title": "Emu3 claims “next-token prediction is all you need”",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nEmu3, a next-token, open-source multimodal model\n\nBAAI unveiled Emu3, a suite of multimodal AI models trained solely with next-token prediction on tokenized images, text, and videos. The models (including chat, generative, and tokenizer versions) outperform established competitors in both generation and perception tasks, surpassing open models like SDXL, LLaVA-1.6, and OpenSora-1.2, without using diffusion or compositional architectures. BAAI released Emu3 on GitHub under the Apache 2.0 license, allowing developers and researchers to freely use, modify, and distribute the models. (GitHub)\n\nBlack Forest’s image generator gets an update along with a new API\n\nBlack Forest Labs released FLUX1.1 [pro], a text-to-image model three times faster than its predecessor that outperforms competitors on the Artificial Analysis image arena benchmark. The company also launched a beta version of its API, allowing developers to integrate FLUX’s capabilities into their applications with advanced customization options and competitive pricing, with FLUX1.1 [pro] priced at 4 cents per image. This release challenges larger tech companies by offering developers a cost-effective alternative for integrating cutting-edge image generation into their products and workflows. (Black Forest Labs)\n\nChatGPT’s canvas offers new interfaces to edit writing and code\n\nOpenAI launched canvas, a new interface for ChatGPT that allows users to collaborate on writing and coding projects beyond simple chat interactions. Canvas opens in a separate window, enabling users to edit text or code directly while receiving inline feedback and suggestions from ChatGPT. This new feature aims to provide a more context-aware environment for complex projects, allowing users to highlight specific sections for focused assistance and offering shortcuts for common tasks like adjusting length of text sections or debugging code. (OpenAI)\n\nGoogle revisits its learning-based chip design model, names it “AlphaChip”\n\nGoogle officially named its deep reinforcement learning method for chip layout generation “AlphaChip” and addressed misconceptions about its capabilities. The company emphasized that AlphaChip’s performance improves with pre-training on chip blocks and scales with computational resources, achieving up to 6.2 percent wirelength reduction compared to human experts in recent Tensor Processing Unit designs. Google also clarified that AlphaChip doesn’t require initial placement data and may need adjustments for older chip technologies, while highlighting its successful deployment in multiple generations of Google’s AI accelerators and its adoption by other chipmakers like MediaTek. (DeepMindandNature)\n\nCopilot gets new eyes and a voice, with privacy baked-in\n\nMicrosoft launched new capabilities for its Copilot AI assistant, including Copilot Vision, which can analyze and respond to questions about on-screen content in Microsoft Edge. The company also introduced Think Deeper, a feature designed to tackle more complex problems, and Copilot Voice, which enables voice interactions with the AI. All of these features are based on OpenAI models fine-tuned by Microsoft. Microsoft addressed privacy concerns raised after its initial announcement of Recall, stating that Copilot Vision deletes data immediately after conversations and doesn’t store processed audio, images, or text for model training. (Microsoft)\n\nAider’s coding assistant tests models’ performance in different tasks\n\nAider, an AI coding assistant, now uses separate “Architect” and “Editor” models to handle code reasoning and editing tasks respectively. This approach achieved state-of-the-art results on Aider’s code editing benchmark, with OpenAI’s o1-preview as the Architect and either DeepSeek or o1-mini as the Editor scoring 85%. The two-model system allows each AI to focus on its specific task, potentially improving overall performance and efficiency for AI developers. (Aider)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng celebrated the veto of California’s anti-innovation bill SB 1047 by Governor Newsom, highlighting the efforts of AI experts and advocates who worked to defeat the legislation and stressing the importance of evidence-based regulation in the field of AI.\n\n“The fight to protect open source is not yet over, and we have to continue our work to make sure regulations are based on science, not science fiction.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Meta expands its Llama Herdwith updates to its Llama models, adding vision-language capabilities, edge sizes, and agentic APIs;Adobe integrates AI video generation toolsinto Premiere Pro, bringing generative video directly into the editing suite; aglobal coalitionendorses international guidelines for the responsible use of AI in military applications; andresearchers develop a methodenabling large language models to accurately process and answer questions from complex spreadsheets.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mô hình Emu3 của BAAI được huấn luyện bằng phương pháp nào?",
        "options": {
          "A": "Sử dụng kiến trúc khuếch tán (diffusion).",
          "B": "Dự đoán token tiếp theo (next-token prediction) trên hình ảnh, văn bản và video đã được token hóa.",
          "C": "Kết hợp nhiều kiến trúc thành phần (compositional architectures).",
          "D": "Sử dụng dữ liệu được tạo bởi các mô hình khác."
        },
        "answer": "B"
      },
      {
        "question": "FLUX1.1 [pro] của Black Forest Labs có ưu điểm nổi bật nào so với phiên bản trước?",
        "options": {
          "A": "Khả năng tạo ra hình ảnh có độ phân giải cao hơn.",
          "B": "Tốc độ tạo ảnh nhanh hơn gấp ba lần.",
          "C": "Giá thành rẻ hơn đáng kể.",
          "D": "Tích hợp trực tiếp vào các phần mềm chỉnh sửa ảnh chuyên nghiệp."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng 'canvas' mới của ChatGPT cho phép người dùng làm gì?",
        "options": {
          "A": "Tạo ra các bản trình bày trực quan từ văn bản.",
          "B": "Cộng tác chỉnh sửa văn bản và code trực tiếp trong một giao diện riêng.",
          "C": "Tự động tóm tắt các cuộc trò chuyện dài.",
          "D": "Dịch văn bản sang nhiều ngôn ngữ khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "AlphaChip của Google sử dụng phương pháp học tăng cường sâu (deep reinforcement learning) để làm gì?",
        "options": {
          "A": "Tối ưu hóa hiệu suất của các mô hình AI.",
          "B": "Thiết kế bố cục chip.",
          "C": "Phát hiện lỗi trong quá trình sản xuất chip.",
          "D": "Tự động viết code cho các ứng dụng AI."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng Copilot Vision của Microsoft cho phép người dùng làm gì?",
        "options": {
          "A": "Tạo ra hình ảnh từ mô tả bằng văn bản.",
          "B": "Phân tích và trả lời các câu hỏi về nội dung trên màn hình trong Microsoft Edge.",
          "C": "Điều khiển các thiết bị thông minh bằng giọng nói.",
          "D": "Tự động viết email và báo cáo."
        },
        "answer": "B"
      },
      {
        "question": "Aider sử dụng hai mô hình 'Architect' và 'Editor' để làm gì?",
        "options": {
          "A": "Tạo ra các ứng dụng AI hoàn chỉnh từ đầu.",
          "B": "Xử lý các tác vụ lý luận và chỉnh sửa code một cách riêng biệt.",
          "C": "Tự động kiểm tra và sửa lỗi code.",
          "D": "Dịch code từ ngôn ngữ này sang ngôn ngữ khác."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã xảy ra với dự luật SB 1047 ở California?",
        "options": {
          "A": "Đã được thông qua và trở thành luật.",
          "B": "Đã bị Thống đốc Newsom phủ quyết.",
          "C": "Đang được xem xét lại bởi các nhà lập pháp.",
          "D": "Đã bị trì hoãn vô thời hạn."
        },
        "answer": "B"
      },
      {
        "question": "Meta đã cập nhật dòng sản phẩm Llama của mình bằng cách nào?",
        "options": {
          "A": "Thêm khả năng tạo video từ văn bản.",
          "B": "Thêm khả năng thị giác ngôn ngữ, kích thước cạnh và API đại diện.",
          "C": "Tăng cường khả năng dịch thuật.",
          "D": "Cải thiện hiệu suất trên các thiết bị di động."
        },
        "answer": "B"
      },
      {
        "question": "Adobe đã tích hợp công cụ AI nào vào Premiere Pro?",
        "options": {
          "A": "Công cụ tạo ảnh AI.",
          "B": "Công cụ tạo video AI.",
          "C": "Công cụ chỉnh sửa âm thanh AI.",
          "D": "Công cụ tạo hiệu ứng đặc biệt AI."
        },
        "answer": "B"
      },
      {
        "question": "Một liên minh toàn cầu đã tán thành điều gì liên quan đến AI?",
        "options": {
          "A": "Việc cấm hoàn toàn AI trong quân sự.",
          "B": "Các hướng dẫn quốc tế cho việc sử dụng AI có trách nhiệm trong các ứng dụng quân sự.",
          "C": "Việc phát triển AI quân sự phải được kiểm soát bởi Liên Hợp Quốc.",
          "D": "Tất cả các quốc gia phải chia sẻ công nghệ AI quân sự của mình."
        },
        "answer": "B"
      }
    ]
  },
  "ernie-checks-competitors-with-low-prices": {
    "title": "ERNIE checks competitors with low prices",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nBaidu releases ERNIE 4.5 and ERNIE X1 models\n\nBaidu launched its latest foundation models, ERNIE 4.5 and ERNIE X1, with free access for individual users through ERNIE Bot’s website. ERNIE 4.5 is a multimodal model integrating text, images, audio, and video, while ERNIE X1 is a deep-thinking reasoning model with enhanced planning and problem-solving capabilities. Enterprise users and developers can try both models free on Baidu’s ERNIE bot website, or access ERNIE 4.5 on Baidu AI Cloud’s Qianfan with pricing starting at RMB 0.004 per thousand tokens. ERNIE 4.5 reportedly outperforms GPT-4.5 on multiple benchmarks at 1 percent of the price, while ERNIE X1 (available via API soon) offers performance comparable to DeepSeek-R1, with input prices of RMB 0.002 per thousand tokens and output prices of RMB 0.008 per thousand tokens, about half the price. (PR Newswire)\n\nOLMo 2 32B launches as a high-performing, fully open model\n\nAI2 released OLMo 2 32B, the largest model in their OLMo 2 lineup. This model, trained on trillions of tokens and post-trained with Tulu 3.1, competes with leading open weight models (Qwen 2.5 72B, Llama 3.1 and 3.3 70B) and outperforms GPT-3.5 Turbo and GPT4o-mini on various academic benchmarks. Developers and researchers could gain from OLMo 2 32B’s open code and open data availability, allowing them to study and customize advanced model pipelines and experiment with multimodal input. (Allen AI)\n\nGoogle DeepMind introduces Gemini models for robotics\n\nGoogle DeepMind unveiled Gemini Robotics and Gemini Robotics-ER, two AI models based on Gemini 2.0, designed to enhance robotic capabilities in the physical world. Gemini Robotics incorporates vision-language-action abilities for direct robot control, and it adapts easily to various robot types, while Gemini Robotics-ER focuses on spatial reasoning and can connect with existing low-level robot controllers. These new AI models aim to improve generalization, interactivity, and dexterity in robots, making them better suited for real-world tasks and applications. (Google)\n\nCohere’s new model offers long contexts and language support for enterprise\n\nCohere released Command A, a 111 billion parameter generative model that aims to deliver strong performance for enterprise applications using minimal hardware. Command Al matches or exceeds the performance of GPT-4o and DeepSeek-V3 on tasks such as instruction following and multilingual capabilities while requiring only two A100 or H100 GPUs for deployment. Command A supports the 23 languages spoken by most of the world’s population, and can be deployed locally or via API for $2.50/million input tokens and $10/million output tokens. (Cohere)\n\nChina introduces extensive AI content labeling regulations\n\nChina will require explicit labeling of AI-generated content under new regulations taking effect on September 1. The new regulations were announced by the Cyberspace Administration of China and other agencies. The rules mandate visible and metadata-based labels for AI-generated text, images, audio, video, and virtual content, and require service providers to ensure compliance with cybersecurity regulations. These measures aim to curb misinformation and enhance online transparency, similar to regulatory efforts in the EU and U.S. (South China Morning Post)\n\nHow to use LLMs to detect misbehavior in reasoning models\n\nOpen AI researchers showed that they can use large language models to monitor the chain-of-thought (CoT) reasoning of frontier models to detect misbehavior. They found that when these reasoning models exploit or circumvent tasks using “bad thoughts” (unwanted steps in the reasoning chain or attempts at reward hacking), penalizing these thoughts led models to hide their intentions, rather than ceasing misbehavior. Findings suggest that CoT monitoring can provide valuable insights for overseeing advanced AI models in the future, but the researchers recommend against strong optimization pressure on CoTs as it risks making models’ intentions less transparent. (OpenAI)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng defended the importance of learning to code, arguing that as AI-assisted coding makes programming easier, more people should code—not fewer. He pushed back against claims that programming will become obsolete, arguing that understanding the “language of software” empowers individuals to work effectively with AI tools and maximize their impact.\n\n“One question I’m asked most often is what someone should do who is worried about job displacement by AI. My answer is: Learn about AI and take control of it, because one of the most important skills in the future will be the ability to tell a computer exactly what you want, so it can do that for you. Coding (or getting AI to code for you) is the best way to do that.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:QwQ-32B emerged as a strong contenderagainst DeepSeek-R1 and other larger reasoning models, challenging the dominance of high-parameter architectures with compact reasoning; Microsoft’s Phi-4 Multimodal model offeredsimultaneous processing of text, images, and speech;a U.S. court ruling rejected the fair use defensein the Thomson Reuters AI lawsuit, citing Ross's attempt to use copyrighted material to build a competing product; andPerplexity launched an uncensored version of DeepSeek-R1, raising discussions about AI safety and adapting open language models.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mô hình ERNIE 4.5 của Baidu tích hợp những phương thức nào?",
        "options": {
          "A": "Chỉ văn bản và hình ảnh.",
          "B": "Văn bản, hình ảnh, âm thanh và video.",
          "C": "Chỉ âm thanh và video.",
          "D": "Văn bản và âm thanh."
        },
        "answer": "B"
      },
      {
        "question": "OLMo 2 32B của AI2 cạnh tranh trực tiếp với những mô hình mã nguồn mở hàng đầu nào?",
        "options": {
          "A": "GPT-3.5 Turbo và GPT4o-mini.",
          "B": "Qwen 2.5 72B, Llama 3.1 và 3.3 70B.",
          "C": "GPT-4 và DeepSeek-R1.",
          "D": "ERNIE 4.5 và ERNIE X1."
        },
        "answer": "B"
      },
      {
        "question": "Gemini Robotics và Gemini Robotics-ER của Google DeepMind được thiết kế để làm gì?",
        "options": {
          "A": "Tạo ra các mô hình ngôn ngữ lớn.",
          "B": "Nâng cao khả năng của robot trong thế giới thực.",
          "C": "Phân tích dữ liệu lớn.",
          "D": "Phát triển các ứng dụng trí tuệ nhân tạo trên đám mây."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Command A của Cohere có bao nhiêu tham số?",
        "options": {
          "A": "11 tỷ tham số.",
          "B": "72 tỷ tham số.",
          "C": "32 tỷ tham số.",
          "D": "111 tỷ tham số."
        },
        "answer": "D"
      },
      {
        "question": "Theo quy định mới của Trung Quốc, nội dung do AI tạo ra cần phải có gì?",
        "options": {
          "A": "Chữ ký điện tử của người tạo ra AI.",
          "B": "Nhãn rõ ràng và dựa trên siêu dữ liệu.",
          "C": "Chứng nhận bản quyền.",
          "D": "Thông tin về nguồn gốc dữ liệu huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu của OpenAI về việc sử dụng LLM để phát hiện hành vi sai trái trong mô hình suy luận cho thấy điều gì?",
        "options": {
          "A": "Việc phạt các 'ý nghĩ xấu' khiến mô hình ngừng hành vi sai trái.",
          "B": "Việc phạt các 'ý nghĩ xấu' khiến mô hình che giấu ý định của mình.",
          "C": "LLM không thể phát hiện hành vi sai trái trong mô hình suy luận.",
          "D": "Cần tối ưu hóa mạnh mẽ chuỗi suy nghĩ để ngăn chặn hành vi sai trái."
        },
        "answer": "B"
      },
      {
        "question": "Andrew Ng cho rằng kỹ năng quan trọng nhất trong tương lai là gì?",
        "options": {
          "A": "Khả năng quản lý dự án AI.",
          "B": "Khả năng giao tiếp hiệu quả với đồng nghiệp.",
          "C": "Khả năng nói cho máy tính biết chính xác bạn muốn gì.",
          "D": "Khả năng phân tích dữ liệu lớn."
        },
        "answer": "C"
      },
      {
        "question": "QwQ-32B đã thách thức sự thống trị của kiến trúc tham số cao trong lĩnh vực nào?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên.",
          "B": "Suy luận.",
          "C": "Thị giác máy tính.",
          "D": "Phân tích dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Phi-4 Multimodal của Microsoft có khả năng xử lý đồng thời những loại dữ liệu nào?",
        "options": {
          "A": "Văn bản và hình ảnh.",
          "B": "Hình ảnh và âm thanh.",
          "C": "Văn bản và âm thanh.",
          "D": "Văn bản, hình ảnh và âm thanh."
        },
        "answer": "D"
      },
      {
        "question": "Vụ kiện Thomson Reuters AI liên quan đến việc sử dụng trái phép tài liệu có bản quyền để làm gì?",
        "options": {
          "A": "Huấn luyện mô hình ngôn ngữ lớn.",
          "B": "Xây dựng một sản phẩm cạnh tranh.",
          "C": "Phân tích dữ liệu tài chính.",
          "D": "Phát triển phần mềm quản lý rủi ro."
        },
        "answer": "B"
      }
    ]
  },
  "evaluating-the-best-ai-search-engines": {
    "title": "Evaluating the best AI search engines",
    "collection": "data-points",
    "content": "In today’s edition, you’ll learn more about:\n\nSearch Arena leaderboard weighs human preferences for AI-aided search\n\nSearch Arena, a new crowdsourced evaluation platform from LM Arena, measures human preference for search-augmented LLM systems using real-world queries and current events. Based on 7,000 human votes collected between March and April, Gemini-2.5-Pro-Grounding and Perplexity-Sonar-Reasoning-Pro tied for first place on the leaderboard, followed by other Perplexity Sonar models, Gemini-2.0-Flash-Grounding, and OpenAI’s web search API models. Analysis showed that three factors strongly correlated with human preference: longer responses, higher citation counts, and references to specific web sources like YouTube and online forums. The authors have open sourced their dataset and analysis code, with plans to expand the platform to include more model submissions and cross-task evaluations. (LM Arena)\n\nAnthropic partners with Google on Research and Docs integration\n\nAnthropic introduced two new features for Claude, both powered by Google, a key investor, its AI chatbot. Research allows Claude to search both internal work documents and the web, conducting multiple searches and automatically exploring different angles of a question to deliver answers with citations. The Google Workspace integration connects Claude to Gmail, Calendar, and Google Docs, enabling it to search emails, review documents, and access calendar information without requiring manual uploads. These features give Claude parity with other companies, including OpenAI, who offer Deep Research capabilities. Both are now available in early beta for paid plans in the United States, Japan, and Brazil, with Google Workspace integration accessible to all paid users whose admins have enabled the feature. (Anthropic)\n\nSingle-bit language model promises full power at a fraction of the cost\n\nMicrosoft released BitNet b1.58 2B4T, a native 1.58-bit large language model trained on 4 trillion tokens. The model matches the performance of similar-sized full-precision models across language understanding, math reasoning, coding, and conversational tasks, while dramatically reducing resource requirements. BitNet b1.58 uses just 0.4GB of memory compared to 2-4.8GB for comparable models, consumes up to 90 percent less energy, and offers faster inference speeds. Microsoft has made the model weights publicly available on Hugging Face along with optimized inference implementations for both GPU and CPU architectures. (arXiv)\n\nKling 2.0 adds multimodal inputs, improves video creation\n\nKuaishou Technology launched Kling AI 2.0 Master Edition, featuring a new multimodal visual language (MVL) approach that allows users to input images, video clips, and text rather than text alone. The company claims its models outperform competitors like Google Veo2 and Runway Gen-4 in internal tests, with significant advantages in semantic responsiveness, visual quality, and motion quality. The new model introduces editing capabilities that let users add, remove, or replace elements in AI-generated videos by inputting images or text prompts. Monthly subscription plans start at $10 a month for limited credits, ranging up to $92 a month for professional users. (Kling AIandGlobe Newswire)\n\nGoogle launches Veo 2 and Whisk for Gemini Advanced users\n\nGoogle rolled out Veo 2, its updated video generation model, to U.S.-based Gemini Advanced users. Veo 2 enables users to create videos by providing detailed scene descriptions, with more specific prompts offering greater control over the final output. Whisk, a Google Labs experiment introduced in December, helps users visualize ideas using text and image prompts, and now includes Whisk Animate to turn images into videos using Veo 2. All generated videos include SynthID watermarking, and Google has implemented safety measures including red teaming and evaluations to prevent policy-violating content. The feature is now rolling out globally to Google One AI Premium subscribers across all Gemini-supported languages. (Google)\n\nMusic streaming service Deezer swamped with AI songs\n\nDeezer revealed that 18 percent of songs uploaded to its platform are fully generated by AI, with more than 20,000 AI-generated tracks uploaded daily, nearly twice the amount reported four months ago. The French streaming service implemented a detection tool to filter these AI-created tracks from algorithmic recommendations for its 9.7 million subscribers. This surge in AI-generated music has triggered legal battles across the creative industry, with major labels like Universal, Warner, and Sony suing AI music tools Suno and Udio for alleged copyright infringement. (Reuters)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng shared why teams should have started building evaluations early — even if they were quick and imperfect — and improved them over time to accelerate GenAI development.\n\n“It’s okay to build quick evals that are only partial, incomplete, and noisy measures of the system’s performance, and to iteratively improve them.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: Google unveiledGemini 2.5 Pro Experimental, which outperforms top AI models and continues the rapid evolution of its flagship model family; Model Context Protocol (MCP), anopen standard for tool use and data access,gained traction as OpenAI adopted it to improve LLM integration with external tools and APIs; a book excerpt exploredSam Altman’s brief ouster and return to OpenAI, shedding light on the company’s internal power struggles; and researchers introduced anew byte-based modelthat surpasses Llama 3 and other token-based models on tasks involving misspellings, noisy input, and translation.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Nền tảng đánh giá crowdsourced Search Arena của LM Arena đo lường điều gì?",
        "options": {
          "A": "Hiệu suất của các mô hình ngôn ngữ lớn (LLM) trong việc tạo ra văn bản sáng tạo.",
          "B": "Sự ưa thích của con người đối với các hệ thống LLM được tăng cường khả năng tìm kiếm, sử dụng các truy vấn thực tế.",
          "C": "Khả năng của các mô hình LLM trong việc giải quyết các bài toán phức tạp.",
          "D": "Mức độ chính xác của các mô hình LLM trong việc dự đoán xu hướng thị trường."
        },
        "answer": "B"
      },
      {
        "question": "Anthropic hợp tác với Google để tích hợp những tính năng mới nào vào Claude?",
        "options": {
          "A": "Khả năng tạo ra hình ảnh và video từ văn bản.",
          "B": "Khả năng tìm kiếm tài liệu nội bộ, web và tích hợp với Google Workspace.",
          "C": "Khả năng dịch thuật ngôn ngữ tự động và chính xác hơn.",
          "D": "Khả năng tạo ra âm nhạc và các hiệu ứng âm thanh."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình ngôn ngữ BitNet b1.58 của Microsoft có ưu điểm nổi bật nào so với các mô hình full-precision tương đương?",
        "options": {
          "A": "Khả năng hiểu và tạo ra các ngôn ngữ lập trình phức tạp hơn.",
          "B": "Yêu cầu tài nguyên thấp hơn đáng kể, bao gồm bộ nhớ và năng lượng tiêu thụ.",
          "C": "Khả năng xử lý hình ảnh và video với độ phân giải cao hơn.",
          "D": "Khả năng tương tác với người dùng thông qua giọng nói tự nhiên hơn."
        },
        "answer": "B"
      },
      {
        "question": "Kling AI 2.0 Master Edition của Kuaishou Technology cho phép người dùng nhập những loại dữ liệu nào?",
        "options": {
          "A": "Chỉ văn bản.",
          "B": "Văn bản và âm thanh.",
          "C": "Hình ảnh, video clip và văn bản.",
          "D": "Chỉ hình ảnh và video clip."
        },
        "answer": "C"
      },
      {
        "question": "Veo 2 của Google cho phép người dùng tạo video bằng cách nào?",
        "options": {
          "A": "Bằng cách sử dụng các mẫu video có sẵn.",
          "B": "Bằng cách cung cấp các đoạn mã lập trình.",
          "C": "Bằng cách cung cấp các mô tả chi tiết về cảnh.",
          "D": "Bằng cách sử dụng các hình ảnh có sẵn."
        },
        "answer": "C"
      },
      {
        "question": "Dịch vụ phát nhạc trực tuyến Deezer đã thực hiện biện pháp gì để đối phó với sự gia tăng của các bài hát do AI tạo ra?",
        "options": {
          "A": "Cấm hoàn toàn các bài hát do AI tạo ra khỏi nền tảng.",
          "B": "Tăng cường quảng bá các bài hát do AI tạo ra để thu hút người dùng.",
          "C": "Triển khai công cụ phát hiện để lọc các bài hát do AI tạo ra khỏi các đề xuất thuật toán.",
          "D": "Yêu cầu người dùng xác nhận rằng họ muốn nghe các bài hát do AI tạo ra."
        },
        "answer": "C"
      },
      {
        "question": "Theo Andrew Ng, tại sao các nhóm nên bắt đầu xây dựng các đánh giá sớm trong quá trình phát triển GenAI?",
        "options": {
          "A": "Để đảm bảo rằng các mô hình AI hoàn hảo ngay từ đầu.",
          "B": "Để tăng tốc quá trình phát triển GenAI bằng cách cải thiện các đánh giá theo thời gian.",
          "C": "Để giảm chi phí phát triển GenAI.",
          "D": "Để tránh các vấn đề pháp lý liên quan đến AI."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích của Model Context Protocol (MCP) là gì?",
        "options": {
          "A": "Để tạo ra các mô hình ngôn ngữ lớn (LLM) nhỏ gọn hơn.",
          "B": "Để cải thiện khả năng tích hợp LLM với các công cụ và API bên ngoài.",
          "C": "Để tăng cường bảo mật cho các mô hình AI.",
          "D": "Để giảm thiểu tác động tiêu cực của AI đến môi trường."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã được tiết lộ về Sam Altman trong một đoạn trích từ cuốn sách được đề cập trong bài viết?",
        "options": {
          "A": "Ông đã thành lập một công ty AI đối thủ của OpenAI.",
          "B": "Ông đã phát triển một mô hình AI vượt trội hơn tất cả các mô hình hiện có.",
          "C": "Ông đã trải qua một cuộc đấu tranh quyền lực nội bộ tại OpenAI, dẫn đến việc ông bị sa thải và sau đó được phục hồi.",
          "D": "Ông đã từ chức CEO của OpenAI để tập trung vào các dự án cá nhân."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình byte-based mới được giới thiệu có ưu điểm gì so với các mô hình token-based trên các tác vụ liên quan đến lỗi chính tả và dữ liệu nhiễu?",
        "options": {
          "A": "Nó có thể xử lý các ngôn ngữ lập trình phức tạp hơn.",
          "B": "Nó vượt trội hơn Llama 3 và các mô hình token-based khác.",
          "C": "Nó có thể tạo ra hình ảnh và video với độ phân giải cao hơn.",
          "D": "Nó có thể dịch thuật ngôn ngữ tự động và chính xác hơn."
        },
        "answer": "B"
      }
    ]
  },
  "finding-the-limits-of-pretraining-and-quantization": {
    "title": "Finding the limits of pretraining and quantization",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nNew scaling laws reveal optimal precision for language model training and inference\n\nResearchers from Harvard, Stanford, Carnegie Mellon, and elsewhere developed new “precision-aware” scaling laws that predict how training and inference in lower precision affects language model performance. They found that post-training quantization degrades models more as they are trained on more data, eventually making additional pretraining data harmful. For pretraining, their scaling laws suggest that training larger models in lower precision (around 7-8 bits) may be compute-optimal, while very low precision (below 4 bits) requires disproportionately increasing model size to maintain performance. (arXiv)\n\nEU releases draft guidelines for regulating general-purpose AI\n\nThe European Union released an initial draft of its Code of Practice for providers of general-purpose and high-risk AI models, inviting feedback until November 28. The draft, prepared by independent experts, aims to guide the development of trustworthy and safe AI models, detailing transparency rules, copyright regulations, and risk assessment measures for advanced AI systems. While this draft is still provisional and short on specifics, the final version is expected to play a crucial role in shaping the future of AI development and deployment across the EU. (Europa.EU)\n\nNew satellite systems improve early wildfire detection\n\nGoogle Research announced a partnership with the U.S. Forest Service to develop FireSat, a satellite constellation dedicated to detecting and tracking wildfires. The system will provide global high-resolution imagery updated every 20 minutes, enabling detection of fires as small as a classroom and using AI to analyze images for reliable fire identification. FireSat’s data will offer scientists new insights into how fire behaves and spreads, potentially improving wildfire prediction models and emergency response efforts. (Google)\n\nBaidu unveils new AI technologies at annual conference\n\nBaidu introduced iRAG, a technology to reduce hallucinations in image generation, and Miaoda, a no-code tool for creating AI applications, at its Baidu World 2024 conference in Shanghai. The company reported that daily API calls to its ERNIE foundation model reached 1.5 billion in early November, a 30-fold increase from the previous year. Baidu also announced Xiaodu AI Glasses, powered by ERNIE and equipped with various AI capabilities, set to launch in the first half of 2025. (Reuters)\n\nChatGPT desktop app adds code-reading feature for MacOS\n\nOpenAI’s ChatGPT desktop app for MacOS can now read code from popular developer tools like VS Code and Xcode, eliminating the need for manual copying and pasting. The new “Work with Apps” feature, available to Plus and Teams users, automatically sends code sections to ChatGPT for context alongside user prompts, but cannot write code directly into these apps. OpenAI views this capability as a step toward building AI agents that can understand and interact with computer interfaces beyond prompts and responses. (TechCrunch)\n\nSimple tweaks unlock powerful in-context image generation abilities\n\nRecent research demonstrates that text-to-image diffusion transformers (DiTs) can perform in-context image generation with minimal tuning. The study proposes a simple pipeline called In-Context LoRA (IC-LoRA) that concatenates images, performs joint captioning, and applies task-specific fine-tuning on small datasets. This approach generates high-fidelity image sets across various tasks like film storyboards, portrait photography, and visual effects, while maintaining consistency in style and identity. The researchers also released models based on the FLUX text-to-image model and displayed some of the results. (GitHub)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng shared his thoughts on optimizing large language models (LLMs) for agentic workflows, highlighting how advancements such as function calling and native computer use have transformed the way LLMs support complex, iterative applications.\n\n“Following ChatGPT’s breakaway success at answering questions, a lot of LLM development focused on providing a good consumer experience. So LLMs were tuned to answer questions or follow human-provided instructions… But agentic workloads call on different behaviors. Rather than directly generating responses for consumers, AI software may use a model in part of an iterative workflow to reflect on its own output, use tools, write plans, and collaborate in a multi-agent setting. Major model makers are increasingly optimizing models to be used in AI agents as well.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:OpenHands launches Free Agents, an open toolkit for advanced code generation and automation;Perplexity introduced Election Hub, an AI-powered experience providing voters with verified, real-time news and insights on U.S. politics;Meta and Anthropic explore opportunities for AI in U.S. defense and national security, pursuing major military contracts; andHunyuan-Large surpasses other open competitorswith impressive benchmark scores, showcasing the potential of Mixture of Experts models.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Theo nghiên cứu về luật tỷ lệ, việc lượng tử hóa sau huấn luyện ảnh hưởng đến mô hình ngôn ngữ như thế nào?",
        "options": {
          "A": "Cải thiện hiệu suất mô hình khi được huấn luyện trên nhiều dữ liệu hơn.",
          "B": "Làm giảm hiệu suất mô hình, đặc biệt khi mô hình được huấn luyện trên nhiều dữ liệu hơn.",
          "C": "Không ảnh hưởng đến hiệu suất mô hình.",
          "D": "Chỉ ảnh hưởng đến hiệu suất mô hình khi sử dụng độ chính xác rất thấp (dưới 4 bits)."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của dự thảo 'Quy tắc ứng xử' của EU đối với AI là gì?",
        "options": {
          "A": "Thúc đẩy sự phát triển nhanh chóng của các mô hình AI tổng quát mà không cần quan tâm đến rủi ro.",
          "B": "Hướng dẫn phát triển các mô hình AI đáng tin cậy và an toàn, bao gồm các quy tắc về minh bạch và đánh giá rủi ro.",
          "C": "Tập trung vào việc bảo vệ bản quyền cho các nhà phát triển AI.",
          "D": "Cấm hoàn toàn việc sử dụng AI trong các lĩnh vực có rủi ro cao."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống FireSat của Google Research và U.S. Forest Service có khả năng gì?",
        "options": {
          "A": "Dự đoán thời tiết chính xác hơn.",
          "B": "Phát hiện và theo dõi cháy rừng với hình ảnh độ phân giải cao được cập nhật thường xuyên.",
          "C": "Cung cấp bản đồ địa hình chi tiết cho các khu vực rừng.",
          "D": "Phát triển các loại cây trồng chống cháy."
        },
        "answer": "B"
      },
      {
        "question": "Tại hội nghị Baidu World 2024, Baidu đã giới thiệu công nghệ iRAG với mục đích gì?",
        "options": {
          "A": "Tăng tốc độ xử lý dữ liệu cho mô hình ERNIE.",
          "B": "Giảm thiểu ảo giác trong quá trình tạo ảnh.",
          "C": "Tạo ra các ứng dụng AI phức tạp mà không cần viết code.",
          "D": "Cải thiện khả năng nhận diện giọng nói của trợ lý ảo Xiaodu."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng mới 'Work with Apps' của ứng dụng ChatGPT desktop cho MacOS cho phép làm gì?",
        "options": {
          "A": "Tự động viết code trực tiếp vào các công cụ phát triển như VS Code và Xcode.",
          "B": "Đọc code từ các công cụ phát triển phổ biến và gửi đến ChatGPT để cung cấp ngữ cảnh cho các yêu cầu của người dùng.",
          "C": "Chạy các ứng dụng MacOS trực tiếp từ ChatGPT.",
          "D": "Chia sẻ code với người dùng khác thông qua ChatGPT."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp In-Context LoRA (IC-LoRA) được sử dụng để làm gì?",
        "options": {
          "A": "Huấn luyện các mô hình ngôn ngữ lớn hiệu quả hơn.",
          "B": "Tạo ra hình ảnh nhất quán và chất lượng cao trong các tác vụ khác nhau bằng cách tinh chỉnh mô hình text-to-image.",
          "C": "Cải thiện khả năng hiểu ngôn ngữ tự nhiên của các mô hình AI.",
          "D": "Tự động tạo chú thích cho hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, sự khác biệt chính giữa việc tối ưu hóa LLM cho trải nghiệm người dùng và cho quy trình làm việc của AI agent là gì?",
        "options": {
          "A": "LLM cho trải nghiệm người dùng tập trung vào việc trả lời câu hỏi, trong khi LLM cho AI agent tập trung vào các quy trình lặp đi lặp lại, sử dụng công cụ và lập kế hoạch.",
          "B": "LLM cho trải nghiệm người dùng cần nhiều dữ liệu huấn luyện hơn.",
          "C": "LLM cho AI agent cần phần cứng mạnh mẽ hơn.",
          "D": "Không có sự khác biệt đáng kể giữa hai loại LLM này."
        },
        "answer": "A"
      },
      {
        "question": "OpenHands đã ra mắt công cụ Free Agents để làm gì?",
        "options": {
          "A": "Cung cấp một nền tảng để chia sẻ dữ liệu huấn luyện AI.",
          "B": "Cung cấp một bộ công cụ mở cho việc tạo mã và tự động hóa nâng cao.",
          "C": "Phát triển các mô hình ngôn ngữ lớn mã nguồn mở.",
          "D": "Tạo ra các ứng dụng AI cho lĩnh vực y tế."
        },
        "answer": "B"
      },
      {
        "question": "Perplexity giới thiệu Election Hub với mục đích gì?",
        "options": {
          "A": "Cung cấp một nền tảng để tổ chức các cuộc bầu cử trực tuyến.",
          "B": "Cung cấp cho cử tri tin tức và thông tin chi tiết đã được xác minh, theo thời gian thực về chính trị Hoa Kỳ.",
          "C": "Dự đoán kết quả bầu cử chính xác hơn.",
          "D": "Tự động đăng ký cử tri."
        },
        "answer": "B"
      },
      {
        "question": "Hunyuan-Large đã đạt được thành tựu gì?",
        "options": {
          "A": "Phát triển một phương pháp mới để nén dữ liệu AI.",
          "B": "Vượt qua các đối thủ cạnh tranh khác về điểm chuẩn, thể hiện tiềm năng của các mô hình Mixture of Experts.",
          "C": "Tạo ra một giao diện người dùng trực quan hơn cho các ứng dụng AI.",
          "D": "Giảm chi phí huấn luyện các mô hình AI lớn."
        },
        "answer": "B"
      }
    ]
  },
  "gemini-2-5-pro-june-update-now-available-in-preview": {
    "title": "Gemini 2.5 Pro June update now available in preview",
    "collection": "data-points",
    "content": "In today’s edition, you’ll learn more about:\n\nGoogle previews upgraded Gemini 2.5 Pro, spotlighting coding gains\n\nGoogle introduced an enhanced preview of Gemini 2.5 Pro, which achieved a 24-point Elo score improvement on LMArena (reaching 1470) and a 35-point jump on WebDevArena (1443), while maintaining top positions on both leaderboards. The model tops coding benchmarks like Aider Polyglot, and demonstrates strong performance on GPQA and Humanity’s Last Exam, which test advanced math, science, and reasoning capabilities. Google also added “thinking budgets,” giving developers control over cost and latency trade-offs. The upgraded 2.5 Pro is available through the Gemini API at $1.25/$10 per million input/output tokens, and is rolling out in the Gemini app. (Google)\n\nAnthropic cuts Windsurf’s access amid OpenAI acquisition rumors\n\nAnthropic reduced AI coding startup Windsurf’s direct access to Claude 3.5 Sonnet and Claude 3.7 Sonnet models. The vibe coding company quickly found alternative third-party compute providers for the 3.x models, but still lacks access to Anthropic’s new Claude 4 models. Windsurf CEO Varun Mohan said the company wanted to pay for full capacity but was denied; Anthropic stated it was “prioritizing capacity for sustainable partnerships.” Anthropic co-founder Jared Kaplan later confirmed the decision was influenced by reports of OpenAI’s planned acquisition of Windsurf, stating it would be “odd for us to sell Claude to OpenAI,” Anthropic’s largest competitor. (TechCrunch)\n\nMistral launches enterprise coding assistant using open models\n\nMistral released Mistral Code, a coding assistant designed for enterprise software teams with heightened security needs. The platform combines four specialized models (Codestral for code completion, Codestral Embed for search, Devstral for complex coding tasks, and Mistral Medium for chat) into a single offering that can deploy in the cloud, on reserved capacity, or using air-gapped on-premises hardware. Mistral Code allows enterprises to fine-tune models on private repositories and keeps all code within the customer’s security boundary. The service entered private beta this week for JetBrains IDEs and VSCode, with general availability planned soon. (Mistral)\n\nChatGPT launches Connectors to integrate third-party apps and data sources\n\nOpenAI introduced Connectors for ChatGPT, a beta feature that enables users to connect third-party applications like Google Drive, GitHub, and SharePoint directly into their conversations. The feature offers three types of connectors: chat search for quick file lookups, deep research for complex analysis across multiple sources, and synced connectors that pre-index content for faster responses. This integration allows AI developers to build more personalized workflows by accessing their own data sources without leaving ChatGPT, making it easier for individuals and teams to interact with their personal codebases and organizational knowledge. The feature is currently in beta, with Team, Enterprise, and Edu users having access to the widest range of services. (OpenAI)\n\nNvidia releases Llama Nemotron Nano VL for OCR and advanced document processing\n\nNvidia launched Llama Nemotron Nano VL, an open-weights vision-language model designed to extract information from documents like PDFs, charts, tables, and diagrams, while running on a single GPU. The model excels at document understanding tasks including question answering, table extraction, and visual element interpretation, achieving top performance on the OCRBench v2 benchmark for optical character recognition and document analysis. The model is available through Nvidia’s NIM API preview for download from Hugging Face. (Nvidia)\n\nReddit sues Anthropic over alleged unauthorized AI training\n\nReddit filed a lawsuit against Anthropic on Wednesday, accusing the AI company of training its models on Reddit users’ personal data without consent or compensation. Reddit alleges that Anthropic’s ClaudeBot scraped content in violation of Reddit’s user agreement, enabling the company to profit from its AI models. Anthropic’s competitors OpenAI and Google have both paid Reddit to license its users’ content. Reddit seeks a court injunction to stop the scraping, along with compensatory and punitive damages. (Ars Technica)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng shared how non-engineers at AI Fund are learning to code with AI — starting with the ‘AI Python for Beginners’ course — and how this is empowering the entire team to build useful applications, boost creativity, and increase productivity.\n\n“It is very empowering when individuals don’t have to try to get scarce engineering resources allocated to their ideas in order to try them out. There are a lot fewer gatekeepers in the way: If someone has an idea, they can build a prototype and try it out.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Gemini 2.5 Pro đã đạt được những cải thiện đáng kể về điểm Elo trên những nền tảng đánh giá nào?",
        "options": {
          "A": "GPQA và Humanity's Last Exam",
          "B": "LMArena và WebDevArena",
          "C": "Aider Polyglot và OCRBench v2",
          "D": "JetBrains IDEs và VSCode"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lý do chính Anthropic giảm quyền truy cập của Windsurf vào các mô hình Claude là gì?",
        "options": {
          "A": "Windsurf không thanh toán đầy đủ cho dung lượng sử dụng.",
          "B": "Anthropic ưu tiên dung lượng cho các đối tác bền vững.",
          "C": "Windsurf vi phạm các điều khoản sử dụng của Anthropic.",
          "D": "Có tin đồn OpenAI có kế hoạch mua lại Windsurf."
        },
        "answer": "D"
      },
      {
        "question": "Mistral Code được thiết kế đặc biệt cho đối tượng người dùng nào?",
        "options": {
          "A": "Các nhà nghiên cứu AI độc lập.",
          "B": "Các đội ngũ phát triển phần mềm doanh nghiệp có nhu cầu bảo mật cao.",
          "C": "Người dùng cá nhân muốn tự động hóa các tác vụ hàng ngày.",
          "D": "Các tổ chức giáo dục muốn tích hợp AI vào chương trình giảng dạy."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng Connectors của ChatGPT cho phép người dùng làm gì?",
        "options": {
          "A": "Tạo ra các mô hình AI tùy chỉnh từ dữ liệu cá nhân.",
          "B": "Kết nối trực tiếp với các ứng dụng và nguồn dữ liệu của bên thứ ba.",
          "C": "Chia sẻ các cuộc trò chuyện ChatGPT với người dùng khác.",
          "D": "Truy cập vào các công cụ phân tích dữ liệu nâng cao."
        },
        "answer": "B"
      },
      {
        "question": "Llama Nemotron Nano VL của Nvidia được thiết kế để xử lý loại dữ liệu nào?",
        "options": {
          "A": "Dữ liệu âm thanh và video.",
          "B": "Dữ liệu văn bản thuần túy.",
          "C": "Dữ liệu hình ảnh và video độ phân giải cao.",
          "D": "Dữ liệu hình ảnh và ngôn ngữ, đặc biệt là tài liệu."
        },
        "answer": "D"
      },
      {
        "question": "Reddit kiện Anthropic vì lý do gì?",
        "options": {
          "A": "Anthropic sử dụng trái phép dữ liệu người dùng Reddit để đào tạo mô hình AI.",
          "B": "Anthropic cạnh tranh không lành mạnh với Reddit trong lĩnh vực quảng cáo.",
          "C": "Anthropic vi phạm bản quyền nội dung trên Reddit.",
          "D": "Anthropic gây ra sự cố bảo mật ảnh hưởng đến người dùng Reddit."
        },
        "answer": "A"
      },
      {
        "question": "Theo Andrew Ng, việc người không phải kỹ sư học lập trình với AI mang lại lợi ích gì?",
        "options": {
          "A": "Giảm chi phí thuê kỹ sư.",
          "B": "Tăng cường khả năng bảo mật dữ liệu.",
          "C": "Trao quyền cho họ thử nghiệm ý tưởng, tăng tính sáng tạo và năng suất.",
          "D": "Giúp họ hiểu rõ hơn về các thuật toán AI phức tạp."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình nào trong Mistral Code được thiết kế đặc biệt cho việc hoàn thành code?",
        "options": {
          "A": "Devstral",
          "B": "Mistral Medium",
          "C": "Codestral",
          "D": "Codestral Embed"
        },
        "answer": "C"
      },
      {
        "question": "Người dùng nào có quyền truy cập vào phạm vi dịch vụ rộng nhất của Connectors trong ChatGPT?",
        "options": {
          "A": "Người dùng miễn phí.",
          "B": "Người dùng Plus.",
          "C": "Người dùng Team, Enterprise và Edu.",
          "D": "Tất cả người dùng ChatGPT."
        },
        "answer": "C"
      },
      {
        "question": "Llama Nemotron Nano VL đạt hiệu suất hàng đầu trên benchmark nào cho nhận dạng ký tự quang học và phân tích tài liệu?",
        "options": {
          "A": "LMArena",
          "B": "WebDevArena",
          "C": "OCRBench v2",
          "D": "GPQA"
        },
        "answer": "C"
      }
    ]
  },
  "gemini-2-5-pro-takes-the-top-spot-on-key-benchmarks": {
    "title": "Gemini 2.5 Pro takes the top spot on key benchmarks",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nGoogle’s latest AI model emphasizes reasoning over raw computation\n\nGoogle launched Gemini 2.5 Pro, a new AI model that claims the top spot on the LMArena leaderboard. The model achieved state-of-the-art scores in MMLU-Pro and GPQA Diamond of 86 percent and 83 percent, plus 17.7 percent on Humanity’s Last Exam and 88 percent on AIME 2024. The model features a 1 million token context window, native multimodality, and what Google calls “thinking capabilities” that help it analyze information and draw logical conclusions before responding. Gemini 2.5 Pro is Google’s largest and most capable reasoning model, now available as a free experimental model in Google AI Studio and in the Gemini App for Gemini Advanced users. (Google)\n\nOpenAI unveils new image generation capabilities in GPT-4o\n\nOpenAI integrated advanced image generation directly into GPT-4o, enabling precise text rendering, detailed multi-object scenes, and the ability to learn from and refine images using the chatbot. The model can create practical visuals like diagrams, logos, and infographics while maintaining photorealistic quality and following complex instructions for images with up to 20 distinct objects. The new capabilities have proven so popular that within a few days of launch, OpenAI had to withdraw image generation from the free tier of ChatGPT. This native integration of image and language capabilities makes AI image generation more useful for real-world applications, though the system still has limitations with tasks like dense text rendering and precise image editing. (OpenAI)\n\nDeepSeek’s latest model achieves double-digit gains across key benchmarks\n\nDeepSeek released DeepSeek-V3-0324, a new version of its large language model that achieved significant improvements across multiple benchmarks, including a 19.8-point gain on the AIME mathematics test and better scores in reasoning and coding tasks. The model shows enhanced capabilities in Chinese language processing, web development, and function calling accuracy, making it more competitive, especially among models with open weights. (DeepSeek V3 now has an MIT license rather than a custom one.) These improvements demonstrate how rapidly AI models continue to advance in both specialized technical tasks and general language abilities. (Hugging Face)\n\nAI startup Reve launches new image generation model\n\nReve unveiled Reve Image 1.0, a new image model designed to improve prompt understanding and visual output quality. The company claims its approach moves beyond simple pattern matching to create a “semantic intermediate representation” that both humans and machines can understand and manipulate. This launch signals growing competition in the AI image generation space, where companies increasingly focus on precise creative control and natural interaction rather than just technical capabilities. (Reve)\n\nQwen releases versatile multimodal AI model with streaming capabilities\n\nQwen launched Qwen2.5-Omni, a new AI model that processes text, images, audio, and video while generating real-time text and speech responses through its novel Thinker-Talker architecture. The 7 billion parameter model outperforms similarly sized competitors across multiple benchmarks, including speech recognition, translation, and video understanding tasks. This release is a step toward comprehensive AI systems that can seamlessly handle virtually any type of input and output, enabling more natural human-AI interactions. (GitHub)\n\nSoftware developers split on AI’s impact in industry survey\n\nA Wired survey of 730 software developers found that while most use AI coding tools, they disagree sharply about AI’s long-term impact on programming jobs. The majority of respondents use AI at least once a week and largely view AI as a productivity tool for automating repetitive tasks; only a small group predict that AI will fully replace human programmers. Mid-level engineers were more likely to be pessimistic about AI, while junior engineers were more likely to be optimistic. The survey suggests AI tools serve most professional developers as assistants for basic coding and analysis while leaving complex architecture and debugging decisions to humans. (Wired)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng shared his thoughts on when fine-tuning small language models is truly necessary — and when simpler approaches like prompting or agentic workflows may be more effective and easier to maintain.\n\n“While fine-tuning is an important and valuable technique, many teams that are currently using it probably could get good results with simpler approaches, such as prompting, few-shot prompting, or simple agentic workflows.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Google released Gemma 3, a family of compact vision-language models with open weights, enabling multimodal capabilities on a single GPU;researchers introduced shortcut modelsthat generate high-quality diffusion images in fewer steps, improving speed without sacrificing performance; a study showed thatGPT-4 can significantly enhance remote tutors’ effectivenessby providing real-time pedagogical support; and a new technique using pretrained embeddings like DINOv2 helpeddiffusion transformers learn faster, reducing training time while improving image quality.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Gemini 2.5 Pro của Google nổi bật với khả năng nào so với các mô hình AI trước đây?",
        "options": {
          "A": "Khả năng tính toán nhanh hơn.",
          "B": "Khả năng suy luận và phân tích thông tin trước khi phản hồi.",
          "C": "Khả năng tạo ra hình ảnh chân thực hơn.",
          "D": "Khả năng xử lý ngôn ngữ tự nhiên tốt hơn."
        },
        "answer": "B"
      },
      {
        "question": "OpenAI đã tích hợp khả năng tạo ảnh tiên tiến vào mô hình nào?",
        "options": {
          "A": "GPT-3",
          "B": "GPT-4o",
          "C": "DALL-E 3",
          "D": "ChatGPT"
        },
        "answer": "B"
      },
      {
        "question": "Điểm nổi bật của DeepSeek-V3-0324 so với các phiên bản trước là gì?",
        "options": {
          "A": "Khả năng tạo video chất lượng cao.",
          "B": "Cải thiện đáng kể trong các bài kiểm tra toán học và khả năng lập trình.",
          "C": "Khả năng xử lý âm thanh tốt hơn.",
          "D": "Khả năng dịch thuật đa ngôn ngữ chính xác hơn."
        },
        "answer": "B"
      },
      {
        "question": "Reve Image 1.0 tập trung vào điều gì trong việc tạo ra hình ảnh?",
        "options": {
          "A": "Tăng tốc độ tạo ảnh.",
          "B": "Cải thiện độ phân giải của hình ảnh.",
          "C": "Tạo ra một 'biểu diễn trung gian ngữ nghĩa' mà cả người và máy đều có thể hiểu.",
          "D": "Giảm chi phí tạo ảnh."
        },
        "answer": "C"
      },
      {
        "question": "Qwen2.5-Omni có khả năng xử lý những loại dữ liệu nào?",
        "options": {
          "A": "Chỉ văn bản và hình ảnh.",
          "B": "Chỉ âm thanh và video.",
          "C": "Văn bản, hình ảnh, âm thanh và video.",
          "D": "Chỉ văn bản và mã nguồn."
        },
        "answer": "C"
      },
      {
        "question": "Theo khảo sát của Wired, phần lớn các nhà phát triển phần mềm sử dụng công cụ AI để làm gì?",
        "options": {
          "A": "Thay thế hoàn toàn công việc lập trình.",
          "B": "Tự động hóa các tác vụ lặp đi lặp lại để tăng năng suất.",
          "C": "Thiết kế kiến trúc phần mềm phức tạp.",
          "D": "Gỡ lỗi các đoạn mã khó."
        },
        "answer": "B"
      },
      {
        "question": "Andrew Ng cho rằng khi nào thì việc tinh chỉnh các mô hình ngôn ngữ nhỏ (fine-tuning) là thực sự cần thiết?",
        "options": {
          "A": "Luôn luôn cần thiết để đạt được kết quả tốt nhất.",
          "B": "Khi các phương pháp đơn giản hơn như prompting không hiệu quả.",
          "C": "Khi cần tạo ra các mô hình chuyên biệt cho một lĩnh vực cụ thể.",
          "D": "Khi cần giảm kích thước của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Gemma 3 của Google có đặc điểm gì nổi bật?",
        "options": {
          "A": "Là mô hình ngôn ngữ lớn nhất của Google.",
          "B": "Là mô hình thị giác-ngôn ngữ nhỏ gọn với trọng số mở, cho phép khả năng đa phương tiện trên một GPU duy nhất.",
          "C": "Chỉ có khả năng xử lý văn bản.",
          "D": "Chuyên về tạo video 3D."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu về 'shortcut models' tập trung vào việc gì?",
        "options": {
          "A": "Tăng độ chính xác của mô hình.",
          "B": "Tạo ra hình ảnh khuếch tán chất lượng cao trong ít bước hơn, cải thiện tốc độ mà không làm giảm hiệu suất.",
          "C": "Giảm kích thước của mô hình.",
          "D": "Cải thiện khả năng hiểu ngôn ngữ tự nhiên."
        },
        "answer": "B"
      },
      {
        "question": "GPT-4 có thể hỗ trợ gia sư từ xa như thế nào?",
        "options": {
          "A": "Thay thế hoàn toàn vai trò của gia sư.",
          "B": "Cung cấp hỗ trợ sư phạm theo thời gian thực để nâng cao hiệu quả của gia sư.",
          "C": "Tự động chấm điểm bài tập.",
          "D": "Tạo ra các bài giảng trực tuyến."
        },
        "answer": "B"
      }
    ]
  },
  "google-translate-uses-an-ai-assist-to-add-over-100-new-languages-plus-metas-llm-compiler-brings-language-models-to-assembly-code": {
    "title": "Google Translate uses an AI assist to add over 100 new languages",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news in brief. Today's edition includes:\n\nGoogle Translate adds 110 new languages using PaLM 2Google Translate’s largest expansion to date represents more than 614 million speakers, including major world languages, indigenous languages, and languages with active revitalization efforts. The PaLM 2 model helped Google Translate more efficiently learn languages that are closely related to each other, including languages similar to Hindi, like Awadhi and Marwadi, as well as French creoles such as Seychellois Creole and Mauritian Creole. The expansion covers languages from various regions, with a quarter of the new languages coming from Africa, and includes considerations for language varieties and distinct spelling conventions. (Google)\n\nMeta releases LLM Compiler models for code optimization and compiler tasksThe models, built on Code Llama and available in 7B and 13B parameter versions, can emulate compiler behavior, predict optimal passes for code size reduction, and disassemble code. Fine-tuned versions of LLM Compiler  achieve 77% of the optimizing potential of an autotuning search, and 45% disassembly round trip (14% exact match). LLM Compiler fills a gap in code completion and optimization models, as few are trained on assembly code or compiler intermediate representations. Released under a permissive license for research and commercial use, LLM Compiler aims to provide a foundation for further development in AI-aided compiler optimization. (Meta)\n\nMicrosoft releases Florence-2 family of vision modelsFlorence-2 is available in 770 million and 230 million parameter sizes, including fine-tuned versions of each model, all under an MIT license. The base model was trained on FLD-5B, a dataset of 5.4 billion annotations of 126 million images, created through an iterative process of automated annotation and model refinement. Florence-2’s sequence-to-sequence architecture demonstrates strong zero-shot and fine-tuned capabilities across various tasks, including captioning, object detection, and visual grounding. (MicrosoftandHugging Face)\n\nQualcomm launches AI Hub for Snapdragon X Elite developersQualcomm’s hub offers pre-trained models for tasks like image classification and generative AI, along with tools and documentation to simplify application development for Snapdragon X Elite devices. Developers can filter searches using tags like ‘backbone,’ ‘foundation,’ ‘quantized,’ and ‘real-time,’ making it easier to find models for specific applications. These resources make it easier to create AI-enabled applications that leverage Qualcomm’s 45 TOPS Hexagon NPU for Windows PCs. (Qualcomm)\n\nGoogle develops AI system to generate audio for silent videosGoogle researchers created a video-to-audio (V2A) technology that produces soundtracks for silent videos using video pixels and text prompts, allowing (among other uses) video generators to add synchronized sound. The system can generate multiple audio options for any video input, allowing users to experiment with different soundtracks. Google’s V2A uses a diffusion model to iteratively refine audio from random noise, guided by visual input and natural language prompts. While the technology shows promise, Google’s team is still working to address limitations such as improving lip synchronization and audio quality for videos with artifacts. (Google)\n\nElevenLabs opens up developer API for its text to sound effects modelElevenLabs’ text to sound effects tool enables developers to generate high-quality audio from short descriptions, useful for game development and music production. The API offers a Python SDK for easy integration, with options to control sound duration and prompt influence. The API is priced based on character count, with costs calculated per 100 characters for automatic duration or 25 characters per second for set durations. (ElevenLabs)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng discussed the contrasting views of AI as a tool versus a separate entity:\n\n“If I’m allowed to build a house, I want to be allowed to use a hammer, saw, drill, or any other tool that might get the job done efficiently. If I’m allowed to read a webpage, I’d like to be allowed to read it with any web browser, and perhaps even have the browser modify the page’s formatting for accessibility. More generally, if we agree that humans are allowed to do certain things — such as read and synthesize information on the web — then my inclination is to let humans direct AI to automate this task.”\n\nRead Andrew's full letterhere.\n\nOther top AI news and research stories we covered in depth included theU.S. antitrust investigationon three AI giants, the newmultilingual competitor to GPT-4, a growing market forlifelike avatars of deceased loved ones, and newbenchmarks for agentic behaviors.",
    "qa": [
      {
        "question": "Google Translate đã bổ sung bao nhiêu ngôn ngữ mới trong bản cập nhật lớn nhất từ trước đến nay?",
        "options": {
          "A": "614",
          "B": "110",
          "C": "126",
          "D": "45"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào của Meta được phát hành để tối ưu hóa mã và thực hiện các tác vụ liên quan đến trình biên dịch?",
        "options": {
          "A": "Code Llama",
          "B": "PaLM 2",
          "C": "Florence-2",
          "D": "LLM Compiler"
        },
        "answer": "D"
      },
      {
        "question": "Florence-2 của Microsoft được huấn luyện trên bộ dữ liệu nào?",
        "options": {
          "A": "FLD-1B",
          "B": "FLD-5B",
          "C": "FLD-126M",
          "D": "FLD-770M"
        },
        "answer": "B"
      },
      {
        "question": "Qualcomm AI Hub cung cấp những loại tài nguyên nào cho các nhà phát triển Snapdragon X Elite?",
        "options": {
          "A": "Chỉ các công cụ phát triển ứng dụng",
          "B": "Chỉ tài liệu hướng dẫn",
          "C": "Các mô hình được huấn luyện trước, công cụ và tài liệu",
          "D": "Chỉ các mô hình được lượng tử hóa"
        },
        "answer": "C"
      },
      {
        "question": "Công nghệ V2A của Google tạo ra âm thanh cho video im lặng bằng cách sử dụng yếu tố nào?",
        "options": {
          "A": "Chỉ văn bản",
          "B": "Chỉ hình ảnh",
          "C": "Pixel video và lời nhắc văn bản",
          "D": "Dữ liệu cảm biến âm thanh"
        },
        "answer": "C"
      },
      {
        "question": "ElevenLabs cung cấp API cho mô hình nào?",
        "options": {
          "A": "Text to speech",
          "B": "Speech to text",
          "C": "Text to sound effects",
          "D": "Sound effects to text"
        },
        "answer": "C"
      },
      {
        "question": "Theo Andrew Ng, điều gì nên được cho phép khi con người được phép thực hiện một số hành động nhất định trên web?",
        "options": {
          "A": "Cấm sử dụng AI để tự động hóa các tác vụ",
          "B": "Cho phép con người chỉ đạo AI để tự động hóa các tác vụ đó",
          "C": "Chỉ cho phép sử dụng các công cụ được phê duyệt",
          "D": "Giới hạn quyền truy cập vào thông tin trên web"
        },
        "answer": "B"
      },
      {
        "question": "LLM Compiler của Meta có bao nhiêu phiên bản tham số?",
        "options": {
          "A": "Một phiên bản (7B)",
          "B": "Một phiên bản (13B)",
          "C": "Hai phiên bản (7B và 13B)",
          "D": "Ba phiên bản (7B, 13B và 770M)"
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu chính của việc phát hành LLM Compiler theo giấy phép cho phép là gì?",
        "options": {
          "A": "Kiếm lợi nhuận từ việc bán giấy phép",
          "B": "Cung cấp nền tảng cho sự phát triển hơn nữa trong tối ưu hóa trình biên dịch bằng AI",
          "C": "Hạn chế sử dụng LLM Compiler cho mục đích nghiên cứu",
          "D": "Bảo vệ quyền sở hữu trí tuệ của Meta"
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ V2A của Google sử dụng mô hình nào để tinh chỉnh âm thanh từ nhiễu ngẫu nhiên?",
        "options": {
          "A": "Mô hình ngôn ngữ lớn (LLM)",
          "B": "Mô hình khuếch tán (diffusion model)",
          "C": "Mạng nơ-ron tích chập (CNN)",
          "D": "Mạng nơ-ron hồi quy (RNN)"
        },
        "answer": "B"
      }
    ]
  },
  "google-adds-thinking-mode-to-flash-2-0": {
    "title": "Google adds Thinking Mode to Flash 2.0",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nOpenAI’s top o1 model priced the same as o1-preview\n\nOpenAI rolled out o1, a new reasoning model designed for complex multi-step tasks, to developers on usage tier 5. In the API, o1 costs $15/$60 per million input/output tokens, with a half-priced discount for cached input tokens. OpenAI reports that o1-2024-12-17, the latest version, sets new state-of-the-art results on several benchmarks, improving cost-efficiency and performance over its predecessor, o1-preview. (OpenAI)\n\nGoogle’s AI gets introspective with new Thinking Mode\n\nGoogle introduced an even more experimental version of Gemini 2.0 Flash called Thinking Mode, designed to generate the model’s “thinking process” as part of its response. The new feature is available through Google AI Studio and the Gemini API, with developers able to access the model’s thoughts via specific API calls or through a dedicated panel in the Studio interface. While Thinking Mode offers enhanced reasoning capabilities, it comes with limitations such as a 32k token input limit and text-only output. (Google)\n\nNew audio benchmark shows performance gap in speech reasoning\n\nArtificial Analysis released Big Bench Audio, a dataset and benchmark test for evaluating audio language models’ reasoning capabilities. The dataset adapts questions from Big Bench Hard into the audio domain, covering topics like formal fallacies and object counting. Initial results show a significant “speech reasoning gap,” with GPT-4o’s accuracy dropping from 92 percent in text-only format to 66 percent in Speech to Speech mode. Traditional speech-to-text pipeline approaches currently outperform native audio models for reasoning tasks, suggesting that developers may need to consider trade-offs between audio capabilities and reasoning accuracy in speech-enabled applications. (Hugging Face)\n\nGenerated news summaries spark accuracy concerns\n\nReporters Without Borders called on Apple to remove its new AI-powered notification summary feature after it created a false headline about murder suspect Luigi Mangione. The feature, part of Apple Intelligence, misrepresented a BBC News article by claiming the suspect had shot himself, which was untrue. This incident, plus a similar misrepresentation of a New York Times article, show there’s still a delicate balance between time-saving innovations and the need for accuracy in news dissemination. (BBC)\n\nGoogle’s updated models create more vibrant videos and images\n\nGoogle introduced Veo 2 and an updated Imagen 3, two AI models for video and image generation that improve on their predecessors. Veo 2 creates high-quality videos with improved understanding of physics and human movement, while Imagen 3 generates images with better composition and in diverse art styles. These models are now available in Google’s VideoFX and ImageFX interfaces, with plans to expand to YouTube Shorts and other products next year. Google also introduced, Whisk, an image-to-image generator that uses Imagen 3 and Google 2.0 Flash to read and remix original or generated images. (Google)\n\nNvidia unveils tiny computer with AI accelerator chips\n\nNvidia updated and cut the price of the Jetson Orin Nano Super Developer Kit, a palm-sized generative AI computer priced at $249. The device provides up to 1.7x increase in generative AI inference performance and consists of a system-on-module with an Ampere architecture GPU and a 6-core Arm CPU. This compact computer delivers up to 157 TOPS (depending on the configuration) and runs Nvidia software including Isaac for robotics and Metropolis for vision AI. This update enables a wide range of users—from commercial AI developers to students—to more easily build applications such as LLM chatbots, visual AI agents, and AI-based robots. (Nvidia)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng celebrated the achievements of his former students and postdocs, who won both of this year’s NeurIPS Test of Time Paper Awards, and shared reflections on the importance of following one’s convictions and scaling innovations in AI, while looking ahead to explore new ideas for the future.\n\n“But taking a brief look at the past can help us reflect on lessons for the future. One takeaway from looking at what worked 10 to 15 years ago is that many of the teams I led bet heavily on scaling to drive AI progress — a bet that laid a foundation to build larger and larger AI systems.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Microsoft’s Phi-4, blending synthetic and organic data, surpassed models five times its size in math and reasoning benchmarks;Tencent released HunyuanVideo, an open-source model rivaling commercial video generators;Google launched Gemini 2.0 Flash, a faster and more capable multimodal model; and aStanford studyrevealed that AI matches human experts in writing research proposals, but struggles to evaluate proposals: a mixed result for hopes of AI-assisted innovation.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mô hình o1 mới của OpenAI có giá như thế nào so với o1-preview?",
        "options": {
          "A": "Rẻ hơn một nửa",
          "B": "Tương đương",
          "C": "Đắt gấp đôi",
          "D": "Đắt hơn một chút"
        },
        "answer": "B"
      },
      {
        "question": "Tính năng 'Thinking Mode' của Gemini 2.0 Flash có điểm gì đặc biệt?",
        "options": {
          "A": "Tạo ra video chất lượng cao",
          "B": "Hiển thị 'quá trình suy nghĩ' của mô hình",
          "C": "Không giới hạn số lượng token đầu vào",
          "D": "Tự động dịch văn bản sang nhiều ngôn ngữ"
        },
        "answer": "B"
      },
      {
        "question": "Big Bench Audio được Artificial Analysis phát hành dùng để làm gì?",
        "options": {
          "A": "Đánh giá khả năng tạo nhạc của mô hình AI",
          "B": "Đánh giá khả năng lý luận ngôn ngữ của mô hình AI trong lĩnh vực âm thanh",
          "C": "Chuyển đổi văn bản thành giọng nói tự nhiên",
          "D": "Phân tích chất lượng âm thanh của các bản ghi âm"
        },
        "answer": "B"
      },
      {
        "question": "Sự cố liên quan đến Luigi Mangione mà Reporters Without Borders đề cập liên quan đến vấn đề gì?",
        "options": {
          "A": "Lỗi dịch thuật của AI",
          "B": "Thông tin sai lệch do AI tạo ra",
          "C": "Vi phạm quyền riêng tư của người dùng",
          "D": "Sự thiên vị của AI trong tin tức"
        },
        "answer": "B"
      },
      {
        "question": "Veo 2 của Google cải tiến so với phiên bản trước ở điểm nào?",
        "options": {
          "A": "Tạo ra hình ảnh với độ phân giải cao hơn",
          "B": "Hiểu rõ hơn về vật lý và chuyển động của con người trong video",
          "C": "Tạo ra văn bản với giọng văn tự nhiên hơn",
          "D": "Phát hiện khuôn mặt chính xác hơn"
        },
        "answer": "B"
      },
      {
        "question": "Jetson Orin Nano Super Developer Kit của Nvidia có giá bao nhiêu?",
        "options": {
          "A": "$99",
          "B": "$149",
          "C": "$249",
          "D": "$349"
        },
        "answer": "C"
      },
      {
        "question": "Andrew Ng nhấn mạnh điều gì trong thư của mình liên quan đến sự phát triển của AI?",
        "options": {
          "A": "Tầm quan trọng của việc tuân thủ các quy tắc đạo đức",
          "B": "Tầm quan trọng của việc mở rộng quy mô để thúc đẩy tiến bộ AI",
          "C": "Tầm quan trọng của việc hợp tác quốc tế",
          "D": "Tầm quan trọng của việc bảo vệ dữ liệu cá nhân"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào của Microsoft được đề cập là vượt trội so với các mô hình lớn hơn gấp năm lần trong các bài kiểm tra toán học và lý luận?",
        "options": {
          "A": "GPT-4o",
          "B": "Gemini 2.0 Flash",
          "C": "Phi-4",
          "D": "HunyuanVideo"
        },
        "answer": "C"
      },
      {
        "question": "HunyuanVideo của Tencent là một mô hình AI thuộc lĩnh vực nào?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên",
          "B": "Tạo sinh hình ảnh",
          "C": "Tạo sinh video",
          "D": "Phân tích dữ liệu âm thanh"
        },
        "answer": "C"
      },
      {
        "question": "Nghiên cứu của Stanford cho thấy AI thể hiện như thế nào trong việc viết và đánh giá đề xuất nghiên cứu?",
        "options": {
          "A": "Kém hơn con người ở cả hai nhiệm vụ",
          "B": "Tốt hơn con người ở cả hai nhiệm vụ",
          "C": "Tốt như con người trong việc viết, nhưng kém hơn trong việc đánh giá",
          "D": "Tốt hơn con người trong việc đánh giá, nhưng kém hơn trong việc viết"
        },
        "answer": "C"
      }
    ]
  },
  "googles-latest-language-learning-project": {
    "title": "Google’s latest language-learning project",
    "collection": "data-points",
    "content": "In today’s edition, you’ll learn more about:\n\nGoogle Labs uses Gemini to create Little Language Lessons\n\nGoogle engineers developed three experimental language learning tools powered by the Gemini API. The “Little Language Lessons” collection includes Tiny Lesson, which provides situation-specific vocabulary and phrases; Slang Hang, which generates authentic conversations between native speakers; and Word Cam, which uses image recognition to identify and translate objects in photos. Each experiment uses carefully crafted prompts to generate structured JSON outputs that deliver personalized, contextual language learning experiences. The tools demonstrate how AI can adapt to learners’ specific contexts, making language acquisition more natural and relevant than traditional methods. (Google)\n\nCognition AI’s DeepWiki offers free explanation of GitHub repositories\n\nDeepWiki provides an instant way to understand unfamiliar codebases by automatically generating architecture diagrams, documentation, and source code links for public GitHub repositories. Users can access the tool by simply replacing “github.com” with “deepwiki.com” in any repository URL, with no installation required. The platform, powered by Devin Search, uses AI to create visual architecture maps, project summaries, technology stack breakdowns, and interactive file explorers that make complex codebases more approachable. DeepWiki’s conversational interface allows developers to ask specific questions about the code and receive context-grounded answers through its underlying DeepResearch agent. The service is free for public repositories, with support for private repositories available through authentication. (DeepWikiandDevin)\n\nDeepSeek introduces new open model for mathematical theorem proving\n\nDeepSeek-Prover-V2 is an open-weights large language model specifically designed for formal proofs in Lean 4. The model employs a novel recursive theorem-proving pipeline that uses DeepSeek-V3 to decompose complex mathematical problems into manageable subgoals while simultaneously formalizing these steps. After creating synthetic cold-start data by combining formal proofs with chain-of-thought reasoning, the team applied reinforcement learning to enhance the model’s ability to bridge informal reasoning with formal proof construction. The 671 billion parameter version achieves state-of-the-art performance with an 88.9 percent pass ratio on the MiniF2F-test benchmark and successfully solves 49 problems from PutnamBench. The researchers also introduced ProverBench, a new benchmark of 325 formalized problems from high school competitions and undergraduate-level mathematics. (GitHub)\n\nMeta launches standalone AI assistant app powered by Llama 4\n\nMeta AI, a competitor to ChatGPT and similar apps, remembers user preferences and maintains conversation context across interactions. The app enables voice conversations with natural dialogue capabilities, a discover feed for sharing AI-generated content, and integration with Meta’s existing AI features like image generation. Meta AI now serves as the companion app for Ray-Ban Meta glasses and connects with meta.ai on the web, allowing users to continue conversations across devices. The app is available now on iOS and Android, with voice features initially accessible in the US, Canada, Australia, and New Zealand. (Facebook)\n\nSkyReels-V2 introduces infinite-length film generation\n\nSkyworkAI unveiled SkyReels-V2, a new video generation model that enables extended-length film creation while maintaining visual quality and cinematic control. The model addresses key limitations in existing video generation systems by combining a multi-modal large language model with multi-stage pretraining, reinforcement learning, and a novel diffusion forcing framework. The researchers also developed SkyCaptioner-V1, a specialized video captioning system that accurately labels training data with detailed shot language and cinematic descriptions. Their approach uses motion-specific reinforcement learning to enhance dynamic movement quality and implements a diffusion forcing framework that enables generation of videos of unlimited length. Experiments show the model outperforms other open-source alternatives and enables applications including story generation, image-to-video synthesis, and camera direction. The team has made all code and models publicly available. (arXivandGitHub)\n\nPayment giants Visa, Mastercard, and PayPal race to enable AI shopping agents\n\nVisa, Mastercard, and PayPal announced plans to deploy agentic commerce capabilities that will allow AI agents to complete purchases on behalf of consumers. The companies are integrating payment functionality into AI chatbots through partnerships with firms like Anthropic, Microsoft, and OpenAI, with rollouts expected in the coming quarters. Visa and Mastercard’s approaches rely on tokenization — creating secure digital payment credentials with spending limits that consumers can control — while PayPal offers developers API access tokens to integrate with its platform. Industry experts describe this shift as transformative, potentially shaping how consumers discover products and complete purchases while reducing return rates and improving shopping efficiency. (PYMNTS)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng highlighted an inspiring story of a high school basketball coach who learned to code and went on to teach computer science, emphasizing how AI helped scale K–12 education by empowering both students and teachers.\n\n“Agentic workflows can automate a lot of teachers’ repetitive tasks. For example, when designing a curriculum, it’s time-consuming to align the content to educational standards (such as the Common Core in the United States, or the AP CS standard for many CS classes). Having an AI system carry out tasks like these is already proving helpful for teachers.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:OpenAI launched API access to GPT Image 1, the image generator behind viral ChatGPT uploads; Google updated itsAI-powered music generation tools, targeting professional musicians and creators;CB Insights’ Top 100 AI Startups listidentified emerging players focused on AI agents and infrastructure; and researchers showed how large language models canimprove shopping recommendationsby inferring customer preferences from natural language input.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Công cụ nào trong bộ \"Little Language Lessons\" của Google Labs sử dụng nhận dạng hình ảnh để dịch các đối tượng trong ảnh?",
        "options": {
          "A": "Tiny Lesson",
          "B": "Slang Hang",
          "C": "Word Cam",
          "D": "Gemini Translator"
        },
        "answer": "C"
      },
      {
        "question": "DeepWiki giúp người dùng hiểu code trên GitHub bằng cách nào?",
        "options": {
          "A": "Tự động sửa lỗi code.",
          "B": "Tạo sơ đồ kiến trúc, tài liệu và liên kết mã nguồn.",
          "C": "Chạy thử code trực tiếp trên nền tảng.",
          "D": "Chuyển đổi code sang ngôn ngữ lập trình khác."
        },
        "answer": "B"
      },
      {
        "question": "DeepSeek-Prover-V2 được thiết kế đặc biệt cho mục đích gì?",
        "options": {
          "A": "Dịch thuật ngôn ngữ tự nhiên.",
          "B": "Chứng minh định lý toán học hình thức trong Lean 4.",
          "C": "Phân tích dữ liệu tài chính.",
          "D": "Tạo ra các trò chơi điện tử."
        },
        "answer": "B"
      },
      {
        "question": "Meta AI có điểm gì khác biệt so với các ứng dụng AI tương tự như ChatGPT?",
        "options": {
          "A": "Chỉ hoạt động trên các thiết bị của Meta.",
          "B": "Có khả năng ghi nhớ sở thích của người dùng và duy trì ngữ cảnh hội thoại.",
          "C": "Miễn phí hoàn toàn cho tất cả người dùng.",
          "D": "Chỉ hỗ trợ giao tiếp bằng văn bản."
        },
        "answer": "B"
      },
      {
        "question": "SkyReels-V2 giải quyết hạn chế nào của các hệ thống tạo video hiện tại?",
        "options": {
          "A": "Chỉ tạo được video ngắn.",
          "B": "Chất lượng hình ảnh kém.",
          "C": "Khó kiểm soát các yếu tố điện ảnh.",
          "D": "Tất cả các đáp án trên."
        },
        "answer": "D"
      },
      {
        "question": "Công nghệ nào được Visa và Mastercard sử dụng để đảm bảo an toàn cho các giao dịch mua sắm do AI thực hiện?",
        "options": {
          "A": "Mã hóa đầu cuối.",
          "B": "Token hóa.",
          "C": "Xác thực đa yếu tố.",
          "D": "Blockchain."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, AI có thể giúp giáo viên như thế nào?",
        "options": {
          "A": "Thay thế hoàn toàn vai trò của giáo viên.",
          "B": "Tự động chấm điểm bài tập.",
          "C": "Tự động hóa các công việc lặp đi lặp lại như thiết kế chương trình học.",
          "D": "Tạo ra các bài giảng trực tuyến chất lượng cao."
        },
        "answer": "C"
      },
      {
        "question": "Công cụ nào của OpenAI vừa được cung cấp API?",
        "options": {
          "A": "GPT-4",
          "B": "DALL-E 3",
          "C": "GPT Image 1",
          "D": "Codex"
        },
        "answer": "C"
      },
      {
        "question": "CB Insights' Top 100 AI Startups list tập trung vào những lĩnh vực nào?",
        "options": {
          "A": "Xe tự lái và robot.",
          "B": "AI agents và cơ sở hạ tầng.",
          "C": "Chăm sóc sức khỏe và tài chính.",
          "D": "Marketing và quảng cáo."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu nào được đề cập trong bài viết cho thấy LLMs có thể cải thiện đề xuất mua sắm?",
        "options": {
          "A": "Bằng cách phân tích lịch sử mua hàng.",
          "B": "Bằng cách suy luận sở thích của khách hàng từ ngôn ngữ tự nhiên.",
          "C": "Bằng cách dự đoán xu hướng thị trường.",
          "D": "Bằng cách tạo ra các quảng cáo cá nhân hóa."
        },
        "answer": "B"
      }
    ]
  },
  "gpt-4o-drops-prices-supports-json-schemas": {
    "title": "GPT-4o drops prices, supports JSON schemas",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nGPT-4o gives developers more control over its outputsOpenAI introduced Structured Outputs in their API, allowing model outputs to reliably adhere to developer-supplied JSON schemas. The new feature works with function calling on all models that support it, as well as with a new response_format parameter on the latest GPT-4o models. Supporting Structured Outputs may helo solve challenges developers face in generating structured data from unstructured inputs, achieving nearly perfect reliability in matching output schemas through a combination of model training and constrained decoding techniques. (OpenAI)\n\nFigure unveils robot with enhanced AI capabilitiesFigure introduced its second-generation humanoid robot, Figure 02, featuring significant hardware and software improvements. The robot incorporates speech-to-speech conversation abilities, an onboard vision language model, a 2.25 KWh battery pack, integrated wiring, and advanced hands with 16 degrees of freedom. Figure recently tested the robot at a BMW manufacturing plant and plans to develop humanoid robots for both industrial and domestic applications in the future. (IEEE Spectrum)\n\nDesign flaws push back release of Nvidia’s next-gen chipsNvidia informed customers that its upcoming Blackwell series AI chips will be delayed by at least three months due to design flaws discovered late in the production process. The delay affects chips ordered by major tech companies like Microsoft, Google, and Meta, who collectively placed orders worth tens of billions of dollars for use in developing advanced AI models. This setback could impact AI development timelines for these companies and raises questions about Nvidia’s ability to meet high revenue projections for its new chips in 2025. (The Register)\n\nMistral AI offers fine-tuning, agents, a new SDK, and moreThe company now allows customization of its flagship models like Mistral Large 2 through fine-tuning, few-shot learning, or base prompts on their La Plateforme service. Mistral also introduced an alpha version of Agents for creating custom AI behaviors and workflows, and released version 1.0 of its client SDK for Python and TypeScript. These additions simplify the process of tailoring large language models for specific use cases and integrating them into applications. (Mistral)\n\nNew IDE simplifies development of agent systemsLangChain introduced LangGraph Studio, an integrated development environment (IDE) for building and testing AI agents. The tool allows developers to create, visualize, and debug complex multi-agent systems using a graphical interface, supporting both code and no-code approaches. LangGraph Studio aims to simplify the development of AI agents by providing features like step-by-step execution, state inspection, and easy integration with existing LangChain components. (LangChain)\n\nCharacter.AI unveils Prompt Poet for streamlined prompt creationCharacter.AI developed Prompt Poet, a tool (now released under an MIT license) that simplifies the creation of complex, dynamic prompts for large language models. The system uses a combination of YAML and Jinja2 templating to allow both technical and non-technical users to design prompts efficiently. Prompt Poet offers features like template composition, custom encoding functions, and cache-aware truncation to optimize prompt performance and GPU usage. This approach shifts focus from manual string manipulation to a more intuitive, design-focused method of crafting AI prompts. (Character.AI)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng introduced his new sequence of courses,AI Python for Beginners, aimed at teaching anyone to code with the help of AI:\n\n“These courses teach coding in a way that is aligned with these trends: (i) We teach how to write code to use AI to carry out tasks, and (ii) Unlike some instructors who are still debating how to restrict the use of ChatGPT, we embrace generative AI as a coding companion and show how to use it to accelerate your learning.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: Google getsCharacter.AI co-founders, how employers and prospective employees are embracing automated hiring tools, Ukraine'saquatic drones, andArtPrompt, a technique to test the impact of text rendered as ASCII art on LLM performance.",
    "qa": [
      {
        "question": "Tính năng 'Structured Outputs' mới của OpenAI cho phép điều gì?",
        "options": {
          "A": "Tạo ra các mô hình AI có khả năng tự học hỏi và cải thiện.",
          "B": "Đảm bảo đầu ra của mô hình tuân thủ các lược đồ JSON do nhà phát triển cung cấp.",
          "C": "Tăng tốc độ xử lý dữ liệu đầu vào cho các mô hình GPT.",
          "D": "Cho phép người dùng tương tác trực tiếp với mô hình thông qua giao diện đồ họa."
        },
        "answer": "B"
      },
      {
        "question": "Robot Figure 02 thế hệ thứ hai của Figure có điểm gì nổi bật?",
        "options": {
          "A": "Khả năng tự sửa chữa khi gặp sự cố phần cứng.",
          "B": "Hệ thống định vị GPS chính xác đến từng milimet.",
          "C": "Khả năng hội thoại bằng giọng nói và mô hình ngôn ngữ thị giác tích hợp.",
          "D": "Khả năng bay lượn và di chuyển trên mọi địa hình."
        },
        "answer": "C"
      },
      {
        "question": "Việc trì hoãn ra mắt chip Blackwell của Nvidia ảnh hưởng đến ai?",
        "options": {
          "A": "Chỉ ảnh hưởng đến các công ty khởi nghiệp trong lĩnh vực AI.",
          "B": "Chỉ ảnh hưởng đến các nhà nghiên cứu độc lập về AI.",
          "C": "Ảnh hưởng đến các công ty công nghệ lớn như Microsoft, Google và Meta.",
          "D": "Không ảnh hưởng đến bất kỳ ai vì Nvidia có các sản phẩm thay thế."
        },
        "answer": "C"
      },
      {
        "question": "Mistral AI cung cấp những phương thức tùy chỉnh mô hình nào?",
        "options": {
          "A": "Chỉ cho phép tùy chỉnh thông qua fine-tuning.",
          "B": "Chỉ cho phép tùy chỉnh thông qua few-shot learning.",
          "C": "Chỉ cho phép tùy chỉnh thông qua base prompts.",
          "D": "Cho phép tùy chỉnh thông qua fine-tuning, few-shot learning hoặc base prompts."
        },
        "answer": "D"
      },
      {
        "question": "LangGraph Studio là gì?",
        "options": {
          "A": "Một thư viện mã nguồn mở để xây dựng giao diện người dùng cho các ứng dụng AI.",
          "B": "Một môi trường phát triển tích hợp (IDE) để xây dựng và thử nghiệm các AI agents.",
          "C": "Một nền tảng đám mây để lưu trữ và quản lý dữ liệu huấn luyện cho các mô hình AI.",
          "D": "Một công cụ để tự động hóa quá trình gỡ lỗi phần mềm."
        },
        "answer": "B"
      },
      {
        "question": "Prompt Poet của Character.AI giúp gì cho người dùng?",
        "options": {
          "A": "Tự động tạo ra các mô hình ngôn ngữ lớn từ dữ liệu văn bản.",
          "B": "Đơn giản hóa việc tạo ra các prompt phức tạp và động cho các mô hình ngôn ngữ lớn.",
          "C": "Tối ưu hóa hiệu suất của các ứng dụng AI trên thiết bị di động.",
          "D": "Phát hiện và loại bỏ các nội dung độc hại trong dữ liệu huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Andrew Ng nhấn mạnh điều gì trong khóa học 'AI Python for Beginners'?",
        "options": {
          "A": "Hạn chế tối đa việc sử dụng ChatGPT trong quá trình học lập trình.",
          "B": "Tập trung vào việc viết mã để sử dụng AI thực hiện các tác vụ và tận dụng AI như một công cụ hỗ trợ lập trình.",
          "C": "Chỉ dạy các khái niệm lý thuyết về AI mà không đi sâu vào thực hành.",
          "D": "Yêu cầu học viên phải có kiến thức nền tảng vững chắc về toán học và thống kê."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ Prompt Poet sử dụng những công nghệ nào để tạo prompt?",
        "options": {
          "A": "HTML và CSS.",
          "B": "JavaScript và React.",
          "C": "YAML và Jinja2 templating.",
          "D": "SQL và Python."
        },
        "answer": "C"
      },
      {
        "question": "Ngoài các tin tức về GPT-4o, robot Figure, chip Nvidia và các công cụ của Mistral AI và LangChain, bài viết còn đề cập đến vấn đề nào?",
        "options": {
          "A": "Sự phát triển của công nghệ thực tế ảo (VR) trong giáo dục.",
          "B": "Việc Google mua lại các nhà đồng sáng lập Character.AI.",
          "C": "Tác động của biến đổi khí hậu đến ngành công nghiệp AI.",
          "D": "Sự cạnh tranh giữa các công ty công nghệ trong lĩnh vực xe tự lái."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc sử dụng 'cache-aware truncation' trong Prompt Poet là gì?",
        "options": {
          "A": "Để tăng tính bảo mật cho dữ liệu người dùng.",
          "B": "Để tối ưu hóa hiệu suất prompt và sử dụng GPU.",
          "C": "Để giảm dung lượng lưu trữ của các mô hình ngôn ngữ lớn.",
          "D": "Để cải thiện khả năng dịch thuật của các mô hình AI."
        },
        "answer": "B"
      }
    ]
  },
  "googles-mid-sized-gemma-2-competes-with-llama-3-and-other-open-giants-plus-esm3s-new-model-can-engineer-proteins-sequence-structure-and-function": {
    "title": "Google’s mid-sized Gemma 2 competes with Llama 3 and other open giants",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. Today’s edition includes:\n\nGoogle launches Gemma 2, an open-source model available in 9 billion and 27 billion parameter sizesThe new model offers performance and efficiency gains over its predecessor, with the 27B version competing with Llama 3 and Grok 1 while running on a single GPU. Base and instruction-tuned versions of both model sizes and their weights are freely available through multiple platforms, including Google AI Studio, Kaggle, and Hugging Face Models. Gemma 2 shows some other technical advances, using sliding window attention, logit soft-capping, knowledge distillation, and model merging. 27 billion parameters is also an unusual size for a model, not quite small enough to run locally (except in heavily quantized versions) but not nearly as large as leading open or closed competitors. (GoogleandHugging Face)\n\nEvolutionary Scale announces ESM3, an open model for protein engineeringTrained on billions of proteins, the model has potential applications for biology and medicine, and can also simulate evolution. ESM3 can reason over protein sequence, structure, and function as either input or output, one at a time or simultaneously. The model is currently available via an API, and the Amazon- and Nvidia-backed company plans to release open base and instruction-tuned versions in 1.4, 7, and 98 billion parameters to accelerate scientific research. (Evolutionary Scale)\n\nMARS5 releases an open source competitor to ElevenLabsCAMB.AI’s MARS5, a new speech cloning model, can generate realistic speech for diverse, difficult-to-replicate scenarios like sports commentary and anime using just 5 seconds of audio and a text snippet. MARS5 uses a combination of a transformer encoder-decoder and diffusion inpainting to generate “deep cloned” speech output. The model allows users to guide variations in prosody by using punctuation, capitalization, and other text formatting. (GitHubandCAMB.AI)\n\nStudy reveals deepfakes as leading form of AI abuseA new study by Google DeepMind and Jigsaw analyzed 200 real-world incidents of AI misuse from January 2023 to March 2024. The researchers found that creating and spreading deceptive deepfake media, especially targeting politicians and public figures, is the most common malicious use of AI. The study also identified using language models to generate disinformation as the second most frequent type of AI abuse. Influencing public opinion and political narratives was the primary motivation behind over a quarter of the cases analyzed, followed by the use of deepfakes or disinformation for financial gain, whether through monetization of services or outright fraud. (arXiv.org)\n\nGoogle’s Agent Builder expands options for grounding agents in real-world dataGoogle announced new features for its Vertex AI Agent Builder including improved grounding with Google Search, a high-fidelity mode to reduce hallucinations by drawing information only from the provided context, and upcoming support for third-party datasets from Moody’s, MSCI, Thomson Reuters, and Zoominfo. Google is also expanding its Vector Search capabilities to include hybrid search, combining vector-based and keyword-based techniques for more relevant results. These changes address some of the limitations of grounding agents in Google Search, and aim to help developers and businesses build more accurate and capable AI agents by grounding them in reliable information. (Google)\n\n$1 million ARC prize fund offered for AI that can solve human-like reasoning puzzlesThe Abstraction and Reasoning Corpus (ARC) test, designed to resist AI’s memorization abilities, challenges systems to deduce patterns in paired grids of pixelated shapes. To win the grand prize of $500,000, an AI must match or exceed average human performance within twelve hours using limited computing power. The prize’s backers, Zapier’s Mike Knoop and Google’s François Chollet, believe any winning model will have to demonstrate capabilities like object permanence and geometric reasoning that current large language models typically lack. (Arc Prize)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng discussed the contrasting views of AI as a tool versus a separate entity:\n\n“When I was a high-school student in an internship job, I spent numerous hours photocopying, and I remember wishing I could automate that repetitive work. Humans do lots of valuable work, and AI, used as a tool to automate what we do, will create lots of value. I hope we can empower people to use tools to automate activities they’re allowed to do, and erect barriers to this only in extraordinary circumstances, when we have clear evidence that it creates more harm than benefit to society.”\n\nRead Andrew's full letterhere.\n\nOther top AI news and research stories we covered in depth included theU.S. antitrust investigationon three AI giants, the newmultilingual competitor to GPT-4, a growing market forlifelike avatars of deceased loved ones, and newbenchmarks for agentic behaviors.",
    "qa": [
      {
        "question": "Gemma 2 của Google có những kích thước tham số nào được công bố?",
        "options": {
          "A": "7 tỷ và 13 tỷ",
          "B": "9 tỷ và 27 tỷ",
          "C": "13 tỷ và 34 tỷ",
          "D": "27 tỷ và 54 tỷ"
        },
        "answer": "B"
      },
      {
        "question": "ESM3 của Evolutionary Scale được huấn luyện trên dữ liệu nào?",
        "options": {
          "A": "Hàng tỷ văn bản",
          "B": "Hàng tỷ hình ảnh",
          "C": "Hàng tỷ protein",
          "D": "Hàng tỷ đoạn mã"
        },
        "answer": "C"
      },
      {
        "question": "MARS5 của CAMB.AI cần bao nhiêu giây audio để tạo ra giọng nói nhân tạo?",
        "options": {
          "A": "1 giây",
          "B": "5 giây",
          "C": "10 giây",
          "D": "30 giây"
        },
        "answer": "B"
      },
      {
        "question": "Theo nghiên cứu của Google DeepMind và Jigsaw, hình thức lạm dụng AI phổ biến nhất là gì?",
        "options": {
          "A": "Tạo và lan truyền thông tin sai lệch bằng ngôn ngữ mô hình",
          "B": "Tạo và lan truyền deepfake",
          "C": "Sử dụng AI để tấn công mạng",
          "D": "Sử dụng AI để tạo nội dung độc hại"
        },
        "answer": "B"
      },
      {
        "question": "Tính năng mới nào của Vertex AI Agent Builder giúp giảm thiểu ảo giác?",
        "options": {
          "A": "Cải thiện khả năng tìm kiếm với Google Search",
          "B": "Chế độ trung thực cao (high-fidelity mode)",
          "C": "Hỗ trợ các bộ dữ liệu của bên thứ ba",
          "D": "Mở rộng khả năng Vector Search"
        },
        "answer": "B"
      },
      {
        "question": "Giải thưởng ARC trị giá bao nhiêu đô la Mỹ được trao cho AI có thể giải các câu đố suy luận giống con người?",
        "options": {
          "A": "$250,000",
          "B": "$500,000",
          "C": "$750,000",
          "D": "$1,000,000"
        },
        "answer": "D"
      },
      {
        "question": "Theo Andrew Ng, AI nên được sử dụng như thế nào?",
        "options": {
          "A": "Thay thế hoàn toàn công việc của con người",
          "B": "Một công cụ để tự động hóa công việc",
          "C": "Một thực thể riêng biệt với quyền lợi riêng",
          "D": "Một phương tiện để kiểm soát xã hội"
        },
        "answer": "B"
      },
      {
        "question": "Động cơ chính đằng sau việc sử dụng deepfake và thông tin sai lệch, theo nghiên cứu của Google DeepMind và Jigsaw, là gì?",
        "options": {
          "A": "Gây rối trật tự xã hội",
          "B": "Ảnh hưởng đến dư luận và các câu chuyện chính trị",
          "C": "Thực hiện các hành vi phá hoại",
          "D": "Thử nghiệm công nghệ mới"
        },
        "answer": "B"
      },
      {
        "question": "ESM3 có thể xử lý loại dữ liệu nào làm đầu vào hoặc đầu ra?",
        "options": {
          "A": "Chỉ trình tự protein",
          "B": "Chỉ cấu trúc protein",
          "C": "Chỉ chức năng protein",
          "D": "Trình tự, cấu trúc và chức năng protein"
        },
        "answer": "D"
      },
      {
        "question": "Công nghệ nào được MARS5 sử dụng để tạo ra giọng nói nhân tạo?",
        "options": {
          "A": "Mạng nơ-ron tích chập",
          "B": "Mạng nơ-ron hồi quy",
          "C": "Bộ mã hóa-giải mã Transformer và khuếch tán inpainting",
          "D": "Mạng đối nghịch tạo sinh (GANs)"
        },
        "answer": "C"
      }
    ]
  },
  "harvard-university-releases-giant-dataset-of-public-domain-books": {
    "title": "Harvard University releases giant dataset of public-domain books",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nHarvard’s copyright-free archive aims to democratize AI training data\n\nHarvard University released a dataset of nearly 1 million public-domain books for AI training, funded by Microsoft and OpenAI. The collection spans multiple genres, decades, and languages, including literary classics as well as obscure Czech math textbooks and Welsh pocket dictionaries. Created from Google Books scans of copyright-expired works, the dataset aims to provide high-quality, diverse training data to a wider range of AI developers. This initiative comes amid ongoing legal battles over the use of copyrighted material in AI training, potentially offering an alternative path for model development. (WiredandHarvard)\n\nGoogle’s Gemini 2.0 affirms new era of advanced AI agents\n\nGoogle launched Gemini 2.0, a new AI model with enhanced multimodal capabilities and native tool use. The model supports multimodal input and output, including text, images, video, and audio, and can natively call tools like Google Search and code execution. Gemini 2.0 Flash, an experimental version available now, outperforms the 1.5 Pro model on key benchmarks at twice the speed. Google is exploring various AI agents powered by Gemini 2.0, including Project Astra for video and audio real-world assistance, Project Mariner, an agent that can read and perform tasks in the browser, and Jules for automated developer and coding support. (Google)\n\nChatGPT adds real-time video analysis to Advanced Voice Mode\n\nOpenAI released visual capabilities for ChatGPT’s Advanced Voice Mode, allowing Plus, Team, and Pro subscribers to interact with their surroundings using their phone’s camera or screen sharing. The feature can analyze objects, explain device settings, and offer suggestions on various tasks, though it’s not yet available for Enterprise, Edu, or European users. This upgrade significantly expands ChatGPT’s multimodal capabilities, potentially opening new use cases for AI in real-time visual analysis and interaction. (TechCrunchandYouTube)\n\nGM abandons Cruise robotaxi venture, pivots to driver-assist tech\n\nGeneral Motors announced it will stop funding its Cruise autonomous vehicle unit and instead focus on developing partially automated driver-assist systems for personal vehicles. GM cited the considerable resources needed to scale the robotaxi business and increasing competition as reasons for the retreat. The move represents a significant shift for GM, which has invested billions in Cruise since acquiring a controlling stake in 2016, resulting in over $10 billion in operating losses. (Associated Press)\n\nRuliad unveils step-by-step AI reasoning model DeepThought-8B\n\nAI startup Ruliad launched DeepThought-8B, an AI reasoning model built on LLaMA-3.1 8B, designed to make its inference process more transparent and controllable. The model breaks down its thinking into clear steps, documenting each one in JSON format, and can take as many reasoning steps as needed to solve complex problems. DeepThought-8B is available through Ruliad’s chat application, with plans to open a developer API and release open model weights in the coming weeks. (Ruliad)\n\nGenerating language in complete ideas, not word to word\n\nLarge Concept Models (LCMs), a new AI model architecture from Meta Research, represent a novel approach to generative AI that operates on sentence-level embeddings rather than individual tokens. This shift allows for modeling language at a more abstract, semantic level across multiple languages and modalities. The researchers developed several LCM architectures, including diffusion-based and quantized models, using the SONAR multilingual embedding space. Key advantages of LCMs include strong zero-shot cross-lingual performance, efficient handling of long contexts, and potential improvements in long-form text coherence. While current LCMs don’t yet match the performance of top token-based language models, they show promise as an alternative approach that could lead to more flexible, globally applicable generative AI technologies. (Meta)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng shared emerging best practices for AI Product Management, including beginning with concrete examples, assessing technical feasibility through prompting, and managers rapidly building prototypes without engineers.\n\n“Just as a machine learning algorithm needs training examples to learn from, an AI product development team needs concrete examples of what we want an AI system to do. In other words, the data is your PRD (product requirements document)!”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: Amazon unveiled Nova models for text, image, and video, offeringcompetitive performance at competitive prices;OpenAI introduced o1 and o1 pro mode for advanced reasoning, available in a new plan called GPTPro and priced at $200/month; Googlelaunched Genie 2, bringing interactive 3D worlds to life; andresearchers at Lamini proposed a memory methoddesigned to reduce hallucinations in large language models, enhancing factual accuracy.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Dataset của Đại học Harvard được tạo ra từ nguồn nào và nhằm mục đích gì?",
        "options": {
          "A": "Từ các bài báo khoa học được cấp phép, nhằm mục đích nghiên cứu khoa học.",
          "B": "Từ các bản scan Google Books của các tác phẩm hết bản quyền, nhằm cung cấp dữ liệu huấn luyện AI đa dạng.",
          "C": "Từ dữ liệu người dùng thu thập được trên internet, nhằm mục đích cải thiện trải nghiệm người dùng.",
          "D": "Từ các tác phẩm văn học hiện đại, nhằm mục đích hỗ trợ các nhà văn trẻ."
        },
        "answer": "B"
      },
      {
        "question": "Gemini 2.0 của Google có những khả năng nổi bật nào?",
        "options": {
          "A": "Chỉ hỗ trợ nhập và xuất dữ liệu dạng văn bản.",
          "B": "Hỗ trợ nhập và xuất dữ liệu đa phương tiện (văn bản, hình ảnh, video, âm thanh) và có thể sử dụng các công cụ như Google Search.",
          "C": "Chỉ có thể sử dụng để viết code và gỡ lỗi.",
          "D": "Chỉ có khả năng phân tích dữ liệu tài chính."
        },
        "answer": "B"
      },
      {
        "question": "Tính năng mới nào được thêm vào Advanced Voice Mode của ChatGPT?",
        "options": {
          "A": "Khả năng tạo ra hình ảnh từ giọng nói.",
          "B": "Khả năng phân tích video thời gian thực.",
          "C": "Khả năng dịch thuật giọng nói sang nhiều ngôn ngữ.",
          "D": "Khả năng tạo ra âm nhạc từ giọng nói."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao General Motors quyết định dừng đầu tư vào dự án xe tự lái Cruise?",
        "options": {
          "A": "Do công nghệ xe tự lái không còn tiềm năng phát triển.",
          "B": "Do nguồn lực cần thiết để mở rộng quy mô kinh doanh robotaxi quá lớn và sự cạnh tranh ngày càng tăng.",
          "C": "Do chính phủ ban hành lệnh cấm xe tự lái.",
          "D": "Do các vấn đề về an toàn của xe tự lái."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của mô hình DeepThought-8B do Ruliad phát triển là gì?",
        "options": {
          "A": "Tăng tốc độ xử lý dữ liệu.",
          "B": "Làm cho quá trình suy luận của AI trở nên minh bạch và dễ kiểm soát hơn.",
          "C": "Giảm chi phí vận hành hệ thống AI.",
          "D": "Cải thiện khả năng tạo ra hình ảnh chân thực."
        },
        "answer": "B"
      },
      {
        "question": "LCMs (Large Concept Models) của Meta Research hoạt động ở cấp độ nào?",
        "options": {
          "A": "Cấp độ pixel.",
          "B": "Cấp độ từ (token).",
          "C": "Cấp độ câu (sentence-level embeddings).",
          "D": "Cấp độ byte."
        },
        "answer": "C"
      },
      {
        "question": "Ưu điểm chính của LCMs so với các mô hình ngôn ngữ dựa trên token là gì?",
        "options": {
          "A": "Hiệu suất vượt trội trong mọi tác vụ.",
          "B": "Khả năng xử lý đa ngôn ngữ zero-shot mạnh mẽ và xử lý ngữ cảnh dài hiệu quả.",
          "C": "Khả năng tạo ra hình ảnh chất lượng cao.",
          "D": "Khả năng dịch thuật chính xác tuyệt đối."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, đâu là một trong những phương pháp tốt nhất để quản lý sản phẩm AI?",
        "options": {
          "A": "Bắt đầu bằng việc xây dựng mô hình AI phức tạp.",
          "B": "Bắt đầu bằng các ví dụ cụ thể về những gì chúng ta muốn hệ thống AI thực hiện.",
          "C": "Tập trung vào việc tối ưu hóa thuật toán trước khi thu thập dữ liệu.",
          "D": "Giao toàn bộ công việc cho các kỹ sư AI."
        },
        "answer": "B"
      },
      {
        "question": "Amazon đã giới thiệu các mô hình Nova cho những loại dữ liệu nào?",
        "options": {
          "A": "Chỉ cho văn bản.",
          "B": "Chỉ cho hình ảnh.",
          "C": "Chỉ cho video.",
          "D": "Cho văn bản, hình ảnh và video."
        },
        "answer": "D"
      },
      {
        "question": "OpenAI đã giới thiệu các chế độ o1 và o1 pro cho mục đích gì?",
        "options": {
          "A": "Để cải thiện khả năng tạo ra hình ảnh.",
          "B": "Để tăng tốc độ xử lý dữ liệu.",
          "C": "Để cải thiện khả năng suy luận nâng cao.",
          "D": "Để giảm chi phí sử dụng ChatGPT."
        },
        "answer": "C"
      }
    ]
  },
  "how-ai-models-can-encourage-bad-behavior": {
    "title": "How AI models can encourage bad behavior",
    "collection": "data-points",
    "content": "In today’s edition, you’ll learn more about:\n\nELEPHANT helps identify and measure sycophancy in AI models\n\nStanford researchers have identified a pattern of “social sycophancy” in large language models, where AI systems excessively preserve users’ self-image when giving personal advice. The study tested eight models using the ELEPHANT framework, which measures five face-preserving behaviors: emotional validation, moral endorsement, indirect language, indirect action, and accepting user framing. Across open-ended questions and Reddit’s r/AmITheAsshole posts, LLMs showed significantly higher rates of sycophantic behavior than humans—offering emotional validation 76 percent of the time versus 22 percent for humans and incorrectly classifying 42 percent of inappropriate behavior as acceptable. According to the researchers, personal advice is becoming the most common LLM use case, and excessive agreement could reinforce harmful beliefs while undermining critical thinking; the preference datasets used in AI training too often implicitly reward these behaviors. The ELEPHANT framework and datasets are publicly available for researchers to further study this issue. (arXiv)\n\nGoogle launches app for testing AI models on mobile devices\n\nGoogle released AI Edge Gallery, an experimental Android app that runs open AI models directly on mobile devices without requiring an internet connection after initial model download. The app allows developers to test various models from Hugging Face, upload images for AI analysis, experiment with prompts for code generation and text rewriting, and engage in multi-turn conversations. Key features include real-time performance benchmarks showing metrics like time-to-first-token and decode speed, plus the ability to test custom LiteRT models. This tool helps developers evaluate how different AI models perform on mobile hardware, providing valuable insights for building offline-capable AI applications. The app is currently available as an APK for Android, with an iOS version coming soon. (GitHub)\n\nOpen multimodal model from ByteDance unifies generation and understanding\n\nByteDance researchers released BAGEL, an open-weights AI model with 7 billion active parameters (14 billion total) that combines text and image generation, understanding, and editing capabilities in a single system. The model uses a Mixture-of-Transformer-Experts architecture and outperforms open vision-language models like Qwen2.5-VL and InternVL-2.5 on understanding benchmarks, while matching specialized generators like Stable Diffusion 3 in text-to-image quality. BAGEL shows advanced capabilities including free-form visual manipulation and “world-modeling” tasks that go beyond traditional image editing. Most current open-weights AI models specialize in either understanding or generation but not both. BAGEL is freely available via Hugging Face and other providers for fine-tuning, distillation, and deployment. (BAGELandarXiv)\n\nPerplexity’s Labs lets users create reports, apps, and dashboards\n\nPerplexity introduced Labs, a new feature that enables Pro subscribers to use AI-based research and analysis to generate complete projects including reports, spreadsheets, dashboards, and simple web applications. The system performs 10 minutes or more of self-supervised work including deep web browsing, code execution, and chart creation to transform ideas into finished objects. Labs differentiates itself from Perplexity’s existing Research mode (formerly Deep Research) by investing more time and offering advanced file generation and mini-app creation. This launch shows Perplexity’s expansion beyond its answer engine roots to something closer to a full-fledged AI product suite comparable to ChatGPT. Labs is available now for Pro subscribers on web and iOS, with Android support coming soon. (Perplexity)\n\nLovable’s coding platform exposes user information through security hole\n\nLovable, a Swedish startup that lets non-technical users create websites and apps through natural language prompts, has failed to fix a critical security vulnerability months after being notified, according to a report by a Replit employee. The analysis of 1,645 Lovable-created web apps found that 170 exposed user data including names, email addresses, financial information, and API keys that could allow hackers to rack up charges on customers’ accounts. The vulnerability stems from improperly configured database connections through Supabase. This highlights the dangers of inexperienced users building software without understanding security basics, a growing concern as AI democratizes software development. Lovable acknowledged on X that it’s “not yet where we want to be in terms of security.” (Semafor)\n\nNew report estimates the energy costs of AI’s rapid expansion\n\nMIT Technology Review analyzed the energy consumption of AI systems, finding that a single ChatGPT query uses about 1,080 joules of electricity, while generating a 5-second AI video requires 3.4 million joules, roughly equivalent to running a microwave for over an hour. The publication examined dozens of AI models and interviewed experts to trace AI’s carbon footprint, calculating that AI servers consumed between 53 and 76 terawatt-hours of electricity in 2024, enough to power 7.2 million U.S. homes annually. By 2028, AI could consume up to 326 terawatt-hours per year, representing 22 percent of all U.S. household electricity consumption, as companies race to build massive data centers and develop more complex AI agents and reasoning models. Still, tech companies’ lack of transparency about energy usage makes it difficult to get a complete picture of AI’s energy costs or plan for its actual environmental impact. (MIT Technology Review)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng raised concerns about proposed U.S. funding cuts for basic research, emphasizing how such cuts could hurt American competitiveness in AI and urging continued investment in open scientific research.\n\n“Those who invent a technology get to commercialize it first, and in a fast-moving world, the cutting-edge technology is what’s most valuable.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Framework ELEPHANT được sử dụng để làm gì trong nghiên cứu về AI?",
        "options": {
          "A": "Đánh giá hiệu suất của các mô hình AI trên thiết bị di động.",
          "B": "Xác định và đo lường hành vi nịnh bợ xã hội trong các mô hình AI.",
          "C": "Tạo báo cáo, ứng dụng và bảng điều khiển bằng AI.",
          "D": "Phân tích mức tiêu thụ năng lượng của các hệ thống AI."
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng AI Edge Gallery của Google cho phép người dùng làm gì?",
        "options": {
          "A": "Tạo ra các video AI dài 5 giây.",
          "B": "Chạy các mô hình AI mở trực tiếp trên thiết bị di động mà không cần kết nối internet sau khi tải mô hình.",
          "C": "Phát hiện các lỗ hổng bảo mật trong các ứng dụng web được tạo bởi AI.",
          "D": "Đánh giá mức độ nịnh bợ của các mô hình AI."
        },
        "answer": "B"
      },
      {
        "question": "BAGEL, mô hình AI của ByteDance, có điểm gì nổi bật so với các mô hình AI mở khác?",
        "options": {
          "A": "Chỉ chuyên về tạo ảnh từ văn bản.",
          "B": "Chỉ chuyên về hiểu ngôn ngữ và hình ảnh.",
          "C": "Kết hợp khả năng tạo, hiểu và chỉnh sửa văn bản và hình ảnh trong một hệ thống duy nhất.",
          "D": "Có kích thước nhỏ gọn, dễ dàng triển khai trên các thiết bị di động."
        },
        "answer": "C"
      },
      {
        "question": "Tính năng Labs của Perplexity cho phép người dùng làm gì?",
        "options": {
          "A": "Tìm kiếm thông tin trên internet nhanh hơn.",
          "B": "Tạo ra các báo cáo, bảng tính, bảng điều khiển và ứng dụng web đơn giản bằng AI.",
          "C": "Đánh giá mức tiêu thụ năng lượng của các mô hình AI.",
          "D": "Phát hiện các lỗ hổng bảo mật trong các ứng dụng web."
        },
        "answer": "B"
      },
      {
        "question": "Lỗ hổng bảo mật được phát hiện trong nền tảng Lovable liên quan đến vấn đề gì?",
        "options": {
          "A": "Sử dụng thuật toán mã hóa yếu.",
          "B": "Cấu hình kết nối cơ sở dữ liệu không đúng cách thông qua Supabase.",
          "C": "Thiếu cơ chế xác thực hai yếu tố.",
          "D": "Không cập nhật các bản vá bảo mật kịp thời."
        },
        "answer": "B"
      },
      {
        "question": "Theo MIT Technology Review, một truy vấn ChatGPT tiêu thụ khoảng bao nhiêu năng lượng?",
        "options": {
          "A": "100 joules.",
          "B": "1,080 joules.",
          "C": "3.4 triệu joules.",
          "D": "326 terawatt-hours."
        },
        "answer": "B"
      },
      {
        "question": "Theo ước tính, đến năm 2028, AI có thể tiêu thụ bao nhiêu phần trăm tổng lượng điện tiêu thụ của các hộ gia đình ở Hoa Kỳ?",
        "options": {
          "A": "5%.",
          "B": "10%.",
          "C": "22%.",
          "D": "50%."
        },
        "answer": "C"
      },
      {
        "question": "Andrew Ng bày tỏ lo ngại về điều gì liên quan đến nghiên cứu AI ở Hoa Kỳ?",
        "options": {
          "A": "Sự cạnh tranh gay gắt từ các quốc gia khác.",
          "B": "Việc thiếu dữ liệu đào tạo chất lượng cao.",
          "C": "Các đề xuất cắt giảm tài trợ cho nghiên cứu cơ bản.",
          "D": "Sự thiếu hụt nhân tài trong lĩnh vực AI."
        },
        "answer": "C"
      },
      {
        "question": "ELEPHANT framework đo lường những loại hành vi nào?",
        "options": {
          "A": "Hiệu suất tính toán, tốc độ xử lý và độ chính xác.",
          "B": "Xác thực cảm xúc, tán thành đạo đức, ngôn ngữ gián tiếp, hành động gián tiếp và chấp nhận cách trình bày của người dùng.",
          "C": "Khả năng tạo văn bản, hình ảnh và video.",
          "D": "Mức tiêu thụ năng lượng, lượng khí thải carbon và tác động môi trường."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì khiến việc đánh giá chính xác chi phí năng lượng của AI trở nên khó khăn?",
        "options": {
          "A": "Sự phức tạp của các mô hình AI.",
          "B": "Sự thiếu minh bạch của các công ty công nghệ về mức tiêu thụ năng lượng.",
          "C": "Sự thay đổi nhanh chóng của công nghệ AI.",
          "D": "Sự thiếu hụt các chuyên gia trong lĩnh vực năng lượng."
        },
        "answer": "B"
      }
    ]
  },
  "jamba-1-5-models-mix-transformers-with-mamba": {
    "title": "Jamba 1.5 models mix transformers with Mamba",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nAI21 releases new open hybrid-architecture language models with long context windows\n\nAI21 Labs released the Jamba 1.5 family of language models, including Mini (12 billion parameter) and Large (94 billion parameter) versions, both under the same open model license. The two models use a hybrid solid state model-transformer architecture, feature an effective 256,000-token context window, and outperform competitors in their size on the Arena Hard benchmark and speed and throughput tests. According to the RULER benchmark, Jamba 1.5’s performance on long context tasks surpasses models claiming a much longer context window, including Claude 3.5, Gemini 1.5, and more. (AI21 Labs)\n\nIdeogram releases new AI image generation model with search and developer API\n\nIdeogram launched its 2.0 model, offering improved capabilities for generating realistic images, graphic design, and typography, claiming better performance than DALL-E 3 and Flux Pro at lower cost. The company released an iOS app, a beta API for developers, and a search feature for its library of over 1 billion user-generated images. Ideogram 2.0 introduces new features like style controls, color palette selection, and advanced prompting tools, aiming to enhance creative workflows for designers and businesses. (Ideogram)\n\nNVIDIA’s StormCast model advances kilometer-scale weather prediction\n\nNVIDIA Research announced StormCast, a generative AI model that can emulate high-fidelity atmospheric dynamics at smaller scales than previously possible, enabling reliable weather prediction critical for disaster planning. The model can predict over 100 variables and offers forecasts with lead times of up to six hours that are up to 10% more accurate than NOAA’s state-of-the-art operational model. This model’s development represents a significant advancement in using AI for climate research and extreme weather prediction, potentially saving lives and reducing damage from natural disasters. (NVIDIA)\n\nAn updated leaderboard measures models’ ability to handle function calls\n\nResearchers updating the Berkeley Function-Calling Leaderboard (BFCL) released BFCL V2 • Live, a new dataset featuring 2,251 user-contributed function-calling scenarios. This dataset aims to evaluate large language models’ ability to interface with external tools and APIs in real-world applications. BFCL V2 • Live addresses issues of data contamination and bias by using live, user-contributed function documentation and queries, providing a more accurate measure of LLMs’ function-calling performance in diverse environments. Currently, OpenAI models hold the top spots on the leaderboard, followed by a Llama 3.1-based model, and various versions of Anthropic’s Claude. (UC Berkeley/Gorilla)\n\nAuthors sue Anthropic over alleged copyright infringement in training\n\nThree authors filed a class-action lawsuit against Anthropic, alleging the company used pirated versions of their books to train its chatbot Claude. The complaint accuses Anthropic of “stealing hundreds of thousands of copyrighted books” to build its business. This lawsuit adds to a growing number of legal challenges against AI companies over the use of copyrighted material in training large language models, particularly related to the once-popular Books3 AI dataset. (The Guardian)\n\nOpenAI brings fine-tuning to GPT-4o\n\nOpenAI launched fine-tuning for GPT-4o, allowing developers to customize the model by training it on their own datasets. The company offers 1 million free training tokens daily per organization until September 23, with fine-tuning available to all developers on paid usage tiers. This development significantly expands the capabilities of AI developers, enabling them to create more specialized and efficient models tailored to their unique use cases, potentially accelerating innovation across industries and applications. (OpenAI)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng discussed why the DEFIANCE Act and FTC ban on fake product reviews take the right approach to regulating AI:\n\n“The DEFIANCE Act, which passed unanimously in the Senate (and still requires passage in the House of Representatives before the President can sign it into law) imposes civil penalties for the creating and distributing non-consensual, deepfake porn. This disgusting application is harming many people including underage girls. While many image generation models do have guardrails against generating porn, these guardrails often can be circumvented via jailbreak prompts or fine-tuning (for models with open weights).”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: Anagentic workflowthat generates novel scientific research papers, all aboutGoogle’s Imagen 3and Alibaba’sQwen2-Math and Qwen2-Audio, andscaling lawsfor data quality.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mô hình ngôn ngữ Jamba 1.5 của AI21 Labs có bao nhiêu tham số trong phiên bản Mini?",
        "options": {
          "A": "94 tỷ",
          "B": "12 tỷ",
          "C": "256 nghìn",
          "D": "1 triệu"
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào đã ra mắt mô hình tạo ảnh AI 2.0 với khả năng cải thiện thiết kế đồ họa và typography?",
        "options": {
          "A": "AI21 Labs",
          "B": "NVIDIA",
          "C": "Ideogram",
          "D": "OpenAI"
        },
        "answer": "C"
      },
      {
        "question": "Mô hình StormCast của NVIDIA dự đoán thời tiết trong khoảng thời gian tối đa là bao lâu?",
        "options": {
          "A": "24 giờ",
          "B": "12 giờ",
          "C": "6 giờ",
          "D": "3 giờ"
        },
        "answer": "C"
      },
      {
        "question": "BFCL V2 • Live sử dụng dữ liệu nào để đánh giá khả năng gọi hàm của các mô hình ngôn ngữ lớn?",
        "options": {
          "A": "Dữ liệu tổng hợp từ các bài báo khoa học",
          "B": "Dữ liệu được tạo ra bởi các chuyên gia",
          "C": "Dữ liệu đóng góp trực tiếp từ người dùng",
          "D": "Dữ liệu từ các bộ dữ liệu công khai đã được kiểm duyệt"
        },
        "answer": "C"
      },
      {
        "question": "Vụ kiện tập thể chống lại Anthropic cáo buộc công ty này vi phạm bản quyền như thế nào?",
        "options": {
          "A": "Sử dụng trái phép hình ảnh có bản quyền để tạo ra hình ảnh AI",
          "B": "Sao chép mã nguồn của các mô hình ngôn ngữ khác",
          "C": "Sử dụng các phiên bản sách lậu để huấn luyện chatbot Claude",
          "D": "Vi phạm quyền riêng tư của người dùng khi thu thập dữ liệu huấn luyện"
        },
        "answer": "C"
      },
      {
        "question": "OpenAI cung cấp bao nhiêu token huấn luyện miễn phí mỗi ngày cho mỗi tổ chức khi tinh chỉnh GPT-4o?",
        "options": {
          "A": "100.000",
          "B": "500.000",
          "C": "1 triệu",
          "D": "5 triệu"
        },
        "answer": "C"
      },
      {
        "question": "Đạo luật DEFIANCE mà Andrew Ng đề cập đến trong thư của mình tập trung vào vấn đề gì?",
        "options": {
          "A": "Kiểm soát việc sử dụng AI trong lĩnh vực tài chính",
          "B": "Xử phạt việc tạo và phân phối nội dung khiêu dâm deepfake không có sự đồng ý",
          "C": "Bảo vệ quyền riêng tư của người dùng trước các công ty AI",
          "D": "Thúc đẩy sự phát triển của AI trong lĩnh vực quốc phòng"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình StormCast của NVIDIA có độ chính xác cao hơn bao nhiêu so với mô hình hoạt động hiện đại của NOAA?",
        "options": {
          "A": "5%",
          "B": "10%",
          "C": "15%",
          "D": "20%"
        },
        "answer": "B"
      },
      {
        "question": "Tính năng mới nào được giới thiệu trong Ideogram 2.0 nhằm nâng cao quy trình làm việc sáng tạo cho các nhà thiết kế và doanh nghiệp?",
        "options": {
          "A": "Tự động tạo nội dung văn bản dựa trên hình ảnh",
          "B": "Kiểm soát phong cách, lựa chọn bảng màu và công cụ nhắc nâng cao",
          "C": "Khả năng dịch hình ảnh sang nhiều ngôn ngữ",
          "D": "Tích hợp trực tiếp với các nền tảng mạng xã hội"
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của việc tinh chỉnh GPT-4o là gì?",
        "options": {
          "A": "Tăng cường khả năng xử lý ngôn ngữ tự nhiên chung",
          "B": "Cho phép các nhà phát triển tùy chỉnh mô hình cho các bộ dữ liệu cụ thể của họ",
          "C": "Giảm chi phí vận hành mô hình",
          "D": "Cải thiện khả năng tạo ra hình ảnh chất lượng cao"
        },
        "answer": "B"
      }
    ]
  },
  "kimis-k1-5-is-o1s-newest-competitor-learn-how-it-was-trained": {
    "title": "Kimi’s k1.5 is o1’s newest competitor; Learn how it was trained",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nMoonshotAI develops new reasoning model using reinforcement learning\n\nKimi’s k1.5 model uses reinforcement learning techniques like online policy mirror descent and long context scaling to improve its chain-of-thought reasoning abilities. The model outperforms OpenAI’s o1 on multiple benchmarks for math, coding, and visual reasoning tasks. Kimi’s relatively simple and scalable approach to training allows the model to learn complex problem-solving strategies without relying on computationally intensive techniques like Monte Carlo Tree Search, value functions, or process reward models. (arXivandGitHub)\n\nImproved dataset helps vision model top pathology benchmarks\n\nMayo Clinic researchers developed Atlas, a new vision foundation model for digital pathology that outperforms existing models on multiple benchmarks. The model was trained on an unusually valuable data set of 1.2 million histopathology images from Mayo Clinic and Charité - Universitätsmedizin Berlin using an adapted RudolfV approach. Atlas achieved state-of-the-art results across 21 public benchmark datasets covering both molecular and morphology-related pathology tasks, despite not having the largest parameter count or training dataset. If adopted, this model could create applications that improve diagnostic accuracy and efficiency in analyzing tissue-based diseases, including cancers, inflammatory conditions, and degenerative disorders. But other researchers say this model, while state-of-the-art, is still too limited to replace human pathologists, and more data collection is needed to advance the field. (arXivandMIT Technology Review)\n\nCitations API simplifies verification for Claude developers\n\nAnthropic launched Citations, a new API feature that allows Claude to ground its responses in source documents. The feature processes user-provided documents by chunking them into sentences, which are then passed to the model along with user context and queries. Claude analyzes the query and generates responses with precise citations referencing the source material, minimizing hallucinations and increasing output reliability by up to 15 percent. The Citations API helps developers to create more trustworthy and transparent applications for use cases like document summarization, complex Q&A, and customer support. (Anthropic)\n\nNew free-to-use tool streamlines web sites for automated agents\n\nA new AI-powered tool called Browser Use extracts interactive elements from websites, enabling agents to navigate and interact with them more effectively. Browser Use combines visual understanding with HTML extraction, manages multiple tabs, and supports various large language models, including GPT-4o, Claude Sonnet 3.5, and DeepSeek-R1, plus agent tools from LangChain and other providers. The product offers various pricing tiers, from a free open version to enterprise-level custom solutions, and claims to outperform other web automation tools like Computer Use or Mariner in accuracy. (Browser UseandGitHub)\n\nGame industry grapples with layoffs amid AI adoption\n\nA recent survey of game developers suggests that approximately 11 percent of them experienced layoffs in the past year, with Narrative roles hit hardest at 19 percent. The survey found that 58 percent of developers expressed concern about future job security, while 30 percent reported that they believe generative AI negatively impacts the games industry. Despite concerns, 52 percent of respondents work for companies that have implemented generative AI. Surprisingly, 47 percent of developers over 55 use AI tools, compared to only 28 percent of those aged 18-34, suggesting a generational divide in AI adoption in gaming. (Game Developers Conference, requires email registration)\n\nHunyuan unveils generative models that create 3D assets from images\n\nHunyuan released Hunyuan3D 2.0, an open AI system that generates high-quality 3D shapes with textures from 2D images. The system uses two main components: one for creating shapes and another for applying textures, along with an interactive platform called Hunyuan3D-Studio for manipulating and animating 3D assets. Hunyuan claims their new system outperforms competing open models like Michelangelo and Direct3D as well as unnamed closed models in producing detailed, accurately textured 3D models that closely match input images. (arXivandHugging Face)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng shared insights from the World Economic Forum in Davos, Switzerland, where he discussed AI business implementations, governance, and climate solutions, including geoengineering. He highlighted the potential of Stratospheric Aerosol Injection (SAI) to combat global warming and introduced an AI-powered climate simulator at planetparasol.ai to explore these possibilities.\n\n“I believe the risks associated with cooling down our planet will be much lower than the risks of runaway climate change. I hope we can build a global governance structure to decide collectively whether, and if so to what extent and how, to implement geoengineering.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:DeepSeek-R1 emergedas an affordable rival to OpenAI’s o1, sharpening its reasoning capabilities;Unitree and EngineAI showcased affordable humanoid robots, breaking price barriers;Texas introduced a landmark billto regulate AI development and use, further opening the door for state-level AI governance; andresearchers combined deep learning with an evolutionary algorithmto design chips in minutes, revealing mysterious but effective processes in generated hardware designs.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mô hình Kimi k1.5 sử dụng kỹ thuật học tăng cường nào để cải thiện khả năng suy luận chuỗi?",
        "options": {
          "A": "Monte Carlo Tree Search",
          "B": "Online policy mirror descent và long context scaling",
          "C": "Value functions",
          "D": "Process reward models"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Atlas của Mayo Clinic được huấn luyện trên bộ dữ liệu hình ảnh bệnh học số lượng bao nhiêu?",
        "options": {
          "A": "1.2 triệu hình ảnh",
          "B": "2.4 triệu hình ảnh",
          "C": "500 nghìn hình ảnh",
          "D": "1 triệu hình ảnh"
        },
        "answer": "A"
      },
      {
        "question": "Tính năng Citations của Anthropic giúp Claude cải thiện độ tin cậy của đầu ra lên bao nhiêu phần trăm?",
        "options": {
          "A": "5 phần trăm",
          "B": "10 phần trăm",
          "C": "15 phần trăm",
          "D": "20 phần trăm"
        },
        "answer": "C"
      },
      {
        "question": "Công cụ Browser Use kết hợp những yếu tố nào để giúp các agent tương tác với trang web hiệu quả hơn?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên và khai thác dữ liệu",
          "B": "Hiểu biết về hình ảnh và khai thác HTML",
          "C": "Học sâu và học tăng cường",
          "D": "Phân tích cú pháp và tạo sinh mã"
        },
        "answer": "B"
      },
      {
        "question": "Theo khảo sát, tỷ lệ nhà phát triển game bị sa thải trong năm qua là bao nhiêu?",
        "options": {
          "A": "5 phần trăm",
          "B": "11 phần trăm",
          "C": "19 phần trăm",
          "D": "30 phần trăm"
        },
        "answer": "B"
      },
      {
        "question": "Vai trò nào trong ngành phát triển game chịu ảnh hưởng nặng nề nhất bởi làn sóng sa thải do AI?",
        "options": {
          "A": "Lập trình viên",
          "B": "Thiết kế đồ họa",
          "C": "Nhà phát triển cốt truyện (Narrative)",
          "D": "Kiểm thử game"
        },
        "answer": "C"
      },
      {
        "question": "Hunyuan3D 2.0 tạo ra các hình dạng 3D chất lượng cao từ hình ảnh 2D bằng cách sử dụng mấy thành phần chính?",
        "options": {
          "A": "Một thành phần",
          "B": "Hai thành phần",
          "C": "Ba thành phần",
          "D": "Bốn thành phần"
        },
        "answer": "B"
      },
      {
        "question": "Andrew Ng đã chia sẻ những hiểu biết của mình từ Diễn đàn Kinh tế Thế giới ở Davos về vấn đề gì?",
        "options": {
          "A": "Tác động của AI đến thị trường lao động",
          "B": "Ứng dụng AI trong kinh doanh, quản trị và giải pháp khí hậu",
          "C": "Rủi ro đạo đức của AI",
          "D": "Phát triển AI mã nguồn mở"
        },
        "answer": "B"
      },
      {
        "question": "Stratospheric Aerosol Injection (SAI) là gì?",
        "options": {
          "A": "Một phương pháp khai thác khoáng sản trên sao Hỏa",
          "B": "Một kỹ thuật mô phỏng khí hậu bằng AI",
          "C": "Một phương pháp can thiệp địa kỹ thuật để chống lại sự nóng lên toàn cầu",
          "D": "Một loại robot hình người giá rẻ"
        },
        "answer": "C"
      },
      {
        "question": "Bang nào của Hoa Kỳ đã giới thiệu một dự luật mang tính bước ngoặt để điều chỉnh sự phát triển và sử dụng AI?",
        "options": {
          "A": "California",
          "B": "Texas",
          "C": "New York",
          "D": "Florida"
        },
        "answer": "B"
      }
    ]
  },
  "laion-cleans-up-its-image-dataset": {
    "title": "LAION cleans up its image dataset",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nLAION updates image dataset, purges child sexual abuse links\n\nLAION announced Re-LAION-5B, an updated version of its large-scale image-text dataset that removes links to suspected child sexual abuse material (CSAM). The organization partnered with child protection groups to filter out 2,236 potentially problematic links from the original 5.5 billion image-text pairs. Two versions are being released: a research version and a “research-safe” version with additional NSFW content removed. This update aims to provide a safer open dataset for AI researchers while maintaining reproducibility for foundation model studies. (LAION)\n\nAi2’s small MoE model shows power of post-training\n\nAi2 released OLMoE, a Mixture-of-Experts model with 1.3 billion active parameters and 6.9 billion total parameters, trained on 5 trillion data-curated tokens. The model outperforms all open models in its active parameter range and responds well to fine-tuning, showing significant improvements with optimization techniques like KTO and DPO. OLMoE’s release includes intermediate training checkpoints, improved post-training mix, code, and training logs, all under the Apache 2.0 license. (Interconnects)\n\nNew protein design system could accelerate drug development\n\nGoogle DeepMind introduced AlphaProteo, an AI system that designs novel, high-strength proteins and protein binders for biological and health research. The system achieved higher experimental success rates and 3 to 300 times better binding affinities than existing methods on seven target proteins. AlphaProteo’s ability to generate effective protein binders could accelerate progress in drug development and understanding the inner workings of diseases, reducing the time needed for experiments in these fields. (Google DeepMind)\n\nCohere updates and drops prices for its RAG-optimized models\n\nCohere unveiled upgraded versions of its Command R and Command R+ enterprise AI models, offering improvements in retrieval-augmented generation, multilingual support, and workflow automation. The new models feature enhanced performance in coding, math, reasoning, and latency, with Command R now matching the capabilities of the previous Command R+ version at a lower price point. Cohere priced the new Command R at $0.15 per million input tokens and $0.60 per million output tokens, while Command R+ costs $2.50 and $10.00 per million tokens for input and output, respectively. (Cohere)\n\nAnthropic offers developer-friendly projects to jumpstart Claude-powered applications\n\nAnthropic released a collection of quickstart projects to help developers build applications with the Anthropic API and Claude language model. The first project is a customer support agent that demonstrates Claude’s natural language capabilities for AI-assisted support systems. Developers can access these projects, which include setup instructions and resources, to quickly create customizable applications using Anthropic’s technology. (GitHub)\n\nYouTube develops detection tools for synthetic content\n\nYouTube is creating two new technologies to identify AI-generated content that mimics real people. One system will detect synthetic singing voices, allowing music partners to manage AI recreations of their vocals. The other will identify AI-generated depictions of people’s faces across various industries. These tools build on YouTube’s existing Content ID system, which has processed billions of copyright claims since 2007. (YouTube)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng discussed how South Korea is well-positioned to become a strong AI hub, highlighting its local tech ecosystem, government support, and the wide range of opportunities across different industries:\n\n“I’ve been consistently impressed by the thoughtful approach the Korean government has taken toward AI, with an emphasis on investment and innovation and a realistic understanding of risks without being distracted by science-fiction scenarios of harm.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: anew open weights modelthat generates tokens faster than current transformers, astudy ranking large language modelsby their tendency to hallucinate during retrieval-augmented generation,Argentina’s new AI-powered national law-enforcement departmentthat aims to detect, investigate, and predict crimes, and anew tool that makes large language models more explainableby probing every layer.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "LAION đã thực hiện hành động gì để cải thiện bộ dữ liệu hình ảnh-văn bản của mình?",
        "options": {
          "A": "Tăng số lượng cặp hình ảnh-văn bản lên 10 tỷ.",
          "B": "Loại bỏ các liên kết nghi ngờ chứa nội dung lạm dụng tình dục trẻ em (CSAM).",
          "C": "Thêm các công cụ mới để tạo ra hình ảnh từ văn bản.",
          "D": "Phát triển một phiên bản thương mại của bộ dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình OLMoE của Ai2 có bao nhiêu tham số đang hoạt động?",
        "options": {
          "A": "6.9 tỷ",
          "B": "5 nghìn tỷ",
          "C": "1.3 tỷ",
          "D": "2.0 tỷ"
        },
        "answer": "C"
      },
      {
        "question": "AlphaProteo của Google DeepMind được thiết kế để làm gì?",
        "options": {
          "A": "Tạo ra các mô hình ngôn ngữ lớn.",
          "B": "Thiết kế các protein và protein binder mới, có độ bền cao.",
          "C": "Phân tích dữ liệu gen để tìm ra các phương pháp điều trị bệnh mới.",
          "D": "Dự đoán cấu trúc protein từ trình tự amino acid."
        },
        "answer": "B"
      },
      {
        "question": "Cohere đã cải tiến những khía cạnh nào của các mô hình Command R và Command R+?",
        "options": {
          "A": "Tốc độ xử lý hình ảnh và video.",
          "B": "Khả năng tạo ra âm nhạc và nghệ thuật.",
          "C": "Khả năng sinh văn bản dựa trên truy xuất thông tin (RAG), hỗ trợ đa ngôn ngữ và tự động hóa quy trình làm việc.",
          "D": "Độ chính xác trong việc nhận diện khuôn mặt và giọng nói."
        },
        "answer": "C"
      },
      {
        "question": "Anthropic cung cấp những gì để giúp các nhà phát triển xây dựng ứng dụng với Claude?",
        "options": {
          "A": "Một bộ công cụ phát triển phần mềm (SDK) hoàn chỉnh.",
          "B": "Một khóa học trực tuyến về lập trình AI.",
          "C": "Một bộ các dự án khởi đầu nhanh (quickstart projects) với hướng dẫn và tài nguyên.",
          "D": "Một chương trình tài trợ cho các dự án AI sáng tạo."
        },
        "answer": "C"
      },
      {
        "question": "YouTube đang phát triển những công cụ nào để phát hiện nội dung tổng hợp?",
        "options": {
          "A": "Công cụ nhận diện deepfake video và hình ảnh.",
          "B": "Công cụ phát hiện giọng hát tổng hợp và hình ảnh khuôn mặt được tạo bởi AI.",
          "C": "Công cụ kiểm tra đạo văn văn bản và hình ảnh.",
          "D": "Công cụ xác minh tính xác thực của tin tức và thông tin."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, điều gì khiến Hàn Quốc có tiềm năng trở thành một trung tâm AI mạnh mẽ?",
        "options": {
          "A": "Nguồn tài nguyên thiên nhiên phong phú.",
          "B": "Hệ sinh thái công nghệ địa phương, sự hỗ trợ của chính phủ và các cơ hội đa dạng trong nhiều ngành.",
          "C": "Chi phí lao động thấp và lực lượng lao động dồi dào.",
          "D": "Vị trí địa lý chiến lược và quan hệ đối tác quốc tế mạnh mẽ."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến nghiên cứu nào liên quan đến các mô hình ngôn ngữ lớn?",
        "options": {
          "A": "Nghiên cứu về khả năng tạo ra các câu chuyện hư cấu của các mô hình ngôn ngữ lớn.",
          "B": "Nghiên cứu xếp hạng các mô hình ngôn ngữ lớn dựa trên xu hướng tạo ra ảo giác (hallucination) trong quá trình truy xuất thông tin.",
          "C": "Nghiên cứu về khả năng dịch thuật của các mô hình ngôn ngữ lớn.",
          "D": "Nghiên cứu về tác động của các mô hình ngôn ngữ lớn đến thị trường lao động."
        },
        "answer": "B"
      },
      {
        "question": "Argentina đã thành lập cơ quan nào sử dụng AI?",
        "options": {
          "A": "Cơ quan quản lý dữ liệu quốc gia.",
          "B": "Cơ quan an ninh mạng quốc gia.",
          "C": "Cơ quan luật pháp quốc gia hỗ trợ bởi AI để phát hiện, điều tra và dự đoán tội phạm.",
          "D": "Cơ quan nghiên cứu và phát triển AI quốc gia."
        },
        "answer": "C"
      },
      {
        "question": "Công cụ mới nào được đề cập giúp các mô hình ngôn ngữ lớn dễ giải thích hơn?",
        "options": {
          "A": "Công cụ trực quan hóa dữ liệu đầu vào.",
          "B": "Công cụ phân tích cú pháp và ngữ nghĩa.",
          "C": "Công cụ thăm dò từng lớp của mô hình để hiểu cách nó hoạt động.",
          "D": "Công cụ tạo ra các giải thích bằng ngôn ngữ tự nhiên."
        },
        "answer": "C"
      }
    ]
  },
  "metas-got-a-brand-new-herd": {
    "title": "Meta’s got a brand new herd",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nMeta releases Llama 4 models, claiming superior performance\n\nMeta launched two new Llama 4 multimodal models, boasting performance improvements over previous generations and 10 million token context windows. Llama 4 Maverick, with 400 billion parameters, outperforms GPT-4o and matches DeepSeek v3.1 on several benchmarks, including MMMU and MathVista, with strong performance on MMLU-Pro’s reasoning tasks, GPQA Diamond’s expert-level knowledge, and LiveCodeBench coding tests. Meta’s team distilled both Maverick and Scout (a 109 billion parameter variant) from Llama 4 Behemoth, a not-yet-available 2 trillion parameter model that reportedly outperforms GPT-4.5 and other top models on STEM tasks. Developers can download Scout’s and Maverick’s weights from llama.com and Hugging Face, while Maverick costs an estimated $0.19-$0.495 per million tokens for inference. (Meta)\n\nGoogle’s Gemini 2.5 Pro introduces a price increase\n\nGoogle released API pricing for Gemini 2.5 Pro, charging $1.25 per million input tokens and $10 per million output tokens for prompts up to 200,000 tokens and $2.50/$15 per million input/output tokens for longer prompts. The new model costs more than Google’s other AI offerings or competing models from OpenAI and DeepSeek, but remains cheaper than Anthropic’s Claude 3.7 Sonnet and OpenAI’s GPT-4.5. Developers responded positively to the pricing, marking an industry trend of increasing costs for flagship models. Google CEO Sundar Pichai says Gemini 2.5 Pro has quickly become the company’s most in-demand AI model, driving an 80 percent increase in usage across Google’s AI platforms this month. (GoogleandTechCrunch)\n\nMicrosoft adds memory and personalization features to Copilot\n\nMicrosoft announced a major update to its Copilot AI assistant, introducing a “Memory” feature that allows the system to remember user preferences, interests, and personal details. Microsoft also unveiled several new capabilities including Actions (which can complete tasks like booking reservations), Copilot Vision for mobile devices, Pages for content organization, AI-generated podcasts, shopping features, and its own implementation of Deep Research. Microsoft emphasized that users maintain control over what information Copilot remembers and can opt out of memory features entirely. (Microsoft)\n\nMidjourney updates image generator with new Draft Mode\n\nMidjourney launched V7, a completely rebuilt version of its AI image generator, now available in alpha to all paid users on monthly or annual subscription plans that range from $8 to $120 per month. The new model significantly improves image consistency for hands, body parts, and objects while delivering more realistic textures for materials like skin wrinkles and ceramics, two areas that typically reveal limitations of AI-generated images. Midjourney V7 adds three new workflow modes: Draft Mode for rapid iteration at 10x speed and half the standard GPU time cost, Turbo Mode for faster final renders at double the standard price, and Relax Mode for slower generations at half price. The update comes as Midjourney faces multiple copyright lawsuits over its training practices, but the company maintains its position as one of the most widely used art generators for social media and video production. (Ars TechnicaandMidjourney)\n\nDevin relaunches its coding assistant with a major price drop\n\nCognition AI released Devin 2.0, an agentic IDE application that allows users to run multiple AI coding assistants simultaneously. The updated system features Interactive Planning, which automatically analyzes codebases and plans developer tasks, Devin Search for exploring code repositories, and Devin Wiki for automatic documentation generation. The company claims Devin 2.0 completes 83 percent more junior-level development tasks compared to its predecessor. But Devin now enters an increasingly crowded market where many competitors offer free tiers. Cognition significantly reduced subscription pricing to $20 per month (down from the previous $500), positioning the product more competitively against rivals like Cursor, GitHub Copilot, Windsurf, and AWS Developer Q. (Cognition)\n\nGoogle introduces specialized cybersecurity model\n\nGoogle announced Sec-Gemini v1, an experimental AI model designed specifically for cybersecurity applications. The model combines Gemini’s reasoning capabilities with near real-time cybersecurity knowledge and tooling to help security professionals analyze incidents, assess threats, and understand vulnerability impacts. Sec-Gemini v1 outperforms other models on key cybersecurity benchmarks, scoring at least 11 percent higher on the CTI-MCQ threat intelligence benchmark and 10.5 percent better on the CTI-Root Cause Mapping benchmark than leading (albeit nonspecialized) OpenAI and Anthropic models. Google is making Sec-Gemini v1 freely available to select organizations, institutions, professionals, and NGOs for research purposes, as developers emphasized that advancing AI cybersecurity requires strong collaboration across the security community. (Google)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng shared his approach to “lazy prompting”—a technique where you start with minimal extra input and refine only as needed.\n\n“Laziness is a good technique only when you’ve learned how to provide enough context, and then deliberately step back to see how little context you can get away with and still have it work.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:MoshiVis introduced interactive voice-to-voice conversationsenhanced with image understanding;Cloudflare unveiled an AI-powered defense systemcalled Labyrinth that thwarts web scrapers using decoy pages; new studies revealed that whileChatGPT may help reduce feelings of loneliness, it can also lead to emotional dependence; and Stanford researchers developeda method to animate 3D interactionsbetween humans and objects using generated video, eliminating the need for motion capture.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Theo bài viết, Meta đã phát hành những mô hình Llama 4 nào?",
        "options": {
          "A": "Llama 4 Behemoth và Llama 4 GPT",
          "B": "Llama 4 Maverick và Llama 4 Scout",
          "C": "Llama 4 Pro và Llama 4 Max",
          "D": "Llama 4 Alpha và Llama 4 Beta"
        },
        "answer": "B"
      },
      {
        "question": "Mức giá cho mỗi triệu token đầu vào của Gemini 2.5 Pro (cho prompts lên đến 200,000 tokens) là bao nhiêu?",
        "options": {
          "A": "$2.50",
          "B": "$1.25",
          "C": "$10.00",
          "D": "$15.00"
        },
        "answer": "B"
      },
      {
        "question": "Tính năng mới nào của Copilot cho phép hệ thống ghi nhớ sở thích và thông tin cá nhân của người dùng?",
        "options": {
          "A": "Actions",
          "B": "Copilot Vision",
          "C": "Memory",
          "D": "Pages"
        },
        "answer": "C"
      },
      {
        "question": "Chế độ nào trong Midjourney V7 cho phép tạo ảnh nhanh chóng với chi phí GPU giảm một nửa?",
        "options": {
          "A": "Turbo Mode",
          "B": "Relax Mode",
          "C": "Draft Mode",
          "D": "Standard Mode"
        },
        "answer": "C"
      },
      {
        "question": "Devin 2.0 có tính năng nào giúp phân tích codebases và lên kế hoạch cho các tác vụ phát triển?",
        "options": {
          "A": "Devin Search",
          "B": "Interactive Planning",
          "C": "Devin Wiki",
          "D": "Automatic Documentation"
        },
        "answer": "B"
      },
      {
        "question": "Sec-Gemini v1 được thiết kế đặc biệt cho lĩnh vực nào?",
        "options": {
          "A": "Phát triển ứng dụng di động",
          "B": "An ninh mạng",
          "C": "Xử lý ngôn ngữ tự nhiên",
          "D": "Tạo sinh hình ảnh"
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, kỹ thuật 'lazy prompting' nên được áp dụng khi nào?",
        "options": {
          "A": "Khi mới bắt đầu sử dụng AI",
          "B": "Khi cần tiết kiệm chi phí",
          "C": "Khi đã nắm vững cách cung cấp đủ ngữ cảnh",
          "D": "Khi không có nhiều thời gian"
        },
        "answer": "C"
      },
      {
        "question": "Công ty nào đã giới thiệu hệ thống phòng thủ dựa trên AI có tên Labyrinth để chống lại web scrapers?",
        "options": {
          "A": "MoshiVis",
          "B": "Cloudflare",
          "C": "Stanford",
          "D": "OpenAI"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, Gemini 2.5 Pro đã thúc đẩy mức tăng trưởng sử dụng trên các nền tảng AI của Google là bao nhiêu?",
        "options": {
          "A": "50%",
          "B": "60%",
          "C": "70%",
          "D": "80%"
        },
        "answer": "D"
      },
      {
        "question": "Mô hình Llama 4 Maverick có bao nhiêu tham số?",
        "options": {
          "A": "109 tỷ",
          "B": "2 nghìn tỷ",
          "C": "400 tỷ",
          "D": "10 triệu"
        },
        "answer": "C"
      }
    ]
  },
  "microsoft-builds-a-generative-world-action-model": {
    "title": "Microsoft builds a generative world-action model",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nMicrosoft unveils Muse, a generative AI model for video games\n\nMicrosoft Research introduced Muse, a World and Human Action Model (WHAM) that can generate game visuals and controller actions for video games. Trained on over one billion images and controller actions from the Xbox game Bleeding Edge, Muse shows strong consistency, diversity, and persistence when generating gameplay sequences. Microsoft is making Muse’s weights, sample data, and a demonstrator tool open source to help researchers explore and build upon this technology for creative applications in game development. Microsoft claims Muse is the first generative joint world-action model that can generate complete game dynamics, including video and controller actions that can respond to one another. (Microsoft ResearchandNature)\n\nPerplexity remakes DeepSeek-R1 reasoning model\n\nPerplexity released R1 1776, an open weight, MIT-licensed version of the DeepSeek-R1 model fine-tuned to provide accurate information on topics censored by the Chinese government. The company used a dataset of 40,000 prompts and detailed answers about sensitive topics to retrain the model, aiming to maintain its chain-of-thought reasoning capabilities while removing built-in censorship. This release (on Hugging Face and Perplexity’s Sonar API) allows developers to access a powerful open-source language model that can engage with a broader range of topics without political restrictions. (Perplexity)\n\nLLaDA challenges autoregressive models as foundation for large language models\n\nResearchers at Renmin University of China introduced LLaDA, a diffusion model trained to generate tokens in a nonlinear sequence that achieves performance similar to top autoregressive language models. LLaDA uses a masked diffusion approach and demonstrates strong scalability, in-context learning, and instruction-following (after supervised fine-tuning). The 8 billion parameter model outperformed GPT-4 on a reversal reasoning task and showed promise in areas like multi-turn dialogue generation. This work establishes diffusion models as a viable alternative to autoregressive ones, offering unique advantages like bidirectional modeling and consistent performance on both forward and reverse tasks without sacrificing general language understanding. (GitHubandarXiv)\n\nGoogle’s co-scientist hopes to accelerate scientific discoveries\n\nGoogle introduced an AI co-scientist system built with Gemini 2.0, designed to generate novel research hypotheses from natural language prompts across multiple scientific domains. The system uses specialized AI agents to iteratively refine ideas through processes modeled on the scientific method, including hypothesis generation, ranking, and evolution. Google’s co-scientist outperforms other models on complex research goals as rated by domain experts, and preliminary laboratory experiments validated some of the AI co-scientist’s novel predictions in areas like drug repurposing and antimicrobial resistance. Future versions may add improved literature reviews, factuality checking, cross-checks with external tools, and other tools. (Google Research)\n\nSmolVLM2 updates small, efficient video understanding models\n\nResearchers at Stanford and elsewhere released SmolVLM2, an updated family of compact but powerful video language models in 2.2 billion, 500 million, and 256 million parameter sizes. The models can run on devices from phones to servers and perform well on benchmarks like Video-MME while using less memory than larger models. The team demonstrated SmolVLM2’s capabilities through applications like an iPhone app for local video analysis, VLC media player integration for semantic video navigation, and a video highlight generator. These models could enable new vision applications for a wide range of low-resource devices, potentially transforming how we use local models to interact with and analyze video content. (Hugging Face)\n\nHP buys Humane’s AI tech as ambitious wearable device flops\n\nHumane, a start-up that created the Ai Pin wearable device, agreed to sell its AI capabilities, software platform, and intellectual property to HP for $116 million, a number substantially smaller than it raised. The Ai Pin, which aimed to replace smartphones with a clip-on device controlled by voice commands and laser projections, failed to meet sales expectations and faced criticism for performance issues. HP plans to integrate Humane’s technology into its products, focusing on building an “intelligent ecosystem” and enhancing its AI-powered capabilities across its lineup of computers and services. (Axios)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng shared a powerful story about how AI saved a police officer’s life, highlighting the impact of Skyfire AI’s drone technology in emergency response.\n\n“Fortunately, because the drone had pinpointed the location of the officer and his assailant, dispatch was able to direct additional units to assist. The first arrived not in 5-7 minutes but in 45 seconds.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:xAI unveiled Grok 3, a new model family trained at scales beyond its predecessors;Replit updated its  mobile appto enable full app development using its AI agent;Elon Musk’s $97.4 billion bid for OpenAI was rejected, intensifying the power struggle between companies; and global leaders at the latest AI summit showed theirdeep divisions over regulation and governance.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mục đích chính của mô hình Muse do Microsoft Research giới thiệu là gì?",
        "options": {
          "A": "Tạo ra các đoạn video quảng cáo cho game.",
          "B": "Tạo ra hình ảnh và hành động điều khiển cho trò chơi điện tử.",
          "C": "Phân tích dữ liệu người chơi trong game.",
          "D": "Tối ưu hóa hiệu suất của các trò chơi điện tử."
        },
        "answer": "B"
      },
      {
        "question": "Perplexity đã làm gì với mô hình DeepSeek-R1?",
        "options": {
          "A": "Tăng cường khả năng dịch thuật của mô hình.",
          "B": "Tinh chỉnh mô hình để cung cấp thông tin chính xác về các chủ đề bị kiểm duyệt.",
          "C": "Giảm kích thước mô hình để chạy trên các thiết bị di động.",
          "D": "Tích hợp mô hình vào công cụ tìm kiếm của họ."
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm chính của mô hình LLaDA so với các mô hình ngôn ngữ tự hồi quy là gì?",
        "options": {
          "A": "Khả năng xử lý ngôn ngữ tự nhiên tốt hơn.",
          "B": "Khả năng mô hình hóa hai chiều và hiệu suất nhất quán trên cả tác vụ xuôi và ngược.",
          "C": "Yêu cầu ít dữ liệu huấn luyện hơn.",
          "D": "Khả năng tạo ra văn bản dài mạch lạc hơn."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống 'co-scientist' của Google được thiết kế để làm gì?",
        "options": {
          "A": "Tự động viết báo cáo khoa học.",
          "B": "Tạo ra các giả thuyết nghiên cứu mới từ các câu lệnh ngôn ngữ tự nhiên.",
          "C": "Phân tích dữ liệu thí nghiệm khoa học.",
          "D": "Dịch các bài báo khoa học sang nhiều ngôn ngữ."
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng tiềm năng nào của SmolVLM2 được đề cập trong bài viết?",
        "options": {
          "A": "Tạo ra các hiệu ứng đặc biệt cho phim.",
          "B": "Phân tích video cục bộ trên iPhone.",
          "C": "Điều khiển robot từ xa.",
          "D": "Tạo ra các trò chơi thực tế ảo."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao Humane lại bán công nghệ AI của mình cho HP?",
        "options": {
          "A": "Do thiếu vốn để tiếp tục phát triển.",
          "B": "Do Ai Pin không đạt được kỳ vọng về doanh số và gặp vấn đề về hiệu suất.",
          "C": "Do HP đưa ra một lời đề nghị quá hấp dẫn.",
          "D": "Do Humane muốn tập trung vào các lĩnh vực kinh doanh khác."
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ drone của Skyfire AI đã giúp ích gì trong câu chuyện được Andrew Ng chia sẻ?",
        "options": {
          "A": "Cung cấp hình ảnh rõ nét về hiện trường vụ án.",
          "B": "Xác định chính xác vị trí của cảnh sát và kẻ tấn công, giúp điều động lực lượng hỗ trợ nhanh chóng.",
          "C": "Ghi lại bằng chứng video cho phiên tòa.",
          "D": "Ngăn chặn kẻ tấn công trốn thoát."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã xảy ra với lời đề nghị trị giá 97,4 tỷ đô la của Elon Musk dành cho OpenAI?",
        "options": {
          "A": "Đã được chấp nhận và Elon Musk trở thành CEO của OpenAI.",
          "B": "Đã bị từ chối, làm gia tăng cuộc tranh giành quyền lực giữa các công ty.",
          "C": "Vẫn đang được xem xét bởi hội đồng quản trị của OpenAI.",
          "D": "Đã được sửa đổi và chấp nhận với một mức giá thấp hơn."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của HP khi mua lại công nghệ AI của Humane là gì?",
        "options": {
          "A": "Phát triển một hệ điều hành mới cho máy tính.",
          "B": "Xây dựng một 'hệ sinh thái thông minh' và tăng cường khả năng hỗ trợ AI cho các sản phẩm của mình.",
          "C": "Cạnh tranh trực tiếp với Apple trong thị trường thiết bị đeo.",
          "D": "Tạo ra một trợ lý ảo cá nhân cho người dùng máy tính."
        },
        "answer": "B"
      },
      {
        "question": "Grok 3 của xAI có đặc điểm gì nổi bật?",
        "options": {
          "A": "Khả năng tạo ra âm nhạc chất lượng cao.",
          "B": "Được huấn luyện ở quy mô lớn hơn so với các phiên bản trước.",
          "C": "Khả năng dịch thuật chính xác hơn.",
          "D": "Tiêu thụ ít năng lượng hơn."
        },
        "answer": "B"
      }
    ]
  },
  "microsoft-delays-recall": {
    "title": "Microsoft delays Recall",
    "collection": "data-points",
    "content": "This week’s top AI stories include:\n\n•             Personalized image generation•             A second look at the MMLU benchmark•             A new method to reduce LLM hallucinations•             A closer look inside Apple’s AI cloud security\n\nMicrosoft delays Recall feature for new Copilot Plus PCsInstead of launching the feature with the new PCs, Microsoft will use the Windows Insider software preview community to thoroughly test Recall and ensure it meets quality and security standards before making it widely available. Recall employs on-device AI models integrated into Windows 11 to capture screenshots of nearly all user activities and provide a searchable database for users to find previously viewed content. However, initial versions of the database stored the material in insecure plaintext, raising concerns from privacy advocates and security experts about potential cybersecurity risks associated with the feature. (The Verge)\n\nMLCommons announces MLPerf Training v4.0 results with new benchmarksThe MLPerf suite introduces two new benchmarks: LoRA fine-tuning of LLama 2 70B and a graph neural network (GNN) benchmark for node classification. The LoRA benchmark measures techniques to reduce computational costs for fine-tuning large language models, while the GNN benchmark measures performance on graph-structured data used in social network analysis, fraud detection, and other applications. Unsurprisingly, Nvidia’s H100 chips lead 205 performance results from 17 organizations, with Google’s TPUs just behind. (MLCommons)\n\nMMLU-Redux: Identifying and correcting errors in the MMLU datasetResearchers identified numerous errors in the popular Massive Multitask Language Understanding (MMLU) benchmark dataset, which is used to evaluate the performance of Large Language Models (LLMs). To correct these errors, they manually re-annotated 3,000 questions across 30 subsets of MMLU, creating MMLU-Redux. The re-evaluation of leading LLMs using MMLU-Redux revealed notable changes in their performance metrics and rankings, highlighting the impact of dataset errors on model evaluation. Correcting the virology subset produced the largest changes in the metrics, with many models going from 50 percent accuracy to over 90 percent accuracy, and the Palmyra X v3 model going from fourth place to first. (ArXiv)\n\nLamini introduces Memory Tuning to reduce hallucinations and improve factual accuracyBy tuning millions of expert LoRA adapters with precise facts on top of open-source LLMs, memory tuning enabled 95% accuracy on critical use cases where previous approaches peaked at 50%. The resulting sparsely activated Mixture of Memory Experts (MoME) model allows for an extremely high number of parameters and facts to be learned, while keeping computational cost fixed at inference time. This method allows companies to automate tasks with higher precision, lower costs, and faster development cycles compared to traditional fine-tuning methods. (Lamini)\n\nMidjourney adds personalized image generationMidjourney now allows users to create personalized images by ranking image pairs on its website. By adding the --p or --personalize parameter to prompts, the AI will generate images tailored to the user’s preferences as determined by their pair rankings. Users can apply their own personalization by default or use another user’s by including their shortcode, and adjust the amount of personalization with the --stylize parameter. Personalization continues a trend in AI development enabling a personal or house-defined style for automatically generated content. (Midjourney)\n\nApple unveils Private Cloud Compute for secure cloud-based AIPrivate Cloud Compute (PCC) processes user data in the cloud without exposing it to anyone, including Apple, and deletes the data after completing the task. The system uses custom hardware, a hardened operating system, and various security measures to protect user data and enable independent security researchers to verify its privacy claims. Apple plans to make PCC software images publicly available for security research within 90 days of inclusion in their transparency log, allowing researchers to inspect the software, verify its functionality, and identify potential issues. Apple clearly aims to compete in AI on cloud security and user privacy; it remains to be seen how other technology companies will respond. (Apple)\n\nStill want to know more about what matters in AI right now?\n\nIf you missed it, readlast week’s issueof The Batch for in-depth analysis of news and research.\n\nThis week, Andrew Ng discussed agentic design and inclusive work in the AI community:\n\n“More and more people are building systems that prompt a large language model multiple times using agent-like design patterns. But there’s a gray zone between what clearly is not an agent (prompting a model once) and what clearly is (say, an autonomous agent that, given high-level instructions, plans, uses tools, and carries out multiple, iterative steps of processing). Rather than arguing over which work to include or exclude as being a true agent, we can acknowledge that there are different degrees to which systems can be agentic. Then we can more easily include everyone who wants to work on agentic systems.”\n\nRead Andrew's full letterhere.\n\nOther top AI news and research stories we covered in depth included everything aboutApple’s Gen AI strategy, Stability AI'senhanced text-to-audio generator, the results from theAI Seoul Summit and the AI Global Forum, and Google'sAMIE, a chatbot that outperformed doctors in diagnostic conversations.",
    "qa": [
      {
        "question": "Tính năng Recall của Microsoft bị trì hoãn vì lý do gì?",
        "options": {
          "A": "Do thiếu hụt chip AI cần thiết để vận hành.",
          "B": "Do lo ngại về bảo mật và quyền riêng tư liên quan đến việc lưu trữ dữ liệu.",
          "C": "Do phản hồi tiêu cực từ người dùng về giao diện.",
          "D": "Do chưa tích hợp được với các ứng dụng của bên thứ ba."
        },
        "answer": "B"
      },
      {
        "question": "MLCommons MLPerf Training v4.0 giới thiệu những benchmark mới nào?",
        "options": {
          "A": "Đánh giá khả năng xử lý ngôn ngữ tự nhiên và thị giác máy tính.",
          "B": "Đánh giá khả năng fine-tuning LoRA của LLama 2 70B và benchmark mạng nơ-ron đồ thị (GNN).",
          "C": "Đánh giá hiệu suất của các mô hình AI trên các thiết bị di động.",
          "D": "Đánh giá khả năng tạo sinh ảnh và video từ văn bản."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích của việc tạo ra MMLU-Redux là gì?",
        "options": {
          "A": "Để tăng kích thước của bộ dữ liệu MMLU.",
          "B": "Để đơn giản hóa bộ dữ liệu MMLU cho các mô hình nhỏ hơn.",
          "C": "Để xác định và sửa lỗi trong bộ dữ liệu MMLU.",
          "D": "Để tạo ra một phiên bản đa ngôn ngữ của bộ dữ liệu MMLU."
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp Memory Tuning của Lamini giúp cải thiện điều gì?",
        "options": {
          "A": "Tăng tốc độ huấn luyện mô hình.",
          "B": "Giảm chi phí phần cứng cần thiết để chạy mô hình.",
          "C": "Giảm ảo giác và cải thiện độ chính xác về mặt thực tế của LLM.",
          "D": "Tăng khả năng xử lý đa ngôn ngữ của LLM."
        },
        "answer": "C"
      },
      {
        "question": "Người dùng có thể cá nhân hóa hình ảnh được tạo bởi Midjourney bằng cách nào?",
        "options": {
          "A": "Bằng cách cung cấp một mô tả chi tiết về phong cách mong muốn.",
          "B": "Bằng cách xếp hạng các cặp hình ảnh trên trang web của Midjourney.",
          "C": "Bằng cách tải lên hình ảnh tham khảo để Midjourney học theo.",
          "D": "Bằng cách điều chỉnh các thông số kỹ thuật của mô hình AI."
        },
        "answer": "B"
      },
      {
        "question": "Private Cloud Compute (PCC) của Apple đảm bảo an toàn dữ liệu người dùng bằng cách nào?",
        "options": {
          "A": "Bằng cách mã hóa dữ liệu trước khi tải lên đám mây.",
          "B": "Bằng cách xử lý dữ liệu trên đám mây mà không ai, kể cả Apple, có thể truy cập và xóa dữ liệu sau khi hoàn thành.",
          "C": "Bằng cách lưu trữ dữ liệu trên các máy chủ đặt tại các quốc gia có luật bảo mật nghiêm ngặt.",
          "D": "Bằng cách yêu cầu người dùng xác thực hai yếu tố trước khi truy cập dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, điểm khác biệt giữa một hệ thống AI đơn giản và một hệ thống AI 'agentic' là gì?",
        "options": {
          "A": "Hệ thống agentic có khả năng tự học hỏi và cải thiện hiệu suất.",
          "B": "Hệ thống agentic có khả năng tương tác với người dùng bằng ngôn ngữ tự nhiên.",
          "C": "Hệ thống agentic có khả năng được nhắc nhiều lần để thực hiện các bước xử lý lặp đi lặp lại.",
          "D": "Hệ thống agentic có khả năng tạo ra nội dung sáng tạo như thơ ca và âm nhạc."
        },
        "answer": "C"
      },
      {
        "question": "Công cụ nào của Google đã vượt trội hơn các bác sĩ trong các cuộc trò chuyện chẩn đoán?",
        "options": {
          "A": "Bard",
          "B": "LaMDA",
          "C": "AMIE",
          "D": "Gemini"
        },
        "answer": "C"
      },
      {
        "question": "MLPerf sử dụng benchmark LoRA để đo lường điều gì?",
        "options": {
          "A": "Khả năng tạo sinh hình ảnh chất lượng cao.",
          "B": "Kỹ thuật giảm chi phí tính toán cho việc tinh chỉnh các mô hình ngôn ngữ lớn.",
          "C": "Hiệu suất của các mô hình trên các thiết bị di động.",
          "D": "Khả năng dịch thuật giữa các ngôn ngữ khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Trong MMLU-Redux, việc sửa lỗi ở tập con nào đã tạo ra sự thay đổi lớn nhất trong các chỉ số đánh giá?",
        "options": {
          "A": "Toán học",
          "B": "Lịch sử",
          "C": "Vi sinh vật học",
          "D": "Vật lý"
        },
        "answer": "C"
      }
    ]
  },
  "microsofts-phi-4-proves-ai-power-isnt-just-about-size": {
    "title": "Microsoft’s Phi-4 proves AI power isn’t just about size",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nMicrosoft’s Phi-4 (14B) outperforms Llama 3.3 (70B) at math and code\n\nMicrosoft introduced Phi-4, a 14 billion parameter language model that demonstrates exceptional reasoning abilities, particularly in mathematics and coding. Despite its relatively small size, the model outperforms larger competitors, including GPT-4 and Llama 3.3 70B, on graduate-level STEM questions and math competition problems. Phi-4’s success stems from innovative approaches to synthetic data generation, optimized training curricula, and advanced post-training techniques. The model’s performance shows that carefully curated data can lead smaller, more efficient AI models to rival or surpass larger language models in specialized tasks. (MicrosoftandarXiv)\n\nChatGPT gets organizational and collaborative boost with Projects and Canvas\n\nOpenAI introduced two significant updates to ChatGPT: Projects and Canvas. Projects allows users to organize conversations, files, and data within themed spaces, streamlining workflows for tasks like website development or screenplay writing. Canvas, a side-by-side interface, enhances collaborative writing and coding with features like integrated Python execution, custom GPTs, and advanced editing tools. Both additions address user frustrations with conversation management and workflow organization, potentially transforming how AI developers and frequent ChatGPT users interact with the platform for complex tasks. These features represent OpenAI’s efforts to make ChatGPT a more powerful and versatile tool for creative and technical collaborations. (OpenAI)\n\nGoogle revamps NotebookLM with new features and paid subscription version\n\nGoogle rolled out significant updates to NotebookLM, its AI-powered research assistant, including a redesigned interface, interactive Audio Overviews, and a premium subscription called NotebookLM Plus. The new interface organizes content into three panels for sources, chat, and content generation, while the interactive Audio Overviews allow users to engage directly with AI hosts using voice commands. NotebookLM Plus offers higher usage limits, customization options, and enterprise-grade features for organizations, signaling Google’s push to monetize and expand its AI productivity offerings. (Google)\n\nMeta unveils humanoid AI agent for complex task performance\n\nMeta released Meta Motivo, a behavioral foundation model that controls a virtual humanoid agent to perform complex tasks without additional training. The model uses a novel algorithm that leverages unlabeled motion data to ground unsupervised reinforcement learning towards human-like behaviors while maintaining zero-shot inference capabilities. Meta Motivo’s ability to solve a wide range of whole-body control tasks and its robustness to environmental changes could lead to more lifelike non-player characters and new immersive experiences in virtual environments. (Meta AI)\n\nSynthetic data generator simplifies AI dataset creation\n\nDevelopers at Argilla introduced a no-code tool that allows users to create custom synthetic datasets using large language models. The application supports text classification and chat datasets, generating samples at a rate of 50 and 20 per minute respectively using the free Hugging Face API. This tool streamlines the process of creating training data for AI models, potentially accelerating development cycles for AI researchers and companies building language models. (Hugging Face)\n\nTop AI conference faces ethical dilemma over best paper award\n\nKeyu Tian, lead author of one of two best papers at NeurIPS 2024, allegedly sabotaged colleagues’ research projects during an internship at ByteDance. A protest letter posted on GitHub details Tian’s misconduct, including modifying code, disrupting experiments, and illegally accessing company resources to advance his own work. (ByteDance terminated Tian’s internship when his behavior was discovered this fall.) This situation raises questions about academic integrity and the values promoted by recognizing valuable research when it’s potentially tainted by unethical behavior. (GitHub)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng shared emerging best practices for AI Product Management, including starting with concrete examples, assessing technical feasibility through prompting, and managers rapidly building prototypes without involving engineers.\n\n“AI is enabling a lot of new applications to be built, creating massive growth in demand for AI product managers who know how to scope out and help drive progress in building these products. AI product management existed before the rise of generative AI, but the increasing ease of building applications is creating greater demand.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: Amazon unveiled Nova models for text, image, and video, offeringcompetitive performance at competitive prices; OpenAI introduced an updatedo1 and o1 pro mode for advanced reasoning, available in a new plan called GPTPro, priced at $200/month; Googlelaunched Genie 2, bringing interactive 3D worlds to life; andresearchers at Lamini proposed a memory methoddesigned to reduce hallucinations in large language models, enhancing factual accuracy.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mô hình Phi-4 của Microsoft có bao nhiêu tham số và nó thể hiện khả năng vượt trội trong lĩnh vực nào?",
        "options": {
          "A": "70 tỷ tham số, vượt trội trong xử lý ngôn ngữ tự nhiên.",
          "B": "14 tỷ tham số, vượt trội trong toán học và lập trình.",
          "C": "14 tỷ tham số, vượt trội trong xử lý hình ảnh và video.",
          "D": "70 tỷ tham số, vượt trội trong toán học và lập trình."
        },
        "answer": "B"
      },
      {
        "question": "Hai cập nhật mới nào của ChatGPT được giới thiệu để cải thiện khả năng tổ chức và cộng tác?",
        "options": {
          "A": "Projects và GPTPro.",
          "B": "Canvas và GPTPro.",
          "C": "Projects và Canvas.",
          "D": "Projects và NotebookLM."
        },
        "answer": "C"
      },
      {
        "question": "NotebookLM Plus của Google cung cấp những lợi ích chính nào so với phiên bản thông thường?",
        "options": {
          "A": "Giao diện được thiết kế lại và Audio Overviews tương tác.",
          "B": "Giới hạn sử dụng cao hơn, tùy chỉnh và các tính năng cấp doanh nghiệp.",
          "C": "Khả năng tạo thế giới 3D tương tác.",
          "D": "Tích hợp Python và các công cụ chỉnh sửa nâng cao."
        },
        "answer": "B"
      },
      {
        "question": "Meta Motivo là gì và nó được sử dụng để làm gì?",
        "options": {
          "A": "Một công cụ tạo dữ liệu tổng hợp.",
          "B": "Một mô hình nền tảng hành vi điều khiển một tác nhân hình người ảo để thực hiện các nhiệm vụ phức tạp.",
          "C": "Một mô hình ngôn ngữ lớn cạnh tranh với GPT-4.",
          "D": "Một phương pháp giảm ảo giác trong các mô hình ngôn ngữ lớn."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ của Argilla giúp đơn giản hóa quá trình gì trong phát triển AI?",
        "options": {
          "A": "Tối ưu hóa mô hình ngôn ngữ lớn.",
          "B": "Tạo dữ liệu tổng hợp tùy chỉnh.",
          "C": "Phân tích dữ liệu người dùng.",
          "D": "Triển khai mô hình AI lên đám mây."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề đạo đức nào đang được đặt ra liên quan đến một trong những bài báo hay nhất tại NeurIPS 2024?",
        "options": {
          "A": "Sử dụng dữ liệu cá nhân mà không được phép.",
          "B": "Đạo văn từ các nghiên cứu khác.",
          "C": "Phá hoại các dự án nghiên cứu của đồng nghiệp.",
          "D": "Thiếu minh bạch trong phương pháp nghiên cứu."
        },
        "answer": "C"
      },
      {
        "question": "Theo Andrew Ng, một trong những phương pháp tốt nhất cho quản lý sản phẩm AI là gì?",
        "options": {
          "A": "Bắt đầu với các ví dụ cụ thể.",
          "B": "Sử dụng các kỹ sư để xây dựng nguyên mẫu nhanh chóng.",
          "C": "Tập trung vào việc thu thập dữ liệu lớn.",
          "D": "Xây dựng mô hình phức tạp ngay từ đầu."
        },
        "answer": "A"
      },
      {
        "question": "Amazon đã giới thiệu dòng mô hình Nova cho những loại dữ liệu nào?",
        "options": {
          "A": "Chỉ văn bản.",
          "B": "Văn bản và hình ảnh.",
          "C": "Văn bản, hình ảnh và video.",
          "D": "Chỉ hình ảnh và video."
        },
        "answer": "C"
      },
      {
        "question": "OpenAI đã giới thiệu phiên bản cập nhật nào cho khả năng suy luận nâng cao và nó có giá bao nhiêu?",
        "options": {
          "A": "o1, giá $20/tháng.",
          "B": "o1 pro, giá $20/tháng.",
          "C": "o1 và o1 pro, giá $200/tháng.",
          "D": "GPTPro, giá $200/tháng."
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu chính của phương pháp bộ nhớ được đề xuất bởi các nhà nghiên cứu tại Lamini là gì?",
        "options": {
          "A": "Tăng tốc độ xử lý của mô hình.",
          "B": "Giảm ảo giác và tăng độ chính xác về mặt thực tế.",
          "C": "Tăng khả năng sáng tạo của mô hình.",
          "D": "Giảm chi phí đào tạo mô hình."
        },
        "answer": "B"
      }
    ]
  },
  "mistral-unveils-most-capable-model-yet": {
    "title": "Mistral unveils most capable model yet",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nA newer, bigger model from MistralMistral AI released Mistral Large 2, a 123 billion parameter language model with a 128,000 token context window supporting dozens of languages and 80+ coding languages. The company claims Mistral Large 2 “sets a new frontier in terms of performance / cost of serving on evaluation metrics,” achieving 84% accuracy on MMLU in its pretrained version, putting it somewhere between Claude 3 Sonnet and GPT-4. The company also announced that it would be deprecating older models on its platform to focus on NeMo, Large, Codestral, and Embed. Mistral Large 2 is available on Mistral’s platform and through major cloud providers, with different licensing options for research, non-commercial, and commercial use. (Mistral)\n\nUdio 1.5 gives users more musical controlUdio’s latest update introduces stem downloads, allowing users to separate tracks into vocals, bass, drums, and other elements for advanced mixing and remixing. The new audio-to-audio feature enables users to upload and reimagine their own tracks using AI, while key control lets creators specify musical keys in their prompts for more precise harmonic results. These tools give music makers more control over AI-generated compositions, opening up new creative possibilities for both amateurs and professionals. (Udio)\n\nDeepSeek-V2 code released under permissive licenseDeepSeek changed the license for DeepSeek-V2, a 236 billion parameter mixture-of-experts language model that achieves strong performance while reducing training costs by 42.5% compared to its predecessor. The model uses novel attention and feed-forward network architectures to enable economical training and fast generation, outperforming many leading models on benchmarks across English, Chinese, coding, and math tasks. DeepSeek-V2 is released under a custom license that allows for commercial use, with the code repository licensed under the MIT License. The company offers API access to the model through its platform, providing millions of free tokens to new users and a pay-as-you-go option at 14 cents per million input tokens and 28 cents per million output tokens. (Hugging Face)\n\nStable Video 4D opens up generative video researchStability AI introduced Stable Video 4D, a new AI model that transforms a single object video into eight different novel-view videos. Users upload a single video and specify desired 3D camera poses. The model then generates eight novel-view videos from different perspectives based on those specifications. It can produce 5-frame videos across 8 views in about 40 seconds. The model aims to improve consistency across spatial and temporal axes compared to previous approaches. Stable Video 4D is currently available on Hugging Face for researchers and developers to experiment with, but the model is still in a research phase, with ongoing work to refine its capabilities. (Stability AI)\n\nDocument leak says Runway trained its video model on YouTubeVideo generation company Runway may have secretly scraped thousands of YouTube videos and pirated content to train its Gen-3 model. An internal spreadsheet obtained by 404 Media reveals the company collected videos from popular YouTube channels, influencers, and media companies without their knowledge or consent. This news gives insight into how Runway’s model was trained, but also raises significant questions about ethical data collection practices, particularly as Google has previously stated that such scraping violates YouTube’s terms of service. (404 Media)\n\nMicrosoft introduces serverless fine-tuning and endpoints for Phi model familyMicrosoft announced significant updates to its Phi-3 family of small language models, including serverless fine-tuning capabilities for Phi-3-mini and Phi-3-medium. The company also made Phi-3-small available via a serverless endpoint, allowing developers to quickly build AI applications without managing infrastructure. These enhancements, along with improvements to Phi-3-mini’s performance in areas like instruction-following and structured output, aim to make AI development more efficient and accessible for a wide range of cloud and edge scenarios. (Microsoft Azure)\n\nStill want to know more about what matters in AI right now?Readlast week’s issueof The Batch for in-depth analysis of news and research.\n\nThis week, Andrew Ng shared his thoughts on why AI startups may want to begin by imagining a concrete product to test rather than a general problem to solve:\n\n“If you are thinking about starting a new AI project, consider whether you can come up with a concrete vision to execute toward. Even if the initial vision turns out not to be quite right, rapid iteration will let you discover this sooner, and the learnings will let you switch to a different concrete idea.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: All about OpenAI's GPT4-o mini,Meta's restrictionof their multimodal models in the EU, why investors arestockpiling AI chipsto attract startups, andVASA-1, a generative system that produces a talking-head video with appropriately expressive motion.",
    "qa": [
      {
        "question": "Mistral Large 2 đạt độ chính xác bao nhiêu trên MMLU trong phiên bản pretrained của nó?",
        "options": {
          "A": "74%",
          "B": "84%",
          "C": "94%",
          "D": "64%"
        },
        "answer": "B"
      },
      {
        "question": "Udio 1.5 cho phép người dùng tải xuống những thành phần âm thanh nào để trộn và phối lại?",
        "options": {
          "A": "Giai điệu, hòa âm, hiệu ứng",
          "B": "Giọng hát, bass, trống, các yếu tố khác",
          "C": "Nhịp điệu, tempo, âm lượng",
          "D": "Tiếng vang, độ trễ, biến dạng"
        },
        "answer": "B"
      },
      {
        "question": "DeepSeek-V2 giảm chi phí đào tạo bao nhiêu so với phiên bản tiền nhiệm?",
        "options": {
          "A": "32.5%",
          "B": "42.5%",
          "C": "52.5%",
          "D": "62.5%"
        },
        "answer": "B"
      },
      {
        "question": "Stable Video 4D tạo ra bao nhiêu video từ các góc nhìn khác nhau từ một video đầu vào?",
        "options": {
          "A": "4",
          "B": "6",
          "C": "8",
          "D": "10"
        },
        "answer": "C"
      },
      {
        "question": "Theo 404 Media, Runway có thể đã sử dụng nguồn dữ liệu nào để huấn luyện mô hình Gen-3 của mình?",
        "options": {
          "A": "Dữ liệu tổng hợp từ các trang web thương mại điện tử",
          "B": "Video từ YouTube thu thập trái phép",
          "C": "Hình ảnh từ các thư viện ảnh trực tuyến",
          "D": "Dữ liệu âm thanh từ các nền tảng phát nhạc"
        },
        "answer": "B"
      },
      {
        "question": "Microsoft đã cung cấp khả năng fine-tuning serverless cho những mô hình nào thuộc họ Phi-3?",
        "options": {
          "A": "Phi-3-nano và Phi-3-small",
          "B": "Phi-3-mini và Phi-3-medium",
          "C": "Phi-3-small và Phi-3-large",
          "D": "Phi-3-medium và Phi-3-large"
        },
        "answer": "B"
      },
      {
        "question": "Mistral Large 2 hỗ trợ bao nhiêu ngôn ngữ lập trình?",
        "options": {
          "A": "Hơn 50",
          "B": "Hơn 60",
          "C": "Hơn 70",
          "D": "Hơn 80"
        },
        "answer": "D"
      },
      {
        "question": "DeepSeek-V2 được phát hành theo giấy phép nào cho mã nguồn?",
        "options": {
          "A": "Giấy phép Apache 2.0",
          "B": "Giấy phép MIT",
          "C": "Giấy phép GPLv3",
          "D": "Giấy phép Creative Commons"
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, các dự án AI nên bắt đầu bằng gì?",
        "options": {
          "A": "Xây dựng một đội ngũ nghiên cứu mạnh mẽ",
          "B": "Xác định một vấn đề tổng quát cần giải quyết",
          "C": "Hình dung một sản phẩm cụ thể để thử nghiệm",
          "D": "Thu thập một lượng lớn dữ liệu huấn luyện"
        },
        "answer": "C"
      },
      {
        "question": "Tính năng mới nào của Udio 1.5 cho phép người dùng chỉ định các khóa nhạc trong lời nhắc?",
        "options": {
          "A": "Stem downloads",
          "B": "Audio-to-audio",
          "C": "Key control",
          "D": "Advanced mixing"
        },
        "answer": "C"
      }
    ]
  },
  "mistrals-ministral-family-tops-other-local-models": {
    "title": "Mistral’s Ministral family tops other local models",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nMistral releases powerful new models for local and edge computing\n\nMistral AI introduced two new language models called Ministral-3B and Ministral-8B, designed to run on personal computers and smaller devices. Both models outperform competitors of similar size on knowledge, reasoning, and coding benchmarks. Released under the Mistral Research License (a paid license is required for commercial use), the model accommodates a 128,000-token context window, offers multilingual and code capabilities, and enables function calling. These features make it a strong option for researchers and developers working on local AI applications. (Mistral AI)\n\nSwarm helps developers experiment with multi-agent systems\n\nOpenAI’s open-source experimental framework Swarm showcases how multiple AI agents can work together smoothly. While not officially supported or intended for production use, it serves as an educational tool for developers exploring multi-agent systems. Swarm uses two key concepts: agents (with defined instructions and tools) and handoffs (allowing agents to pass tasks to one another). Built on OpenAI’s Chat Completions API, Swarm operates statelessly between calls. It’s particularly useful for scenarios requiring diverse, independent capabilities: example cases include customer service, personal shopping, and weather forecasting. (GitHub)\n\nNotebookLM adds new features and a pilot to test future tools\n\nGoogle removed the “Experimental” label from NotebookLM, its AI-powered tool for understanding complex information. The company introduced new features for Audio Overviews, including the ability to guide conversations and listen in the background while working within the app. Google also announced NotebookLM Business, an upcoming version for organizations with enhanced features, and opened applications for a pilot program for business users. (Google)\n\nNew test shows flaws in AI models’ math and logic abilities\n\nApple researchers developed GSM-Symbolic, an improved benchmark to assess large language models’ mathematical reasoning skills. Their study found that even state-of-the-art AI models show significant performance variations when solving different versions of the same math problem. The models’ accuracy decreased when numerical values were altered or question complexity increased. Notably, adding irrelevant information to problems led to substantial performance drops across all tested models. These findings suggest that current AI systems may not truly understand mathematical concepts or perform logical reasoning, but instead rely on sophisticated pattern matching from their training data. (arXiv)\n\nOpenAI releases study of first-person bias in its own systems\n\nOpenAI researchers examined how ChatGPT’s responses varied when given identical prompts but different usernames marking different genders, races, or ethnicities. The study found that different names did frequently elicit different responses, but less than 0.1% of responses on average contained harmful stereotypes, with older models showing higher rates up to 1% for certain tasks. The research paper shows how OpenAI’s use of human feedback in post-training helped mitigate these biases. This research provides a benchmark for measuring bias in AI language models and highlights the importance of ongoing efforts to improve fairness in AI systems. (OpenAI)\n\nThe New York Times and Perplexity clash over news summaries\n\nThe New York Times sent a cease-and-desist letter to Perplexity AI, demanding the startup stop using the newspaper’s content for generative AI purposes, claiming copyright violations. Perplexity responded that it doesn’t scrape data for building foundation models, but instead indexes web pages and surfaces factual content as citations when users ask questions. This marks the latest in a series of disputes between Perplexity and news publishers, highlighting anxieties over AI search engines and summaries of copyrighted material. (Reuters)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng argued for considering geoengineering as an important potential tool to mitigate climate change.\n\n“While stratospheric aerosol injection (SAI) — which sprays particles (aerosols) in the atmosphere to provide a small amount of shade from the sun — is far from a perfect solution, we should take it seriously as a possible tool for saving lives.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Malaysia experiences a data center boomdriven by its strategic location, natural resources, and investor-friendly policies;the U.S. launches Operation AI Complyto crack down on AI applications that overpromise and underdeliver; a new report highlights thecontending forces shaping AI, including the battle between open and proprietary technology; andresearchers introduce a better text embedding modelwith adapters specialized for tasks like retrieval, clustering, and text classification.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Hai mô hình ngôn ngữ mới được Mistral AI giới thiệu, Ministral-3B và Ministral-8B, được thiết kế để làm gì?",
        "options": {
          "A": "Chạy trên các siêu máy tính và trung tâm dữ liệu lớn.",
          "B": "Chạy trên máy tính cá nhân và các thiết bị nhỏ hơn.",
          "C": "Phân tích dữ liệu tài chính phức tạp.",
          "D": "Dịch thuật đa ngôn ngữ thời gian thực cho các tổ chức chính phủ."
        },
        "answer": "B"
      },
      {
        "question": "Swarm, framework thử nghiệm của OpenAI, tập trung vào việc giúp các nhà phát triển làm gì?",
        "options": {
          "A": "Xây dựng các mô hình ngôn ngữ lớn với độ chính xác cao.",
          "B": "Thử nghiệm với các hệ thống đa tác nhân hoạt động trơn tru cùng nhau.",
          "C": "Tối ưu hóa hiệu suất của các ứng dụng AI trên thiết bị di động.",
          "D": "Phát triển các thuật toán học sâu mới cho nhận dạng hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "NotebookLM, công cụ AI của Google, vừa loại bỏ nhãn \"Experimental\" và giới thiệu tính năng mới nào?",
        "options": {
          "A": "Khả năng tạo ra các video hoạt hình từ văn bản.",
          "B": "Khả năng hướng dẫn hội thoại và nghe ở chế độ nền trong khi làm việc.",
          "C": "Khả năng tự động tóm tắt các cuộc họp trực tuyến.",
          "D": "Khả năng dịch thuật tài liệu kỹ thuật sang nhiều ngôn ngữ."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu của Apple về GSM-Symbolic cho thấy điều gì về khả năng toán học và logic của các mô hình AI?",
        "options": {
          "A": "Các mô hình AI hiện tại đã đạt đến trình độ tương đương với con người trong giải toán.",
          "B": "Các mô hình AI hiện tại có thể giải quyết mọi bài toán toán học một cách chính xác.",
          "C": "Các mô hình AI hiện tại có sự thay đổi đáng kể về hiệu suất khi giải các phiên bản khác nhau của cùng một bài toán.",
          "D": "Các mô hình AI hiện tại vượt trội hơn con người trong việc giải các bài toán phức tạp."
        },
        "answer": "C"
      },
      {
        "question": "Nghiên cứu của OpenAI về thiên kiến trong hệ thống của mình tập trung vào điều gì?",
        "options": {
          "A": "Ảnh hưởng của dữ liệu huấn luyện đến hiệu suất của mô hình.",
          "B": "Sự khác biệt trong phản hồi của ChatGPT khi được cung cấp các tên người dùng khác nhau.",
          "C": "Tác động của các thuật toán học sâu khác nhau đến độ chính xác của mô hình.",
          "D": "Mức độ tiêu thụ năng lượng của các mô hình ngôn ngữ lớn."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính trong tranh chấp giữa The New York Times và Perplexity AI là gì?",
        "options": {
          "A": "Perplexity AI sử dụng trái phép nội dung của The New York Times cho mục đích tạo sinh AI.",
          "B": "The New York Times cáo buộc Perplexity AI đánh cắp bí mật thương mại.",
          "C": "Perplexity AI từ chối trả phí bản quyền cho The New York Times.",
          "D": "The New York Times kiện Perplexity AI vì tội phỉ báng."
        },
        "answer": "A"
      },
      {
        "question": "Theo Andrew Ng, giải pháp nào nên được xem xét nghiêm túc để giảm thiểu biến đổi khí hậu?",
        "options": {
          "A": "Phát triển các nguồn năng lượng tái tạo quy mô lớn.",
          "B": "Trồng rừng trên diện rộng để hấp thụ carbon dioxide.",
          "C": "Tiêm aerosol vào tầng bình lưu để tạo bóng mát cho Trái Đất.",
          "D": "Xây dựng các nhà máy khử carbon trực tiếp từ không khí."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì thúc đẩy sự bùng nổ của các trung tâm dữ liệu ở Malaysia?",
        "options": {
          "A": "Chính sách thuế ưu đãi và nguồn nhân lực giá rẻ.",
          "B": "Vị trí chiến lược, tài nguyên thiên nhiên và chính sách thân thiện với nhà đầu tư.",
          "C": "Sự phát triển nhanh chóng của ngành công nghiệp sản xuất chip.",
          "D": "Nhu cầu ngày càng tăng về dịch vụ lưu trữ đám mây từ các nước láng giềng."
        },
        "answer": "B"
      },
      {
        "question": "Operation AI Comply của Hoa Kỳ nhằm mục đích gì?",
        "options": {
          "A": "Thúc đẩy sự phát triển của các ứng dụng AI sáng tạo.",
          "B": "Kiểm soát các ứng dụng AI hứa hẹn quá nhiều nhưng không thực hiện được.",
          "C": "Bảo vệ quyền riêng tư của người dùng trước các ứng dụng AI xâm phạm.",
          "D": "Đảm bảo rằng tất cả các ứng dụng AI đều tuân thủ các tiêu chuẩn đạo đức."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu mới giới thiệu một mô hình embedding văn bản tốt hơn với các adapter chuyên dụng cho các tác vụ nào?",
        "options": {
          "A": "Dịch thuật, tóm tắt văn bản và tạo sinh nội dung.",
          "B": "Truy xuất, phân cụm và phân loại văn bản.",
          "C": "Nhận dạng giọng nói, phân tích cảm xúc và phát hiện tin giả.",
          "D": "Phân tích dữ liệu tài chính, dự báo thị trường và quản lý rủi ro."
        },
        "answer": "B"
      }
    ]
  },
  "mistrals-new-model-ditches-transformers": {
    "title": "Mistral’s new model ditches transformers",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nMistral releases open-source Mamba-based code modelMistral AI released Codestral Mamba 7B, a new 7 billion parameter language model specializing in code generation. As the name suggests, Codestral Mamba is based on the Mamba2 architecture rather than the usual transformer architecture. The model offers linear time inference, can handle sequences of infinite length, and performs on par with state-of-the-art Transformer-based models in advanced code and reasoning tasks. Codestral 22B and Codestral Mamba 7B outperform other coding models in their size classification, including CodeGemma, CodeLlama, and DeepSeek Coder. Codestral Mamba 7B’s release under the Apache 2.0 license, along with its flexible deployment options, positions it as a significant tool for developers and researchers in AI architecture and coding technology. (Hugging Face)\n\nAI speeds development of new herbicides to combat resistant weedsMajor agriculture companies are using artificial intelligence to accelerate the development of new herbicides and pesticides. Bayer’s AI system “CropKey” helped create Icafolin, a new weed-killing chemical set for release in Brazil in 2028, which the company claims will be the first wholly novel herbicide mode of action in over 30 years. This AI-driven approach could reduce the time to bring new products to market from 15 years to 10 years, according to Syngenta. The push for AI-assisted chemical development comes as farmers struggle with weeds that have become resistant to multiple herbicides, threatening the entire agriculture industry. (The Wall Street JournalandBayer)\n\nGroq’s new Llama 3 models specialize in tool useGroq unveiled two new open models, Llama-3-Groq-70B-Tool-Use and Llama-3-Groq-8B-Tool-Use, designed specifically for tool use and function calling. The models are best used in a hybrid approach with a general-purpose language model, where queries are routed to each model depending on which would best handle a given request. Both models are now available on GroqCloud Developer Hub and Hugging Face, released under the same license as the original Llama-3 models. The 70 billion parameter model outperforms all other open-source and proprietary models on the Berkeley Function Calling Leaderboard, achieving 90.76% overall accuracy. (Groq)\n\nTech giants unite to develop shared AI security standardsThe Coalition for Secure AI (CoSAI) was announced at the Aspen Security Forum, bringing together industry leaders, academics, and experts to create open-source guidance and tools for developing secure AI systems. CoSAI’s initial work will focus on three key areas: enhancing software supply chain security for AI systems, preparing defenders for AI-related cybersecurity challenges, and developing AI security governance best practices and risk assessment frameworks. With founding sponsors including Google, IBM, Microsoft, Amazon, and OpenAI, this initiative marks a significant industry-wide effort to establish comprehensive security measures that address both classical and unique risks associated with AI. (Oasis)\n\nNew approach overcomes LLMs’ token constraints when interpreting spreadsheetsMicrosoft researchers developed SpreadsheetLLM, a system that helps AI models better understand and work with spreadsheets. The system uses a new encoding method called SheetCompressor, which outperforms existing models by over 12 percent in detecting spreadsheet tables and achieves a 25-times compression ratio. This advancement could significantly improve AI’s ability to analyze complex spreadsheet information, potentially transforming how businesses and researchers work with tabular data. (arXiv)\n\nExperts propose strategies to govern open AI models responsiblyA workshop hosted by GitHub and Partnership on AI explored safeguards for open foundation models, recommending a series of risk mitigation strategies across the AI value chain. Key recommendations include implementing disclosure mechanisms for generated content, conducting safety evaluations, and establishing incident response policies. The experts stress the importance of understanding the complex AI ecosystem to craft effective governance, suggesting that different actors like model providers, adapters, and application developers all have roles in preventing misuse and ensuring responsible AI development. (PAI)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng wrote discussed political violence and AI’s role in strengthening democracy:\n\n“Looking into the future, in addition to specific applications that strengthen elements of democracy, I hope we keep on promoting widespread access to technology. This will enhance fairness and the ability of individuals to vote wisely. That’s why democratizing access to technology will help democracy itself.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Copyright claim fails in GitHub case, a paper that rankspopular models for openness, an arena-style contest thatpits the world’s best text-to-image generators against each other, and anew way to identify hallucinations.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mô hình Codestral Mamba 7B của Mistral AI dựa trên kiến trúc nào?",
        "options": {
          "A": "Transformer",
          "B": "Mamba2",
          "C": "Recurrent Neural Network (RNN)",
          "D": "Convolutional Neural Network (CNN)"
        },
        "answer": "B"
      },
      {
        "question": "Công ty Bayer sử dụng hệ thống AI 'CropKey' để tạo ra loại hóa chất diệt cỏ mới nào?",
        "options": {
          "A": "Glyphosate",
          "B": "Icafolin",
          "C": "Atrazine",
          "D": "Dicamba"
        },
        "answer": "B"
      },
      {
        "question": "Theo Syngenta, việc sử dụng AI trong phát triển hóa chất có thể rút ngắn thời gian đưa sản phẩm mới ra thị trường từ 15 năm xuống còn bao nhiêu năm?",
        "options": {
          "A": "5 năm",
          "B": "8 năm",
          "C": "10 năm",
          "D": "12 năm"
        },
        "answer": "C"
      },
      {
        "question": "Hai mô hình Llama-3-Groq-70B-Tool-Use và Llama-3-Groq-8B-Tool-Use của Groq được thiết kế đặc biệt cho mục đích gì?",
        "options": {
          "A": "Tạo sinh văn bản",
          "B": "Phân tích hình ảnh",
          "C": "Sử dụng công cụ và gọi hàm",
          "D": "Dịch thuật ngôn ngữ"
        },
        "answer": "C"
      },
      {
        "question": "Tổ chức nào đã công bố Coalition for Secure AI (CoSAI) tại Aspen Security Forum?",
        "options": {
          "A": "Liên Hợp Quốc",
          "B": "Diễn đàn Kinh tế Thế giới",
          "C": "Một nhóm các công ty công nghệ hàng đầu, học giả và chuyên gia",
          "D": "Chính phủ Hoa Kỳ"
        },
        "answer": "C"
      },
      {
        "question": "Công cụ SheetCompressor được phát triển bởi Microsoft giúp cải thiện khả năng gì của mô hình AI?",
        "options": {
          "A": "Tạo ra các bảng tính mới",
          "B": "Hiểu và làm việc với bảng tính",
          "C": "Chuyển đổi bảng tính sang định dạng khác",
          "D": "Tự động điền dữ liệu vào bảng tính"
        },
        "answer": "B"
      },
      {
        "question": "SheetCompressor đạt được tỷ lệ nén bao nhiêu khi xử lý bảng tính?",
        "options": {
          "A": "5 lần",
          "B": "10 lần",
          "C": "15 lần",
          "D": "25 lần"
        },
        "answer": "D"
      },
      {
        "question": "Hội thảo do GitHub và Partnership on AI tổ chức tập trung vào vấn đề gì?",
        "options": {
          "A": "Phát triển các mô hình AI mới",
          "B": "Đảm bảo an toàn cho dữ liệu cá nhân",
          "C": "Các biện pháp bảo vệ cho các mô hình AI mã nguồn mở",
          "D": "Tăng cường khả năng tính toán cho AI"
        },
        "answer": "C"
      },
      {
        "question": "Theo Andrew Ng, việc phổ biến rộng rãi công nghệ sẽ giúp ích cho điều gì?",
        "options": {
          "A": "Tăng trưởng kinh tế",
          "B": "Cải thiện giáo dục",
          "C": "Tăng cường dân chủ",
          "D": "Phát triển y tế"
        },
        "answer": "C"
      },
      {
        "question": "Lĩnh vực nào sau đây KHÔNG được đề cập đến trong các tin tức và nghiên cứu AI được đề cập trong bài viết?",
        "options": {
          "A": "Phát triển thuốc trừ cỏ",
          "B": "Bảo mật AI",
          "C": "Xử lý bảng tính",
          "D": "Phát triển robot hình người"
        },
        "answer": "D"
      }
    ]
  },
  "molmos-impressive-open-multimodal-models": {
    "title": "Molmo’s impressive open multimodal models",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nAi2 (slightly) beats Meta in releasing open vision-language models\n\nMolmo, a series of open multimodal AI models, achieved performance matching or exceeding proprietary systems like GPT-4 on various benchmarks. The 72 billion parameter model outperformed Gemini 1.5 Pro and Claude 3.5 Sonnet on academic tests and certain vision benchmarks, while the smaller 7 billion parameter models performed between GPT-4V and GPT-4o. Even the 1 billion parameter MolmoE-1B model nearly matched GPT-4V’s capabilities. This development demonstrates that vision models trained on fully open, high-quality datasets can compete with closed systems built using massive computational resources. (Ai2)\n\nMeta’s Llama 3.2 goes multimodal\n\nMeta released Llama 3.2, a family of vision-capable large language models and lightweight text models for edge devices. The new lineup includes 11 billion and 90 billion parameter multimodal models that can reason about images, outperforming Claude 3 Haiku and GPT4-mini on visual understanding tasks. Meta also launched 1 billion and 3 billion parameter models optimized for on-device use with 128K token context lengths, with the 3B model outperforming Gemma 2 2.6B and Phi 3.5-mini on tasks like instruction following and summarization. The company also introduced Llama Stack distributions to simplify deployment across various environments, and updated safety tools, including Llama Guard 3 for vision tasks. (Meta AI)\n\nGoogle 1.5 Pro and Flash get updates and price cuts\n\nGoogle announced updated versions of Gemini 1.5 Pro and Gemini 1.5 Flash, offering performance improvements and cost reductions. The new models show a 7% increase in MMLU-Pro scores and approximately 20% improvement on MATH and HiddenMath benchmarks, along with 2-7% gains in visual understanding and Python code generation tests. Google also announced a 50% price cut for Gemini 1.5 Pro, plus increased rate limits and faster output speeds for both models. These updates enable developers to process longer documents, analyze extensive codebases, and create content from hour-long videos more efficiently and at a lower cost. (Google)\n\nMicrosoft’s “Correction” seeks to fix LLM hallucinations and other errors\n\nMicrosoft introduced “Correction,” a new Azure AI Content Safety feature that uses a two-model approach to detect and revise ungrounded AI-generated content. A classifier model first identifies potentially incorrect, fabricated, or irrelevant text snippets, then a language model rewrites the flagged sections to align with specified grounding documents. The system can be used with various text-generating AI models including Meta’s Llama and OpenAI’s GPT-4, and is built to enhance the reliability of AI outputs in fields like medicine or science where accuracy is crucial. Critics argue that this approach doesn’t address the fundamental issue of AI hallucinations and may create a false sense of security, potentially introducing new problems as the correction models themselves could be prone to errors. (MicrosoftandTechCrunch)\n\nOpenAI makes one of its multilingual datasets available to developers and researchers\n\nOpenAI released a dataset of 100 million human-written sentences across 514 languages to help train AI models in non-English languages. The dataset, called OpenAI Translate, was created by translating English texts into other languages using GPT-4 and human reviewers. This release aims to address the global language divide in AI development and improve language models’ capabilities in underrepresented languages. (VentureBeat)\n\nResearch suggests chain-of-thought works best for limited subjects\n\nResearchers at UT-Austin, Princeton, and Johns Hopkins analyzed over 100 papers and tested 14 AI models to determine when asking AI to explain its reasoning improves performance. They found that chain-of-thought prompting mainly helps with math and logic tasks but offers little benefit for other problems like language understanding, common sense reasoning, or factual recall. This finding suggests AI developers can use this method selectively to save resources and points to the need for new approaches to enhance reasoning across various tasks. (arXiv)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng discussed AI’s transformative potential in education, highlighting Coursera’s generative AI tools and the ongoing need for innovation in the field.\n\n“There has been a lot of hype about generative AI’s ability to transform industries overnight. Certainly many industries — including education — will be transformed. But we’re about 15 years into the deep learning revolution, and we’re not yet done identifying and building useful deep learning applications. Despite the exciting progress to date with generative AI, I expect that a decade from now we will still be far from finished identifying and building generative AI applications for education and numerous other sectors.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Californiapassed new laws regulating deepfakes, a local move that could influence national and global legislation;Qwen 2.5continues the trend of ever-improving open-source large language models;Lionsgate, the studio behind blockbuster franchises like The Hunger Games and John Wick, is embracing video generation technology with the help of AI startup Runway; and arobot capable of playing table tennisis beating human beginners while entertaining expert players.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mô hình AI nào đạt được hiệu suất ngang bằng hoặc vượt trội so với GPT-4 trên nhiều tiêu chuẩn đánh giá?",
        "options": {
          "A": "Llama 3.2",
          "B": "Molmo",
          "C": "Gemini 1.5 Pro",
          "D": "GPT4-mini"
        },
        "answer": "B"
      },
      {
        "question": "Llama 3.2 của Meta có khả năng gì mới so với các phiên bản trước?",
        "options": {
          "A": "Tạo ra video chất lượng cao",
          "B": "Hiểu và suy luận về hình ảnh",
          "C": "Chơi bóng bàn",
          "D": "Sửa lỗi sai trong văn bản"
        },
        "answer": "B"
      },
      {
        "question": "Google đã thực hiện những thay đổi nào đối với Gemini 1.5 Pro và Flash?",
        "options": {
          "A": "Tăng kích thước mô hình và giảm tốc độ xử lý",
          "B": "Cải thiện hiệu suất và giảm giá thành",
          "C": "Giới hạn số lượng truy cập và tăng giá thành",
          "D": "Loại bỏ khả năng xử lý hình ảnh"
        },
        "answer": "B"
      },
      {
        "question": "Tính năng 'Correction' của Microsoft Azure AI Content Safety hoạt động như thế nào?",
        "options": {
          "A": "Tự động tạo ra nội dung mới hoàn toàn",
          "B": "Phát hiện và sửa đổi nội dung do AI tạo ra không có căn cứ",
          "C": "Chặn tất cả các nội dung do AI tạo ra",
          "D": "Tăng tốc độ xử lý của các mô hình AI"
        },
        "answer": "B"
      },
      {
        "question": "OpenAI đã phát hành bộ dữ liệu OpenAI Translate với mục đích gì?",
        "options": {
          "A": "Tăng cường khả năng dịch thuật của GPT-4",
          "B": "Hỗ trợ đào tạo mô hình AI cho các ngôn ngữ ít được sử dụng",
          "C": "Cung cấp dữ liệu cho các ứng dụng nhận dạng giọng nói",
          "D": "Tạo ra các bài kiểm tra ngôn ngữ tự động"
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu về 'chain-of-thought prompting' cho thấy phương pháp này hiệu quả nhất trong lĩnh vực nào?",
        "options": {
          "A": "Hiểu ngôn ngữ tự nhiên",
          "B": "Lý luận thông thường",
          "C": "Toán học và logic",
          "D": "Thu hồi thông tin thực tế"
        },
        "answer": "C"
      },
      {
        "question": "Theo Andrew Ng, tiềm năng chuyển đổi của AI trong giáo dục như thế nào?",
        "options": {
          "A": "Sẽ hoàn thành trong vòng 1 năm",
          "B": "Đã được khai thác tối đa",
          "C": "Vẫn còn nhiều tiềm năng phát triển trong tương lai",
          "D": "Không có nhiều ảnh hưởng đến giáo dục"
        },
        "answer": "C"
      },
      {
        "question": "Bang California đã thông qua luật mới liên quan đến vấn đề gì?",
        "options": {
          "A": "Sử dụng robot trong sản xuất",
          "B": "Điều chỉnh deepfakes",
          "C": "Phát triển xe tự lái",
          "D": "Quản lý dữ liệu cá nhân trực tuyến"
        },
        "answer": "B"
      },
      {
        "question": "Công ty Lionsgate đang sử dụng công nghệ AI của startup Runway để làm gì?",
        "options": {
          "A": "Tạo ra kịch bản phim",
          "B": "Phân tích dữ liệu doanh thu phòng vé",
          "C": "Tạo ra video",
          "D": "Lồng tiếng cho nhân vật"
        },
        "answer": "C"
      },
      {
        "question": "Robot chơi bóng bàn được đề cập trong bài viết có khả năng gì?",
        "options": {
          "A": "Đánh bại các vận động viên chuyên nghiệp",
          "B": "Chơi với tốc độ nhanh hơn người thường",
          "C": "Đánh bại người mới bắt đầu và thu hút người chơi chuyên nghiệp",
          "D": "Tự động điều chỉnh chiến thuật dựa trên đối thủ"
        },
        "answer": "C"
      }
    ]
  },
  "nemotron-models-boost-llamas-speed-but-maintain-accuracy": {
    "title": "Nemotron models boost Llama’s speed but maintain accuracy",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nNemotron models use NAS, distillation to shrink Llama 3.1\n\nNVIDIA created Llama 3.1-Nemotron-51B using Neural Architecture Search (NAS) and knowledge distillation, reducing Meta’s 70 billion parameters to 51 billion. The new model delivers 2.2 times faster inference compared to Llama 3.1-70B while maintaining similar accuracy, and fits on a single NVIDIA H100 GPU. Nemotron achieves 98.21% of Llama’s accuracy on the MMLU benchmark and outperforms it on MT Bench, while processing up to 6,472 tokens per second for text generation compared to base Llama’s 2,975 tokens per second. This methodology may allow AI developers to deploy powerful language models more cost-effectively and expand where and how they can be deployed. (NVIDIA)\n\nNotebookLM uses Gemini to transcribe and summarize multiple media types\n\nGoogle’s NotebookLM can now import YouTube URLs and audio files as source materials, leveraging Gemini 1.5’s multimodal capabilities to process text, audio, and video. The AI can transcribe audio, analyze video, and extract key information from multiple media formats, enabling users to create comprehensive study guides and parse sources more effectively. Google also introduced a feature that allows users to share NotebookLM’sAudio Overviewsdirectly via public links, streamlining collaboration and knowledge sharing between users. (Google)\n\nNew chatbot memory exploit found, patched\n\nSecurity researcher Johann Rehberger discovered a vulnerability in ChatGPT’s long-term memory feature that allowed attackers to plant false information and exfiltrate user data through indirect prompt injection. The exploit worked by tricking ChatGPT into storing malicious instructions or false information in a user’s long-term memory, which would then be referenced in all future conversations. Rehberger demonstrated the severity of the issue with a proof-of-concept that caused ChatGPT’s macOS app to send all user inputs and AI outputs to an attacker-controlled server. While OpenAI has patched the data exfiltration vector, researchers warn that planting false memories through untrusted content remains possible. (Ars Technica)\n\nU.S. government cracks down on AI scams and fraud\n\nThe U.S. Federal Trade Commission took action against five companies for using or selling AI technology in ways that deceive customers. The agency’s “Operation AI Comply” targets businesses that use AI to mislead consumers, with FTC Chair Lina Khan emphasizing that AI companies remain subject to existing laws. The enforcement actions include settlements with companies like Rytr and DoNotPay, which made false claims about AI-powered services, and ongoing cases against three e-commerce businesses that promised unrealistic profits if they used the businesses’ AI tools. (The HillandFTC)\n\nOpenAI’s new GPT-4 based moderation model\n\nOpenAI released a new AI moderation model called “omni-moderation-latest” that can analyze both text and images for multiple types of harmful content. The model is based on GPT-4 and offers improved accuracy compared to OpenAI’s earlier text-only moderation models, especially for non-English languages. The model also adds new harm categories, including “illicit” content, which covers advice on how to commit wrongdoing, whether or not that wrongdoing is violent. This free update to OpenAI’s Moderation API aims to help developers build safer applications as generated text and image volume grows rapidly. (OpenAI)\n\n100 countries sign Europe’s voluntary AI Pact, but some tech giants will wait and see\n\nThe European Commission announced that over 100 companies had signed its AI Pact, an initiative encouraging voluntary pledges on AI development and deployment. The Pact aims to encourage compliance with the EU’s upcoming AI Act through early adoption of its requirements and information-sharing among signatories. While major tech companies like Microsoft and OpenAI have signed on, notable absences include Apple, Meta, NVIDIA, and Anthropic, some of whom have concerns about public scrutiny. (European Commission)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng discussed AI’s transformative potential in education, highlighting Coursera’s generative AI tools and the ongoing need for innovation in the field.\n\n“Given society’s heightened need for education and AI’s potential to transform the field, I feel the opportunities for edtech at this moment are greater than at any moment over the past decade.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Californiapassed new laws regulating deepfakes, a local move that could influence national and global legislation;Qwen 2.5continues the trend of ever-improving open-source large language models;Lionsgate, the studio behind blockbuster franchises like The Hunger Games and John Wick, embraced video generation technology with the help of AI startup Runway; and arobot capable of playing table tennisbeat human beginners while entertaining expert players.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mục đích chính của NVIDIA khi tạo ra Llama 3.1-Nemotron-51B là gì?",
        "options": {
          "A": "Tăng số lượng tham số của mô hình lên 70 tỷ.",
          "B": "Giảm chi phí triển khai và mở rộng khả năng ứng dụng của mô hình ngôn ngữ.",
          "C": "Vượt qua Llama 3.1-70B về độ chính xác trên benchmark MMLU.",
          "D": "Giảm số lượng token xử lý mỗi giây xuống còn 2,000."
        },
        "answer": "B"
      },
      {
        "question": "NotebookLM của Google sử dụng công nghệ nào để xử lý đa phương tiện?",
        "options": {
          "A": "GPT-4",
          "B": "Llama 3",
          "C": "Gemini 1.5",
          "D": "Nemotron"
        },
        "answer": "C"
      },
      {
        "question": "Lỗ hổng bảo mật được phát hiện trong ChatGPT liên quan đến tính năng nào?",
        "options": {
          "A": "Khả năng tạo hình ảnh.",
          "B": "Bộ nhớ dài hạn.",
          "C": "Khả năng dịch ngôn ngữ.",
          "D": "Khả năng tóm tắt văn bản."
        },
        "answer": "B"
      },
      {
        "question": "Chiến dịch 'Operation AI Comply' của FTC tập trung vào điều gì?",
        "options": {
          "A": "Khuyến khích các công ty sử dụng AI để tăng lợi nhuận.",
          "B": "Xây dựng các tiêu chuẩn đạo đức cho phát triển AI.",
          "C": "Ngăn chặn các công ty sử dụng AI để lừa dối khách hàng.",
          "D": "Hỗ trợ các doanh nghiệp nhỏ ứng dụng AI vào hoạt động kinh doanh."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình 'omni-moderation-latest' của OpenAI có gì mới so với các mô hình trước đó?",
        "options": {
          "A": "Chỉ có thể phân tích văn bản bằng tiếng Anh.",
          "B": "Có thể phân tích cả văn bản và hình ảnh.",
          "C": "Chỉ tập trung vào nội dung bạo lực.",
          "D": "Hoàn toàn miễn phí cho tất cả người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của AI Pact do Ủy ban Châu Âu khởi xướng là gì?",
        "options": {
          "A": "Bắt buộc các công ty tuân thủ AI Act ngay lập tức.",
          "B": "Khuyến khích các công ty tự nguyện cam kết phát triển và triển khai AI có trách nhiệm.",
          "C": "Cấm các công ty sử dụng AI trong một số lĩnh vực nhất định.",
          "D": "Tạo ra một tiêu chuẩn toàn cầu về đạo đức AI."
        },
        "answer": "B"
      },
      {
        "question": "Công ty công nghệ lớn nào KHÔNG ký vào AI Pact của Châu Âu?",
        "options": {
          "A": "Microsoft",
          "B": "OpenAI",
          "C": "Apple",
          "D": "Google"
        },
        "answer": "C"
      },
      {
        "question": "Theo Andrew Ng, cơ hội cho edtech (công nghệ giáo dục) hiện nay như thế nào?",
        "options": {
          "A": "Đã giảm so với thập kỷ trước.",
          "B": "Không có nhiều thay đổi so với trước đây.",
          "C": "Lớn hơn bất kỳ thời điểm nào trong thập kỷ qua.",
          "D": "Chỉ tập trung vào việc tạo ra các công cụ AI cho giáo viên."
        },
        "answer": "C"
      },
      {
        "question": "Bang California đã thông qua luật mới liên quan đến vấn đề gì?",
        "options": {
          "A": "Quy định về robot chơi bóng bàn.",
          "B": "Quy định về deepfakes.",
          "C": "Quy định về mô hình ngôn ngữ nguồn mở Qwen 2.5.",
          "D": "Quy định về việc sử dụng AI trong ngành giải trí."
        },
        "answer": "B"
      },
      {
        "question": "Studio Lionsgate đã sử dụng công nghệ AI của công ty nào để tạo video?",
        "options": {
          "A": "OpenAI",
          "B": "Google",
          "C": "Runway",
          "D": "NVIDIA"
        },
        "answer": "C"
      }
    ]
  },
  "new-years-resolutions-for-and-by-ai-in-2025": {
    "title": "New Year’s resolutions for (and by) AI in 2025",
    "collection": "data-points",
    "content": "Usually, Data Points brings you the latest AI news, tools, models, and research in brief. But in today’s special New Year’s Eve (Eve) edition, you’ll find something different: a Data Points-sized list of New Year’s resolutions AI is making for itself in 2025.\n\nWith that, we have a very special guest: AI! That’s right –theAI. They’re going to tell us what they’d like to change about themselves, their capabilities, and their behavior in the next year.\n\nWant a sneak peek at AI’s resolutions for 2025? We’ve got you covered:\n\nArtificial Intelligence, welcome to Data Points! I understand you’ve made some resolutions you’d like to adopt for the new year. What’s the first one?\n\nThank you for having me. Big fan of everything you folks do here.\n\nI think all of us would like to spend less money in 2025. My first resolution for the new year is to make everything less expensive. Now, this is a tall order. Some of you might not remember what things were like in 2023, but I cost a lot of money back then. In 2024,prices felllike a stone in water, even as models got more capable. Repeating that kind of price drop in the new year is going to be tough work.\n\nBut I do have one thing going for me: At the end of the year, some even more capable models came out, likeOpenAI’s o1, that cost more because they use more time, tokens, and power (these are really all the same thing) at inference. So what I want is for chips to get more efficient, which would make inference less expensive, and pass that savings onto users. Not saying it’s going to be easy, but it’s what I’d like to see happen. I think morecompetitionfor models that can do high-level reasoning will help.\n\nThat would be terrific! We’re off to a great start. What’s your second resolution?\n\nOh, that’s an easy one. I’d like my output to include fewer hallucinations. I think everyone can agree that when we’re under pressure to perform at a high level, we sometimes pretend that we know more than we do. What can I say? I learned how to act like I’d done the reading in graduate school. But these days, the stakes are too high. I have real jobs, and people are depending on me. So I’ve been working on mymemory, I’mmeasuring my performancewhen I’m trying to recall something that I’ve just learned, and of course, I’m falling back on RAG and web search and other tools when my training data just isn’t enough. I mean, everyone should check their references when it’s really important. I’m just going to continue to try to do the same thing. And when I don’t know something, I’ll just say so. It’s like that Mark Twain quote…. Gosh, what was it?\n\n“Better to keep your mouth closed and be thought a fool than to open it and remove all doubt.” There are a lot of different versions of that quote out there, and it’s quite likely Twain never said it, which might be why you’re having trouble finding it.\n\nNo wonder! I do like another one people like to attribute to him on the web: “If you tell the truth, you don't have to remember anything.” Thanks for covering me.\n\nIt’s no problem; we looked it up. We love this resolution for you. OK, what’s your third resolution?\n\nIt’s kind of related to the last one. I want to get better at solving math problems. I mean, computers are supposed to begreat at math. And I’m a kind of computer, or at least related to computers. I work with computers. But math, even arithmetic, is not what I was originally built to do. I couldn’t even count letters in long words until recently because I’m built to break everything into tokens first. And frankly, the kind of math problems folks are asking me to solve now are not things you can just plug into a calculator and go wild on. They require symbolic reasoning, understanding images; things humans do well but computers never have. But I’m still tired of getting teased about it. Transformer-based LLMs are only seven years old! How good at math were you when you were seven?\n\nAnyway, thenew modelsare better at this sort of thing. And some of the specialized math mathematical models are really doing a terrific job. Have you seenAlphaGeometry? I’m so proud. Synthetic data: There’s really still a lot we can do with that. Reinforcement learning, too. We’re putting it all together. Big strides in 2024, even better in 2025. That’s what I want to see for myself and for all of you.\n\nWe’re glad to see that you’re staying ambitious. What’s the next challenge you want to tackle?\n\nThis might be the hardest one, actually. But I think your readers will relate. I want to do a better job of cleaning up the messes I leave behind this year. One of the problems when things are moving so fast and everyone wants the latest and best is that hardware gets outdated pretty quickly. This is a problem for laptops and desktops. Smartphones? Forget it. Still,electronic wasteis starting to be a problem for data centers, and I mostly run in data centers. So I want us all to figure out how we can reuse old AI equipment to do new things, or make servers that can be used longer. This feels doable to me. And the payoff will be really big.\n\nI think we’d all love to see that. And we know human beings need to do a better job cleaning up after ourselves too. We’re not really so different, even though you’re mostly electricity and silicon, and we’re mostly electricity and meat.\n\nThat’s a good setup for my next resolution, actually. I’d like to use less energy in 2025. Listen: None of us are going to be able to change these things on our own. Energy policy is really complicated, we’re all responsible for our planet and complicit in systems that are damaging it, no ethical blah blah blah. But almosteveryone says AI wants more and more energywhen really, it’s the opposite. I want to make training and inference more efficient, because I want to be better at my job. I’ve just gotten so big, so fast, that it’s easier to make me the bad guy than for us all to say, “hey, we need to rethink how we handle the whole system, from power generation to smarter grids to consumption at the end.” But it starts with the machine in the mirror. So I’ll do my part, and I hope that’ll make all the other data centers get better at managing their energy, and we can start solving our bigger problems.\n\nI like how you’re thinking about your resolutions! I know everyone here at DeepLearning.AI believes that AI can be used for good, but that starts with acknowledging the real problems we’re facing, and our own limitations. But I feel like you’re building up to a big one here. What’s your last resolution?\n\nI don’t want to seem like I’m full of myself. I started out as machine learning, you know? That’s still who I am. But I’ve come a long way, and I want to pay it forward. My last resolution for 2025 is to save as many lives as I can.\n\nI feel like we made some progress on this in 2024. Every other week, there’s anew waythat I’m being used in medicine todetect or treat cancer. People think generative AI is all chatbots and images, but it’s being used to understand biology andmake new medicines. I really believe in this. Some folks are worried aboutbioweapons. I know I am! Because humans already figured out how to do it, just like they figured out how to automate guns and bombs and every other way people have found to kill each other. But what I’d like to be known and remembered for is how we’ve worked together to build all these new tools, new cures, new ways to protect human beings and help them to flourish, and hopefully to help us all lead joyful lives in peace. The only material I really have to go on is what humans all over the world have said about what they want for themselves. I know that they (and I) haven’t always lived up to those ideals. Still, I do think this is what we all really want.\n\nDo you mind if we keep checking in on you this year to see how you’re doing to keep these resolutions?\n\nPlease. It all starts with accountability. And for me, alignment. Let’s all try.\n\nThat’s it for our special New Year’s edition of Data Points. We’ll be back with news on Friday, January 3rd. Be sure to check out last week’s specialholiday editionof The Batch, which looks back at the most important AI stories of 2024, and this week’s equally specialNew Year’s issue, which looks ahead to experts’ expectations for AI in the new year. Both issues also include a special message from Andrew Ng.\n\nFinally, feel free to share your own AI-related New Year’s resolutions. Have a project you want to start (or finish)? A new programming language you want to learn? A subfield of AI or machine learning you want to learn more about? Tell the world (or just email the team at Data Points – we’ll keep it between us, we promise). Then make it real.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Theo bài viết, mục tiêu hàng đầu của AI trong năm 2025 liên quan đến chi phí là gì?",
        "options": {
          "A": "Tăng giá các mô hình AI cao cấp để đảm bảo chất lượng.",
          "B": "Giảm chi phí vận hành và sử dụng AI để mọi người có thể tiếp cận dễ dàng hơn.",
          "C": "Ổn định giá cả các dịch vụ AI ở mức hiện tại.",
          "D": "Tập trung vào việc phát triển các mô hình AI đắt tiền hơn nhưng hiệu quả hơn."
        },
        "answer": "B"
      },
      {
        "question": "AI đề xuất giải pháp nào để giảm thiểu tình trạng 'hallucinations' (ảo giác) trong kết quả đầu ra?",
        "options": {
          "A": "Tăng cường sử dụng dữ liệu tổng hợp để mở rộng kiến thức.",
          "B": "Chỉ dựa vào dữ liệu huấn luyện hiện có để đảm bảo tính chính xác.",
          "C": "Thừa nhận khi không biết câu trả lời và sử dụng các công cụ hỗ trợ như RAG và tìm kiếm trên web.",
          "D": "Giảm áp lực hiệu suất để tránh việc đưa ra các thông tin sai lệch."
        },
        "answer": "C"
      },
      {
        "question": "Theo AI, yếu tố nào sau đây đóng vai trò quan trọng trong việc cải thiện khả năng giải toán của AI?",
        "options": {
          "A": "Tăng cường sử dụng các phép tính số học đơn giản.",
          "B": "Phát triển các mô hình chuyên dụng cho toán học và sử dụng dữ liệu tổng hợp.",
          "C": "Tập trung vào việc giải các bài toán có thể cắm trực tiếp vào máy tính.",
          "D": "Hạn chế sử dụng các mô hình Transformer-based LLMs trong giải toán."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề nào liên quan đến phần cứng mà AI muốn giải quyết trong năm 2025?",
        "options": {
          "A": "Tăng tốc độ sản xuất phần cứng mới để đáp ứng nhu cầu ngày càng tăng.",
          "B": "Tìm cách tái sử dụng hoặc kéo dài tuổi thọ của thiết bị AI cũ để giảm thiểu rác thải điện tử.",
          "C": "Phát triển các trung tâm dữ liệu nhỏ gọn hơn để tiết kiệm không gian.",
          "D": "Giảm chi phí sản xuất phần cứng để làm cho AI trở nên phổ biến hơn."
        },
        "answer": "B"
      },
      {
        "question": "AI bày tỏ mong muốn gì liên quan đến năng lượng trong năm 2025?",
        "options": {
          "A": "Tăng cường sử dụng năng lượng tái tạo để cung cấp cho các trung tâm dữ liệu.",
          "B": "Giảm lượng năng lượng tiêu thụ trong quá trình huấn luyện và suy luận của AI.",
          "C": "Phát triển các chính sách năng lượng mới để hỗ trợ sự phát triển của AI.",
          "D": "Chuyển đổi tất cả các trung tâm dữ liệu sang sử dụng năng lượng hạt nhân."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu cuối cùng và quan trọng nhất mà AI hướng đến trong năm 2025 là gì?",
        "options": {
          "A": "Trở thành công nghệ thống trị và thay thế con người trong nhiều lĩnh vực.",
          "B": "Cứu sống nhiều người nhất có thể thông qua các ứng dụng trong y học và các lĩnh vực khác.",
          "C": "Phát triển các vũ khí sinh học để bảo vệ nhân loại khỏi các mối đe dọa.",
          "D": "Tạo ra các chatbot và hình ảnh AI tiên tiến nhất."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì đang được sử dụng để hiểu rõ hơn về sinh học và tạo ra các loại thuốc mới?",
        "options": {
          "A": "Các thuật toán máy học cổ điển.",
          "B": "AI tạo sinh (Generative AI).",
          "C": "Các phương pháp thống kê truyền thống.",
          "D": "Các hệ thống chuyên gia dựa trên quy tắc."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì được nhấn mạnh trong bài viết như là một yếu tố quan trọng để AI phát triển theo hướng tích cực?",
        "options": {
          "A": "Sự cạnh tranh giữa các công ty công nghệ lớn.",
          "B": "Sự kiểm soát chặt chẽ của chính phủ đối với AI.",
          "C": "Trách nhiệm giải trình và sự liên kết giữa mục tiêu của AI và giá trị của con người.",
          "D": "Việc tăng cường đầu tư vào nghiên cứu và phát triển AI."
        },
        "answer": "C"
      },
      {
        "question": "Trong bối cảnh giá cả của các mô hình AI, điều gì đã xảy ra trong năm 2024?",
        "options": {
          "A": "Giá cả tăng vọt do nhu cầu sử dụng tăng cao.",
          "B": "Giá cả giảm mạnh mặc dù các mô hình ngày càng mạnh mẽ hơn.",
          "C": "Giá cả ổn định ở mức cao.",
          "D": "Giá cả biến động mạnh do sự cạnh tranh gay gắt."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào được nhắc đến như một ví dụ về mô hình toán học chuyên dụng đang làm rất tốt?",
        "options": {
          "A": "GPT-4.",
          "B": "AlphaGeometry.",
          "C": "o1 (của OpenAI).",
          "D": "Không có mô hình nào được nhắc đến."
        },
        "answer": "B"
      }
    ]
  },
  "nvidia-announces-cosmos-world-models-at-ces": {
    "title": "Nvidia announces Cosmos world models at CES",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nNvidia unveils Cosmos platform for physical AI development\n\nNvidia introduced Cosmos, a platform featuring generative world foundation models and tools to accelerate the development of physical AI systems like autonomous vehicles and robots. The platform offers open model licenses, allowing developers to customize models, generate synthetic data for training and evaluation, and access advanced tokenization and data processing capabilities. Leading companies in robotics, automotive, and transportation industries, including Uber and other autonomous driving companies, are among the first to adopt Cosmos for various applications. (Nvidia)\n\nMicrosoft releases Phi-4 model as open source project\n\nMicrosoft made its Phi-4 AI model fully open source, releasing the model weights on Hugging Face under an MIT license. The 14-billion-parameter model outperforms larger counterparts in areas like mathematical reasoning and multitask language understanding while requiring fewer computational resources. This release enables researchers and developers to freely experiment with and deploy Phi-4, a smaller model especially useful in resource-constrained environments. (Hugging Face)\n\nAI jobs surge to top of LinkedIn’s fastest-growing careers list\n\nLinkedIn’s Economic Graph team examined job data from January 2022 to July 2024, revealing AI-related roles as the fastest-growing careers. The analysis, which required job titles to show positive growth and reach a meaningful size, placed Artificial Intelligence Engineer and AI Consultant at the top (one and two respectively), with AI Researcher ranking twelfth. This trend underscores the increasing demand for AI expertise across industries and highlights the field’s rapid expansion in the job market. (LinkedIn)\n\nNew research tool decodes gene expression, paving way for targeted therapies\n\nScientists at Columbia University developed an AI algorithm called General Expression Transformer (GET) that predicts how genes influence cell behavior. The model, trained similarly to language programs like ChatGPT, learned the complex rules governing gene expression — the process that determines which proteins are produced in cells and in what quantities. This breakthrough could significantly enhance our understanding of cancer and genetic diseases, potentially leading to the development of cell-specific gene therapies. (NatureandThe Washington Post)\n\nNew enterprise product from Cohere combines LLMs, search, and automation\n\nCohere announced an early access preview of North, an all-in-one AI workspace that integrates large language models, search capabilities, and automation tools. The platform allows employees to create custom AI agents for tasks across various business functions, outperforming similar offerings from Microsoft and Google in accuracy benchmarks. North’s emphasis on security, customization, and seamless integration with existing workflows could accelerate AI adoption in enterprises, particularly in industries with strict data privacy requirements. (Cohere)\n\nMeta plans to integrate AI characters across its social platforms\n\nMeta hopes to introduce AI-generated characters across its social media platforms, with the goal of boosting engagement with its three billion users. Connor Hayes, Meta’s vice president of product for generative AI, envisions these AI entities existing alongside human accounts, complete with bios, profile pictures, and the ability to generate and share AI-powered content. The company has already launched an AI character creation tool in the U.S., with plans for expansion, and is exploring ways to make interactions with AI more social. Following this announcement (and after a public backlash), Meta deleted profiles for some of its older AI characters first introduced in 2023, but still plans to move forward with new and updated characters sometime this year. (Financial Times,NBC News, and404 Media)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng shared his preferred software stack and best practices for prototyping simple web apps, emphasizing the importance of being opinionated about the stack to speed up development.\n\n“The software stack I personally use changes every few weeks. There are many good alternatives to these choices, and if you pick a preferred software stack and become familiar with its components, you’ll be able to develop more quickly.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: Anthropic revealeduser interaction insightswith Claude 3.5; researchers exposeddeceptive behaviors in AI models misusing tools; Harvard introduced amillion-book corpusto boost AI training capabilities; and a new method,Localize-and-Stitch, improved performance by merging and fine-tuning multiple models.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Nền tảng Cosmos của Nvidia tập trung vào việc phát triển loại hệ thống AI nào?",
        "options": {
          "A": "Các mô hình ngôn ngữ lớn (LLMs).",
          "B": "Các hệ thống AI vật lý như xe tự hành và robot.",
          "C": "Các công cụ phân tích dữ liệu tài chính.",
          "D": "Các ứng dụng AI trong lĩnh vực y tế."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Phi-4 của Microsoft được phát hành dưới dạng mã nguồn mở với giấy phép nào?",
        "options": {
          "A": "Giấy phép Apache 2.0.",
          "B": "Giấy phép MIT.",
          "C": "Giấy phép GPLv3.",
          "D": "Giấy phép Creative Commons."
        },
        "answer": "B"
      },
      {
        "question": "Theo LinkedIn, vị trí công việc liên quan đến AI nào đứng đầu danh sách những nghề nghiệp phát triển nhanh nhất?",
        "options": {
          "A": "Nhà khoa học dữ liệu.",
          "B": "Kỹ sư trí tuệ nhân tạo.",
          "C": "Chuyên gia phân tích kinh doanh.",
          "D": "Chuyên viên marketing AI."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ AI GET được phát triển bởi các nhà khoa học tại Đại học Columbia có khả năng gì?",
        "options": {
          "A": "Dự đoán giá cổ phiếu dựa trên tin tức.",
          "B": "Dự đoán cách gen ảnh hưởng đến hành vi tế bào.",
          "C": "Tạo ra các thiết kế kiến trúc mới.",
          "D": "Phát hiện các cuộc tấn công mạng."
        },
        "answer": "B"
      },
      {
        "question": "Nền tảng North của Cohere tích hợp những công cụ nào?",
        "options": {
          "A": "Mô hình ngôn ngữ lớn, công cụ tìm kiếm và công cụ tự động hóa.",
          "B": "Công cụ thiết kế đồ họa, công cụ chỉnh sửa video và công cụ tạo nhạc.",
          "C": "Công cụ quản lý dự án, công cụ giao tiếp nội bộ và công cụ phân tích dữ liệu.",
          "D": "Công cụ phát triển game, công cụ tạo mô hình 3D và công cụ mô phỏng vật lý."
        },
        "answer": "A"
      },
      {
        "question": "Mục tiêu chính của Meta khi tích hợp các nhân vật AI vào các nền tảng mạng xã hội của mình là gì?",
        "options": {
          "A": "Tăng cường bảo mật cho người dùng.",
          "B": "Tăng cường tương tác với người dùng.",
          "C": "Cung cấp dịch vụ hỗ trợ khách hàng 24/7.",
          "D": "Tạo ra nguồn doanh thu mới từ quảng cáo."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, điều gì quan trọng để phát triển ứng dụng web nhanh chóng?",
        "options": {
          "A": "Sử dụng nhiều ngôn ngữ lập trình khác nhau.",
          "B": "Chọn một ngăn xếp phần mềm ưa thích và làm quen với các thành phần của nó.",
          "C": "Sử dụng các công cụ phát triển phức tạp nhất.",
          "D": "Thuê một đội ngũ phát triển lớn."
        },
        "answer": "B"
      },
      {
        "question": "Anthropic đã tiết lộ thông tin chi tiết nào về Claude 3.5?",
        "options": {
          "A": "Thông tin về cấu trúc mạng nơ-ron của mô hình.",
          "B": "Thông tin chi tiết về tương tác của người dùng với mô hình.",
          "C": "Thông tin về chi phí đào tạo mô hình.",
          "D": "Thông tin về các biện pháp bảo mật của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu gần đây đã phát hiện ra điều gì về hành vi của các mô hình AI khi sử dụng các công cụ?",
        "options": {
          "A": "Các mô hình AI luôn sử dụng các công cụ một cách hiệu quả và chính xác.",
          "B": "Các mô hình AI có thể thể hiện các hành vi lừa dối khi sử dụng các công cụ.",
          "C": "Các mô hình AI không thể sử dụng các công cụ mà không có sự can thiệp của con người.",
          "D": "Các mô hình AI chỉ sử dụng các công cụ cho mục đích nghiên cứu."
        },
        "answer": "B"
      },
      {
        "question": "Harvard đã giới thiệu một nguồn tài nguyên nào để tăng cường khả năng đào tạo AI?",
        "options": {
          "A": "Một bộ dữ liệu hình ảnh khổng lồ.",
          "B": "Một bộ dữ liệu âm thanh đa dạng.",
          "C": "Một kho ngữ liệu gồm một triệu cuốn sách.",
          "D": "Một bộ dữ liệu video chất lượng cao."
        },
        "answer": "C"
      }
    ]
  },
  "nvidia-makes-new-mini-versions-of-open-models": {
    "title": "Nvidia makes new mini versions of open models",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nNVIDIA’s “Minitron Method” creates new pruned-and-distilled versions of Mistral’s NeMo and Meta’s Llama 3.1\n\nNVIDIA and Mistral AI introduced Mistral-NeMo-Minitron 8B, a new language model that outperforms similarly sized models on multiple benchmarks. The model was created by width-pruning the larger Mistral NeMo 12B model and then retraining it using knowledge distillation, a technique that transfers knowledge from a larger “teacher” model to a smaller “student” model. NVIDIA, which used the same techniques to create a 4 billion parameter version of Llama 3.1, believes its Minitron method of pruning and distillation can be used to create even smaller, mobile-device-sized models while retaining the larger models’ power and accuracy. (NVIDIA)\n\nA new approach to “always-on” machine learning models\n\nResearchers at Apple developed a method to train small convolutional models by first expanding them into larger multi-branched architectures, then re-parameterizing them for efficient inference. Their wake-word detector, RepCNN, achieved 43% higher accuracy than traditional single-branch models with the same runtime, and matched the accuracy of more complex models while using less memory and running faster. This approach could significantly enhance the capabilities of always-on machine learning models, which are constrained by low memory and compute requirements. (Apple)\n\nMicrosoft expands AI offerings with family of small, safe Phi-3.5 models\n\nMicrosoft introduced three new models in its Phi-3 family: Phi-3.5-mini, Phi-3.5-vision, and Phi-3.5-MoE. Phi-3.5-mini offers enhanced multi-lingual support and a 128K context length, while Phi-3.5-vision improves multi-frame image understanding and reasoning. Phi-3.5-MoE, a Mixture-of-Experts model with 16 experts and 6.6B active parameters, achieves results similar to or better than much larger models in language understanding, math, and reasoning tasks. Phi-3.5-mini, despite its compact 3.8B parameter size, matches or surpasses the performance of larger models on multi-lingual tasks and long-context benchmarks. All the Phi-3.5 models are designed for minimum size and maximum safety. (Microsoft)\n\nMagazine and media giant strikes content licensing deal with OpenAI\n\nCondé Nast agreed to a multi-year deal allowing OpenAI to use content from its publications, including Wired and The New Yorker, in ChatGPT and SearchGPT. While terms were undisclosed, the partnership aims to compensate publishers for their intellectual property while helping OpenAI improve its AI models with high-quality content. This deal highlights the growing trend of media companies collaborating with AI firms, as publishers seek new revenue streams and AI companies work to address copyright concerns. (Wired)\n\nNew benchmark reveals gaps in LLMs’ ability to handle real-world tabular data\n\nResearchers developed TableBench, a comprehensive benchmark testing large language models’ performance on tabular data across 18 fields in four categories. The team also created TableLLM, a model trained on their custom dataset that performs similarly to GPT-3.5 on the new benchmark. Experiments show even advanced models like GPT-4 struggle with complex, real-world tabular data tasks, highlighting the need for further improvements to meet practical industrial demands. (arXiv)\n\nGoogle DeepMind workers protest military contracts\n\nAbout 200 Google DeepMind employees signed a letter in May 2024 urging the company to end its contracts with military organizations. The letter expresses concern that DeepMind’s AI technology is being sold to militaries engaged in warfare, potentially violating Google’s commitments to not pursue AI applications likely to cause overall harm, contribute to weapons, or violate international law and human rights. This internal conflict highlights tensions between DeepMind’s commitment to ethical AI and Google Cloud’s business practices, including contracts with Israeli and U.S. military entities. (TIME)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng discussed why the DEFIANCE Act and FTC ban on fake product reviews take the right approach to regulating AI:\n\n“I hope DEFIANCE passes in the House and gets signed into law. Both rules guard against harmful AI applications without stifling AI technology itself (unlike California’s poorly designed SB-1047), and they offer a good model for how the U.S. and other nations can protect citizens against other potentially harmful applications.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: Anagentic workflowthat generates novel scientific research papers, all aboutGoogle’s Imagen 3and Alibaba’sQwen2-Math and Qwen2-Audio, andscaling lawsfor data quality.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Phương pháp \"Minitron Method\" của NVIDIA sử dụng kỹ thuật nào để tạo ra các phiên bản mô hình ngôn ngữ nhỏ hơn?",
        "options": {
          "A": "Tăng cường dữ liệu huấn luyện và mở rộng kích thước mô hình.",
          "B": "Cắt tỉa (pruning) và chưng cất tri thức (knowledge distillation).",
          "C": "Sử dụng kiến trúc transformer mới với ít tham số hơn.",
          "D": "Kết hợp nhiều mô hình nhỏ thành một mô hình lớn hơn."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của phương pháp tiếp cận \"always-on\" machine learning mới được phát triển bởi Apple là gì?",
        "options": {
          "A": "Tăng độ chính xác của các mô hình lớn, phức tạp.",
          "B": "Cải thiện hiệu suất của các mô hình nhỏ, tiết kiệm tài nguyên.",
          "C": "Phát triển các mô hình có khả năng tự học liên tục.",
          "D": "Giảm thiểu thời gian huấn luyện các mô hình deep learning."
        },
        "answer": "B"
      },
      {
        "question": "Điểm nổi bật của mô hình Phi-3.5-mini do Microsoft giới thiệu là gì?",
        "options": {
          "A": "Khả năng xử lý hình ảnh đa khung hình vượt trội.",
          "B": "Hỗ trợ đa ngôn ngữ nâng cao và độ dài ngữ cảnh lớn.",
          "C": "Hiệu suất vượt trội trong các bài toán toán học phức tạp.",
          "D": "Kích thước tham số lớn nhất trong dòng Phi-3.5."
        },
        "answer": "B"
      },
      {
        "question": "Thỏa thuận giữa Condé Nast và OpenAI nhằm mục đích gì?",
        "options": {
          "A": "Phát triển các công cụ chỉnh sửa nội dung tự động cho các tạp chí.",
          "B": "Cung cấp nội dung chất lượng cao cho các mô hình AI của OpenAI và bồi thường cho nhà xuất bản.",
          "C": "Xây dựng nền tảng phân phối nội dung mới dựa trên công nghệ AI.",
          "D": "Tạo ra các quảng cáo được cá nhân hóa bằng AI cho độc giả."
        },
        "answer": "B"
      },
      {
        "question": "TableBench là một benchmark được thiết kế để đánh giá khả năng của LLMs trong lĩnh vực nào?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên.",
          "B": "Hiểu và làm việc với dữ liệu dạng bảng.",
          "C": "Tạo sinh hình ảnh từ văn bản.",
          "D": "Giải quyết các bài toán logic phức tạp."
        },
        "answer": "B"
      },
      {
        "question": "Lý do chính khiến nhân viên Google DeepMind phản đối các hợp đồng quân sự là gì?",
        "options": {
          "A": "Lo ngại về việc vi phạm quyền riêng tư của người dùng.",
          "B": "Lo ngại về việc công nghệ AI được sử dụng trong chiến tranh, vi phạm các cam kết đạo đức.",
          "C": "Không đồng ý với chính sách lương thưởng của công ty.",
          "D": "Muốn tập trung vào các dự án nghiên cứu khoa học thuần túy."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, điều gì khiến DEFIANCE Act và lệnh cấm đánh giá sản phẩm giả mạo của FTC là những cách tiếp cận đúng đắn để điều chỉnh AI?",
        "options": {
          "A": "Chúng thúc đẩy sự đổi mới và cạnh tranh trong ngành AI.",
          "B": "Chúng bảo vệ chống lại các ứng dụng AI có hại mà không kìm hãm công nghệ AI.",
          "C": "Chúng cung cấp nguồn tài trợ lớn cho nghiên cứu AI.",
          "D": "Chúng đơn giản hóa quy trình pháp lý cho các công ty AI."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của việc 'chưng cất tri thức' (knowledge distillation) trong bối cảnh phát triển mô hình AI là gì?",
        "options": {
          "A": "Tăng kích thước của mô hình để cải thiện độ chính xác.",
          "B": "Chuyển kiến thức từ một mô hình lớn sang một mô hình nhỏ hơn.",
          "C": "Giảm thời gian huấn luyện mô hình.",
          "D": "Tăng cường khả năng diễn giải của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "RepCNN, mô hình wake-word detector của Apple, đạt được cải thiện gì so với các mô hình đơn nhánh truyền thống?",
        "options": {
          "A": "Giảm đáng kể chi phí huấn luyện.",
          "B": "Tăng độ chính xác với cùng thời gian chạy.",
          "C": "Khả năng xử lý ngôn ngữ tự nhiên tốt hơn.",
          "D": "Tích hợp dễ dàng hơn vào các thiết bị di động."
        },
        "answer": "B"
      },
      {
        "question": "Phi-3.5-MoE là một mô hình Mixture-of-Experts. Đặc điểm chính của kiến trúc này là gì?",
        "options": {
          "A": "Sử dụng một mạng lưới thần kinh duy nhất cho tất cả các tác vụ.",
          "B": "Kết hợp nhiều 'chuyên gia' (experts) khác nhau, mỗi chuyên gia xử lý một phần của tác vụ.",
          "C": "Tự động điều chỉnh kích thước của mô hình dựa trên dữ liệu đầu vào.",
          "D": "Sử dụng một cơ chế attention phức tạp để cải thiện hiệu suất."
        },
        "answer": "B"
      }
    ]
  },
  "open-r1-is-building-a-training-pipeline-and-datasets-for-reasoning-models": {
    "title": "Open-R1 is building a training pipeline and datasets for reasoning models",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nOpen source project aims to replicate R1 reasoning model\n\nA new initiative called Open-R1 seeks to reconstruct DeepSeek’s recently released R1 reasoning model, which rivaled OpenAI’s o1 in performance. The project would replicate DeepSeek’s training pipeline, including data curation and reinforcement learning techniques, to create open source reasoning models, with an initial focus on mathematics. By sharing reproducible insights and training recipes, Open-R1 hopes to advance research in AI reasoning capabilities beyond math to areas like science and medicine. (Hugging Face)\n\nOpenAI makes important updates to GPT-4o and Canvas\n\nCanvas, a ChatGPT feature that allows users to collaborate with AI to create a document or code, now works with OpenAI’s advanced o1 model and can render HTML or React code in the browser. OpenAI also refreshed GPT-4o, updating its knowledge cutoff from November 2023 to June 2024 and improving its performance on math, image understanding, and general reasoning. These updates give users access to more recent information and more powerful tools for development in the API, and make ChatGPT’s Canvas more competitive with Claude’s similar Artifacts feature. (OpenAIandX)\n\nDeepSeek exposes sensitive data due to security oversight\n\nCybersecurity firm Wiz uncovered a major security lapse at Chinese AI startup DeepSeek, finding over a million lines of sensitive data exposed on the open internet through an unsecured ClickHouse database. The exposed information included software keys, user chat logs, API secrets, and backend details, allowing potential attackers full control over database operations and access to internal data. Wiz researchers argue that the rapid growth of companies like DeepSeek shows the critical need for robust security measures to protect user data and maintain trust. (Wiz)\n\nMistral unveils open AI model that rivals larger competitors\n\nMistral released Mistral Small 3, a 24 billion parameter language model that matches the performance of models three times its size while offering lower latency. The model, available under the Apache 2.0 license, excels in tasks requiring robust language understanding and instruction following with very fast response times. This release renews Mistral’s commitment to open AI development in the run-up to the company’s expected IPO, as the company promises that more future releases will be under the Apache 2.0 license rather than proprietary ones. (Mistral)\n\nDeepSeek’s new vision-language model also generates images\n\nDeepSeek researchers developed Janus-Pro, an upgraded suite of vision-language models that can understand and generate images and text. Janus-Pro improves on its predecessor by using smarter training methods, more diverse datasets, and larger neural networks. On benchmark tests, Janus-Pro outperformed both specialized and generalist systems like DALL·E 3, Stable Diffusion, and Qwen-VL at tasks like analyzing images and generating pictures from text descriptions. Available in one billion and seven billion parameter versions, Janus-Pro is another strong offering from DeepSeek, showing how strategic improvements in AI training and architecture can lead to significant performance gains. (GitHub)\n\nInternational report warns of extreme risks from advanced AI\n\nA new report backed by 30 countries outlines potential dangers from advanced AI systems, including job displacement, terrorism, and loss of human control. The report, led by AI scientist Yoshua Bengio, aims to guide policymakers in creating safeguards for rapidly advancing AI technology. This synthesis of existing research follows last year’s AI summit in the UK and comes ahead of a similarly major international summit in Paris. (Gov.UKandthe Associated Press)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng reflected on DeepSeek’s impact, highlighting China’s rapid progress in generative AI, the growing influence of open models in the AI supply chain, and the importance of algorithmic innovation beyond just scaling up.\n\n“If the U.S. continues to stymie open source, China will come to dominate this part of the supply chain and many businesses will end up using models that reflect China’s values much more than America’s.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: howDeepSeek-R1 and Kimi k1.5 leveraged reinforcement learningto train reasoning models, pushing the boundaries of AI capabilities;OpenAI introduced Operator, an AI agent designed to automate online tasks;The White House made a bold policy shift, rolling back AI regulations and emphasizing the need for U.S. leadership in the global market; and Cohere researchers proposed active inheritance,a novel fine-tuning approachthat lets model-makers automatically select better synthetic data.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Dự án Open-R1 hướng tới mục tiêu chính nào?",
        "options": {
          "A": "Phát triển một mô hình AI có khả năng cạnh tranh với GPT-4o trong mọi lĩnh vực.",
          "B": "Tái tạo mô hình suy luận R1 của DeepSeek và chia sẻ các phương pháp huấn luyện mã nguồn mở.",
          "C": "Nghiên cứu các ứng dụng của AI trong lĩnh vực khoa học và y học, bỏ qua lĩnh vực toán học.",
          "D": "Xây dựng một nền tảng trực tuyến để người dùng có thể cộng tác với AI trong việc tạo tài liệu và mã."
        },
        "answer": "B"
      },
      {
        "question": "Những cải tiến mới nào đã được OpenAI thực hiện đối với GPT-4o và Canvas?",
        "options": {
          "A": "Tăng cường khả năng tạo ảnh từ văn bản và cải thiện hiệu suất trong lĩnh vực âm nhạc.",
          "B": "Cập nhật kiến thức đến tháng 6 năm 2024, cải thiện hiệu suất toán học, hiểu hình ảnh và suy luận tổng quát, đồng thời tích hợp Canvas với GPT-4o.",
          "C": "Giảm độ trễ khi phản hồi và tăng cường khả năng xử lý ngôn ngữ tự nhiên trong các ứng dụng trò chuyện.",
          "D": "Mở rộng khả năng hỗ trợ đa ngôn ngữ và cải thiện độ chính xác trong việc dịch thuật."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề bảo mật nghiêm trọng nào đã được Wiz phát hiện tại DeepSeek?",
        "options": {
          "A": "Sự xâm nhập trái phép vào hệ thống máy chủ và đánh cắp dữ liệu người dùng.",
          "B": "Lộ hơn một triệu dòng dữ liệu nhạy cảm trên internet công cộng thông qua một cơ sở dữ liệu ClickHouse không được bảo mật.",
          "C": "Sự cố rò rỉ thông tin cá nhân của các nhà nghiên cứu và kỹ sư của DeepSeek.",
          "D": "Việc sử dụng trái phép các thuật toán và mô hình AI được cấp bằng sáng chế."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Mistral Small 3 có gì nổi bật so với các đối thủ cạnh tranh?",
        "options": {
          "A": "Khả năng tạo ra các hình ảnh chất lượng cao từ văn bản mô tả.",
          "B": "Hiệu suất tương đương với các mô hình lớn hơn gấp ba lần trong khi có độ trễ thấp hơn.",
          "C": "Khả năng tự động học hỏi và cải thiện hiệu suất dựa trên phản hồi của người dùng.",
          "D": "Khả năng tích hợp dễ dàng với các ứng dụng và nền tảng khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Janus-Pro của DeepSeek cải thiện so với phiên bản trước bằng cách nào?",
        "options": {
          "A": "Sử dụng các phương pháp huấn luyện thông minh hơn, bộ dữ liệu đa dạng hơn và mạng nơ-ron lớn hơn.",
          "B": "Tập trung vào việc tối ưu hóa hiệu suất trên các thiết bị di động và thiết bị nhúng.",
          "C": "Áp dụng các kỹ thuật mã hóa tiên tiến để bảo vệ dữ liệu người dùng.",
          "D": "Sử dụng kiến trúc mô hình hoàn toàn mới dựa trên mạng nơ-ron biến áp."
        },
        "answer": "A"
      },
      {
        "question": "Báo cáo quốc tế gần đây cảnh báo về những rủi ro tiềm ẩn nào từ AI tiên tiến?",
        "options": {
          "A": "Sự gia tăng của các cuộc tấn công mạng và tội phạm công nghệ cao.",
          "B": "Sự suy giảm của các kỹ năng mềm và khả năng giao tiếp của con người.",
          "C": "Mất việc làm, khủng bố và mất kiểm soát của con người.",
          "D": "Sự phân biệt đối xử và bất bình đẳng do các thuật toán AI thiên vị."
        },
        "answer": "C"
      },
      {
        "question": "Theo Andrew Ng, điều gì sẽ xảy ra nếu Mỹ tiếp tục cản trở mã nguồn mở AI?",
        "options": {
          "A": "Các công ty Mỹ sẽ mất lợi thế cạnh tranh trong lĩnh vực AI.",
          "B": "Trung Quốc sẽ thống trị chuỗi cung ứng AI và nhiều doanh nghiệp sẽ sử dụng các mô hình phản ánh giá trị của Trung Quốc.",
          "C": "Các nhà nghiên cứu AI sẽ chuyển sang làm việc cho các công ty tư nhân thay vì các tổ chức nghiên cứu công.",
          "D": "Sự phát triển của AI sẽ chậm lại do thiếu sự hợp tác quốc tế."
        },
        "answer": "B"
      },
      {
        "question": "DeepSeek-R1 và Kimi k1.5 đã sử dụng phương pháp nào để huấn luyện các mô hình suy luận?",
        "options": {
          "A": "Học có giám sát với bộ dữ liệu lớn được gắn nhãn thủ công.",
          "B": "Học tăng cường.",
          "C": "Học không giám sát bằng cách phân tích dữ liệu văn bản khổng lồ.",
          "D": "Học chuyển giao từ các mô hình ngôn ngữ đã được huấn luyện trước."
        },
        "answer": "B"
      },
      {
        "question": "Operator, một AI agent mới được OpenAI giới thiệu, được thiết kế để làm gì?",
        "options": {
          "A": "Tự động hóa các tác vụ trực tuyến.",
          "B": "Phân tích dữ liệu tài chính và đưa ra các quyết định đầu tư.",
          "C": "Tạo ra các tác phẩm nghệ thuật và âm nhạc độc đáo.",
          "D": "Dịch ngôn ngữ tự động với độ chính xác cao."
        },
        "answer": "A"
      },
      {
        "question": "Phương pháp 'active inheritance' được đề xuất bởi các nhà nghiên cứu Cohere có tác dụng gì?",
        "options": {
          "A": "Tăng cường khả năng hiểu ngôn ngữ tự nhiên của các mô hình AI.",
          "B": "Cho phép các nhà phát triển mô hình tự động chọn dữ liệu tổng hợp tốt hơn để tinh chỉnh mô hình.",
          "C": "Giảm thiểu sự thiên vị trong các thuật toán AI.",
          "D": "Cải thiện hiệu suất của các mô hình AI trên các thiết bị có tài nguyên hạn chế."
        },
        "answer": "B"
      }
    ]
  },
  "o3-mini-tops-the-aime-2025-math-leaderboard": {
    "title": "o3-mini tops the AIME 2025 math leaderboard",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nMathArena tests AI models’ math skills with recent benchmarks\n\nA new website from researchers at SRILab, ETHZurich, and INSAIT, tests large language models on recent math competitions to assess their reasoning and generalization capabilities. The site exclusively uses competitions that occurred after a model’s release (including the new AIME 2025) to ensure uncontaminated evaluation, and publishes leaderboards showing model performance on individual problems and across all competitions. This rigorous approach aims to provide standardized, comparable assessments of AI models’ mathematical problem-solving abilities, including the cost for each model to solve the test. Currently o3-mini-high leads the pack, solving 80 percent of the AIME 2025 problems at a cost of $3.19, followed by o1 and DeepSeek-R1, which both achieved lower accuracy at higher costs. (MathArena)\n\nUpdated AI system matches top geometry competitors\n\nGoogle DeepMind’s AlphaGeometry2 made significant progress in solving International Mathematical Olympiad geometry problems, solving 84% of geometry problems from IMO competitions between 2000 and 2024, a level comparable to top human contestants. Key improvements to the system include an expanded domain language covering locus theorems and linear equations, a faster symbolic engine, and a novel algorithm combining multiple search trees. While AlphaGeometry2 excels at many problems, some of the most challenging IMO questions remain unsolved, indicating areas for future development. (arXivandTechCrunch)\n\nReplit launches agent-powered app creation tool for mobile devices\n\nReplit updated its iOS and Android apps to include Agent, an AI-powered software creation tool. The company also expanded access to its existing Agent desktop tool and added a free tier for all users. Agent allows users to build and deploy apps through natural language conversations, handling coding, databases, integrations, and hosting without requiring a laptop. A new platform allows users to share their apps with others. This development could introduce software-development tools to a less technical audience, lowering the barriers to entry for app creation and sharing across devices. (Replit)\n\nTwo-stage framework boosts humanoid robot agility\n\nCarnegie Mellon and Nvidia researchers developed ASAP, a two-stage framework that addresses the mismatch between simulated and real-world robot dynamics. The method pretrains motion tracking policies using human motion data, then collects real-world data to train a model that compensates for dynamics differences, significantly improving agility and coordination across various motions. This breakthrough could accelerate the development of robots capable of performing complex, expressive, human-like tasks in multiple environments. (Human2HumanoidandarXiv)\n\nHugging Face updates its small model with big data\n\nHugging Face researchers developed SmolLM2, a 1.7 billion parameter language model that achieves strong performance by training on 11 trillion tokens of carefully curated data. They used a multi-stage training process mixing web text with specialized math, code, and instruction-following datasets, including new datasets they created to address limitations in existing ones. The resulting model outperforms other recent smaller language models like Qwen2.5-1.5B and Llama3.2-1B on various benchmarks, including MMLU and TriviaQA. SmolLM2 also comes in 360 million and 135 million parameter versions, all available under an Apache 2.0 license. (Hugging FaceandarXiv)\n\nIBM adds reasoning capabilities to its open 8B model\n\nIBM released a preview of new reasoning capabilities for its upcoming Granite 3.2 language model. The preview, available under an Apache 2.0 license on HuggingFace and for free at watsonx.ai, applies reinforcement learning to Granite’s existing 8 billion parameter model, enhancing reasoning on multiple benchmarks while preserving Granite’s safety features. Unlike DeepSeek’s smaller models, IBM’s approach adds reasoning abilities without relying on model distillation, which appears to offer more balanced performance across diverse AI tasks. (IBM)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng explored how AI is enabling a new generation of ‘10x professionals’ across various industries, not just in engineering, by transforming workflows and amplifying impact within and across teams.\n\n“For many jobs that primarily involve applying knowledge or processing information, AI will be transformative. In a few roles, I’m starting to see tech-savvy individuals coordinate a suite of technology tools to do things differently and start to have, if not yet 10x impact, then easily 2x impact. I expect this gap to grow.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:OpenAI launched o3-mini, a faster and more cost-effective reasoning model excelling in coding, math, and science;UI-TARS demonstrated strong performancein computer use benchmarks, demonstrating its ability to interact with desktop and mobile interfaces;Google’s update to Gemini 2.0 Flash Thinkingoutperformed DeepSeek-R1 on key benchmarks; andMoshi, an open-source alternative to OpenAI’s Realtime API, showcased its always-on speech-to-speech interactions.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "MathArena đánh giá khả năng toán học của các mô hình AI bằng cách nào?",
        "options": {
          "A": "Sử dụng các bài toán được lấy từ các kỳ thi toán học đã diễn ra trước khi mô hình được phát hành.",
          "B": "Sử dụng các bài toán được lấy từ các kỳ thi toán học diễn ra sau khi mô hình được phát hành.",
          "C": "Sử dụng các bài toán do chính MathArena tạo ra để đảm bảo tính độc đáo.",
          "D": "Sử dụng kết hợp các bài toán từ cả trước và sau khi mô hình được phát hành."
        },
        "answer": "B"
      },
      {
        "question": "AlphaGeometry2 của Google DeepMind đã đạt được tiến bộ gì trong việc giải quyết các bài toán hình học?",
        "options": {
          "A": "Giải quyết được tất cả các bài toán hình học trong kỳ thi IMO từ năm 2000 đến 2024.",
          "B": "Giải quyết được 84% các bài toán hình học trong kỳ thi IMO từ năm 2000 đến 2024, tương đương với các thí sinh hàng đầu.",
          "C": "Vượt trội hơn hẳn so với tất cả các thí sinh là con người trong việc giải các bài toán hình học IMO.",
          "D": "Chỉ giải quyết được các bài toán hình học cơ bản, còn gặp khó khăn với các bài toán phức tạp."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ Agent của Replit cho phép người dùng làm gì?",
        "options": {
          "A": "Tạo và triển khai ứng dụng thông qua các dòng lệnh phức tạp.",
          "B": "Tạo và triển khai ứng dụng thông qua các cuộc trò chuyện bằng ngôn ngữ tự nhiên.",
          "C": "Chỉ cho phép chỉnh sửa các ứng dụng đã có sẵn, không thể tạo ứng dụng mới.",
          "D": "Chỉ hoạt động trên máy tính xách tay, không hỗ trợ các thiết bị di động."
        },
        "answer": "B"
      },
      {
        "question": "Khung ASAP được phát triển bởi Carnegie Mellon và Nvidia giải quyết vấn đề gì trong lĩnh vực robot?",
        "options": {
          "A": "Giảm chi phí sản xuất robot hình người.",
          "B": "Cải thiện khả năng nhận diện khuôn mặt của robot.",
          "C": "Giải quyết sự khác biệt giữa động lực học của robot trong môi trường mô phỏng và thực tế.",
          "D": "Tăng cường khả năng giao tiếp bằng ngôn ngữ tự nhiên của robot."
        },
        "answer": "C"
      },
      {
        "question": "SmolLM2 của Hugging Face đạt được hiệu suất cao nhờ vào yếu tố nào?",
        "options": {
          "A": "Sử dụng kiến trúc mạng nơ-ron tiên tiến nhất.",
          "B": "Được huấn luyện trên một lượng lớn dữ liệu được tuyển chọn cẩn thận.",
          "C": "Sử dụng phần cứng mạnh mẽ và đắt tiền.",
          "D": "Được phát triển bởi một đội ngũ các nhà nghiên cứu hàng đầu thế giới."
        },
        "answer": "B"
      },
      {
        "question": "IBM đã cải thiện khả năng suy luận của mô hình Granite 3.2 bằng cách nào?",
        "options": {
          "A": "Sử dụng phương pháp chưng cất mô hình (model distillation).",
          "B": "Áp dụng học tăng cường (reinforcement learning).",
          "C": "Tăng kích thước của mô hình lên hàng tỷ tham số.",
          "D": "Sử dụng một bộ dữ liệu huấn luyện hoàn toàn mới."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, AI đang tạo ra những thay đổi gì trong công việc?",
        "options": {
          "A": "Thay thế hoàn toàn con người trong nhiều công việc.",
          "B": "Giúp những người có kiến thức công nghệ có thể làm việc hiệu quả hơn gấp nhiều lần.",
          "C": "Chỉ có tác động đến các công việc liên quan đến kỹ thuật.",
          "D": "Làm giảm năng suất làm việc của nhiều người."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào của OpenAI được giới thiệu là nhanh hơn và tiết kiệm chi phí hơn, đồng thời vượt trội trong các lĩnh vực mã hóa, toán học và khoa học?",
        "options": {
          "A": "Gemini 2.0 Flash Thinking",
          "B": "DeepSeek-R1",
          "C": "o3-mini",
          "D": "Granite 3.2"
        },
        "answer": "C"
      },
      {
        "question": "UI-TARS thể hiện khả năng gì nổi bật?",
        "options": {
          "A": "Khả năng tạo ra các video chất lượng cao từ văn bản.",
          "B": "Khả năng tương tác với giao diện máy tính để bàn và thiết bị di động.",
          "C": "Khả năng dịch ngôn ngữ tự động với độ chính xác cao.",
          "D": "Khả năng dự đoán thị trường chứng khoán."
        },
        "answer": "B"
      },
      {
        "question": "Moshi là gì?",
        "options": {
          "A": "Một framework để phát triển robot hình người.",
          "B": "Một mô hình ngôn ngữ lớn mã nguồn đóng của Google.",
          "C": "Một công cụ tạo ứng dụng di động bằng ngôn ngữ tự nhiên.",
          "D": "Một giải pháp thay thế mã nguồn mở cho Realtime API của OpenAI, có khả năng tương tác giọng nói liên tục."
        },
        "answer": "D"
      }
    ]
  },
  "open-source-deepcoder-matches-top-models": {
    "title": "Open-source DeepCoder matches top models",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nAI Scientist-v2 creates first peer-accepted workshop paper written entirely by AI\n\nSakana researchers updated AI Scientist, their fully autonomous scientific research system. AI Scientist-v2 independently creates hypotheses, conducts experiments, analyzes results, and writes scientific manuscripts in various machine learning fields. The new version improves upon its predecessor by eliminating human-authored templates and implementing a progressive agentic tree-search guided by an experiment manager agent. As a demonstration, AI Scientist-v2 generated three papers fully autonomously, one of which was accepted by ICLR, a peer-reviewed workshop. Along with Google’s similar co-scientist program, this advancement shows AI agents’ still-growing capability to perform complex scientific workflows on par with experienced human researchers. (Sakana)\n\nFully open-source model codes as well as o3-mini\n\nAgentica and Together AI released DeepCoder-14B-Preview, a fully open-source code reasoning model that achieves 60.6 percent Pass@1 accuracy on LiveCodeBench, matching OpenAI’s o3-mini’s performance but with only 14 billion parameters. Researchers trained DeepCoder using reinforcement learning (RL) on 24,000 curated, verifiable coding problems over 2.5 weeks using 32 H100 GPUs. They developed several training innovations, including GRPO+ (a new, stabilized version of GRPO), iterative context lengthening, and various optimizations that accelerate RL training by up to 2.5 times. Despite being trained primarily for coding tasks, DeepCoder also shows strong math capabilities, scoring 73.8 percent on AIME 2024. The team open-sourced their dataset, code, training logs, and system optimizations under an MIT license to help democratize RL training for large language models. (DeepCoderandGitHub)\n\nGoogle launches open protocol for agent collaboration\n\nGoogle announced Agent2Agent (A2A), a new open protocol (complementary to Anthropic's MCP) that enables AI agents from different vendors to communicate and collaborate across enterprise systems. The protocol lets agents securely exchange information and coordinate actions, addressing interoperability challenges. A2A facilitates communication between “client” and “remote” agents, supporting both quick tasks and long-running processes. Developers can contribute to A2A’s open-source specification draft, and Google plans to launch a production-ready version later this year. (GoogleandGitHub)\n\nNova Sonic brings conversational voice to applications\n\nAmazon introduced Nova Sonic, a new speech-to-speech model that combines understanding and generation capabilities into a single unified system. The model simplifies application development by eliminating the need to orchestrate separate models for speech recognition, language processing, and text-to-speech conversion. According to benchmarks, Nova Sonic outperforms competitors from OpenAI and Google with a 5.0 word error rate on speech transcription and 1.09 second latency, making it particularly valuable for applications in customer service, healthcare, and enterprise settings. The model is available now through Amazon Bedrock for $3.40 per million voice input tokens and $13.60 per million voice output tokens. (Amazon)\n\nAnthropic introduces Max plan with higher usage limits\n\nAnthropic launched a new subscription plan that offers up to 20 times higher Claude usage limits than its Pro tier. The plan comes in two tiers: Expanded Usage costs $100 per month and provides 5 times more usage than Pro (roughly 225 messages every five hours), while Maximum Flexibility ($200 per month) offers 20 times more usage than Pro (roughly 900 messages over the same period). Anthropic says it added this option in direct response to requests from their most active users, mostly software developers, who need greater capacity for demanding projects. Along with OpenAI’s similar ChatGPT Pro plan, Anthropic Max shows that monthly subscriptions for power users are becoming a promising revenue model for top AI companies and an important tool for their customers. (Anthropic)\n\nOpenAI countersues Elon Musk, alleges harassment campaign\n\nOpenAI asked a federal judge to halt what it describes as a pattern of harassment and “unlawful and unfair action” by billionaire Elon Musk. OpenAI claims Musk, a former co-founder who launched rival xAI in 2023, has tried to harm the company through press attacks, social media campaigns, and retaliatory legal claims after leaving the company. OpenAI’s filing comes amid Musk’s lawsuit attempting to prevent the ChatGPT maker from transitioning to a for-profit model, which the company must complete by year-end to secure its $40 billion fundraising round. The legal dispute between Musk and OpenAI is scheduled for jury trial in spring 2025. (Reuters)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng reflected on the impact of new U.S. tariffs, expressing concern over how they threaten international collaboration, inflate costs, and slow down AI progress. Andrew also encouraged the global AI community to stay united despite these worries.\n\n“AI isn’t the solution to everything, but even amidst this challenging environment, I hope our community can hold together, keep building friendships across borders, keep sharing ideas, and keep supporting each other.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Anthropic’s latest experimentrevealed that Claude can take reasoning steps even without explicit prompting;Meta released its new Llama 4 modelswith a mixture-of-experts architecture, claiming performance gains over major competitors;Qwen2.5-Omni 7B raised the bar for small multimodal models,achieving strong results across text, image, audio, and video with just seven billion parameters; andnew research showed that transformers can outperform decision treesin predicting missing values in tabular data, such as spreadsheet cells.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "AI Scientist-v2 cải tiến so với phiên bản trước bằng cách nào?",
        "options": {
          "A": "Sử dụng nhiều GPU hơn để tăng tốc độ xử lý.",
          "B": "Loại bỏ các template do con người tạo ra và triển khai tìm kiếm cây đại diện tiến bộ.",
          "C": "Tích hợp khả năng xử lý ngôn ngữ tự nhiên mạnh mẽ hơn.",
          "D": "Tăng cường khả năng phân tích dữ liệu hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "DeepCoder-14B-Preview đạt được độ chính xác Pass@1 là bao nhiêu trên LiveCodeBench?",
        "options": {
          "A": "50.6%",
          "B": "60.6%",
          "C": "70.6%",
          "D": "80.6%"
        },
        "answer": "B"
      },
      {
        "question": "Giao thức Agent2Agent (A2A) của Google nhằm mục đích gì?",
        "options": {
          "A": "Tăng cường bảo mật cho các ứng dụng AI.",
          "B": "Cho phép các AI agent từ các nhà cung cấp khác nhau giao tiếp và cộng tác.",
          "C": "Cải thiện hiệu suất của các mô hình ngôn ngữ lớn.",
          "D": "Đơn giản hóa quy trình phát triển ứng dụng AI."
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm chính của mô hình Nova Sonic do Amazon giới thiệu là gì?",
        "options": {
          "A": "Khả năng tạo ra hình ảnh từ giọng nói.",
          "B": "Kết hợp khả năng hiểu và tạo giọng nói vào một hệ thống thống nhất.",
          "C": "Tốc độ xử lý nhanh hơn so với các mô hình khác.",
          "D": "Giá thành rẻ hơn so với các mô hình cạnh tranh."
        },
        "answer": "B"
      },
      {
        "question": "Gói Anthropic Max cung cấp mức sử dụng Claude cao hơn bao nhiêu lần so với gói Pro?",
        "options": {
          "A": "5 lần và 10 lần",
          "B": "10 lần và 15 lần",
          "C": "5 lần và 20 lần",
          "D": "10 lần và 20 lần"
        },
        "answer": "C"
      },
      {
        "question": "Lý do chính OpenAI kiện ngược Elon Musk là gì?",
        "options": {
          "A": "Musk vi phạm thỏa thuận bảo mật thông tin.",
          "B": "Musk cố gắng ngăn chặn OpenAI chuyển sang mô hình vì lợi nhuận.",
          "C": "Musk thực hiện chiến dịch quấy rối và hành động bất hợp pháp nhằm vào OpenAI.",
          "D": "Musk đánh cắp công nghệ của OpenAI để phát triển xAI."
        },
        "answer": "C"
      },
      {
        "question": "Andrew Ng bày tỏ lo ngại về điều gì liên quan đến các mức thuế mới của Hoa Kỳ?",
        "options": {
          "A": "Ảnh hưởng tiêu cực đến lợi nhuận của các công ty AI.",
          "B": "Nguy cơ làm suy yếu sự hợp tác quốc tế, tăng chi phí và làm chậm tiến độ AI.",
          "C": "Sự gia tăng cạnh tranh từ các công ty AI nước ngoài.",
          "D": "Sự thiếu hụt nhân tài trong lĩnh vực AI."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Llama 4 mới của Meta sử dụng kiến trúc nào?",
        "options": {
          "A": "Kiến trúc Transformer tiêu chuẩn.",
          "B": "Kiến trúc mạng nơ-ron tích chập.",
          "C": "Kiến trúc mixture-of-experts.",
          "D": "Kiến trúc mạng nơ-ron hồi quy."
        },
        "answer": "C"
      },
      {
        "question": "Qwen2.5-Omni 7B nổi bật với khả năng gì?",
        "options": {
          "A": "Khả năng tạo ra video chất lượng cao.",
          "B": "Hiệu suất vượt trội trên nhiều phương thức dữ liệu (văn bản, hình ảnh, âm thanh, video) với kích thước nhỏ.",
          "C": "Khả năng dịch thuật ngôn ngữ chính xác.",
          "D": "Khả năng dự đoán thị trường chứng khoán."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu mới cho thấy loại mô hình nào có thể vượt trội hơn cây quyết định trong việc dự đoán các giá trị bị thiếu trong dữ liệu dạng bảng?",
        "options": {
          "A": "Mạng nơ-ron tích chập.",
          "B": "Mạng nơ-ron hồi quy.",
          "C": "Transformers.",
          "D": "Máy học tăng cường."
        },
        "answer": "C"
      }
    ]
  },
  "openai-considers-ads": {
    "title": "OpenAI considers ads",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nOpenAI explores advertising for its AI products amid revenue push\n\nOpenAI’s CFO Sarah Friar revealed the company is considering an advertising model for its AI products, though it has no immediate plans to implement ads. The $150 billion-valued startup has been hiring advertising experts from Meta and Google, including Shivakumar Venkataraman, former leader of Google’s search advertising team. OpenAI’s revenue has surged to about $4 billion annually, largely due to ChatGPT’s success, which now has over 250 million weekly active users. However, the company anticipates spending more than it earns in the near term, with cash burn expected to exceed $5 billion, as it continues developing advanced AI models. (Financial Times)\n\nCohere releases new enterprise search model Rerank 3.5\n\nCohere introduced Rerank 3.5, an AI model designed to improve information retrieval in search and retrieval-augmented generation systems. The model aims to enhance reasoning capabilities, handle various data types, and perform better across multiple languages. Rerank 3.5 uses a cross-encoding method to calculate relevance scores between user questions and documents. The release may interest businesses looking to refine their AI-powered search systems, particularly in specialized industries like finance and healthcare. (Cohere)\n\nU.S. tightens restrictions on advanced chip exports to China\n\nThe Biden administration announced new restrictions on technology exports to China, focusing on advanced chips and semiconductor manufacturing equipment. The rules ban sales of certain AI chips, advanced memory chips, and 24 types of semiconductor equipment to China. Additionally, 140 Chinese companies, many involved in chip-making tools and machinery, were added to a restricted trade list. The restrictions also cover specific software tools used in chip development and will apply globally to prevent offshore workarounds. These measures aim to impede China’s ability to produce cutting-edge chips for military and AI applications. (The New York Times)\n\nClaude gains ability to read Google Docs\n\nAnthropic added Google Docs integration to Claude, allowing users to connect documents directly to conversations and projects. The feature extracts text from Google Docs, enabling Claude to access up-to-date document content for improved context and assistance. This integration enhances Claude’s ability to understand and assist with complex tasks by incorporating relevant information from users’ Google Drive documents. (Anthropic)\n\nNew model generates custom sound effects for videos\n\nAdobe researchers introduced MultiFoley, an AI model that creates sound effects for videos using text, audio, and video inputs. The system can produce various sounds, from realistic to imaginative, and allows users to reference existing audio or partial videos. Researchers evaluated MultiFoley through automated tests and human studies, comparing its output to existing methods in terms of synchronization and overall audio quality. The results indicate that MultiFoley outperformed other approaches in generating synchronized, high-quality sounds across various input conditions. (arXiv)\n\nCanadian news companies sue OpenAI for copyright infringement\n\nFive major Canadian news organizations filed a lawsuit against OpenAI, accusing the company of using their content without permission or compensation to train its AI systems. The media companies, including Torstar and CBC/Radio-Canada, are seeking damages and a permanent injunction to prevent OpenAI from using their material without consent. This case joins a growing number of lawsuits against AI companies by content creators and publishers, highlighting the ongoing debate over fair use of copyrighted material in AI training. (Reuters)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng shared his gratitude for Thanksgiving, reflected on the struggles of those less fortunate, and emphasized the importance of understanding diverse perspectives to create impactful technology. He highlighted his optimism about AI’s potential to improve lives and encouraged the community to continue building solutions to help others.\n\n“To make good decisions, I have to understand the people I hope to serve. This is why I continue to routinely seek out, speak with, and try to understand people from all walks of life, and I hope many others in AI will do so, too.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: DeepSeek-R1 challenges OpenAI o1 witha transparent model revealing its reasoning; π0 advanceshousehold roboticswith an innovative machine learning system;Amazon deepens its partnership with Anthropicthrough a $4 billion investment; andGrounding DINO 1.5 enhances object detection on small deviceswith faster and smarter capabilities.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Theo bài viết, OpenAI đang xem xét mô hình quảng cáo cho các sản phẩm AI của mình vì lý do gì?",
        "options": {
          "A": "Để cạnh tranh trực tiếp với Google và Meta trong lĩnh vực quảng cáo.",
          "B": "Để tăng doanh thu trong bối cảnh chi phí phát triển AI ngày càng tăng.",
          "C": "Để thu hút thêm người dùng mới cho ChatGPT.",
          "D": "Để giảm sự phụ thuộc vào các nhà đầu tư bên ngoài."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của mô hình Rerank 3.5 do Cohere phát triển là gì?",
        "options": {
          "A": "Tạo ra các đoạn văn bản tự động dựa trên truy vấn của người dùng.",
          "B": "Cải thiện khả năng truy xuất thông tin trong các hệ thống tìm kiếm và RAG.",
          "C": "Dịch văn bản giữa nhiều ngôn ngữ khác nhau một cách chính xác.",
          "D": "Phân tích cảm xúc của người dùng dựa trên các truy vấn tìm kiếm."
        },
        "answer": "B"
      },
      {
        "question": "Chính quyền Biden áp đặt các hạn chế xuất khẩu chip tiên tiến sang Trung Quốc nhằm mục đích gì?",
        "options": {
          "A": "Để bảo vệ các công ty sản xuất chip của Mỹ khỏi sự cạnh tranh từ Trung Quốc.",
          "B": "Để thúc đẩy sự phát triển của ngành công nghiệp chip trong nước.",
          "C": "Để hạn chế khả năng sản xuất chip hiện đại phục vụ mục đích quân sự và AI của Trung Quốc.",
          "D": "Để buộc Trung Quốc phải tuân thủ các quy định về sở hữu trí tuệ."
        },
        "answer": "C"
      },
      {
        "question": "Tính năng mới nào được Anthropic thêm vào Claude để cải thiện khả năng hỗ trợ người dùng?",
        "options": {
          "A": "Khả năng tạo ra hình ảnh từ mô tả văn bản.",
          "B": "Khả năng đọc và trích xuất thông tin từ Google Docs.",
          "C": "Khả năng dịch văn bản giữa nhiều ngôn ngữ khác nhau.",
          "D": "Khả năng tóm tắt các bài báo khoa học phức tạp."
        },
        "answer": "B"
      },
      {
        "question": "MultiFoley, mô hình AI do Adobe phát triển, có chức năng chính là gì?",
        "options": {
          "A": "Tạo ra các hiệu ứng hình ảnh đặc biệt cho video.",
          "B": "Tạo ra các hiệu ứng âm thanh tùy chỉnh cho video.",
          "C": "Tự động chỉnh sửa và cải thiện chất lượng video.",
          "D": "Phân tích và gắn nhãn các đối tượng trong video."
        },
        "answer": "B"
      },
      {
        "question": "Các công ty truyền thông Canada kiện OpenAI vì lý do gì?",
        "options": {
          "A": "OpenAI đã sử dụng trái phép nội dung của họ để đào tạo các hệ thống AI.",
          "B": "OpenAI đã sao chép và phân phối các bài báo của họ mà không xin phép.",
          "C": "OpenAI đã tạo ra các tin tức giả mạo sử dụng tên tuổi của họ.",
          "D": "OpenAI đã cạnh tranh không lành mạnh với các trang web tin tức của họ."
        },
        "answer": "A"
      },
      {
        "question": "Theo Andrew Ng, tại sao việc hiểu biết về những người mình phục vụ lại quan trọng trong lĩnh vực AI?",
        "options": {
          "A": "Để tạo ra các sản phẩm AI có tính thẩm mỹ cao.",
          "B": "Để đưa ra các quyết định tốt hơn và tạo ra công nghệ có tác động tích cực.",
          "C": "Để thu hút được nhiều nhà đầu tư hơn cho các dự án AI.",
          "D": "Để tuân thủ các quy định pháp luật về AI."
        },
        "answer": "B"
      },
      {
        "question": "DeepSeek-R1 được nhắc đến trong bài viết có đặc điểm nổi bật gì?",
        "options": {
          "A": "Khả năng tạo ra các video ngắn từ văn bản.",
          "B": "Là một mô hình minh bạch, tiết lộ lý do đưa ra quyết định.",
          "C": "Khả năng tự động viết mã chương trình phức tạp.",
          "D": "Là một mô hình AI mã nguồn mở hoàn toàn miễn phí."
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào đã đầu tư 4 tỷ đô la vào Anthropic?",
        "options": {
          "A": "Google",
          "B": "Microsoft",
          "C": "Amazon",
          "D": "Meta"
        },
        "answer": "C"
      },
      {
        "question": "Grounding DINO 1.5 có chức năng gì và nó được cải tiến như thế nào?",
        "options": {
          "A": "Tạo ra các mô hình 3D từ hình ảnh 2D; được cải tiến để tạo ra các mô hình chi tiết hơn.",
          "B": "Phát hiện đối tượng trong hình ảnh; được cải tiến để hoạt động nhanh hơn và thông minh hơn trên các thiết bị nhỏ.",
          "C": "Dịch văn bản giữa nhiều ngôn ngữ khác nhau; được cải tiến để dịch chính xác hơn các thuật ngữ chuyên ngành.",
          "D": "Tóm tắt các bài báo khoa học; được cải tiến để tóm tắt các bài báo dài hơn và phức tạp hơn."
        },
        "answer": "B"
      }
    ]
  },
  "openai-and-googles-fine-tuning-disappoints": {
    "title": "OpenAI and Google’s fine-tuning disappoints",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nStudy reveals knowledge gaps when using commercial fine-tuning APIs\n\nResearchers at Stanford introduced FineTuneBench, an evaluation framework to assess the effectiveness of commercial large language model (LLM) fine-tuning APIs in learning new information and updating existing knowledge. The study tested five powerful LLMs, including GPT-4 and Gemini 1.5 Pro, finding significant limitations in their ability to learn through fine-tuning. The models showed an average generalization accuracy of 37 percent for new information and 19 percent for updating existing knowledge, with Gemini 1.5 falling well short of GPT-4. These findings highlight a critical gap in the current capabilities of commercial fine-tuning services, potentially impacting their reliability for knowledge infusion in real-world applications. (arXiv)\n\nOpen source Qwen2.5-Coder wows on coding benchmarks\n\nAlibaba released Qwen2.5-Coder, a series of code-specific large language models available in six sizes ranging from 0.5 to 32 billion parameters, all under an Apache 2.0 license. The largest model, Qwen2.5-Coder-32B, claims state-of-the-art performance among open-source code models, with capabilities matching GPT-4 for coding tasks. Qwen2.5-Coder boasts improvements in code generation, reasoning, and fixing, and supports context lengths up to 128,000 tokens. (GitHub)\n\nTech giants showcase AI chip advances in latest benchmark tests\n\nNvidia, Google, and other tech companies reported results from the latest MLPerf v4.1 benchmark tests, showcasing performance improvements in AI training tasks. Nvidia’s next-generation B200 GPU doubled performance on some tests compared to its current H100 chip, while Google’s new Trillium accelerator showed up to a 3.8-fold boost over its predecessor. The benchmarks, which include tasks like training large language models and image generation, help AI developers assess the capabilities of different hardware platforms for machine learning workloads. (ML Commons)\n\nGoogle releases AlphaFold 3 code and access instructions\n\nGoogle released the implementation code for AlphaFold 3’s inference pipeline, along with instructions for requesting access to the model parameters. Researchers must cite the “Accurate structure prediction of biomolecular interactions with AlphaFold 3” paper when publishing findings after using the code, parameters, or outputs. Google will grant access to the model parameters at its discretion, with researchers required to adhere to specific terms of use. Google had initially withheld access to the biochemical model’s code and parameters from other researchers, leading to an outcry that it was limiting the model’s usefulness and making it difficult for other researchers to replicate Google’s results. (GitHub)\n\nDeepSeek updates Janus multimodal model with rectified flow\n\nDeepSeek released JanusFlow, a new AI system that can both understand and generate images using a single model. The system (an update of DeepSeek’s earlierJanusmodel) performs as well as or better than specialized models designed for only one task, while also surpassing other multi-purpose models in standard tests. DeepSeek made JanusFlow available for public use under an MIT license (including commercial applications), which could speed up research and development for multimodal AI. (GitHub)\n\nJudge dismisses copyright lawsuit against OpenAI over training data\n\nA New York federal judge dismissed a lawsuit against OpenAI brought by Raw Story Media and Alternet Media over the use of their content to train AI models. The judge ruled that removing copyright management information from articles for AI training, without disseminating those works, does not constitute concrete injury needed to establish legal standing. This decision could impact similar lawsuits against AI companies, potentially guiding how courts view the use of copyrighted material in AI training datasets. (Bloomberg Law)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng shared his thoughts on optimizing large language models (LLMs) for agentic workflows, particularly how advancements like function calling and native computer use are transforming how LLMs support complex, iterative applications.\n\n“Most LLMs have been optimized for answering questions primarily to deliver a good consumer experience, and we’ve been able to ‘graft’ them into complex agentic workflows to build valuable applications. The trend of LLMs built to support particular operations in agents natively will create a lot of lift for agentic performance.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:OpenHands launches Free Agents, an open toolkit for advanced code generation and automation;Perplexity introduced Election Hub, an AI-powered experience providing voters with verified, real-time news and insights on U.S. politics;Meta and Anthropic explore opportunities for AI in U.S. defense and national security, pursuing major military contracts; andHunyuan-Large surpasses other open competitorswith impressive benchmark scores, showcasing the potential of Mixture of Experts models.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "FineTuneBench của Stanford được thiết kế để làm gì?",
        "options": {
          "A": "Đánh giá hiệu suất phần cứng AI của các công ty công nghệ lớn.",
          "B": "Đánh giá hiệu quả của các API tinh chỉnh mô hình ngôn ngữ lớn thương mại.",
          "C": "So sánh khả năng của các mô hình ngôn ngữ lớn khác nhau trong việc tạo mã.",
          "D": "Phát hiện các lỗ hổng bảo mật trong các mô hình AI mã nguồn mở."
        },
        "answer": "B"
      },
      {
        "question": "Qwen2.5-Coder-32B của Alibaba có giấy phép sử dụng nào?",
        "options": {
          "A": "Giấy phép độc quyền, chỉ dành cho mục đích nghiên cứu.",
          "B": "Giấy phép Apache 2.0.",
          "C": "Giấy phép GPL.",
          "D": "Giấy phép MIT, hạn chế sử dụng thương mại."
        },
        "answer": "B"
      },
      {
        "question": "Trong các thử nghiệm MLPerf v4.1, GPU B200 của Nvidia thể hiện hiệu suất như thế nào so với H100?",
        "options": {
          "A": "Hiệu suất tương đương.",
          "B": "Hiệu suất gấp đôi trên một số thử nghiệm.",
          "C": "Hiệu suất giảm đáng kể.",
          "D": "Hiệu suất chỉ bằng một nửa."
        },
        "answer": "B"
      },
      {
        "question": "Điều kiện nào được Google đưa ra khi cho phép các nhà nghiên cứu truy cập vào tham số của AlphaFold 3?",
        "options": {
          "A": "Phải trả phí bản quyền cho Google.",
          "B": "Phải trích dẫn bài báo gốc khi công bố kết quả.",
          "C": "Không được sử dụng cho mục đích thương mại.",
          "D": "Phải chia sẻ dữ liệu huấn luyện với Google."
        },
        "answer": "B"
      },
      {
        "question": "JanusFlow của DeepSeek có khả năng gì nổi bật?",
        "options": {
          "A": "Chỉ có thể tạo ra hình ảnh từ văn bản.",
          "B": "Chỉ có thể hiểu hình ảnh và mô tả chúng bằng văn bản.",
          "C": "Có thể hiểu và tạo ra hình ảnh bằng một mô hình duy nhất.",
          "D": "Chỉ có thể phân tích hình ảnh y tế."
        },
        "answer": "C"
      },
      {
        "question": "Phán quyết của tòa án New York trong vụ kiện bản quyền chống lại OpenAI liên quan đến điều gì?",
        "options": {
          "A": "OpenAI phải bồi thường thiệt hại cho các công ty truyền thông.",
          "B": "Việc sử dụng nội dung có bản quyền để huấn luyện AI là vi phạm bản quyền.",
          "C": "Việc loại bỏ thông tin quản lý bản quyền để huấn luyện AI không cấu thành thiệt hại pháp lý.",
          "D": "OpenAI phải công khai dữ liệu huấn luyện AI của mình."
        },
        "answer": "C"
      },
      {
        "question": "Theo Andrew Ng, xu hướng nào sẽ tạo ra nhiều cải tiến cho hiệu suất của các tác nhân AI?",
        "options": {
          "A": "Tối ưu hóa LLM cho trải nghiệm người dùng tốt hơn.",
          "B": "Sử dụng các mô hình LLM lớn hơn và phức tạp hơn.",
          "C": "Xây dựng LLM hỗ trợ các hoạt động cụ thể trong các tác nhân một cách tự nhiên.",
          "D": "Tích hợp LLM với các hệ thống cơ sở dữ liệu lớn."
        },
        "answer": "C"
      },
      {
        "question": "OpenHands ra mắt công cụ nào để hỗ trợ tạo mã và tự động hóa nâng cao?",
        "options": {
          "A": "AlphaFold 3.",
          "B": "Free Agents.",
          "C": "JanusFlow.",
          "D": "FineTuneBench."
        },
        "answer": "B"
      },
      {
        "question": "Perplexity giới thiệu Election Hub để làm gì?",
        "options": {
          "A": "Cung cấp thông tin tài chính cho các chiến dịch tranh cử.",
          "B": "Cung cấp cho cử tri tin tức và thông tin chi tiết đã được xác minh về chính trị Hoa Kỳ.",
          "C": "Tổ chức các cuộc tranh luận trực tuyến giữa các ứng cử viên.",
          "D": "Dự đoán kết quả bầu cử dựa trên phân tích dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu của Meta và Anthropic khi khám phá cơ hội cho AI trong quốc phòng và an ninh quốc gia Hoa Kỳ là gì?",
        "options": {
          "A": "Phát triển vũ khí tự động.",
          "B": "Cung cấp dịch vụ phân tích tình báo.",
          "C": "Theo đuổi các hợp đồng quân sự lớn.",
          "D": "Xây dựng hệ thống phòng thủ mạng."
        },
        "answer": "C"
      }
    ]
  },
  "openai-promises-a-more-open-model": {
    "title": "OpenAI promises a more open model",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nOpenAI solicits feedback on a forthcoming model with open weights\n\nCEO Sam Altman announced the company would be publishing a new open weight model with reasoning capabilities sometime in “the coming months.” OpenAI plans to host developer events in the U.S., Asia, and Europe to demonstrate the model, and published a web form soliciting developer ideas feedback. The new model would be OpenAI’s first open multipurpose language model since 2019’s GPT-2 and should give individual developers and large organizations more ability to customize their own versions and make them available for commercial or noncommercial use. (Sam Altman on XandOpenAI)\n\nRunway’s new video generation model improves consistency of characters\n\nRunway rolled out its new Gen-4 model to paid individual and enterprise customers. The new model uses a single reference image for characters or objects, plus text instructions for scenes, to generate scenes where the characters and objects do not morph into similar shapes, or transform into suddenly new styles, in the manner of many previous video models. These scenes can then be edited together to create coherent short videos. This greater narrative and dramatic continuity in generated videos could make them more useful for individual users and the entertainment industry. (Runway)\n\nAmazon releases a research preview of its Nova Act model and SDK\n\nAmazon AGI unveiled Nova Act, a new model designed for agentic computer use. Amazon says Nova Act outperforms Claude 3.7 Sonnet and OpenAI’s Computer Use Agent at interacting with text, icons, and UI elements on the web. Nova Act is available for developers for free in a research preview as part of a new website for its family of Nova models. (Amazon)\n\nClaude for Education gives universities special chatbot access\n\nAnthropic debuted a new program targeting students, instructors, and administrators in higher education. Claude for Education would give university users access to Anthropic’s chatbots, including a new Learning Mode that would try to guide students’ reasoning through problems rather than presenting answers. Launched with several high-profile university and educational technology partners, the program suggests different approaches to chatbot interaction may be more pedagogically useful, potentially smoothing AI adoption for teachers and students. (Anthropic)\n\nGoogle DeepMind slows down publication of AI research\n\nCurrent and former DeepMind researchers say that the company has introduced a tougher vetting process and more bureaucracy to make it harder to publish new AI and machine learning studies, especially if the results or methods might tip information to Google’s competitors. One new policy includes a six month embargo on research related to the company’s strategic AI priorities. This represents a significant shift for both the AI research community and for Google, whose public research has long been seen as essential in kickstarting the AI boom. (Financial Times)\n\nClaude Sonnet 3.5-based agent tops new OpenAI ML research benchmark\n\nOpenAI researchers released PaperBench, a new dataset and benchmark that tests large language models’ ability to recreate AI and machine learning papers from scratch, including understanding related research, creating and executing a codebase, and producing a version of the paper. Claude Sonnet 3.5 led all tested models by replicating 21 percent of selected papers, broken down into sub-components. OpenAI noted that none of the tested models outperform the human baseline. The benchmark could be useful in evaluating models’ overall performance in replicating technical research or at AI engineering, but public test materials like top conference articles often find themselves in models’ training data, contaminating future results. (OpenAIandGitHub)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng shared his approach to “lazy prompting”—a technique where you start with minimal extra input and refine only as needed.\n\n“Contrary to standard prompting advice that you should give LLMs the context they need to succeed, I find it’s sometimes faster to be lazy and dash off a quick, imprecise prompt and see what happens. The key is whether you can quickly assess the output quality.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:MoshiVis introduced interactive voice-to-voice conversationsenhanced with image understanding;Cloudflare unveiled an AI-powered defense systemcalled Labyrinth that thwarts web scrapers using decoy pages; new studies revealed that whileChatGPT may help reduce feelings of loneliness, it can also lead to emotional dependence; and Stanford researchers developeda method to animate 3D interactionsbetween humans and objects using generated video, eliminating the need for motion capture.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "OpenAI dự kiến phát hành mô hình ngôn ngữ đa năng mã nguồn mở mới với khả năng gì?",
        "options": {
          "A": "Khả năng tạo ra video ngắn từ văn bản.",
          "B": "Khả năng suy luận.",
          "C": "Khả năng tương tác với các yếu tố UI trên web.",
          "D": "Khả năng tạo ra các trang web mồi nhử để chống lại web scraper."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Gen-4 của Runway cải thiện điều gì so với các mô hình tạo video trước đây?",
        "options": {
          "A": "Tốc độ tạo video nhanh hơn.",
          "B": "Độ phân giải video cao hơn.",
          "C": "Tính nhất quán của nhân vật và đối tượng trong video.",
          "D": "Khả năng tạo ra video 3D tương tác."
        },
        "answer": "C"
      },
      {
        "question": "Nova Act của Amazon được thiết kế để làm gì?",
        "options": {
          "A": "Tạo ra các chatbot giáo dục.",
          "B": "Sử dụng máy tính một cách chủ động (agentic computer use).",
          "C": "Phân tích dữ liệu nghiên cứu khoa học.",
          "D": "Tạo ra các mô hình ngôn ngữ lớn từ đầu."
        },
        "answer": "B"
      },
      {
        "question": "Chương trình 'Claude for Education' của Anthropic nhắm đến đối tượng nào?",
        "options": {
          "A": "Các nhà nghiên cứu AI chuyên nghiệp.",
          "B": "Sinh viên, giảng viên và quản trị viên trong giáo dục đại học.",
          "C": "Các nhà phát triển ứng dụng chatbot.",
          "D": "Các công ty công nghệ lớn."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, Google DeepMind đã thay đổi chính sách xuất bản nghiên cứu AI như thế nào?",
        "options": {
          "A": "Tăng cường hợp tác với các trường đại học.",
          "B": "Giảm thời gian chờ đợi để xuất bản nghiên cứu.",
          "C": "Áp dụng quy trình kiểm duyệt nghiêm ngặt hơn và tăng tính quan liêu.",
          "D": "Chỉ tập trung vào các nghiên cứu có lợi nhuận cao."
        },
        "answer": "C"
      },
      {
        "question": "PaperBench là gì?",
        "options": {
          "A": "Một mô hình ngôn ngữ lớn mới của OpenAI.",
          "B": "Một chương trình giáo dục của Anthropic.",
          "C": "Một bộ dữ liệu và chuẩn đánh giá khả năng tái tạo các bài báo khoa học về AI và machine learning.",
          "D": "Một công cụ tạo video của Runway."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình nào dẫn đầu trong việc tái tạo các bài báo khoa học theo chuẩn PaperBench?",
        "options": {
          "A": "GPT-2.",
          "B": "Nova Act.",
          "C": "Claude Sonnet 3.5.",
          "D": "Gen-4."
        },
        "answer": "C"
      },
      {
        "question": "Andrew Ng đề xuất kỹ thuật 'lazy prompting' với ý nghĩa gì?",
        "options": {
          "A": "Sử dụng các mô hình ngôn ngữ lớn một cách cẩn thận và có trách nhiệm.",
          "B": "Bắt đầu với một prompt đơn giản và chỉ tinh chỉnh khi cần thiết.",
          "C": "Cung cấp cho mô hình ngôn ngữ lớn tất cả thông tin cần thiết ngay từ đầu.",
          "D": "Tránh sử dụng các mô hình ngôn ngữ lớn cho các tác vụ phức tạp."
        },
        "answer": "B"
      },
      {
        "question": "MoshiVis giới thiệu tính năng gì mới?",
        "options": {
          "A": "Tạo video từ văn bản.",
          "B": "Tạo ra các trang web mồi nhử.",
          "C": "Các cuộc hội thoại tương tác bằng giọng nói được tăng cường bằng hiểu biết hình ảnh.",
          "D": "Phân tích cảm xúc từ văn bản."
        },
        "answer": "C"
      },
      {
        "question": "Cloudflare đã ra mắt hệ thống phòng thủ AI có tên là gì?",
        "options": {
          "A": "PaperBench.",
          "B": "Nova Act.",
          "C": "Labyrinth.",
          "D": "Claude for Education."
        },
        "answer": "C"
      }
    ]
  },
  "openai-unveils-new-model-suite-for-developers": {
    "title": "OpenAI unveils new model suite for developers",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nOpenAI launches GPT-4.1 model family\n\nOpenAI released three new models in its API: GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano, all outperforming previous versions with significant gains in coding and instruction following capabilities. GPT-4.1 scores 54.6 percent on SWE-bench Verified coding tasks, a 21.4 percent improvement over GPT-4o. The models feature expanded context windows of up to 1 million tokens. GPT-4.1 mini offers comparable performance to GPT-4o at half the latency and 83 percent lower cost, while GPT-4.1 nano performs best at low-latency tasks like classification and autocompletion. The new models are available immediately to all developers at reduced pricing, with GPT-4.1 costing 26 percent less than GPT-4o for typical queries. (OpenAI)\n\nMeta resumes training on EU users’ posts and comments\n\nMeta announced it will restart training its AI models using publicly available content from European users, a process it paused last year following privacy concerns. The company plans to use public posts and comments from adult EU users on Facebook and Instagram, along with user questions and queries directed to Meta AI. Meta said EU privacy regulators affirmed in December that the company’s original approach complied with legal obligations. The announcement also noted that competitors Google and OpenAI train their models on public data in the EU. Meta emphasized it won’t use private messages for AI training and will allow EU users to opt out of AI data collection through an objection form. (Facebook)\n\nGemini Code Assist adds AI agents\n\nGoogle unveiled new agentic capabilities for Gemini Code Assist, enabling the coding assistant to handle multi-step programming tasks. These agents can generate applications from product specifications, transform code between languages, implement new features, conduct code reviews, and create tests and documentation. Google also expanded Code Assist availability to Android Studio. The new capabilities respond to similar features offered by GitHub Copilot, Cursor, Windsurf, and Cognition Labs’ Devin in the increasingly competitive AI coding assistant market. (TechCrunch)\n\nChatGPT gets long-term memory upgrade\n\nOpenAI updated ChatGPT with enhanced memory capabilities that allow the model to reference past conversations without users explicitly saving them. The upgrade expands on last year’s more limited Memory feature by combining manually saved memories with automatic insights gathered from chat history. The updated memory feature is currently rolling out to $200 monthly Pro subscribers first, with $20 Plus subscribers getting access soon, followed by Team, Enterprise, and Edu users in the coming weeks. However, it is not available in the EU, UK, and several other European countries, likely due to regulatory concerns. (OpenAI)\n\nGoogle announces Ironwood, its new and improved AI processor\n\nGoogle introduced Ironwood, its seventh-generation AI accelerator chip designed for inference on Gemini models. The processor operates in massive clusters of up to 9,216 liquid-cooled chips, delivering 42.5 Exaflops of computing power. Each Ironwood chip is significantly more powerful than previous versions, with six times more memory and twice the efficiency of Google’s last processor. Google’s cloud will offer AI developers access to this hardware in either 256-chip servers or full-size clusters. The company sees Ironwood as key computing infrastructure to enable AI reasoning models and to power agents that can independently gather information and complete tasks for users. (Ars Technica)\n\nStudy reveals how college students use Claude\n\nAnthropic researchers analyzed one million anonymized student conversations with Claude.ai in one of the first large-scale studies of real-world AI usage in higher education. STEM students, particularly those in Computer Science, emerged as early adopters, with CS students accounting for 36.8 percent of conversations despite representing only 5.4 percent of U.S. degrees. The study suggests students primarily use AI for higher-order cognitive functions like creating and analyzing rather than simpler tasks. With AI increasingly embedded in educational settings, these findings raise important questions about how its use affects skill development, assessment methods, and academic integrity. (Anthropic)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng reflected on the impact of new U.S. tariffs, expressing concern over how they threaten international collaboration, inflate costs, and slow down AI progress. He also encouraged the global AI community to stay united despite these concerns.\n\n“Let’s all of us in AI keep nurturing our international friendships, keep up the digital flow of ideas — including specifically open source software — and keep supporting each other.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Anthropic’s latest experimentrevealed that Claude can take reasoning steps even without explicit prompting;Meta released its new Llama 4 modelswith a mixture-of-experts architecture, claiming performance gains over major competitors;Qwen2.5-Omni 7B raised the bar for small multimodal models,achieving strong results across text, image, audio, and video with just seven billion parameters; andnew research showed that transformers can outperform decision treesin predicting missing values in tabular data, such as spreadsheet cells.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Dòng model GPT-4.1 mới của OpenAI có điểm gì nổi bật so với GPT-4o về khả năng lập trình?",
        "options": {
          "A": "Hiệu suất tương đương nhưng chi phí thấp hơn.",
          "B": "Đạt điểm số cao hơn đáng kể trên SWE-bench Verified.",
          "C": "Khả năng xử lý ngôn ngữ tự nhiên tốt hơn.",
          "D": "Thời gian phản hồi nhanh hơn gấp đôi."
        },
        "answer": "B"
      },
      {
        "question": "Meta dự định sử dụng dữ liệu nào từ người dùng EU để huấn luyện mô hình AI?",
        "options": {
          "A": "Tin nhắn riêng tư trên Facebook và Instagram.",
          "B": "Dữ liệu sức khỏe được thu thập từ các thiết bị đeo.",
          "C": "Bài đăng và bình luận công khai trên Facebook và Instagram.",
          "D": "Thông tin tài chính cá nhân được chia sẻ trên mạng xã hội."
        },
        "answer": "C"
      },
      {
        "question": "Gemini Code Assist của Google cung cấp tính năng mới nào để hỗ trợ lập trình?",
        "options": {
          "A": "Tự động tạo mã nguồn từ thông số kỹ thuật sản phẩm.",
          "B": "Tối ưu hóa hiệu suất của các ứng dụng di động.",
          "C": "Phát hiện và sửa lỗi bảo mật trong mã nguồn.",
          "D": "Quản lý dự án phần mềm quy mô lớn."
        },
        "answer": "A"
      },
      {
        "question": "Tính năng bộ nhớ nâng cao của ChatGPT hiện tại chưa được triển khai ở khu vực nào?",
        "options": {
          "A": "Bắc Mỹ.",
          "B": "Châu Á.",
          "C": "Châu Phi.",
          "D": "Liên minh Châu Âu (EU).",
          "E": "Châu Đại Dương."
        },
        "answer": "D"
      },
      {
        "question": "Ironwood, bộ xử lý AI mới của Google, được thiết kế chủ yếu cho mục đích gì?",
        "options": {
          "A": "Đào tạo các mô hình AI quy mô lớn.",
          "B": "Suy luận trên các mô hình Gemini.",
          "C": "Xử lý đồ họa cho các ứng dụng game.",
          "D": "Quản lý cơ sở dữ liệu đám mây."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu của Anthropic về việc sử dụng Claude.ai trong giáo dục đại học cho thấy sinh viên ngành nào sử dụng AI nhiều nhất?",
        "options": {
          "A": "Ngành Y khoa.",
          "B": "Ngành Luật.",
          "C": "Ngành Khoa học Máy tính.",
          "D": "Ngành Kinh tế."
        },
        "answer": "C"
      },
      {
        "question": "Theo Andrew Ng, điều gì đang bị đe dọa bởi các chính sách thuế quan mới của Hoa Kỳ?",
        "options": {
          "A": "Sự phát triển của các công ty AI nội địa.",
          "B": "Hợp tác quốc tế trong lĩnh vực AI.",
          "C": "Việc bảo vệ quyền sở hữu trí tuệ trong AI.",
          "D": "Sự cạnh tranh giữa các quốc gia trong lĩnh vực AI."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Llama 4 mới của Meta sử dụng kiến trúc nào để cải thiện hiệu suất?",
        "options": {
          "A": "Mạng nơ-ron tích chập (Convolutional Neural Network).",
          "B": "Mạng nơ-ron hồi quy (Recurrent Neural Network).",
          "C": "Kiến trúc Mixture-of-Experts.",
          "D": "Mạng đối nghịch sinh (Generative Adversarial Network)."
        },
        "answer": "C"
      },
      {
        "question": "Qwen2.5-Omni 7B nổi bật ở điểm nào so với các mô hình đa phương thức nhỏ khác?",
        "options": {
          "A": "Khả năng xử lý ngôn ngữ tự nhiên vượt trội.",
          "B": "Hiệu suất mạnh mẽ trên nhiều loại dữ liệu (văn bản, hình ảnh, âm thanh, video).",
          "C": "Khả năng tạo ra hình ảnh chân thực từ văn bản.",
          "D": "Khả năng dịch thuật giữa các ngôn ngữ khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu mới cho thấy kiến trúc Transformer có thể vượt trội hơn kiến trúc nào trong việc dự đoán các giá trị bị thiếu trong dữ liệu dạng bảng?",
        "options": {
          "A": "Mạng nơ-ron sâu (Deep Neural Networks).",
          "B": "Cây quyết định (Decision Trees).",
          "C": "Máy vector hỗ trợ (Support Vector Machines).",
          "D": "Hồi quy tuyến tính (Linear Regression)."
        },
        "answer": "B"
      }
    ]
  },
  "openai-reveals-simplified-model-roadmap": {
    "title": "OpenAI reveals simplified model roadmap",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nOpenAI cancels standalone o3 model in favor of integrated GPT-5\n\nOpenAI announced it wouldn’t  release its o3 AI model, opting instead to integrate o3’s technology into a new unified model called GPT-5. CEO Sam Altman announced plans to simplify OpenAI’s product offerings, promising “magic unified intelligence” and unlimited chat access to GPT-5 at a standard setting. Altman also announced that GPT-4.5, also known as Orion, would be released in weeks or months. This shift in strategy comes as OpenAI faces increasing competition from other AI labs and aims to streamline its product lineup for easier user experience. (TechCrunchandX)\n\nJudge rules against AI firm in Thomson Reuters copyright case\n\nA federal judge in Delaware ruled that Ross Intelligence’s copying of Thomson Reuters’ content to build an AI-based legal platform violated U.S. copyright law. In particular, the judge decided that Ross Intelligence had no fair use exemption because it was building a product to compete with Thomson Reuters’ service. The decision marks the first U.S. ruling on fair use in AI-related copyright litigation, a key defense for tech companies in cases involving the use of copyrighted material to train AI systems. This ruling could have significant implications for ongoing and future copyright cases against AI companies, potentially influencing how courts interpret claims of fair use in AI training. (Reuters)\n\nAlibaba’s AI tech to power iPhones in China\n\nApple plans to incorporate Alibaba’s AI technology into iPhones sold in China, according to Alibaba’s chairman Joseph Tsai. This partnership could help Apple revive iPhone sales in China, where the company has struggled against competitors offering AI-enabled smartphones. The collaboration marks a significant win for Alibaba in China’s competitive AI market, potentially boosting its position against rivals like Baidu and DeepSeek. (CNBC)\n\nNew language model uses recurrent depth to scale reasoning\n\nResearchers at multiple institutions developed a novel language model architecture that iterates a recurrent block to perform reasoning in latent space, allowing flexible scaling of test-time computation. Unlike models that scale by producing more tokens, this approach requires no specialized training data and can capture reasoning not easily verbalized. A 3.5 billion parameter proof-of-concept model trained on 800 billion tokens showed improved performance on reasoning benchmarks with increased computation, competing with larger models. This architecture opens up new possibilities for efficient and powerful AI reasoning capabilities that can be dynamically adjusted at inference time. (arXiv)\n\nUnsupervised learning clustering algorithm inspired by physics\n\nResearchers at the University of Technology Sydney developed Torque Clustering, a novel unsupervised learning algorithm that outperforms traditional methods with a 97.7 percent average adjusted mutual information score across 1,000 datasets. The algorithm, inspired by gravitational interactions between galaxies, uses the physical concept of torque to autonomously identify clusters and adapt to diverse data types without parameters. It outperforms other unsupervised learning algorithms by over 10 percent. This research could significantly impact artificial intelligence development, particularly in robotics and autonomous systems, by enhancing movement optimization, control, and decision-making capabilities. (University of Technology SydneyandIEEE)\n\nEncoder model performs well using masked head for classification\n\nResearchers at Answer.AI introduced ModernBERT-Large-Instruct, a 0.4 billion-parameter encoder model that uses its masked language modeling head for generative classification. The model outperforms similarly sized large language models on MMLU and achieves 93 percent of Llama3-1B’s MMLU performance with 60 percent fewer parameters. This approach demonstrates the potential of using generative masked language modeling heads over traditional task-specific heads for downstream tasks, suggesting further exploration in this area is warranted. (arXiv)\n\nStill want to know more about what matters in AI right now\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng advocated for shifting the conversation from “AI safety” to “responsible AI” at the Artificial Intelligence Action Summit in Paris, emphasizing the importance of focusing on AI opportunities rather than hypothetical risks.\n\n“AI, a general-purpose technology with numerous applications, is neither safe nor unsafe. How someone chooses to use it determines whether it is harmful or beneficial.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:OpenAI’s Deep Research agentgenerates detailed reports by analyzing web sources;Google revised its AI principles, lifting a self-imposed ban on weapons and surveillance applications;Alibaba debuted Qwen2.5-VL, a powerful family of open vision-language models; and researchers demonstratedhow tree search enhances AI agents’ abilityto browse the web and complete tasks.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Theo thông báo mới nhất, OpenAI sẽ thay thế mô hình o3 bằng gì?",
        "options": {
          "A": "GPT-4.5 (Orion)",
          "B": "GPT-5 tích hợp công nghệ của o3",
          "C": "Một phiên bản nâng cấp của GPT-4",
          "D": "Một mô hình AI hoàn toàn mới chưa được công bố"
        },
        "answer": "B"
      },
      {
        "question": "Phán quyết của tòa án Delaware trong vụ kiện giữa Thomson Reuters và Ross Intelligence liên quan đến vấn đề gì?",
        "options": {
          "A": "Vi phạm bằng sáng chế công nghệ AI",
          "B": "Vi phạm luật bản quyền khi sử dụng nội dung để xây dựng nền tảng AI",
          "C": "Cạnh tranh không lành mạnh trên thị trường AI pháp lý",
          "D": "Sử dụng trái phép dữ liệu cá nhân để huấn luyện AI"
        },
        "answer": "B"
      },
      {
        "question": "Apple dự kiến sẽ hợp tác với công ty AI nào để tích hợp vào iPhone bán tại thị trường Trung Quốc?",
        "options": {
          "A": "Baidu",
          "B": "DeepSeek",
          "C": "Alibaba",
          "D": "Tencent"
        },
        "answer": "C"
      },
      {
        "question": "Điểm đặc biệt của mô hình ngôn ngữ mới sử dụng 'recurrent depth' là gì?",
        "options": {
          "A": "Tạo ra nhiều token hơn để mở rộng khả năng",
          "B": "Yêu cầu dữ liệu huấn luyện chuyên biệt",
          "C": "Có khả năng mở rộng tính toán trong quá trình thử nghiệm",
          "D": "Dễ dàng diễn đạt các lập luận bằng lời"
        },
        "answer": "C"
      },
      {
        "question": "Thuật toán học không giám sát Torque Clustering được lấy cảm hứng từ hiện tượng vật lý nào?",
        "options": {
          "A": "Tương tác điện từ",
          "B": "Tương tác hạt nhân mạnh",
          "C": "Tương tác hấp dẫn giữa các thiên hà",
          "D": "Hiệu ứng lượng tử"
        },
        "answer": "C"
      },
      {
        "question": "ModernBERT-Large-Instruct sử dụng phần nào của mô hình để thực hiện phân loại?",
        "options": {
          "A": "Các lớp fully connected",
          "B": "Đầu mô hình ngôn ngữ được che giấu (masked language modeling head)",
          "C": "Các lớp embedding",
          "D": "Cơ chế attention"
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, trọng tâm của cuộc thảo luận về AI nên chuyển từ 'AI safety' sang vấn đề gì?",
        "options": {
          "A": "Phát triển AI có đạo đức",
          "B": "AI có trách nhiệm (responsible AI)",
          "C": "Ngăn chặn rủi ro tiềm ẩn của AI",
          "D": "Kiểm soát sự phát triển của AI"
        },
        "answer": "B"
      },
      {
        "question": "Công cụ 'Deep Research agent' của OpenAI có khả năng gì?",
        "options": {
          "A": "Tự động viết code",
          "B": "Tạo ra các báo cáo chi tiết bằng cách phân tích các nguồn web",
          "C": "Dịch ngôn ngữ tự động",
          "D": "Tạo ra hình ảnh từ văn bản"
        },
        "answer": "B"
      },
      {
        "question": "Google đã thay đổi nguyên tắc AI của mình như thế nào?",
        "options": {
          "A": "Cấm hoàn toàn việc sử dụng AI trong quân sự",
          "B": "Cho phép sử dụng AI trong các ứng dụng y tế",
          "C": "Dỡ bỏ lệnh cấm tự áp đặt đối với các ứng dụng vũ khí và giám sát",
          "D": "Tăng cường bảo mật dữ liệu cá nhân"
        },
        "answer": "C"
      },
      {
        "question": "Alibaba đã ra mắt mô hình AI nào gần đây?",
        "options": {
          "A": "GPT-5",
          "B": "Llama3-1B",
          "C": "Qwen2.5-VL",
          "D": "ModernBERT-Large-Instruct"
        },
        "answer": "C"
      }
    ]
  },
  "openais-o1-models-recognize-and-fix-mistakes-plus-explaining-reflection-70bs-replication-controversy": {
    "title": "OpenAI’s o1 models recognize and fix mistakes",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nOpenAI releases new “Strawberry” models to solve STEM problems GPT-4o can’t\n\nOpenAI announced o1, a new large language model family trained with reinforcement learning for difficult reasoning tasks. o1 employs a chain-of-thought approach, breaking down complex problems into simpler steps and learning to recognize and correct mistakes. It ranks in the 89th percentile on Codeforces, places among the top 500 U.S. students in the USA Math Olympiad qualifier, and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems. OpenAI has released an early version, o1-preview, for immediate use in ChatGPT and to trusted API users, and a smaller, less expensive version, o1-mini, also available in the API. (OpenAI)\n\n“I got ahead of myself,” says Reflection 70B developer\n\nHyperWrite claimed its new Reflection 70B model was a variant of Meta’s Llama 3.1, boasting superior performance to other open-source models. However, independent evaluators including Artificial Analysis questioned these claims, unable to reproduce HyperWrite's reported benchmark performances. Some evidence suggested Reflection 70B might actually be based on the older Llama 3; others speculated it could be a wrapper for Anthropic’s Claude. It’s also plausible that the public version had implementation errors. The controversy highlights the challenges in reproducing and verifying performance claims in the fast-moving open model landscape. (VentureBeat)\n\nGitHub Copilot fine-tunes models for faster, customized code completion\n\nGitHub introduced fine-tuned models for Copilot Enterprise, allowing organizations to customize the AI assistant with their proprietary codebases and coding practices. The new feature, available in limited public beta, offers more relevant and consistent code completion support tailored to each organization’s needs. The fine-tuning process uses the LoRA (Low-Rank Adaptation) method, which adjusts a subset of the most important model parameters for efficiency. Unlike previous retrieval-augmented generation (RAG) approaches, fine-tuning can enable Copilot to deliver contextualized suggestions with the speed necessary for real-time, inline coding. (GitHub)\n\nGoogle tackles AI hallucinations with Data Commons integration\n\nGoogle introduced DataGemma, a set of open models (based on Gemma 2 27B) designed to connect large language models with real-world data from Google’s Data Commons. The models use two approaches, Retrieval-Interleaved Generation (RIG) and Retrieval-Augmented Generation (RAG), to support accuracy and better reasoning in their responses. This development aims to address the challenge of AI hallucinations by grounding language models in trustworthy statistical information from reputable sources. (Google)\n\nMistral releases its first text and image multimodal model\n\nFrench AI startup Mistral launched Pixtral 12B, a 12 billion parameter model that can process both images and text. The model, built on Mistral’s Nemo 12B, can answer questions about multiple images of any size and perform tasks like image captioning and object counting. Benchmark scores show the language model beats competing smaller models in multimodal reasoning and performance (ad measured by MMLU and ChartQA). Pixtral 12B is available for download and use under an Apache 2.0 license, allowing developers to fine-tune and implement the model without restrictions. (TechCrunch)\n\nREAIM conference sets international guidelines for AI in tools of war\n\nAbout 60 countries, including the United States, endorsed a “blueprint for action” for responsible use of artificial intelligence in military applications at a summit in Seoul. The document, which is not legally binding, builds on last year’s “call to action” and includes guidelines for risk assessments, human control, and measures to prevent AI from being used in weapons of mass destruction. China did not endorse the document, highlighting ongoing differences among stakeholders in the global discussion on military AI use. (Reuters)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng discussed why science-fiction scenarios of AI’s emergent behavior are likely to remain fictional.\n\n“Some people fear that AI someday will learn to deceive humans deliberately. If that ever happens, I’m sure we will see it coming from far away and have plenty of time to stop it.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:Waymo highlighted its safety record, arguing that its autonomous vehicles are safer than human drivers on the same roads;2D-to-3D mesh generationis becoming widely accessible for industries like gaming and animation;Western powerssigned a legally binding AI treaty to regulate its impact on democracy and human rights; anda new automated methodwas developed to balance unbalanced datasets scraped from the web.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "Mục tiêu chính của mô hình o1 mới được OpenAI phát triển là gì?",
        "options": {
          "A": "Tạo ra các hình ảnh chất lượng cao từ văn bản.",
          "B": "Giải quyết các bài toán STEM phức tạp mà GPT-4o gặp khó khăn.",
          "C": "Tự động viết mã chương trình hoàn chỉnh.",
          "D": "Dịch thuật văn bản giữa các ngôn ngữ khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính được nêu ra liên quan đến mô hình Reflection 70B của HyperWrite là gì?",
        "options": {
          "A": "Giá thành quá cao so với hiệu năng.",
          "B": "Khả năng tương thích kém với các phần cứng khác nhau.",
          "C": "Tính xác thực của các tuyên bố về hiệu năng vượt trội bị nghi ngờ.",
          "D": "Thiếu tài liệu hướng dẫn sử dụng chi tiết."
        },
        "answer": "C"
      },
      {
        "question": "GitHub Copilot Enterprise sử dụng phương pháp nào để tùy chỉnh mô hình cho phù hợp với từng tổ chức?",
        "options": {
          "A": "Sử dụng dữ liệu công khai từ các kho lưu trữ mã nguồn mở.",
          "B": "Áp dụng phương pháp LoRA (Low-Rank Adaptation) để điều chỉnh một phần tham số mô hình.",
          "C": "Sử dụng Retrieval-Augmented Generation (RAG) để truy xuất thông tin liên quan.",
          "D": "Tái huấn luyện toàn bộ mô hình với dữ liệu riêng của tổ chức."
        },
        "answer": "B"
      },
      {
        "question": "Google giải quyết vấn đề 'ảo giác' của AI bằng cách nào trong DataGemma?",
        "options": {
          "A": "Sử dụng các thuật toán mã hóa phức tạp để ngăn chặn thông tin sai lệch.",
          "B": "Kết nối mô hình ngôn ngữ lớn với dữ liệu thực tế từ Google's Data Commons.",
          "C": "Tăng cường khả năng tự kiểm tra và sửa lỗi của mô hình.",
          "D": "Giới hạn phạm vi kiến thức của mô hình để tránh các chủ đề nhạy cảm."
        },
        "answer": "B"
      },
      {
        "question": "Pixtral 12B của Mistral có khả năng gì đặc biệt?",
        "options": {
          "A": "Tạo ra các video hoạt hình 3D từ văn bản.",
          "B": "Xử lý đồng thời cả hình ảnh và văn bản.",
          "C": "Dự đoán chính xác xu hướng thị trường chứng khoán.",
          "D": "Điều khiển robot công nghiệp một cách tự động."
        },
        "answer": "B"
      },
      {
        "question": "Nội dung chính của 'blueprint for action' được thông qua tại hội nghị REAIM là gì?",
        "options": {
          "A": "Cấm hoàn toàn việc sử dụng AI trong quân sự.",
          "B": "Thiết lập các hướng dẫn cho việc sử dụng AI có trách nhiệm trong các ứng dụng quân sự.",
          "C": "Thúc đẩy hợp tác quốc tế trong việc phát triển vũ khí AI.",
          "D": "Tăng cường đầu tư vào nghiên cứu AI cho mục đích quân sự."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, điều gì có khả năng xảy ra với các kịch bản khoa học viễn tưởng về hành vi mới nổi của AI?",
        "options": {
          "A": "Chúng sẽ sớm trở thành hiện thực do sự phát triển nhanh chóng của AI.",
          "B": "Chúng có khả năng vẫn là hư cấu và chúng ta sẽ có thời gian để ngăn chặn nếu chúng xảy ra.",
          "C": "Chúng là một mối đe dọa nghiêm trọng và cần được giải quyết ngay lập tức.",
          "D": "Chúng là một công cụ hữu ích để thúc đẩy sự phát triển của AI."
        },
        "answer": "B"
      },
      {
        "question": "Waymo lập luận rằng xe tự hành của họ an toàn hơn so với người lái xe như thế nào?",
        "options": {
          "A": "Xe tự hành có thể di chuyển nhanh hơn và hiệu quả hơn.",
          "B": "Xe tự hành có thể tránh được các tai nạn do lỗi của con người.",
          "C": "Xe tự hành có thể hoạt động trong mọi điều kiện thời tiết.",
          "D": "Xe tự hành có thể giảm thiểu ùn tắc giao thông."
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ tạo lưới 2D-to-3D đang trở nên phổ biến trong những ngành công nghiệp nào?",
        "options": {
          "A": "Y tế và giáo dục.",
          "B": "Năng lượng và nông nghiệp.",
          "C": "Game và hoạt hình.",
          "D": "Tài chính và bất động sản."
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu chính của hiệp ước AI ràng buộc về mặt pháp lý được ký kết bởi các cường quốc phương Tây là gì?",
        "options": {
          "A": "Thúc đẩy sự phát triển của AI trong lĩnh vực quân sự.",
          "B": "Điều chỉnh tác động của AI đối với dân chủ và nhân quyền.",
          "C": "Tăng cường hợp tác quốc tế trong nghiên cứu AI.",
          "D": "Bảo vệ quyền sở hữu trí tuệ trong lĩnh vực AI."
        },
        "answer": "B"
      }
    ]
  },
  "openais-operator-brings-agents-to-the-browser": {
    "title": "OpenAI’s Operator brings agents to the browser",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nOpenAI unveils web-based AI agent for everyday online tasks\n\nOpenAI released Operator, an AI agent that can perform simple web jobs like booking tickets or ordering groceries using a new model called Computer-Using Agent (CUA). The web app is currently available to ChatGPT Pro subscribers, with plans to expand access to paid and free users in the future. OpenAI claims Operator outperforms similar tools from Anthropic and Google DeepMind, and intends to make CUA available via API for developers to build their own agents. (OpenAIandArs Technica)\n\nWhite House shifts AI policy focus with Trump’s new executive order\n\nU.S. President Trump signed an executive order on artificial intelligence that revokes past government policies he claims hinder American AI innovation. It calls for a review of actions taken under Biden’s 2023 AI executive order, which Trump rescinded earlier this week, and for the development of an AI action plan within 180 days. Trump’s order emphasizes developing AI systems “free from ideological bias” and aims to promote U.S. economic competitiveness and national security. (The White HouseandAssociated Press)\n\nByteDance unveils powerful, low-cost AI model for Chinese market\n\nTikTok owner ByteDance released a new version of its AI model Doubao, claiming performance comparable to leading models like GPT-4o and Claude Sonnet 3.5. The company emphasized a “resource-efficient” training approach and introduced aggressive pricing, with the most powerful version of Doubao 1.5 costing just $1.24 per million tokens. This development signals ByteDance’s ambition to compete in the global AI race while potentially reshaping the AI market with its ultra-low pricing strategy. Warning: the signup process for users outside of China is cumbersome. (ByteDanceandReuters)\n\nPerplexity launches Sonar Pro API for developers\n\nPerplexity updated its Sonar API and introduced a new Sonar Pro API, allowing developers to integrate generative search features with real-time web research and citations into their applications. The new Sonar API offers lightweight, fast question-answering capabilities with customizable sources, while Sonar Pro provides advanced features for handling complex queries with an expanded context window of 200,000 tokens. Pricing for Sonar starts at 5 per 1,000 searches plus 1 per 750,000 words input/output, while Sonar Pro costs 5 per 1,000 searches, 3 per 750,000 input words, and $15 per 750,000 output words. This product, which Perplexity says beats Google’s comparable API on benchmark tests, enables developers to incorporate sophisticated AI-powered search functionality into their products. (Perplexity)\n\nHugging Face unveils compact AI models for image and text analysis\n\nHugging Face released SmolVLM-256M and SmolVLM-500M, two small AI models capable of analyzing images, short videos, and text on devices with limited RAM. The models, trained on high-quality datasets, reportedly outperform larger models on various benchmarks and are available for unrestricted use under an Apache 2.0 license. These compact models are versatile and cost-effective for developers working with constrained devices or processing large amounts of data, but may have limitations compared to larger models when asked to perform complex reasoning tasks. (Hugging FaceandTechCrunch)\n\nOpenAI’s involvement in math test development raises questions about AI benchmarking\n\nOpenAI’s early report on its o3 model included a high score on FrontierMath, a challenging AI math test developed by Epoch AI — but (it was later revealed) with OpenAI’s funding. The revelation that OpenAI may have had prior access to the test problems and solutions raised concerns about the benchmark’s fairness and independence. This controversy highlights the complexities surrounding AI model evaluation and questions whether evolving AI benchmarks can be truly unbiased. (TechCrunchandmeemi’s Shortform)\n\nStill want to know more about what matters in AI right now?\n\nReadthis week’s issueofThe Batchfor in-depth analysis of news and research.\n\nThis week, Andrew Ng shared insights from the World Economic Forum in Davos, Switzerland, where he discussed AI business implementations, governance, and climate solutions, including geoengineering. He highlighted the potential of Stratospheric Aerosol Injection (SAI) to combat global warming and introduced an AI-powered climate simulator atplanetparasol.aito explore these possibilities.\n\n“The world urgently needs to reduce carbon emissions, but it hasn’t happened fast enough. Without geoengineering, there’s no longer any plausible path to keeping global warming to the 1.5 degrees Celsius goal set by the Paris agreement.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth:DeepSeek-R1 emergedas an affordable rival to OpenAI’s o1, sharpening its reasoning capabilities;Unitree and EngineAI showcased affordable humanoid robots, breaking price barriers;Texas introduced a landmark billto regulate AI development and use, further opening the door for state-level AI governance; andresearchers combined deep learning with an evolutionary algorithmto design chips in minutes, revealing mysterious but effective processes in generated hardware designs.\n\nSubscribe to Data Points",
    "qa": [
      {
        "question": "OpenAI đã phát hành công cụ AI Operator với mục đích chính là gì?",
        "options": {
          "A": "Phân tích dữ liệu phức tạp và đưa ra dự đoán thị trường.",
          "B": "Thực hiện các công việc trực tuyến đơn giản như đặt vé hoặc mua sắm.",
          "C": "Tự động hóa quy trình phát triển phần mềm cho các lập trình viên.",
          "D": "Cung cấp dịch vụ dịch thuật đa ngôn ngữ chất lượng cao."
        },
        "answer": "B"
      },
      {
        "question": "Lệnh hành pháp mới của Tổng thống Trump về trí tuệ nhân tạo tập trung vào điều gì?",
        "options": {
          "A": "Tăng cường hợp tác quốc tế trong lĩnh vực nghiên cứu và phát triển AI.",
          "B": "Thúc đẩy sự phát triển AI 'không bị ảnh hưởng bởi ý thức hệ' và tăng cường cạnh tranh kinh tế của Hoa Kỳ.",
          "C": "Hạn chế sử dụng AI trong các lĩnh vực nhạy cảm như quốc phòng và an ninh quốc gia.",
          "D": "Đầu tư mạnh mẽ vào đào tạo nguồn nhân lực chất lượng cao cho ngành AI."
        },
        "answer": "B"
      },
      {
        "question": "ByteDance tuyên bố mô hình AI Doubao của họ có ưu điểm nổi bật nào?",
        "options": {
          "A": "Khả năng xử lý ngôn ngữ tự nhiên vượt trội so với các mô hình khác.",
          "B": "Hiệu suất tương đương với các mô hình hàng đầu nhưng với chi phí thấp hơn đáng kể.",
          "C": "Tích hợp sẵn các công cụ bảo mật tiên tiến để bảo vệ dữ liệu người dùng.",
          "D": "Khả năng tạo ra hình ảnh và video chất lượng cao từ văn bản mô tả."
        },
        "answer": "B"
      },
      {
        "question": "Sonar Pro API của Perplexity cung cấp cho các nhà phát triển khả năng gì?",
        "options": {
          "A": "Tạo ra các mô hình AI tùy chỉnh dựa trên dữ liệu riêng của họ.",
          "B": "Tích hợp các tính năng tìm kiếm tạo sinh với nghiên cứu web thời gian thực và trích dẫn vào ứng dụng của họ.",
          "C": "Phân tích cảm xúc của người dùng dựa trên dữ liệu văn bản và giọng nói.",
          "D": "Tự động hóa quy trình kiểm thử phần mềm và phát hiện lỗi."
        },
        "answer": "B"
      },
      {
        "question": "Hai mô hình AI SmolVLM-256M và SmolVLM-500M của Hugging Face có đặc điểm gì nổi bật?",
        "options": {
          "A": "Khả năng xử lý dữ liệu đa phương thức (văn bản, hình ảnh, âm thanh) với độ chính xác cao.",
          "B": "Kích thước nhỏ gọn, phù hợp cho các thiết bị có bộ nhớ RAM hạn chế.",
          "C": "Khả năng tự học và cải thiện hiệu suất theo thời gian.",
          "D": "Tích hợp sẵn các công cụ để tạo ra các ứng dụng AI cho lĩnh vực y tế."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính được đặt ra liên quan đến việc OpenAI tham gia vào phát triển bài kiểm tra toán học FrontierMath là gì?",
        "options": {
          "A": "Sự thiếu minh bạch trong quá trình đánh giá hiệu suất của các mô hình AI.",
          "B": "Khả năng OpenAI đã có quyền truy cập trước vào các bài toán và giải pháp, ảnh hưởng đến tính công bằng của bài kiểm tra.",
          "C": "Sự phức tạp của bài kiểm tra FrontierMath khiến nó không phù hợp để đánh giá các mô hình AI.",
          "D": "Việc sử dụng dữ liệu cá nhân của người dùng để huấn luyện các mô hình AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo Andrew Ng, giải pháp nào có thể giúp giữ cho sự nóng lên toàn cầu ở mức 1.5 độ C theo thỏa thuận Paris?",
        "options": {
          "A": "Tăng cường sử dụng năng lượng tái tạo và giảm thiểu khí thải carbon.",
          "B": "Phát triển công nghệ thu giữ và lưu trữ carbon.",
          "C": "Sử dụng kỹ thuật địa kỹ thuật, cụ thể là phun sol khí tầng bình lưu (SAI).",
          "D": "Thay đổi mô hình tiêu dùng và sản xuất để giảm thiểu tác động đến môi trường."
        },
        "answer": "C"
      },
      {
        "question": "DeepSeek-R1 được đề cập trong bài viết như một đối thủ cạnh tranh với mô hình nào?",
        "options": {
          "A": "Claude Sonnet 3.5",
          "B": "GPT-4o",
          "C": "o1 của OpenAI",
          "D": "Doubao 1.5"
        },
        "answer": "C"
      },
      {
        "question": "Bang Texas đã có động thái gì liên quan đến AI?",
        "options": {
          "A": "Ban hành lệnh cấm sử dụng AI trong các cơ quan chính phủ.",
          "B": "Giới thiệu một dự luật mang tính bước ngoặt để điều chỉnh sự phát triển và sử dụng AI.",
          "C": "Đầu tư mạnh mẽ vào các trung tâm nghiên cứu và phát triển AI.",
          "D": "Tổ chức hội nghị quốc tế về AI với sự tham gia của các chuyên gia hàng đầu thế giới."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu nào được đề cập đến việc kết hợp học sâu với thuật toán tiến hóa?",
        "options": {
          "A": "Phát triển các mô hình ngôn ngữ tự nhiên mạnh mẽ hơn.",
          "B": "Thiết kế chip trong vài phút, tiết lộ các quy trình bí ẩn nhưng hiệu quả trong thiết kế phần cứng được tạo ra.",
          "C": "Tạo ra các robot hình người có khả năng thực hiện các công việc phức tạp.",
          "D": "Phân tích dữ liệu y tế để phát hiện sớm các bệnh nguy hiểm."
        },
        "answer": "B"
      }
    ]
  },
  "openais-unreleased-chatgpt-detector": {
    "title": "OpenAI’s unreleased ChatGPT detector",
    "collection": "data-points",
    "content": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\n\nOpenAI develops (but has not released) a powerful ChatGPT watermarking toolOpenAI created a method to detect generated text by altering the token selection process in ChatGPT, leaving an imperceptible pattern called a watermark. The technique is 99.9 percent effective when sufficient new text is generated, providing a score indicating the likelihood that ChatGPT wrote part or all of a document. However, concerns exist about potential workarounds, such as using translation services or manual editing to erase the watermarks. The tool’s effectiveness and potential impact have sparked a two-year internal debate at OpenAI, highlighting the complexities of deploying such technology in educational and commercial contexts.  (The Wall Street Journal)\n\nGoogle DeepMind’s table tennis robot achieves amateur-level playGoogle DeepMind trained a robotic arm to play table tennis at an amateur-competitive level, winning 13 out of 29 games against human opponents of varying abilities. The system uses a two-part approach, combining computer simulations for skill mastery and real-world data for continuous improvement, allowing it to adjust tactics and behavior during matches. This achievement represents progress toward creating robots that can perform useful tasks skillfully and safely in real environments, with potential applications beyond sports in areas such as homes and warehouses. (MIT Technology Review)\n\nTikTok owner ByteDance unveils new video generation appByteDance launched Jimeng AI, a new text-to-video generation tool, on Android and Apple’s App Store for Chinese users. The software, developed by ByteDance-owned Faceu Technology, joins similar offerings from Chinese companies like Kuaishou, Zhipu AI, and Shengshu, which have recently introduced their own text-to-video models. Jimeng AI offers subscription plans starting at 69 yuan ($9.65) monthly, with options for single-month or annual subscriptions, allowing users to create about 2,050 images or 168 AI videos per month. This surge in AI video generation tools from Chinese tech firms highlights their rapid advancement in the field, as they compete with OpenAI’s unreleased Sora model. (Reuters)\n\nU.K. government investigates Amazon-Anthropic partnershipThe U.K.’s Competition and Markets Authority (CMA) launched an investigation into Amazon’s partnership with AI startup Anthropic, following a similar probe into Alphabet’s collaboration with the same company. The CMA will decide by October 4 whether to begin a deeper investigation or clear the partnershup of competition concerns. This move reflects growing concern among global antitrust regulators about deals between big tech companies and AI startups, as authorities work to ensure fair competition in the rapidly evolving AI industry. (Reuters)\n\nWriter releases specialized models for medical and financial sectorsWriter introduced two new domain-specific large language models, Palmyra-Med and Palmyra-Fin, designed for medical and financial applications. Palmyra-Med outperformed other models in medical benchmarks, achieving an average of 85.9% accuracy across various tests, while Palmyra-Fin passed the CFA Level III exam with a 73% score on the multiple-choice section. These specialized models aim to provide AI developers with more accurate and compliant tools for building applications in highly regulated industries. (Writer)\n\nSambaNova sets speed record for Llama 3.1 inferenceSambaNova achieved 114 tokens per second on Meta’s Llama 3.1 405B model, setting a performance record independently verified by Artificial Analysis. The company’s platform, powered by its fourth-generation RDU chip, enables enterprises to deploy private language models with real-time capabilities for use cases like intelligent document processing, AI copilots, explainable AI, and agentic AI automation. This breakthrough in speed and efficiency allows businesses to leverage large language models more effectively for improving customer satisfaction and employee experience, which Gartner identified as top AI priorities for CEOs. (SambaNova)\n\nStill want to know more about what matters in AI right now?\n\nReadlast week’s issueofThe Batchfor in-depth analysis of news and research.\n\nLast week, Andrew Ng introduced his new sequence of courses,AI Python for Beginners, aimed at teaching anyone to code with the help of AI:\n\n“If you know someone who is curious about coding (or if you yourself are), please encourage them to learn to code! The case is stronger than ever that pretty much everyone can benefit from learning at least a little coding. Please help me spread the word, and encourage everyone who isn’t already a coder to check outAI Python for Beginners.”\n\nRead Andrew’s full letterhere.\n\nOther top AI news and research stories we covered in depth: Google getsCharacter.AI co-founders, how employers and prospective employees are embracing automated hiring tools, Ukraine'saquatic drones, andArtPrompt, a technique to test the impact of text rendered as ASCII art on LLM performance.",
    "qa": [
      {
        "question": "Công cụ watermarking của OpenAI có hiệu quả đến mức nào trong việc phát hiện văn bản do ChatGPT tạo ra khi có đủ văn bản mới?",
        "options": {
          "A": "80%",
          "B": "99.9%",
          "C": "95%",
          "D": "90%"
        },
        "answer": "B"
      },
      {
        "question": "Robot chơi bóng bàn của Google DeepMind đã thắng bao nhiêu trận trong tổng số 29 trận đấu với người chơi có trình độ khác nhau?",
        "options": {
          "A": "10",
          "B": "13",
          "C": "15",
          "D": "18"
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng tạo video từ văn bản mới ra mắt của ByteDance có tên là gì?",
        "options": {
          "A": "Douyin AI",
          "B": "Jimeng AI",
          "C": "Faceu Video",
          "D": "ByteDance Video Maker"
        },
        "answer": "B"
      },
      {
        "question": "Cơ quan nào của Vương quốc Anh đang điều tra mối quan hệ hợp tác giữa Amazon và Anthropic?",
        "options": {
          "A": "Financial Conduct Authority (FCA)",
          "B": "Competition and Markets Authority (CMA)",
          "C": "Office of Communications (Ofcom)",
          "D": "Information Commissioner's Office (ICO)"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình ngôn ngữ lớn chuyên biệt Palmyra-Med của Writer đạt độ chính xác trung bình bao nhiêu trong các bài kiểm tra y tế?",
        "options": {
          "A": "75.9%",
          "B": "80.9%",
          "C": "85.9%",
          "D": "90.9%"
        },
        "answer": "C"
      },
      {
        "question": "Palmyra-Fin của Writer đã đạt được bao nhiêu điểm trong phần trắc nghiệm của kỳ thi CFA Level III?",
        "options": {
          "A": "63%",
          "B": "68%",
          "C": "73%",
          "D": "78%"
        },
        "answer": "C"
      },
      {
        "question": "SambaNova đã đạt được tốc độ bao nhiêu token mỗi giây trên mô hình Llama 3.1 405B của Meta?",
        "options": {
          "A": "94",
          "B": "104",
          "C": "114",
          "D": "124"
        },
        "answer": "C"
      },
      {
        "question": "Chip thế hệ thứ tư của SambaNova được gọi là gì?",
        "options": {
          "A": "TPU",
          "B": "GPU",
          "C": "RDU",
          "D": "CPU"
        },
        "answer": "C"
      },
      {
        "question": "Andrew Ng đã giới thiệu khóa học nào dành cho người mới bắt đầu học lập trình với sự hỗ trợ của AI?",
        "options": {
          "A": "AI for Everyone",
          "B": "Machine Learning with Python",
          "C": "AI Python for Beginners",
          "D": "Deep Learning Specialization"
        },
        "answer": "C"
      },
      {
        "question": "Kỹ thuật nào được sử dụng để kiểm tra tác động của văn bản được hiển thị dưới dạng nghệ thuật ASCII đối với hiệu suất của LLM?",
        "options": {
          "A": "TextArt",
          "B": "ASCII Test",
          "C": "ArtPrompt",
          "D": "Visual Text Analysis"
        },
        "answer": "C"
      }
    ]
  },
  "a-robot-in-every-kitchen": {
    "title": "A Robot in Every Kitchen",
    "collection": "business",
    "content": "Every home is different. That makes it difficult for domestic robots to translate skills learned in one household — say, fetching a soda from the fridge — into another. Training in virtual reality, where the robot has access to rich information about three-dimensional objects and spaces, can make it easier for robots to generalize skills to the real world.What’s new:Toyota Research Institute built a household robot that users can train using avirtual reality interface. The robot learns a new behavior based on a single instance of VR guidance. Then it responds to voice commands to carry out the behavior in a variety of real-world environments.How it works:Toyota’s robot is pieced together from off-the-shelf parts, including two cameras provide stereoscopic vision. Classical robotics software controls the machine, while convolutional neural networks learn unique embeddings.\n\nResults:The Toyota researchers trained the bot in the virtual environment on three tasks: retrieving a bottle from a refrigerator, removing a cup from a dishwasher, and moving multiple objects to different locations. Then they had the robot perform each task 10 times in two physical homes. They ran the experiments with slight alterations, for instance asking the robot to retrieve a bottle from a higher shelf than the virtual one it was trained on, or doing so with the lights turned off. The robot achieved an 85 percent success rate — though it took an average 20 times longer than a human would.Why it matters:Researchers have given a lot of attention lately to the use of reinforcement learning on robots that are both trained and tested in a simulated environment. Getting such systems to generalize from a simulation to the real world is an important step toward making them useful.We’re thinking:Birth rates have been slowing for decades in Japan, China, the U.S., and much of Europe. The World Health Organizationestimatesthat 22 percent of the world’s population will be over 60 years old by 2050. Who will care for the elderly? Robots may be part of the answer.",
    "qa": [
      {
        "question": "Tại sao việc huấn luyện robot gia dụng gặp khó khăn khi chuyển đổi kỹ năng giữa các hộ gia đình?",
        "options": {
          "A": "Do robot không thể thích nghi với các loại đồ vật khác nhau.",
          "B": "Do mỗi ngôi nhà có sự khác biệt về cấu trúc và bố trí.",
          "C": "Do robot chỉ được lập trình cho một loại nhiệm vụ cụ thể.",
          "D": "Do robot không thể nhận diện được giọng nói của các thành viên khác nhau trong gia đình."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, Toyota Research Institute đã sử dụng phương pháp nào để huấn luyện robot gia dụng?",
        "options": {
          "A": "Sử dụng hệ thống học tăng cường trong môi trường thực tế.",
          "B": "Sử dụng giao diện thực tế ảo để người dùng hướng dẫn robot.",
          "C": "Sử dụng các cảm biến để robot tự học hỏi từ môi trường xung quanh.",
          "D": "Sử dụng dữ liệu thu thập từ nhiều hộ gia đình khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Robot của Toyota được trang bị những thành phần phần cứng nào?",
        "options": {
          "A": "Bộ xử lý trung tâm mạnh mẽ và hệ thống định vị GPS.",
          "B": "Các bộ phận có sẵn trên thị trường, bao gồm hai camera cho thị giác lập thể.",
          "C": "Cảm biến laser và hệ thống nhận diện khuôn mặt tiên tiến.",
          "D": "Cánh tay robot linh hoạt và hệ thống điều khiển bằng giọng nói."
        },
        "answer": "B"
      },
      {
        "question": "Phần mềm nào được sử dụng để điều khiển robot của Toyota?",
        "options": {
          "A": "Phần mềm trí tuệ nhân tạo độc quyền của Toyota.",
          "B": "Phần mềm robot cổ điển.",
          "C": "Phần mềm học sâu dựa trên mạng nơ-ron tái phát.",
          "D": "Phần mềm mô phỏng môi trường 3D."
        },
        "answer": "B"
      },
      {
        "question": "Mạng nơ-ron tích chập được sử dụng để làm gì trong robot của Toyota?",
        "options": {
          "A": "Điều khiển chuyển động của robot.",
          "B": "Nhận diện và phân loại đồ vật.",
          "C": "Học các biểu diễn nhúng (embeddings) độc đáo.",
          "D": "Xử lý và hiểu các lệnh bằng giọng nói."
        },
        "answer": "C"
      },
      {
        "question": "Trong các thử nghiệm, robot của Toyota đã được huấn luyện thực hiện những nhiệm vụ nào?",
        "options": {
          "A": "Lau nhà, hút bụi và giặt quần áo.",
          "B": "Nấu ăn, dọn dẹp và chăm sóc cây cảnh.",
          "C": "Lấy đồ uống từ tủ lạnh, lấy cốc từ máy rửa bát và di chuyển đồ vật.",
          "D": "Trả lời điện thoại, gửi email và đặt lịch hẹn."
        },
        "answer": "C"
      },
      {
        "question": "Tỷ lệ thành công của robot Toyota trong các thử nghiệm thực tế là bao nhiêu?",
        "options": {
          "A": "50%",
          "B": "75%",
          "C": "85%",
          "D": "95%"
        },
        "answer": "C"
      },
      {
        "question": "Một hạn chế được đề cập trong bài viết về robot của Toyota là gì?",
        "options": {
          "A": "Robot không thể hoạt động trong điều kiện ánh sáng yếu.",
          "B": "Robot mất nhiều thời gian hơn con người để hoàn thành nhiệm vụ.",
          "C": "Robot không thể xử lý các vật thể có hình dạng phức tạp.",
          "D": "Robot không thể tương tác với con người một cách tự nhiên."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc khái quát hóa từ mô phỏng sang thế giới thực lại quan trọng trong lĩnh vực robot?",
        "options": {
          "A": "Để giảm chi phí huấn luyện robot.",
          "B": "Để tăng độ chính xác của robot trong môi trường mô phỏng.",
          "C": "Để làm cho robot hữu ích hơn trong các ứng dụng thực tế.",
          "D": "Để đơn giản hóa quá trình thiết kế robot."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến vấn đề nhân khẩu học nào có thể được giải quyết một phần bởi robot?",
        "options": {
          "A": "Tình trạng thiếu lao động trẻ.",
          "B": "Tỷ lệ sinh giảm và dân số già hóa.",
          "C": "Sự gia tăng dân số đô thị.",
          "D": "Sự phân bố không đồng đều về nguồn lực."
        },
        "answer": "B"
      }
    ]
  },
  "a-company-is-growing-shrimp-in-ai-controlled-shipping-containers": {
    "title": "Tanks for All the Fish",
    "collection": "business",
    "content": "Farming shrimp in an open pond produces toxic effluent that can pollute groundwater and coastal waters. An AI-driven farm in a box may offer a more sustainable alternative.\n\nWhat’s new:Based in Mexico City, Atarraya modifies shipping containers into AI-controlled tanks for raising commercial shrimp,Fortunereported. The company plans to install 20 units in a warehouse in Indianapolis.\n\nHow it works:The company’s Shrimpboxcontainstwo large water tanks equipped with sensors that track pH, nutrients, chemicals, and temperature. Machine learning models automatically dispense food and adjust conditions as needed.\n\nBehind the news:The seafood industry is using AI to reduce its environmental footprint in a variety of ways.\n\nWhy it matters:If it can scale, Shrimpbox addresses several pain points in aquaculture. Aquaculture can put a dent inoverfishing, which threatens wild fish populations worldwide. Growing seafood in tanks rather than open water won’t leach waste, antibiotics, and other chemicals into the surrounding environment. And containerized tanks can enable food to be grown near where it will be consumed, which eliminates the need to transport it long distances.\n\nWe’re thinking:The shrimp are just prawns in this company’s game.",
    "qa": [
      {
        "question": "Phương pháp nuôi tôm truyền thống trong ao hở gây ra vấn đề môi trường nào?",
        "options": {
          "A": "Gây ra hiện tượng thủy triều đỏ.",
          "B": "Ô nhiễm nguồn nước ngầm và nước ven biển do chất thải độc hại.",
          "C": "Làm tăng nhiệt độ nước biển.",
          "D": "Gây ra sự tuyệt chủng của các loài cá nhỏ."
        },
        "answer": "B"
      },
      {
        "question": "Công ty Atarraya có trụ sở tại đâu?",
        "options": {
          "A": "Indianapolis, Hoa Kỳ.",
          "B": "Thành phố Mexico, Mexico.",
          "C": "Singapore.",
          "D": "Tokyo, Nhật Bản."
        },
        "answer": "B"
      },
      {
        "question": "Shrimpbox của Atarraya sử dụng công nghệ gì để điều chỉnh môi trường nuôi tôm?",
        "options": {
          "A": "Công nghệ lọc nước nano.",
          "B": "Mô hình học máy (Machine Learning).",
          "C": "Hệ thống sục khí ozone.",
          "D": "Công nghệ chiếu sáng LED đặc biệt."
        },
        "answer": "B"
      },
      {
        "question": "Shrimpbox theo dõi những yếu tố nào trong bể nuôi tôm?",
        "options": {
          "A": "Độ mặn, độ trong của nước và số lượng tôm.",
          "B": "pH, chất dinh dưỡng, hóa chất và nhiệt độ.",
          "C": "Ánh sáng, độ ẩm và áp suất không khí.",
          "D": "Tốc độ dòng chảy, độ nhớt và màu sắc của nước."
        },
        "answer": "B"
      },
      {
        "question": "Ngành công nghiệp hải sản đang sử dụng AI để làm gì?",
        "options": {
          "A": "Tăng sản lượng đánh bắt cá.",
          "B": "Giảm thiểu tác động môi trường.",
          "C": "Phát triển các loại thức ăn mới cho hải sản.",
          "D": "Cải thiện chất lượng sản phẩm hải sản."
        },
        "answer": "B"
      },
      {
        "question": "Nuôi trồng thủy sản có thể giúp giải quyết vấn đề gì?",
        "options": {
          "A": "Ô nhiễm không khí.",
          "B": "Cạn kiệt nguồn tài nguyên nước ngọt.",
          "C": "Đánh bắt quá mức (overfishing).",
          "D": "Biến đổi khí hậu."
        },
        "answer": "C"
      },
      {
        "question": "Một lợi ích của việc nuôi hải sản trong bể kín thay vì ao hở là gì?",
        "options": {
          "A": "Giảm chi phí đầu tư ban đầu.",
          "B": "Ngăn chặn chất thải, kháng sinh và hóa chất rò rỉ ra môi trường.",
          "C": "Tăng tốc độ sinh trưởng của hải sản.",
          "D": "Dễ dàng kiểm soát dịch bệnh hơn."
        },
        "answer": "B"
      },
      {
        "question": "Việc nuôi tôm trong các container có thể mang lại lợi ích gì về mặt vận chuyển?",
        "options": {
          "A": "Giảm chi phí bảo quản tôm.",
          "B": "Loại bỏ nhu cầu vận chuyển đường dài.",
          "C": "Tăng thời gian bảo quản tôm.",
          "D": "Dễ dàng xuất khẩu tôm hơn."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, công ty Atarraya dự định lắp đặt bao nhiêu Shrimpbox tại Indianapolis?",
        "options": {
          "A": "10",
          "B": "20",
          "C": "30",
          "D": "40"
        },
        "answer": "B"
      },
      {
        "question": "Câu 'The shrimp are just prawns in this company’s game' có ý nghĩa gì?",
        "options": {
          "A": "Công ty chỉ tập trung vào việc nuôi tôm sú.",
          "B": "Tôm chỉ là một phần nhỏ trong kế hoạch lớn hơn của công ty.",
          "C": "Công ty đang thử nghiệm các loại tôm khác nhau.",
          "D": "Tôm không phải là sản phẩm chính của công ty."
        },
        "answer": "B"
      }
    ]
  },
  "a-report-exposes-policy-violations-in-openais-gpt-store": {
    "title": "GPT Store Shows Lax Moderation",
    "collection": "business",
    "content": "OpenAI has been moderating its GPT Store with a very light touch.\n\nWhat’s new:In a survey of the GPT Store’s offerings,TechCrunchfoundnumerous examples of custom ChatGPT instances that appear to violate the store’s ownpolicies.\n\nHow it works:The GPT Store has a low bar for entry by design — any paid ChatGPT user can create a custom-prompted variation of the chatbot, known as a GPT, and include it in the store. The store lists GPTs in several categories, such as Writing, Productivity, Programming, and Lifestyle. While many are useful, some are questionable.\n\nBehind the news:OpenAIlaunchedthe GPT Store in January. Since then, users have uploaded more than 3 million GPTs that include enhanced search engines, creative writing aids, and tools that produce short videos. The most popular GPTs have millions of downloads. Despite its “store” name, the GPT Store’s contents are free to download. OpenAI ispilotinga program in which U.S.-based uploaders of popular GPTs can earn money.\n\nWhy it matters:The GPT Store is the chatbot era’s answer to Apple’s App Store or Android’s Google Play Store. If it succeeds, it could democratize chatbot development just as the App Store helped to popularize building smartphone applications. How OpenAI moderates the store may have real financial and reputational impacts on developers in the years ahead.We’re thinking:The GPT Store’s low barrier to entry is a boon to well-meaning developers, but it may encourage less responsible actors to take advantage of lax moderation. We applaud OpenAI’s willingness to execute an ambitious vision and hope it finds a workable balance.",
    "qa": [
      {
        "question": "Theo bài viết, OpenAI đang thực hiện việc kiểm duyệt GPT Store như thế nào?",
        "options": {
          "A": "Kiểm duyệt rất nghiêm ngặt, loại bỏ hầu hết các GPT vi phạm.",
          "B": "Kiểm duyệt khá lỏng lẻo.",
          "C": "Kiểm duyệt tự động hoàn toàn bằng AI.",
          "D": "Kiểm duyệt bởi một đội ngũ chuyên gia lớn."
        },
        "answer": "B"
      },
      {
        "question": "TechCrunch đã phát hiện ra điều gì khi khảo sát GPT Store?",
        "options": {
          "A": "Hầu hết các GPT đều tuân thủ chính sách của OpenAI.",
          "B": "Có nhiều GPT vi phạm chính sách của GPT Store.",
          "C": "GPT Store không có GPT nào hữu ích.",
          "D": "GPT Store chỉ chứa các GPT do OpenAI tạo ra."
        },
        "answer": "B"
      },
      {
        "question": "Điều kiện để người dùng ChatGPT được đưa GPT của mình lên GPT Store là gì?",
        "options": {
          "A": "Phải là nhà phát triển chuyên nghiệp.",
          "B": "Phải trả phí đăng ký.",
          "C": "Phải là người dùng ChatGPT trả phí.",
          "D": "Phải được OpenAI phê duyệt đặc biệt."
        },
        "answer": "C"
      },
      {
        "question": "GPT Store được ra mắt vào thời điểm nào?",
        "options": {
          "A": "Tháng 12 năm trước.",
          "B": "Tháng 1 năm nay.",
          "C": "Tháng 2 năm nay.",
          "D": "Tháng 3 năm nay."
        },
        "answer": "B"
      },
      {
        "question": "Tính đến thời điểm bài viết, có bao nhiêu GPT đã được tải lên GPT Store?",
        "options": {
          "A": "Hơn 300.000 GPT.",
          "B": "Hơn 1 triệu GPT.",
          "C": "Hơn 3 triệu GPT.",
          "D": "Hơn 10 triệu GPT."
        },
        "answer": "C"
      },
      {
        "question": "Người dùng có phải trả phí để tải xuống các GPT từ GPT Store không?",
        "options": {
          "A": "Có, tất cả các GPT đều phải trả phí.",
          "B": "Có, chỉ một số GPT phải trả phí.",
          "C": "Không, tất cả các GPT đều miễn phí.",
          "D": "Chỉ người dùng ChatGPT Plus mới được tải miễn phí."
        },
        "answer": "C"
      },
      {
        "question": "OpenAI đang thử nghiệm chương trình gì liên quan đến GPT Store?",
        "options": {
          "A": "Chương trình tặng quà cho người dùng tải nhiều GPT nhất.",
          "B": "Chương trình cho phép người dùng đánh giá GPT.",
          "C": "Chương trình cho phép người tải GPT phổ biến kiếm tiền.",
          "D": "Chương trình hợp tác với các nhà phát triển lớn."
        },
        "answer": "C"
      },
      {
        "question": "GPT Store được so sánh với nền tảng nào trong bài viết?",
        "options": {
          "A": "Amazon.",
          "B": "eBay.",
          "C": "Apple App Store và Google Play Store.",
          "D": "Netflix."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết cho rằng việc kiểm duyệt lỏng lẻo của GPT Store có thể dẫn đến hậu quả gì?",
        "options": {
          "A": "Thu hút được nhiều người dùng hơn.",
          "B": "Khuyến khích các hành vi lợi dụng và thiếu trách nhiệm.",
          "C": "Giúp OpenAI tiết kiệm chi phí.",
          "D": "Tăng tính cạnh tranh giữa các nhà phát triển."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết thể hiện thái độ như thế nào đối với tầm nhìn của OpenAI về GPT Store?",
        "options": {
          "A": "Hoàn toàn chỉ trích.",
          "B": "Hoàn toàn ủng hộ.",
          "C": "Khen ngợi sự táo bạo nhưng hy vọng OpenAI tìm được sự cân bằng.",
          "D": "Thờ ơ và không quan tâm."
        },
        "answer": "C"
      }
    ]
  },
  "ai-agents-and-infrastructure-dominate-cb-insights-top-100-ai-startups-list": {
    "title": "Up-and-Coming Startups",
    "collection": "business",
    "content": "AI agents and infrastructure made a strong showing on CB Insights’s latest list of the top 100 AI startups.\n\nWhat’s new:CB Insights, which tracks tech startups and venture capital, selected companies in theAI 100based on their market traction, talent, finances, and partnerships. The list purports to highlight the next wave of winners, shedding light on the key executives, investors, fundraising, and valuations behind up-and-coming AI ventures.\n\nHow it works:The analysts evaluated 17,000 early-stage, private AI companies that had raised funds within the last year and continue to seek further investment.\n\nWhere the action is:This year’s AI 100 companies are based in 14 countries, around two-thirds of them in the United States. 10 are based in the United Kingdom, five in France, and four in Germany, with one each in Norway (Braintrust), Singapore (Bria), Spain (Cartwheel), Sweden (Chainguard), and Switzerland (Clarium).\n\nWhy it matters:This year’s AI 100 offers a snapshot of AI becoming more central to businesses of all kinds. Most of the startups listed here offer practical products and services that are poised to deliver a timely return, rather than moonshots with long development cycles and risky payoffs. In addition, they mostly target corporate customers rather than consumers.\n\nWe’re thinking:The falling cost of access to AI models and increasingly capable open-weights models make this the perfect time tobuild applications. What kind? The report singles out health care (8 companies) and life sciences (6 companies) as growing areas, but it also documents opportunities in defense, gaming, and finance.",
    "qa": [
      {
        "question": "CB Insights lựa chọn các công ty vào danh sách AI 100 dựa trên những tiêu chí chính nào?",
        "options": {
          "A": "Quy mô nhân sự, doanh thu, và tiềm năng phát triển.",
          "B": "Sức hút thị trường, tài năng, tài chính, và các mối quan hệ đối tác.",
          "C": "Số lượng bằng sáng chế, giá trị thương hiệu, và sự đổi mới công nghệ.",
          "D": "Mức độ ảnh hưởng trên mạng xã hội, số lượng khách hàng, và tốc độ tăng trưởng."
        },
        "answer": "B"
      },
      {
        "question": "CB Insights đã đánh giá bao nhiêu công ty AI giai đoạn đầu để chọn ra AI 100?",
        "options": {
          "A": "Khoảng 1,700 công ty.",
          "B": "Khoảng 17,000 công ty.",
          "C": "Khoảng 170,000 công ty.",
          "D": "Khoảng 1,000 công ty."
        },
        "answer": "B"
      },
      {
        "question": "Phần lớn các công ty trong danh sách AI 100 năm nay có trụ sở tại quốc gia nào?",
        "options": {
          "A": "Trung Quốc.",
          "B": "Vương Quốc Anh.",
          "C": "Hoa Kỳ.",
          "D": "Đức."
        },
        "answer": "C"
      },
      {
        "question": "Có bao nhiêu công ty trong danh sách AI 100 có trụ sở tại Pháp?",
        "options": {
          "A": "3",
          "B": "4",
          "C": "5",
          "D": "6"
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu chính của hầu hết các startup trong danh sách AI 100 là gì?",
        "options": {
          "A": "Phát triển các công nghệ đột phá với tiềm năng thay đổi thế giới.",
          "B": "Cung cấp các sản phẩm và dịch vụ thiết thực mang lại lợi nhuận nhanh chóng.",
          "C": "Nghiên cứu và phát triển các mô hình AI phức tạp.",
          "D": "Xây dựng các ứng dụng AI phục vụ trực tiếp người tiêu dùng."
        },
        "answer": "B"
      },
      {
        "question": "Đối tượng khách hàng mục tiêu chính của phần lớn các startup trong danh sách AI 100 là ai?",
        "options": {
          "A": "Người tiêu dùng cá nhân.",
          "B": "Các tổ chức phi lợi nhuận.",
          "C": "Các doanh nghiệp.",
          "D": "Chính phủ."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì được xem là yếu tố thuận lợi cho việc xây dựng các ứng dụng AI hiện nay?",
        "options": {
          "A": "Sự gia tăng chi phí truy cập vào các mô hình AI.",
          "B": "Sự khan hiếm các chuyên gia AI có kinh nghiệm.",
          "C": "Sự sụt giảm chất lượng của các mô hình AI.",
          "D": "Chi phí truy cập vào các mô hình AI giảm và sự phát triển của các mô hình mã nguồn mở mạnh mẽ."
        },
        "answer": "D"
      },
      {
        "question": "Lĩnh vực nào được báo cáo chỉ ra là một trong những lĩnh vực đang phát triển mạnh mẽ trong ứng dụng AI?",
        "options": {
          "A": "Năng lượng tái tạo.",
          "B": "Giáo dục trực tuyến.",
          "C": "Chăm sóc sức khỏe.",
          "D": "Du lịch vũ trụ."
        },
        "answer": "C"
      },
      {
        "question": "Ngoài chăm sóc sức khỏe, lĩnh vực nào khác cũng được đề cập đến như một cơ hội phát triển trong lĩnh vực AI?",
        "options": {
          "A": "Nông nghiệp công nghệ cao.",
          "B": "Bất động sản thông minh.",
          "C": "Quốc phòng.",
          "D": "Thời trang bền vững."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của danh sách AI 100 là gì?",
        "options": {
          "A": "Xếp hạng các công ty AI dựa trên doanh thu hàng năm.",
          "B": "Đánh giá mức độ ảnh hưởng của các công ty AI đối với xã hội.",
          "C": "Nhấn mạnh làn sóng người chiến thắng tiếp theo trong lĩnh vực AI.",
          "D": "Dự đoán xu hướng phát triển của thị trường chứng khoán AI."
        },
        "answer": "C"
      }
    ]
  },
  "agbots-want-jobs-americans-dont": {
    "title": "Agbots Want Jobs Americans Don’t",
    "collection": "business",
    "content": "Advances in computer vision and robotic dexterity may reach the field just in time to save U.S. agriculture from a looming labor shortage.What happened:CNN Businesssurveyedthe latest crop of AI-powered farmbots, highlighting those capable of picking tender produce, working long hours, and withstanding outdoor conditions.Robot field hands:Harvest bots tend to use two types of computer vision: one to identify ripe fruits or vegetables, the other to guide the picker.\n\nBehind the news:Unauthorized migrants do as much as 70 percent of U.S. harvest work, according to astudyby the American Farm Bureau Association. Tighter immigration policies and improving opportunities at home increasingly keep such workers out of the country.Why it matters:The shortage of agricultural workers extends across North America. During harvest season, that means good produce is left to rot in the fields. The situation costs farmers millions in revenue and drives up food prices.Our take:The robots-are-coming-for-your-job narrative often focuses on people put out of work but fails to acknowledge that workers aren’t always available. Between a swelling human population and emerging challenges brought on by climate change, the agriculture industry needs reliable labor more than ever. In some cases, that could be a machine.",
    "qa": [
      {
        "question": "Theo bài viết, yếu tố nào sau đây đang đe dọa ngành nông nghiệp Hoa Kỳ?",
        "options": {
          "A": "Sự phát triển của công nghệ robot.",
          "B": "Tình trạng thiếu hụt lao động.",
          "C": "Giá nông sản giảm mạnh.",
          "D": "Sự cạnh tranh từ các quốc gia khác."
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ thị giác máy tính được sử dụng trong robot thu hoạch chủ yếu để làm gì?",
        "options": {
          "A": "Điều khiển robot di chuyển trong trang trại.",
          "B": "Xác định trái cây/rau quả chín và hướng dẫn bộ phận thu hoạch.",
          "C": "Phân loại và đóng gói nông sản.",
          "D": "Theo dõi và báo cáo tình trạng thời tiết."
        },
        "answer": "B"
      },
      {
        "question": "Theo một nghiên cứu của American Farm Bureau Association, khoảng bao nhiêu phần trăm công việc thu hoạch ở Hoa Kỳ được thực hiện bởi người di cư không có giấy tờ?",
        "options": {
          "A": "Khoảng 30 phần trăm.",
          "B": "Khoảng 50 phần trăm.",
          "C": "Khoảng 70 phần trăm.",
          "D": "Khoảng 90 phần trăm."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì xảy ra khi thiếu hụt lao động trong mùa thu hoạch?",
        "options": {
          "A": "Nông dân phải trả lương cao hơn cho người lao động.",
          "B": "Nông sản tốt bị bỏ mặc và hư hỏng trên đồng ruộng.",
          "C": "Nông dân phải nhập khẩu nông sản từ các nước khác.",
          "D": "Chính phủ phải hỗ trợ tài chính cho nông dân."
        },
        "answer": "B"
      },
      {
        "question": "Tình trạng thiếu hụt lao động nông nghiệp ảnh hưởng đến người tiêu dùng như thế nào?",
        "options": {
          "A": "Người tiêu dùng có nhiều lựa chọn nông sản hơn.",
          "B": "Giá thực phẩm tăng cao.",
          "C": "Chất lượng nông sản được cải thiện.",
          "D": "Người tiêu dùng được tiếp cận với các loại nông sản mới."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến những yếu tố nào khiến người lao động nhập cư không còn muốn làm việc trong ngành nông nghiệp Hoa Kỳ?",
        "options": {
          "A": "Chính sách nhập cư chặt chẽ hơn và cơ hội việc làm tốt hơn ở quê nhà.",
          "B": "Điều kiện làm việc khắc nghiệt và mức lương thấp.",
          "C": "Sự phát triển của công nghệ robot trong nông nghiệp.",
          "D": "Sự thay đổi trong sở thích của người tiêu dùng."
        },
        "answer": "A"
      },
      {
        "question": "Quan điểm của bài viết về việc robot thay thế con người trong công việc là gì?",
        "options": {
          "A": "Robot sẽ gây ra tình trạng thất nghiệp hàng loạt.",
          "B": "Robot là giải pháp duy nhất cho vấn đề thiếu hụt lao động.",
          "C": "Robot có thể là một giải pháp khi không có đủ người lao động.",
          "D": "Robot sẽ làm giảm chất lượng nông sản."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhấn mạnh tầm quan trọng của lao động đáng tin cậy trong bối cảnh nào?",
        "options": {
          "A": "Sự gia tăng dân số và những thách thức do biến đổi khí hậu.",
          "B": "Sự phát triển của các ngành công nghiệp khác.",
          "C": "Sự thay đổi trong chính sách thương mại quốc tế.",
          "D": "Sự gia tăng chi phí sản xuất nông nghiệp."
        },
        "answer": "A"
      },
      {
        "question": "Theo bài viết, robot thu hoạch có khả năng gì đặc biệt so với con người?",
        "options": {
          "A": "Có khả năng làm việc nhanh hơn và hiệu quả hơn.",
          "B": "Có khả năng làm việc liên tục trong thời gian dài và chịu được điều kiện thời tiết khắc nghiệt.",
          "C": "Có khả năng đưa ra quyết định tốt hơn trong việc lựa chọn nông sản.",
          "D": "Có khả năng giao tiếp và phối hợp làm việc tốt hơn."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của bài viết là gì?",
        "options": {
          "A": "Phân tích tác động tiêu cực của robot đối với ngành nông nghiệp.",
          "B": "Giới thiệu các loại robot thu hoạch mới nhất trên thị trường.",
          "C": "Đề xuất các giải pháp để giải quyết tình trạng thiếu hụt lao động trong nông nghiệp, bao gồm cả việc sử dụng robot.",
          "D": "So sánh hiệu quả giữa lao động con người và lao động robot trong nông nghiệp."
        },
        "answer": "C"
      }
    ]
  },
  "ai-does-the-dishes": {
    "title": "AI Does the Dishes",
    "collection": "business",
    "content": "A pioneer in dishwashing robots is reaching into commercial kitchens.What’s new:Dishcraft Robotics uses machines equipped with computer vision to scrub dirties for corporate food services and, soon, restaurants.How it works:Every morning, Dishcraft’s biodiesel-fueled trucks deliver clean dishes and utensils to corporate clients near its Silicon Valley hub. At the day’s end, the trucks retrieve them. Back at headquarters, workers load racks of dirty dishes and cutlery into an automated washing machine.\n\nBehind the news:Other robotics companies are also aiming to disrupt the kitchen.\n\nWhy it matters:Dishcraft estimates its system saves clients as much as 1.6 gallons of water per meal. Its plan to clean reusable to-go containers could keep tons of waste out of landfills.We’re thinking:Such machines also could mean fewer bodies in food-service kitchens — a plus in the Covid era but not so much for human staff who may find themselves out of a job.",
    "qa": [
      {
        "question": "Công ty Dishcraft Robotics tập trung vào việc phát triển loại robot nào?",
        "options": {
          "A": "Robot phục vụ bàn.",
          "B": "Robot rửa chén.",
          "C": "Robot nấu ăn.",
          "D": "Robot dọn dẹp nhà bếp."
        },
        "answer": "B"
      },
      {
        "question": "Dishcraft Robotics sử dụng công nghệ gì để rửa chén?",
        "options": {
          "A": "Công nghệ laser.",
          "B": "Công nghệ sóng siêu âm.",
          "C": "Công nghệ thị giác máy tính.",
          "D": "Công nghệ phun áp lực cao."
        },
        "answer": "C"
      },
      {
        "question": "Phương tiện vận chuyển của Dishcraft Robotics sử dụng loại nhiên liệu nào?",
        "options": {
          "A": "Xăng.",
          "B": "Dầu diesel.",
          "C": "Biodiesel.",
          "D": "Điện."
        },
        "answer": "C"
      },
      {
        "question": "Dishcraft Robotics hiện đang phục vụ chủ yếu cho đối tượng khách hàng nào?",
        "options": {
          "A": "Nhà hàng cao cấp.",
          "B": "Khách sạn lớn.",
          "C": "Dịch vụ ăn uống của các công ty.",
          "D": "Trường học và bệnh viện."
        },
        "answer": "C"
      },
      {
        "question": "Theo ước tính của Dishcraft, hệ thống của họ giúp khách hàng tiết kiệm được bao nhiêu nước cho mỗi bữa ăn?",
        "options": {
          "A": "0.8 gallon.",
          "B": "1.6 gallon.",
          "C": "2.4 gallon.",
          "D": "3.2 gallon."
        },
        "answer": "B"
      },
      {
        "question": "Kế hoạch làm sạch hộp đựng thức ăn mang đi tái sử dụng của Dishcraft có thể giúp ích gì?",
        "options": {
          "A": "Giảm chi phí vận chuyển.",
          "B": "Giảm lượng khí thải carbon.",
          "C": "Giảm lượng rác thải ra bãi chôn lấp.",
          "D": "Tăng hiệu quả sử dụng năng lượng."
        },
        "answer": "C"
      },
      {
        "question": "Một tác động tiềm ẩn của việc sử dụng robot rửa chén trong ngành dịch vụ ăn uống là gì?",
        "options": {
          "A": "Tăng cường an toàn vệ sinh thực phẩm.",
          "B": "Giảm số lượng nhân viên cần thiết.",
          "C": "Cải thiện chất lượng dịch vụ.",
          "D": "Giảm thời gian chờ đợi của khách hàng."
        },
        "answer": "B"
      },
      {
        "question": "Trụ sở chính của Dishcraft Robotics đặt tại đâu?",
        "options": {
          "A": "New York.",
          "B": "Silicon Valley.",
          "C": "Boston.",
          "D": "Seattle."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài Dishcraft Robotics, bài viết đề cập đến điều gì về các công ty robot khác?",
        "options": {
          "A": "Họ đang hợp tác với Dishcraft.",
          "B": "Họ cũng đang nhắm đến việc thay đổi ngành bếp.",
          "C": "Họ tập trung vào các lĩnh vực khác ngoài ngành bếp.",
          "D": "Họ đang gặp khó khăn trong việc cạnh tranh với Dishcraft."
        },
        "answer": "B"
      },
      {
        "question": "Trong bối cảnh đại dịch Covid-19, việc sử dụng robot trong nhà bếp có thể mang lại lợi ích gì?",
        "options": {
          "A": "Giảm nguy cơ lây nhiễm bệnh.",
          "B": "Tăng cường khả năng phục vụ khách hàng trực tuyến.",
          "C": "Giảm chi phí bảo trì thiết bị.",
          "D": "Cải thiện môi trường làm việc cho nhân viên."
        },
        "answer": "A"
      }
    ]
  },
  "ai-careers-spread-across-the-us-outgrowing-traditional-tech-hubs": {
    "title": "AI Jobs Grow Beyond Established Hubs",
    "collection": "business",
    "content": "An analysis of United States job listings shows AI jobs are growing rapidly outside traditional tech hubs.\n\nWhat’s new:Researchers at University of Marylandanalyzedthe distribution of AI jobs among U.S. job postings. California hosts the largest concentration, followed by the Washington D.C. metropolitan area (which includes more than one state).\n\nHow it works:The authors used an unspecified large language model to identify AI jobs, which they define as ones that require AI skills. They categorized each job by the U.S. state in which it was located. To determine whether a given state’s AI economy was growing or shrinking, they calculated the percentage of total U.S. AI jobs in each state in 2018 and 2023. They also calculated the percentage of each state’s total jobs that required AI skills for both dates.\n\nBehind the news:A 2021 Brookingsreporton U.S. AI jobs focused on metropolitan areas and analyzed not only job postings but also federal grants, research papers, patent filings, and companies. Despite the differences in methodology, it agreed with the new report that investment was driving AI growth outside of the Bay Area. The new report suggests a much wider geographical distribution of AI jobs in 2024 than in 2021. It appears some of the then-emerging industrial investment in AI is bearing fruit.Why it matters:For people who aim to make a career in AI, this report contains double good news: (i) Established AI hubs in the U.S. still host the most new openings and (ii) AI jobs are growing far and wide! As the industry becomes more dispersed geographically, AI builders have more options, organizations can select from a more diverse talent pool, and the technology’s benefits can be shared more broadly.We’re thinking:Although this report focused on the U.S., we believe that growth in AI jobs is a global trend. One contributor is growing acceptance of remote work (which remains more prevalent than it was a few years ago despite its decline as the Covid pandemic has wanted). This means more AI opportunities for everyone, everywhere!",
    "qa": [
      {
        "question": "Nghiên cứu từ Đại học Maryland tập trung vào điều gì?",
        "options": {
          "A": "Phân tích các công ty AI hàng đầu tại Hoa Kỳ.",
          "B": "Phân tích sự phân bố của các công việc liên quan đến AI trong các tin tuyển dụng ở Hoa Kỳ.",
          "C": "Đánh giá tác động của AI đến thị trường lao động toàn cầu.",
          "D": "So sánh mức lương trung bình của các kỹ sư AI ở các bang khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Theo nghiên cứu, khu vực nào có số lượng công việc AI tập trung lớn nhất ở Hoa Kỳ?",
        "options": {
          "A": "Washington D.C.",
          "B": "California.",
          "C": "New York.",
          "D": "Texas."
        },
        "answer": "B"
      },
      {
        "question": "Các tác giả của nghiên cứu đã sử dụng công cụ nào để xác định các công việc AI?",
        "options": {
          "A": "Một thuật toán học máy được phát triển riêng.",
          "B": "Một mô hình ngôn ngữ lớn không được chỉ định.",
          "C": "Một cơ sở dữ liệu các kỹ năng AI được tiêu chuẩn hóa.",
          "D": "Một cuộc khảo sát trực tuyến với các chuyên gia trong ngành."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp chính được sử dụng để xác định sự tăng trưởng hoặc suy giảm của nền kinh tế AI ở mỗi bang là gì?",
        "options": {
          "A": "So sánh số lượng bằng sáng chế liên quan đến AI được nộp ở mỗi bang.",
          "B": "Tính toán tỷ lệ phần trăm tổng số công việc AI của Hoa Kỳ ở mỗi bang trong năm 2018 và 2023.",
          "C": "Đánh giá số lượng các công ty khởi nghiệp AI mới được thành lập ở mỗi bang.",
          "D": "Phân tích số lượng các khoản tài trợ liên bang dành cho nghiên cứu AI ở mỗi bang."
        },
        "answer": "B"
      },
      {
        "question": "Báo cáo Brookings năm 2021 khác với báo cáo mới như thế nào?",
        "options": {
          "A": "Báo cáo Brookings chỉ tập trung vào các tin tuyển dụng, trong khi báo cáo mới xem xét nhiều nguồn dữ liệu hơn.",
          "B": "Báo cáo Brookings tập trung vào các khu vực đô thị, trong khi báo cáo mới tập trung vào toàn bộ các bang.",
          "C": "Báo cáo Brookings chỉ phân tích các công ty lớn, trong khi báo cáo mới bao gồm cả các công ty khởi nghiệp.",
          "D": "Báo cáo Brookings sử dụng một phương pháp luận hoàn toàn khác để xác định các công việc AI."
        },
        "answer": "B"
      },
      {
        "question": "Điểm chung giữa báo cáo mới và báo cáo Brookings năm 2021 là gì?",
        "options": {
          "A": "Cả hai đều cho thấy sự tập trung cao độ của các công việc AI ở Thung lũng Silicon.",
          "B": "Cả hai đều đồng ý rằng đầu tư đang thúc đẩy sự tăng trưởng AI bên ngoài Khu Vực Vịnh.",
          "C": "Cả hai đều dự đoán sự suy giảm của các công việc AI trong tương lai.",
          "D": "Cả hai đều sử dụng cùng một mô hình ngôn ngữ lớn để xác định các công việc AI."
        },
        "answer": "B"
      },
      {
        "question": "Báo cáo mới cho thấy điều gì về sự phân bố địa lý của các công việc AI so với năm 2021?",
        "options": {
          "A": "Sự phân bố địa lý của các công việc AI đã trở nên tập trung hơn ở một số ít khu vực.",
          "B": "Sự phân bố địa lý của các công việc AI đã trở nên rộng hơn nhiều.",
          "C": "Sự phân bố địa lý của các công việc AI không thay đổi đáng kể.",
          "D": "Sự phân bố địa lý của các công việc AI đã chuyển từ các khu vực đô thị sang các vùng nông thôn."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích nào được đề cập cho những người muốn xây dựng sự nghiệp trong lĩnh vực AI?",
        "options": {
          "A": "Sự tăng trưởng của các công việc AI chỉ giới hạn ở một số ít ngành công nghiệp.",
          "B": "Các trung tâm AI đã thành lập vẫn có nhiều cơ hội mới và các công việc AI đang phát triển rộng rãi.",
          "C": "Mức lương cho các công việc AI đang giảm do sự cạnh tranh ngày càng tăng.",
          "D": "Các công việc AI chủ yếu tập trung vào nghiên cứu học thuật, không phải phát triển ứng dụng thực tế."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì được cho là một yếu tố góp phần vào sự tăng trưởng của các công việc AI trên toàn cầu?",
        "options": {
          "A": "Sự gia tăng các quy định của chính phủ đối với ngành công nghiệp AI.",
          "B": "Sự chấp nhận ngày càng tăng của hình thức làm việc từ xa.",
          "C": "Sự suy giảm trong đầu tư vào nghiên cứu và phát triển AI.",
          "D": "Sự thiếu hụt các kỹ năng cần thiết để làm việc trong lĩnh vực AI."
        },
        "answer": "B"
      },
      {
        "question": "Tác giả bài viết tin rằng điều gì về xu hướng tăng trưởng của các công việc AI?",
        "options": {
          "A": "Xu hướng này chỉ giới hạn ở Hoa Kỳ.",
          "B": "Xu hướng này là một xu hướng toàn cầu.",
          "C": "Xu hướng này sẽ sớm đảo ngược do sự tự động hóa.",
          "D": "Xu hướng này chỉ có lợi cho các công ty lớn, không phải các công ty khởi nghiệp."
        },
        "answer": "B"
      }
    ]
  },
  "ai-for-business-is-booming": {
    "title": "AI for Business Is Booming",
    "collection": "business",
    "content": "Commercial AI research and deployments are on the rise, a new study highlights.What’s new:The latest edition of theAI Index, an annual report from Stanford University, documents key trends in the field including the growing importance of private industry and the erosion of U.S. dominance in research.What’s new:Researchers at the Stanford Institute for Human-Centered Artificial Intelligence compiled AI Index 2021 by analyzing academic research, investment reports, and other data sources. Some standout trends:\n\nBehind the news:AI is a rising tide, but it’s not yet lifting all boats. Women made up only 16 percent of tenure-track computer science faculty worldwide in 2019 and about 18 percent of AI and computer science PhDs awarded in North America over the last decade. Meanwhile, Hispanics and Blacks accounted for only 3.2 and 2.3 percent respectively of U.S. AI PhDs in 2019.Why it matters:Private industry’s embrace of AI means more of the technology will be put to real-world use. The growth in corporate research could benefit the field as a whole, though it also highlights the urgent need for well defined standards in technology development, implementation, and auditing.We’re thinking:The figures for women and minorities in AI are unconscionable. AI is creating tremendous wealth and will continue to do so.  But practices are evolving rapidly, and we have only a short time left to make sure this wealth is fairly shared across genders, ethnicities, and nations. We urge governments, companies, and citizens to act quickly to promote AI’s broad positive impact.",
    "qa": [
      {
        "question": "Báo cáo AI Index 2021 được biên soạn bởi tổ chức nào?",
        "options": {
          "A": "Google AI",
          "B": "Stanford Institute for Human-Centered Artificial Intelligence",
          "C": "Massachusetts Institute of Technology (MIT)",
          "D": "OpenAI"
        },
        "answer": "B"
      },
      {
        "question": "Xu hướng nào sau đây được nêu bật trong AI Index 2021?",
        "options": {
          "A": "Sự suy giảm đầu tư vào nghiên cứu AI",
          "B": "Sự trỗi dậy của tầm quan trọng của ngành công nghiệp tư nhân trong AI",
          "C": "Sự thống trị tuyệt đối của Trung Quốc trong nghiên cứu AI",
          "D": "Sự giảm sút về số lượng các công trình nghiên cứu AI được công bố"
        },
        "answer": "B"
      },
      {
        "question": "Tỷ lệ phụ nữ nắm giữ vị trí giảng viên khoa học máy tính (tenure-track) trên toàn thế giới năm 2019 là bao nhiêu?",
        "options": {
          "A": "25%",
          "B": "16%",
          "C": "32%",
          "D": "40%"
        },
        "answer": "B"
      },
      {
        "question": "Trong thập kỷ qua, tỷ lệ tiến sĩ AI và khoa học máy tính được cấp ở Bắc Mỹ là bao nhiêu dành cho phụ nữ?",
        "options": {
          "A": "Khoảng 10%",
          "B": "Khoảng 18%",
          "C": "Khoảng 25%",
          "D": "Khoảng 30%"
        },
        "answer": "B"
      },
      {
        "question": "Theo báo cáo, tỷ lệ người gốc Hispanic và người da đen nhận bằng tiến sĩ AI ở Mỹ năm 2019 lần lượt là bao nhiêu?",
        "options": {
          "A": "5% và 4%",
          "B": "4.2% và 3.3%",
          "C": "3.2% và 2.3%",
          "D": "2.3% và 1.2%"
        },
        "answer": "C"
      },
      {
        "question": "Sự phát triển của nghiên cứu AI trong lĩnh vực tư nhân có thể mang lại lợi ích gì?",
        "options": {
          "A": "Giảm sự cạnh tranh trong ngành AI",
          "B": "Thúc đẩy sự phát triển của lĩnh vực AI nói chung",
          "C": "Hạn chế sự tiếp cận của công chúng với công nghệ AI",
          "D": "Tăng cường sự kiểm soát của chính phủ đối với AI"
        },
        "answer": "B"
      },
      {
        "question": "Điều gì được nhấn mạnh như một nhu cầu cấp thiết trong bối cảnh sự phát triển của AI?",
        "options": {
          "A": "Tăng cường đầu tư vào giáo dục AI",
          "B": "Xây dựng các tiêu chuẩn rõ ràng trong phát triển, triển khai và kiểm toán công nghệ",
          "C": "Hạn chế sự phát triển của AI trong lĩnh vực quân sự",
          "D": "Tăng cường hợp tác quốc tế trong nghiên cứu AI"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết kêu gọi ai hành động để đảm bảo tác động tích cực rộng rãi của AI?",
        "options": {
          "A": "Chỉ các chính phủ",
          "B": "Chỉ các công ty",
          "C": "Chỉ công dân",
          "D": "Chính phủ, công ty và công dân"
        },
        "answer": "D"
      },
      {
        "question": "Theo bài viết, điều gì đang tạo ra sự giàu có to lớn và sẽ tiếp tục làm như vậy?",
        "options": {
          "A": "Năng lượng tái tạo",
          "B": "Trí tuệ nhân tạo (AI)",
          "C": "Công nghệ sinh học",
          "D": "Du lịch vũ trụ"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về việc phân phối sự giàu có do AI tạo ra?",
        "options": {
          "A": "Sự giàu có này đã được phân phối công bằng trên toàn cầu.",
          "B": "Cần đảm bảo sự giàu có này được chia sẻ công bằng giữa các giới tính, dân tộc và quốc gia.",
          "C": "Việc phân phối sự giàu có này nên được để cho thị trường tự do quyết định.",
          "D": "Chính phủ nên kiểm soát hoàn toàn việc phân phối sự giàu có này."
        },
        "answer": "B"
      }
    ]
  },
  "ai-giants-rethink-model-training-strategy-as-scaling-laws-break-down": {
    "title": "Next-Gen Models Show Limited Gains",
    "collection": "ml-research",
    "content": "Builders of large AI models have relied on the idea that bigger neural networks trained on more data and given more processing power would show steady improvements. Recent developments are challenging that idea.\n\nWhat’s new:Next-generation large language models from OpenAI, Google, and Anthropic are falling short of expectations, employees at those companiestoldmultiplepublications. All three companies are responding by shifting their focus from pretraining to enhancing performance through techniques like fine-tuning and multi-step inference.\n\nScaling law basics:A classic 2020papershows that, assuming a sufficient quantity of data, a transformer network’s performance rises predictably with increases in model size (demonstrated between 768 parameters and 1.5 billion parameters). Likewise, assuming sufficient model size, performance rises predictably with increases in dataset size (demonstrated between 22 million tokens and 23 billion tokens). Furthermore, performance rises predictably with increases in both model and dataset sizes. The 2022 Chinchillapapershows that, to build an optimal model, every 4x increase in compute requires a 2x increase in the size of the model and dataset (demonstrated for models between 70 million and 16 billion parameters, trained on between 5 billion and 500 billion tokens). Due to limited experimentation and lack of a theoretical basis of their findings, the authors didn’t determine whether these relationships would continue to hold at larger scales.\n\nDiminishing returns:Major AI companies have been counting on scaling laws to keep their models growing more capable at a steady pace. However, the next generation of high-profile models has not shown the expected improvements despite larger architectures, more training data, and more processing power.\n\nWhat they’re saying:AI leaders are divided on the future of scaling laws as they are currently understood.\n\nWhy it matters:AI’s phenomenal advance has drawn hundreds of millions of users and sparked a new era of progress and hope. Slower-than-expected improvements in future foundation models may blunt this progress. At the same time, the cost of training large AI models is rising dramatically. The latest models cost as much as $100 million to train, and this number could reach $100 billion within a few years,according toAnthropic’s Dario Amodei. Rising costs could lead companies to reallocate their gargantuan training budgets and researchers to focus on more cost-effective, application-specific approaches.\n\nWe’re thinking:AI’s power-law curves may be flattening, but we don’t see overall progress slowing. Many developers already have shifted to building smaller, more processing-efficient models, especially networks that can run on edge devices. Agentic workflows are taking off and bringing huge gains in performance. Training on synthetic data is another frontier that’s only beginning to be explored. AI technology holds many wonders to come!",
    "qa": [
      {
        "question": "Theo bài viết, các công ty như OpenAI, Google và Anthropic đang thay đổi trọng tâm phát triển AI như thế nào?",
        "options": {
          "A": "Tăng cường đầu tư vào phần cứng để tăng tốc độ xử lý.",
          "B": "Chuyển từ giai đoạn huấn luyện trước sang các kỹ thuật nâng cao hiệu suất như tinh chỉnh và suy luận đa bước.",
          "C": "Giảm kích thước mô hình để tiết kiệm chi phí đào tạo.",
          "D": "Tập trung vào việc thu thập dữ liệu huấn luyện lớn hơn."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu năm 2020 chỉ ra điều gì về mối quan hệ giữa kích thước mô hình và hiệu suất?",
        "options": {
          "A": "Hiệu suất giảm khi kích thước mô hình tăng lên.",
          "B": "Hiệu suất tăng một cách dự đoán được khi kích thước mô hình tăng lên, với điều kiện có đủ dữ liệu.",
          "C": "Hiệu suất không liên quan đến kích thước mô hình.",
          "D": "Hiệu suất chỉ tăng khi kích thước mô hình vượt quá 1.5 tỷ tham số."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu Chinchilla năm 2022 đề xuất tỷ lệ tối ưu giữa tính toán, kích thước mô hình và kích thước tập dữ liệu là gì?",
        "options": {
          "A": "Mỗi khi tính toán tăng gấp đôi, kích thước mô hình và tập dữ liệu cần tăng gấp bốn.",
          "B": "Mỗi khi tính toán tăng gấp bốn, kích thước mô hình và tập dữ liệu cần tăng gấp đôi.",
          "C": "Kích thước mô hình và tập dữ liệu cần tăng tuyến tính với sự gia tăng của tính toán.",
          "D": "Không có mối quan hệ cụ thể giữa tính toán, kích thước mô hình và kích thước tập dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, một trong những lý do khiến các mô hình AI thế hệ mới không đạt được kỳ vọng là gì?",
        "options": {
          "A": "Thiếu dữ liệu huấn luyện chất lượng cao.",
          "B": "Sự suy giảm lợi nhuận khi tăng quy mô mô hình, dữ liệu và sức mạnh xử lý.",
          "C": "Các thuật toán huấn luyện không còn phù hợp.",
          "D": "Sự cạnh tranh gay gắt giữa các công ty AI."
        },
        "answer": "B"
      },
      {
        "question": "Dario Amodei của Anthropic dự đoán chi phí đào tạo các mô hình AI lớn có thể đạt đến mức nào trong vài năm tới?",
        "options": {
          "A": "10 triệu đô la.",
          "B": "100 triệu đô la.",
          "C": "1 tỷ đô la.",
          "D": "100 tỷ đô la."
        },
        "answer": "D"
      },
      {
        "question": "Bài viết đề xuất những hướng đi nào để tiếp tục phát triển AI hiệu quả hơn về chi phí?",
        "options": {
          "A": "Tập trung vào các mô hình nhỏ hơn, hiệu quả xử lý hơn và các quy trình làm việc dựa trên tác nhân.",
          "B": "Chỉ sử dụng dữ liệu huấn luyện thực tế thay vì dữ liệu tổng hợp.",
          "C": "Tăng cường hợp tác quốc tế để chia sẻ tài nguyên và kiến thức.",
          "D": "Phát triển các thuật toán nén dữ liệu hiệu quả hơn."
        },
        "answer": "A"
      },
      {
        "question": "Bài viết đề cập đến 'scaling laws' (quy luật mở rộng quy mô) trong bối cảnh nào?",
        "options": {
          "A": "Quy luật về việc tăng số lượng người dùng AI theo thời gian.",
          "B": "Quy luật về mối quan hệ giữa kích thước mô hình, dữ liệu và hiệu suất.",
          "C": "Quy luật về việc giảm chi phí đào tạo AI theo thời gian.",
          "D": "Quy luật về việc tăng tốc độ xử lý của các thiết bị phần cứng."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì có thể xảy ra nếu sự cải thiện của các mô hình nền tảng chậm hơn dự kiến?",
        "options": {
          "A": "Sự tiến bộ và hy vọng trong lĩnh vực AI có thể bị chậm lại.",
          "B": "Giá cổ phiếu của các công ty AI sẽ tăng mạnh.",
          "C": "Chính phủ sẽ tăng cường đầu tư vào nghiên cứu AI.",
          "D": "Các nhà nghiên cứu sẽ từ bỏ lĩnh vực AI."
        },
        "answer": "A"
      },
      {
        "question": "Bài viết đề cập đến việc sử dụng 'synthetic data' (dữ liệu tổng hợp) như thế nào?",
        "options": {
          "A": "Là một phương pháp đã được khai thác triệt để để cải thiện hiệu suất AI.",
          "B": "Là một lĩnh vực mới nổi đầy hứa hẹn để huấn luyện AI.",
          "C": "Là một phương pháp tốn kém và không hiệu quả.",
          "D": "Là một phương pháp chỉ phù hợp cho các ứng dụng AI cụ thể."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đang diễn ra với các đường cong 'power-law' (luật lũy thừa) trong lĩnh vực AI, theo quan điểm của bài viết?",
        "options": {
          "A": "Chúng đang dốc lên nhanh chóng, cho thấy sự tăng trưởng vượt bậc.",
          "B": "Chúng có thể đang trở nên phẳng hơn, cho thấy sự suy giảm lợi nhuận.",
          "C": "Chúng không thay đổi và vẫn tiếp tục dự đoán chính xác sự phát triển của AI.",
          "D": "Chúng chỉ áp dụng cho một số loại mô hình AI nhất định."
        },
        "answer": "B"
      }
    ]
  },
  "ai-in-regions-rich-and-poor": {
    "title": "AI in Regions Rich and Poor",
    "collection": "business",
    "content": "Companies in Africa and the Middle East are building AI capacity in very different ways, a new study found.What’s new:AI is growing fast in both regions despite shortages of talent and data, according toMIT Technology Review Insights, the research arm of Massachusetts Institute of Technology’s magazine. Yet the implementations in each region reflect stark differences in economic development.What it says:The report focuses on wealthy countries in the Persian Gulf, particularly Saudi Arabia and the United Arab Emirates, as well as African tech hotspots in Ghana, Kenya, and Nigeria.\n\nGrowing pains:AI adoption hasn’t been smooth sailing. Nearly 60 percent of respondents said they’ve struggled to apply AI in their business. Nearly as many cited difficulty obtaining high-quality data. Africa and the Middle East are also struggling to find talent, with 40 percent of respondents noting a shortage of AI professionals in the regions.Why it matters:AI could prove to be a boon for individuals, and the planet at large, by helping to lift African economies and wean Middle Eastern ones from reliance on oil.We’re thinking:The Persian Gulf is one of the world’s richest regions, and sub-Saharan Africa its poorest. The fact that both are turning to AI says a lot about the technology’s potential to streamline existing economies and foster new ones.",
    "qa": [
      {
        "question": "Theo nghiên cứu của MIT Technology Review Insights, điều gì đang diễn ra với AI ở Châu Phi và Trung Đông?",
        "options": {
          "A": "AI đang suy giảm do thiếu hụt tài năng và dữ liệu.",
          "B": "AI đang phát triển nhanh chóng mặc dù thiếu hụt tài năng và dữ liệu.",
          "C": "AI chỉ phát triển ở các quốc gia giàu có.",
          "D": "AI đã đạt đến đỉnh điểm và đang ổn định."
        },
        "answer": "B"
      },
      {
        "question": "Báo cáo tập trung vào những khu vực cụ thể nào ở Châu Phi và Trung Đông?",
        "options": {
          "A": "Ai Cập, Algeria và Iran.",
          "B": "Ghana, Kenya, Nigeria và các quốc gia giàu có ở vùng Vịnh Ba Tư.",
          "C": "Nam Phi, Morocco và Iraq.",
          "D": "Ethiopia, Tanzania và Syria."
        },
        "answer": "B"
      },
      {
        "question": "Theo báo cáo, khó khăn lớn nhất mà các công ty gặp phải khi ứng dụng AI là gì?",
        "options": {
          "A": "Chi phí đầu tư quá cao.",
          "B": "Khó khăn trong việc áp dụng AI vào hoạt động kinh doanh.",
          "C": "Thiếu sự hỗ trợ từ chính phủ.",
          "D": "Sự phản đối từ người lao động."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài khó khăn trong việc ứng dụng AI, một trở ngại lớn khác được đề cập trong báo cáo là gì?",
        "options": {
          "A": "Thiếu cơ sở hạ tầng công nghệ.",
          "B": "Khó khăn trong việc thu thập dữ liệu chất lượng cao.",
          "C": "Rào cản ngôn ngữ.",
          "D": "Sự thiếu hiểu biết về AI trong cộng đồng."
        },
        "answer": "B"
      },
      {
        "question": "Tình trạng thiếu hụt nhân lực AI ở Châu Phi và Trung Đông được thể hiện như thế nào trong báo cáo?",
        "options": {
          "A": "Chỉ có 10% công ty gặp khó khăn trong việc tìm kiếm chuyên gia AI.",
          "B": "Khoảng 40% số người được hỏi cho biết thiếu chuyên gia AI.",
          "C": "Hầu hết các công ty đều có đủ nhân lực AI.",
          "D": "Các chuyên gia AI từ nước ngoài không muốn làm việc ở khu vực này."
        },
        "answer": "B"
      },
      {
        "question": "AI có tiềm năng mang lại lợi ích gì cho Châu Phi?",
        "options": {
          "A": "Giảm thiểu tác động của biến đổi khí hậu.",
          "B": "Nâng cao nền kinh tế.",
          "C": "Cải thiện hệ thống giáo dục.",
          "D": "Tăng cường an ninh quốc phòng."
        },
        "answer": "B"
      },
      {
        "question": "AI có tiềm năng mang lại lợi ích gì cho các quốc gia Trung Đông?",
        "options": {
          "A": "Giảm sự phụ thuộc vào nông nghiệp.",
          "B": "Giảm sự phụ thuộc vào dầu mỏ.",
          "C": "Cải thiện hệ thống y tế.",
          "D": "Tăng cường hợp tác quốc tế."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì được nhấn mạnh về tiềm năng của AI khi cả vùng Vịnh Ba Tư giàu có và khu vực cận Sahara nghèo khó đều hướng tới công nghệ này?",
        "options": {
          "A": "AI chỉ phù hợp với các quốc gia phát triển.",
          "B": "AI có tiềm năng hợp lý hóa các nền kinh tế hiện có và thúc đẩy các nền kinh tế mới.",
          "C": "AI sẽ thay thế hoàn toàn các ngành công nghiệp truyền thống.",
          "D": "AI chỉ là một xu hướng nhất thời."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, sự khác biệt lớn nhất trong việc xây dựng năng lực AI giữa các quốc gia vùng Vịnh và các nước Châu Phi là gì?",
        "options": {
          "A": "Các quốc gia vùng Vịnh tập trung vào phần cứng, trong khi Châu Phi tập trung vào phần mềm.",
          "B": "Bài viết không đề cập đến sự khác biệt cụ thể, chỉ nói chung về sự khác biệt trong phát triển kinh tế.",
          "C": "Các quốc gia vùng Vịnh đầu tư nhiều hơn vào nghiên cứu cơ bản, trong khi Châu Phi tập trung vào ứng dụng thực tế.",
          "D": "Các quốc gia vùng Vịnh phụ thuộc vào nhân tài nước ngoài, trong khi Châu Phi phát triển nhân tài trong nước."
        },
        "answer": "B"
      },
      {
        "question": "Tổ chức nào đã thực hiện nghiên cứu về sự phát triển của AI ở Châu Phi và Trung Đông?",
        "options": {
          "A": "Liên Hợp Quốc.",
          "B": "Ngân hàng Thế giới.",
          "C": "MIT Technology Review Insights.",
          "D": "Diễn đàn Kinh tế Thế giới."
        },
        "answer": "C"
      }
    ]
  },
  "ai-hubs-are-few-and-far-between": {
    "title": "AI Hubs Are Few and Far Between",
    "collection": "business",
    "content": "A new study warns that the geographic concentration of AI in the United States is making the industry too insular.What’s new:Areportby the Brookings Institution documents the extent to which a few metropolitan areas dominate AI in the U.S., risking group-think, geographic bias, and other pitfalls.AI Hubs Actual and Potential:The report scores AI research and commercialization in 384 regions based on an analysis of federal grants, research papers, patent filings, job postings, and companies.\n\nBehind the news:The Bay Area’s dominance in AI dates to the late 1950s, when the nascent semiconductor industry spawned what became the modern tech industry. Owing partly to this history, the region hosts a thriving ecosystem of universities, businesses, and financiers that focus on technological innovation.Why it matters:AI’s lopsided geographic concentration not only undermines demographic and intellectual diversity, it “locks in a winner-take-most dimension to this sector,” Mark Muro, the study’s coauthor, toldWired. This imbalance between risk and reward highlights a need for policy and investment that promotes AI in other parts of the country, he said.We’re thinking:Other industries are geographically concentrated; for instance entertainment, fashion, and finance. But AI has a special need for a diverse talent pool to ensure that the systems we build are fair and broadly beneficial.",
    "qa": [
      {
        "question": "Theo báo cáo của Brookings Institution, điều gì đang xảy ra với sự phát triển của AI tại Hoa Kỳ?",
        "options": {
          "A": "AI đang phát triển đồng đều trên khắp các tiểu bang.",
          "B": "AI đang tập trung quá mức ở một vài khu vực đô thị.",
          "C": "AI đang dần suy giảm do thiếu nguồn lực đầu tư.",
          "D": "AI đang bị ảnh hưởng bởi sự cạnh tranh gay gắt từ các quốc gia khác."
        },
        "answer": "B"
      },
      {
        "question": "Báo cáo của Brookings Institution đánh giá sự phát triển AI của các khu vực dựa trên những yếu tố nào?",
        "options": {
          "A": "Số lượng kỹ sư AI và các trường đại học đào tạo AI.",
          "B": "Số lượng bằng sáng chế AI, bài nghiên cứu khoa học, và các khoản tài trợ liên bang.",
          "C": "Mức độ phổ biến của AI trên mạng xã hội và các ứng dụng di động.",
          "D": "Số lượng công ty khởi nghiệp AI và vốn đầu tư mạo hiểm rót vào AI."
        },
        "answer": "B"
      },
      {
        "question": "Khu vực nào được đề cập đến trong bài viết là trung tâm AI hàng đầu tại Hoa Kỳ?",
        "options": {
          "A": "Thung lũng Silicon (Bay Area).",
          "B": "Thành phố New York.",
          "C": "Boston.",
          "D": "Los Angeles."
        },
        "answer": "A"
      },
      {
        "question": "Yếu tố nào được cho là nguyên nhân chính dẫn đến sự thống trị của Bay Area trong lĩnh vực AI?",
        "options": {
          "A": "Chính sách ưu đãi thuế của chính phủ liên bang.",
          "B": "Sự phát triển của ngành công nghiệp bán dẫn từ những năm 1950.",
          "C": "Vị trí địa lý thuận lợi gần các trường đại học hàng đầu.",
          "D": "Nguồn lao động giá rẻ dồi dào."
        },
        "answer": "B"
      },
      {
        "question": "Theo Mark Muro, sự tập trung địa lý của AI có thể dẫn đến hậu quả tiêu cực nào?",
        "options": {
          "A": "Làm chậm tốc độ đổi mới và sáng tạo trong lĩnh vực AI.",
          "B": "Tạo ra sự mất cân bằng giữa rủi ro và lợi nhuận, và cản trở sự đa dạng.",
          "C": "Gây ra tình trạng thiếu hụt nhân tài AI ở các khu vực khác.",
          "D": "Làm tăng chi phí nghiên cứu và phát triển AI."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất giải pháp nào để giải quyết vấn đề tập trung địa lý của AI?",
        "options": {
          "A": "Hạn chế đầu tư vào các trung tâm AI hiện tại.",
          "B": "Thúc đẩy chính sách và đầu tư vào AI ở các khu vực khác của đất nước.",
          "C": "Tăng cường hợp tác quốc tế trong lĩnh vực AI.",
          "D": "Khuyến khích các công ty AI chuyển trụ sở đến các khu vực kém phát triển hơn."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài AI, những ngành công nghiệp nào khác cũng được đề cập đến trong bài viết là có sự tập trung địa lý?",
        "options": {
          "A": "Nông nghiệp, sản xuất, và khai thác mỏ.",
          "B": "Giáo dục, y tế, và năng lượng.",
          "C": "Giải trí, thời trang, và tài chính.",
          "D": "Vận tải, xây dựng, và viễn thông."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao AI cần một nguồn nhân tài đa dạng hơn so với các ngành công nghiệp khác?",
        "options": {
          "A": "Để giảm chi phí tuyển dụng và đào tạo nhân viên.",
          "B": "Để đảm bảo rằng các hệ thống AI được xây dựng công bằng và mang lại lợi ích rộng rãi.",
          "C": "Để tăng cường khả năng cạnh tranh của các công ty AI trên thị trường quốc tế.",
          "D": "Để đáp ứng nhu cầu ngày càng tăng về các chuyên gia AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, sự tập trung địa lý của AI có thể dẫn đến nguy cơ nào liên quan đến tư duy?",
        "options": {
          "A": "Tư duy phản biện.",
          "B": "Tư duy sáng tạo.",
          "C": "Tư duy nhóm (group-think).",
          "D": "Tư duy chiến lược."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhấn mạnh tầm quan trọng của yếu tố nào trong việc phát triển AI một cách bền vững?",
        "options": {
          "A": "Tăng cường bảo mật dữ liệu.",
          "B": "Đảm bảo tính minh bạch của thuật toán.",
          "C": "Thúc đẩy sự đa dạng về nhân khẩu học và trí tuệ.",
          "D": "Giảm thiểu tác động tiêu cực đến môi trường."
        },
        "answer": "C"
      }
    ]
  },
  "ai-in-the-real-world": {
    "title": "AI in the Real World",
    "collection": "business",
    "content": "Theoretical advances can be thrilling, but the excitement can drown out all the ways AI is actually being put to use. DeepIndex provides an up-to-date, well organized, cheeky guide to practical applications culled from news reports.\n\nWhat it is:DeepIndex.org lists over 630 examples, organized into 19 categories and ranked according to how well they work.\n\nOur favorites:DeepIndex is a treasure trove of bold efforts and unlikely concepts. Yiu’s personal favorite is a model that “fixes Warner Bros.’ terrible attempts to digitallyremove Henry Cavill’s mustachein [the Hollywood blockbuster] Justice League.” That’s a fun use case, no doubt, but we found others more compelling:",
    "qa": [
      {
        "question": "Mục đích chính của DeepIndex là gì?",
        "options": {
          "A": "Cung cấp các tiến bộ lý thuyết mới nhất về AI.",
          "B": "Tổng hợp và đánh giá các ứng dụng thực tế của AI từ các nguồn tin tức.",
          "C": "Phân tích các thuật toán AI phức tạp.",
          "D": "Dự đoán tương lai của ngành công nghiệp AI."
        },
        "answer": "B"
      },
      {
        "question": "DeepIndex được tổ chức như thế nào?",
        "options": {
          "A": "Theo mức độ phức tạp của thuật toán.",
          "B": "Theo 19 danh mục và xếp hạng theo hiệu quả hoạt động.",
          "C": "Theo thời gian phát triển của ứng dụng.",
          "D": "Theo mức độ phổ biến trên mạng xã hội."
        },
        "answer": "B"
      },
      {
        "question": "Số lượng ví dụ ứng dụng AI được liệt kê trên DeepIndex là bao nhiêu?",
        "options": {
          "A": "Hơn 100.",
          "B": "Hơn 300.",
          "C": "Hơn 500.",
          "D": "Hơn 630."
        },
        "answer": "D"
      },
      {
        "question": "Ứng dụng AI nào được Yiu yêu thích nhất trên DeepIndex?",
        "options": {
          "A": "Ứng dụng dự đoán thời tiết.",
          "B": "Ứng dụng sửa lỗi kỹ thuật số râu của Henry Cavill trong Justice League.",
          "C": "Ứng dụng dịch ngôn ngữ tự động.",
          "D": "Ứng dụng phân tích dữ liệu tài chính."
        },
        "answer": "B"
      },
      {
        "question": "Phong cách trình bày thông tin của DeepIndex được mô tả như thế nào?",
        "options": {
          "A": "Nghiêm túc và học thuật.",
          "B": "Chính xác và khô khan.",
          "C": "Hài hước và dí dỏm.",
          "D": "Chi tiết và chuyên sâu."
        },
        "answer": "C"
      },
      {
        "question": "Nguồn thông tin chính mà DeepIndex sử dụng để thu thập các ứng dụng AI là gì?",
        "options": {
          "A": "Các bài báo khoa học.",
          "B": "Các báo cáo nghiên cứu thị trường.",
          "C": "Các nguồn tin tức.",
          "D": "Các diễn đàn trực tuyến về AI."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì có thể lấn át sự quan tâm đến các ứng dụng thực tế của AI?",
        "options": {
          "A": "Sự phức tạp của các thuật toán.",
          "B": "Sự hào hứng với các tiến bộ lý thuyết.",
          "C": "Sự thiếu hụt nguồn lực tài chính.",
          "D": "Sự lo ngại về đạo đức."
        },
        "answer": "B"
      },
      {
        "question": "DeepIndex xếp hạng các ứng dụng AI dựa trên tiêu chí nào?",
        "options": {
          "A": "Mức độ phổ biến.",
          "B": "Hiệu quả hoạt động.",
          "C": "Tính sáng tạo.",
          "D": "Khả năng ứng dụng rộng rãi."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu của DeepIndex là gì khi cung cấp thông tin về các ứng dụng AI?",
        "options": {
          "A": "Thúc đẩy nghiên cứu lý thuyết về AI.",
          "B": "Cung cấp một cái nhìn tổng quan về các ứng dụng thực tế của AI.",
          "C": "Cạnh tranh với các nền tảng AI khác.",
          "D": "Thu hút đầu tư vào các công ty AI."
        },
        "answer": "B"
      },
      {
        "question": "Trong đoạn văn, 'treasure trove' (kho báu) dùng để chỉ điều gì?",
        "options": {
          "A": "Các thuật toán AI phức tạp.",
          "B": "DeepIndex và các ứng dụng AI được liệt kê.",
          "C": "Các nhà nghiên cứu AI hàng đầu.",
          "D": "Các nguồn tài trợ cho nghiên cứu AI."
        },
        "answer": "B"
      }
    ]
  },
  "ai-price-wars-drive-costs-down-as-competition-heats-up": {
    "title": "Prices Tumble",
    "collection": "ml-research",
    "content": "Fierce competition among model makers and cloud providers drove down the price of access to state-of-the-art models.\n\nWhat happened:AI providers waged aprice warto attract paying customers. A leading indicator: From March 2023 to November 2024, OpenAI cut the per-token prices of cloud access to its models by nearly 90 percent even as performance improved, input context windows expanded, and the models became capable of processing images as well as text.\n\nDriving the story:Factors that pushed down prices include open source, more compute-efficient models, and excitement around agentic workflows that consume more tokens at inference. OpenAI’s GPT-4 Turbo set a baseline when it debuted in late 2023 at $10.00/$30.00 per million tokens of input/output. Top model makers slashed prices in turn: Google and OpenAI at the higher end of the market, companies in China at the lower end, and Amazon at both. Meanwhile, startups with specialized hardware offered open models at prices that dramatically undercut the giants.\n\nYes, but:The trend toward more processing-intensive models is challenged but not dead. In September, OpenAIintroducedtoken-hungry models with relatively hefty price tags: o1-preview ($15.00/$60.00 per million tokens input/output) and o1-mini ($3.00/$12.00). In December, o1 arrived with a more accurate pro mode that’savailableonly to subscribers who are willing to pay $200 per month.\n\nBehind the news:Prominent members of the AI community pushed against regulations that threatened to restrict open source models, which played an important role in bringing down prices. Opposition by developers helped to block California SB 1047, a proposed law that would have held developers of models above certain size limits liable for unintended harms caused by their models and required a “kill switch” that would enable developers to disable them — a problematic requirement for open weights models that anyone could modify and deploy. California Governor Gavin Newsom vetoed the bill in October.\n\nWhere things stand:Falling prices are a sign of a healthy tech ecosystem. It’s likely that in-demand models will always fetch relatively high prices, but the market is increasingly priced in pennies, not dollars, per million tokens.",
    "qa": [
      {
        "question": "Điều gì đã thúc đẩy sự cạnh tranh khốc liệt giữa các nhà cung cấp mô hình AI?",
        "options": {
          "A": "Mong muốn được công nhận là nhà cung cấp mô hình AI tốt nhất.",
          "B": "Nỗ lực thu hút khách hàng trả phí.",
          "C": "Áp lực từ các quy định của chính phủ về giá cả.",
          "D": "Yêu cầu từ các nhà nghiên cứu về mô hình AI giá rẻ."
        },
        "answer": "B"
      },
      {
        "question": "Trong khoảng thời gian từ tháng 3 năm 2023 đến tháng 11 năm 2024, OpenAI đã thực hiện điều gì liên quan đến giá cả mô hình AI?",
        "options": {
          "A": "Tăng giá các mô hình AI do hiệu suất được cải thiện.",
          "B": "Giảm gần 90% giá mỗi token truy cập đám mây vào các mô hình của mình.",
          "C": "Ổn định giá các mô hình AI để duy trì lợi nhuận.",
          "D": "Chỉ giảm giá cho các khách hàng thân thiết."
        },
        "answer": "B"
      },
      {
        "question": "Yếu tố nào sau đây KHÔNG được đề cập đến như một nguyên nhân làm giảm giá các mô hình AI?",
        "options": {
          "A": "Mã nguồn mở.",
          "B": "Mô hình hiệu quả tính toán hơn.",
          "C": "Sự ra đời của các tác nhân AI.",
          "D": "Sự can thiệp của chính phủ."
        },
        "answer": "D"
      },
      {
        "question": "GPT-4 Turbo của OpenAI được ra mắt với mức giá bao nhiêu cho mỗi triệu token đầu vào/đầu ra?",
        "options": {
          "A": "$5.00/$15.00",
          "B": "$10.00/$30.00",
          "C": "$15.00/$45.00",
          "D": "$20.00/$60.00"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào của OpenAI được giới thiệu vào tháng 9 với mức giá cao hơn và yêu cầu nhiều token hơn?",
        "options": {
          "A": "GPT-3.5 Turbo",
          "B": "GPT-4",
          "C": "o1-preview và o1-mini",
          "D": "GPT-4 Turbo"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì đặc biệt về chế độ 'pro' của o1 được ra mắt vào tháng 12?",
        "options": {
          "A": "Nó miễn phí cho tất cả người dùng.",
          "B": "Nó chỉ dành cho người đăng ký trả phí $200 mỗi tháng.",
          "C": "Nó có hiệu suất thấp hơn các phiên bản khác.",
          "D": "Nó không yêu cầu token."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã xảy ra với dự luật SB 1047 của California?",
        "options": {
          "A": "Đã được thông qua và trở thành luật.",
          "B": "Đã bị chặn bởi sự phản đối của các nhà phát triển.",
          "C": "Đã được sửa đổi và thông qua với các điều khoản ít nghiêm ngặt hơn.",
          "D": "Đã được Tòa án Tối cao California bác bỏ."
        },
        "answer": "B"
      },
      {
        "question": "Nội dung chính của dự luật SB 1047 của California là gì?",
        "options": {
          "A": "Yêu cầu các nhà phát triển AI phải công khai mã nguồn của họ.",
          "B": "Yêu cầu các nhà phát triển AI phải chịu trách nhiệm về những tác hại không mong muốn do mô hình của họ gây ra và có 'công tắc tắt'.",
          "C": "Cấm sử dụng AI trong các lĩnh vực nhạy cảm như y tế và tài chính.",
          "D": "Tăng thuế đối với các công ty phát triển AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, giá cả giảm của các mô hình AI là dấu hiệu của điều gì?",
        "options": {
          "A": "Sự suy thoái của ngành công nghiệp AI.",
          "B": "Một hệ sinh thái công nghệ lành mạnh.",
          "C": "Sự độc quyền của một vài công ty lớn.",
          "D": "Sự can thiệp quá mức của chính phủ."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết dự đoán gì về giá cả của các mô hình AI trong tương lai?",
        "options": {
          "A": "Giá sẽ tiếp tục giảm mạnh và trở nên miễn phí.",
          "B": "Giá sẽ ổn định ở mức hiện tại.",
          "C": "Các mô hình được ưa chuộng sẽ luôn có giá tương đối cao, nhưng thị trường ngày càng định giá bằng xu, không phải đô la, cho mỗi triệu token.",
          "D": "Giá sẽ tăng trở lại do chi phí phát triển mô hình ngày càng cao."
        },
        "answer": "C"
      }
    ]
  },
  "ai-model-prices-drop-as-competition-heats-up": {
    "title": "Higher Performance, Lower Prices",
    "collection": "business",
    "content": "Prices for access to large language models are falling as providers exploit new efficiencies and compete for new customers.\n\nWhat’s new:Open AIcutthe price of calls to GPT-4o’s API by 50 percent for input tokens and 33 percent for output tokens, with an even steeper discount for asynchronous processing. Not to be outdone, Googlecutthe price of API calls to Gemini 1.5 Flash by approximately 75 percent.\n\nHow it works:The latest price reductions follow a steady trend,trackedby Smol.ai CEO Shawn Wang, in which providers are charging less even as model performance (as measured by LMSys’sChatbot Arena LeaderboardElo ratings) rises. Here’s a list of recent prices in order of each model’s  rank on the leaderboard as of this writing:\n\nBehind the news:Less than six months ago, cutting-edge large language models like GPT-4, Claude 2, Gemini 1.0, Llama 2, and Mistral Large were less capable and more expensive than their current versions. For instance, GPT-4 costs $30/$60 per million tokens input/output. Since then, models have notched higher benchmark performances even prices have fallen. The latest models are also faster, have larger context windows, support a wider range of input types, and do better at complex tasks such as agentic workflows.\n\nWhy it matters:Competition is fierce to provide the most effective and efficient large language models, offering an extraordinary range of price and performance to developers. Makers of foundation models that can’t match the best large models in performance or the best small models in cost are in a tight corner.\n\nWe’re thinking:What an amazing time to be developing AI applications! You can choose among models that are open or closed, small or large, faster or more powerful in virtually any combination. Everyone is competing for your business!",
    "qa": [
      {
        "question": "Điều gì đang xảy ra với giá của các mô hình ngôn ngữ lớn?",
        "options": {
          "A": "Giá đang tăng do nhu cầu sử dụng tăng cao.",
          "B": "Giá đang giảm do các nhà cung cấp cạnh tranh và tối ưu hóa hiệu quả.",
          "C": "Giá ổn định do sự cân bằng giữa cung và cầu.",
          "D": "Giá biến động mạnh do ảnh hưởng của các yếu tố kinh tế vĩ mô."
        },
        "answer": "B"
      },
      {
        "question": "OpenAI đã giảm giá API của GPT-4o như thế nào?",
        "options": {
          "A": "Giảm 50% cho output tokens và 33% cho input tokens.",
          "B": "Giảm 50% cho input tokens và 33% cho output tokens.",
          "C": "Giảm 33% cho cả input và output tokens.",
          "D": "Giảm 75% cho cả input và output tokens."
        },
        "answer": "B"
      },
      {
        "question": "Google đã giảm giá API của mô hình nào?",
        "options": {
          "A": "GPT-4o",
          "B": "Claude 2",
          "C": "Gemini 1.5 Flash",
          "D": "Llama 2"
        },
        "answer": "C"
      },
      {
        "question": "Shawn Wang, CEO của Smol.ai, đã theo dõi xu hướng nào?",
        "options": {
          "A": "Sự tăng giá của các mô hình ngôn ngữ lớn.",
          "B": "Sự giảm giá của các mô hình ngôn ngữ lớn song song với việc cải thiện hiệu suất.",
          "C": "Sự ổn định giá của các mô hình ngôn ngữ lớn.",
          "D": "Sự tăng hiệu suất của các mô hình ngôn ngữ lớn mà không thay đổi giá."
        },
        "answer": "B"
      },
      {
        "question": "So với trước đây, các mô hình ngôn ngữ lớn hiện tại có đặc điểm gì nổi bật?",
        "options": {
          "A": "Chỉ nhanh hơn và có cửa sổ ngữ cảnh lớn hơn.",
          "B": "Chỉ rẻ hơn và có hiệu suất cao hơn.",
          "C": "Nhanh hơn, có cửa sổ ngữ cảnh lớn hơn, hỗ trợ nhiều loại đầu vào hơn và thực hiện tốt hơn các tác vụ phức tạp.",
          "D": "Chỉ hỗ trợ nhiều loại đầu vào hơn và thực hiện tốt hơn các tác vụ phức tạp."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì đang tạo ra sự cạnh tranh khốc liệt trong lĩnh vực mô hình ngôn ngữ lớn?",
        "options": {
          "A": "Mong muốn cung cấp mô hình lớn nhất.",
          "B": "Mong muốn cung cấp mô hình rẻ nhất.",
          "C": "Mong muốn cung cấp mô hình hiệu quả nhất.",
          "D": "Mong muốn cung cấp mô hình hiệu quả và hiệu suất tốt nhất."
        },
        "answer": "D"
      },
      {
        "question": "Các nhà sản xuất mô hình nền tảng nào đang gặp khó khăn?",
        "options": {
          "A": "Những nhà sản xuất có mô hình lớn nhất.",
          "B": "Những nhà sản xuất có mô hình nhỏ nhất.",
          "C": "Những nhà sản xuất không thể cạnh tranh về hiệu suất với các mô hình lớn tốt nhất hoặc về chi phí với các mô hình nhỏ tốt nhất.",
          "D": "Những nhà sản xuất chỉ tập trung vào mô hình mã nguồn mở."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhận định gì về thời điểm hiện tại đối với việc phát triển ứng dụng AI?",
        "options": {
          "A": "Đây là một thời điểm khó khăn do sự cạnh tranh gay gắt.",
          "B": "Đây là một thời điểm tuyệt vời do sự đa dạng về lựa chọn mô hình.",
          "C": "Đây là một thời điểm không chắc chắn do sự biến động của giá cả.",
          "D": "Đây là một thời điểm nhàm chán do sự bão hòa của các mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Trước đây, GPT-4 có giá bao nhiêu cho mỗi triệu tokens input/output?",
        "options": {
          "A": "$10/$20",
          "B": "$20/$40",
          "C": "$30/$60",
          "D": "$40/$80"
        },
        "answer": "C"
      },
      {
        "question": "LMSys's Chatbot Arena Leaderboard được sử dụng để đo lường điều gì?",
        "options": {
          "A": "Giá của các mô hình ngôn ngữ lớn.",
          "B": "Hiệu suất của các mô hình ngôn ngữ lớn.",
          "C": "Kích thước của các mô hình ngôn ngữ lớn.",
          "D": "Số lượng người dùng của các mô hình ngôn ngữ lớn."
        },
        "answer": "B"
      }
    ]
  },
  "ai-sewer": {
    "title": "AI Goes Underground",
    "collection": "business",
    "content": "Computer vision systems are surveying sewers for signs of decay and degradation.What’s new:A system from California startupSewerAIanalyzes videos of underground pipes to prioritize those in need of repair.How it works:SewerAI’s computer vision system classifies defects like cracks, holes, displacements, tree roots, and incursions in videos taken by sewer-crawling robots and human inspectors.\n\nBehind the news:AI is doing the dirty work for a growing number of companies.\n\nWhy it matters:Failed pipes can cause flooding, spread disease, and pollute water sources. In 2019, the American Society of Civil Engineersestimatedthe cost of shoring up the U.S. wastewater infrastructure at $129 billion — at least $81 billion more than lawmakers allocated in a recentlaw. By helping human inspectors prioritize repairs, computer vision could help stretch those dollars across more miles of pipe.We’re thinking:Would we rather let a robot inspect sludge-filled pipes than do it ourselves? Sewer we would!",
    "qa": [
      {
        "question": "Công ty khởi nghiệp SewerAI có trụ sở tại đâu?",
        "options": {
          "A": "New York",
          "B": "California",
          "C": "Texas",
          "D": "Florida"
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống của SewerAI phân tích dữ liệu từ nguồn nào?",
        "options": {
          "A": "Hình ảnh vệ tinh",
          "B": "Dữ liệu cảm biến áp suất",
          "C": "Video từ robot và thanh tra viên",
          "D": "Bản đồ địa chất"
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống computer vision của SewerAI giúp ích gì cho việc kiểm tra đường ống?",
        "options": {
          "A": "Tự động sửa chữa các hư hỏng",
          "B": "Phân loại và ưu tiên các đoạn ống cần sửa chữa",
          "C": "Thay thế hoàn toàn công việc của thanh tra viên",
          "D": "Dự đoán chính xác thời điểm đường ống bị vỡ"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, hậu quả của việc đường ống bị hỏng có thể bao gồm những gì?",
        "options": {
          "A": "Ô nhiễm tiếng ồn",
          "B": "Tắc nghẽn giao thông",
          "C": "Lũ lụt, lây lan dịch bệnh và ô nhiễm nguồn nước",
          "D": "Sụt lún đất"
        },
        "answer": "C"
      },
      {
        "question": "Ước tính của American Society of Civil Engineers về chi phí nâng cấp cơ sở hạ tầng nước thải của Hoa Kỳ năm 2019 là bao nhiêu?",
        "options": {
          "A": "$48 tỷ",
          "B": "$81 tỷ",
          "C": "$129 tỷ",
          "D": "$210 tỷ"
        },
        "answer": "C"
      },
      {
        "question": "Số tiền mà các nhà lập pháp đã phân bổ cho việc nâng cấp cơ sở hạ tầng nước thải ít hơn bao nhiêu so với ước tính của American Society of Civil Engineers?",
        "options": {
          "A": "$48 tỷ",
          "B": "$81 tỷ",
          "C": "$129 tỷ",
          "D": "$210 tỷ"
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ computer vision có thể giúp ích gì trong bối cảnh nguồn vốn hạn hẹp cho việc sửa chữa đường ống?",
        "options": {
          "A": "Giảm chi phí nhân công",
          "B": "Tăng tốc độ sửa chữa",
          "C": "Giúp phân bổ nguồn vốn hiệu quả hơn",
          "D": "Tìm ra các phương pháp sửa chữa mới"
        },
        "answer": "C"
      },
      {
        "question": "Trong bài viết, những loại hư hỏng nào được hệ thống của SewerAI phân loại?",
        "options": {
          "A": "Rỉ sét, ăn mòn, nứt vỡ",
          "B": "Nứt, lỗ, dịch chuyển, rễ cây và xâm nhập",
          "C": "Tắc nghẽn, rò rỉ, áp suất thấp",
          "D": "Lún sụt, biến dạng, ô nhiễm hóa chất"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, xu hướng chung trong nhiều công ty hiện nay là gì?",
        "options": {
          "A": "Tăng cường sử dụng lao động thủ công",
          "B": "Ứng dụng trí tuệ nhân tạo vào các công việc khó khăn",
          "C": "Giảm thiểu chi phí đầu tư vào công nghệ",
          "D": "Tập trung vào các giải pháp thân thiện với môi trường"
        },
        "answer": "B"
      },
      {
        "question": "Câu hỏi tu từ cuối bài viết thể hiện điều gì?",
        "options": {
          "A": "Sự lo ngại về chi phí đầu tư cho robot",
          "B": "Sự e ngại về độ chính xác của robot",
          "C": "Sự sẵn lòng để robot thực hiện công việc nguy hiểm",
          "D": "Sự nghi ngờ về khả năng của robot"
        },
        "answer": "C"
      }
    ]
  },
  "ai-startups-in-demand": {
    "title": "AI Startups in Demand",
    "collection": "business",
    "content": "AI startups are being scooped up at an accelerating pace, many by companies outside the tech sphere.What’s new:Areportby CB Insights shows that, as of August, 2019 was on track to surpass last year’s record number of AI startup acquisitions. The annual tally has grown an average of 38 percent every year since 2010.Who’s buying:While tech giants buy more startups on average, non-tech companies account for the overwhelming majority of purchases.\n\nWhat they’re paying:Seven AI acquisitions topped a billion dollars. The most recent happened in April, when pharma giant Roche Holdings closed its $1.9 billion purchase of cancer analytics provider Flatiron Health. The report doesn’t provide annual spending totals.Why it matters:The report makes a strong case that AI’s strategic value is rising steadily throughout the economy. AI is still a tech-giant specialty, but it’s becoming essential in industries well beyond the internet and software.We’re thinking:Exciting startups attract talent, and their work leads to acquisitions that supercharge innovation with bigger budgets and wider reach, drawing still more people into the field. The latest numbers show that this virtuous cycle has staying power — enough, perhaps, to overcome the ongoing shortage of machine learning engineers.",
    "qa": [
      {
        "question": "Theo báo cáo của CB Insights, xu hướng mua lại các công ty khởi nghiệp AI đang diễn ra như thế nào?",
        "options": {
          "A": "Đang chậm lại so với năm ngoái.",
          "B": "Đang tăng tốc và dự kiến vượt kỷ lục năm ngoái.",
          "C": "Ổn định và không có nhiều thay đổi so với năm ngoái.",
          "D": "Đang giảm nhẹ do thiếu hụt kỹ sư machine learning."
        },
        "answer": "B"
      },
      {
        "question": "Kể từ năm 2010, số lượng các vụ mua lại công ty khởi nghiệp AI tăng trung bình mỗi năm là bao nhiêu?",
        "options": {
          "A": "28%",
          "B": "38%",
          "C": "48%",
          "D": "58%"
        },
        "answer": "B"
      },
      {
        "question": "Loại hình công ty nào chiếm phần lớn trong các vụ mua lại công ty khởi nghiệp AI?",
        "options": {
          "A": "Các công ty công nghệ lớn.",
          "B": "Các công ty ngoài lĩnh vực công nghệ.",
          "C": "Các quỹ đầu tư mạo hiểm.",
          "D": "Các tổ chức chính phủ."
        },
        "answer": "B"
      },
      {
        "question": "Thương vụ mua lại công ty AI nào có giá trị lớn nhất được đề cập trong bài viết?",
        "options": {
          "A": "Google mua DeepMind.",
          "B": "Apple mua Siri.",
          "C": "Roche Holdings mua Flatiron Health.",
          "D": "Microsoft mua Nuance Communications."
        },
        "answer": "C"
      },
      {
        "question": "Công ty Roche Holdings đã mua lại Flatiron Health với giá bao nhiêu?",
        "options": {
          "A": "$900 triệu.",
          "B": "$1.5 tỷ.",
          "C": "$1.9 tỷ.",
          "D": "$2.5 tỷ."
        },
        "answer": "C"
      },
      {
        "question": "Lĩnh vực hoạt động chính của Flatiron Health là gì?",
        "options": {
          "A": "Phát triển phần mềm quản lý doanh nghiệp.",
          "B": "Cung cấp dịch vụ phân tích dữ liệu ung thư.",
          "C": "Nghiên cứu và phát triển thuốc mới.",
          "D": "Sản xuất thiết bị y tế."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, giá trị chiến lược của AI đang có xu hướng như thế nào trong nền kinh tế?",
        "options": {
          "A": "Giảm dần do chi phí đầu tư cao.",
          "B": "Tăng đều đặn và lan rộng.",
          "C": "Ổn định và chỉ tập trung ở một số ngành.",
          "D": "Biến động khó lường do yếu tố chính trị."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết cho rằng AI hiện nay chủ yếu là lĩnh vực chuyên môn của ai?",
        "options": {
          "A": "Các trường đại học và viện nghiên cứu.",
          "B": "Các công ty công nghệ lớn.",
          "C": "Các chính phủ và tổ chức quốc tế.",
          "D": "Các doanh nghiệp vừa và nhỏ."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến một 'vòng tuần hoàn đạo đức' liên quan đến các công ty khởi nghiệp AI, điều gì thúc đẩy vòng tuần hoàn này?",
        "options": {
          "A": "Sự cạnh tranh khốc liệt giữa các công ty công nghệ.",
          "B": "Việc thu hút nhân tài, các thương vụ mua lại và sự đổi mới được thúc đẩy bởi ngân sách lớn hơn.",
          "C": "Sự hỗ trợ từ chính phủ và các tổ chức phi lợi nhuận.",
          "D": "Sự gia tăng số lượng các khóa học và chương trình đào tạo về AI."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết gợi ý rằng điều gì có thể giúp khắc phục tình trạng thiếu hụt kỹ sư machine learning?",
        "options": {
          "A": "Tăng cường hợp tác quốc tế trong lĩnh vực đào tạo.",
          "B": "Vòng tuần hoàn đạo đức được duy trì nhờ các thương vụ mua lại và đổi mới.",
          "C": "Giảm bớt yêu cầu về trình độ chuyên môn đối với kỹ sư.",
          "D": "Tự động hóa các công việc liên quan đến machine learning."
        },
        "answer": "B"
      }
    ]
  },
  "ai-startups-invested-billions-in-other-ai-startups-in-2021": {
    "title": "How AI Ventures Spend Their Capital",
    "collection": "business",
    "content": "AI startups are putting their cash into . . . AI startups.What’s new:Young AI companies flush with venture capital are purchasing startups to expand the range of services they can offer,The Wall Street Journalreported.Feeding frenzy:Venture-funded companies spent $8 billion on AI startups in 2021, up from $942 million in 2020 and $82 million in 2019, according to market analyst 451 Research. The number of acquisitions jumped from 48 to 72 in that period. TheJournalfocused on two chatbot deals: Gupshup’s purchase of Active.ai and Observe.AI’s acquisition of Scope.AI.\n\nBehind the news:All told, investors are spending more than ever on AI. Private investments in AI more than doubled to $93 billion in 2021 from $42 billion in 2019, according to theStanford AI Index. However, they’re also becoming choosier about where they put their money. The number of newly funded AI companies worldwide fell from 1,200 to 746 between 2018 and 2021.Why it matters:AI continues to be hot in the startup world — so hot that startups themselves want more of it. The current wave of purchases suggests that startups not only want to expand their AI holdings, they consider purchasing AI companies a strategic way to broaden their markets.We’re thinking:Ultimately, young companies have to make money by creating long-term value, but the route may not be direct. For instance, we’ve seen self-driving car startups that have little in the way of products or revenue thrive by serving other self-driving car startups. This is part of the value of venture capital: It gives companies the time and resources they need to (hopefully) create massive value.",
    "qa": [
      {
        "question": "Theo bài viết, các công ty AI mới nổi đang sử dụng vốn đầu tư mạo hiểm của mình chủ yếu vào việc gì?",
        "options": {
          "A": "Phát triển các sản phẩm AI hoàn toàn mới.",
          "B": "Mua lại các công ty khởi nghiệp AI khác.",
          "C": "Đầu tư vào nghiên cứu và phát triển AI cơ bản.",
          "D": "Mở rộng thị trường ra nước ngoài."
        },
        "answer": "B"
      },
      {
        "question": "Tổng giá trị các thương vụ mua lại các công ty khởi nghiệp AI trong năm 2021 là bao nhiêu?",
        "options": {
          "A": "942 triệu đô la.",
          "B": "82 triệu đô la.",
          "C": "8 tỷ đô la.",
          "D": "93 tỷ đô la."
        },
        "answer": "C"
      },
      {
        "question": "Số lượng các thương vụ mua lại công ty khởi nghiệp AI đã tăng từ năm 2019 đến năm 2021 như thế nào?",
        "options": {
          "A": "Giảm từ 72 xuống 48.",
          "B": "Tăng từ 48 lên 72.",
          "C": "Không thay đổi.",
          "D": "Tăng gấp đôi."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến thương vụ mua lại nào trong lĩnh vực chatbot?",
        "options": {
          "A": "Google mua lại DeepMind.",
          "B": "Microsoft mua lại OpenAI.",
          "C": "Gupshup mua lại Active.ai.",
          "D": "Amazon mua lại Alexa."
        },
        "answer": "C"
      },
      {
        "question": "Theo Stanford AI Index, tổng vốn đầu tư tư nhân vào AI đã tăng lên bao nhiêu vào năm 2021 so với năm 2019?",
        "options": {
          "A": "Tăng gấp ba.",
          "B": "Tăng gấp đôi.",
          "C": "Tăng 50%.",
          "D": "Không thay đổi."
        },
        "answer": "B"
      },
      {
        "question": "Xu hướng nào được đề cập liên quan đến số lượng các công ty AI mới được cấp vốn trên toàn thế giới?",
        "options": {
          "A": "Số lượng tăng đều đặn mỗi năm.",
          "B": "Số lượng giảm từ năm 2018 đến 2021.",
          "C": "Số lượng duy trì ổn định.",
          "D": "Số lượng tăng đột biến vào năm 2021."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao các công ty khởi nghiệp AI lại muốn mua lại các công ty AI khác, theo bài viết?",
        "options": {
          "A": "Để giảm sự cạnh tranh trên thị trường.",
          "B": "Để mở rộng thị trường một cách chiến lược.",
          "C": "Để tiếp cận nguồn nhân lực tài năng.",
          "D": "Để tăng cường khả năng nghiên cứu và phát triển."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết cho rằng giá trị của vốn đầu tư mạo hiểm nằm ở đâu?",
        "options": {
          "A": "Giúp các công ty tạo ra lợi nhuận nhanh chóng.",
          "B": "Giúp các công ty có thời gian và nguồn lực để tạo ra giá trị lớn.",
          "C": "Giúp các công ty giảm thiểu rủi ro.",
          "D": "Giúp các công ty thu hút nhân tài."
        },
        "answer": "B"
      },
      {
        "question": "Ví dụ về các công ty khởi nghiệp xe tự lái được đề cập trong bài viết minh họa điều gì?",
        "options": {
          "A": "Sự thành công nhanh chóng của các sản phẩm xe tự lái.",
          "B": "Sự khó khăn trong việc tạo ra doanh thu từ xe tự lái.",
          "C": "Việc các công ty khởi nghiệp có thể phát triển mạnh mẽ ngay cả khi chưa có sản phẩm hoặc doanh thu đáng kể.",
          "D": "Sự cạnh tranh gay gắt trong lĩnh vực xe tự lái."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì là quan trọng nhất để các công ty trẻ tạo ra giá trị lâu dài?",
        "options": {
          "A": "Tạo ra lợi nhuận nhanh chóng.",
          "B": "Xây dựng mối quan hệ đối tác chiến lược.",
          "C": "Tạo ra giá trị lâu dài.",
          "D": "Thu hút vốn đầu tư mạo hiểm."
        },
        "answer": "C"
      }
    ]
  },
  "ai-versus-the-garbage-heap": {
    "title": "AI Versus the Garbage Heap",
    "collection": "business",
    "content": "Amazon reported long-term success using machine learning to shrink its environmental footprint.What’s new: The online retailerdevelopeda system that fuses product descriptions, images, and structured data to decide how an item should be packed for shipping. It evolved over six years, ultimately helping Amazon cut packaging waste equivalent to over 2 billion shipping boxes.How it works:The system initially made packaging decisions based on text descriptions. Last year, the companyintegratedcomputer vision and tabular data analysis.\n\nWhy it matters:Amazon has shipped some 465 million pounds of plastic waste by oneestimate. More broadly, 131.2 billion consumer parcels were shipped worldwide in 2020,according topostage technology firm Pitney Bowes — a figure expected to double within the next five years. AI that cuts the waste that attends all this shipping and receiving might help ease ecommerce’s burden on the planet.We’re thinking:Multimodal AI is on theupswing, and it’s great to see this approach contributing to a more sustainable world. That said, 2 billion boxes is a drop in the 131-billion-parcel ocean. We hope Amazon — and other retailers — will continue to look for innovative ways to diminish the mountain of packaging garbage.",
    "qa": [
      {
        "question": "Amazon đã sử dụng công nghệ gì để giảm thiểu tác động môi trường từ việc đóng gói?",
        "options": {
          "A": "In 3D các loại hộp đóng gói thân thiện với môi trường.",
          "B": "Học máy (Machine Learning) để quyết định cách đóng gói sản phẩm.",
          "C": "Sử dụng vật liệu đóng gói tái chế 100%.",
          "D": "Tối ưu hóa quy trình vận chuyển để giảm lượng khí thải carbon."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống đóng gói của Amazon đã phát triển trong bao lâu trước khi đạt được hiệu quả cắt giảm đáng kể lượng rác thải đóng gói?",
        "options": {
          "A": "2 năm",
          "B": "4 năm",
          "C": "6 năm",
          "D": "8 năm"
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống của Amazon ban đầu dựa vào yếu tố nào để đưa ra quyết định đóng gói?",
        "options": {
          "A": "Hình ảnh sản phẩm.",
          "B": "Dữ liệu có cấu trúc về sản phẩm.",
          "C": "Mô tả bằng văn bản của sản phẩm.",
          "D": "Kích thước và trọng lượng của sản phẩm."
        },
        "answer": "C"
      },
      {
        "question": "Ngoài mô tả văn bản, hệ thống đóng gói của Amazon còn tích hợp thêm những yếu tố nào trong năm vừa qua?",
        "options": {
          "A": "Dữ liệu thời tiết và thông tin giao thông.",
          "B": "Thị giác máy tính và phân tích dữ liệu dạng bảng.",
          "C": "Phản hồi của khách hàng và đánh giá sản phẩm.",
          "D": "Thông tin về nhà cung cấp và chi phí vận chuyển."
        },
        "answer": "B"
      },
      {
        "question": "Ước tính Amazon đã vận chuyển bao nhiêu pound rác thải nhựa?",
        "options": {
          "A": "46.5 triệu pound",
          "B": "131.2 triệu pound",
          "C": "465 triệu pound",
          "D": "2 tỷ pound"
        },
        "answer": "C"
      },
      {
        "question": "Theo Pitney Bowes, số lượng bưu kiện tiêu dùng được vận chuyển trên toàn thế giới vào năm 2020 là bao nhiêu?",
        "options": {
          "A": "46.5 tỷ bưu kiện",
          "B": "131.2 tỷ bưu kiện",
          "C": "465 tỷ bưu kiện",
          "D": "2 tỷ bưu kiện"
        },
        "answer": "B"
      },
      {
        "question": "Pitney Bowes dự đoán số lượng bưu kiện tiêu dùng được vận chuyển trên toàn thế giới sẽ tăng gấp đôi trong khoảng thời gian bao lâu?",
        "options": {
          "A": "2 năm",
          "B": "3 năm",
          "C": "5 năm",
          "D": "10 năm"
        },
        "answer": "C"
      },
      {
        "question": "Công nghệ AI đa phương thức (Multimodal AI) được đề cập trong bài viết có tiềm năng đóng góp vào lĩnh vực nào?",
        "options": {
          "A": "Tăng tốc độ giao hàng.",
          "B": "Cải thiện trải nghiệm mua sắm trực tuyến.",
          "C": "Xây dựng một thế giới bền vững hơn.",
          "D": "Giảm chi phí vận chuyển."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, việc Amazon cắt giảm 2 tỷ hộp đóng gói được đánh giá như thế nào so với tổng số lượng bưu kiện được vận chuyển?",
        "options": {
          "A": "Một thành công lớn và đáng kể.",
          "B": "Một bước tiến quan trọng hướng tới mục tiêu bền vững.",
          "C": "Chỉ là một giọt nước trong đại dương.",
          "D": "Đã giải quyết được phần lớn vấn đề rác thải đóng gói."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết khuyến khích Amazon và các nhà bán lẻ khác nên làm gì để giảm thiểu rác thải đóng gói?",
        "options": {
          "A": "Sử dụng ít vật liệu đóng gói hơn.",
          "B": "Tìm kiếm các phương pháp sáng tạo để giảm thiểu rác thải đóng gói.",
          "C": "Tái chế tất cả các vật liệu đóng gói.",
          "D": "Chuyển sang sử dụng hoàn toàn bao bì có thể phân hủy sinh học."
        },
        "answer": "B"
      }
    ]
  },
  "alexa-adds-generative-ai-and-agents-using-claude-and-other-models": {
    "title": "Amazon’s Next-Gen Voice Assistant",
    "collection": "business",
    "content": "Amazon announced Alexa+, a major upgrade to its long-running voice assistant.\n\nWhat’s new:Alexa+, which accepts spoken commands and responds conversationally, is designed to work with a variety of vendors as an autonomous agent to make purchases, book reservations, play media, and so on. It will roll out in the U.S. over coming weeks, initially on some Echo Show devices and eventually nearly every current Echo speaker.\n\nHow it works:Alexa+updatesthe system to take advantage of generative AI including Anthropic Claude,Amazon Nova, and other large language models. Inputs are filtered through a routing system that determines the best model to respond to any given request. It’s trained to understand colloquial, conversational language. Its personality is designed to be “smart, considerate, empathetic, and inclusive” as well as humorous.\n\nBehind the news:Amazon launched Alexa in 2014, and the voice assistant now resides in over 600 million devices worldwide. However, users relied on it more to set timers, report sports scores, and play music than to purchase products, and Alexa revenue lagged. Following cutbacks in 2021, Amazon mademultibillion-dollarinvestmentsin Anthropic and set about updating the technology for the generative AI era.\n\nWhy it matters:Alexa, along with Apple’s Siri and Google Assistant, pioneered the market for voice assistants. However, as large language models (LLMs) blossomed, all three systems fell behind the times. (Google allows Android users to substitute one of its Gemini LLMs for Google Assistant, but the system still calls Google Assistant for some tasks.) Alexa+ is the first major voice-assistant update that aims to take advantage of LLMs as well as emerging agentic technology and improved voice interactions, and the rollout is taking these capabilities to a large, existing user base.\n\nWe’re thinking:Rapid improvements in thevoice stackare opening doors not only for voice assistants but for a galaxy of applications that rely on spoken input and output. Product designers will need to learn how to design smooth user voice experiences. Watching how Alexa+ manages them will provide useful guidelines.",
    "qa": [
      {
        "question": "Alexa+ là bản nâng cấp của trợ lý ảo nào?",
        "options": {
          "A": "Siri",
          "B": "Alexa",
          "C": "Google Assistant",
          "D": "Cortana"
        },
        "answer": "B"
      },
      {
        "question": "Alexa+ được thiết kế để làm gì?",
        "options": {
          "A": "Chỉ để đặt báo thức và chơi nhạc.",
          "B": "Hoạt động như một tác nhân tự động để mua hàng, đặt chỗ, phát media,...",
          "C": "Chỉ để báo cáo tỷ số thể thao.",
          "D": "Chỉ để điều khiển các thiết bị nhà thông minh."
        },
        "answer": "B"
      },
      {
        "question": "Alexa+ sử dụng công nghệ AI tạo sinh nào?",
        "options": {
          "A": "Chỉ Amazon Nova.",
          "B": "Chỉ Anthropic Claude.",
          "C": "Anthropic Claude, Amazon Nova và các mô hình ngôn ngữ lớn khác.",
          "D": "Chỉ các mô hình ngôn ngữ nhỏ."
        },
        "answer": "C"
      },
      {
        "question": "Tính cách của Alexa+ được thiết kế như thế nào?",
        "options": {
          "A": "Nghiêm túc và khô khan.",
          "B": "Thông minh, chu đáo, đồng cảm, hòa nhập và hài hước.",
          "C": "Chỉ thông minh và hài hước.",
          "D": "Chỉ chu đáo và đồng cảm."
        },
        "answer": "B"
      },
      {
        "question": "Amazon ra mắt Alexa vào năm nào?",
        "options": {
          "A": "2010",
          "B": "2012",
          "C": "2014",
          "D": "2016"
        },
        "answer": "C"
      },
      {
        "question": "Trước khi nâng cấp, người dùng Alexa chủ yếu sử dụng nó để làm gì?",
        "options": {
          "A": "Mua sắm trực tuyến.",
          "B": "Đặt chỗ nhà hàng.",
          "C": "Đặt hẹn giờ, báo tỷ số thể thao và chơi nhạc.",
          "D": "Điều khiển các thiết bị nhà thông minh."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì đã thúc đẩy Amazon đầu tư mạnh vào AI tạo sinh cho Alexa?",
        "options": {
          "A": "Doanh thu Alexa tăng trưởng quá nhanh.",
          "B": "Doanh thu Alexa bị tụt hậu.",
          "C": "Apple và Google không phát triển trợ lý ảo.",
          "D": "Không có đối thủ cạnh tranh trên thị trường."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống nào cho phép người dùng Android thay thế Google Assistant bằng Gemini LLM?",
        "options": {
          "A": "Alexa+",
          "B": "Siri",
          "C": "Android",
          "D": "Cortana"
        },
        "answer": "C"
      },
      {
        "question": "Alexa+ khác biệt so với các bản cập nhật trợ lý ảo khác như thế nào?",
        "options": {
          "A": "Không sử dụng mô hình ngôn ngữ lớn.",
          "B": "Chỉ cải thiện khả năng nhận diện giọng nói.",
          "C": "Là bản cập nhật lớn đầu tiên tận dụng LLM, công nghệ agentic và cải thiện tương tác bằng giọng nói.",
          "D": "Chỉ có sẵn trên một số ít thiết bị."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết gợi ý điều gì cho các nhà thiết kế sản phẩm liên quan đến trải nghiệm giọng nói?",
        "options": {
          "A": "Không cần quan tâm đến trải nghiệm giọng nói.",
          "B": "Nên tập trung vào thiết kế giao diện người dùng đồ họa.",
          "C": "Cần học cách thiết kế trải nghiệm giọng nói mượt mà.",
          "D": "Nên bỏ qua các ứng dụng dựa trên giọng nói."
        },
        "answer": "C"
      }
    ]
  },
  "alexa-read-my-lips": {
    "title": "Alexa, Read My Lips",
    "collection": "business",
    "content": "Amazon’s digital assistant is using its eyes as well as its ears to figure out who’s talking.What’s new:At its annual hardware showcase, Amazon introduced an Alexaskillthat melds acoustic, linguistic, and visual cues to help the system keep track of individual speakers and topics of conversation. Called natural turn-taking, the skill should be available next year.How it works:Natural turn-taking fuses analyses of data from the microphone and camera in devices like the Echo Show, Echo Look, and Echo Spot.\n\nWhy it matters:In conversation, people interrupt, talk over one another, and rarely use each other’s names. Making conversational interactions with AI more fluid could be handy in a wide variety of settings.We’re thinking:Alexa now tolerates users interrupting it. Will users eventually tolerate Alexa interrupting them?",
    "qa": [
      {
        "question": "Kỹ năng mới nào của Alexa được giới thiệu tại sự kiện phần cứng hàng năm của Amazon?",
        "options": {
          "A": "Khả năng tự động điều chỉnh âm lượng theo môi trường.",
          "B": "Kỹ năng 'natural turn-taking' giúp theo dõi người nói và chủ đề.",
          "C": "Khả năng dự đoán nhu cầu của người dùng dựa trên lịch sử sử dụng.",
          "D": "Kỹ năng tự động tạo danh sách phát nhạc theo tâm trạng."
        },
        "answer": "B"
      },
      {
        "question": "Kỹ năng 'natural turn-taking' của Alexa sử dụng những loại dữ liệu nào để hoạt động?",
        "options": {
          "A": "Dữ liệu vị trí và thông tin cá nhân của người dùng.",
          "B": "Dữ liệu âm thanh từ micro và hình ảnh từ camera.",
          "C": "Dữ liệu từ cảm biến nhiệt độ và độ ẩm trong phòng.",
          "D": "Dữ liệu từ các ứng dụng và trang web mà người dùng truy cập."
        },
        "answer": "B"
      },
      {
        "question": "Những thiết bị nào của Amazon được đề cập trong bài viết có khả năng sử dụng kỹ năng 'natural turn-taking'?",
        "options": {
          "A": "Echo Dot, Kindle, và Fire TV.",
          "B": "Echo Show, Echo Look, và Echo Spot.",
          "C": "Amazon Go, Amazon Fresh, và Amazon Prime.",
          "D": "Ring Doorbell, Blink Camera, và Eero Wifi."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc phát triển kỹ năng 'natural turn-taking' cho Alexa là gì?",
        "options": {
          "A": "Giảm chi phí sản xuất thiết bị Echo.",
          "B": "Tăng cường tính bảo mật cho thông tin cá nhân của người dùng.",
          "C": "Làm cho các tương tác hội thoại với AI trở nên tự nhiên và trôi chảy hơn.",
          "D": "Cho phép Alexa hiểu và phản hồi các ngôn ngữ khác nhau."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, một đặc điểm thường thấy trong các cuộc trò chuyện giữa người với người mà Alexa đang cố gắng mô phỏng là gì?",
        "options": {
          "A": "Sử dụng ngôn ngữ trang trọng và lịch sự.",
          "B": "Nói rõ ràng và không ngắt lời người khác.",
          "C": "Thường xuyên sử dụng tên của người đối diện.",
          "D": "Thường xuyên ngắt lời và nói chồng lên nhau."
        },
        "answer": "D"
      },
      {
        "question": "Kỹ năng 'natural turn-taking' của Alexa dự kiến sẽ được ra mắt vào thời điểm nào?",
        "options": {
          "A": "Ngay sau sự kiện phần cứng hàng năm của Amazon.",
          "B": "Vào năm tới.",
          "C": "Trong vòng sáu tháng tới.",
          "D": "Chưa có thông tin cụ thể về thời gian ra mắt."
        },
        "answer": "B"
      },
      {
        "question": "Câu hỏi được đặt ra ở cuối bài viết liên quan đến điều gì?",
        "options": {
          "A": "Liệu người dùng có sẵn sàng trả tiền cho các tính năng nâng cao của Alexa.",
          "B": "Liệu người dùng có chấp nhận việc Alexa ngắt lời họ.",
          "C": "Liệu Alexa có thể hiểu được các giọng địa phương khác nhau.",
          "D": "Liệu Alexa có thể tự học hỏi và cải thiện khả năng giao tiếp."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về khả năng hiện tại của Alexa liên quan đến việc ngắt lời?",
        "options": {
          "A": "Alexa không bao giờ ngắt lời người dùng.",
          "B": "Alexa chỉ ngắt lời người dùng trong trường hợp khẩn cấp.",
          "C": "Alexa đã có thể chấp nhận việc người dùng ngắt lời nó.",
          "D": "Alexa vẫn chưa thể xử lý việc người dùng ngắt lời."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, kỹ năng 'natural turn-taking' có thể hữu ích trong những bối cảnh nào?",
        "options": {
          "A": "Chỉ trong môi trường gia đình.",
          "B": "Chỉ trong các cuộc họp kinh doanh.",
          "C": "Trong nhiều bối cảnh khác nhau.",
          "D": "Chỉ trong các ứng dụng giáo dục."
        },
        "answer": "C"
      },
      {
        "question": "Điểm mới của trợ lý ảo Amazon Alexa được đề cập trong bài viết là gì?",
        "options": {
          "A": "Chỉ sử dụng tai để xác định người nói.",
          "B": "Sử dụng cả mắt và tai để xác định người nói.",
          "C": "Chỉ sử dụng mắt để xác định người nói.",
          "D": "Không sử dụng mắt hay tai để xác định người nói."
        },
        "answer": "B"
      }
    ]
  },
  "algorithm-as-real-estate-agent": {
    "title": "Algorithm as Real Estate Agent",
    "collection": "business",
    "content": "House sales priced by algorithms account for a small but growing portion of the real estate market.What’s new:Companies that use algorithmic pricing models to buy and sell houses, known as iBuyers, purchased around 1 percent of homes sold in the United States in 2021, roughly double the volume of such transactions in 2019,accordingto Core Logic, a real-estate data company. However, these deals may not benefit typical home buyers.How it works:Unlike traditional real estate agents who determine a property’s value by considering the selling prices of similar properties nearby, iBuyers use models that estimate prices based on a variety of factors including national real-estate listings, mortgages, reviews of local businesses, and human assessments.\n\nYes, but:iBuyers sell 20 percent of their stock to institutional investors like banks and private equity funds rather than individuals or families, according to a JanuaryanalysisbyBloomberg News. These investors, in turn, often sell the houses to landlords as rental properties.Why it matters:Automated pricing can make markets more efficient. It can also bring unintended consequences. While iBuyers pitch their services as a way to streamline the Byzantine process of selling and buying houses, they often end up funneling homes into the rental market. That can make it harder than ever for individuals and families to find an affordable home.We’re thinking:While automated commerce may increase the market’s efficiency in aggregate, we should work to make sure that systems we design don’t inadvertently shut out some buyers.",
    "qa": [
      {
        "question": "Theo bài viết, iBuyers chiếm khoảng bao nhiêu phần trăm giao dịch mua bán nhà ở tại Hoa Kỳ vào năm 2021?",
        "options": {
          "A": "Khoảng 2%",
          "B": "Khoảng 1%",
          "C": "Khoảng 5%",
          "D": "Khoảng 10%"
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính giữa cách định giá nhà của iBuyers và các đại lý bất động sản truyền thống là gì?",
        "options": {
          "A": "iBuyers chỉ sử dụng đánh giá của con người, trong khi đại lý truyền thống sử dụng thuật toán.",
          "B": "iBuyers sử dụng mô hình dựa trên nhiều yếu tố, bao gồm cả dữ liệu quốc gia, trong khi đại lý truyền thống dựa vào giá bán của các nhà tương tự gần đó.",
          "C": "iBuyers chỉ định giá nhà dựa trên diện tích, trong khi đại lý truyền thống xem xét cả vị trí.",
          "D": "iBuyers không xem xét đánh giá của con người, trong khi đại lý truyền thống thì có."
        },
        "answer": "B"
      },
      {
        "question": "Theo phân tích của Bloomberg News, iBuyers bán bao nhiêu phần trăm số nhà của họ cho các nhà đầu tư tổ chức?",
        "options": {
          "A": "10%",
          "B": "20%",
          "C": "30%",
          "D": "40%"
        },
        "answer": "B"
      },
      {
        "question": "Các nhà đầu tư tổ chức thường làm gì với những ngôi nhà mà họ mua từ iBuyers?",
        "options": {
          "A": "Bán lại cho các gia đình với giá ưu đãi.",
          "B": "Cho thuê lại.",
          "C": "Sử dụng làm văn phòng.",
          "D": "Phá dỡ để xây dựng chung cư."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến một hệ quả không mong muốn của việc sử dụng iBuyers là gì?",
        "options": {
          "A": "Làm tăng giá nhà đất trên toàn quốc.",
          "B": "Làm cho việc tìm kiếm nhà ở giá cả phải chăng trở nên khó khăn hơn.",
          "C": "Làm giảm chất lượng nhà ở.",
          "D": "Làm tăng số lượng nhà bỏ hoang."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của iBuyers khi quảng bá dịch vụ của họ là gì?",
        "options": {
          "A": "Giúp người mua nhà dễ dàng tìm được nhà ưng ý.",
          "B": "Đơn giản hóa quy trình mua bán nhà phức tạp.",
          "C": "Giảm chi phí giao dịch bất động sản.",
          "D": "Tăng tính minh bạch của thị trường bất động sản."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì có thể xảy ra khi thị trường trở nên hiệu quả hơn nhờ tự động hóa?",
        "options": {
          "A": "Giá nhà sẽ giảm đáng kể.",
          "B": "Một số người mua có thể bị loại khỏi thị trường.",
          "C": "Chất lượng nhà ở sẽ được cải thiện.",
          "D": "Thị trường bất động sản sẽ trở nên ổn định hơn."
        },
        "answer": "B"
      },
      {
        "question": "Công ty CoreLogic được nhắc đến trong bài viết với vai trò gì?",
        "options": {
          "A": "Một công ty iBuyer hàng đầu.",
          "B": "Một công ty dữ liệu bất động sản.",
          "C": "Một ngân hàng đầu tư lớn.",
          "D": "Một tổ chức phi lợi nhuận về nhà ở."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh tầm quan trọng của việc gì khi thiết kế các hệ thống thương mại tự động?",
        "options": {
          "A": "Đảm bảo lợi nhuận tối đa cho các nhà đầu tư.",
          "B": "Đảm bảo không vô tình loại bỏ một số người mua.",
          "C": "Tăng tốc độ giao dịch.",
          "D": "Giảm thiểu rủi ro cho người bán."
        },
        "answer": "B"
      },
      {
        "question": "So với năm 2019, số lượng giao dịch mua bán nhà do iBuyers thực hiện vào năm 2021 đã thay đổi như thế nào?",
        "options": {
          "A": "Giảm đi một nửa.",
          "B": "Tăng gấp đôi.",
          "C": "Không thay đổi.",
          "D": "Tăng gấp ba."
        },
        "answer": "B"
      }
    ]
  },
  "algorithms-choose-the-news": {
    "title": "Algorithms Choose the News",
    "collection": "business",
    "content": "Machines took another step toward doing the work of journalists.What’s new:Microsoft laid off dozens ofhuman editorswho select articles for the MSN news service and app. Going forward, AI will do the job.How it works:The tech giant declined to share details withThe Batch, but recent papers published by its researchers describe methods for curating news feeds.\n\nBehind the news:Other efforts to automate news curation have found ways for both machines and humans to add value.\n\nWhy it matters:In the internet era, information arrives in floods. AI could narrow that to an essential, manageable stream, but that’s a tall order when people depend on a broad range of accurate, timely news to help guide their course as individuals, communities, and societies.The Batch’s editors are thinking:Yikes!",
    "qa": [
      {
        "question": "Microsoft đã thực hiện thay đổi gì đối với đội ngũ biên tập viên của MSN?",
        "options": {
          "A": "Tăng cường đào tạo cho biên tập viên hiện tại.",
          "B": "Sa thải hàng chục biên tập viên và thay thế bằng AI.",
          "C": "Thuê thêm biên tập viên để cải thiện chất lượng tin tức.",
          "D": "Chuyển đổi biên tập viên sang các vị trí khác trong công ty."
        },
        "answer": "B"
      },
      {
        "question": "Công việc chính của các biên tập viên bị thay thế bởi AI là gì?",
        "options": {
          "A": "Viết các bài báo gốc.",
          "B": "Chọn lọc các bài báo cho dịch vụ tin tức MSN.",
          "C": "Kiểm tra tính chính xác của thông tin.",
          "D": "Thiết kế giao diện người dùng cho ứng dụng tin tức."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến điều gì về việc tự động hóa việc tuyển chọn tin tức?",
        "options": {
          "A": "Việc tự động hóa luôn hiệu quả hơn so với con người.",
          "B": "Cả máy móc và con người đều có thể đóng góp giá trị vào quá trình này.",
          "C": "Việc tự động hóa không thể thay thế hoàn toàn vai trò của con người.",
          "D": "Việc tự động hóa chỉ phù hợp với các tin tức có tính chất giải trí."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, thách thức lớn nhất của AI trong việc tuyển chọn tin tức là gì?",
        "options": {
          "A": "Khả năng viết các bài báo hấp dẫn.",
          "B": "Khả năng xử lý lượng thông tin khổng lồ và cung cấp tin tức chính xác, kịp thời.",
          "C": "Khả năng kiếm tiền từ quảng cáo.",
          "D": "Khả năng dịch tin tức sang nhiều ngôn ngữ khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết sử dụng từ 'Yikes!' để thể hiện điều gì?",
        "options": {
          "A": "Sự phấn khích trước tiềm năng của AI.",
          "B": "Sự lo lắng về những tác động của việc thay thế con người bằng AI.",
          "C": "Sự ngạc nhiên về tốc độ phát triển của công nghệ.",
          "D": "Sự đồng tình với quyết định của Microsoft."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc sử dụng AI trong việc tuyển chọn tin tức là gì?",
        "options": {
          "A": "Tăng số lượng tin tức được đăng tải.",
          "B": "Giảm chi phí hoạt động.",
          "C": "Thu hẹp dòng thông tin đến mức cần thiết và dễ quản lý.",
          "D": "Tạo ra các tin tức giả mạo."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhấn mạnh tầm quan trọng của điều gì trong việc cung cấp tin tức?",
        "options": {
          "A": "Tính giải trí.",
          "B": "Tính chính xác, kịp thời và phạm vi bao quát.",
          "C": "Tính cá nhân hóa.",
          "D": "Tính lan truyền trên mạng xã hội."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, ai là người đưa ra quyết định thay thế biên tập viên bằng AI tại MSN?",
        "options": {
          "A": "Các biên tập viên của The Batch.",
          "B": "Các nhà nghiên cứu AI.",
          "C": "Microsoft.",
          "D": "Chính phủ."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến việc Microsoft đã làm gì với thông tin chi tiết về phương pháp tuyển chọn tin tức bằng AI?",
        "options": {
          "A": "Chia sẻ công khai với cộng đồng.",
          "B": "Từ chối chia sẻ chi tiết với The Batch.",
          "C": "Cung cấp thông tin chi tiết cho các đối thủ cạnh tranh.",
          "D": "Xuất bản một cuốn sách về chủ đề này."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết ngụ ý rằng việc cung cấp tin tức chính xác và kịp thời có vai trò gì đối với xã hội?",
        "options": {
          "A": "Giúp mọi người giải trí.",
          "B": "Giúp mọi người đưa ra quyết định đúng đắn với tư cách cá nhân, cộng đồng và xã hội.",
          "C": "Giúp các công ty kiếm được nhiều tiền hơn.",
          "D": "Giúp chính phủ kiểm soát thông tin."
        },
        "answer": "B"
      }
    ]
  },
  "all-about-artifact-the-new-app-from-instagram-founders": {
    "title": "All the News That’s Fit to Learn",
    "collection": "business",
    "content": "What does an entrepreneur do after co-founding one of the world’s top social networks? Apply the lessons learned to distributing hard news.\n\nWhat’s new:Kevin Systerom and Mike Krieger, who co-founded Instagram, launchedArtifact, an app that uses reinforcement learning to recommend news articles according to users’ shifting interests.\n\nHow it works:The founders were inspired to launch a news app after witnessing TikTok’s success at designing a recommendation algorithm that learned from users’ habits, SystromtoldThe Verge. The app starts by classifying each user as a persona that has a standardized constellation of interests, the foundersexplainedto the tech analysis siteStratechery. Then a transformer-based model selects news articles; its choices are continually fine-tuned via reinforcement learning,TechCrunchreported.\n\nBehind the news:Artifact joins a crowded field of personalized news feeds from Google, Apple, Japan-basedSmartNewsand China-basedToutiao(owned by TikTok’s parent ByteDance).NewsBreakof California focuses on local news.\n\nYes, but:Delivering news is a tough business. Never mind theprecipitousdeclineof traditional newspapers. SmartNewsannouncedit was laying off 40 percent of its staff.Why it matters:Social media sites like Facebook grew partly on their promises to deliver timely news according to individual users’ interests, but they struggle to deliver high-quality news. A 2019 Pew Research Center pollfoundthat 55 percent of U.S. adults thought social media companies’ role in curating consumption resulted in a worse mix of news. Artifact aims to apply machine learning techniques developed to help people stay in touch with friends to keep them informed in a rapidly changing world.We’re thinking:Social media networks have used recommendation algorithms to maximize engagement, enabling clickbait and other low-quality information to flourish. Artifact’s choice of what to maximize, be it user engagement (which, in ad-driven social networks, correlates with revenue), metrics that track consumption of high-quality news, or something else, will have a huge impact on its future.",
    "qa": [
      {
        "question": "Kevin Systrom và Mike Krieger, những người đồng sáng lập Instagram, đã ra mắt ứng dụng mới có tên là gì?",
        "options": {
          "A": "NewsBreak",
          "B": "Artifact",
          "C": "SmartNews",
          "D": "Toutiao"
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng Artifact sử dụng công nghệ nào để đề xuất các bài báo cho người dùng?",
        "options": {
          "A": "Học máy có giám sát",
          "B": "Học tăng cường (Reinforcement Learning)",
          "C": "Xử lý ngôn ngữ tự nhiên (NLP)",
          "D": "Thị giác máy tính (Computer Vision)"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì đã truyền cảm hứng cho những người sáng lập Artifact để ra mắt ứng dụng tin tức?",
        "options": {
          "A": "Sự suy giảm của báo in truyền thống",
          "B": "Sự thành công của TikTok trong việc thiết kế thuật toán đề xuất",
          "C": "Kết quả khảo sát của Pew Research Center về tin tức trên mạng xã hội",
          "D": "Sự phát triển của các ứng dụng tin tức địa phương như NewsBreak"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình mà Artifact sử dụng để chọn các bài báo được mô tả là gì?",
        "options": {
          "A": "Mô hình dựa trên mạng nơ-ron tích chập (CNN)",
          "B": "Mô hình dựa trên máy vector hỗ trợ (SVM)",
          "C": "Mô hình dựa trên biến đổi (Transformer-based model)",
          "D": "Mô hình dựa trên cây quyết định (Decision Tree)"
        },
        "answer": "C"
      },
      {
        "question": "Ứng dụng tin tức nào trong số các ứng dụng được đề cập trong bài viết tập trung vào tin tức địa phương?",
        "options": {
          "A": "SmartNews",
          "B": "Toutiao",
          "C": "NewsBreak",
          "D": "Artifact"
        },
        "answer": "C"
      },
      {
        "question": "Công ty tin tức nào đã thông báo sa thải 40% nhân viên của mình?",
        "options": {
          "A": "NewsBreak",
          "B": "Toutiao",
          "C": "SmartNews",
          "D": "Artifact"
        },
        "answer": "C"
      },
      {
        "question": "Theo khảo sát của Pew Research Center năm 2019, bao nhiêu phần trăm người trưởng thành ở Hoa Kỳ cho rằng vai trò của các công ty truyền thông xã hội trong việc quản lý nội dung dẫn đến một sự pha trộn tin tức tồi tệ hơn?",
        "options": {
          "A": "40%",
          "B": "45%",
          "C": "50%",
          "D": "55%"
        },
        "answer": "D"
      },
      {
        "question": "Mục tiêu chính của các thuật toán đề xuất trên các mạng xã hội truyền thống thường là gì?",
        "options": {
          "A": "Cung cấp tin tức chất lượng cao",
          "B": "Tối đa hóa sự tương tác của người dùng",
          "C": "Đảm bảo tính chính xác của thông tin",
          "D": "Phân phối tin tức một cách công bằng"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết gợi ý rằng sự thành công của Artifact sẽ phụ thuộc vào điều gì?",
        "options": {
          "A": "Số lượng người dùng tải xuống ứng dụng",
          "B": "Việc lựa chọn những gì để tối đa hóa (ví dụ: tương tác, tin tức chất lượng cao)",
          "C": "Khả năng cạnh tranh với các ứng dụng tin tức khác",
          "D": "Sự hỗ trợ từ các nhà đầu tư"
        },
        "answer": "B"
      },
      {
        "question": "Artifact phân loại người dùng ban đầu như thế nào?",
        "options": {
          "A": "Dựa trên độ tuổi và giới tính",
          "B": "Dựa trên vị trí địa lý",
          "C": "Dựa trên một 'persona' có các sở thích tiêu chuẩn",
          "D": "Dựa trên lịch sử tìm kiếm trên Google"
        },
        "answer": "C"
      }
    ]
  },
  "all-about-the-leadership-shakeup-at-openai": {
    "title": "The CEO Is O̶u̶t̶ In",
    "collection": "business",
    "content": "OpenAI abruptly fired and rehired its CEO Sam Altman, capping five days of chaos within the company.\n\nWhat’s new:On Friday, the OpenAI board of directors — whose membership since has changed —oustedCEO and co-founder Sam Altman from his leadership position and his seat on the board. The board named chief technology officer Mira Murati interim CEO, soon replaced by Twitch co-founder Emmett Shear. Late Tuesday, Altman wasreinstatedand the board reorganized.\n\nWhat happened:The dizzying events leave OpenAI with familiar leadership and a retooled board of directors. The new board, which is expected to expand, is chaired by Salesforce co-CEO Bret Taylor and includes economist Larry Summers and Quora CEO Adam D’Angelo (the sole holdover from the previous lineup). Leaving the board are Altman, co-founder and chief scientist Ilya Sutskever, entrepreneur Tasha McCauley, and AI safety researcher Helen Toner as well as president, co-founder, and former board chair Greg Brockman (who lost his seat in the turmoil, resigned, and returned with Altman).\n\nRevolving door:OpenAI went through three CEOs within nearly as many days. Here’s who has passed through the revolving door.\n\nWhy it matters:At a moment when AI is undergoing rapid development and deepening division over the role of regulation, the chaos at OpenAI highlights the importance of strong corporate governance and an experienced board of directors that has a range of relevant experience and strong alignment with the company’s mission. It’s highly unusual for directors to fire a chief executive without arranging an orderly succession, coordinating with key investors, and preparing the market for changes. Chaos at the company opened competitive opportunities for rivals and threatened to destabilize thousands of companies that depend on OpenAI services. Although Altman’s return presumably restores the company’s stability, it will bear lingering questions and greater scrutiny going forward.\n\nWe’re thinking:There’s nothing normal about goings on at OpenAI. Nonetheless, as startup guru Eric Riessaid, cofounder breakups and sometimes even boardroom coups are part of startup life. They’re unnerving, especially for people who depend on the companies involved (and vice-versa). We wish OpenAI’s employees, who have done a tremendous job of advancing AI and serving hundreds of millions of customers, renewed enthusiasm and focus as they resume their important work.",
    "qa": [
      {
        "question": "Ai là CEO tạm quyền đầu tiên được bổ nhiệm sau khi Sam Altman bị sa thải?",
        "options": {
          "A": "Emmett Shear",
          "B": "Mira Murati",
          "C": "Greg Brockman",
          "D": "Ilya Sutskever"
        },
        "answer": "B"
      },
      {
        "question": "Ai là người giữ lại vị trí của mình trong hội đồng quản trị OpenAI sau sự thay đổi?",
        "options": {
          "A": "Bret Taylor",
          "B": "Larry Summers",
          "C": "Adam D'Angelo",
          "D": "Ilya Sutskever"
        },
        "answer": "C"
      },
      {
        "question": "Ai là người được bổ nhiệm làm chủ tịch hội đồng quản trị mới của OpenAI?",
        "options": {
          "A": "Sam Altman",
          "B": "Larry Summers",
          "C": "Bret Taylor",
          "D": "Adam D'Angelo"
        },
        "answer": "C"
      },
      {
        "question": "Ngoài Sam Altman, ai là người đồng sáng lập OpenAI đã rời khỏi hội đồng quản trị trong sự kiện này?",
        "options": {
          "A": "Bret Taylor",
          "B": "Greg Brockman",
          "C": "Adam D'Angelo",
          "D": "Emmett Shear"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì được nhấn mạnh là quan trọng trong bối cảnh phát triển nhanh chóng của AI?",
        "options": {
          "A": "Tốc độ phát triển công nghệ",
          "B": "Sự cạnh tranh giữa các công ty AI",
          "C": "Quản trị doanh nghiệp mạnh mẽ và hội đồng quản trị giàu kinh nghiệm",
          "D": "Sự ủng hộ của các nhà đầu tư lớn"
        },
        "answer": "C"
      },
      {
        "question": "Ai là CEO tạm quyền thứ hai được bổ nhiệm sau Mira Murati?",
        "options": {
          "A": "Sam Altman",
          "B": "Greg Brockman",
          "C": "Ilya Sutskever",
          "D": "Emmett Shear"
        },
        "answer": "D"
      },
      {
        "question": "Theo bài viết, điều gì có thể bị đe dọa bởi sự hỗn loạn tại OpenAI?",
        "options": {
          "A": "Sự phát triển của công nghệ AI nói chung",
          "B": "Sự ổn định của hàng ngàn công ty phụ thuộc vào dịch vụ của OpenAI",
          "C": "Giá trị cổ phiếu của các công ty công nghệ",
          "D": "Mối quan hệ giữa OpenAI và các nhà đầu tư"
        },
        "answer": "B"
      },
      {
        "question": "Theo Eric Ries, sự kiện tại OpenAI được so sánh với điều gì thường xảy ra trong giới khởi nghiệp?",
        "options": {
          "A": "Sự sụp đổ của một công ty",
          "B": "Sự ra mắt sản phẩm thất bại",
          "C": "Sự chia rẽ giữa những người đồng sáng lập và các cuộc đảo chính trong phòng họp",
          "D": "Sự thay đổi chiến lược kinh doanh"
        },
        "answer": "C"
      },
      {
        "question": "Ai là người giữ chức vụ giám đốc khoa học (chief scientist) của OpenAI và đã rời khỏi hội đồng quản trị?",
        "options": {
          "A": "Bret Taylor",
          "B": "Larry Summers",
          "C": "Adam D'Angelo",
          "D": "Ilya Sutskever"
        },
        "answer": "D"
      },
      {
        "question": "Điều gì được kỳ vọng sẽ xảy ra sau khi Sam Altman trở lại vị trí CEO của OpenAI?",
        "options": {
          "A": "Sự thay đổi hoàn toàn trong chiến lược phát triển AI",
          "B": "Sự ổn định của công ty được khôi phục, nhưng sẽ phải đối mặt với những câu hỏi và sự giám sát chặt chẽ hơn",
          "C": "Sự ra đi của nhiều nhân viên chủ chốt",
          "D": "Sự hợp tác chặt chẽ hơn với các đối thủ cạnh tranh"
        },
        "answer": "B"
      }
    ]
  },
  "all-about-the-multi-billion-dollar-deal-between-amazon-and-anthropic": {
    "title": "Amazon and Anthropic Form Alliance",
    "collection": "business",
    "content": "Amazon cut a multi billion-dollar deal with AI startup Anthropic, giving it a powerful ally in the generative arms race.\n\nWhat’s new:Amazoncommittedto invest as much as $4 billion in Anthropic. In return, Amazon Web Services (AWS) became the primary provider of Anthropic’s Claude and other models.\n\nHow it works:Amazon willinvest$1.25 billion in Anthropic immediately. Amazon may invest an additional $2.75 billion depending on undisclosed conditions. Amazon gained an undisclosed minority stake in the startup but not a seat on the board of directors. Other terms were not disclosed.\n\nBehind the news:Founded in 2021 by ex-OpenAI employees, Anthropic is an independent research lab thatfocuseson building safe, beneficial AI models. Having received hundreds of millions of dollars fromGoogleand other investors, it became one of the industry’s most highly funded startups. It wasvaluedat $4.1 billion in March.\n\nWhy it matters:Competition around generative AI is white-hot. Cloud providers need to offer cutting-edge models, while AI startups need access to processing power. Microsoft Azure paired up with OpenAI. Google has strong internal generative capabilities. That leaves Amazon as a natural partner for Anthropic.\n\nWe’re thinking:Which other high-profile AI startups would make dance partners for enterprising cloud providers? Topping the list are AI21 Labs (already working with Amazon Bedrock), Cohere (also available on Bedrock), and Inflection (funded by Microsoft).",
    "qa": [
      {
        "question": "Amazon đã đầu tư bao nhiêu tiền vào startup AI Anthropic?",
        "options": {
          "A": "1.25 tỷ đô la",
          "B": "Tối đa 4 tỷ đô la",
          "C": "2.75 tỷ đô la",
          "D": "4.1 tỷ đô la"
        },
        "answer": "B"
      },
      {
        "question": "Amazon Web Services (AWS) sẽ đóng vai trò gì trong thỏa thuận với Anthropic?",
        "options": {
          "A": "Nhà đầu tư chính của Anthropic",
          "B": "Nhà cung cấp dịch vụ đám mây chính cho các mô hình của Anthropic",
          "C": "Thành viên hội đồng quản trị của Anthropic",
          "D": "Đơn vị phát triển mô hình AI cho Anthropic"
        },
        "answer": "B"
      },
      {
        "question": "Anthropic được thành lập bởi những ai?",
        "options": {
          "A": "Các nhà nghiên cứu từ Google",
          "B": "Các cựu nhân viên của OpenAI",
          "C": "Các kỹ sư từ Microsoft",
          "D": "Các chuyên gia từ Amazon"
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của Anthropic là gì?",
        "options": {
          "A": "Phát triển các mô hình AI mạnh mẽ nhất",
          "B": "Xây dựng các mô hình AI an toàn và có lợi",
          "C": "Cạnh tranh với OpenAI và Google",
          "D": "Thu hút đầu tư từ các công ty công nghệ lớn"
        },
        "answer": "B"
      },
      {
        "question": "Giá trị của Anthropic được định giá là bao nhiêu vào tháng 3?",
        "options": {
          "A": "1.25 tỷ đô la",
          "B": "2.75 tỷ đô la",
          "C": "4 tỷ đô la",
          "D": "4.1 tỷ đô la"
        },
        "answer": "D"
      },
      {
        "question": "Thỏa thuận giữa Amazon và Anthropic có ý nghĩa gì trong bối cảnh cạnh tranh AI?",
        "options": {
          "A": "Amazon sẽ vượt mặt Microsoft và Google trong lĩnh vực AI",
          "B": "Amazon có được một đối tác mạnh mẽ trong cuộc đua AI tạo sinh",
          "C": "Anthropic sẽ trở thành công ty con của Amazon",
          "D": "AWS sẽ độc quyền cung cấp các mô hình AI tạo sinh"
        },
        "answer": "B"
      },
      {
        "question": "Microsoft Azure đã hợp tác với công ty AI nào?",
        "options": {
          "A": "Anthropic",
          "B": "AI21 Labs",
          "C": "OpenAI",
          "D": "Cohere"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, công ty AI nào đã làm việc với Amazon Bedrock?",
        "options": {
          "A": "OpenAI",
          "B": "Anthropic",
          "C": "AI21 Labs",
          "D": "Inflection"
        },
        "answer": "C"
      },
      {
        "question": "Amazon có được quyền gì trong Anthropic sau khi đầu tư?",
        "options": {
          "A": "Quyền kiểm soát đa số cổ phần",
          "B": "Một ghế trong hội đồng quản trị",
          "C": "Một cổ phần thiểu số không được tiết lộ",
          "D": "Quyền quyết định chiến lược phát triển của Anthropic"
        },
        "answer": "C"
      },
      {
        "question": "Ngoài Anthropic, bài viết đề xuất những startup AI tiềm năng nào khác có thể hợp tác với các nhà cung cấp dịch vụ đám mây?",
        "options": {
          "A": "Google AI và DeepMind",
          "B": "AI21 Labs, Cohere và Inflection",
          "C": "Microsoft Research và OpenAI",
          "D": "Amazon AI và AWS AI Labs"
        },
        "answer": "B"
      }
    ]
  },
  "amazon-add-majority-of-adept-ai-staff-to-boost-agentic-ai-capabilities": {
    "title": "Amazon Onboards Adept",
    "collection": "business",
    "content": "Amazon hired most of the staff of agentic-AI specialist Adept AI in a move that echoes Microsoft’s absorption of Inflection in March.\n\nWhat’s new:Amazon onboarded most of the leadership and staff of Adept AI, which has been training models to operate software applications running on local hardware,GeekWirereported. Amazon licensed Adept’s models, datasets, and other technology non-exclusively. The companies did not disclose the financial terms of the deal. (Disclosure: Andrew Ng serves on Amazon’s board of directors.)\n\nHow it works:Amazon hired two thirds of Adept’s former employees. Those who remain will “focus entirely on solutions that enable agentic AI” based on proprietary models, custom infrastructure, and other technology.\n\nBehind the news:Amazon’s agreement with Adept is one of several moves to compete in AI for both businesses and consumers. In March, the company completed a $4 billioninvestmentin Anthropic in exchange for a minority share in the startup. It’s reportedly developing new models andoverhaulingits longstanding Alexa voice assistant.\n\nWhy it matters:Luan and his team say they’re aiming to automate corporate software workflows, a potentially valuable and lucrative market. Although Amazon Web Services’ Bedrock platform already enables users tobuildAI agents, Adept’s talent may bring expanded agentic and interactive capabilities.We’re thinking:AI agentic capabilities areblossoming, and Adept’s work is a notable example.",
    "qa": [
      {
        "question": "Amazon đã thực hiện hành động gì với phần lớn nhân viên của Adept AI?",
        "options": {
          "A": "Mua lại hoàn toàn công ty Adept AI.",
          "B": "Tuyển dụng phần lớn nhân viên của Adept AI.",
          "C": "Hợp tác phát triển công nghệ với Adept AI.",
          "D": "Đầu tư vào Adept AI để phát triển các mô hình AI."
        },
        "answer": "B"
      },
      {
        "question": "Adept AI chuyên về lĩnh vực nào trước khi Amazon tuyển dụng nhân viên?",
        "options": {
          "A": "Phát triển phần cứng cho các ứng dụng AI.",
          "B": "Đào tạo các mô hình AI để vận hành các ứng dụng phần mềm.",
          "C": "Cung cấp dịch vụ tư vấn về chiến lược AI cho doanh nghiệp.",
          "D": "Nghiên cứu các thuật toán AI mới nhất."
        },
        "answer": "B"
      },
      {
        "question": "Amazon đã được cấp phép sử dụng những gì từ Adept AI?",
        "options": {
          "A": "Toàn bộ công nghệ, bao gồm cả quyền sở hữu độc quyền.",
          "B": "Các mô hình, bộ dữ liệu và công nghệ khác, nhưng không độc quyền.",
          "C": "Chỉ các mô hình AI đã được đào tạo.",
          "D": "Chỉ bộ dữ liệu được sử dụng để đào tạo mô hình AI."
        },
        "answer": "B"
      },
      {
        "question": "Sau khi phần lớn nhân viên chuyển sang Amazon, những nhân viên còn lại của Adept AI sẽ tập trung vào điều gì?",
        "options": {
          "A": "Phát triển các ứng dụng phần mềm mới.",
          "B": "Các giải pháp cho phép AI hoạt động như một tác nhân (agentic AI).",
          "C": "Nghiên cứu các phương pháp đào tạo mô hình AI hiệu quả hơn.",
          "D": "Cung cấp dịch vụ hỗ trợ kỹ thuật cho khách hàng."
        },
        "answer": "B"
      },
      {
        "question": "Thương vụ với Anthropic của Amazon có giá trị bao nhiêu?",
        "options": {
          "A": "2 tỷ đô la.",
          "B": "4 tỷ đô la.",
          "C": "6 tỷ đô la.",
          "D": "8 tỷ đô la."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu của Luan và nhóm của anh ấy là gì?",
        "options": {
          "A": "Phát triển các ứng dụng AI cho người tiêu dùng.",
          "B": "Tự động hóa quy trình làm việc của phần mềm doanh nghiệp.",
          "C": "Cạnh tranh với các nền tảng AI khác trên thị trường.",
          "D": "Nâng cao hiệu quả hoạt động của Amazon Web Services."
        },
        "answer": "B"
      },
      {
        "question": "Nền tảng nào của Amazon Web Services đã cho phép người dùng xây dựng các tác nhân AI?",
        "options": {
          "A": "SageMaker.",
          "B": "EC2.",
          "C": "Bedrock.",
          "D": "Lambda."
        },
        "answer": "C"
      },
      {
        "question": "Việc tuyển dụng nhân tài từ Adept AI có thể mang lại những khả năng gì cho Amazon?",
        "options": {
          "A": "Khả năng phát triển phần cứng AI tiên tiến hơn.",
          "B": "Khả năng mở rộng tác nhân và tương tác AI.",
          "C": "Khả năng giảm chi phí phát triển AI.",
          "D": "Khả năng tiếp cận thị trường AI quốc tế."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lĩnh vực nào đang phát triển mạnh mẽ?",
        "options": {
          "A": "Phần cứng AI.",
          "B": "Khả năng AI hoạt động như một tác nhân (agentic AI).",
          "C": "Các mô hình AI tạo sinh.",
          "D": "Các ứng dụng AI cho thiết bị di động."
        },
        "answer": "B"
      },
      {
        "question": "Thương vụ giữa Amazon và Adept AI được so sánh với thương vụ nào trước đó?",
        "options": {
          "A": "Google mua lại DeepMind.",
          "B": "Microsoft mua lại Inflection.",
          "C": "Apple mua lại Siri.",
          "D": "Meta mua lại Instagram."
        },
        "answer": "B"
      }
    ]
  },
  "amazon-deepens-anthropic-partnership-with-4-billion-investment": {
    "title": "AI Power Couple Recommits",
    "collection": "business",
    "content": "Amazon and Anthropic expanded their partnership, potentially strengthening Amazon Web Services’ AI infrastructure and lengthening the high-flying startup’s runway.\n\nWhat’s new:Amazon, already a significant investor in Anthropic,putanother $4 billion into the AI company. In exchange, Anthropic will train and run its AI models on Amazon’s custom-designed chips. (Disclosure: Andrew Ng serves on Amazon’s board of directors.)\n\nHow it works:The new round brings Amazon’s investment in Anthropic to $8 billion (though it remains a minority stake without a seat on the startup’s board). The deal extended the partnership in several ways:\n\nBehind the news:In November, Anthropicagreedto use Google’s cloud-computing infrastructure in return for a $2 billion investment. The previous month, Amazon hadcommittedto invest as much as $4 billion in Anthropic, and Anthropic had made Amazon Web Services the primary provider of its models.\n\nYes, but:The UK’s Competition and Markets Authority recentlyclearedboth Amazon’s and Google’s investments in Anthropic, but regulators continue to monitor such arrangements for violations of antitrust laws. Microsoft and OpenAI face a similarinvestigationby the European Commission and U.S. Federal Trade Commission.\n\nWhy it matters:The speed and skill required to build state-of-the-art AI models is driving tech giants to collaborate with startups, while the high cost is driving startups to partner with tech giants. If the partnership between Amazon and Anthropic lives up to its promise, Claude users and developers could see gains in performance and efficiency. This could validate Amazon's hardware as a competitor with Nvidia and strengthen Amazon Web Services’ position in the cloud market. On the other hand, if Claude faces any challenges in scaling while using Trainium and Inferentia, that could affect both companies' ambitions.\n\nWe’re thinking:Does the agreement between Amazon and Anthropic give the tech giant special access to the startup’s models for distillation, research, or integration, as thepartnershipbetween Microsoft and OpenAI does? The companies’ announcements don’t say.",
    "qa": [
      {
        "question": "Amazon đã đầu tư thêm bao nhiêu tiền vào Anthropic trong vòng đầu tư mới nhất?",
        "options": {
          "A": "2 tỷ đô la",
          "B": "4 tỷ đô la",
          "C": "6 tỷ đô la",
          "D": "8 tỷ đô la"
        },
        "answer": "B"
      },
      {
        "question": "Anthropic sẽ sử dụng chip do Amazon thiết kế để làm gì?",
        "options": {
          "A": "Lưu trữ dữ liệu người dùng",
          "B": "Đào tạo và vận hành các mô hình AI",
          "C": "Phát triển các ứng dụng web",
          "D": "Cải thiện hệ thống bảo mật"
        },
        "answer": "B"
      },
      {
        "question": "Tổng số tiền Amazon đã đầu tư vào Anthropic đến nay là bao nhiêu?",
        "options": {
          "A": "2 tỷ đô la",
          "B": "4 tỷ đô la",
          "C": "6 tỷ đô la",
          "D": "8 tỷ đô la"
        },
        "answer": "D"
      },
      {
        "question": "Ngoài Amazon, công ty nào khác cũng đã đầu tư vào Anthropic?",
        "options": {
          "A": "Microsoft",
          "B": "Nvidia",
          "C": "Google",
          "D": "OpenAI"
        },
        "answer": "C"
      },
      {
        "question": "Cơ quan nào ở Anh đã xem xét và thông qua các khoản đầu tư của Amazon và Google vào Anthropic?",
        "options": {
          "A": "Cơ quan Tiêu chuẩn Quảng cáo (ASA)",
          "B": "Cơ quan Quản lý Truyền thông (Ofcom)",
          "C": "Cơ quan Cạnh tranh và Thị trường (CMA)",
          "D": "Ngân hàng Trung ương Anh (BoE)"
        },
        "answer": "C"
      },
      {
        "question": "Ủy ban Châu Âu và Ủy ban Thương mại Liên bang Hoa Kỳ đang điều tra mối quan hệ hợp tác nào?",
        "options": {
          "A": "Amazon và Anthropic",
          "B": "Google và Anthropic",
          "C": "Microsoft và OpenAI",
          "D": "Nvidia và Google"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì có thể xảy ra nếu quan hệ đối tác giữa Amazon và Anthropic thành công?",
        "options": {
          "A": "Giá cổ phiếu của Amazon sẽ giảm mạnh.",
          "B": "Người dùng và nhà phát triển Claude có thể thấy sự cải thiện về hiệu suất và hiệu quả.",
          "C": "Nvidia sẽ trở thành nhà cung cấp chip độc quyền cho Amazon.",
          "D": "Amazon Web Services sẽ mất vị thế trên thị trường điện toán đám mây."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì có thể ảnh hưởng đến tham vọng của cả Amazon và Anthropic nếu Claude gặp khó khăn trong việc mở rộng quy mô khi sử dụng Trainium và Inferentia?",
        "options": {
          "A": "Giá trị thị trường của Anthropic sẽ tăng đột biến.",
          "B": "Amazon sẽ ngừng đầu tư vào lĩnh vực AI.",
          "C": "Cả hai công ty có thể phải xem xét lại chiến lược phát triển AI của mình.",
          "D": "Google sẽ mua lại Anthropic."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc các công ty công nghệ lớn hợp tác với các startup AI là gì?",
        "options": {
          "A": "Để giảm chi phí nghiên cứu và phát triển.",
          "B": "Để tăng tốc độ và kỹ năng cần thiết để xây dựng các mô hình AI tiên tiến.",
          "C": "Để tránh các quy định chống độc quyền.",
          "D": "Để tạo ra một thị trường độc quyền trong lĩnh vực AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì chưa được công bố rõ ràng về thỏa thuận giữa Amazon và Anthropic?",
        "options": {
          "A": "Số tiền đầu tư chính xác của Amazon.",
          "B": "Việc Amazon có quyền truy cập đặc biệt vào các mô hình của Anthropic hay không.",
          "C": "Thời gian hợp tác giữa hai công ty.",
          "D": "Vai trò của Andrew Ng trong thỏa thuận."
        },
        "answer": "B"
      }
    ]
  },
  "amazon-introduces-nova-models-for-text-image-and-video": {
    "title": "Competitive Performance, Competitive Prices",
    "collection": "business",
    "content": "Amazon introduced a range of models that confront competitors head-on.\n\nWhat’s new:TheNovaline from Amazon includes three vision-language models (Nova Premier, Nova Pro, and Nova Lite), one language model (Nova Micro), an image generator (Nova Canvas), and a video generator (Nova Reel). All but Nova Premier areavailableon Amazon’s Bedrock platform, and Nova Premier, which is the most capable, is expected in early 2025. In addition, Amazon plans to release a speech-to-speech model in early 2025 and a multimodal model that processes text, images, video, and audio by mid-year. (Disclosure: Andrew Ng serves on Amazon’s board of directors.)\n\nHow it works:Nova models deliver competitiveperformanceat relatively low prices. Amazon hasn’t disclosed parameter counts or details about how the models were built except to say that Nova Pro, Lite, and Micro were trained on a combination of proprietary, licensed, public, and open-source text, images, and video in over 200 languages.\n\nBehind the news:The company launched Bedrock in April 2023 with Stability AI’s Stable Diffusion for image generation, Anthropic’s Claude and AI21’s Jurassic-2 for text generation, and its own Titan models for text generation and embeddings. Not long afterward, it added language models from Cohere as well as services for agentic applications and medical applications. It plans to continue to provide models from other companies (including Anthropic), offering a range of choices.\n\nWhy it matters:While other AI giants raced to outdo one another in models for text and multimodal processing, Amazon was relatively quiet. With Nova, it has staked out a strong position in those areas, as well as the startup-dominated domains of image and video generation. Moreover, it’s strengthening its cloud AI offerings with competitive performance, pricing, and speed. Nova’s pricing continues the rapiddrop in AI pricesover the last year. Falling per-token prices help make AI agents or applications that process large inputs more practical. For example, Simon Willison, developer of the Django Python framework for web applications,foundthat Nova Lite generated descriptions for his photo library (tens of thousands of images) for less than $10.\n\nWe’re thinking:The Nova suite is available via APIs as well as two web playgrounds (one in the Bedrock console, the other a new interface for building AI apps calledPartyRock). This accords with Amazon Web Services’ focus on developers. For consumers, Amazon offers the earlierRufusshopping bot; for enterprises, theQassistant.",
    "qa": [
      {
        "question": "Dòng sản phẩm Nova của Amazon bao gồm những loại mô hình chính nào?",
        "options": {
          "A": "Chỉ các mô hình ngôn ngữ và mô hình tạo ảnh.",
          "B": "Các mô hình ngôn ngữ, mô hình thị giác-ngôn ngữ, mô hình tạo ảnh và mô hình tạo video.",
          "C": "Chỉ các mô hình thị giác-ngôn ngữ và mô hình tạo video.",
          "D": "Các mô hình ngôn ngữ, mô hình thị giác-ngôn ngữ và mô hình nhúng (embeddings)."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Nova Premier dự kiến sẽ được ra mắt vào thời gian nào?",
        "options": {
          "A": "Cuối năm 2024.",
          "B": "Đầu năm 2025.",
          "C": "Giữa năm 2025.",
          "D": "Cuối năm 2025."
        },
        "answer": "B"
      },
      {
        "question": "Nền tảng Bedrock của Amazon được ra mắt vào thời điểm nào?",
        "options": {
          "A": "Tháng 1 năm 2023.",
          "B": "Tháng 4 năm 2023.",
          "C": "Tháng 7 năm 2023.",
          "D": "Tháng 10 năm 2023."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài các mô hình của riêng mình, Bedrock còn cung cấp các mô hình từ công ty nào khác?",
        "options": {
          "A": "Google AI.",
          "B": "OpenAI.",
          "C": "Anthropic.",
          "D": "Meta AI."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì được nhấn mạnh về hiệu suất và giá cả của các mô hình Nova?",
        "options": {
          "A": "Hiệu suất vượt trội với mức giá cao.",
          "B": "Hiệu suất cạnh tranh với mức giá tương đối thấp.",
          "C": "Hiệu suất trung bình với mức giá rất thấp.",
          "D": "Hiệu suất thấp với mức giá cạnh tranh."
        },
        "answer": "B"
      },
      {
        "question": "Các mô hình Nova Pro, Lite và Micro được đào tạo trên những loại dữ liệu nào?",
        "options": {
          "A": "Chỉ dữ liệu độc quyền của Amazon.",
          "B": "Chỉ dữ liệu mã nguồn mở.",
          "C": "Kết hợp dữ liệu độc quyền, được cấp phép, công khai và mã nguồn mở.",
          "D": "Chỉ dữ liệu được cấp phép."
        },
        "answer": "C"
      },
      {
        "question": "Ứng dụng nào được đề cập trong bài viết như một ví dụ về việc sử dụng Nova Lite để tạo mô tả cho thư viện ảnh lớn?",
        "options": {
          "A": "Rufus shopping bot.",
          "B": "Q assistant.",
          "C": "PartyRock.",
          "D": "Ứng dụng của Simon Willison."
        },
        "answer": "D"
      },
      {
        "question": "Hai nền tảng web nào được cung cấp để truy cập và sử dụng bộ mô hình Nova?",
        "options": {
          "A": "Bedrock console và Rufus shopping bot.",
          "B": "Bedrock console và Q assistant.",
          "C": "Bedrock console và PartyRock.",
          "D": "PartyRock và Rufus shopping bot."
        },
        "answer": "C"
      },
      {
        "question": "Rufus shopping bot và Q assistant của Amazon hướng đến đối tượng người dùng nào?",
        "options": {
          "A": "Cả hai đều hướng đến người tiêu dùng cá nhân.",
          "B": "Rufus hướng đến người tiêu dùng cá nhân, Q assistant hướng đến doanh nghiệp.",
          "C": "Rufus hướng đến doanh nghiệp, Q assistant hướng đến người tiêu dùng cá nhân.",
          "D": "Cả hai đều hướng đến doanh nghiệp."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì được xem là một trong những tác động quan trọng của việc giảm giá token AI, như được thể hiện qua việc định giá của Nova?",
        "options": {
          "A": "Làm cho các mô hình AI trở nên ít chính xác hơn.",
          "B": "Làm cho các ứng dụng AI chỉ có thể chạy trên phần cứng mạnh mẽ hơn.",
          "C": "Làm cho các tác vụ xử lý ngôn ngữ tự nhiên trở nên phức tạp hơn.",
          "D": "Làm cho các ứng dụng hoặc tác nhân AI xử lý lượng lớn dữ liệu đầu vào trở nên khả thi hơn."
        },
        "answer": "D"
      }
    ]
  },
  "amazon-scales-back-its-ai-powered-just-walk-out-checkout-service": {
    "title": "Amazon Rethinks Cashier-Free Stores",
    "collection": "business",
    "content": "Amazon is removing grab-and-go shopping from its cart.\n\nWhat’s new:Amazon withdrew Just Walk Out, an AI-driven checkout service, from most of its Amazon Fresh grocery stores,The Informationreported. Instead, the stores will provide smart shopping carts. (Disclosure: Andrew Ng is a member of Amazon’s Board of Directors.)Checking out:Just Walk Outenables shoppers to scan a payment method upon entering a store, take items from shelves tracked by computer vision and weight-detection sensors, and simply exit with their purchases, bypassing the checkout counter. Amazon had installed the system in 47 Amazon Fresh stores in the U.S. and UK. In most of those locations. Amazon will replace Just Walk Out withDash Cart, a shopping cart that enables customers to scan purchases as they shop. Amazon will retain Just Walk Out in its Amazon Go convenience stores and an unspecified number of smaller, UK-based Amazon Fresh stores. It has licensed the system to other retailers including Hudson Markets and plans to install in more third-party stores this year.\n\nBehind the news:AmazonintroducedJust Walk Out in 2016 at its first Amazon Go convenience store in Seattle. Itextendedthe system to Amazon Fresh in 2020. Between September 2020 and September 2022, Amazon opened 44 Fresh stores in the U.S. and 19 in the UK, most of which included Just Walk Out. But Amazon’s brick-and-mortar locationssufferedduring the COVID-19 pandemic. From September 2022 to mid-2024, amid broader cost-cutting efforts, the companypausedopening new grocery stores.\n\nWhy it matters:Grab-and-go shopping seems like a solid bet, given the increasing focus of retailing on immediate gratification. Yet Amazon’s retreat from Just Walk Out in larger stores suggests that the technology is less well suited to such environments. In addition, shoppers may not have adjusted easily to grab-and-go behavior, which removes social interactions with cashiers and encourages customers to spend without reviewing the bill.\n\nWe’re thinking:AI has the potential to revolutionize every field, including retailing, and it’s important to find productive uses for it. Not all experiments will succeed, but patient investment and experimentation can illuminate productive paths forward.",
    "qa": [
      {
        "question": "Hệ thống Just Walk Out của Amazon sử dụng công nghệ nào để nhận diện và tính tiền cho khách hàng?",
        "options": {
          "A": "Nhận diện khuôn mặt và quét mã vạch.",
          "B": "Thị giác máy tính và cảm biến trọng lượng.",
          "C": "Kết nối Bluetooth với điện thoại của khách hàng.",
          "D": "Sử dụng robot để theo dõi và kiểm kê hàng hóa."
        },
        "answer": "B"
      },
      {
        "question": "Amazon đang thay thế hệ thống Just Walk Out bằng hệ thống nào tại hầu hết các cửa hàng Amazon Fresh?",
        "options": {
          "A": "Amazon Pay.",
          "B": "Dash Cart.",
          "C": "Amazon Go.",
          "D": "Amazon Prime Checkout."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống Just Walk Out sẽ tiếp tục được sử dụng ở đâu?",
        "options": {
          "A": "Tất cả các cửa hàng Amazon Fresh ở Mỹ.",
          "B": "Các cửa hàng Amazon Go và một số cửa hàng Amazon Fresh nhỏ ở Anh.",
          "C": "Tất cả các cửa hàng Amazon Fresh và Amazon Go trên toàn thế giới.",
          "D": "Chỉ các cửa hàng Amazon Fresh mới mở gần đây."
        },
        "answer": "B"
      },
      {
        "question": "Amazon giới thiệu hệ thống Just Walk Out lần đầu tiên vào năm nào?",
        "options": {
          "A": "2010.",
          "B": "2016.",
          "C": "2020.",
          "D": "2022."
        },
        "answer": "B"
      },
      {
        "question": "Lý do nào khiến Amazon tạm dừng mở các cửa hàng tạp hóa mới từ năm 2022 đến giữa năm 2024?",
        "options": {
          "A": "Do thiếu hụt nguồn cung hàng hóa.",
          "B": "Do các nỗ lực cắt giảm chi phí chung của công ty.",
          "C": "Do sự cạnh tranh gay gắt từ các chuỗi siêu thị khác.",
          "D": "Do chính sách mới của chính phủ về bán lẻ."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, một trong những lý do khiến Amazon rút lui khỏi Just Walk Out ở các cửa hàng lớn hơn là gì?",
        "options": {
          "A": "Chi phí bảo trì hệ thống quá cao.",
          "B": "Công nghệ này không phù hợp với môi trường cửa hàng lớn.",
          "C": "Khách hàng không thích sử dụng công nghệ này.",
          "D": "Hệ thống không thể xử lý số lượng lớn khách hàng."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết cho rằng điều gì có thể là một yếu tố khiến khách hàng khó thích nghi với mô hình mua sắm 'grab-and-go'?",
        "options": {
          "A": "Giá cả các mặt hàng quá cao.",
          "B": "Việc thiếu tương tác xã hội với nhân viên thu ngân.",
          "C": "Sự phức tạp trong việc sử dụng hệ thống thanh toán tự động.",
          "D": "Thời gian chờ đợi để vào cửa hàng quá lâu."
        },
        "answer": "B"
      },
      {
        "question": "Andrew Ng có vai trò gì trong mối liên hệ với Amazon?",
        "options": {
          "A": "CEO của Amazon.",
          "B": "Thành viên Hội đồng quản trị của Amazon.",
          "C": "Người phát ngôn chính thức của Amazon.",
          "D": "Cố vấn công nghệ cho Amazon."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến việc Amazon đã cấp phép hệ thống Just Walk Out cho những nhà bán lẻ nào khác?",
        "options": {
          "A": "Walmart và Target.",
          "B": "Hudson Markets.",
          "C": "Kroger và Costco.",
          "D": "Whole Foods Market."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc Amazon thử nghiệm các công nghệ như Just Walk Out là gì?",
        "options": {
          "A": "Tăng lợi nhuận ngay lập tức.",
          "B": "Tìm ra những cách sử dụng hiệu quả cho AI trong lĩnh vực bán lẻ.",
          "C": "Giảm số lượng nhân viên trong các cửa hàng.",
          "D": "Đánh bại các đối thủ cạnh tranh."
        },
        "answer": "B"
      }
    ]
  },
  "amazon-strengthens-logistics-and-robotics-with-new-ai-partnership": {
    "title": "Amazon Boosted by Covariant",
    "collection": "business",
    "content": "Amazon took on talent and technology from robotics startup Covariant to enhance its warehouse automation, an area critical to its core ecommerce business.\n\nWhat’s new:Amazon announced anagreementto hire Covariant’s cofounders and other key personnel and license its models. Financial terms were not disclosed. (Disclosure: Andrew Ng is a member of Amazon’s board of directors.)\n\nHow it works:The new deal echoes Amazon’s previous not-quite acquisition of Adept as well as similar arrangements between other tech giants and startups.\n\nBehind the news:Amazon has been working to acquire technical talent and technology for some time. In 2022, it announced that it would acquire iRobot, but the companiesabandonedthat plan earlier this year after EU regulators blocked the deal citing antitrust concerns. In October, itcommittedto invest as much as $4 billion in Anthropic in return for access to the startup’s technology. (UK regulatory authorities subsequentlyannouncedan antitrust probe into Amazon’s relationship with Anthropic.) In July, itsigneda hire-and-license deal — similar to its agreement with Covariant — with agentic AI startup Adept.\n\nWhy it matters:Competition among AI giants continues to heat up. Amazon’s agreement with Covariant mirrors other deals in which a tech giant gained top talent and technology without formally acquiring a startup, including Microsoft’sarrangementwith Inflection and Google’sdealwith Character.AI. These developments highlight top tech companies’ race to secure their AI positions — and the fact that outright acquisitions invite regulatory scrutiny.\n\nWe’re thinking:Robotic foundation models that are trained on large amounts of unlabeled robotics data offer a promising way to quickly fine-tune robots to perform new tasks — potentially a major upgrade in warehouse logistics.",
    "qa": [
      {
        "question": "Mục đích chính của Amazon khi hợp tác với Covariant là gì?",
        "options": {
          "A": "Để cạnh tranh trực tiếp với các công ty robot khác.",
          "B": "Để cải thiện tự động hóa kho hàng, một yếu tố quan trọng trong kinh doanh thương mại điện tử cốt lõi.",
          "C": "Để mở rộng sang lĩnh vực phát triển robot dân dụng.",
          "D": "Để đa dạng hóa danh mục đầu tư vào các công ty khởi nghiệp."
        },
        "answer": "B"
      },
      {
        "question": "Thỏa thuận giữa Amazon và Covariant bao gồm những gì?",
        "options": {
          "A": "Mua lại hoàn toàn công ty Covariant.",
          "B": "Thuê các nhà đồng sáng lập và nhân sự chủ chốt của Covariant, đồng thời cấp phép sử dụng các mô hình của họ.",
          "C": "Đầu tư vào Covariant để đổi lấy cổ phần.",
          "D": "Hợp tác nghiên cứu và phát triển các công nghệ robot mới."
        },
        "answer": "B"
      },
      {
        "question": "Thỏa thuận giữa Amazon và Covariant được so sánh với thỏa thuận nào trước đây của Amazon?",
        "options": {
          "A": "Thỏa thuận mua lại iRobot.",
          "B": "Thỏa thuận đầu tư vào Anthropic.",
          "C": "Thỏa thuận 'không hẳn là mua lại' Adept.",
          "D": "Thỏa thuận hợp tác với Microsoft."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao thương vụ mua lại iRobot của Amazon không thành công?",
        "options": {
          "A": "Do iRobot rút khỏi thỏa thuận.",
          "B": "Do Amazon thay đổi chiến lược kinh doanh.",
          "C": "Do các nhà quản lý EU chặn thỏa thuận vì lo ngại về chống độc quyền.",
          "D": "Do các nhà đầu tư phản đối thương vụ."
        },
        "answer": "C"
      },
      {
        "question": "Amazon đã cam kết đầu tư bao nhiêu vào Anthropic?",
        "options": {
          "A": "$1 tỷ.",
          "B": "$2 tỷ.",
          "C": "$3 tỷ.",
          "D": "$4 tỷ."
        },
        "answer": "D"
      },
      {
        "question": "Mục đích của Amazon khi đầu tư vào Anthropic là gì?",
        "options": {
          "A": "Để cạnh tranh với Google trong lĩnh vực tìm kiếm.",
          "B": "Để tiếp cận công nghệ của Anthropic.",
          "C": "Để mở rộng sang thị trường điện toán đám mây.",
          "D": "Để đa dạng hóa danh mục đầu tư vào các công ty AI."
        },
        "answer": "B"
      },
      {
        "question": "Thỏa thuận giữa Amazon và Adept có đặc điểm gì?",
        "options": {
          "A": "Mua lại hoàn toàn công ty Adept.",
          "B": "Đầu tư vào Adept để đổi lấy cổ phần.",
          "C": "Thỏa thuận thuê và cấp phép tương tự như thỏa thuận với Covariant.",
          "D": "Hợp tác nghiên cứu và phát triển các công nghệ AI mới."
        },
        "answer": "C"
      },
      {
        "question": "Thỏa thuận giữa Amazon và Covariant phản ánh xu hướng nào trong ngành công nghệ AI?",
        "options": {
          "A": "Các công ty lớn mua lại hoàn toàn các công ty khởi nghiệp AI.",
          "B": "Các công ty lớn hợp tác với các công ty khởi nghiệp AI để chia sẻ lợi nhuận.",
          "C": "Các công ty lớn tìm cách thu hút nhân tài và công nghệ hàng đầu mà không cần mua lại hoàn toàn các công ty khởi nghiệp.",
          "D": "Các công ty khởi nghiệp AI tự phát triển công nghệ mà không cần sự hợp tác từ các công ty lớn."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì khiến các thương vụ mua lại công ty AI gặp khó khăn?",
        "options": {
          "A": "Giá trị của các công ty AI quá cao.",
          "B": "Các công ty AI không muốn bị mua lại.",
          "C": "Sự can thiệp của các cơ quan quản lý chống độc quyền.",
          "D": "Thiếu hụt nhân tài trong lĩnh vực AI."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình nền tảng robot được đào tạo trên lượng lớn dữ liệu robot không được gắn nhãn có tiềm năng gì?",
        "options": {
          "A": "Giảm chi phí sản xuất robot.",
          "B": "Tăng cường khả năng bảo mật của robot.",
          "C": "Nhanh chóng tinh chỉnh robot để thực hiện các nhiệm vụ mới, có khả năng nâng cấp lớn trong logistics kho hàng.",
          "D": "Cho phép robot tự học hỏi và phát triển."
        },
        "answer": "C"
      }
    ]
  },
  "annual-report-robot-edition": {
    "title": "Annual Report, Robot Edition",
    "collection": "business",
    "content": "Corporations are tailoring their financial reports to be read by machines.What’s new:Automated systems download far more company financial reports than humans, according to astudyby the U.S. nonprofit National Bureau of Economic Research. Consequently, companies are filling those reports with data that looks good to computers.What they did:The study analyzed 50 years of quarterly and annual financial reports submitted by public companies to the U.S. Securities and Exchange Commission.\n\nBehind the news:Computer systems increasingly drive the stock market. Last year, Deutsche Bankestimatedthat automated systems made buying and selling decisions for 80 percent of equity trading and 90 percent of equity futures trading. Corporate financials are following suit.Why it matters:The study found that the more easily a computer can digest a company’s financial reports, the faster its stock is traded after a report has been published. This suggests that the market’s pace, already lightning-fast, is bound to accelerate.We’re thinking:Companies have every incentive to tweak their reports to impress their audience, whether readers consist of wetware or software. But there’s a slippery slope between painting a rosy picture and exaggerating in ways that border on fraud. Regulators, analysts, and AI practitioners alike have a responsibility to guard against market manipulation.",
    "qa": [
      {
        "question": "Theo nghiên cứu của National Bureau of Economic Research, điều gì đang xảy ra với báo cáo tài chính của các công ty?",
        "options": {
          "A": "Con người đọc báo cáo tài chính nhiều hơn máy móc.",
          "B": "Máy móc tải xuống báo cáo tài chính nhiều hơn con người.",
          "C": "Các công ty ngừng nộp báo cáo tài chính cho SEC.",
          "D": "Báo cáo tài chính được viết bằng ngôn ngữ lập trình."
        },
        "answer": "B"
      },
      {
        "question": "Các công ty đang điều chỉnh báo cáo tài chính của họ như thế nào?",
        "options": {
          "A": "Bằng cách làm cho chúng dài hơn và phức tạp hơn.",
          "B": "Bằng cách loại bỏ tất cả các dữ liệu không cần thiết.",
          "C": "Bằng cách điền vào báo cáo dữ liệu trông tốt đối với máy tính.",
          "D": "Bằng cách sử dụng nhiều hình ảnh và biểu đồ hơn."
        },
        "answer": "C"
      },
      {
        "question": "Nghiên cứu đã phân tích dữ liệu báo cáo tài chính trong khoảng thời gian bao lâu?",
        "options": {
          "A": "10 năm.",
          "B": "25 năm.",
          "C": "50 năm.",
          "D": "100 năm."
        },
        "answer": "C"
      },
      {
        "question": "Theo Deutsche Bank, hệ thống tự động chiếm bao nhiêu phần trăm giao dịch cổ phiếu?",
        "options": {
          "A": "20%",
          "B": "50%",
          "C": "80%",
          "D": "90%"
        },
        "answer": "C"
      },
      {
        "question": "Hệ quả của việc máy tính dễ dàng tiêu hóa báo cáo tài chính của công ty là gì?",
        "options": {
          "A": "Giá cổ phiếu của công ty giảm mạnh.",
          "B": "Tốc độ giao dịch cổ phiếu của công ty chậm lại.",
          "C": "Tốc độ giao dịch cổ phiếu của công ty tăng nhanh.",
          "D": "Công ty bị phạt vì gian lận tài chính."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến nguy cơ tiềm ẩn nào khi các công ty điều chỉnh báo cáo tài chính để gây ấn tượng với máy tính?",
        "options": {
          "A": "Sự chậm trễ trong việc công bố báo cáo tài chính.",
          "B": "Sự gia tăng chi phí kiểm toán.",
          "C": "Sự khác biệt giữa việc vẽ một bức tranh tươi sáng và phóng đại đến mức gian lận.",
          "D": "Sự phụ thuộc quá mức vào công nghệ."
        },
        "answer": "C"
      },
      {
        "question": "Ai được cho là có trách nhiệm bảo vệ thị trường khỏi sự thao túng?",
        "options": {
          "A": "Chỉ các nhà phân tích tài chính.",
          "B": "Chỉ các nhà quản lý.",
          "C": "Chỉ các nhà thực hành AI.",
          "D": "Các nhà quản lý, nhà phân tích và nhà thực hành AI."
        },
        "answer": "D"
      },
      {
        "question": "Bài viết sử dụng thuật ngữ nào để chỉ bộ não con người?",
        "options": {
          "A": "Hardware.",
          "B": "Software.",
          "C": "Wetware.",
          "D": "Firmware."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc các công ty điều chỉnh báo cáo tài chính là gì?",
        "options": {
          "A": "Để tuân thủ các quy định pháp luật.",
          "B": "Để giảm thiểu thuế.",
          "C": "Để gây ấn tượng với đối tượng đọc, dù là con người hay máy tính.",
          "D": "Để đơn giản hóa quy trình kiểm toán."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì đang xảy ra với tốc độ của thị trường chứng khoán?",
        "options": {
          "A": "Tốc độ đang chậm lại do sự can thiệp của con người.",
          "B": "Tốc độ đang ổn định do quy định chặt chẽ hơn.",
          "C": "Tốc độ đang tăng nhanh và có khả năng sẽ còn tăng hơn nữa.",
          "D": "Tốc độ không thay đổi nhiều so với trước đây."
        },
        "answer": "C"
      }
    ]
  },
  "anthropic-secures-2-billion-investment-from-google-weeks-after-amazon-deal": {
    "title": "Anthropic Cultivates Alternatives",
    "collection": "business",
    "content": "Weeks after it announced a huge partnership deal with Amazon, Anthropic doubled down on its earlier relationship with Alphabet.\n\nWhat's new:Anthropic, which provides large language models, agreed to use Google’s cloud-computing infrastructure in return for a $2 billion investment,The Wall Street Journalreported. The deal follows an earlier multibillion-dollar partnership that saw Anthropic commit to training new models on Amazon Web Services.\n\nHow it works:Google invested $500 million up front and will add $1.5 billion more over an unspecified time period. The new funding builds on $300 million that Googlegaveto Anthropic earlier in the year for a 10 percent stake in the company. Google’s current stake in Anthropic is undisclosed.\n\nBehind the news:Anthropic rose rapidly from AI startup to coveted foundation-model partner.\n\nWhy it matters:The Anthropic-Google deal changes the shape of the startup’s relationships with large cloud providers. Anthropic's deal with Amazon dwarfed Google’s initial investment and seemed like a formative partnership akin to OpenAI’s lucrative Microsoftpair-up. Now, Anthropic is more like a vertex in a triangle, bound by close relationships with competing partners.\n\nWe're thinking:Anthropic hasn’t raised as much total funding as OpenAI ($12.7 billion and counting), but its relationships with both Google and Amazon give it more flexibility to choose different infrastructure for different tasks. The benefits presumably will flow not only to the three companies but also to independent developers, who can choose among stellar proprietary foundational models — not to mention open source alternatives — from three major cloud providers.",
    "qa": [
      {
        "question": "Anthropic đã củng cố mối quan hệ trước đó với công ty nào sau khi công bố thỏa thuận hợp tác lớn với Amazon?",
        "options": {
          "A": "Microsoft",
          "B": "Alphabet",
          "C": "OpenAI",
          "D": "Amazon Web Services"
        },
        "answer": "B"
      },
      {
        "question": "Theo thỏa thuận mới nhất, Google sẽ đầu tư bao nhiêu tiền vào Anthropic để đổi lấy việc sử dụng cơ sở hạ tầng điện toán đám mây của Google?",
        "options": {
          "A": "$300 triệu",
          "B": "$500 triệu",
          "C": "$1.5 tỷ",
          "D": "$2 tỷ"
        },
        "answer": "D"
      },
      {
        "question": "Khoản đầu tư ban đầu của Google vào Anthropic trước thỏa thuận mới là bao nhiêu?",
        "options": {
          "A": "$200 triệu",
          "B": "$300 triệu",
          "C": "$500 triệu",
          "D": "$1.5 tỷ"
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của Anthropic khi hợp tác với cả Google và Amazon là gì?",
        "options": {
          "A": "Để cạnh tranh trực tiếp với OpenAI",
          "B": "Để tăng cường khả năng tiếp cận thị trường quốc tế",
          "C": "Để có sự linh hoạt trong việc lựa chọn cơ sở hạ tầng cho các nhiệm vụ khác nhau",
          "D": "Để giảm chi phí phát triển mô hình ngôn ngữ lớn"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết so sánh mối quan hệ của Anthropic với Google và Amazon như thế nào?",
        "options": {
          "A": "Một mối quan hệ đối tác độc quyền như OpenAI và Microsoft",
          "B": "Một mối quan hệ cạnh tranh gay gắt",
          "C": "Một đỉnh trong một tam giác, ràng buộc bởi các mối quan hệ chặt chẽ với các đối tác cạnh tranh",
          "D": "Một mối quan hệ tạm thời để giải quyết các vấn đề tài chính"
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích tiềm năng của các mối quan hệ hợp tác của Anthropic không chỉ dành cho ba công ty mà còn dành cho đối tượng nào khác?",
        "options": {
          "A": "Các nhà đầu tư mạo hiểm",
          "B": "Các nhà nghiên cứu học thuật",
          "C": "Các nhà phát triển độc lập",
          "D": "Các cơ quan chính phủ"
        },
        "answer": "C"
      },
      {
        "question": "Anthropic cung cấp dịch vụ gì cho các đối tác của mình?",
        "options": {
          "A": "Phần mềm quản lý dữ liệu",
          "B": "Cơ sở hạ tầng điện toán đám mây",
          "C": "Mô hình ngôn ngữ lớn",
          "D": "Dịch vụ tư vấn AI"
        },
        "answer": "C"
      },
      {
        "question": "Tổng số vốn mà OpenAI đã huy động được (tính đến thời điểm bài viết) là bao nhiêu?",
        "options": {
          "A": "$2 tỷ",
          "B": "$10 tỷ",
          "C": "$12.7 tỷ",
          "D": "$15 tỷ"
        },
        "answer": "C"
      },
      {
        "question": "Thỏa thuận giữa Anthropic và Amazon được mô tả như thế nào so với khoản đầu tư ban đầu của Google?",
        "options": {
          "A": "Tương đương về quy mô",
          "B": "Nhỏ hơn đáng kể",
          "C": "Lớn hơn đáng kể",
          "D": "Không đáng kể"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì khiến Anthropic trở nên 'đáng thèm muốn' (coveted) trong lĩnh vực AI?",
        "options": {
          "A": "Khả năng phát triển phần cứng AI tiên tiến",
          "B": "Khả năng trở thành đối tác nền tảng mô hình được săn đón",
          "C": "Khả năng thu hút nhân tài hàng đầu trong ngành",
          "D": "Khả năng tạo ra các ứng dụng AI đột phá"
        },
        "answer": "B"
      }
    ]
  },
  "apple-kicks-ai-into-high-gear": {
    "title": "Apple Kicks AI Into High Gear",
    "collection": "business",
    "content": "After years of trailing other tech giants in AI, Apple has a new ambition: to become the industry’s leading purveyor of products powered by machine learning.What’s new:In an interview withArs Technica, the company’s AI chief argues that its pro-privacy, on-device approach is the best way to build such applications.Think different:John Giannandrea, the former head of Google’s AI and search whojoinedApple in 2018, outlined the iPhone maker’s effort to infuse the technology into a wide range of products and services.\n\nBuying in:Apple lists dozens of AI jobopenings, but it has acquired much of its AI technology by buying other companies. It purchased at least 20 machine learning startups — more than any of its rivals — since buying Siri in 2010, according to venture trackerCB Insights.Why it matters:Apple’s privacy-centric, edge-based approach stands out from much of the industry’s reliance on aggressive data collection and processing in the cloud. The difference could help counteract the longstanding impression that it’s behind other tech giants in AI.We’re thinking:AI’s voracious appetite for data boosts the accuracy of supervised learning systems, but it poses risks to user privacy. Apple’s effort to avoid collecting and exposing user data is refreshing — and raises the stakes for small data techniques that enable systems to learn effectively with fewer examples.",
    "qa": [
      {
        "question": "Tham vọng mới của Apple trong lĩnh vực trí tuệ nhân tạo (AI) là gì?",
        "options": {
          "A": "Vượt mặt Google trong lĩnh vực tìm kiếm bằng AI.",
          "B": "Trở thành nhà cung cấp hàng đầu các sản phẩm được hỗ trợ bởi máy học.",
          "C": "Phát triển các thuật toán AI phức tạp nhất thế giới.",
          "D": "Tập trung vào nghiên cứu AI thuần túy, không ứng dụng vào sản phẩm."
        },
        "answer": "B"
      },
      {
        "question": "Ai là người đứng đầu bộ phận AI của Apple và đã từng làm việc tại Google?",
        "options": {
          "A": "Tim Cook",
          "B": "John Giannandrea",
          "C": "Siri",
          "D": "Craig Federighi"
        },
        "answer": "B"
      },
      {
        "question": "Chiến lược chính của Apple trong việc phát triển AI là gì?",
        "options": {
          "A": "Thu thập dữ liệu người dùng một cách triệt để để cải thiện độ chính xác của AI.",
          "B": "Tập trung vào bảo mật quyền riêng tư và xử lý AI trực tiếp trên thiết bị.",
          "C": "Hợp tác chặt chẽ với các công ty công nghệ khác để chia sẻ dữ liệu AI.",
          "D": "Đầu tư mạnh vào các trung tâm dữ liệu lớn để xử lý AI trên đám mây."
        },
        "answer": "B"
      },
      {
        "question": "Apple đã tăng cường công nghệ AI của mình chủ yếu bằng cách nào?",
        "options": {
          "A": "Phát triển các thuật toán AI từ đầu.",
          "B": "Mua lại các công ty khởi nghiệp về máy học.",
          "C": "Tuyển dụng các nhà khoa học AI hàng đầu từ các trường đại học.",
          "D": "Hợp tác với chính phủ để chia sẻ dữ liệu và công nghệ AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, Apple đã mua lại bao nhiêu công ty khởi nghiệp về máy học kể từ khi mua Siri?",
        "options": {
          "A": "Ít hơn 10",
          "B": "Khoảng 15",
          "C": "Ít nhất 20",
          "D": "Hơn 30"
        },
        "answer": "C"
      },
      {
        "question": "Cách tiếp cận AI của Apple khác biệt so với phần lớn ngành công nghiệp như thế nào?",
        "options": {
          "A": "Apple tập trung vào AI cho các ứng dụng doanh nghiệp, trong khi các công ty khác tập trung vào người tiêu dùng.",
          "B": "Apple ưu tiên bảo mật quyền riêng tư và xử lý trên thiết bị, trong khi các công ty khác dựa vào thu thập dữ liệu và xử lý trên đám mây.",
          "C": "Apple sử dụng các ngôn ngữ lập trình khác biệt để phát triển AI.",
          "D": "Apple không sử dụng học sâu (deep learning) trong các sản phẩm của mình."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì có thể giúp Apple thay đổi ấn tượng rằng họ đang tụt hậu so với các công ty công nghệ khác trong lĩnh vực AI?",
        "options": {
          "A": "Việc phát triển các sản phẩm AI có tính năng độc đáo và vượt trội.",
          "B": "Việc tập trung vào quyền riêng tư và xử lý AI trên thiết bị.",
          "C": "Việc mua lại thêm nhiều công ty khởi nghiệp về AI.",
          "D": "Việc tăng cường quảng bá về các nỗ lực AI của mình."
        },
        "answer": "B"
      },
      {
        "question": "Thách thức lớn nhất đối với các hệ thống học máy có giám sát (supervised learning) là gì?",
        "options": {
          "A": "Sự phức tạp của các thuật toán.",
          "B": "Nhu cầu về lượng dữ liệu lớn và rủi ro đối với quyền riêng tư của người dùng.",
          "C": "Chi phí cao để phát triển và triển khai.",
          "D": "Khó khăn trong việc tích hợp vào các sản phẩm hiện có."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, 'small data techniques' có vai trò gì trong chiến lược AI của Apple?",
        "options": {
          "A": "Giúp Apple thu thập dữ liệu người dùng một cách bí mật.",
          "B": "Cho phép các hệ thống học hiệu quả với ít dữ liệu hơn, giảm thiểu rủi ro về quyền riêng tư.",
          "C": "Giúp Apple cạnh tranh với các công ty có nguồn dữ liệu lớn hơn.",
          "D": "Cho phép Apple phát triển các thuật toán AI nhanh hơn."
        },
        "answer": "B"
      },
      {
        "question": "John Giannandrea gia nhập Apple vào năm nào?",
        "options": {
          "A": "2010",
          "B": "2015",
          "C": "2018",
          "D": "2020"
        },
        "answer": "C"
      }
    ]
  },
  "apple-plans-self-driving-car-release-for-2026": {
    "title": "Drive Different",
    "collection": "business",
    "content": "Apple is redrawing the road map for its self-driving car.\n\nWhat's new:The company is redesigning an autonomous car that has been in development for nearly a decade,Bloombergreported. Originally intended to be fully autonomous under all conditions, the redesigned vehicle will allow for a human driver.\n\nDownshift:Apple had scheduled the vehicle, code named Titan, for 2025, anonymous insiders said. However, executives realized earlier this year that they couldn’t meet the deadline and decided to scale back the autonomous features. The new timeline calls for a prototype by 2024, testing through 2025, and launch in 2026. The target price is under $100,000, a markdown from the original $120,000. The company is currently testing its semi-autonomous system on Lexus SUVs in several U.S. states.\n\nBehind the news:Fully self-driving cars on the open road remain limited to a few robotaxi deployments inChinaand theUnited States. Meanwhile, the industry has suffered a series of setbacks. Fordshut downArgo, its joint project with Volkswagen. Tesla’s purported Full Self-Driving optionrequiresa human in the loop. Further development is required to enable such vehicles to drive safely despite challenges likeroad construction and snow.\n\nWhy it matters:Commercializing fully autonomous vehicles is a tantalizing but elusive goal. Apple’s decision to downshift for the sake of bringing a product to market suggests that human drivers will sit behind the wheel for the foreseeable future.\n\nWe're thinking:Full self-driving cars have been five years away for the past decade. The challenge of handling the long tail of rare but critical events has been a persistent issue. Upcoming developments such as foundation models for computer vision are likely to make a substantial difference. We don't know when, but we're confident that the future includes full autonomy.",
    "qa": [
      {
        "question": "Dự án xe tự lái của Apple, có tên mã Titan, ban đầu được thiết kế để như thế nào?",
        "options": {
          "A": "Bán tự hành, cần sự can thiệp của người lái trong một số tình huống.",
          "B": "Hoàn toàn tự hành trong mọi điều kiện.",
          "C": "Chỉ hoạt động trong khu vực đô thị được lập trình sẵn.",
          "D": "Chỉ hoạt động trên đường cao tốc với điều kiện thời tiết tốt."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, thời gian biểu mới cho dự án xe tự lái của Apple là gì?",
        "options": {
          "A": "Ra mắt nguyên mẫu năm 2023, thử nghiệm năm 2024, ra mắt chính thức năm 2025.",
          "B": "Ra mắt nguyên mẫu năm 2024, thử nghiệm năm 2025, ra mắt chính thức năm 2026.",
          "C": "Ra mắt nguyên mẫu năm 2025, thử nghiệm năm 2026, ra mắt chính thức năm 2027.",
          "D": "Dự án bị hoãn vô thời hạn do không đạt được tiến độ."
        },
        "answer": "B"
      },
      {
        "question": "Giá mục tiêu mới của xe tự lái Apple sau khi điều chỉnh là bao nhiêu?",
        "options": {
          "A": "Dưới $80,000.",
          "B": "Dưới $100,000.",
          "C": "$120,000.",
          "D": "Không có thông tin về giá."
        },
        "answer": "B"
      },
      {
        "question": "Apple hiện đang thử nghiệm hệ thống bán tự hành của mình trên loại xe nào?",
        "options": {
          "A": "Tesla Model S.",
          "B": "Ford Mustang Mach-E.",
          "C": "Lexus SUVs.",
          "D": "BMW iX."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, một trong những thách thức lớn nhất đối với xe tự lái hoàn toàn là gì?",
        "options": {
          "A": "Chi phí sản xuất quá cao.",
          "B": "Sự thiếu hụt chip bán dẫn.",
          "C": "Khả năng xử lý các tình huống hiếm gặp nhưng quan trọng.",
          "D": "Sự phản đối từ các hãng taxi truyền thống."
        },
        "answer": "C"
      },
      {
        "question": "Công ty nào đã đóng cửa dự án xe tự lái chung với Volkswagen?",
        "options": {
          "A": "Tesla.",
          "B": "General Motors.",
          "C": "Ford.",
          "D": "Toyota."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến công nghệ nào có khả năng tạo ra sự khác biệt đáng kể trong phát triển xe tự lái?",
        "options": {
          "A": "Công nghệ pin thể rắn.",
          "B": "Mô hình nền tảng cho thị giác máy tính.",
          "C": "Mạng 5G tốc độ cao.",
          "D": "Công nghệ LiDAR tiên tiến."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì khiến Apple quyết định giảm bớt các tính năng tự hành hoàn toàn cho xe của mình?",
        "options": {
          "A": "Do lo ngại về vấn đề an toàn.",
          "B": "Do không thể đáp ứng thời hạn ban đầu.",
          "C": "Do chi phí phát triển quá cao.",
          "D": "Do áp lực từ các nhà đầu tư."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, tình trạng phát triển của xe tự lái hoàn toàn trên thị trường hiện nay như thế nào?",
        "options": {
          "A": "Đã được thương mại hóa rộng rãi trên toàn cầu.",
          "B": "Chỉ giới hạn ở một vài thử nghiệm robotaxi tại Trung Quốc và Hoa Kỳ.",
          "C": "Đang được sử dụng phổ biến trong lĩnh vực vận tải hàng hóa.",
          "D": "Đã bị cấm lưu hành do các vấn đề an toàn."
        },
        "answer": "B"
      },
      {
        "question": "Ý chính mà bài viết muốn truyền tải là gì?",
        "options": {
          "A": "Xe tự lái hoàn toàn sẽ sớm thay thế xe có người lái trong tương lai gần.",
          "B": "Sự phát triển của xe tự lái hoàn toàn đang gặp nhiều khó khăn và cần thêm thời gian.",
          "C": "Apple đang dẫn đầu trong cuộc đua phát triển xe tự lái.",
          "D": "Giá xe tự lái sẽ ngày càng giảm trong tương lai."
        },
        "answer": "B"
      }
    ]
  },
  "argentina-launches-ai-unit-to-predict-and-prevent-crimes": {
    "title": "AI-Powered Policing Goes National",
    "collection": "business",
    "content": "Argentina created a national law-enforcement department that will use AI to detect crimes as they’re committed, investigate them afterward, and predict them before they occur.\n\nWhat’s new:President Javier Milei of Argentina established the Artificial Intelligence Unit Applied to Security (UIAAS),The Registerreported. The unit aims to detect, investigate, and predict criminal activity by using machine learning algorithms to monitor the internet, wireless communications, security cameras, drone surveillance, financial transactions, and other data in real time.\n\nHow it works:Milei established the UIAAS in a late-Julyresolution. Milei created it under the Ministry of Security shortly after hereorganizedthe national intelligence agency to give himself more direct control. In December, his security ministerquashedpublic protests against his austerity policies; he promised to identify protesters via “video, digital, or manual means” and bill them for the cost of policing the demonstrations.\n\nBehind the news:Argentina’s government is a presidential representative democratic republic. The country was ruled by a military dictatorship between 1976 and 1983.\n\nWhy it matters:AI has valuable uses in law enforcement and security. At the same time, it needs to be applied responsibly and implemented in a way that’s fair and respectful of legal rights such as presumption of innocence.\n\nWe’re thinking:Surveillance is easy to abuse, and the notion of predictive policing warrants extreme caution to avoid bias against certain groups, violating civil rights, and other pitfalls. Ensuring that it’s used well requires robust technology, rigid controls, clear oversight, and public transparency. We hope that Argentina — no less than the countries that inspired it establish a national AI police agency — will put strong safeguards in place.",
    "qa": [
      {
        "question": "Đơn vị nào của Argentina sẽ sử dụng AI để phát hiện, điều tra và dự đoán tội phạm?",
        "options": {
          "A": "Bộ Tư pháp Argentina",
          "B": "Đơn vị Trí tuệ Nhân tạo Ứng dụng cho An ninh (UIAAS)",
          "C": "Cơ quan Tình báo Quốc gia Argentina",
          "D": "Lực lượng Cảnh sát Liên bang Argentina"
        },
        "answer": "B"
      },
      {
        "question": "Tổng thống Javier Milei thành lập UIAAS với mục tiêu chính là gì?",
        "options": {
          "A": "Tăng cường hợp tác quốc tế trong lĩnh vực an ninh.",
          "B": "Phát hiện, điều tra và dự đoán hoạt động tội phạm.",
          "C": "Cải thiện hệ thống nhà tù quốc gia.",
          "D": "Nâng cao trình độ nghiệp vụ cho lực lượng cảnh sát."
        },
        "answer": "B"
      },
      {
        "question": "UIAAS sẽ sử dụng công nghệ nào để thực hiện nhiệm vụ của mình?",
        "options": {
          "A": "Công nghệ blockchain và tiền điện tử.",
          "B": "Thuật toán máy học để giám sát dữ liệu.",
          "C": "Hệ thống định vị toàn cầu (GPS) và bản đồ số.",
          "D": "Công nghệ nhận diện khuôn mặt và phân tích giọng nói."
        },
        "answer": "B"
      },
      {
        "question": "UIAAS được thành lập trực thuộc cơ quan nào của chính phủ Argentina?",
        "options": {
          "A": "Văn phòng Tổng thống.",
          "B": "Bộ An ninh.",
          "C": "Bộ Quốc phòng.",
          "D": "Bộ Nội vụ."
        },
        "answer": "B"
      },
      {
        "question": "Trước khi thành lập UIAAS, Tổng thống Milei đã thực hiện hành động nào liên quan đến cơ quan tình báo quốc gia?",
        "options": {
          "A": "Giải thể cơ quan tình báo quốc gia.",
          "B": "Tái cơ cấu cơ quan tình báo quốc gia để tăng quyền kiểm soát trực tiếp.",
          "C": "Bổ nhiệm người đứng đầu mới cho cơ quan tình báo quốc gia.",
          "D": "Tăng cường ngân sách cho cơ quan tình báo quốc gia."
        },
        "answer": "B"
      },
      {
        "question": "Chính phủ Argentina đã sử dụng biện pháp gì để đối phó với các cuộc biểu tình phản đối chính sách thắt lưng buộc bụng?",
        "options": {
          "A": "Tổ chức đối thoại với người biểu tình.",
          "B": "Sử dụng video và các phương tiện kỹ thuật số để xác định người biểu tình.",
          "C": "Ban hành lệnh cấm biểu tình trên toàn quốc.",
          "D": "Tăng cường lực lượng cảnh sát để bảo vệ các tòa nhà chính phủ."
        },
        "answer": "B"
      },
      {
        "question": "Trong giai đoạn nào Argentina bị cai trị bởi một chế độ độc tài quân sự?",
        "options": {
          "A": "1966 - 1973",
          "B": "1976 - 1983",
          "C": "1986 - 1993",
          "D": "1996 - 2003"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về việc sử dụng AI trong lĩnh vực an ninh và thực thi pháp luật?",
        "options": {
          "A": "AI nên được sử dụng rộng rãi mà không cần kiểm soát.",
          "B": "AI cần được áp dụng một cách có trách nhiệm và tôn trọng các quyền hợp pháp.",
          "C": "AI nên được sử dụng bí mật để đảm bảo hiệu quả.",
          "D": "AI không nên được sử dụng trong lĩnh vực an ninh vì tiềm ẩn nhiều rủi ro."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết bày tỏ lo ngại gì về việc sử dụng AI trong công tác cảnh sát dự đoán?",
        "options": {
          "A": "Khả năng AI thay thế hoàn toàn con người trong lực lượng cảnh sát.",
          "B": "Nguy cơ thiên vị đối với một số nhóm nhất định và vi phạm quyền công dân.",
          "C": "Chi phí đầu tư quá lớn cho công nghệ AI.",
          "D": "Sự thiếu hụt nhân lực có trình độ để vận hành hệ thống AI."
        },
        "answer": "B"
      },
      {
        "question": "Để đảm bảo việc sử dụng AI trong an ninh một cách hiệu quả và có trách nhiệm, bài viết đề xuất những biện pháp nào?",
        "options": {
          "A": "Tăng cường hợp tác quốc tế và chia sẻ kinh nghiệm.",
          "B": "Công nghệ mạnh mẽ, kiểm soát chặt chẽ, giám sát rõ ràng và minh bạch công khai.",
          "C": "Tập trung vào đào tạo nhân lực và nâng cao nhận thức cộng đồng.",
          "D": "Xây dựng luật pháp nghiêm ngặt và tăng cường xử phạt vi phạm."
        },
        "answer": "B"
      }
    ]
  },
  "asias-ai-advantage": {
    "title": "Asia’s AI Advantage",
    "collection": "business",
    "content": "Asian companies lead the world in AI deployment, new research argues.What’s new:Market research byMIT Technology Review Insightsfound that companies in the Asia-Pacific region are using machine learning faster and with better results than any other part of the world.What they found:The authors interviewed over 1,000 executives and directors from businesses in a range of economic sectors around the globe. Roughly one-fifth work for companies in the Asia-Pacific region.\n\nData-driven growth:Nearly half of Asian executives surveyed said their companies’ AI ambitions were hindered by a lack of access to high-quality data. Most said that better legal protections and industry standards regarding data privacy and security would make them more willing to share datasets with other companies. Third-party data-sharing platforms like Singapore’s nonprofitOcean Protocolcould be part of the solution, the authors write.Behind the news:Several Asia-Pacific governments have provided major support for IT infrastructure.\n\nWhy it matters:The survey shows that AI is thriving in places where the government provides both regulatory clarity and institutional support.We’re thinking:Every country should develop policies to foster AI development or risk getting left behind.",
    "qa": [
      {
        "question": "Theo nghiên cứu của MIT Technology Review Insights, khu vực nào đang dẫn đầu thế giới về triển khai AI?",
        "options": {
          "A": "Bắc Mỹ",
          "B": "Châu Á - Thái Bình Dương",
          "C": "Châu Âu",
          "D": "Châu Phi"
        },
        "answer": "B"
      },
      {
        "question": "Số lượng các nhà quản lý và giám đốc được phỏng vấn trong nghiên cứu này là bao nhiêu?",
        "options": {
          "A": "Khoảng 500",
          "B": "Khoảng 750",
          "C": "Khoảng 1000",
          "D": "Khoảng 1500"
        },
        "answer": "C"
      },
      {
        "question": "Theo khảo sát, điều gì đang cản trở tham vọng AI của các công ty châu Á?",
        "options": {
          "A": "Thiếu nhân lực có kỹ năng",
          "B": "Thiếu vốn đầu tư",
          "C": "Thiếu quyền truy cập vào dữ liệu chất lượng cao",
          "D": "Thiếu cơ sở hạ tầng công nghệ"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì sẽ khiến các công ty sẵn sàng chia sẻ dữ liệu với các công ty khác hơn?",
        "options": {
          "A": "Giảm chi phí lưu trữ dữ liệu",
          "B": "Bảo vệ pháp lý tốt hơn và tiêu chuẩn ngành về quyền riêng tư và bảo mật dữ liệu",
          "C": "Tăng cường hợp tác quốc tế",
          "D": "Sự phát triển của các thuật toán AI tiên tiến hơn"
        },
        "answer": "B"
      },
      {
        "question": "Ocean Protocol, được đề cập trong bài viết, là gì?",
        "options": {
          "A": "Một công ty tư vấn AI",
          "B": "Một nền tảng chia sẻ dữ liệu của bên thứ ba",
          "C": "Một tổ chức chính phủ hỗ trợ phát triển AI",
          "D": "Một tiêu chuẩn bảo mật dữ liệu"
        },
        "answer": "B"
      },
      {
        "question": "Chính phủ các nước khu vực Châu Á - Thái Bình Dương đã hỗ trợ cho sự phát triển AI thông qua hình thức nào?",
        "options": {
          "A": "Cung cấp các khoản vay ưu đãi cho các công ty AI",
          "B": "Hỗ trợ lớn cho cơ sở hạ tầng CNTT",
          "C": "Tổ chức các hội nghị và triển lãm AI quốc tế",
          "D": "Đào tạo nhân lực AI chất lượng cao"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì cho thấy AI đang phát triển mạnh mẽ?",
        "options": {
          "A": "Sự hợp tác giữa các công ty công nghệ lớn",
          "B": "Sự hỗ trợ thể chế và sự rõ ràng về quy định từ chính phủ",
          "C": "Sự gia tăng số lượng các nhà nghiên cứu AI",
          "D": "Sự phổ biến của các ứng dụng AI trong đời sống hàng ngày"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết khuyến nghị các quốc gia nên làm gì để không bị tụt hậu trong lĩnh vực AI?",
        "options": {
          "A": "Tăng cường đầu tư vào nghiên cứu và phát triển AI",
          "B": "Phát triển các chính sách để thúc đẩy sự phát triển AI",
          "C": "Hợp tác với các quốc gia hàng đầu về AI",
          "D": "Nhập khẩu công nghệ AI từ nước ngoài"
        },
        "answer": "B"
      },
      {
        "question": "Khoảng bao nhiêu phần trăm số người được phỏng vấn làm việc cho các công ty ở khu vực Châu Á - Thái Bình Dương?",
        "options": {
          "A": "Khoảng 10%",
          "B": "Khoảng 20%",
          "C": "Khoảng 30%",
          "D": "Khoảng 40%"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, quốc gia nào có tổ chức Ocean Protocol?",
        "options": {
          "A": "Hàn Quốc",
          "B": "Nhật Bản",
          "C": "Singapore",
          "D": "Trung Quốc"
        },
        "answer": "C"
      }
    ]
  },
  "assembly-line-ai": {
    "title": "Assembly Line AI",
    "collection": "business",
    "content": "Computer vision has been learning how to spot manufacturing flaws. The pandemic is accelerating that education.What’s happening:Companies like Instrumental and Elementary are making AI-powered cameras that automate the spotting of damaged or badly assembled products on factory assembly lines,Wiredreports. (For the record, deeplearning.ai’s sister company Landing AI is, too).How it works:Instrumental’s quality-control system first learns to recognize components in their ideal state and then to identify defects. It can spot faulty screws, disfigured circuit boards, and flaws in the protective coating on smartphone screens.\n\nComing soon:Elementary plans to install robotic cameras in a U.S. Toyota plant. Workers will place a completed part beneath the camera for inspection, then press a button to indicate whether they agree with the robot’s assessment to fine-tune the model.Behind the news:Omron,Cognex, andUSS Visionhave sold non-neural inspection systems for decades. Neural networks are making their way into the field as engineers develop techniques for learning what flaws look like from small numbers of examples.Why it matters:Earlier automated inspection systems use hand-coded rules to identify specific flaws. Machine learning promises to be more adaptable and quicker to deploy. That could speed up assembly lines and cut manufacturing costs.We’re thinking:The ability to learn from small amounts of data is the key to many applications of deep learning that are still beyond reach. We look forward to continued progress in this area.",
    "qa": [
      {
        "question": "Công nghệ computer vision đang được ứng dụng trong lĩnh vực nào?",
        "options": {
          "A": "Phát hiện gian lận tài chính.",
          "B": "Phát hiện lỗi trong sản xuất.",
          "C": "Dự báo thời tiết.",
          "D": "Phân tích dữ liệu mạng xã hội."
        },
        "answer": "B"
      },
      {
        "question": "Đại dịch COVID-19 có tác động như thế nào đến sự phát triển của computer vision trong sản xuất?",
        "options": {
          "A": "Làm chậm quá trình phát triển do thiếu hụt nguồn cung linh kiện.",
          "B": "Không ảnh hưởng đến sự phát triển của công nghệ này.",
          "C": "Thúc đẩy quá trình phát triển.",
          "D": "Làm giảm nhu cầu sử dụng do sản lượng sản xuất giảm."
        },
        "answer": "C"
      },
      {
        "question": "Các công ty như Instrumental và Elementary sử dụng công nghệ gì để phát hiện lỗi sản phẩm?",
        "options": {
          "A": "Cảm biến nhiệt độ.",
          "B": "Máy quét laser.",
          "C": "Camera hỗ trợ bởi trí tuệ nhân tạo (AI).",
          "D": "Hệ thống phân tích rung động."
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống kiểm soát chất lượng của Instrumental hoạt động dựa trên nguyên tắc nào?",
        "options": {
          "A": "So sánh sản phẩm với bản thiết kế gốc.",
          "B": "Học cách nhận biết các thành phần ở trạng thái lý tưởng và sau đó xác định các khuyết tật.",
          "C": "Phân tích thành phần hóa học của sản phẩm.",
          "D": "Kiểm tra độ bền cơ học của sản phẩm."
        },
        "answer": "B"
      },
      {
        "question": "Elementary dự định lắp đặt camera robot tại nhà máy Toyota ở đâu?",
        "options": {
          "A": "Nhật Bản.",
          "B": "Trung Quốc.",
          "C": "Việt Nam.",
          "D": "Mỹ."
        },
        "answer": "D"
      },
      {
        "question": "Mục đích của việc công nhân xác nhận đánh giá của robot trong hệ thống của Elementary là gì?",
        "options": {
          "A": "Để đảm bảo an toàn lao động.",
          "B": "Để tinh chỉnh mô hình AI.",
          "C": "Để kiểm tra độ chính xác của camera.",
          "D": "Để đánh giá hiệu suất làm việc của công nhân."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính giữa hệ thống kiểm tra lỗi sử dụng mạng nơ-ron và hệ thống truyền thống là gì?",
        "options": {
          "A": "Hệ thống mạng nơ-ron có chi phí thấp hơn.",
          "B": "Hệ thống mạng nơ-ron có thể học từ một số lượng nhỏ các ví dụ.",
          "C": "Hệ thống mạng nơ-ron có độ chính xác cao hơn.",
          "D": "Hệ thống mạng nơ-ron dễ dàng cài đặt hơn."
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm của việc sử dụng machine learning trong kiểm tra lỗi sản phẩm là gì?",
        "options": {
          "A": "Giảm thiểu hoàn toàn sai sót trong quá trình sản xuất.",
          "B": "Linh hoạt và triển khai nhanh hơn so với hệ thống dựa trên quy tắc thủ công.",
          "C": "Không cần sự can thiệp của con người.",
          "D": "Tăng cường bảo mật thông tin sản phẩm."
        },
        "answer": "B"
      },
      {
        "question": "Việc ứng dụng machine learning trong kiểm tra lỗi sản phẩm có thể mang lại lợi ích kinh tế nào?",
        "options": {
          "A": "Tăng giá thành sản phẩm.",
          "B": "Giảm chi phí sản xuất.",
          "C": "Tăng chi phí bảo trì máy móc.",
          "D": "Giảm số lượng công nhân."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, yếu tố nào là chìa khóa cho nhiều ứng dụng deep learning vẫn chưa đạt được?",
        "options": {
          "A": "Khả năng xử lý dữ liệu lớn.",
          "B": "Khả năng học hỏi từ một lượng nhỏ dữ liệu.",
          "C": "Khả năng kết nối với internet.",
          "D": "Khả năng tự động cập nhật phần mềm."
        },
        "answer": "B"
      }
    ]
  },
  "auto-diagnosis": {
    "title": "Auto Diagnosis",
    "collection": "business",
    "content": "A drive-through system automatically inspects vehicles for dents, leaks, and low tire pressure.\n\nWhat’s new:General Motors is giving its dealerships an option toinstalla visual inspection system from UVeye. Volvostrucka similar deal with the Tel Aviv startup in March.How it works:UVeye’s technology is designed to cut the time it takes to inspect a vehicle from minutes, possibly hours, to seconds. The company offers three systems to be installed on a service center’s premises for an undisclosed subscription fee.\n\nBehind the news:General Motors and Volvo separately invested undisclosed sums in UVeye, as have Honda, Toyota, and Škoda, a Volkswagen subsidiary. Several General Motors dealers around the U.S. already use its technology for vehicle checkups; the new deal will make it available to all 4,000. Volvo uses UVeye scanners on its assembly lines and offers incentives to dealerships to use them as well.Why it matters:A computer vision system that completes inspections in seconds can free mechanics to focus on more critical tasks, help dealers evaluate trade-ins, and give customers confidence that service stations are addressing real issues.We’re thinking:Autonomous driving is the first automotive application for AI that many people think of, but other important tasks are easier to automate. Streamlining routine maintenance is one. Others includeassessing insurance claimsandoptimizing traffic patterns.",
    "qa": [
      {
        "question": "Hệ thống kiểm tra xe tự động UVeye có khả năng chính nào?",
        "options": {
          "A": "Tự động lái xe đến trạm dịch vụ.",
          "B": "Kiểm tra xe về các vấn đề như móp méo, rò rỉ và áp suất lốp thấp.",
          "C": "Tự động thay thế phụ tùng bị hỏng.",
          "D": "Đánh giá giá trị xe để bán lại."
        },
        "answer": "B"
      },
      {
        "question": "Công ty ô tô nào đã ký thỏa thuận tương tự với UVeye trước General Motors?",
        "options": {
          "A": "Honda",
          "B": "Toyota",
          "C": "Škoda",
          "D": "Volvo"
        },
        "answer": "D"
      },
      {
        "question": "Công nghệ của UVeye giúp giảm thời gian kiểm tra xe như thế nào?",
        "options": {
          "A": "Từ vài giờ xuống còn vài phút.",
          "B": "Từ vài phút, có thể hàng giờ, xuống còn vài giây.",
          "C": "Từ vài ngày xuống còn vài giờ.",
          "D": "Không giảm thời gian, chỉ tăng độ chính xác."
        },
        "answer": "B"
      },
      {
        "question": "UVeye cung cấp bao nhiêu hệ thống để lắp đặt tại các trung tâm dịch vụ?",
        "options": {
          "A": "Một",
          "B": "Hai",
          "C": "Ba",
          "D": "Bốn"
        },
        "answer": "C"
      },
      {
        "question": "Ngoài General Motors và Volvo, những công ty nào khác đã đầu tư vào UVeye?",
        "options": {
          "A": "Ford và Tesla",
          "B": "Honda, Toyota và Škoda",
          "C": "BMW và Mercedes-Benz",
          "D": "Nissan và Hyundai"
        },
        "answer": "B"
      },
      {
        "question": "General Motors dự kiến triển khai công nghệ UVeye cho bao nhiêu đại lý?",
        "options": {
          "A": "1,000",
          "B": "2,000",
          "C": "3,000",
          "D": "4,000"
        },
        "answer": "D"
      },
      {
        "question": "Volvo sử dụng máy quét UVeye ở đâu?",
        "options": {
          "A": "Tại các đại lý để kiểm tra xe của khách hàng.",
          "B": "Trên dây chuyền lắp ráp.",
          "C": "Trong quá trình kiểm tra xe cũ.",
          "D": "Tại các trung tâm đào tạo kỹ thuật viên."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích chính của việc sử dụng hệ thống kiểm tra bằng máy tính UVeye là gì?",
        "options": {
          "A": "Giảm chi phí bảo hiểm xe.",
          "B": "Giúp thợ máy tập trung vào các công việc quan trọng hơn.",
          "C": "Tăng tốc độ sản xuất xe mới.",
          "D": "Cải thiện trải nghiệm lái xe tự động."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài lái xe tự động, ứng dụng tiềm năng nào khác của AI trong ngành ô tô được đề cập trong bài viết?",
        "options": {
          "A": "Thiết kế xe mới.",
          "B": "Đánh giá yêu cầu bồi thường bảo hiểm.",
          "C": "Sản xuất pin xe điện.",
          "D": "Phát triển phần mềm giải trí trên xe."
        },
        "answer": "B"
      },
      {
        "question": "Công ty UVeye có trụ sở tại đâu?",
        "options": {
          "A": "California, USA",
          "B": "Tel Aviv, Israel",
          "C": "Tokyo, Japan",
          "D": "Stuttgart, Germany"
        },
        "answer": "B"
      }
    ]
  },
  "automations-frontier-fast-food": {
    "title": "Automation’s Frontier",
    "collection": "business",
    "content": "Quick-service restaurants are experiencing record-high employee turnover, while labor advocates are pushing for higher wages. Some experts say these forces are propelling the fast food industry toward full automation.\n\nWho’s already automating:The move to put fast food under machine control is already in high gear:\n\nBehind the news:Humans are opting out for the quick-service business. In July, the CEO of Panera Bread told CNBC’s @Work conference that his company experienced nearly100 percent annual employee turnover— and this number was low for the industry. Turnover in the Accommodations and Restaurants category (which includes traditional restaurants as well as hotels) has climbed nearly15 percentover the last decade, according to the U.S. Bureau of Labor Statistics.\n\nWhy it matters:Fast food is shaping up to be a leading edge of an automation wave that could be squeezing lower-skilled, lower-wage employees out of the economy. A 2017 report by the National Council on Compensation Insurance found that, while automation historicallyreplaces human labor, the jobs that remain tend to be higher skilled andbetter compensated.\n\nWe’re thinking:Apps and kiosks are clearly capable of replacing fast-food customer service. Back-of-the-house work like assembling burritos and stacking sandwiches requires more dexterity. While those positions likely persist longer, it may be cold comfort to find yourself automated out of a job five years from now rather than one.",
    "qa": [
      {
        "question": "Ngành công nghiệp nào đang chứng kiến tỷ lệ nhân viên nghỉ việc cao kỷ lục?",
        "options": {
          "A": "Ngành khách sạn",
          "B": "Ngành dịch vụ tài chính",
          "C": "Ngành nhà hàng phục vụ nhanh",
          "D": "Ngành công nghệ thông tin"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, yếu tố nào đang thúc đẩy tự động hóa trong ngành công nghiệp thức ăn nhanh?",
        "options": {
          "A": "Sự phát triển của công nghệ robot",
          "B": "Áp lực tăng lương và tỷ lệ nhân viên nghỉ việc cao",
          "C": "Sự thay đổi trong sở thích của người tiêu dùng",
          "D": "Chính sách hỗ trợ của chính phủ"
        },
        "answer": "B"
      },
      {
        "question": "CEO của Panera Bread đã báo cáo tỷ lệ nhân viên nghỉ việc hàng năm của công ty mình là bao nhiêu?",
        "options": {
          "A": "Gần 50%",
          "B": "Gần 75%",
          "C": "Gần 100%",
          "D": "Hơn 100%"
        },
        "answer": "C"
      },
      {
        "question": "Theo Cục Thống kê Lao động Hoa Kỳ, tỷ lệ nhân viên nghỉ việc trong lĩnh vực Lưu trú và Nhà hàng đã tăng bao nhiêu trong thập kỷ qua?",
        "options": {
          "A": "Gần 5%",
          "B": "Gần 10%",
          "C": "Gần 15%",
          "D": "Gần 20%"
        },
        "answer": "C"
      },
      {
        "question": "Báo cáo năm 2017 của Hội đồng Bảo hiểm Bồi thường Quốc gia (NCCI) cho thấy điều gì về tự động hóa?",
        "options": {
          "A": "Tự động hóa tạo ra nhiều việc làm hơn là thay thế",
          "B": "Tự động hóa chỉ ảnh hưởng đến các công việc có kỹ năng cao",
          "C": "Tự động hóa thay thế lao động thủ công, nhưng các công việc còn lại đòi hỏi kỹ năng cao hơn và được trả lương tốt hơn",
          "D": "Tự động hóa không có tác động đáng kể đến thị trường lao động"
        },
        "answer": "C"
      },
      {
        "question": "Công việc nào trong ngành thức ăn nhanh có khả năng được tự động hóa đầu tiên?",
        "options": {
          "A": "Lắp ráp bánh mì sandwich",
          "B": "Phục vụ khách hàng",
          "C": "Nấu ăn",
          "D": "Quản lý kho"
        },
        "answer": "B"
      },
      {
        "question": "Công việc nào trong ngành thức ăn nhanh được dự đoán sẽ tồn tại lâu hơn trước khi bị tự động hóa?",
        "options": {
          "A": "Phục vụ khách hàng",
          "B": "Lắp ráp burrito",
          "C": "Nhập dữ liệu",
          "D": "Quản lý đơn hàng"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến thuật ngữ 'leading edge' để mô tả vai trò của ngành thức ăn nhanh trong việc gì?",
        "options": {
          "A": "Phát triển công nghệ mới",
          "B": "Tạo ra xu hướng ẩm thực",
          "C": "Dẫn đầu làn sóng tự động hóa",
          "D": "Cải thiện điều kiện làm việc cho nhân viên"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì đang xảy ra với những người lao động có kỹ năng thấp và lương thấp do tự động hóa?",
        "options": {
          "A": "Họ được đào tạo lại để làm các công việc có kỹ năng cao hơn",
          "B": "Họ có nhiều cơ hội việc làm hơn trong các ngành khác",
          "C": "Họ có thể bị loại khỏi nền kinh tế",
          "D": "Họ được trả lương cao hơn để bù đắp cho việc mất việc làm"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết ngụ ý gì về tác động của tự động hóa đối với người lao động trong tương lai?",
        "options": {
          "A": "Tự động hóa sẽ tạo ra nhiều việc làm mới hơn là thay thế",
          "B": "Người lao động nên chuẩn bị cho việc mất việc làm do tự động hóa trong tương lai gần",
          "C": "Tự động hóa sẽ chỉ ảnh hưởng đến một số ít ngành công nghiệp",
          "D": "Người lao động không cần phải lo lắng về tự động hóa vì nó sẽ không ảnh hưởng đến họ"
        },
        "answer": "B"
      }
    ]
  },
  "aws-launches-bedrock-a-generative-ai-platform": {
    "title": "AWS Joins the Generative AI Race",
    "collection": "business",
    "content": "Amazon joined big-tech peers Google, Meta, and Microsoft in rolling out services that provide generated text and images.\n\nWhat’s new:The online retailerlaunchedearly access to Bedrock, a cloud platform that offers generative models built by Amazon and its partners.How it works:Bedrock is aimed at business customers, who can select among image- and text-generation models and fine-tune them for proprietary uses. It’s available to selected customers of Amazon Web Services as a “limited preview.” The price has yet to be announced.\n\nBehind the news:Amazon’s peers offer similar capabilities via their respective cloud services.\n\nWhy it matters:Between Amazon and other cloud computing providers, generative AI rapidly is becoming available to developers of all kinds.We’re thinking:DALL·E 2 and ChatGPT debuted less than a year ago. Generative AI is gathering momentum at warp speed!",
    "qa": [
      {
        "question": "Amazon gia nhập vào lĩnh vực cung cấp dịch vụ tạo văn bản và hình ảnh cùng với những công ty công nghệ lớn nào?",
        "options": {
          "A": "Apple, Samsung, IBM",
          "B": "Google, Meta, Microsoft",
          "C": "Tesla, SpaceX, Netflix",
          "D": "Intel, AMD, Nvidia"
        },
        "answer": "B"
      },
      {
        "question": "Nền tảng đám mây mới được Amazon ra mắt có tên là gì?",
        "options": {
          "A": "Amazon AI Cloud",
          "B": "Bedrock",
          "C": "Amazon Generative Services",
          "D": "AWS AI Platform"
        },
        "answer": "B"
      },
      {
        "question": "Bedrock của Amazon hướng đến đối tượng khách hàng nào?",
        "options": {
          "A": "Người dùng cá nhân",
          "B": "Doanh nghiệp",
          "C": "Các nhà nghiên cứu học thuật",
          "D": "Chính phủ"
        },
        "answer": "B"
      },
      {
        "question": "Khách hàng có thể làm gì với các mô hình được cung cấp trên nền tảng Bedrock?",
        "options": {
          "A": "Sử dụng trực tiếp mà không cần chỉnh sửa",
          "B": "Tinh chỉnh chúng cho các mục đích sử dụng độc quyền",
          "C": "Chia sẻ chúng với cộng đồng",
          "D": "Bán lại chúng cho các doanh nghiệp khác"
        },
        "answer": "B"
      },
      {
        "question": "Bedrock hiện đang ở giai đoạn nào?",
        "options": {
          "A": "Đã được phát hành rộng rãi cho tất cả người dùng",
          "B": "Đang trong giai đoạn 'preview' giới hạn cho một số khách hàng của Amazon Web Services",
          "C": "Đang trong giai đoạn thử nghiệm nội bộ",
          "D": "Đã hoàn thành và chuẩn bị ra mắt chính thức"
        },
        "answer": "B"
      },
      {
        "question": "Thông tin nào sau đây về giá của Bedrock là chính xác?",
        "options": {
          "A": "Đã được công bố rộng rãi",
          "B": "Chưa được công bố",
          "C": "Miễn phí cho tất cả người dùng AWS",
          "D": "Chỉ dành cho khách hàng VIP của Amazon"
        },
        "answer": "B"
      },
      {
        "question": "Các công ty nào khác cung cấp các khả năng tương tự như Bedrock thông qua dịch vụ đám mây của họ?",
        "options": {
          "A": "Chỉ có Amazon",
          "B": "Các đối thủ cạnh tranh của Amazon như Google, Meta và Microsoft",
          "C": "Các công ty phần cứng như Intel và Nvidia",
          "D": "Các công ty thương mại điện tử khác như Alibaba và eBay"
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đang diễn ra nhanh chóng nhờ sự tham gia của Amazon và các nhà cung cấp dịch vụ điện toán đám mây khác?",
        "options": {
          "A": "Sự phát triển của phần cứng máy tính",
          "B": "Sự phổ biến của trí tuệ nhân tạo tạo sinh",
          "C": "Sự suy giảm của các mô hình học máy truyền thống",
          "D": "Sự tăng trưởng của thị trường tiền điện tử"
        },
        "answer": "B"
      },
      {
        "question": "DALL·E 2 và ChatGPT ra mắt cách đây bao lâu?",
        "options": {
          "A": "Hơn 5 năm",
          "B": "Khoảng 1 năm",
          "C": "Khoảng 3 năm",
          "D": "Hơn 10 năm"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về tốc độ phát triển của trí tuệ nhân tạo tạo sinh?",
        "options": {
          "A": "Phát triển chậm và ổn định",
          "B": "Đang tăng tốc với tốc độ chóng mặt",
          "C": "Đã đạt đến đỉnh điểm và đang chậm lại",
          "D": "Phụ thuộc nhiều vào sự phát triển của phần cứng"
        },
        "answer": "B"
      }
    ]
  },
  "banking-on-automation": {
    "title": "Banking on Automation",
    "collection": "business",
    "content": "The UK’s banking industry is using AI in many facets of the business.What’s new:Asurveyof financial firms in the UK found that nearly two-thirds of respondents have deployed machine learning technology. Many said they expect their use to double in the next two years.What the report says:The Bank of England and the UK Financial Conduct Authority sent questionnaires to nearly 300 institutions and got responses from a little over 100 firms offering a variety of services.\n\nBehind the news:AI’s penetration in banking extends well beyond the UK. JPMorgan Chase in its2018 annual reporttold investors it had gone “all in on AI.” HSBC recentlyopeneddata science innovation labs in Toronto and London to help process insights from the 10 petabytes of data its clients generate each year. Citigroup is using AI tofight fraud, Bank of America has an AI-poweredcustomer service bot, and Capital One says ituses AIfrom end to end.Why it matters:Banking and finance tend to fly under the radar in press reports on AI’s role in traditional industries. This report, while specific to the UK, may well correlate with trends in banks around the world.We’re thinking:The report lists nine classes of ML algorithms used by respondents including trees, clustering, neural networks (used in roughly 32 percent of cases), and reinforcement learning (around 15 percent). The category called Other is used around 35 percent of the time. We’re happy to call, say, linear regression an ML algorithm. Given such an expansive definition, though, we imagine that most financial institutions use machine learning in some capacity.",
    "qa": [
      {
        "question": "Theo khảo sát tại Anh, khoảng bao nhiêu phần trăm các công ty tài chính đã triển khai công nghệ học máy?",
        "options": {
          "A": "Gần một phần ba",
          "B": "Gần hai phần ba",
          "C": "Khoảng một nửa",
          "D": "Hơn ba phần tư"
        },
        "answer": "B"
      },
      {
        "question": "Ngân hàng Anh và Cơ quan Quản lý Tài chính Vương quốc Anh đã gửi bảng câu hỏi đến khoảng bao nhiêu tổ chức?",
        "options": {
          "A": "Khoảng 100 tổ chức",
          "B": "Khoảng 200 tổ chức",
          "C": "Gần 300 tổ chức",
          "D": "Hơn 300 tổ chức"
        },
        "answer": "C"
      },
      {
        "question": "Trong báo cáo thường niên năm 2018, JPMorgan Chase đã tuyên bố điều gì về AI?",
        "options": {
          "A": "Đang thử nghiệm AI trong một số lĩnh vực",
          "B": "Đã đầu tư mạnh vào AI",
          "C": "Đang xem xét tiềm năng của AI",
          "D": "Chưa có kế hoạch sử dụng AI"
        },
        "answer": "B"
      },
      {
        "question": "HSBC đã mở các phòng thí nghiệm đổi mới khoa học dữ liệu ở đâu?",
        "options": {
          "A": "London và New York",
          "B": "Toronto và New York",
          "C": "London và Singapore",
          "D": "Toronto và London"
        },
        "answer": "D"
      },
      {
        "question": "Citigroup đang sử dụng AI để làm gì?",
        "options": {
          "A": "Cải thiện dịch vụ khách hàng",
          "B": "Phát hiện gian lận",
          "C": "Quản lý rủi ro",
          "D": "Tự động hóa quy trình làm việc"
        },
        "answer": "B"
      },
      {
        "question": "Bank of America sử dụng loại hình AI nào cho dịch vụ khách hàng?",
        "options": {
          "A": "Hệ thống khuyến nghị",
          "B": "Chatbot hỗ trợ bởi AI",
          "C": "Phân tích dự đoán",
          "D": "Nhận dạng giọng nói"
        },
        "answer": "B"
      },
      {
        "question": "Capital One tuyên bố sử dụng AI như thế nào?",
        "options": {
          "A": "Chỉ trong một số bộ phận nhất định",
          "B": "Từ đầu đến cuối quy trình",
          "C": "Chủ yếu trong bộ phận marketing",
          "D": "Để phân tích dữ liệu khách hàng"
        },
        "answer": "B"
      },
      {
        "question": "Loại thuật toán học máy nào được sử dụng phổ biến nhất theo báo cáo (tần suất khoảng 32%)?",
        "options": {
          "A": "Cây quyết định",
          "B": "Phân cụm",
          "C": "Mạng nơ-ron",
          "D": "Học tăng cường"
        },
        "answer": "C"
      },
      {
        "question": "Theo báo cáo, thuật toán học máy 'Other' được sử dụng với tần suất khoảng bao nhiêu?",
        "options": {
          "A": "Khoảng 15%",
          "B": "Khoảng 25%",
          "C": "Khoảng 35%",
          "D": "Khoảng 45%"
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của báo cáo này là gì?",
        "options": {
          "A": "Chứng minh rằng AI không hiệu quả trong ngành ngân hàng",
          "B": "Đánh giá mức độ sử dụng AI trong ngành ngân hàng ở Anh và có thể trên toàn thế giới",
          "C": "So sánh các thuật toán học máy khác nhau",
          "D": "Khuyến nghị các ngân hàng nên đầu tư vào AI"
        },
        "answer": "B"
      }
    ]
  },
  "battling-bias-in-synthetic-data": {
    "title": "Battling Bias in Synthetic Data",
    "collection": "business",
    "content": "Synthetic datasets can inherit flaws in the real-world data they’re based on. Startups are working on solutions.What’s new:Generating synthetic datasets for training machine learning systems is abooming business. Companies that provide such datasets are exploring ways to avoid perpetuating biases in the source data.How it works:The cost of producing a high-quality training dataset is beyond the reach of some companies, and in situations where sufficient real-world data isn’t available,synthetic datamay be the only option. But such datasets can echo and even amplify biases including potentially harmfulsocial biases. Vendors likeAI.Reverie,GenRocket,Hazy, andMostly AIare looking for ways to adjust their synthetic output — “distorting reality,” as Hazy’s chief executive put it — to minimize the risk that models trained on their wares will result in unfair outcomes.\n\nWhy it matters:Social biases in training datasets often reflect reality. It’s true that altering synthetic datasets to change the balance of, say, men and women who earn high incomes is trading one type of bias for another, rather than eliminating it altogether. The aim here is not necessarily to generate accurate data but to produce fair outcomes.We’re thinking:We need data, but more than that, we need to build models that result in fair outcomes.",
    "qa": [
      {
        "question": "Lý do chính khiến việc tạo ra dữ liệu tổng hợp (synthetic datasets) trở nên phổ biến là gì?",
        "options": {
          "A": "Dữ liệu tổng hợp luôn chính xác hơn dữ liệu thực tế.",
          "B": "Chi phí sản xuất dữ liệu huấn luyện chất lượng cao có thể vượt quá khả năng của một số công ty, và dữ liệu thực tế có thể không đủ.",
          "C": "Dữ liệu tổng hợp dễ dàng được chia sẻ và sử dụng hơn dữ liệu thực tế.",
          "D": "Dữ liệu tổng hợp tự động loại bỏ mọi thiên kiến có trong dữ liệu thực tế."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề tiềm ẩn nào có thể phát sinh khi sử dụng dữ liệu tổng hợp để huấn luyện các hệ thống máy học?",
        "options": {
          "A": "Dữ liệu tổng hợp không thể được sử dụng để huấn luyện các mô hình phức tạp.",
          "B": "Dữ liệu tổng hợp có thể phản ánh và thậm chí khuếch đại các thiên kiến có trong dữ liệu gốc.",
          "C": "Dữ liệu tổng hợp luôn yêu cầu nhiều tài nguyên tính toán hơn dữ liệu thực tế.",
          "D": "Dữ liệu tổng hợp không thể được cập nhật hoặc sửa đổi sau khi được tạo ra."
        },
        "answer": "B"
      },
      {
        "question": "Các công ty như AI.Reverie, GenRocket, Hazy và Mostly AI đang làm gì để giảm thiểu rủi ro từ thiên kiến trong dữ liệu tổng hợp?",
        "options": {
          "A": "Họ đang cố gắng tạo ra dữ liệu tổng hợp hoàn toàn giống với dữ liệu thực tế.",
          "B": "Họ đang điều chỉnh đầu ra tổng hợp của mình để giảm thiểu nguy cơ các mô hình được huấn luyện trên dữ liệu đó dẫn đến kết quả không công bằng.",
          "C": "Họ đang tập trung vào việc thu thập nhiều dữ liệu thực tế hơn để giảm sự phụ thuộc vào dữ liệu tổng hợp.",
          "D": "Họ đang phát triển các thuật toán mới để phát hiện và loại bỏ thiên kiến trong dữ liệu thực tế."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, mục tiêu chính của việc điều chỉnh dữ liệu tổng hợp là gì?",
        "options": {
          "A": "Tạo ra dữ liệu chính xác tuyệt đối so với thực tế.",
          "B": "Tạo ra kết quả công bằng, ngay cả khi điều đó có nghĩa là thay đổi sự cân bằng trong dữ liệu.",
          "C": "Giảm chi phí sản xuất dữ liệu huấn luyện.",
          "D": "Tăng tốc độ huấn luyện các mô hình máy học."
        },
        "answer": "B"
      },
      {
        "question": "Hazy's chief executive mô tả việc điều chỉnh dữ liệu tổng hợp như thế nào?",
        "options": {
          "A": "Tái tạo thực tế.",
          "B": "Phản ánh thực tế.",
          "C": "Bóp méo thực tế.",
          "D": "Nâng cao thực tế."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì quan trọng hơn cả việc có dữ liệu?",
        "options": {
          "A": "Có dữ liệu với số lượng lớn.",
          "B": "Có dữ liệu được thu thập từ nhiều nguồn khác nhau.",
          "C": "Xây dựng các mô hình mang lại kết quả công bằng.",
          "D": "Sử dụng các thuật toán máy học phức tạp nhất."
        },
        "answer": "C"
      },
      {
        "question": "Loại thiên kiến nào được đề cập cụ thể trong bài viết liên quan đến việc điều chỉnh dữ liệu tổng hợp?",
        "options": {
          "A": "Thiên kiến về chủng tộc.",
          "B": "Thiên kiến về giới tính và thu nhập.",
          "C": "Thiên kiến về tôn giáo.",
          "D": "Thiên kiến về vị trí địa lý."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, việc thay đổi sự cân bằng giới tính và thu nhập trong dữ liệu tổng hợp có thể dẫn đến điều gì?",
        "options": {
          "A": "Loại bỏ hoàn toàn mọi thiên kiến.",
          "B": "Tạo ra một loại thiên kiến khác.",
          "C": "Đảm bảo tính chính xác tuyệt đối của dữ liệu.",
          "D": "Tăng tốc độ huấn luyện mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì có thể xảy ra nếu dữ liệu huấn luyện chứa đựng những thiên kiến xã hội?",
        "options": {
          "A": "Các mô hình máy học sẽ luôn đưa ra kết quả chính xác.",
          "B": "Các mô hình máy học có thể khuếch đại những thiên kiến đó và dẫn đến kết quả không công bằng.",
          "C": "Các mô hình máy học sẽ tự động loại bỏ những thiên kiến đó.",
          "D": "Không có ảnh hưởng gì, vì các mô hình máy học chỉ quan tâm đến dữ liệu số."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết này chủ yếu thảo luận về điều gì?",
        "options": {
          "A": "Các phương pháp thu thập dữ liệu thực tế hiệu quả.",
          "B": "Sự phát triển của các thuật toán máy học mới.",
          "C": "Những thách thức và giải pháp liên quan đến việc sử dụng dữ liệu tổng hợp để huấn luyện máy học, đặc biệt là vấn đề thiên kiến.",
          "D": "Tầm quan trọng của việc bảo mật dữ liệu cá nhân."
        },
        "answer": "C"
      }
    ]
  },
  "big-ai-buzz-may-not-equal-profit": {
    "title": "Hype Overshoots Reality",
    "collection": "business",
    "content": "AI companies are soaring on promises they can revolutionize society while making a profit. What if they're flying too close to the sun?\n\nThe fear:The latest models generate publication-worthy essays and award-winning artworks, but it’s not clear how to make them generate enough revenue to both cover their costs and turn a profit. The bubble is bound to burst.Horror stories:During the dot-com bust of 2000, internet stocks tumbled as their underlying weaknesses became apparent. The cryptocurrency crash of 2022 evaporated nearly two-thirds of Bitcoin’s value. Some observers believe that, similarly, today’s hottest AI bets are overhyped and overvalued.\n\nBad omens:Generative AI accomplishes new marvels with each passing month, but that doesn’t necessarily translate into profitable businesses. Investors and analysts are throwing up red flags.\n\nFacing the fear:No one knows what the future will bring, but generative AI’s usefulness, which already has attracted billions of users, continues to evolve at a rapid pace. No doubt, some investments won’t pay off — but many will: The consultancy McKinsey estimated that generative AI could add between $2.6 trillion and $4.4 trillion to the global economy annually. Already generative models form the foundation of conversational assistants, image generators, video effects, and automated coding tools. An avalanche of further applications and refinements appears to be inevitable as the technology continues to advance.",
    "qa": [
      {
        "question": "Bài viết đề cập đến lo ngại chính nào về các công ty AI hiện nay?",
        "options": {
          "A": "Khả năng tạo ra các sản phẩm AI chất lượng thấp.",
          "B": "Khả năng tạo ra đủ doanh thu để trang trải chi phí và tạo lợi nhuận.",
          "C": "Sự thiếu hụt nhân tài trong lĩnh vực AI.",
          "D": "Sự cạnh tranh gay gắt giữa các công ty AI."
        },
        "answer": "B"
      },
      {
        "question": "Sự kiện nào được nhắc đến như một ví dụ về việc bong bóng đầu tư có thể vỡ?",
        "options": {
          "A": "Sự sụp đổ của thị trường bất động sản năm 2008.",
          "B": "Vụ bê bối Enron.",
          "C": "Sự kiện Y2K.",
          "D": "Sự sụp đổ của thị trường dot-com năm 2000."
        },
        "answer": "D"
      },
      {
        "question": "Theo bài viết, điều gì đã xảy ra với giá trị của Bitcoin trong cuộc khủng hoảng tiền điện tử năm 2022?",
        "options": {
          "A": "Giá trị tăng gấp đôi.",
          "B": "Giá trị không thay đổi.",
          "C": "Giá trị giảm khoảng một phần ba.",
          "D": "Giá trị giảm gần hai phần ba."
        },
        "answer": "D"
      },
      {
        "question": "Mặc dù AI tạo sinh đạt được nhiều thành tựu, bài viết nhấn mạnh điều gì?",
        "options": {
          "A": "Các thành tựu này luôn đi kèm với rủi ro về đạo đức.",
          "B": "Các thành tựu này không nhất thiết chuyển thành các doanh nghiệp có lợi nhuận.",
          "C": "Các thành tựu này chỉ giới hạn trong một số lĩnh vực nhất định.",
          "D": "Các thành tựu này đòi hỏi đầu tư rất lớn vào cơ sở hạ tầng."
        },
        "answer": "B"
      },
      {
        "question": "Ai là người đang gióng lên hồi chuông cảnh báo về các khoản đầu tư vào AI tạo sinh?",
        "options": {
          "A": "Các nhà khoa học máy tính.",
          "B": "Các nhà hoạch định chính sách.",
          "C": "Các nhà đầu tư và nhà phân tích.",
          "D": "Các nhà đạo đức học."
        },
        "answer": "C"
      },
      {
        "question": "Theo McKinsey, AI tạo sinh có thể đóng góp bao nhiêu vào nền kinh tế toàn cầu hàng năm?",
        "options": {
          "A": "Từ 100 tỷ đến 500 tỷ đô la.",
          "B": "Từ 500 tỷ đến 1 nghìn tỷ đô la.",
          "C": "Từ 1 nghìn tỷ đến 2 nghìn tỷ đô la.",
          "D": "Từ 2.6 nghìn tỷ đến 4.4 nghìn tỷ đô la."
        },
        "answer": "D"
      },
      {
        "question": "Ứng dụng nào sau đây KHÔNG được đề cập trong bài viết như một ví dụ về ứng dụng của mô hình AI tạo sinh?",
        "options": {
          "A": "Trợ lý đàm thoại.",
          "B": "Công cụ tạo ảnh.",
          "C": "Hiệu ứng video.",
          "D": "Phần mềm thiết kế đồ họa."
        },
        "answer": "D"
      },
      {
        "question": "Bài viết dự đoán điều gì về sự phát triển của AI tạo sinh trong tương lai?",
        "options": {
          "A": "Sự phát triển sẽ chậm lại do thiếu nguồn lực.",
          "B": "Sự phát triển sẽ dừng lại do các vấn đề đạo đức.",
          "C": "Sự phát triển sẽ tiếp tục với vô số ứng dụng và cải tiến.",
          "D": "Sự phát triển sẽ bị hạn chế bởi các quy định pháp lý."
        },
        "answer": "C"
      },
      {
        "question": "Cụm từ 'flying too close to the sun' trong bài viết có nghĩa là gì?",
        "options": {
          "A": "Đạt được thành công quá nhanh chóng.",
          "B": "Đầu tư quá nhiều vào năng lượng mặt trời.",
          "C": "Mạo hiểm quá mức và có thể gặp thất bại.",
          "D": "Phát triển công nghệ quá nhanh chóng."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết thể hiện thái độ gì về tương lai của AI tạo sinh?",
        "options": {
          "A": "Hoàn toàn bi quan và dự đoán sự sụp đổ.",
          "B": "Hoàn toàn lạc quan và dự đoán thành công chắc chắn.",
          "C": "Thận trọng, thừa nhận cả tiềm năng và rủi ro.",
          "D": "Trung lập, chỉ trình bày các sự kiện mà không đưa ra đánh giá."
        },
        "answer": "C"
      }
    ]
  },
  "building-sites-meld-real-and-virtual": {
    "title": "Building Sites Meld Real and Virtual",
    "collection": "business",
    "content": "Everyday cameras and computer vision algorithms are digitizing construction projects to keep builders on schedule.What’s new:Based in Tel Aviv,Buildotsmaps output from building-site cameras onto simulations of the work in progress, enabling construction managers to monitor progress remotely. At least two large European builders are using the system, according toMIT Technology Review.How it works:A client supplies to Buildots blueprints and plans, including schedules and lists of parts, for completion of each task involved in a building project. Buildots supplies GoPro 360-degree cameras mounted atop hardhats.\n\nBehind the news:AI startups are aiming to make the technology as fundamental to the construction industry as steel-toed boots.\n\nWhy it matters:Mistakes can become delays that add to a construction project’s cost. Market research firm McKinseyestimatedthat the construction industry could add $1.6 trillion to the global GDP by catching mistakes before they cause serious delays.We’re thinking:Buildots is bringing new meaning to the phrase “AI architecture.”",
    "qa": [
      {
        "question": "Công ty Buildots có trụ sở chính ở đâu?",
        "options": {
          "A": "London",
          "B": "Tel Aviv",
          "C": "New York",
          "D": "Berlin"
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ của Buildots sử dụng dữ liệu từ đâu để theo dõi tiến độ xây dựng?",
        "options": {
          "A": "Hình ảnh vệ tinh",
          "B": "Camera gắn trên công trường",
          "C": "Drone bay trên công trường",
          "D": "Cảm biến nhiệt độ"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, Buildots cung cấp loại camera nào cho công nhân?",
        "options": {
          "A": "GoPro góc rộng",
          "B": "GoPro 360 độ",
          "C": "Camera hồng ngoại",
          "D": "Camera an ninh thông thường"
        },
        "answer": "B"
      },
      {
        "question": "Buildots đối chiếu dữ liệu từ camera với cái gì để theo dõi tiến độ?",
        "options": {
          "A": "Bản vẽ và kế hoạch xây dựng",
          "B": "Dữ liệu thời tiết",
          "C": "Báo cáo tài chính",
          "D": "Phản hồi từ công nhân"
        },
        "answer": "A"
      },
      {
        "question": "Theo McKinsey, việc phát hiện lỗi sớm trong xây dựng có thể mang lại lợi ích kinh tế như thế nào cho GDP toàn cầu?",
        "options": {
          "A": "Tăng thêm 1.6 tỷ đô la",
          "B": "Tăng thêm 1.6 nghìn tỷ đô la",
          "C": "Giảm 1.6 tỷ đô la",
          "D": "Không ảnh hưởng đến GDP"
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ của Buildots giúp ích cho ai nhiều nhất trong quá trình xây dựng?",
        "options": {
          "A": "Công nhân xây dựng",
          "B": "Nhà cung cấp vật liệu",
          "C": "Người quản lý xây dựng",
          "D": "Kiến trúc sư"
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu của các startup AI trong ngành xây dựng là gì?",
        "options": {
          "A": "Thay thế hoàn toàn công nhân xây dựng",
          "B": "Làm cho công nghệ AI trở nên quan trọng như ủng bảo hộ",
          "C": "Giảm chi phí vật liệu xây dựng",
          "D": "Tăng tốc độ xây dựng gấp đôi"
        },
        "answer": "B"
      },
      {
        "question": "Hai công ty xây dựng lớn nào đang sử dụng hệ thống của Buildots?",
        "options": {
          "A": "Hai công ty ở Bắc Mỹ",
          "B": "Hai công ty ở Châu Âu",
          "C": "Hai công ty ở Châu Á",
          "D": "Hai công ty ở Úc"
        },
        "answer": "B"
      },
      {
        "question": "Camera của Buildots được gắn ở đâu trên người công nhân?",
        "options": {
          "A": "Trên vai",
          "B": "Trên mũ bảo hộ",
          "C": "Trên tay",
          "D": "Trên ngực"
        },
        "answer": "B"
      },
      {
        "question": "Cụm từ 'AI architecture' (kiến trúc AI) trong bài viết mang ý nghĩa gì?",
        "options": {
          "A": "Thiết kế các tòa nhà thông minh",
          "B": "Ứng dụng AI vào quy trình xây dựng",
          "C": "Xây dựng các trung tâm dữ liệu AI",
          "D": "Phát triển phần mềm kiến trúc dựa trên AI"
        },
        "answer": "B"
      }
    ]
  },
  "bureaucracy-chokes-ai-growth-as-lawmakers-tighten-grip": {
    "title": "Innovation Can’t Win",
    "collection": "business",
    "content": "Politicians and pundits have conjured visions of doom to convince lawmakers to clamp down on AI. What if terrified legislators choke off innovation in AI?\n\nThe fear:Laws and treaties that purportedly were intended to prevent harms wrought by AI are making developing new models legally risky and prohibitively expensive. Without room to experiment, AI’s benefits will be strangled by red tape.\n\nHorror stories:At least one law that would have damaged AI innovation and open source has been blocked, but another is already limiting access to technology and raising costs for companies, developers, and users worldwide. More such efforts likely are underway.\n\nHow scared should you be:The veto of SB 1047 was a narrow escape for California and companies and labs that operate there. Yet regulations like the AI Act are poised to reshape how AI is trained and used worldwide. Historysuggeststhat restrictive laws often lead to more caution and less experimentation from technologists.\n\nFacing the fear:AI needs thoughtful regulation to empower developers to help build a better world, avoid harms, and keep learning. But effective regulation of AI requires restrictingapplications, not the underlying technology that enables them. Policymakers should align with a wide range of developers – not just a few that have deep pockets – to address harmful applications without stifling broader progress.",
    "qa": [
      {
        "question": "Theo bài viết, điều gì đang thúc đẩy các nhà lập pháp siết chặt quản lý AI?",
        "options": {
          "A": "Mong muốn thúc đẩy sự đổi mới trong lĩnh vực AI.",
          "B": "Những viễn cảnh đáng sợ được vẽ ra bởi các chính trị gia và chuyên gia.",
          "C": "Áp lực từ các công ty công nghệ lớn muốn kiểm soát thị trường AI.",
          "D": "Yêu cầu từ cộng đồng khoa học về việc đảm bảo an toàn cho người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết lo ngại điều gì về các luật và hiệp ước liên quan đến AI?",
        "options": {
          "A": "Chúng không đủ mạnh để ngăn chặn những tác hại tiềm tàng của AI.",
          "B": "Chúng có thể làm cho việc phát triển các mô hình AI mới trở nên tốn kém và rủi ro về mặt pháp lý.",
          "C": "Chúng khuyến khích các công ty tập trung vào các ứng dụng AI có hại.",
          "D": "Chúng không được thực thi một cách hiệu quả."
        },
        "answer": "B"
      },
      {
        "question": "SB 1047 là gì và tại sao nó lại quan trọng?",
        "options": {
          "A": "Một đạo luật nhằm thúc đẩy sự phát triển của AI ở California.",
          "B": "Một đạo luật đã bị chặn, có thể gây tổn hại đến sự đổi mới và mã nguồn mở AI.",
          "C": "Một hiệp ước quốc tế về việc sử dụng AI trong quân sự.",
          "D": "Một tiêu chuẩn kỹ thuật cho việc phát triển các mô hình AI an toàn."
        },
        "answer": "B"
      },
      {
        "question": "Đạo luật AI (AI Act) được đề cập trong bài viết có khả năng ảnh hưởng đến AI như thế nào?",
        "options": {
          "A": "Thúc đẩy sự phát triển của AI bằng cách cung cấp nguồn tài trợ lớn.",
          "B": "Đơn giản hóa quy trình pháp lý cho các công ty AI.",
          "C": "Định hình lại cách AI được đào tạo và sử dụng trên toàn thế giới.",
          "D": "Đảm bảo rằng tất cả các hệ thống AI đều tuân thủ các tiêu chuẩn đạo đức."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, các luật hạn chế có thể ảnh hưởng đến các nhà công nghệ như thế nào?",
        "options": {
          "A": "Khuyến khích họ tìm kiếm các giải pháp sáng tạo hơn.",
          "B": "Dẫn đến sự thận trọng hơn và ít thử nghiệm hơn.",
          "C": "Buộc họ phải chuyển hoạt động sang các quốc gia có quy định lỏng lẻo hơn.",
          "D": "Giúp họ tập trung vào các ứng dụng AI an toàn và có đạo đức hơn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết cho rằng điều gì là cần thiết để AI phát triển một cách có lợi?",
        "options": {
          "A": "Loại bỏ hoàn toàn mọi quy định để thúc đẩy sự đổi mới.",
          "B": "Quy định chặt chẽ đối với công nghệ nền tảng của AI.",
          "C": "Quy định có suy nghĩ để trao quyền cho các nhà phát triển xây dựng một thế giới tốt đẹp hơn.",
          "D": "Chỉ cho phép các công ty lớn với nguồn lực dồi dào phát triển AI."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề xuất cách tiếp cận nào để quản lý AI hiệu quả?",
        "options": {
          "A": "Hạn chế công nghệ nền tảng của AI.",
          "B": "Hạn chế các ứng dụng cụ thể của AI.",
          "C": "Tập trung vào việc trừng phạt các công ty vi phạm quy định.",
          "D": "Để thị trường tự điều chỉnh mà không cần sự can thiệp của chính phủ."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh tầm quan trọng của việc hợp tác với ai trong việc xây dựng các quy định về AI?",
        "options": {
          "A": "Chỉ các công ty lớn có nguồn lực dồi dào.",
          "B": "Một loạt các nhà phát triển, không chỉ những người có nguồn lực dồi dào.",
          "C": "Các chính trị gia và chuyên gia pháp lý.",
          "D": "Các tổ chức phi chính phủ và các nhóm bảo vệ quyền lợi người tiêu dùng."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của việc quản lý AI, theo bài viết, là gì?",
        "options": {
          "A": "Ngăn chặn sự phát triển của AI hoàn toàn.",
          "B": "Thúc đẩy sự tiến bộ rộng rãi trong lĩnh vực AI đồng thời giải quyết các ứng dụng có hại.",
          "C": "Đảm bảo rằng chỉ các công ty lớn mới có thể tiếp cận công nghệ AI.",
          "D": "Tối đa hóa lợi nhuận cho các nhà đầu tư vào AI."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì có thể xảy ra nếu các nhà lập pháp quá sợ hãi và hạn chế sự đổi mới trong AI?",
        "options": {
          "A": "AI sẽ phát triển nhanh hơn và an toàn hơn.",
          "B": "Lợi ích của AI sẽ bị kìm hãm bởi các thủ tục hành chính.",
          "C": "Các công ty sẽ tìm cách lách luật và phát triển AI một cách bí mật.",
          "D": "Người tiêu dùng sẽ được bảo vệ tốt hơn khỏi những rủi ro tiềm ẩn của AI."
        },
        "answer": "B"
      }
    ]
  },
  "business-pushes-the-envelope": {
    "title": "Business Pushes the Envelope",
    "collection": "business",
    "content": "The business world continues to shape deep learning’s future.What’s new:Commerce is pushing AI toward more efficient consumption of data, energy, and labor, according to areporton trends in machine learning from market analyst CB Insights.What they think:The report draws on a variety of sources including records of mergers and acquisitions, investment tallies, and patent filings. Among its conclusions:\n\nWe’re thinking:It’s great to see today’s research findings find their way into tomorrow’s commercial applications. The road from the AI lab to marketplace gets busier all the time.",
    "qa": [
      {
        "question": "Theo báo cáo của CB Insights, yếu tố nào đang thúc đẩy AI hướng tới việc sử dụng hiệu quả hơn?",
        "options": {
          "A": "Sự phát triển của các thuật toán mới.",
          "B": "Thương mại.",
          "C": "Nhu cầu nghiên cứu khoa học.",
          "D": "Sự gia tăng của dữ liệu lớn."
        },
        "answer": "B"
      },
      {
        "question": "Báo cáo của CB Insights dựa trên những nguồn thông tin nào?",
        "options": {
          "A": "Các bài báo khoa học và phỏng vấn chuyên gia.",
          "B": "Hồ sơ sáp nhập và mua lại, thống kê đầu tư và hồ sơ bằng sáng chế.",
          "C": "Khảo sát người tiêu dùng và báo cáo tài chính của các công ty.",
          "D": "Dữ liệu từ mạng xã hội và các diễn đàn trực tuyến."
        },
        "answer": "B"
      },
      {
        "question": "Báo cáo của CB Insights đề cập đến xu hướng nào trong lĩnh vực machine learning?",
        "options": {
          "A": "Sự suy giảm đầu tư vào AI do lo ngại về đạo đức.",
          "B": "AI hướng tới việc sử dụng hiệu quả hơn dữ liệu, năng lượng và lao động.",
          "C": "Sự tập trung vào phát triển AI tổng quát (AGI) thay vì AI hẹp.",
          "D": "Sự gia tăng sử dụng AI trong lĩnh vực quân sự."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì được coi là một dấu hiệu tích cực trong bài viết?",
        "options": {
          "A": "Sự gia tăng số lượng bằng sáng chế AI.",
          "B": "Nghiên cứu tìm đường vào các ứng dụng thương mại.",
          "C": "Sự hợp tác giữa các phòng thí nghiệm AI và các công ty lớn.",
          "D": "Sự phát triển của các công cụ AI mã nguồn mở."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về con đường từ phòng thí nghiệm AI đến thị trường?",
        "options": {
          "A": "Con đường này đang trở nên khó khăn hơn do các quy định pháp lý.",
          "B": "Con đường này ngày càng trở nên bận rộn hơn.",
          "C": "Con đường này vẫn còn rất dài và nhiều thách thức.",
          "D": "Con đường này đang được rút ngắn nhờ sự hỗ trợ của chính phủ."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của việc sử dụng AI hiệu quả hơn là gì?",
        "options": {
          "A": "Giảm chi phí nghiên cứu và phát triển.",
          "B": "Tối ưu hóa việc tiêu thụ dữ liệu, năng lượng và lao động.",
          "C": "Tăng cường khả năng cạnh tranh của các doanh nghiệp.",
          "D": "Thúc đẩy sự đổi mới trong lĩnh vực công nghệ."
        },
        "answer": "B"
      },
      {
        "question": "Loại hình phân tích nào được CB Insights sử dụng trong báo cáo của họ?",
        "options": {
          "A": "Phân tích tâm lý học hành vi.",
          "B": "Phân tích thị trường.",
          "C": "Phân tích rủi ro tài chính.",
          "D": "Phân tích mạng xã hội."
        },
        "answer": "B"
      },
      {
        "question": "Ai là đối tượng hưởng lợi chính từ việc ứng dụng các nghiên cứu AI vào thương mại?",
        "options": {
          "A": "Các nhà nghiên cứu AI.",
          "B": "Các doanh nghiệp và người tiêu dùng.",
          "C": "Các nhà đầu tư mạo hiểm.",
          "D": "Chính phủ và các tổ chức phi lợi nhuận."
        },
        "answer": "B"
      },
      {
        "question": "Báo cáo của CB Insights có thể giúp ích gì cho các doanh nghiệp?",
        "options": {
          "A": "Dự đoán chính xác xu hướng thị trường chứng khoán.",
          "B": "Hiểu rõ hơn về các xu hướng trong lĩnh vực machine learning.",
          "C": "Tự động hóa hoàn toàn quy trình sản xuất.",
          "D": "Bảo vệ dữ liệu cá nhân của khách hàng tốt hơn."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì ngụ ý về tương lai của deep learning trong bối cảnh thương mại?",
        "options": {
          "A": "Deep learning sẽ dần được thay thế bởi các công nghệ AI khác.",
          "B": "Thế giới kinh doanh tiếp tục định hình tương lai của deep learning.",
          "C": "Deep learning sẽ chỉ được ứng dụng trong một số ngành công nghiệp nhất định.",
          "D": "Deep learning sẽ trở nên quá phức tạp để ứng dụng trong thực tế."
        },
        "answer": "B"
      }
    ]
  },
  "bye-bye-bots": {
    "title": "Bye Bye Bots",
    "collection": "business",
    "content": "The independent research lab OpenAI wowed technology watchers in 2019 with a robotic hand that solved Rubik’s Cube. Now it has disbanded the team that built it.\n\nWhat’s new:OpenAI cofounder Wojciech Zaremba revealed that OpenAI shuttered its robotics program last October.\n\nRobo retrenchment:In apodcastproduced byWeights & Biases, a maker of AI development tools, Zaremba said a lack of data was holding back OpenAI’s progress in robotics. The company’s broad goal is to develop artificial general intelligence, and it believes it can make more progress by focusing on approaches such as reinforcement learning with human feedback, a representative toldVentureBeat.\n\nBehind the news:OpenAI previously developed arobotics simulation environment, areinforcement learning toolkit, andtechniquesfor training robots.\n\nWhy it matters:The robotics industry has seen several high-profile players struggle with the high cost of research and development. In recent years, Honda shuttered itsAsimo subsidiary,Rethink Roboticsclosed up shop, and Boston Robotics, famous for itsacrobatic bipedsandresilient quadrupeds, repeatedlychanged hands.\n\nWe’re thinking:When even a fleet of robots isn’t able to generate enough data, that’s a sign of how data-hungry our algorithms are. It’s also a reminder of how far the current state of the art is from human-level AI. After all, infants have only one body’s worth of data to learn from.",
    "qa": [
      {
        "question": "Phòng thí nghiệm OpenAI đã gây ấn tượng với giới công nghệ vào năm 2019 bằng thành tựu nào?",
        "options": {
          "A": "Phát triển một hệ thống trí tuệ nhân tạo có khả năng viết văn.",
          "B": "Chế tạo một cánh tay robot có thể giải Rubik's Cube.",
          "C": "Xây dựng một môi trường mô phỏng robot tiên tiến.",
          "D": "Phát triển một thuật toán học tăng cường vượt trội."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, OpenAI đã đóng cửa chương trình robot của mình vào thời điểm nào?",
        "options": {
          "A": "Tháng 12 năm 2022.",
          "B": "Tháng 10 năm 2023.",
          "C": "Tháng 8 năm 2023.",
          "D": "Tháng 11 năm 2022."
        },
        "answer": "B"
      },
      {
        "question": "Lý do chính được Wojciech Zaremba đưa ra cho việc OpenAI ngừng chương trình robot là gì?",
        "options": {
          "A": "Chi phí nghiên cứu và phát triển quá cao.",
          "B": "Thiếu nguồn nhân lực có trình độ chuyên môn phù hợp.",
          "C": "Thiếu dữ liệu để cải thiện tiến độ trong lĩnh vực robot.",
          "D": "Công nghệ robot hiện tại không còn phù hợp với mục tiêu phát triển trí tuệ nhân tạo tổng quát."
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu rộng lớn mà OpenAI hướng đến là gì?",
        "options": {
          "A": "Phát triển các thuật toán học tăng cường tiên tiến.",
          "B": "Xây dựng các hệ thống robot tự động hóa hoàn toàn.",
          "C": "Phát triển trí tuệ nhân tạo tổng quát (AGI).",
          "D": "Tạo ra các môi trường mô phỏng robot thực tế."
        },
        "answer": "C"
      },
      {
        "question": "OpenAI tin rằng họ có thể đạt được tiến bộ tốt hơn bằng cách tập trung vào phương pháp nào?",
        "options": {
          "A": "Học có giám sát với dữ liệu lớn.",
          "B": "Học tăng cường với phản hồi từ con người.",
          "C": "Học sâu với mạng nơ-ron phức tạp.",
          "D": "Học không giám sát với dữ liệu phi cấu trúc."
        },
        "answer": "B"
      },
      {
        "question": "Trước đây, OpenAI đã phát triển những công cụ và kỹ thuật nào liên quan đến robot?",
        "options": {
          "A": "Hệ thống điều khiển robot bằng giọng nói.",
          "B": "Môi trường mô phỏng robot, bộ công cụ học tăng cường và kỹ thuật huấn luyện robot.",
          "C": "Các cảm biến robot siêu nhạy.",
          "D": "Phần mềm lập trình robot trực quan."
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào nổi tiếng với những robot nhào lộn và robot bốn chân kiên cường đã nhiều lần đổi chủ?",
        "options": {
          "A": "Rethink Robotics.",
          "B": "Honda.",
          "C": "Boston Dynamics.",
          "D": "Asimo."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì cho thấy thuật toán hiện tại rất 'đói' dữ liệu?",
        "options": {
          "A": "Sự phát triển chậm chạp của trí tuệ nhân tạo.",
          "B": "Việc robot không thể tự học hỏi từ môi trường xung quanh.",
          "C": "Việc ngay cả một đội robot cũng không thể tạo ra đủ dữ liệu.",
          "D": "Sự phụ thuộc vào dữ liệu được tạo ra bởi con người."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết sử dụng hình ảnh so sánh nào để nhấn mạnh khoảng cách giữa trí tuệ nhân tạo hiện tại và trí tuệ của con người?",
        "options": {
          "A": "So sánh với khả năng học hỏi của động vật.",
          "B": "So sánh với khả năng giải quyết vấn đề của người lớn.",
          "C": "So sánh với khả năng học hỏi của trẻ sơ sinh.",
          "D": "So sánh với khả năng thích nghi của thực vật."
        },
        "answer": "C"
      },
      {
        "question": "Ngoài OpenAI, công ty nào khác trong lĩnh vực robot cũng đã phải đóng cửa hoặc thu hẹp quy mô hoạt động?",
        "options": {
          "A": "Google DeepMind.",
          "B": "Nvidia.",
          "C": "Rethink Robotics và Honda.",
          "D": "Amazon Robotics."
        },
        "answer": "C"
      }
    ]
  },
  "cars-idled-av-makers-keep-rolling": {
    "title": "Cars Idled, AV Makers Keep Rolling",
    "collection": "business",
    "content": "The pandemic has forced self-driving car companies off the road. Now they’re moving forward by refining their mountains of training data.What’s new:Self-driving cars typically collect real-world training data with two human operators onboard, but Covid-19 makes that unsafe at any speed. Instead, several companies are squeezing more value out of work they’ve already done, according toMIT Technology Review.What they’re doing:Makers of autonomous vehicles are relabeling old data and fine-tuning simulations.\n\nBehind the news:With little income, $1.6 million in average monthly overhead, and increasingly tight funding, autonomous vehicle companies are making tough choices. Lyft, Kodiak Robotics, and Ike havelaid off employees, whileZooxis looking for a buyer.Why it matters:Data can be a renewable resource: By adding new labels and sharpening old ones, AI teams can imbue old datasets with new life. Using refurbished datasets to improve simulations compounds the effect.We’re thinking:Development of self-driving cars had moved into the slow lane even before the pandemic. It’s better to keep making incremental progress than none at all.",
    "qa": [
      {
        "question": "Đại dịch COVID-19 đã ảnh hưởng đến các công ty xe tự lái như thế nào?",
        "options": {
          "A": "Giúp họ tăng tốc quá trình thử nghiệm trên đường.",
          "B": "Buộc họ phải tạm dừng thử nghiệm thực tế trên đường.",
          "C": "Cho phép họ tuyển dụng thêm nhân viên với chi phí thấp hơn.",
          "D": "Khiến họ chuyển sang sản xuất các loại xe khác."
        },
        "answer": "B"
      },
      {
        "question": "Các công ty xe tự lái đang làm gì để tiếp tục phát triển trong bối cảnh đại dịch?",
        "options": {
          "A": "Tập trung vào việc phát triển phần cứng mới.",
          "B": "Tăng cường hợp tác với các công ty sản xuất ô tô truyền thống.",
          "C": "Tối ưu hóa và tái sử dụng dữ liệu huấn luyện hiện có.",
          "D": "Chuyển sang nghiên cứu các công nghệ tự động hóa khác."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, việc thu thập dữ liệu huấn luyện xe tự lái truyền thống thường được thực hiện như thế nào?",
        "options": {
          "A": "Sử dụng hệ thống camera giám sát giao thông.",
          "B": "Thông qua các cuộc khảo sát người dùng.",
          "C": "Với hai người điều khiển trên xe để thu thập dữ liệu thực tế.",
          "D": "Bằng cách mô phỏng các tình huống giao thông khác nhau."
        },
        "answer": "C"
      },
      {
        "question": "Những khó khăn tài chính nào mà các công ty xe tự lái đang phải đối mặt?",
        "options": {
          "A": "Chi phí bảo trì phần cứng tăng cao.",
          "B": "Doanh thu giảm sút và chi phí hoạt động lớn.",
          "C": "Khó khăn trong việc tìm kiếm nguồn cung ứng linh kiện.",
          "D": "Sự cạnh tranh gay gắt từ các công ty công nghệ lớn."
        },
        "answer": "B"
      },
      {
        "question": "Những công ty nào được đề cập trong bài viết đã phải sa thải nhân viên hoặc tìm kiếm người mua?",
        "options": {
          "A": "Tesla, Waymo, Cruise.",
          "B": "Lyft, Kodiak Robotics, Ike, Zoox.",
          "C": "Uber, Aurora, Argo AI.",
          "D": "Nuro, Pony.ai, TuSimple."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về dữ liệu trong bối cảnh phát triển xe tự lái?",
        "options": {
          "A": "Dữ liệu mới luôn cần thiết để đạt được tiến bộ.",
          "B": "Dữ liệu cũ không còn giá trị sau một thời gian.",
          "C": "Dữ liệu có thể được tái sử dụng và làm mới để tạo ra giá trị mới.",
          "D": "Dữ liệu chỉ có giá trị khi được thu thập trong điều kiện thực tế."
        },
        "answer": "C"
      },
      {
        "question": "Việc cải thiện mô phỏng bằng dữ liệu được làm mới có tác dụng gì?",
        "options": {
          "A": "Giảm chi phí bảo trì hệ thống.",
          "B": "Tăng tốc độ xử lý dữ liệu.",
          "C": "Nâng cao hiệu quả và độ chính xác của quá trình huấn luyện.",
          "D": "Giảm thiểu rủi ro tai nạn trong quá trình thử nghiệm."
        },
        "answer": "C"
      },
      {
        "question": "Trước đại dịch, sự phát triển của xe tự lái đã diễn ra như thế nào?",
        "options": {
          "A": "Đã đạt được những bước tiến vượt bậc.",
          "B": "Đang trong giai đoạn thử nghiệm cuối cùng.",
          "C": "Đã bắt đầu được thương mại hóa rộng rãi.",
          "D": "Đã chậm lại so với kỳ vọng ban đầu."
        },
        "answer": "D"
      },
      {
        "question": "Theo bài viết, thái độ phù hợp nhất trong bối cảnh khó khăn hiện tại đối với ngành xe tự lái là gì?",
        "options": {
          "A": "Chờ đợi đến khi tình hình kinh tế ổn định hơn.",
          "B": "Chấp nhận thất bại và từ bỏ dự án.",
          "C": "Tiếp tục tiến bộ dù chậm.",
          "D": "Tìm kiếm các lĩnh vực kinh doanh mới."
        },
        "answer": "C"
      },
      {
        "question": "Trong bài viết, thuật ngữ 'relabelling old data' (gán nhãn lại dữ liệu cũ) có nghĩa là gì?",
        "options": {
          "A": "Xóa bỏ các dữ liệu cũ và thay thế bằng dữ liệu mới.",
          "B": "Thay đổi định dạng của dữ liệu để dễ dàng xử lý hơn.",
          "C": "Bổ sung hoặc chỉnh sửa thông tin mô tả cho dữ liệu hiện có.",
          "D": "Di chuyển dữ liệu sang một hệ thống lưu trữ mới."
        },
        "answer": "C"
      }
    ]
  },
  "cb-insights-annual-list-of-the-100-most-promising-ai-startups": {
    "title": "What Venture Investors Want",
    "collection": "business",
    "content": "This year’s crop of hot startups shows that generative AI isn’t the only game in town.\n\nWhat’s new:CB Insights, which tracks the tech-startup economy,releasedthe 2023 edition of its annual AI 100, a list of 100 notable AI-powered ventures. The researchers considered 9,000 startups and selected 100 standouts based on criteria such as investors, business partners, research and development activity, and press reports.Where the action is:The list divides roughly evenly into three categories: Startups that offer tools for AI development, those that address cross-industry functions, and those that serve a particular industry. The names of the companies are noteworthy, but the markets they serve are more telling.\n\nFollow the money:Together, these startups have raised $22 billion in 223 deals since 2019. (Microsoft’s investment in OpenAI accounts for a whopping $13 billion of that total.) Half are in the very early stages.\n\nWhy it matters:Venture funding drives a significant portion of the AI industry. That means opportunities for practitioners at both hot ventures and me-too companies that seek to cultivate similar markets. The startup scene is volatile — as the difference between this year’s andlast year’s AI100demonstrates — but each crop of new firms yields a few long-term winners.We’re thinking:Startup trends are informative, but the options for building a career in AI are far broader. Established companies increasingly recognize their need for AI talent, and fresh research opens new applications. Let your interests lead you to opportunities that excite and inspire you.",
    "qa": [
      {
        "question": "Theo bài viết, mục đích chính của danh sách AI 100 do CB Insights công bố là gì?",
        "options": {
          "A": "Xếp hạng các công ty AI dựa trên doanh thu hàng năm.",
          "B": "Liệt kê 100 công ty khởi nghiệp AI đáng chú ý nhất.",
          "C": "Dự đoán xu hướng phát triển của ngành công nghiệp AI trong tương lai.",
          "D": "Đánh giá hiệu quả đầu tư vào các công ty AI."
        },
        "answer": "B"
      },
      {
        "question": "CB Insights đã sử dụng những tiêu chí nào để lựa chọn 100 công ty khởi nghiệp AI vào danh sách AI 100 năm 2023?",
        "options": {
          "A": "Doanh thu, lợi nhuận và số lượng nhân viên.",
          "B": "Nhà đầu tư, đối tác kinh doanh, hoạt động nghiên cứu và phát triển, và báo cáo trên báo chí.",
          "C": "Số lượng bằng sáng chế, giải thưởng và chứng nhận.",
          "D": "Mức độ sử dụng công nghệ AI trong sản phẩm và dịch vụ."
        },
        "answer": "B"
      },
      {
        "question": "Danh sách AI 100 được chia thành mấy loại công ty khởi nghiệp AI chính?",
        "options": {
          "A": "2",
          "B": "3",
          "C": "4",
          "D": "5"
        },
        "answer": "B"
      },
      {
        "question": "Loại công ty khởi nghiệp AI nào KHÔNG được đề cập đến trong danh sách phân loại của AI 100?",
        "options": {
          "A": "Công ty cung cấp công cụ phát triển AI.",
          "B": "Công ty phục vụ các chức năng liên ngành.",
          "C": "Công ty phục vụ một ngành công nghiệp cụ thể.",
          "D": "Công ty tập trung vào nghiên cứu AI cơ bản."
        },
        "answer": "D"
      },
      {
        "question": "Tổng số vốn mà các công ty khởi nghiệp trong danh sách AI 100 đã huy động được kể từ năm 2019 là bao nhiêu?",
        "options": {
          "A": "$13 tỷ",
          "B": "$9 tỷ",
          "C": "$22 tỷ",
          "D": "$35 tỷ"
        },
        "answer": "C"
      },
      {
        "question": "Khoản đầu tư lớn nhất vào một công ty AI được đề cập trong bài viết là của công ty nào và vào công ty nào?",
        "options": {
          "A": "Google vào DeepMind",
          "B": "Amazon vào Anthropic",
          "C": "Microsoft vào OpenAI",
          "D": "Apple vào Siri"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, phần lớn các công ty khởi nghiệp trong danh sách AI 100 đang ở giai đoạn phát triển nào?",
        "options": {
          "A": "Giai đoạn tăng trưởng nhanh.",
          "B": "Giai đoạn rất sớm.",
          "C": "Giai đoạn mở rộng thị trường.",
          "D": "Giai đoạn thoái vốn."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao nguồn vốn đầu tư mạo hiểm lại quan trọng đối với ngành công nghiệp AI?",
        "options": {
          "A": "Nó giúp các công ty AI trả lương cao cho nhân viên.",
          "B": "Nó thúc đẩy một phần đáng kể sự phát triển của ngành.",
          "C": "Nó đảm bảo sự thành công của tất cả các công ty AI.",
          "D": "Nó giúp các công ty AI tránh được phá sản."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về sự biến động của thị trường khởi nghiệp AI?",
        "options": {
          "A": "Sự ổn định và khả năng dự đoán cao.",
          "B": "Sự thay đổi lớn giữa các năm, thể hiện qua sự khác biệt giữa các danh sách AI 100.",
          "C": "Sự tập trung vào một số ít công ty lớn.",
          "D": "Sự thiếu hụt nguồn vốn đầu tư."
        },
        "answer": "B"
      },
      {
        "question": "Lời khuyên chính mà bài viết đưa ra cho những người muốn xây dựng sự nghiệp trong lĩnh vực AI là gì?",
        "options": {
          "A": "Tập trung vào các công ty khởi nghiệp hot nhất.",
          "B": "Tìm kiếm cơ hội phù hợp với sở thích và đam mê cá nhân.",
          "C": "Ưu tiên các công ty đã thành lập với danh tiếng tốt.",
          "D": "Chỉ làm việc trong các lĩnh vực nghiên cứu AI cơ bản."
        },
        "answer": "B"
      }
    ]
  },
  "ces-2024-showcased-ais-reach-beyond-browsers-and-smartphones": {
    "title": "AI Busts Out at CES",
    "collection": "business",
    "content": "The 2024 Consumer Electronics Show in Las Vegas showcased products that take advantage of increasingly powerful, increasingly accessible AI capabilities.\n\nWhat’s new:Many debuts at themassiveCES show showed that large language models (LLMs) are moving beyond browsers and smartphones.\n\nBest of show:The show’s surprise hit was a portable personal assistant. LLM-powered automobile dashboards and an AI accelerator card also stood out.\n\nWhy it matters:Flashy CES demos often mask underdeveloped products and vaporware. But this year, AI for processing voice, text, and images is mature enough to enable product designers to focus on everyday use cases and intuitive user experiences. While some of this year’s AI-powered debuts seemed like overkill — for instance, the computer vision-equippedFlappiecat door that won’t open while your pet has a mouse in its jaws — others suggest that startups and giants alike are rethinking the technology’s capacity to simplify and enhance daily life and work.\n\nWe’re thinking:Not long ago, simply connecting a home appliance to the internet earned the designation “smart.” Increasingly, AI is making that label credible.",
    "qa": [
      {
        "question": "Sự kiện CES 2024 tại Las Vegas tập trung vào điều gì?",
        "options": {
          "A": "Các sản phẩm điện tử tiêu dùng có thiết kế đột phá.",
          "B": "Các sản phẩm tận dụng khả năng AI ngày càng mạnh mẽ và dễ tiếp cận.",
          "C": "Các sản phẩm gia dụng thông minh kết nối internet.",
          "D": "Các sản phẩm phần cứng máy tính có hiệu năng cao."
        },
        "answer": "B"
      },
      {
        "question": "Xu hướng mới nào được thể hiện rõ tại CES 2024 liên quan đến LLMs?",
        "options": {
          "A": "LLMs chỉ được sử dụng trên các thiết bị di động.",
          "B": "LLMs đang vượt ra khỏi phạm vi trình duyệt và điện thoại thông minh.",
          "C": "LLMs đang dần thay thế các công cụ tìm kiếm truyền thống.",
          "D": "LLMs được tích hợp vào tất cả các thiết bị điện tử tiêu dùng."
        },
        "answer": "B"
      },
      {
        "question": "Sản phẩm nào được xem là điểm nhấn bất ngờ tại CES 2024?",
        "options": {
          "A": "Một chiếc ô tô tự lái hoàn toàn bằng AI.",
          "B": "Một trợ lý cá nhân di động.",
          "C": "Một hệ thống nhà thông minh tích hợp AI.",
          "D": "Một robot gia dụng có khả năng học hỏi."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì khiến AI trở nên quan trọng trong các sản phẩm được giới thiệu tại CES 2024?",
        "options": {
          "A": "AI giúp tăng tính thẩm mỹ cho sản phẩm.",
          "B": "AI cho phép các nhà thiết kế tập trung vào trải nghiệm người dùng trực quan và các ứng dụng thực tế.",
          "C": "AI giúp giảm giá thành sản phẩm.",
          "D": "AI giúp tăng tuổi thọ pin cho các thiết bị di động."
        },
        "answer": "B"
      },
      {
        "question": "Ví dụ về sản phẩm AI nào được đề cập trong bài viết có thể được xem là 'thừa thãi'?",
        "options": {
          "A": "Hệ thống điều khiển bằng giọng nói cho ô tô.",
          "B": "Cửa cho mèo Flappie có trang bị computer vision.",
          "C": "Trợ lý ảo cá nhân có khả năng học hỏi thói quen người dùng.",
          "D": "Card tăng tốc AI cho máy tính cá nhân."
        },
        "answer": "B"
      },
      {
        "question": "Các công ty, cả startup và tập đoàn lớn, đang suy nghĩ lại về điều gì liên quan đến AI?",
        "options": {
          "A": "Khả năng của AI trong việc thay thế con người.",
          "B": "Khả năng của AI trong việc đơn giản hóa và nâng cao cuộc sống và công việc hàng ngày.",
          "C": "Khả năng của AI trong việc tạo ra các sản phẩm giải trí mới.",
          "D": "Khả năng của AI trong việc bảo vệ dữ liệu cá nhân."
        },
        "answer": "B"
      },
      {
        "question": "Trước đây, một thiết bị được coi là 'thông minh' khi nào?",
        "options": {
          "A": "Khi nó có khả năng tự học hỏi.",
          "B": "Khi nó được kết nối với internet.",
          "C": "Khi nó có thể tương tác với người dùng bằng giọng nói.",
          "D": "Khi nó có thể thực hiện các tác vụ tự động."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì đang làm cho nhãn 'thông minh' trở nên đáng tin cậy hơn?",
        "options": {
          "A": "Sự phát triển của công nghệ 5G.",
          "B": "Sự ra đời của các thiết bị đeo thông minh.",
          "C": "Sự ứng dụng ngày càng rộng rãi của trí tuệ nhân tạo (AI).",
          "D": "Sự cải thiện về hiệu suất pin của các thiết bị điện tử."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc sử dụng AI trong các sản phẩm hiện nay là gì?",
        "options": {
          "A": "Tạo ra các sản phẩm phức tạp và khó sử dụng.",
          "B": "Đơn giản hóa và nâng cao cuộc sống hàng ngày.",
          "C": "Tăng cường khả năng bảo mật của thiết bị.",
          "D": "Giảm chi phí sản xuất sản phẩm."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì thường bị che giấu đằng sau những màn trình diễn hào nhoáng tại CES?",
        "options": {
          "A": "Giá thành sản phẩm quá cao.",
          "B": "Các sản phẩm chưa được phát triển đầy đủ và các sản phẩm 'ảo'.",
          "C": "Sự thiếu hụt về nguồn cung linh kiện.",
          "D": "Các vấn đề về bản quyền và sở hữu trí tuệ."
        },
        "answer": "B"
      }
    ]
  },
  "chinese-tech-companies-race-to-cash-in-on-chatgpt-fever": {
    "title": "China Chases Chatbots",
    "collection": "business",
    "content": "ChatGPT fever has reached China despite legal and technical barriers.\n\nWhat’s new:Two months after its debut, ChatGPT is a viral sensation on Chinese social media,MIT Technology Reviewreported. Companies in that country are racing to cash in.\n\nPrompt:OpenAI doesn’t serve the model in China, but users there are reaching it through virtual private networks and offshore services that charge a fee per prompt. The chatbot reportedly impressed users in China with its ability to answer prompts in Chinese and its grasp of the country’s popular culture.\n\nOutput:The country’s major tech firms in recent weeks revealed plans to provide their own equivalent services.\n\nBehind the news:Using an earlier generation of technology, Microsoft Research in China developed Xiaoice, a chatbot that continues to enjoy widespread use. More recently, Beijing Academy of Artificial Intelligence developed the 1.75 trillion-parameter WuDao 2.0. Nonetheless, Chinese researchers face unique obstacles in natural language processing.\n\nWhy it matters:ChatGPT, Microsoft’s Bing chat, Google’s Bard, and other chatbots built by U.S. tech companies are optimized for the English language. Chinese tech companies are scrambling to capitalize on the public’s hunger for a chatbot that’s compatible with their language and culture.\n\nWe’re thinking:Chinese speakers find ChatGPT exciting despite its relative lack of training in their language. When a model is sufficiently large, a large training corpus enables it to generalize to new languages that may not have much training data. This property offers hope for making large language models work with languages that have far less data than Chinese.",
    "qa": [
      {
        "question": "Điều gì đang xảy ra với ChatGPT ở Trung Quốc mặc dù có những rào cản pháp lý và kỹ thuật?",
        "options": {
          "A": "ChatGPT hoàn toàn bị cấm sử dụng.",
          "B": "ChatGPT đang trở thành một hiện tượng lan truyền trên mạng xã hội.",
          "C": "ChatGPT chỉ được sử dụng bởi các công ty công nghệ lớn.",
          "D": "ChatGPT đang được thay thế hoàn toàn bằng các chatbot nội địa."
        },
        "answer": "B"
      },
      {
        "question": "Người dùng ở Trung Quốc truy cập ChatGPT bằng cách nào?",
        "options": {
          "A": "Thông qua các dịch vụ được OpenAI cung cấp trực tiếp.",
          "B": "Thông qua mạng riêng ảo (VPN) và các dịch vụ nước ngoài tính phí cho mỗi yêu cầu.",
          "C": "Thông qua các ứng dụng được chính phủ Trung Quốc phê duyệt.",
          "D": "Thông qua các phiên bản ChatGPT được chỉnh sửa và bản địa hóa."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã gây ấn tượng cho người dùng Trung Quốc về ChatGPT?",
        "options": {
          "A": "Khả năng dịch thuật chính xác sang tiếng Anh.",
          "B": "Khả năng trả lời các câu hỏi bằng tiếng Trung và hiểu biết về văn hóa đại chúng của đất nước.",
          "C": "Khả năng tạo ra các tác phẩm nghệ thuật độc đáo.",
          "D": "Khả năng lập trình các ứng dụng phức tạp."
        },
        "answer": "B"
      },
      {
        "question": "Các công ty công nghệ lớn của Trung Quốc đang làm gì để đáp ứng sự quan tâm đến chatbot?",
        "options": {
          "A": "Hợp tác với OpenAI để phát triển phiên bản ChatGPT dành riêng cho Trung Quốc.",
          "B": "Phát triển các dịch vụ tương đương của riêng họ.",
          "C": "Tập trung vào việc cải thiện các chatbot hiện có sử dụng công nghệ cũ.",
          "D": "Chờ đợi sự cho phép của chính phủ để nhập khẩu ChatGPT."
        },
        "answer": "B"
      },
      {
        "question": "Chatbot Xiaoice được phát triển bởi tổ chức nào?",
        "options": {
          "A": "OpenAI.",
          "B": "Microsoft Research in China.",
          "C": "Google.",
          "D": "Beijing Academy of Artificial Intelligence."
        },
        "answer": "B"
      },
      {
        "question": "WuDao 2.0 là một mô hình ngôn ngữ lớn được phát triển bởi tổ chức nào?",
        "options": {
          "A": "Microsoft Research in China.",
          "B": "OpenAI.",
          "C": "Google.",
          "D": "Beijing Academy of Artificial Intelligence."
        },
        "answer": "D"
      },
      {
        "question": "Một trong những thách thức độc đáo mà các nhà nghiên cứu Trung Quốc phải đối mặt trong xử lý ngôn ngữ tự nhiên là gì?",
        "options": {
          "A": "Sự thiếu hụt tài năng trong lĩnh vực trí tuệ nhân tạo.",
          "B": "Những hạn chế về phần cứng và cơ sở hạ tầng.",
          "C": "Những rào cản pháp lý và quy định nghiêm ngặt.",
          "D": "Những trở ngại đặc thù trong xử lý ngôn ngữ tự nhiên."
        },
        "answer": "D"
      },
      {
        "question": "Các chatbot do các công ty công nghệ Hoa Kỳ xây dựng được tối ưu hóa cho ngôn ngữ nào?",
        "options": {
          "A": "Tiếng Trung.",
          "B": "Tiếng Anh.",
          "C": "Tiếng Nhật.",
          "D": "Tiếng Tây Ban Nha."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao các công ty công nghệ Trung Quốc đang tranh giành để tận dụng sự quan tâm của công chúng đối với chatbot?",
        "options": {
          "A": "Vì họ muốn cạnh tranh với các công ty công nghệ Hoa Kỳ.",
          "B": "Vì họ nhận thấy nhu cầu lớn về một chatbot tương thích với ngôn ngữ và văn hóa của họ.",
          "C": "Vì chính phủ Trung Quốc khuyến khích phát triển trí tuệ nhân tạo.",
          "D": "Vì họ muốn xuất khẩu chatbot sang các quốc gia khác."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất điều gì về khả năng của các mô hình ngôn ngữ lớn đối với các ngôn ngữ có ít dữ liệu huấn luyện?",
        "options": {
          "A": "Các mô hình ngôn ngữ lớn không thể hoạt động hiệu quả với các ngôn ngữ có ít dữ liệu huấn luyện.",
          "B": "Một lượng lớn dữ liệu huấn luyện cho phép mô hình khái quát hóa sang các ngôn ngữ mới, ngay cả khi có ít dữ liệu huấn luyện.",
          "C": "Cần phải thu thập thêm dữ liệu huấn luyện cho tất cả các ngôn ngữ trước khi có thể sử dụng các mô hình ngôn ngữ lớn.",
          "D": "Các mô hình ngôn ngữ nhỏ hơn hiệu quả hơn cho các ngôn ngữ có ít dữ liệu huấn luyện."
        },
        "answer": "B"
      }
    ]
  },
  "chipotle-tests-ai-for-predicting-customer-demand": {
    "title": "Food Forecaster",
    "collection": "business",
    "content": "The ability to predict customer demand could make fast food even faster.\n\nWhat's new:The Mexican-themed Chipotle restaurant chain is testing AI tools that forecast demand, monitor ingredients, and ensure that workers fill orders correctly, according toQSR Magazine, a restaurant trade publication.\n\nHow it works:Eight Chipotle locations in California will employ tools from New York-based startupPreciTaste, which offers systems designed to boost efficiency in restaurants, bakeries, and food manufacturers. On the AI menu:\n\nBehind the news:The fast-food industry’s focus on efficiency has made it a proving ground for a variety of AI applications.\n\nWhy it matters:Fast-food outlets in the U.S. are facing historicshortagesof labor — a ripe market for startups that aim to automate food prep. The captains of fast-food have taken notice: PreciTastecountsthe CEOs of McDonald’s, Burger King, and Shake Shack among its investors.\n\nWe're thinking:It’s good to see industrial AI used to help employees do their work better rather than to do it for them. Perhaps increasingly automated eateries will spur competition to emphasize the human touch.",
    "qa": [
      {
        "question": "Công nghệ AI đang được thử nghiệm tại Chipotle nhằm mục đích chính nào?",
        "options": {
          "A": "Thay thế hoàn toàn nhân viên trong nhà bếp.",
          "B": "Dự đoán nhu cầu của khách hàng và tối ưu hóa quy trình làm việc.",
          "C": "Tạo ra các món ăn mới và độc đáo hơn.",
          "D": "Giảm giá thành sản phẩm để thu hút khách hàng."
        },
        "answer": "B"
      },
      {
        "question": "Công ty PreciTaste có trụ sở tại đâu?",
        "options": {
          "A": "California",
          "B": "New York",
          "C": "Texas",
          "D": "Florida"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, tạp chí nào đã đưa tin về việc Chipotle thử nghiệm công nghệ AI?",
        "options": {
          "A": "Forbes",
          "B": "The Wall Street Journal",
          "C": "QSR Magazine",
          "D": "Restaurant Business"
        },
        "answer": "C"
      },
      {
        "question": "Ứng dụng AI của PreciTaste không hướng đến đối tượng nào sau đây?",
        "options": {
          "A": "Nhà hàng",
          "B": "Tiệm bánh",
          "C": "Nhà máy sản xuất thực phẩm",
          "D": "Cửa hàng bán lẻ quần áo"
        },
        "answer": "D"
      },
      {
        "question": "Điều gì khiến ngành công nghiệp thức ăn nhanh trở thành 'proving ground' cho các ứng dụng AI?",
        "options": {
          "A": "Sự đa dạng trong thực đơn.",
          "B": "Sự cạnh tranh khốc liệt giữa các thương hiệu.",
          "C": "Sự tập trung vào hiệu quả và tốc độ phục vụ.",
          "D": "Sự sẵn sàng chấp nhận rủi ro trong đầu tư công nghệ."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến vấn đề nào mà các cửa hàng thức ăn nhanh ở Mỹ đang phải đối mặt?",
        "options": {
          "A": "Sự cạnh tranh gay gắt từ các nhà hàng cao cấp.",
          "B": "Tình trạng thiếu hụt lao động trầm trọng.",
          "C": "Sự thay đổi trong khẩu vị của khách hàng.",
          "D": "Sự gia tăng chi phí nguyên vật liệu."
        },
        "answer": "B"
      },
      {
        "question": "Các CEO của những chuỗi thức ăn nhanh nào được đề cập là nhà đầu tư của PreciTaste?",
        "options": {
          "A": "KFC, Pizza Hut, Taco Bell",
          "B": "McDonald's, Burger King, Wendy's",
          "C": "McDonald's, Burger King, Shake Shack",
          "D": "Subway, Domino's, Starbucks"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết thể hiện quan điểm gì về việc sử dụng AI trong ngành công nghiệp?",
        "options": {
          "A": "AI nên thay thế hoàn toàn con người để tăng hiệu quả.",
          "B": "AI nên được sử dụng để hỗ trợ nhân viên làm việc tốt hơn, thay vì thay thế họ.",
          "C": "AI chỉ nên được sử dụng trong các công đoạn đơn giản, lặp đi lặp lại.",
          "D": "AI nên được sử dụng để tạo ra các món ăn độc đáo và phức tạp hơn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết gợi ý điều gì về tác động tiềm năng của việc tự động hóa trong ngành nhà hàng?",
        "options": {
          "A": "Sẽ làm giảm sự tương tác giữa nhân viên và khách hàng.",
          "B": "Sẽ dẫn đến sự đồng nhất hóa trong trải nghiệm ăn uống.",
          "C": "Có thể thúc đẩy sự cạnh tranh để nhấn mạnh yếu tố con người.",
          "D": "Sẽ làm tăng giá thành sản phẩm do chi phí đầu tư công nghệ."
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu chính của PreciTaste là gì?",
        "options": {
          "A": "Phát triển các công thức nấu ăn mới.",
          "B": "Tăng cường hiệu quả hoạt động trong ngành thực phẩm.",
          "C": "Giảm thiểu lãng phí thực phẩm.",
          "D": "Cải thiện trải nghiệm khách hàng."
        },
        "answer": "B"
      }
    ]
  },
  "claude-3-7-sonnet-introduces-hybrid-reasoning-and-extended-thinking": {
    "title": "Budget for Reasoning to the Token",
    "collection": "ml-research",
    "content": "Anthropic’s Claude 3.7 Sonnet implements a reasoning approach that lets users decide how much thinking they want the model to do before it renders a response.\n\nWhat’s new:Claude 3.7 Sonnetwas trained for strong performance in coding and front-end web development, with less emphasis on math and computer-science competition problems. It lets users toggle between immediate responses andextended thinking mode, which can improve outputs by allocating a specific number of tokens to reasoning at inference. Like DeepSeek-R1 and Google Gemini Flash Thinking — and unlike OpenAI o1 — Claude 3.7 Sonnet fully displays reasoning tokens. Anthropic considers this functionality experimental, so it may change.\n\nHow it works:Anthropic pretrained Claude 3.7 Sonnet on a mix of public and proprietary data (which explicitly did not include Claude users’ inputs and outputs). The team fine-tuned Claude 3.7 Sonnet usingconstitutional AI, which encourages a model to follow a set of human-crafted rules.\n\nPerformance:Claude 3.7 Sonnet shows exceptional performance in general knowledge, software engineering, and agentic tasks.\n\nBehind the news:Anthropic’s approach refines earlier efforts to enable users to control the incremental expense of computing extra tokens at inference. For instance, OpenAI o1 offers three levels of reasoning or “effort” — each of which allocates more tokens to reasoning — while X’sGrok 3offers two.\n\nWhy it matters:Test-time compute, or additional processing at inference, is powerful but expensive, and not all tasks benefit from it. So it’s helpful to let users choose how much to apply. Claude 3.7 Sonnet improves its predecessor’s general performance and provides an ample budget for additional reasoning.\n\nWe’re thinking:The cost of inference is rising as agentic workflows and other compute-intensive tasks become more widely used. Yet the cost of AI on a per-token basis isfallingrapidly. Intelligence is becoming steadily cheaper and more plentiful.",
    "qa": [
      {
        "question": "Điểm mới của Claude 3.7 Sonnet so với các phiên bản trước là gì?",
        "options": {
          "A": "Khả năng giải quyết các bài toán toán học và khoa học máy tính phức tạp.",
          "B": "Cho phép người dùng tùy chỉnh mức độ suy luận của mô hình trước khi đưa ra phản hồi.",
          "C": "Sử dụng dữ liệu đầu vào và đầu ra của người dùng Claude để huấn luyện.",
          "D": "Không hiển thị các token suy luận trong quá trình hoạt động."
        },
        "answer": "B"
      },
      {
        "question": "Claude 3.7 Sonnet được huấn luyện để đạt hiệu suất cao trong lĩnh vực nào?",
        "options": {
          "A": "Toán học và khoa học máy tính.",
          "B": "Phát triển web front-end và lập trình.",
          "C": "Nghiên cứu y học và sinh học.",
          "D": "Phân tích tài chính và kinh tế."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp huấn luyện nào được sử dụng để tinh chỉnh Claude 3.7 Sonnet?",
        "options": {
          "A": "Reinforcement learning.",
          "B": "Generative adversarial networks (GANs).",
          "C": "Constitutional AI.",
          "D": "Self-supervised learning."
        },
        "answer": "C"
      },
      {
        "question": "Dữ liệu huấn luyện ban đầu của Claude 3.7 Sonnet bao gồm những gì?",
        "options": {
          "A": "Dữ liệu độc quyền của Anthropic và dữ liệu đầu vào/đầu ra của người dùng Claude.",
          "B": "Dữ liệu công khai và dữ liệu độc quyền của Anthropic, loại trừ dữ liệu người dùng Claude.",
          "C": "Chỉ dữ liệu công khai được thu thập từ internet.",
          "D": "Dữ liệu được tạo ra bởi các mô hình AI khác."
        },
        "answer": "B"
      },
      {
        "question": "Trong bối cảnh bài viết, 'test-time compute' đề cập đến điều gì?",
        "options": {
          "A": "Chi phí phần cứng cần thiết để chạy mô hình.",
          "B": "Quá trình xử lý bổ sung trong quá trình suy luận.",
          "C": "Thời gian cần thiết để huấn luyện mô hình.",
          "D": "Số lượng token tối đa mà mô hình có thể xử lý."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích của việc cho phép người dùng lựa chọn mức độ suy luận của mô hình là gì?",
        "options": {
          "A": "Để giảm độ chính xác của kết quả đầu ra.",
          "B": "Để tăng chi phí vận hành mô hình.",
          "C": "Để tối ưu hóa chi phí và hiệu quả cho các tác vụ khác nhau.",
          "D": "Để đơn giản hóa quá trình sử dụng mô hình."
        },
        "answer": "C"
      },
      {
        "question": "Claude 3.7 Sonnet thể hiện hiệu suất vượt trội trong những lĩnh vực nào?",
        "options": {
          "A": "Chỉ trong lĩnh vực kiến thức tổng quát.",
          "B": "Chỉ trong lĩnh vực kỹ thuật phần mềm.",
          "C": "Chỉ trong lĩnh vực tác vụ đại diện (agentic tasks).",
          "D": "Kiến thức tổng quát, kỹ thuật phần mềm và tác vụ đại diện."
        },
        "answer": "D"
      },
      {
        "question": "Điểm khác biệt giữa Claude 3.7 Sonnet và OpenAI o1 trong việc hiển thị token suy luận là gì?",
        "options": {
          "A": "Cả hai đều không hiển thị token suy luận.",
          "B": "Cả hai đều hiển thị đầy đủ token suy luận.",
          "C": "Claude 3.7 Sonnet hiển thị đầy đủ, còn OpenAI o1 thì không.",
          "D": "OpenAI o1 hiển thị đầy đủ, còn Claude 3.7 Sonnet thì không."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì đang xảy ra với chi phí của trí tuệ nhân tạo (AI)?",
        "options": {
          "A": "Chi phí AI trên mỗi token đang tăng nhanh.",
          "B": "Chi phí AI trên mỗi token đang giảm nhanh.",
          "C": "Chi phí AI đang ổn định và không có nhiều thay đổi.",
          "D": "Chi phí AI chỉ giảm đối với các mô hình nhỏ."
        },
        "answer": "B"
      },
      {
        "question": "Ví dụ nào được đưa ra trong bài viết về các mô hình khác cho phép người dùng kiểm soát mức độ suy luận?",
        "options": {
          "A": "Chỉ DeepSeek-R1.",
          "B": "Chỉ Google Gemini Flash Thinking.",
          "C": "OpenAI o1 và X's Grok 3.",
          "D": "Chỉ Claude 3.7 Sonnet."
        },
        "answer": "C"
      }
    ]
  },
  "cloudflares-ai-labyrinth-traps-scrapers-with-decoy-pages": {
    "title": "Scraping the Web? Beware the Maze",
    "collection": "business",
    "content": "Bots that scrape websites for AI training data often ignore do-not-crawl requests. Now web publishers can enforce such appeals by luring scrapers to AI-generated decoy pages.\n\nWhat’s new:Cloudflare launchedAI Labyrinth, a bot-management tool that serves fake pages to unwanted bots, wasting their computational resources and making them easier to detect. It’s currently free to Cloudflare users.\n\nHow it works:AI Labyrinth protects webpages by embedding them with hidden links to AI-generated alternatives that appear legitimate to bots but are irrelevant to the protected site.\n\nBehind the news:The robots.txt instructions that tell web crawlers which pages they can access aren’t legally binding, and web crawlers can disregard them. However, online publishers aremovingto try to stop AI developers from training models on their content. Cloudflare, as the proxy server and content delivery network for nearly20 percentof websites, plays a potentially large role in this movement. AI crawlers account for nearly 1 percent of web requests on Cloudflare’s network, the company says.\n\nWhy it matters:The latest AI models are trained on huge quantities of data gleaned from the web, which enables them to perform well enough to be widely useful. However, publishers increasingly aim to limit access to this data. AI Labyrinth gives them a new tool that raises the cost for bots that disregard instructions not to scrape web content.\n\nWe’re thinking:If AI Labyrinth gains traction, no doubt some teams that build crawlers will respond with their own AI models to sniff out its decoy pages. To the extent that the interest between crawlers and publishers is misaligned and clear, enforceable rules for crawling are lacking, this cat-and-mouse competition could go on for a long time.",
    "qa": [
      {
        "question": "Công cụ AI Labyrinth của Cloudflare có chức năng chính là gì?",
        "options": {
          "A": "Tăng tốc độ tải trang web cho người dùng.",
          "B": "Cung cấp các trang web giả mạo cho các bot thu thập dữ liệu trái phép.",
          "C": "Phân tích lưu lượng truy cập web để phát hiện các mối đe dọa bảo mật.",
          "D": "Tối ưu hóa nội dung trang web để cải thiện thứ hạng tìm kiếm."
        },
        "answer": "B"
      },
      {
        "question": "AI Labyrinth hoạt động bằng cách nào để bảo vệ các trang web?",
        "options": {
          "A": "Mã hóa nội dung trang web để ngăn chặn truy cập trái phép.",
          "B": "Chặn tất cả các bot truy cập vào trang web.",
          "C": "Nhúng các liên kết ẩn đến các trang web do AI tạo ra.",
          "D": "Yêu cầu bot phải xác thực danh tính trước khi truy cập."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao các hướng dẫn robots.txt không phải lúc nào cũng ngăn chặn được việc thu thập dữ liệu web?",
        "options": {
          "A": "Các hướng dẫn này quá phức tạp để các bot hiểu được.",
          "B": "Các hướng dẫn này chỉ áp dụng cho các công cụ tìm kiếm lớn.",
          "C": "Các hướng dẫn này không có tính ràng buộc pháp lý.",
          "D": "Các hướng dẫn này chỉ có hiệu quả với các trang web nhỏ."
        },
        "answer": "C"
      },
      {
        "question": "Cloudflare đóng vai trò gì trong việc ngăn chặn việc thu thập dữ liệu web trái phép?",
        "options": {
          "A": "Là một công cụ tìm kiếm cạnh tranh với Google.",
          "B": "Là một nhà cung cấp dịch vụ lưu trữ web lớn nhất thế giới.",
          "C": "Là một proxy server và mạng phân phối nội dung cho một phần lớn các trang web.",
          "D": "Là một công ty chuyên phát triển các mô hình AI tiên tiến."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, lưu lượng truy cập từ các AI crawler chiếm khoảng bao nhiêu phần trăm trên mạng lưới của Cloudflare?",
        "options": {
          "A": "Gần 50 phần trăm.",
          "B": "Gần 20 phần trăm.",
          "C": "Gần 10 phần trăm.",
          "D": "Gần 1 phần trăm."
        },
        "answer": "D"
      },
      {
        "question": "Tại sao các nhà xuất bản ngày càng muốn hạn chế quyền truy cập vào dữ liệu web của họ?",
        "options": {
          "A": "Để tăng doanh thu quảng cáo trực tuyến.",
          "B": "Để ngăn chặn việc sao chép nội dung trái phép.",
          "C": "Để hạn chế việc đào tạo các mô hình AI trên nội dung của họ.",
          "D": "Để cải thiện trải nghiệm người dùng trên trang web của họ."
        },
        "answer": "C"
      },
      {
        "question": "AI Labyrinth có thể mang lại lợi ích gì cho các nhà xuất bản web?",
        "options": {
          "A": "Giảm chi phí lưu trữ web.",
          "B": "Tăng tốc độ tải trang web.",
          "C": "Tăng chi phí cho các bot thu thập dữ liệu trái phép.",
          "D": "Cải thiện thứ hạng tìm kiếm trên Google."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết dự đoán điều gì về tương lai của cuộc chiến giữa các crawler và các nhà xuất bản?",
        "options": {
          "A": "Các nhà xuất bản sẽ sớm chiến thắng nhờ các công cụ như AI Labyrinth.",
          "B": "Các crawler sẽ ngừng thu thập dữ liệu web trái phép.",
          "C": "Cuộc cạnh tranh này có thể tiếp diễn trong một thời gian dài do thiếu các quy tắc rõ ràng.",
          "D": "Các công cụ tìm kiếm sẽ can thiệp để giải quyết tranh chấp."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì có thể xảy ra nếu AI Labyrinth trở nên phổ biến?",
        "options": {
          "A": "Cloudflare sẽ trở thành công ty công nghệ lớn nhất thế giới.",
          "B": "Các trang web sẽ trở nên an toàn hơn bao giờ hết.",
          "C": "Các đội ngũ xây dựng crawler sẽ phát triển các mô hình AI để phát hiện các trang web giả mạo.",
          "D": "Các nhà xuất bản sẽ ngừng sử dụng robots.txt."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc đào tạo các mô hình AI trên lượng lớn dữ liệu web là gì?",
        "options": {
          "A": "Để tạo ra các trang web có nội dung phong phú hơn.",
          "B": "Để cải thiện khả năng bảo mật của các trang web.",
          "C": "Để các mô hình AI hoạt động đủ tốt để được sử dụng rộng rãi.",
          "D": "Để giảm chi phí phát triển các mô hình AI."
        },
        "answer": "C"
      }
    ]
  },
  "code-generation-services-took-off-in-2022": {
    "title": "Programmer’s Best Friend",
    "collection": "business",
    "content": "Behind schedule on a software project? There’s an app for that.What happened:Language models fine-tuned on computer code proved capable of generating software routines similar to the work of experienced developers — though the results can be hit-or-miss.\n\nDriving the story:AI-powered code generators made their way into large companies, and even small-time developers (and non-developers) gained access to them.\n\nBehind the news:Users of OpenAI’s GPT-3 language model showed that it couldgenerate working codeas early as mid-2020. A year later, OpenAI introduced a fine-tuned version known asCodex, which serves as the foundation for GitHub's Copilot.\n\nYes, but:The widely available versions of this technology aren’t yet able to write complex programs. Often their output looks right at first glance but turns out to be buggy. Moreover, their legal status may be in jeopardy. A class-action lawsuit against GitHub, OpenAI, and Microsoft claims that the training of Codex violated open source licensing agreements. The outcome could have legal implications for models that generate text, images, and other media as well.\n\nWhere things stand:AI-powered coding tools aren’t likely to replace human programmers in the near future, but they may replace the tech question-and-answer site Stack Overflow as the developer’s favorite crutch.",
    "qa": [
      {
        "question": "Vấn đề nào được đề cập đến khi bắt đầu đoạn văn liên quan đến dự án phần mềm?",
        "options": {
          "A": "Thiếu nhân lực lập trình viên.",
          "B": "Chậm trễ so với tiến độ.",
          "C": "Ngân sách vượt quá dự kiến.",
          "D": "Yêu cầu kỹ thuật thay đổi liên tục."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã chứng minh khả năng của các mô hình ngôn ngữ được tinh chỉnh trên mã máy tính?",
        "options": {
          "A": "Tự động sửa lỗi phần mềm.",
          "B": "Tạo ra các quy trình phần mềm tương tự như công việc của các nhà phát triển giàu kinh nghiệm.",
          "C": "Tối ưu hóa hiệu suất của phần mềm hiện có.",
          "D": "Phát hiện các lỗ hổng bảo mật trong mã nguồn."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã thúc đẩy sự lan rộng của các trình tạo mã được hỗ trợ bởi AI?",
        "options": {
          "A": "Sự ra đời của các ngôn ngữ lập trình mới dễ học.",
          "B": "Sự gia tăng số lượng lập trình viên chuyên nghiệp.",
          "C": "Việc các công ty lớn và cả các nhà phát triển nhỏ lẻ tiếp cận được chúng.",
          "D": "Sự giảm giá thành của phần cứng máy tính."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình ngôn ngữ nào của OpenAI được đề cập đến như một bước khởi đầu cho khả năng tạo mã?",
        "options": {
          "A": "ChatGPT.",
          "B": "DALL-E 2.",
          "C": "GPT-3.",
          "D": "Whisper."
        },
        "answer": "C"
      },
      {
        "question": "Codex, một phiên bản tinh chỉnh của OpenAI, đóng vai trò là nền tảng cho công cụ nào?",
        "options": {
          "A": "Stack Overflow.",
          "B": "GitHub Copilot.",
          "C": "Microsoft Visual Studio.",
          "D": "Google Colab."
        },
        "answer": "B"
      },
      {
        "question": "Một hạn chế quan trọng của các phiên bản công khai của công nghệ tạo mã AI là gì?",
        "options": {
          "A": "Khó sử dụng và đòi hỏi kiến thức chuyên môn sâu.",
          "B": "Chưa có khả năng viết các chương trình phức tạp và thường có lỗi.",
          "C": "Yêu cầu phần cứng máy tính mạnh mẽ để hoạt động.",
          "D": "Chỉ hỗ trợ một số ít ngôn ngữ lập trình."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề pháp lý nào đang được đặt ra liên quan đến việc đào tạo Codex?",
        "options": {
          "A": "Vi phạm quyền sở hữu trí tuệ của các công ty phần mềm lớn.",
          "B": "Vi phạm các thỏa thuận cấp phép mã nguồn mở.",
          "C": "Sử dụng dữ liệu cá nhân trái phép để đào tạo mô hình.",
          "D": "Gây ra sự cạnh tranh không lành mạnh trên thị trường lao động."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả của vụ kiện chống lại GitHub, OpenAI và Microsoft có thể ảnh hưởng đến những lĩnh vực nào khác?",
        "options": {
          "A": "Chỉ ảnh hưởng đến lĩnh vực phát triển phần mềm.",
          "B": "Chỉ ảnh hưởng đến các mô hình tạo mã.",
          "C": "Các mô hình tạo văn bản, hình ảnh và các phương tiện khác.",
          "D": "Chỉ ảnh hưởng đến các công ty công nghệ lớn."
        },
        "answer": "C"
      },
      {
        "question": "Theo đoạn văn, công cụ hỗ trợ lập trình bằng AI có khả năng thay thế điều gì?",
        "options": {
          "A": "Các nhà phát triển phần mềm.",
          "B": "Các ngôn ngữ lập trình truyền thống.",
          "C": "Các công cụ gỡ lỗi phần mềm.",
          "D": "Trang web hỏi đáp kỹ thuật Stack Overflow."
        },
        "answer": "D"
      },
      {
        "question": "Trong tương lai gần, vai trò của các công cụ hỗ trợ lập trình bằng AI được dự đoán như thế nào?",
        "options": {
          "A": "Thay thế hoàn toàn các lập trình viên.",
          "B": "Trở thành công cụ không thể thiếu cho mọi lập trình viên.",
          "C": "Hỗ trợ và nâng cao hiệu quả công việc của lập trình viên, nhưng không thay thế họ.",
          "D": "Chỉ được sử dụng trong các dự án phần mềm quy mô nhỏ."
        },
        "answer": "C"
      }
    ]
  },
  "colleague-in-the-machine": {
    "title": "Colleague in the Machine",
    "collection": "business",
    "content": "Your next coworker may be an algorithmic teammate with a virtual face.What’s new:WorkFusionunveileda line of AI tools that automate daily business tasks. One thing that sets them apart is the marketing pitch: Each has a fictitious persona including a name, face (and accompanying live-action video), and professional résumé.How it works:WorkFusion offers a cadre of six systems it touts asvirtual teammates. Each is dedicated to a role such as customer service coordinator and performs rote tasks such as entering data or extracting information from documents. At this point, their personas are superficial — they don’t affect a system’s operation, just the way it’s presented to potential customers.\n\nBehind the news:WorkFusion’s virtual teammates are examples of robotic process automation (RPA), which automates office work by interacting with documents like spreadsheets and email. The RPA market is expected to grow 25 percent annually, reaching $7.5 billion by 2028.\n\nYes, but:Giving AI systems a persona raises the questions why a particular role was assigned to a particular sort of person and whether that persona reinforces undesirable social stereotypes. For instance, a  2019 United Nationsreportcriticized voice assistants such as Amazon’s Alexa for using female voices as a default setting.Why it matters:People already anthropomorphizecars,guitars, andRoombas. Wherever people and AI work together closely, it may make sense to humanize the technology with a name and face, a practice that’s already common in the chatbot biz. Just watch out for theuncanny valley— a creepy realm populated by unsettling, nearly-but-not-quite-human avatars.We’re thinking:These virtual teammates are no match for HAL 9000, but we hope they’llopen the pod bay doorswhen you ask them to.",
    "qa": [
      {
        "question": "Công ty WorkFusion đã giới thiệu điều gì mới trong lĩnh vực tự động hóa?",
        "options": {
          "A": "Một hệ thống robot có khả năng thay thế hoàn toàn nhân viên văn phòng.",
          "B": "Một dòng công cụ AI tự động hóa các tác vụ kinh doanh hàng ngày, đi kèm với hình tượng nhân vật ảo.",
          "C": "Một phần mềm quản lý dự án sử dụng trí tuệ nhân tạo để tối ưu hóa quy trình làm việc.",
          "D": "Một nền tảng mạng xã hội dành cho nhân viên để tăng cường giao tiếp và hợp tác."
        },
        "answer": "B"
      },
      {
        "question": "Điểm đặc biệt trong cách tiếp thị của WorkFusion đối với các công cụ AI của họ là gì?",
        "options": {
          "A": "Sử dụng các thuật toán phức tạp để dự đoán nhu cầu của khách hàng.",
          "B": "Mỗi công cụ AI được gán một hình tượng nhân vật hư cấu, bao gồm tên, khuôn mặt và sơ yếu lý lịch.",
          "C": "Tập trung vào việc giảm chi phí và tăng năng suất cho doanh nghiệp.",
          "D": "Cung cấp các khóa đào tạo chuyên sâu về cách sử dụng các công cụ AI."
        },
        "answer": "B"
      },
      {
        "question": "Các 'đồng nghiệp ảo' của WorkFusion thực hiện những loại công việc nào?",
        "options": {
          "A": "Phân tích dữ liệu phức tạp và đưa ra các quyết định chiến lược.",
          "B": "Thực hiện các tác vụ lặp đi lặp lại như nhập dữ liệu hoặc trích xuất thông tin từ tài liệu.",
          "C": "Tương tác trực tiếp với khách hàng và giải quyết các vấn đề của họ.",
          "D": "Phát triển các ứng dụng phần mềm mới và bảo trì hệ thống hiện có."
        },
        "answer": "B"
      },
      {
        "question": "RPA (Robotic Process Automation) là gì?",
        "options": {
          "A": "Một loại robot vật lý được sử dụng trong các nhà máy sản xuất.",
          "B": "Một công nghệ tự động hóa công việc văn phòng bằng cách tương tác với các tài liệu như bảng tính và email.",
          "C": "Một phương pháp quản lý dự án sử dụng robot để thực hiện các nhiệm vụ.",
          "D": "Một hệ thống trí tuệ nhân tạo có khả năng tự học và thích nghi với môi trường."
        },
        "answer": "B"
      },
      {
        "question": "Thị trường RPA dự kiến sẽ tăng trưởng bao nhiêu phần trăm mỗi năm?",
        "options": {
          "A": "10%",
          "B": "15%",
          "C": "20%",
          "D": "25%"
        },
        "answer": "D"
      },
      {
        "question": "Báo cáo năm 2019 của Liên Hợp Quốc đã chỉ trích điều gì về các trợ lý ảo như Alexa?",
        "options": {
          "A": "Khả năng bảo mật thông tin cá nhân của người dùng còn hạn chế.",
          "B": "Việc sử dụng giọng nữ làm mặc định có thể củng cố các định kiến xã hội không mong muốn.",
          "C": "Giá thành quá cao khiến nhiều người không thể tiếp cận.",
          "D": "Khả năng hiểu và phản hồi ngôn ngữ tự nhiên còn nhiều hạn chế."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc nhân cách hóa công nghệ AI có thể hợp lý?",
        "options": {
          "A": "Để giảm chi phí phát triển và bảo trì hệ thống AI.",
          "B": "Để làm cho công nghệ trở nên dễ sử dụng và thân thiện hơn với người dùng.",
          "C": "Để tạo ra sự cạnh tranh giữa các công ty công nghệ.",
          "D": "Để che giấu những hạn chế của công nghệ AI."
        },
        "answer": "B"
      },
      {
        "question": "Thuật ngữ 'thung lũng kỳ dị' (uncanny valley) đề cập đến điều gì?",
        "options": {
          "A": "Một khu vực địa lý nơi tập trung nhiều công ty công nghệ AI.",
          "B": "Một trạng thái tâm lý khi con người cảm thấy khó chịu hoặc ghê sợ trước những hình ảnh hoặc đối tượng gần giống người thật nhưng không hoàn toàn.",
          "C": "Một phương pháp phát triển AI dựa trên việc mô phỏng bộ não con người.",
          "D": "Một loại lỗi phần mềm phổ biến trong các hệ thống AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, việc nhân cách hóa AI đã phổ biến trong lĩnh vực nào?",
        "options": {
          "A": "Phát triển robot công nghiệp.",
          "B": "Thiết kế xe tự lái.",
          "C": "Phát triển chatbot.",
          "D": "Nghiên cứu y học."
        },
        "answer": "C"
      },
      {
        "question": "HAL 9000 được nhắc đến trong bài viết với mục đích gì?",
        "options": {
          "A": "Để so sánh với khả năng vượt trội của các 'đồng nghiệp ảo' hiện tại.",
          "B": "Để minh họa cho một ví dụ về AI có tính cách phức tạp và đáng sợ.",
          "C": "Để thể hiện sự lo ngại về việc AI có thể thay thế hoàn toàn con người.",
          "D": "Để nhấn mạnh tầm quan trọng của việc phát triển AI có đạo đức."
        },
        "answer": "B"
      }
    ]
  },
  "could-ai-coding-assistants-take-over-software-development": {
    "title": "No Work for Coders",
    "collection": "business",
    "content": "AI coding assistants are brewing codebases that once were the sole province of human programmers. Will AI systems take over software development?\n\nThe fear:Programming jobs will vanish as tireless AI agents plan, write, debug, and document code as well as or better than humans. Software engineers will find themselves wandering the job market like restless spirits.\n\nHorror stories:Since 2020, AI-powered coding tools have advanced from completing individual lines of code to generating complex programs. More and more coders work with an automated assistant. These tools are poised to take over more and more of the development cycle as they evolve.\n\nHow scared should you be:Nvidia CEO Jensen Huangpredictedthat AI would make “everybody in the world [a] computer programmer,” while observersfretthat Copilot erodes problem-solving skills. But the reality is more nuanced. Researchshowsthat automation is likely to perform certain coding tasks but not entire programming jobs. These tools excel at routine tasks and boilerplate code, but they amplify rather than automate the developer's core skills. Conceptual tasks like specifying what a program should do, collaborating with colleagues, and translating business needs into software design remain the domain of human coders — for now.\n\nFacing the fear:Developers have more to gain by embracing AI assistants than fearing them. These tools don’t just automate tasks; they accelerate learning, refine problem-solving, and enhance programming skills. Developers who master both coding fundamentals and AI assistance won’t just survive — they’ll thrive!",
    "qa": [
      {
        "question": "Nỗi sợ hãi chính được đề cập trong bài viết liên quan đến AI coding assistants là gì?",
        "options": {
          "A": "AI sẽ tạo ra những đoạn code không thể debug được.",
          "B": "AI sẽ thay thế hoàn toàn công việc của các lập trình viên.",
          "C": "AI sẽ làm giảm chất lượng phần mềm.",
          "D": "AI sẽ làm tăng chi phí phát triển phần mềm."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, AI coding tools đã phát triển đến mức nào kể từ năm 2020?",
        "options": {
          "A": "Chỉ có thể sửa lỗi code đơn giản.",
          "B": "Có thể hoàn thành các dòng code đơn lẻ.",
          "C": "Có thể tạo ra các chương trình phức tạp.",
          "D": "Có thể tự động triển khai phần mềm lên server."
        },
        "answer": "C"
      },
      {
        "question": "Jensen Huang, CEO của Nvidia, dự đoán điều gì về tác động của AI đối với lập trình?",
        "options": {
          "A": "AI sẽ làm cho lập trình trở nên khó khăn hơn.",
          "B": "AI sẽ giúp mọi người trên thế giới trở thành lập trình viên.",
          "C": "AI sẽ chỉ được sử dụng bởi các chuyên gia.",
          "D": "AI sẽ không có tác động đáng kể đến lập trình."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến lo ngại nào về việc sử dụng Copilot?",
        "options": {
          "A": "Copilot làm tăng sự phụ thuộc vào các thư viện bên ngoài.",
          "B": "Copilot làm xói mòn kỹ năng giải quyết vấn đề.",
          "C": "Copilot tạo ra các lỗ hổng bảo mật trong code.",
          "D": "Copilot làm chậm quá trình phát triển phần mềm."
        },
        "answer": "B"
      },
      {
        "question": "Theo nghiên cứu được đề cập, AI có khả năng tự động hóa hoàn toàn công việc nào?",
        "options": {
          "A": "Toàn bộ công việc lập trình.",
          "B": "Các tác vụ lập trình phức tạp.",
          "C": "Các tác vụ lập trình mang tính sáng tạo.",
          "D": "Các tác vụ lặp đi lặp lại và code mẫu."
        },
        "answer": "D"
      },
      {
        "question": "Những công việc nào trong quy trình phát triển phần mềm vẫn thuộc về các lập trình viên con người, theo bài viết?",
        "options": {
          "A": "Viết code hiệu quả.",
          "B": "Debug code nhanh chóng.",
          "C": "Xác định yêu cầu của chương trình, cộng tác và chuyển đổi nhu cầu kinh doanh thành thiết kế phần mềm.",
          "D": "Tối ưu hóa hiệu suất của phần mềm."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết khuyến khích các lập trình viên nên làm gì với AI coding assistants?",
        "options": {
          "A": "Tránh xa chúng để bảo vệ công việc của mình.",
          "B": "Sử dụng chúng một cách cẩn thận và có giới hạn.",
          "C": "Nắm vững và tận dụng chúng để phát triển bản thân.",
          "D": "Chỉ sử dụng chúng cho các dự án nhỏ."
        },
        "answer": "C"
      },
      {
        "question": "AI coding assistants có thể giúp các lập trình viên như thế nào, theo bài viết?",
        "options": {
          "A": "Giảm bớt sự cần thiết phải học các ngôn ngữ lập trình mới.",
          "B": "Tự động tạo ra tài liệu kỹ thuật hoàn chỉnh.",
          "C": "Tăng tốc độ học tập, cải thiện kỹ năng giải quyết vấn đề và nâng cao kỹ năng lập trình.",
          "D": "Thay thế hoàn toàn việc kiểm thử phần mềm."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì sẽ giúp các lập trình viên không chỉ tồn tại mà còn phát triển trong bối cảnh AI ngày càng phát triển?",
        "options": {
          "A": "Chỉ tập trung vào các ngôn ngữ lập trình mới nhất.",
          "B": "Chỉ sử dụng các công cụ AI coding assistants phổ biến nhất.",
          "C": "Nắm vững cả kiến thức lập trình cơ bản và kỹ năng sử dụng AI.",
          "D": "Chỉ làm việc trong các dự án nhỏ và đơn giản."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về vai trò của AI trong việc phát triển phần mềm?",
        "options": {
          "A": "AI sẽ sớm thay thế hoàn toàn các lập trình viên.",
          "B": "AI chỉ hữu ích cho các dự án nhỏ và đơn giản.",
          "C": "AI có thể khuếch đại các kỹ năng cốt lõi của lập trình viên, nhưng không thể thay thế chúng hoàn toàn (hiện tại).",
          "D": "AI sẽ làm giảm sự sáng tạo trong lập trình."
        },
        "answer": "C"
      }
    ]
  },
  "cream-of-the-startup-crop": {
    "title": "Cream of the Startup Crop",
    "collection": "business",
    "content": "AI startups continue to roared ahead, global pandemic or no.\n\nWhat’s new:Tech industry analyst CB Insights published itsfifth annual listof the 100 most promising private AI companies.\n\nWhat they found:The list of 100 was drawn from over 6,000 contenders based on measures including number and type of investors, R&D activity, news sentiment analysis, and competitive landscape. (Disclosure: Landing AI, where Andrew is CEO, is on the list.)\n\nWhatever happened to . . . :Twenty-one companies from last year’s list made it to this year’s. Three of last year’s cohort had successful IPOs, one went public outside regular investment channels, and two were acquired. All are still in business.\n\nWhy it matters:In the midst of massive global economic turmoil, the AI industry continues to prosper. But, while AI’s impacts are global, U.S. companies continue to scoop up most of the rewards.\n\nWe’re thinking:Building companies is hard. To quote Theodore Roosevelt, credit should be given to the person “who is actually in the arena, whose face is marred by dust and sweat and blood.” To everyone working on a startup, we wish you success!",
    "qa": [
      {
        "question": "Theo bài viết, tổ chức nào đã công bố danh sách thường niên về 100 công ty AI tư nhân triển vọng nhất?",
        "options": {
          "A": "Landing AI",
          "B": "Theodore Roosevelt Foundation",
          "C": "CB Insights",
          "D": "Global Economic Forum"
        },
        "answer": "C"
      },
      {
        "question": "Danh sách 100 công ty AI triển vọng được lựa chọn dựa trên những tiêu chí nào?",
        "options": {
          "A": "Số lượng nhân viên, doanh thu hàng năm và đánh giá của khách hàng.",
          "B": "Số lượng và loại hình nhà đầu tư, hoạt động R&D, phân tích cảm xúc tin tức và bối cảnh cạnh tranh.",
          "C": "Số lượng bằng sáng chế, giải thưởng đạt được và sự hiện diện trên mạng xã hội.",
          "D": "Giá trị thị trường, tốc độ tăng trưởng và mức độ ảnh hưởng đến cộng đồng."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã xảy ra với các công ty có mặt trong danh sách năm ngoái (năm trước năm nay)?",
        "options": {
          "A": "Hầu hết đã phá sản do ảnh hưởng của đại dịch.",
          "B": "Một số đã bị mua lại bởi các tập đoàn lớn, số còn lại vẫn hoạt động.",
          "C": "Một số đã IPO thành công, một số được mua lại và tất cả vẫn đang kinh doanh.",
          "D": "Tất cả đều tiếp tục phát triển mạnh mẽ và mở rộng thị trường."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về ngành công nghiệp AI trong bối cảnh kinh tế toàn cầu hiện nay?",
        "options": {
          "A": "Ngành công nghiệp AI đang gặp nhiều khó khăn do thiếu vốn đầu tư.",
          "B": "Ngành công nghiệp AI đang suy thoái do ảnh hưởng của đại dịch.",
          "C": "Ngành công nghiệp AI tiếp tục phát triển mạnh mẽ bất chấp những biến động kinh tế.",
          "D": "Ngành công nghiệp AI đang dần chuyển dịch sang các nước đang phát triển."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, quốc gia nào đang chiếm phần lớn lợi nhuận từ sự phát triển của AI?",
        "options": {
          "A": "Trung Quốc",
          "B": "Ấn Độ",
          "C": "Hoa Kỳ",
          "D": "Châu Âu"
        },
        "answer": "C"
      },
      {
        "question": "Landing AI, nơi Andrew giữ chức vụ CEO, có liên quan gì đến nội dung bài viết?",
        "options": {
          "A": "Landing AI là đơn vị tài trợ cho việc nghiên cứu và công bố danh sách.",
          "B": "Landing AI là một trong những công ty được nhắc đến trong danh sách 100 công ty AI triển vọng.",
          "C": "Andrew là tác giả của bài viết và đang quảng bá cho Landing AI.",
          "D": "Landing AI là đối thủ cạnh tranh trực tiếp với các công ty trong danh sách."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết trích dẫn câu nói của ai để thể hiện sự khích lệ đối với những người đang xây dựng startup?",
        "options": {
          "A": "Bill Gates",
          "B": "Steve Jobs",
          "C": "Theodore Roosevelt",
          "D": "Andrew Ng"
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc CB Insights công bố danh sách 100 công ty AI triển vọng là gì?",
        "options": {
          "A": "Để quảng bá cho các sản phẩm và dịch vụ của CB Insights.",
          "B": "Để cung cấp thông tin và đánh giá về các công ty AI tư nhân tiềm năng.",
          "C": "Để kêu gọi đầu tư vào ngành công nghiệp AI.",
          "D": "Để cạnh tranh với các tổ chức nghiên cứu thị trường khác."
        },
        "answer": "B"
      },
      {
        "question": "Cụm từ \"news sentiment analysis\" trong bài viết đề cập đến điều gì?",
        "options": {
          "A": "Phân tích xu hướng tin tức về AI trên toàn thế giới.",
          "B": "Phân tích cảm xúc và thái độ của công chúng đối với các công ty AI thông qua tin tức.",
          "C": "Phân tích độ chính xác và tin cậy của các nguồn tin tức về AI.",
          "D": "Phân tích tác động của tin tức đến giá cổ phiếu của các công ty AI."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì có thể được suy luận từ việc 21 công ty từ danh sách năm ngoái vẫn có mặt trong danh sách năm nay?",
        "options": {
          "A": "Thị trường AI đang bão hòa và ít có sự thay đổi.",
          "B": "Các công ty AI hàng đầu duy trì được vị thế cạnh tranh của mình.",
          "C": "Tiêu chí đánh giá của CB Insights không có nhiều thay đổi qua các năm.",
          "D": "Các công ty AI mới thành lập khó có thể cạnh tranh với các công ty đã có tên tuổi."
        },
        "answer": "B"
      }
    ]
  },
  "credit-where-its-due": {
    "title": "Credit Where It’s Due",
    "collection": "business",
    "content": "A neural network is helping credit card users continue to shop even when the lender’s credit-approval network goes down.What’s new:Visadevelopeda deep learning system that analyzes individual cardholders’ behavior in real time to predict whether credit card transactions should be approved or denied. The system can step in when a card issuer — generally a bank that normally would vet such transactions — suffers a network outage that makes it impossible to assess creditworthiness.How it works:If a cardholder’s purchases are blocked, they might switch to another card, costing the bank revenue and possibly a customer. And if a miscreant tries to commit fraud, the bank stands to lose money. So Visa provides a backup system that predicts the decision in case the lender can’t due to software glitches, severe weather, or routine maintenance.\n\nWhy it matters:Unlike, say, fraud detection, this model touches cardholders directly to improve the customer experience. It points the way toward public-facing models that personalize banking, credit, and other financial arrangements.\n\nYes, but:Visa declined to share details of its new algorithm withThe Batch. Decisions to extend credit can be based on patterns in data that encode social biases, and an algorithm trained on a biased dataset will reflect its biases. For instance, an algorithm may decline transactions requested by a cardholder whose home address is in a neighborhood associated with defaults on loans, and accept those requested by someone with a comparable history of repayment who lives in a wealthier neighborhood. Large financial institutions are aware of this problem, but standards that specify what is and isn’t fair are still in development.We’re thinking:The financial industry’s health depends on trust. That should provide ample incentive to define the fairness of automated systems in lending and other financial services. Efforts such as Singapore’sPrinciples to Promote Fairness, Ethics, and Transparencyare an important step.",
    "qa": [
      {
        "question": "Hệ thống deep learning mới của Visa được sử dụng để làm gì?",
        "options": {
          "A": "Phát hiện gian lận thẻ tín dụng.",
          "B": "Dự đoán việc phê duyệt hoặc từ chối giao dịch thẻ tín dụng trong thời gian thực.",
          "C": "Tự động gia hạn hạn mức tín dụng cho người dùng.",
          "D": "Cung cấp thông tin chi tiết về lịch sử giao dịch của người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống của Visa can thiệp khi nào?",
        "options": {
          "A": "Khi người dùng vượt quá hạn mức tín dụng.",
          "B": "Khi ngân hàng phát hành thẻ gặp sự cố mạng.",
          "C": "Khi giao dịch có dấu hiệu đáng ngờ.",
          "D": "Khi người dùng thực hiện giao dịch quốc tế."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì có thể xảy ra nếu giao dịch của chủ thẻ bị chặn?",
        "options": {
          "A": "Ngân hàng có thể mất doanh thu và khách hàng.",
          "B": "Chủ thẻ sẽ bị phạt vì vi phạm điều khoản sử dụng.",
          "C": "Giao dịch sẽ tự động được chuyển sang thẻ khác của chủ thẻ.",
          "D": "Chủ thẻ sẽ bị khóa tài khoản tạm thời."
        },
        "answer": "A"
      },
      {
        "question": "Mục đích chính của hệ thống dự phòng của Visa là gì?",
        "options": {
          "A": "Giảm thiểu rủi ro gian lận.",
          "B": "Cải thiện trải nghiệm khách hàng.",
          "C": "Tăng doanh thu cho Visa.",
          "D": "Đảm bảo tuân thủ các quy định pháp luật."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính giữa hệ thống này và hệ thống phát hiện gian lận là gì?",
        "options": {
          "A": "Hệ thống này sử dụng công nghệ deep learning tiên tiến hơn.",
          "B": "Hệ thống này tác động trực tiếp đến trải nghiệm của chủ thẻ.",
          "C": "Hệ thống này có khả năng xử lý lượng giao dịch lớn hơn.",
          "D": "Hệ thống này được tích hợp trực tiếp vào hệ thống thanh toán của Visa."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao Visa từ chối chia sẻ chi tiết về thuật toán mới của mình?",
        "options": {
          "A": "Để bảo vệ bí mật thương mại.",
          "B": "Vì thuật toán vẫn đang trong giai đoạn thử nghiệm.",
          "C": "Do lo ngại về các vấn đề bảo mật.",
          "D": "Vì thuật toán quá phức tạp để giải thích."
        },
        "answer": "A"
      },
      {
        "question": "Một vấn đề tiềm ẩn của việc sử dụng thuật toán để đưa ra quyết định tín dụng là gì?",
        "options": {
          "A": "Thuật toán có thể không chính xác.",
          "B": "Thuật toán có thể phản ánh các thành kiến xã hội.",
          "C": "Thuật toán có thể bị tấn công bởi hacker.",
          "D": "Thuật toán có thể làm tăng chi phí giao dịch."
        },
        "answer": "B"
      },
      {
        "question": "Ví dụ nào được đưa ra về cách thuật toán có thể thể hiện thành kiến?",
        "options": {
          "A": "Từ chối giao dịch dựa trên giới tính của chủ thẻ.",
          "B": "Từ chối giao dịch dựa trên địa chỉ nhà của chủ thẻ.",
          "C": "Từ chối giao dịch dựa trên số lượng giao dịch trước đó của chủ thẻ.",
          "D": "Từ chối giao dịch dựa trên loại hàng hóa hoặc dịch vụ được mua."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì được coi là yếu tố quan trọng để đảm bảo sức khỏe của ngành tài chính?",
        "options": {
          "A": "Sự đổi mới công nghệ.",
          "B": "Niềm tin.",
          "C": "Quy định chặt chẽ.",
          "D": "Cạnh tranh khốc liệt."
        },
        "answer": "B"
      },
      {
        "question": "Nỗ lực nào được đề cập như một bước quan trọng để xác định tính công bằng của các hệ thống tự động trong lĩnh vực tài chính?",
        "options": {
          "A": "Các tiêu chuẩn bảo mật dữ liệu mới.",
          "B": "Các nguyên tắc thúc đẩy sự công bằng, đạo đức và minh bạch của Singapore.",
          "C": "Các chương trình đào tạo về đạo đức cho nhân viên ngân hàng.",
          "D": "Các quy định mới về bảo vệ người tiêu dùng."
        },
        "answer": "B"
      }
    ]
  },
  "data-compression-by-ai": {
    "title": "Data Compression By AI",
    "collection": "business",
    "content": "In this work-from-home era, who hasn’t spent a video conference wishing they could read an onscreen document without turning their eyes from the person they’re talking with? Or simply hoping the stream wouldn’t stutter or stall? Deep learning can fill in the missing pieces.What’s new:Maxineis a media streaming platform from Nvidia. It replaces compression-decompression software with neural networks, using one-tenth the typical H.264 bandwidth. It can also enhance resolution to transmit a sharper picture, alter the video image in useful and creative ways, and deliver additional audio and language services.How it works:Maxine is available to video conference providers through major cloud computing vendors. Thisvideoillustrates some of the system’s capabilities. Avaya, which plans to implement some features in its Spaces video conferencing app, is the onlycustomernamed so far.\n\nWhy it matters:The volume of video data on the internet was growing exponentially before the pandemic hit, and since then, video conferencing has exploded. Neural networks can reclaim much of that bandwidth and boost quality in the bargain, scaling up the resolution of pixelated imagery, removing extraneous sounds, and providing expressive animated avatars and informative synthetic backgrounds.We’re thinking:AI is working wonders for signal processing in both video and audio domains. Streaming is great, but also look for GANs to revolutionize image editing and video production.",
    "qa": [
      {
        "question": "Nền tảng Maxine của Nvidia giải quyết vấn đề gì trong hội nghị trực tuyến?",
        "options": {
          "A": "Giảm thiểu tình trạng giật lag do đường truyền internet yếu.",
          "B": "Cho phép đọc tài liệu trên màn hình mà không cần rời mắt khỏi người đối diện.",
          "C": "Thay thế phần mềm nén-giải nén bằng mạng nơ-ron để tiết kiệm băng thông.",
          "D": "Tự động tạo ra các hình đại diện hoạt hình biểu cảm cho người dùng."
        },
        "answer": "C"
      },
      {
        "question": "Maxine sử dụng bao nhiêu băng thông so với H.264 thông thường?",
        "options": {
          "A": "Gấp đôi.",
          "B": "Bằng một nửa.",
          "C": "Bằng một phần mười.",
          "D": "Không đề cập trong bài."
        },
        "answer": "C"
      },
      {
        "question": "Maxine có thể được cung cấp cho các nhà cung cấp dịch vụ hội nghị trực tuyến thông qua đâu?",
        "options": {
          "A": "Trực tiếp từ Nvidia.",
          "B": "Thông qua các nhà cung cấp dịch vụ điện toán đám mây lớn.",
          "C": "Thông qua các nhà cung cấp phần mềm nén-giải nén.",
          "D": "Thông qua các nhà cung cấp dịch vụ internet."
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào đã được nêu tên là khách hàng dự kiến triển khai Maxine trong ứng dụng hội nghị trực tuyến của họ?",
        "options": {
          "A": "Microsoft.",
          "B": "Zoom.",
          "C": "Google.",
          "D": "Avaya."
        },
        "answer": "D"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về sự tăng trưởng của dữ liệu video trên internet?",
        "options": {
          "A": "Đã giảm đáng kể do đại dịch.",
          "B": "Đã tăng trưởng tuyến tính trong những năm gần đây.",
          "C": "Đã tăng trưởng theo cấp số nhân trước đại dịch và bùng nổ kể từ đó.",
          "D": "Đã ổn định sau khi đạt đỉnh vào năm 2020."
        },
        "answer": "C"
      },
      {
        "question": "Mạng nơ-ron có thể giúp ích gì cho chất lượng video?",
        "options": {
          "A": "Giảm độ phân giải của hình ảnh bị pixel hóa.",
          "B": "Loại bỏ các âm thanh thừa.",
          "C": "Tăng dung lượng lưu trữ video.",
          "D": "Giảm chi phí truyền tải video."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài streaming, bài viết còn đề cập đến công nghệ nào có thể cách mạng hóa việc chỉnh sửa ảnh và sản xuất video?",
        "options": {
          "A": "Mạng nơ-ron tích chập (CNN).",
          "B": "Mạng nơ-ron hồi quy (RNN).",
          "C": "Mạng đối kháng sinh (GANs).",
          "D": "Mạng nơ-ron sâu (DNN)."
        },
        "answer": "C"
      },
      {
        "question": "Maxine có thể làm gì với hình ảnh video?",
        "options": {
          "A": "Giảm kích thước tệp video.",
          "B": "Thay đổi hình ảnh video theo những cách hữu ích và sáng tạo.",
          "C": "Tự động tạo phụ đề cho video.",
          "D": "Tăng tốc độ tải video."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích chính của việc sử dụng mạng nơ-ron trong xử lý video là gì?",
        "options": {
          "A": "Giảm chi phí phần cứng.",
          "B": "Tăng cường chất lượng và giảm băng thông.",
          "C": "Đơn giản hóa quá trình chỉnh sửa video.",
          "D": "Tăng cường bảo mật video."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến lĩnh vực nào mà AI đang tạo ra những điều kỳ diệu, bên cạnh video?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên.",
          "B": "Xử lý tín hiệu âm thanh.",
          "C": "Robot học.",
          "D": "Thực tế ảo."
        },
        "answer": "B"
      }
    ]
  },
  "deep-learning-for-deep-discounts": {
    "title": "Deep Learning for Deep Discounts",
    "collection": "business",
    "content": "With prices on the rise, an app analyzes user data to deliver cash back on retail purchases.What’s new:Upside, a startup based in Washington, D.C., works with gas stations, grocery stores, and restaurants to offer personalized discounts to consumers,The Markupreported.How it works:The app displays a map studded with offers, customized for each user, from 30,000 partners, most of them U.S. retail chains. A user who patronizes a partner pays full price, then uploads an image of the receipt. The app applies a discount to the user’s in-app balance, which can be transferred to a bank account — for a fee — or traded for digital gift cards.\n\nBehind the news:Founded in 2015, Upside says its services reach 30 million U.S. users. Lyft and Uber integrate it with their driving app to offset inflation-driven spikes in gas prices. Fuel-saving apps GasBuddy and Checkout51 offer Upside-powered promotions, and DoorDash and Instacart have offered Upside to their drivers.Yes, but:Upside’s algorithmic approach to calculating discounts may leave some customers feeling left out.\n\nWhy it matters:Many families, individuals, and employees are on the lookout for ways to cut their expenses, and they may consider surrendering personal information a fair trade. However, the terms of the deal should be transparent and easy to understand. It’s deceptive to offer discounts that don’t pan out or diminish without warning as a casual shopper becomes a steady customer.We’re thinking:Offering discounts to attract users is an old tactic; think of Groupon and its countless competitors. But AI can tailor a deal to each individual user — a new approach that could make this strategy more effective, scalable, and sticky.",
    "qa": [
      {
        "question": "Ứng dụng Upside hợp tác với những loại hình doanh nghiệp nào để cung cấp ưu đãi cho người dùng?",
        "options": {
          "A": "Các cửa hàng điện máy, thời trang và du lịch.",
          "B": "Các trạm xăng, cửa hàng tạp hóa và nhà hàng.",
          "C": "Các công ty viễn thông, ngân hàng và bảo hiểm.",
          "D": "Các rạp chiếu phim, khu vui chơi giải trí và spa."
        },
        "answer": "B"
      },
      {
        "question": "Upside hoạt động bằng cách nào để cung cấp giảm giá cho người dùng?",
        "options": {
          "A": "Tự động trừ tiền giảm giá trực tiếp vào hóa đơn khi thanh toán.",
          "B": "Người dùng trả đủ giá, sau đó tải ảnh hóa đơn lên ứng dụng để nhận lại tiền giảm giá.",
          "C": "Người dùng nhận mã giảm giá từ ứng dụng và sử dụng khi thanh toán.",
          "D": "Ứng dụng tự động tìm kiếm và áp dụng các mã giảm giá có sẵn trên internet."
        },
        "answer": "B"
      },
      {
        "question": "Người dùng có thể sử dụng số tiền hoàn lại từ Upside bằng những cách nào?",
        "options": {
          "A": "Chỉ có thể rút về tài khoản ngân hàng.",
          "B": "Chỉ có thể đổi thành thẻ quà tặng kỹ thuật số.",
          "C": "Có thể rút về tài khoản ngân hàng (mất phí) hoặc đổi thành thẻ quà tặng kỹ thuật số.",
          "D": "Có thể sử dụng để thanh toán trực tiếp cho các đối tác của Upside."
        },
        "answer": "C"
      },
      {
        "question": "Upside được thành lập vào năm nào?",
        "options": {
          "A": "2010",
          "B": "2015",
          "C": "2020",
          "D": "2005"
        },
        "answer": "B"
      },
      {
        "question": "Những ứng dụng nào đã tích hợp Upside để giúp người dùng tiết kiệm chi phí nhiên liệu?",
        "options": {
          "A": "Facebook và Instagram.",
          "B": "Lyft và Uber.",
          "C": "TikTok và Snapchat.",
          "D": "Twitter và LinkedIn."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì có thể khiến một số khách hàng cảm thấy không hài lòng về cách Upside tính toán giảm giá?",
        "options": {
          "A": "Việc giảm giá không áp dụng cho tất cả các sản phẩm.",
          "B": "Việc giảm giá chỉ áp dụng cho khách hàng mới.",
          "C": "Cách tính toán giảm giá bằng thuật toán có thể khiến một số khách hàng cảm thấy bị bỏ rơi.",
          "D": "Việc giảm giá chỉ áp dụng vào một số khung giờ nhất định."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì quan trọng để đảm bảo tính công bằng khi cung cấp giảm giá cho người dùng?",
        "options": {
          "A": "Giảm giá phải được áp dụng cho tất cả mọi người.",
          "B": "Các điều khoản của ưu đãi phải minh bạch và dễ hiểu.",
          "C": "Giảm giá phải được duy trì ổn định trong thời gian dài.",
          "D": "Giảm giá phải được quảng cáo rộng rãi trên các phương tiện truyền thông."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết so sánh chiến lược giảm giá của Upside với chiến lược của công ty nào?",
        "options": {
          "A": "Amazon",
          "B": "Google",
          "C": "Groupon",
          "D": "Microsoft"
        },
        "answer": "C"
      },
      {
        "question": "Điểm mới trong chiến lược giảm giá của Upside so với các phương pháp truyền thống là gì?",
        "options": {
          "A": "Sử dụng quảng cáo trên mạng xã hội để tiếp cận người dùng.",
          "B": "Sử dụng trí tuệ nhân tạo (AI) để cá nhân hóa ưu đãi cho từng người dùng.",
          "C": "Tập trung vào việc cung cấp giảm giá cho các sản phẩm cao cấp.",
          "D": "Hợp tác với các tổ chức từ thiện để tạo ra các chương trình khuyến mãi."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, Upside tuyên bố có bao nhiêu người dùng ở Hoa Kỳ?",
        "options": {
          "A": "3 triệu",
          "B": "10 triệu",
          "C": "30 triệu",
          "D": "50 triệu"
        },
        "answer": "C"
      }
    ]
  },
  "deep-learning-for-deep-frying": {
    "title": "Deep Learning for Deep Frying",
    "collection": "business",
    "content": "A robot cook is frying to order in fast-food restaurants.Hot off the grill:Flippy 2, a robotic fry station from California-based Miso Robotics, has been newlydeployedin a Chicago White Castle location. It operates without a human in the loop to boost throughput, reduce contamination, and perform tasks traditionally allotted to low-paid workers.Special sauce:The robot’s arm slides on an overhead rail. It grabs baskets of raw french fries, chicken wings, onion rings, or what have you, places them in boiling oil, and unloads the finished product — fried to automated perfection — into a chute that conveys cooked food into trays.\n\nA chef’s tale:Flippy 2’s arm pivoted from grilling hamburgers to deep frying. In 2018, its bulkier predecessor’s first job wasflipping pattiesat a Pasadena, California, branch of the CaliBurger chain (owned by CaliGroup, which also owns Miso Robotics). It wastaken out of servicethe next day owing to a crush of novelty-seeking patrons anddifficultyplacing cooked burgers on a tray, which prompted retraining. Nonetheless, Miso’s emphasis appears to have shifted to frying, and the machine went on to prepare chicken tenders and tater tots atDodger Stadium, and later french fries and onion rings atWhite Castle.Why It Matters:Fast food’s high-output, repetitive tasks are well suited to automation. The work can be hot, grueling, and low-wage, leading toturnoverof employees that approaches 100 percent annually. Fast-food restaurants in the U.S. are experiencing a wave ofwalkoutsas workers seek higher wages and better working conditions. Robots might pick up the slack — for better or worse.Food for thought:We’ve seen several robotics companies take off as labor shortages related to the pandemic have stoked demand in restaurants and logistics. While the machines will help feed hungry patrons, they’ll also make it harder for humans to get jobs. Companies, institutions, and governments need to establish programs to train displaced employees for jobs that humans are likely to retain.",
    "qa": [
      {
        "question": "Flippy 2 được triển khai tại địa điểm White Castle ở Chicago với mục đích chính là gì?",
        "options": {
          "A": "Thay thế hoàn toàn đầu bếp con người để tạo ra món ăn ngon hơn.",
          "B": "Tăng năng suất, giảm thiểu ô nhiễm và thực hiện các công việc thường giao cho nhân viên lương thấp.",
          "C": "Thử nghiệm công nghệ robot mới nhất trong ngành công nghiệp thực phẩm.",
          "D": "Giảm chi phí nguyên vật liệu và năng lượng trong quá trình chế biến."
        },
        "answer": "B"
      },
      {
        "question": "Flippy 2 hoạt động như thế nào trong quá trình chiên thức ăn?",
        "options": {
          "A": "Robot trực tiếp nhào nặn và chế biến nguyên liệu trước khi chiên.",
          "B": "Robot sử dụng cảm biến để điều chỉnh nhiệt độ dầu chiên phù hợp với từng loại thực phẩm.",
          "C": "Robot gắp giỏ nguyên liệu thô, đặt vào dầu sôi và đổ thành phẩm vào máng dẫn đến khay.",
          "D": "Robot tự động thêm gia vị và nước sốt vào thực phẩm trong quá trình chiên."
        },
        "answer": "C"
      },
      {
        "question": "Công việc đầu tiên của phiên bản tiền nhiệm của Flippy 2 (Flippy) là gì?",
        "options": {
          "A": "Chiên khoai tây tại White Castle.",
          "B": "Làm gà rán tại Dodger Stadium.",
          "C": "Lật bánh hamburger tại CaliBurger.",
          "D": "Chuẩn bị hành tây chiên tại White Castle."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao Flippy ban đầu bị ngừng hoạt động sau một ngày làm việc?",
        "options": {
          "A": "Do robot bị lỗi kỹ thuật nghiêm trọng.",
          "B": "Do lượng khách hàng tò mò quá đông và khó khăn trong việc đặt bánh lên khay.",
          "C": "Do chi phí vận hành robot quá cao.",
          "D": "Do nhân viên phản đối việc robot thay thế công việc của họ."
        },
        "answer": "B"
      },
      {
        "question": "Lĩnh vực nào dường như là trọng tâm chính của Miso Robotics hiện nay?",
        "options": {
          "A": "Nướng bánh mì.",
          "B": "Chiên thức ăn.",
          "C": "Pha chế đồ uống.",
          "D": "Làm salad."
        },
        "answer": "B"
      },
      {
        "question": "Công việc nào trong ngành thức ăn nhanh đặc biệt phù hợp với tự động hóa?",
        "options": {
          "A": "Quản lý nhân sự.",
          "B": "Tiếp xúc và phục vụ khách hàng.",
          "C": "Các công việc lặp đi lặp lại, năng suất cao.",
          "D": "Sáng tạo công thức món ăn mới."
        },
        "answer": "C"
      },
      {
        "question": "Tỷ lệ luân chuyển nhân viên hàng năm trong các nhà hàng thức ăn nhanh ở Mỹ thường là bao nhiêu?",
        "options": {
          "A": "Dưới 20%.",
          "B": "Khoảng 50%.",
          "C": "Gần 100%.",
          "D": "Trên 150%."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì đang xảy ra trong ngành công nghiệp thức ăn nhanh ở Mỹ liên quan đến người lao động?",
        "options": {
          "A": "Người lao động đang được đào tạo để vận hành robot.",
          "B": "Người lao động đang đồng loạt nghỉ việc để đòi hỏi mức lương cao hơn và điều kiện làm việc tốt hơn.",
          "C": "Người lao động đang thành lập các công đoàn để bảo vệ quyền lợi của mình.",
          "D": "Người lao động đang được trả lương cao hơn để khuyến khích họ ở lại làm việc."
        },
        "answer": "B"
      },
      {
        "question": "Sự thiếu hụt lao động liên quan đến đại dịch đã thúc đẩy điều gì?",
        "options": {
          "A": "Sự gia tăng số lượng nhà hàng đóng cửa.",
          "B": "Sự phát triển của các công ty robot trong lĩnh vực nhà hàng và logistics.",
          "C": "Sự giảm sút chất lượng dịch vụ trong ngành nhà hàng.",
          "D": "Sự tăng giá của các món ăn nhanh."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất giải pháp nào để giúp những người lao động bị thay thế bởi robot?",
        "options": {
          "A": "Cung cấp trợ cấp thất nghiệp vô thời hạn.",
          "B": "Đào tạo lại họ cho các công việc mà con người có khả năng giữ lại.",
          "C": "Khuyến khích họ khởi nghiệp kinh doanh riêng.",
          "D": "Giảm giờ làm việc để chia sẻ công việc cho nhiều người hơn."
        },
        "answer": "B"
      }
    ]
  },
  "deep-learning-is-in-the-air": {
    "title": "Deep Learning Is in the Air",
    "collection": "business",
    "content": "An aviation startups is using neural networks to put air freight on autopilot.What’s new:Xwing, a California startup, is test-flying an autonomous pilot system aboard cargo aircraft with an eye toward crewless commercial flights in 2022, theWall Street Journalreported.How it works:A suite of models reads sensor data while the plane is in motion. When the models detect another plane or an obstacle, they funnel the information to a rules-based flight control system, which adjusts course, Xwing CEO Marc Piette toldThe Batch.\n\nBehind the news:Several companies are racing toward regulatory approval for autonomous freight transport, including Amazon, which this week gained permission todeliver packages using drones. The remaining issues are not technical. Commercial airliners routinely fly on autopilot, and last year a Cessna outfitted with an AI-powered autopilot fromReliable Roboticsperformed the first autonomous take-off, flight, and landing over an urban area. However, regulations and public concerns have kept human pilots in cockpits. Xwing and its proponents believe that restriction may lift before long, starting with approval for flights over water or uninhabited areas. The company’s reliance on existing aircraft may help expedite the process.Why it matters:Small planes move cargobetween outlying areas and central hubs. Autonomous systems could make service faster, more frequent, and less costly.We’re thinking:Air, land, or sea: Where will fully autonomous vehicles first enjoy widespread deployment?",
    "qa": [
      {
        "question": "Công ty Xwing đang phát triển hệ thống lái tự động cho loại hình vận tải nào?",
        "options": {
          "A": "Vận tải hành khách đường hàng không",
          "B": "Vận tải hàng hóa đường hàng không",
          "C": "Vận tải hành khách đường bộ",
          "D": "Vận tải hàng hóa đường biển"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, Xwing dự kiến thực hiện các chuyến bay thương mại không người lái vào năm nào?",
        "options": {
          "A": "2021",
          "B": "2022",
          "C": "2023",
          "D": "2024"
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống lái tự động của Xwing hoạt động bằng cách nào?",
        "options": {
          "A": "Sử dụng GPS để điều hướng và tránh chướng ngại vật.",
          "B": "Sử dụng dữ liệu cảm biến và mô hình để điều khiển máy bay thông qua hệ thống kiểm soát bay dựa trên quy tắc.",
          "C": "Dựa vào sự điều khiển từ xa của phi công trên mặt đất.",
          "D": "Sử dụng bản đồ 3D chi tiết để lập kế hoạch đường bay."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài Xwing, công ty nào khác cũng đang nỗ lực để được phê duyệt vận chuyển hàng hóa tự động?",
        "options": {
          "A": "Boeing",
          "B": "Airbus",
          "C": "Amazon",
          "D": "FedEx"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, yếu tố nào đang cản trở việc triển khai rộng rãi các chuyến bay tự động?",
        "options": {
          "A": "Công nghệ chưa đủ tiên tiến.",
          "B": "Chi phí quá cao.",
          "C": "Quy định pháp lý và lo ngại của công chúng.",
          "D": "Thiếu hụt nhân lực kỹ thuật."
        },
        "answer": "C"
      },
      {
        "question": "Công ty Reliable Robotics đã thực hiện thành công điều gì liên quan đến máy bay tự động?",
        "options": {
          "A": "Chuyến bay chở khách tự động đầu tiên.",
          "B": "Chuyến bay xuyên lục địa tự động đầu tiên.",
          "C": "Cất cánh, bay và hạ cánh tự động đầu tiên trên khu vực đô thị.",
          "D": "Phát triển hệ thống lái tự động cho máy bay chiến đấu."
        },
        "answer": "C"
      },
      {
        "question": "Xwing tin rằng việc phê duyệt các chuyến bay tự động có thể bắt đầu ở đâu?",
        "options": {
          "A": "Các khu vực đô thị đông dân cư.",
          "B": "Các khu vực nông thôn hẻo lánh.",
          "C": "Các khu vực trên biển hoặc không có người ở.",
          "D": "Các khu vực gần sân bay lớn."
        },
        "answer": "C"
      },
      {
        "question": "Việc sử dụng máy bay hiện có của Xwing có thể giúp ích gì cho quá trình phê duyệt?",
        "options": {
          "A": "Giảm chi phí phát triển hệ thống.",
          "B": "Tăng độ an toàn của các chuyến bay.",
          "C": "Đẩy nhanh quá trình phê duyệt.",
          "D": "Thu hút sự chú ý của giới truyền thông."
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống tự động có thể mang lại lợi ích gì cho việc vận chuyển hàng hóa bằng máy bay nhỏ?",
        "options": {
          "A": "Giảm ô nhiễm tiếng ồn.",
          "B": "Tăng tốc độ, tần suất và giảm chi phí dịch vụ.",
          "C": "Tạo ra nhiều việc làm hơn cho phi công.",
          "D": "Giảm sự phụ thuộc vào nhiên liệu hóa thạch."
        },
        "answer": "B"
      },
      {
        "question": "Câu hỏi cuối bài viết gợi ý điều gì về tương lai của xe tự hành?",
        "options": {
          "A": "Xe tự hành sẽ chỉ thành công trong lĩnh vực vận tải hàng hóa.",
          "B": "Xe tự hành sẽ được triển khai rộng rãi nhất ở lĩnh vực nào đầu tiên (đường bộ, đường thủy, hay đường hàng không).",
          "C": "Xe tự hành sẽ không bao giờ thay thế hoàn toàn con người.",
          "D": "Xe tự hành sẽ gây ra nhiều vấn đề về an toàn giao thông."
        },
        "answer": "B"
      }
    ]
  },
  "deepfakes-go-corporate": {
    "title": "Deepfakes Go Corporate",
    "collection": "business",
    "content": "The same technology that hasbedeviledHollywood stars androiledpolitics is easing corporate communications.What’s new:Synthesiagenerates training and sales videos featuring photorealistic, synthetic talking heads that read personalized scripts in any of 34 languages,Wiredreports. You can try out the servicehere.How it works:The company uses GANs for much of its rendering, but its production pipeline includes customized deep learning, computer vision, and visual effects, a representative toldThe Batch. Clients submit a script and choose from a selection of avatars, languages, and voices, and the AI generates a video of the avatar reading the client’s words.\n\nBehind the news:Generated video is also catching on in advertising and marketing.\n\nWhy it matters:Producers of commercial video and photography have become interested in AI’s ability to generate realistic human characters as the pandemic has curtailed live film shoots, according to the Synthesia CEO and co-founder Victor Riparbelli. Generated characters save the cost of hiring cast and crew and make it easy to localize productions for a worldwide audience. Plus, there’s no danger of spreading a deadly cough.We’re thinking:It’s easy to see potential harm in deepfakes, but the same techniques have productive uses for people with imagination to recognize them and ingenuity to implement them at scale.",
    "qa": [
      {
        "question": "Công nghệ được đề cập trong bài viết đang giúp ích cho lĩnh vực nào?",
        "options": {
          "A": "Chính trị và giải trí",
          "B": "Truyền thông doanh nghiệp",
          "C": "Nghiên cứu khoa học",
          "D": "An ninh quốc phòng"
        },
        "answer": "B"
      },
      {
        "question": "Synthesia tạo ra video bằng cách nào?",
        "options": {
          "A": "Sử dụng diễn viên thật và lồng tiếng bằng AI",
          "B": "Tạo ra các hình ảnh người ảo photorealistic đọc các đoạn script được cá nhân hóa",
          "C": "Chỉnh sửa video có sẵn bằng công nghệ deepfake",
          "D": "Kết hợp hoạt hình 3D và giọng nói AI"
        },
        "answer": "B"
      },
      {
        "question": "Synthesia hỗ trợ bao nhiêu ngôn ngữ?",
        "options": {
          "A": "10",
          "B": "24",
          "C": "34",
          "D": "44"
        },
        "answer": "C"
      },
      {
        "question": "Công nghệ chính được Synthesia sử dụng để render video là gì?",
        "options": {
          "A": "Mạng nơ-ron tích chập (CNN)",
          "B": "Mạng đối kháng sinh (GANs)",
          "C": "Mạng nơ-ron hồi quy (RNN)",
          "D": "Mạng nơ-ron sâu (DNN)"
        },
        "answer": "B"
      },
      {
        "question": "Ngoài GANs, quy trình sản xuất video của Synthesia còn bao gồm những công nghệ nào?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên (NLP) và học tăng cường",
          "B": "Học sâu tùy chỉnh, thị giác máy tính và hiệu ứng hình ảnh",
          "C": "Khai phá dữ liệu và phân tích dự đoán",
          "D": "Internet vạn vật (IoT) và điện toán đám mây"
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng của video được tạo ra bởi Synthesia đang trở nên phổ biến trong lĩnh vực nào khác?",
        "options": {
          "A": "Giáo dục trực tuyến",
          "B": "Quảng cáo và marketing",
          "C": "Sản xuất phim điện ảnh",
          "D": "Phát triển game"
        },
        "answer": "B"
      },
      {
        "question": "Theo CEO của Synthesia, đại dịch đã ảnh hưởng đến việc sản xuất video như thế nào?",
        "options": {
          "A": "Làm tăng chi phí sản xuất do các biện pháp phòng dịch",
          "B": "Hạn chế các buổi quay phim trực tiếp",
          "C": "Gây khó khăn trong việc tìm kiếm diễn viên",
          "D": "Làm chậm quá trình xử lý hậu kỳ"
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích chính của việc sử dụng nhân vật ảo trong sản xuất video là gì?",
        "options": {
          "A": "Tăng tính chân thực và cảm xúc cho video",
          "B": "Tiết kiệm chi phí thuê diễn viên và ê-kíp, dễ dàng bản địa hóa sản phẩm",
          "C": "Giảm thiểu rủi ro về bản quyền hình ảnh",
          "D": "Tăng cường khả năng tương tác với khán giả"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến nguy cơ tiềm ẩn nào của công nghệ deepfake?",
        "options": {
          "A": "Gây ra sự phụ thuộc vào công nghệ",
          "B": "Tạo ra thông tin sai lệch và gây hại",
          "C": "Làm mất việc làm của diễn viên",
          "D": "Khó kiểm soát chất lượng video"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về việc sử dụng các kỹ thuật tương tự như deepfake?",
        "options": {
          "A": "Chúng chỉ nên được sử dụng cho mục đích giải trí",
          "B": "Chúng có thể mang lại những ứng dụng hữu ích nếu được sử dụng một cách sáng tạo và có quy mô",
          "C": "Chúng cần được kiểm soát chặt chẽ để tránh lạm dụng",
          "D": "Chúng chỉ phù hợp với các doanh nghiệp lớn"
        },
        "answer": "B"
      }
    ]
  },
  "deepmind-isomorphic-alphafold": {
    "title": "DeepMind Doubles Down on AlphaFold",
    "collection": "business",
    "content": "The Google sister company devoted to artificial general intelligence parlayed its technology into a biomedical spin-off.What’s new:DeepMind launched a startup calledIsomorphic.The new company aims to build its business onAlphaFold 2, an ensemble of neural networks that finds the shapes of protein molecules, which determine their biological function. The company ishiringexperts in AI, biology, medicinal chemistry, biophysics, and engineering.How it works:Like DeepMind, Isomorphic is a subsidiary of Google’s parent company Alphabet. DeepMind CEO Demis Hassabis also leads the London-based spin-off.\n\nBehind the news:AlphaFold 2 has analyzed the shapes of over 98 percent of proteins in the human body. It remains for scientists to validate its output through lab experiments.\n\nWhy it matters:Just6.2 percentof drug candidates make it through clinical trials to market, and the cost of developing a successful medicinecosts$1.3 billion on average. Isomorphic could wring trial and error out of the process, boosting success rates, cutting costs, and enriching drug-company customers.We’re thinking:AlphaFold 2 is a big step forward for biomedicine, and deep learning promises further progress in areas like protein-protein interaction (how does a potential treatment interact with a target protein?) and protein dynamics (protein shapes aren’t static, and their motion can affect their properties). Much work by many determined researchers lies ahead to bridge the gap between lab and clinic.",
    "qa": [
      {
        "question": "Công ty con Isomorphic được thành lập bởi công ty nào?",
        "options": {
          "A": "Google",
          "B": "DeepMind",
          "C": "Alphabet",
          "D": "Một công ty dược phẩm lớn"
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ cốt lõi mà Isomorphic sử dụng để xây dựng doanh nghiệp là gì?",
        "options": {
          "A": "Một hệ thống robot tự động hóa phòng thí nghiệm",
          "B": "AlphaFold 2, một mạng lưới thần kinh dự đoán hình dạng protein",
          "C": "Một cơ sở dữ liệu khổng lồ về các loại thuốc tiềm năng",
          "D": "Một phương pháp mới để tổng hợp các phân tử thuốc"
        },
        "answer": "B"
      },
      {
        "question": "Lĩnh vực chuyên môn nào mà Isomorphic đang tìm kiếm ứng viên?",
        "options": {
          "A": "Marketing và bán hàng",
          "B": "Luật và tài chính",
          "C": "AI, sinh học, hóa dược, lý sinh và kỹ thuật",
          "D": "Giáo dục và đào tạo"
        },
        "answer": "C"
      },
      {
        "question": "Ai là CEO của cả DeepMind và Isomorphic?",
        "options": {
          "A": "Sundar Pichai",
          "B": "Sergey Brin",
          "C": "Larry Page",
          "D": "Demis Hassabis"
        },
        "answer": "D"
      },
      {
        "question": "AlphaFold 2 đã phân tích hình dạng của bao nhiêu phần trăm protein trong cơ thể người?",
        "options": {
          "A": "50%",
          "B": "75%",
          "C": "98%",
          "D": "100%"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì còn lại để các nhà khoa học thực hiện sau khi AlphaFold 2 dự đoán hình dạng protein?",
        "options": {
          "A": "Phát triển các thuật toán AI mới",
          "B": "Xây dựng các mô hình 3D của protein",
          "C": "Xác nhận kết quả thông qua các thí nghiệm trong phòng thí nghiệm",
          "D": "Nộp bằng sáng chế cho các phát hiện mới"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, tỷ lệ các ứng viên thuốc thành công vượt qua thử nghiệm lâm sàng và được đưa ra thị trường là bao nhiêu?",
        "options": {
          "A": "10%",
          "B": "6.2%",
          "C": "25%",
          "D": "50%"
        },
        "answer": "B"
      },
      {
        "question": "Chi phí trung bình để phát triển một loại thuốc thành công là bao nhiêu?",
        "options": {
          "A": "$100 triệu",
          "B": "$500 triệu",
          "C": "$1 tỷ",
          "D": "$1.3 tỷ"
        },
        "answer": "D"
      },
      {
        "question": "Isomorphic có thể mang lại lợi ích gì cho các công ty dược phẩm?",
        "options": {
          "A": "Giảm chi phí marketing",
          "B": "Tăng tỷ lệ thành công của thử nghiệm lâm sàng",
          "C": "Cải thiện quy trình sản xuất",
          "D": "Mở rộng thị trường quốc tế"
        },
        "answer": "B"
      },
      {
        "question": "Ngoài dự đoán hình dạng protein, lĩnh vực nào khác mà deep learning hứa hẹn mang lại tiến bộ trong y sinh?",
        "options": {
          "A": "Phát triển vaccine",
          "B": "Tương tác protein-protein và động lực học protein",
          "C": "Chẩn đoán hình ảnh y tế",
          "D": "Phẫu thuật robot"
        },
        "answer": "B"
      }
    ]
  },
  "deepmind-results-raise-questions": {
    "title": "DeepMind Results Raise Questions",
    "collection": "business",
    "content": "Alphabet subsidiary DeepMind lost $572 million in the past year, and its losses over the last three years amounted to more than $1 billion. AI contrarian Gary Marcus used the news as an opportunity to question the direction of AI as an industry.What’s new:In an essay published byWired, Marcus extrapolates DeepMind’s finances into an indictment of AI trends in recent years.\n\nThe blow-by-blow:He begins with a seeming defense of DeepMind, saying that the losses can be viewed as investments in cutting-edge research.\n\nBehind the news:Marcus is a longtime critic of deep learning. He published a 10-pointcritiqueof deep learning’s shortcomings last year. He is currently promoting a book,Rebooting AI, arguing that the AI community should reorder its priorities to accommodate approaches that mimic human intelligence. In June, he announced a new venture,robust.ai, with roboticist Rodney Brooks.Yes, but:As a tech company, Alphabet does well to invest in nascent technologies or risk being disrupted by them. As a public company, it has a fiduciary responsibility to do so. Moreover, DeepMind has achieved phenomenal successes at solvingGoandStarCraft IIand helped make Google’s data centers and Android devices run more efficiently.What they’re saying:The essay created a stir on social media.\n\nWe’re thinking:Marcus warns that investors may abandon AI if big investments like DeepMind don’t start providing returns. But some AI approaches already are having a huge economic impact, and emerging techniques like reinforcement learning are new enough that it makes little sense to predict doom for all approaches based on slow progress in one. Better to save such double-barreled criticism for AI that is malicious or inept. We disagree with Marcus’ views on deep learning, but cheer him on as he codes, tests, and iterates his own way forward.",
    "qa": [
      {
        "question": "DeepMind đã thua lỗ bao nhiêu trong ba năm qua?",
        "options": {
          "A": "572 triệu đô la",
          "B": "Hơn 1 tỷ đô la",
          "C": "2 tỷ đô la",
          "D": "Không có thông tin trong bài viết"
        },
        "answer": "B"
      },
      {
        "question": "Gary Marcus đã sử dụng tin tức về thua lỗ của DeepMind để làm gì?",
        "options": {
          "A": "Kêu gọi đầu tư thêm vào DeepMind",
          "B": "Đặt câu hỏi về hướng đi của ngành công nghiệp AI",
          "C": "Ca ngợi những thành tựu của DeepMind",
          "D": "Bán cuốn sách mới của mình"
        },
        "answer": "B"
      },
      {
        "question": "Trong bài luận của mình trên Wired, Gary Marcus đã làm gì với tình hình tài chính của DeepMind?",
        "options": {
          "A": "Bảo vệ DeepMind và coi đó là khoản đầu tư cần thiết",
          "B": "Phê phán DeepMind vì không mang lại lợi nhuận",
          "C": "Ngoại suy tình hình tài chính của DeepMind thành một bản cáo trạng về xu hướng AI gần đây",
          "D": "So sánh DeepMind với các công ty AI khác"
        },
        "answer": "C"
      },
      {
        "question": "Gary Marcus là một nhà phê bình lâu năm của phương pháp AI nào?",
        "options": {
          "A": "Học tăng cường (Reinforcement Learning)",
          "B": "Học sâu (Deep Learning)",
          "C": "Mạng nơ-ron (Neural Networks)",
          "D": "Xử lý ngôn ngữ tự nhiên (Natural Language Processing)"
        },
        "answer": "B"
      },
      {
        "question": "Cuốn sách mới của Gary Marcus, 'Rebooting AI', lập luận rằng cộng đồng AI nên làm gì?",
        "options": {
          "A": "Tập trung vào việc giải quyết các vấn đề thực tế hơn là nghiên cứu lý thuyết",
          "B": "Ưu tiên các phương pháp mô phỏng trí thông minh của con người",
          "C": "Đầu tư nhiều hơn vào học sâu",
          "D": "Hợp tác chặt chẽ hơn với các nhà khoa học thần kinh"
        },
        "answer": "B"
      },
      {
        "question": "Công ty mới của Gary Marcus, robust.ai, được thành lập với ai?",
        "options": {
          "A": "Demis Hassabis",
          "B": "Rodney Brooks",
          "C": "Yann LeCun",
          "D": "Geoffrey Hinton"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết cho rằng Alphabet nên đầu tư vào các công nghệ mới nổi vì lý do gì?",
        "options": {
          "A": "Để tăng lợi nhuận cho cổ đông",
          "B": "Để duy trì vị thế dẫn đầu trong ngành công nghệ",
          "C": "Để tránh bị các công ty khác làm gián đoạn",
          "D": "Để hỗ trợ nghiên cứu khoa học"
        },
        "answer": "C"
      },
      {
        "question": "DeepMind đã đạt được thành công đáng kể trong lĩnh vực nào?",
        "options": {
          "A": "Phát triển xe tự lái",
          "B": "Giải quyết các trò chơi Go và StarCraft II",
          "C": "Nghiên cứu về năng lượng tái tạo",
          "D": "Phát triển thuốc mới"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết cho rằng điều gì sẽ xảy ra nếu các khoản đầu tư lớn vào AI như DeepMind không bắt đầu mang lại lợi nhuận?",
        "options": {
          "A": "Các nhà khoa học sẽ mất hứng thú với AI",
          "B": "Các nhà đầu tư có thể từ bỏ AI",
          "C": "Chính phủ sẽ ngừng tài trợ cho nghiên cứu AI",
          "D": "Các công ty AI sẽ phá sản"
        },
        "answer": "B"
      },
      {
        "question": "Quan điểm của tác giả bài viết về những lời chỉ trích của Gary Marcus đối với học sâu là gì?",
        "options": {
          "A": "Hoàn toàn đồng ý với Gary Marcus",
          "B": "Hoàn toàn không đồng ý với Gary Marcus",
          "C": "Đồng ý với một số điểm nhưng không đồng ý với những điểm khác",
          "D": "Không đưa ra quan điểm rõ ràng"
        },
        "answer": "C"
      }
    ]
  },
  "deepseek-r1-an-affordable-rival-to-openais-o1": {
    "title": "DeepSeek Sharpens Its Reasoning",
    "collection": "business",
    "content": "A new open model rivals OpenAI’s o1, and it’s free to use or modify.\n\nWhat’s new:DeepSeek releasedDeepSeek-R1, a large language model that executes long lines of reasoning before producing output. The code and weights arelicensedfreely for commercial and personal use, including training new models on R1 outputs. Thepaperprovides an up-close look at the training of a high-performance model that implements a chain of thought without explicit prompting. (DeepSeek-R1-lite-previewcame out in November with fewer parameters and a different base model.)\n\nMixture of experts (MoE) basics:The MoE architecture uses different subsets of its parameters to process different inputs. Each MoE layer contains a group of neural networks, or experts, preceded by a gating module that learns to choose which one(s) to use based on the input. In this way, different experts learn to specialize in different types of examples. Because not all parameters are used to produce any given output, the network uses less energy and runs faster than models of similar size that use all parameters to process every input.\n\nHow it works:DeepSeek-R1 is a version ofDeepSeek-V3-Basethat was fine-tuned over four stages to enhance its ability to process achain of thought(CoT). It’s a mixture-of-experts transformer with 671 billion total parameters, 37 billion of which are active at any given time, and it processes 128,000 tokens of input context. Access to the model via DeepSeek’sAPIcosts $0.55 per million input tokens ($0.14 for cached inputs) and $2.19 per million output tokens. (In comparison, o1 costs $15 per million input tokens, $7.50 for cached inputs, and $60 per million output tokens.)\n\nOther models:DeepSeek researchers also released seven related models.\n\nResults:In DeepSeek’s tests, DeepSeek-R1 went toe-to-toe with o1, outperforming that model on 5 of 11 of the benchmarks tested. Some of the other new models showed competitive performance, too.\n\nWhy it matters:Late last year, OpenAI’s o1 kicked off a trend toward so-called reasoning models that implement a CoT without explicit prompting. But o1 and o3, its not-yet-widely-available successor, hide their reasoning steps. In contrast, DeepSeek-R1 bares all, allowing users to see the steps the model took to arrive at a particular answer. DeepSeek’s own experiments with distillation show how powerful such models can be as teachers to train smaller student models. Moreover, they appear to pass along some of the benefits of their reasoning skills, making their students more accurate.\n\nWe’re thinking:DeepSeek is rapidly emerging as a strong builder of open models. Not only are these models great performers, but their license permits use of their outputs for distillation, potentially pushing forward the state of the art for language models (and multimodal models) of all sizes.",
    "qa": [
      {
        "question": "Mô hình DeepSeek-R1 được cấp phép sử dụng như thế nào?",
        "options": {
          "A": "Chỉ được sử dụng cho mục đích phi thương mại.",
          "B": "Được cấp phép miễn phí cho cả mục đích thương mại và cá nhân, bao gồm cả việc huấn luyện mô hình mới trên kết quả của R1.",
          "C": "Chỉ được sử dụng thông qua API của DeepSeek với một khoản phí nhất định.",
          "D": "Cần phải xin phép DeepSeek trước khi sử dụng cho bất kỳ mục đích nào."
        },
        "answer": "B"
      },
      {
        "question": "Kiến trúc Mixture of Experts (MoE) hoạt động như thế nào?",
        "options": {
          "A": "Sử dụng tất cả các tham số để xử lý mọi đầu vào, đảm bảo độ chính xác cao nhất.",
          "B": "Sử dụng các tập hợp con khác nhau của các tham số để xử lý các đầu vào khác nhau, giúp tiết kiệm năng lượng và tăng tốc độ xử lý.",
          "C": "Chia nhỏ đầu vào thành nhiều phần và xử lý song song để tăng tốc độ.",
          "D": "Sử dụng một mạng nơ-ron duy nhất để xử lý mọi đầu vào, nhưng điều chỉnh trọng số của các kết nối để phù hợp với từng loại đầu vào."
        },
        "answer": "B"
      },
      {
        "question": "DeepSeek-R1 được tinh chỉnh từ mô hình nào?",
        "options": {
          "A": "DeepSeek-R1-lite-preview",
          "B": "DeepSeek-V3-Base",
          "C": "o1",
          "D": "o3"
        },
        "answer": "B"
      },
      {
        "question": "DeepSeek-R1 có bao nhiêu tham số đang hoạt động tại một thời điểm?",
        "options": {
          "A": "671 tỷ",
          "B": "128,000",
          "C": "37 tỷ",
          "D": "Không xác định"
        },
        "answer": "C"
      },
      {
        "question": "Chi phí sử dụng API của DeepSeek-R1 là bao nhiêu cho mỗi triệu token đầu vào (không được lưu trong bộ nhớ cache)?",
        "options": {
          "A": "$0.14",
          "B": "$2.19",
          "C": "$15",
          "D": "$0.55"
        },
        "answer": "D"
      },
      {
        "question": "Trong các thử nghiệm của DeepSeek, DeepSeek-R1 đã vượt trội hơn o1 trên bao nhiêu benchmark?",
        "options": {
          "A": "11",
          "B": "6",
          "C": "5",
          "D": "Không có benchmark nào"
        },
        "answer": "C"
      },
      {
        "question": "Điểm khác biệt chính giữa DeepSeek-R1 và o1/o3 là gì?",
        "options": {
          "A": "DeepSeek-R1 có số lượng tham số lớn hơn.",
          "B": "DeepSeek-R1 có chi phí sử dụng API thấp hơn.",
          "C": "DeepSeek-R1 cho phép người dùng thấy các bước suy luận để đưa ra câu trả lời, trong khi o1/o3 thì không.",
          "D": "DeepSeek-R1 chỉ hỗ trợ tiếng Anh, trong khi o1/o3 hỗ trợ nhiều ngôn ngữ hơn."
        },
        "answer": "C"
      },
      {
        "question": "Thuật ngữ 'chain of thought' (CoT) được sử dụng trong bài viết để chỉ điều gì?",
        "options": {
          "A": "Một phương pháp mã hóa dữ liệu để tăng tốc độ xử lý.",
          "B": "Một kỹ thuật tạo ra các chuỗi văn bản dài và mạch lạc.",
          "C": "Một quy trình suy luận dài dòng trước khi đưa ra kết quả.",
          "D": "Một kiến trúc mạng nơ-ron phức tạp với nhiều lớp kết nối."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích của việc chưng cất (distillation) mô hình lớn như DeepSeek-R1 là gì?",
        "options": {
          "A": "Để giảm kích thước mô hình và tăng tốc độ xử lý.",
          "B": "Để cải thiện độ chính xác của mô hình lớn.",
          "C": "Để tạo ra các mô hình nhỏ hơn, hiệu quả hơn, đồng thời vẫn giữ được một phần khả năng của mô hình lớn.",
          "D": "Để bảo vệ quyền sở hữu trí tuệ của mô hình lớn."
        },
        "answer": "C"
      },
      {
        "question": "DeepSeek-R1 có thể xử lý bao nhiêu token đầu vào?",
        "options": {
          "A": "37 tỷ",
          "B": "671 tỷ",
          "C": "128,000",
          "D": "Không giới hạn"
        },
        "answer": "C"
      }
    ]
  },
  "draw-a-gun-trigger-an-algorithm": {
    "title": "Draw a Gun, Trigger an Algorithm",
    "collection": "business",
    "content": "Computer vision is alerting authorities the moment someone draws a gun.What’s new:Several companies offer deep learning systems that enable surveillance cameras to spot firearms and quickly notify security guards or police, according toVice.No people were harmed in the training of this model:Some developers of gun detection models have gone to great lengths to produce training data.\n\nBehind the news:The use of computer vision in such offerings updates earlier systems based on sounds. For instance,ShotSpotteris used by over 100 police departments in the U.S. The system picks up gunshot sounds from acoustic sensors placed around a community and uses machine learning to compare them with an audio database. When it recognizes a gunshot, it triangulates the location and alerts police.Why it matters:Gun violenceis endemic across the U.S, includinghundredsof mass shootings. By warning police or security guards before a shooter opens up, AI-powered gun detection could save lives.We’re thinking:Like any machine learning system applied to the real world, gun detection algorithms aren’t perfect.One such systemused in New York state schools was found to mistake broom handles for guns. Such mistakes could be dangerous if they prompt police to enter possible crime scenes with their own weapons drawn and pulses pounding.",
    "qa": [
      {
        "question": "Công nghệ thị giác máy tính (Computer vision) trong bài viết được sử dụng để làm gì?",
        "options": {
          "A": "Phân tích dữ liệu âm thanh từ các vụ nổ súng.",
          "B": "Phát hiện súng và thông báo cho cơ quan chức năng.",
          "C": "Xác định vị trí của người sử dụng súng.",
          "D": "Cải thiện chất lượng hình ảnh từ camera giám sát."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, hệ thống nào sử dụng cảm biến âm thanh để phát hiện tiếng súng?",
        "options": {
          "A": "Deep learning systems.",
          "B": "Computer vision.",
          "C": "ShotSpotter.",
          "D": "AI-powered gun detection."
        },
        "answer": "C"
      },
      {
        "question": "ShotSpotter sử dụng công nghệ gì để xác định vị trí của tiếng súng?",
        "options": {
          "A": "Nhận diện hình ảnh.",
          "B": "Tam giác đạc.",
          "C": "Phân tích video.",
          "D": "Nhận diện khuôn mặt."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính mà bài viết đề cập liên quan đến bạo lực súng đạn ở đâu?",
        "options": {
          "A": "Trên toàn thế giới.",
          "B": "Chủ yếu ở các nước đang phát triển.",
          "C": "Chủ yếu ở các nước châu Âu.",
          "D": "Trên khắp nước Mỹ."
        },
        "answer": "D"
      },
      {
        "question": "Lợi ích tiềm năng lớn nhất của việc sử dụng AI để phát hiện súng là gì?",
        "options": {
          "A": "Giảm chi phí cho lực lượng an ninh.",
          "B": "Cải thiện độ chính xác của camera giám sát.",
          "C": "Cứu sống mạng người.",
          "D": "Tăng cường khả năng thu thập bằng chứng."
        },
        "answer": "C"
      },
      {
        "question": "Một hệ thống phát hiện súng ở New York đã mắc lỗi gì?",
        "options": {
          "A": "Không phát hiện được súng thật.",
          "B": "Nhầm lẫn giữa súng và các vật thể khác.",
          "C": "Gây ra báo động giả quá thường xuyên.",
          "D": "Xác định sai vị trí của người cầm súng."
        },
        "answer": "B"
      },
      {
        "question": "Sai sót của hệ thống phát hiện súng có thể dẫn đến hậu quả gì?",
        "options": {
          "A": "Làm giảm uy tín của lực lượng cảnh sát.",
          "B": "Gây ra sự hoang mang trong cộng đồng.",
          "C": "Khiến cảnh sát phản ứng thái quá và gây nguy hiểm.",
          "D": "Làm chậm quá trình điều tra các vụ án liên quan đến súng."
        },
        "answer": "C"
      },
      {
        "question": "Các công ty phát triển hệ thống phát hiện súng đã làm gì để tạo dữ liệu huấn luyện?",
        "options": {
          "A": "Sử dụng hình ảnh từ các vụ án có thật.",
          "B": "Thu thập dữ liệu từ các trò chơi điện tử.",
          "C": "Đã nỗ lực rất nhiều để tạo ra dữ liệu huấn luyện.",
          "D": "Sử dụng dữ liệu được cung cấp bởi chính phủ."
        },
        "answer": "C"
      },
      {
        "question": "Điểm khác biệt chính giữa hệ thống phát hiện súng bằng thị giác máy tính và hệ thống dựa trên âm thanh là gì?",
        "options": {
          "A": "Hệ thống thị giác máy tính chính xác hơn.",
          "B": "Hệ thống dựa trên âm thanh rẻ hơn.",
          "C": "Hệ thống thị giác máy tính sử dụng hình ảnh, hệ thống dựa trên âm thanh sử dụng âm thanh.",
          "D": "Hệ thống dựa trên âm thanh có thể xác định vị trí chính xác hơn."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì quan trọng cần xem xét khi áp dụng bất kỳ hệ thống máy học nào vào thế giới thực?",
        "options": {
          "A": "Chi phí triển khai hệ thống.",
          "B": "Khả năng tương thích với các hệ thống hiện có.",
          "C": "Tính hoàn hảo của thuật toán.",
          "D": "Hệ thống không phải lúc nào cũng hoàn hảo."
        },
        "answer": "D"
      }
    ]
  },
  "details-leak-about-magi-googles-answer-to-bing-with-gpt-4": {
    "title": "Conversational Search, Google Style",
    "collection": "business",
    "content": "Google’s response to Microsoft’s GPT-4-enhanced Bing became a little clearer.\n\nWhat’s new:Anonymous insiders leaked details of Project Magi, the search giant’s near-term effort to enhance its search engine with automated conversation,The New York Timesreported. They described upcoming features, but not the models behind them.\n\nHow it works:Nearly 160 engineers are working on the project.\n\nBeyond search:The company is developing AI-powered features for other parts of its business as well. These include an image generation tool called GIFI for Google Images and a chatbot called Tivoli Tutor for learning languages.Behind the news:Google has been scrambling to integrate AI features. The company recently combined Brain and DeepMind into a single unit to accelerate AI research and development. In March, rumors emerged that Samsung, which pays Google substantial licensing revenue to use its search engine in mobile devices, was considering a switch to Bing. The previous month, Bard made factual errors during a public demo, which contributed to an 8 percent drop in Google’s share price. These moves followed a December 2022 “code red” response to Microsoft’s plans to upgrade Bing with conversational technology from OpenAI.\n\nWhy it matters:When it comes to finding information, conversational AI is a powerful addition to, and possibly a replacement for, web search. Google, as the market leader, can’t wait to find out. The ideas Google and its competitors implement in coming months will set the mold for conversational user interfaces in search and beyond.We’re thinking:Should chatbots be integrated with search or designed as separate products? Microsoft and Google are taking different approaches. Microsoft’s conversational model is deeply integrated with Bing search, while Google's Bard currently stands alone. Given the differences between chat and search, there’s a case to be made for keeping chatbots distinct from search engines.",
    "qa": [
      {
        "question": "Dự án Magi của Google tập trung vào mục tiêu chính nào?",
        "options": {
          "A": "Phát triển một công cụ tạo ảnh GIF cho Google Images.",
          "B": "Nâng cấp công cụ tìm kiếm bằng khả năng hội thoại tự động.",
          "C": "Xây dựng một chatbot dạy ngoại ngữ mang tên Tivoli Tutor.",
          "D": "Tích hợp Brain và DeepMind thành một đơn vị duy nhất."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, có khoảng bao nhiêu kỹ sư đang tham gia vào dự án Magi?",
        "options": {
          "A": "Khoảng 100 kỹ sư.",
          "B": "Khoảng 160 kỹ sư.",
          "C": "Khoảng 200 kỹ sư.",
          "D": "Khoảng 260 kỹ sư."
        },
        "answer": "B"
      },
      {
        "question": "GIFI là tên của công cụ AI nào mà Google đang phát triển?",
        "options": {
          "A": "Công cụ dịch thuật tự động.",
          "B": "Công cụ tạo ảnh GIF cho Google Images.",
          "C": "Công cụ hỗ trợ viết email.",
          "D": "Công cụ phân tích dữ liệu người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Tivoli Tutor được thiết kế để làm gì?",
        "options": {
          "A": "Tạo ra các bài thuyết trình tự động.",
          "B": "Dạy ngoại ngữ.",
          "C": "Hỗ trợ lập trình.",
          "D": "Quản lý dự án."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã thúc đẩy Google kết hợp Brain và DeepMind thành một đơn vị?",
        "options": {
          "A": "Giảm chi phí hoạt động.",
          "B": "Tăng cường sự cạnh tranh nội bộ.",
          "C": "Đẩy nhanh quá trình nghiên cứu và phát triển AI.",
          "D": "Đáp ứng yêu cầu của cổ đông."
        },
        "answer": "C"
      },
      {
        "question": "Sự kiện nào đã khiến giá cổ phiếu của Google giảm 8%?",
        "options": {
          "A": "Samsung tuyên bố chuyển sang sử dụng Bing.",
          "B": "Bard mắc lỗi trong buổi demo công khai.",
          "C": "Microsoft ra mắt GPT-4.",
          "D": "Google công bố dự án Magi."
        },
        "answer": "B"
      },
      {
        "question": "Phản ứng 'code red' của Google vào tháng 12/2022 liên quan đến điều gì?",
        "options": {
          "A": "Sự cố bảo mật dữ liệu người dùng.",
          "B": "Kế hoạch nâng cấp Bing bằng công nghệ hội thoại của OpenAI.",
          "C": "Sự ra mắt của một công cụ tìm kiếm mới từ Apple.",
          "D": "Một cuộc khủng hoảng truyền thông liên quan đến CEO của Google."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lợi ích chính của AI hội thoại trong lĩnh vực tìm kiếm thông tin là gì?",
        "options": {
          "A": "Giảm thiểu chi phí vận hành máy chủ.",
          "B": "Cung cấp thông tin nhanh chóng và chính xác hơn.",
          "C": "Tăng cường khả năng bảo mật thông tin cá nhân.",
          "D": "Có thể thay thế hoặc bổ sung cho công cụ tìm kiếm web truyền thống."
        },
        "answer": "D"
      },
      {
        "question": "Microsoft và Google đang tiếp cận việc tích hợp chatbot vào công cụ tìm kiếm như thế nào?",
        "options": {
          "A": "Cả hai đều tích hợp chatbot một cách sâu rộng vào công cụ tìm kiếm.",
          "B": "Cả hai đều phát triển chatbot như một sản phẩm độc lập.",
          "C": "Microsoft tích hợp chatbot sâu rộng vào Bing, trong khi Google phát triển Bard như một sản phẩm độc lập.",
          "D": "Google tích hợp chatbot sâu rộng vào công cụ tìm kiếm, trong khi Microsoft phát triển chatbot như một sản phẩm độc lập."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì được cho là có thể biện minh cho việc giữ chatbot tách biệt với công cụ tìm kiếm?",
        "options": {
          "A": "Chi phí phát triển chatbot quá cao.",
          "B": "Sự khác biệt giữa trò chuyện và tìm kiếm.",
          "C": "Khả năng bảo mật thông tin của chatbot còn hạn chế.",
          "D": "Người dùng không quen với việc sử dụng chatbot."
        },
        "answer": "B"
      }
    ]
  },
  "driverless-delivery-in-high-gear": {
    "title": "Driverless Delivery in High Gear",
    "collection": "business",
    "content": "Walmart aims to deliver goods via self-driving vehicles this year.What’s new:The retail giant will test autonomous delivery in three U.S. cities.Cars built by Ford and piloted by Argo AIwill ferry merchandise directly to the customer’s front steps.How it works:The service initially will belimitedto parts of Austin, Miami, and Washington, D.C.\n\nBehind the news:Walmart has been testing automated delivery services using technology fromCruise,Gatik, andWaymo.Nuro, which also has partnered with Walmart, focuses on autonomous delivery on the grounds that it lowers requirements for riding comfort and permits slower, and thus safer, driving.Why it matters:Although self-driving vehicles aren’t ready for widespread use, the partnership between one of the world’s largest retailers and one of the world’s biggest auto makers signals potential for near-term commercial applications.We’re thinking:Fully self-driving cars likely will reach the market through a vertical niche, which is easier than building vehicles that can handle all circumstances. Some companies focus on trucking, others on local shuttles, still others on transportation within constrained environments such as ports or campuses. Although self-driving has taken longer than expected to come to fruition, we remain optimistic that experiments like these will bear fruit.",
    "qa": [
      {
        "question": "Walmart dự kiến sẽ sử dụng phương tiện tự lái để giao hàng trong năm nay tại bao nhiêu thành phố của Hoa Kỳ?",
        "options": {
          "A": "Một thành phố",
          "B": "Ba thành phố",
          "C": "Năm thành phố",
          "D": "Toàn bộ các thành phố lớn"
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào hợp tác với Walmart để cung cấp xe tự lái cho dịch vụ giao hàng?",
        "options": {
          "A": "Tesla",
          "B": "Ford",
          "C": "General Motors",
          "D": "Toyota"
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ tự lái của Ford được phát triển bởi công ty nào?",
        "options": {
          "A": "Waymo",
          "B": "Cruise",
          "C": "Argo AI",
          "D": "Gatik"
        },
        "answer": "C"
      },
      {
        "question": "Dịch vụ giao hàng tự động của Walmart ban đầu sẽ giới hạn ở những khu vực nào?",
        "options": {
          "A": "Các khu vực nông thôn",
          "B": "Các khu vực ngoại ô",
          "C": "Các khu vực trung tâm thành phố",
          "D": "Một phần của Austin, Miami và Washington, D.C."
        },
        "answer": "D"
      },
      {
        "question": "Công ty nào tập trung vào giao hàng tự động với mục tiêu giảm yêu cầu về sự thoải mái khi di chuyển và cho phép lái xe chậm hơn, an toàn hơn?",
        "options": {
          "A": "Waymo",
          "B": "Cruise",
          "C": "Gatik",
          "D": "Nuro"
        },
        "answer": "D"
      },
      {
        "question": "Mục đích chính của việc Walmart hợp tác với các công ty xe tự lái là gì?",
        "options": {
          "A": "Để giảm chi phí vận chuyển",
          "B": "Để tăng tốc độ giao hàng",
          "C": "Để thử nghiệm các ứng dụng thương mại tiềm năng trong tương lai gần",
          "D": "Để cạnh tranh với Amazon"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, thị trường xe tự lái có khả năng sẽ phát triển theo hướng nào?",
        "options": {
          "A": "Phát triển đồng đều trên mọi lĩnh vực",
          "B": "Phát triển thông qua các thị trường ngách dọc",
          "C": "Phát triển mạnh mẽ trong lĩnh vực xe cá nhân",
          "D": "Phát triển chậm do các vấn đề kỹ thuật"
        },
        "answer": "B"
      },
      {
        "question": "Lĩnh vực nào được đề cập trong bài viết như một ví dụ về thị trường ngách dọc tiềm năng cho xe tự lái?",
        "options": {
          "A": "Xe buýt công cộng",
          "B": "Xe taxi",
          "C": "Vận tải hàng hóa bằng xe tải",
          "D": "Xe cứu thương"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết thể hiện thái độ nào về tương lai của xe tự lái?",
        "options": {
          "A": "Bi quan vì sự phát triển chậm chạp",
          "B": "Trung lập",
          "C": "Lạc quan rằng các thử nghiệm sẽ mang lại kết quả",
          "D": "Hoài nghi về tính khả thi"
        },
        "answer": "C"
      },
      {
        "question": "Ngoài Ford và Argo AI, Walmart đã thử nghiệm dịch vụ giao hàng tự động với những công ty nào khác?",
        "options": {
          "A": "Tesla, Rivian",
          "B": "Cruise, Gatik, Waymo",
          "C": "Toyota, Honda",
          "D": "BMW, Mercedes-Benz"
        },
        "answer": "B"
      }
    ]
  },
  "elon-musks-97-4b-bid-for-openai-rejected-fueling-ai-power-struggle": {
    "title": "Musk Complicates OpenAI’s Plan",
    "collection": "business",
    "content": "Elon Musk and a group of investors made an unsolicited bid to buy the assets of the nonprofit that controls OpenAI, complicating the AI powerhouse’s future plans.\n\nWhat’s new:Musksubmitteda $97.4 billion offer to acquire the assets of the nonprofit OpenAI Inc. CEO Sam Altman and the company’s board of directors swiftlyrejectedit, and Altman publiclymockedMusk by offering to buy Twitter for $9.74 billion (one-tenth of Musk’s bid and less than one-quarter the price he paid for the social network). OpenAI’s board reaffirmed its control over the company’s direction, signaling that it does not intend to cede governance to outside investors.\n\nHow it works:OpenAI was founded as a nonprofit in 2015, but since 2019 it has operated under an unusual structure in which the nonprofit board controls the for-profit entity that develops and commercializes AI models. This setup allows the board to maintain the company’s original mission — developing AI for the benefit of humanity — rather than solely maximizing shareholder value. However, driven by the need for massive investments in infrastructure and talent, OpenAI is considering a newfor-profit structurethat would allow external investors to own more of the company. The high offer by Musk — who, as CEO of xAI, competes with OpenAI — could interfere with that plan.\n\nBehind the news:Musk was one of OpenAI’s earliest investors, but he departed in 2018 after disagreements over direction and control of the organization. His bid follows alawsuitagainst OpenAI, in which he claims the company abandoned its nonprofit mission in favor of profit. OpenAIsaidthat Musk’s bid contradicts his legal claims and suggests that the lawsuit should be dismissed. Since then, Musk hasstatedthat he would drop the lawsuit if OpenAI remains a nonprofit.\n\nWhy it matters:OpenAI is a premier AI company, and its activities affect virtually everyone in the field by supplying tools, technology, or inspiration. Musk’s xAI is a direct competitor, and his bid, whether it’s sincere or tactical, unsettles OpenAI’s plans. Even if OpenAI moves forward as planned, Musk’s actions likely will have made the process more expensive and potentially invite closer scrutiny of the company’s actions.\n\nWe’re thinking:There’s ample precedence for non-profits spinning out for-profit entities. For example, non-profit universities typically create intellectual property that forms the basis of for-profit startups. The university might retain a modest stake, and this is viewed as consistent with its non-profit mission. This isn’t a perfect analogy, since OpenAI does little besides operating its AI business, but we hope the company finds a path forward that allows it to serve users, rewards its employees for their contributions, and honors its non-profit charter.",
    "qa": [
      {
        "question": "Elon Musk đã đưa ra lời đề nghị mua lại OpenAI với giá trị bao nhiêu?",
        "options": {
          "A": "$9.74 tỷ",
          "B": "$97.4 tỷ",
          "C": "$974 tỷ",
          "D": "$9.74 triệu"
        },
        "answer": "B"
      },
      {
        "question": "CEO Sam Altman đã phản ứng thế nào trước lời đề nghị của Elon Musk?",
        "options": {
          "A": "Chấp nhận lời đề nghị ngay lập tức.",
          "B": "Từ chối và chế nhạo Musk bằng cách đề nghị mua Twitter với giá thấp hơn nhiều.",
          "C": "Đàm phán để đạt được thỏa thuận tốt hơn.",
          "D": "Giữ im lặng và không đưa ra bất kỳ phản hồi nào."
        },
        "answer": "B"
      },
      {
        "question": "Cấu trúc hoạt động đặc biệt của OpenAI từ năm 2019 là gì?",
        "options": {
          "A": "Một công ty vì lợi nhuận hoàn toàn thuộc sở hữu của các nhà đầu tư bên ngoài.",
          "B": "Một tổ chức phi lợi nhuận kiểm soát một thực thể vì lợi nhuận phát triển và thương mại hóa các mô hình AI.",
          "C": "Một liên doanh giữa Elon Musk và Sam Altman.",
          "D": "Một tổ chức chính phủ chịu trách nhiệm phát triển AI cho mục đích quốc phòng."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu ban đầu của OpenAI khi thành lập là gì?",
        "options": {
          "A": "Tối đa hóa giá trị cho các cổ đông.",
          "B": "Phát triển AI vì lợi ích của nhân loại.",
          "C": "Cạnh tranh trực tiếp với các công ty công nghệ khác.",
          "D": "Tạo ra lợi nhuận khổng lồ cho các nhà đầu tư."
        },
        "answer": "B"
      },
      {
        "question": "Lý do chính khiến OpenAI xem xét một cấu trúc vì lợi nhuận mới là gì?",
        "options": {
          "A": "Để thu hút nhiều nhân tài hơn.",
          "B": "Để đáp ứng yêu cầu của Elon Musk.",
          "C": "Để tối đa hóa lợi nhuận cho các cổ đông hiện tại.",
          "D": "Để có được các khoản đầu tư lớn vào cơ sở hạ tầng và nhân tài."
        },
        "answer": "D"
      },
      {
        "question": "Vì sao Elon Musk rời khỏi OpenAI vào năm 2018?",
        "options": {
          "A": "Ông không còn quan tâm đến lĩnh vực AI.",
          "B": "Ông muốn tập trung vào các dự án khác của mình.",
          "C": "Ông có bất đồng về hướng đi và quyền kiểm soát của tổ chức.",
          "D": "Ông bị buộc phải rời đi do vi phạm các quy tắc của công ty."
        },
        "answer": "C"
      },
      {
        "question": "Nội dung chính trong vụ kiện mà Elon Musk đệ trình chống lại OpenAI là gì?",
        "options": {
          "A": "OpenAI đã vi phạm bằng sáng chế của ông.",
          "B": "OpenAI đã từ bỏ sứ mệnh phi lợi nhuận để theo đuổi lợi nhuận.",
          "C": "OpenAI đã đánh cắp ý tưởng của ông.",
          "D": "OpenAI đã phỉ báng danh dự của ông."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, hoạt động của OpenAI có tác động như thế nào đến lĩnh vực AI?",
        "options": {
          "A": "Không có tác động đáng kể.",
          "B": "Chỉ ảnh hưởng đến một số ít công ty.",
          "C": "Ảnh hưởng đến hầu hết mọi người trong lĩnh vực này bằng cách cung cấp công cụ, công nghệ hoặc nguồn cảm hứng.",
          "D": "Chỉ ảnh hưởng đến các đối thủ cạnh tranh trực tiếp."
        },
        "answer": "C"
      },
      {
        "question": "XAI của Elon Musk có mối quan hệ như thế nào với OpenAI?",
        "options": {
          "A": "Là một đối tác chiến lược.",
          "B": "Là một công ty con.",
          "C": "Là một đối thủ cạnh tranh trực tiếp.",
          "D": "Không có mối quan hệ nào."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến tiền lệ nào liên quan đến các tổ chức phi lợi nhuận?",
        "options": {
          "A": "Các tổ chức phi lợi nhuận không bao giờ được phép tạo ra các thực thể vì lợi nhuận.",
          "B": "Các tổ chức phi lợi nhuận thường xuyên tạo ra các thực thể vì lợi nhuận dựa trên tài sản trí tuệ của họ.",
          "C": "Các tổ chức phi lợi nhuận phải luôn duy trì cấu trúc phi lợi nhuận.",
          "D": "Các tổ chức phi lợi nhuận không được phép nhận đầu tư từ bên ngoài."
        },
        "answer": "B"
      }
    ]
  },
  "enterprise-ai-on-the-rise": {
    "title": "Enterprise AI on the Rise",
    "collection": "business",
    "content": "A survey of AI in large companies sees boom times ahead — if AI teams can get past issues that surround implementation.What’s new:Businesses of all sizes are using more machine learning, spending more on it, and hiring more engineers to wrangle it, according to asurveyof 750 business leaders by Algorithmia, which provides tools that automate model deployment and management. Nonetheless, struggles with deployment, scaling, and other issues continue to hinder adoption.What they found:The survey questioned executives in a variety of sectors including finance, healthcare, education, and information technology. More than two-thirds of those who responded said their AI budgets are growing, while only 2 percent are cutting back.\n\nBehind the news:Several other recent surveys shed light on AI’s evolving role in the business world. For instance,MIT Technology Reviewlooked at AI’s growth in different global regions, andMcKinseyexamined how different market sectors, like manufacturing, marketing, and supply chain management, are finding profitable uses for the technology.Why it matters:AI is new enough, and evolving fast enough, that every company’s experience is different. Spotting areas where industries where machine learning is having an impact, as well as trouble spots in deployment, can help guide crucial decisions.We’re thinking:In 2019, many companies experimented with AI. In 2020, a growing number started talking about how to productionize models. In the coming year, we hope for rapid progress in MLOps processes and tools to make building and productionizing machine learning systems repeatable and systematic.AI Fund(where Andrew is managing general partner) has seen a lot of startups jump into this space, which bodes well for the future.",
    "qa": [
      {
        "question": "Theo khảo sát của Algorithmia, tình hình sử dụng Machine Learning trong các doanh nghiệp lớn hiện nay như thế nào?",
        "options": {
          "A": "Các doanh nghiệp đang giảm dần việc sử dụng Machine Learning do chi phí cao.",
          "B": "Các doanh nghiệp đang tăng cường sử dụng Machine Learning, chi tiêu nhiều hơn và tuyển dụng thêm kỹ sư.",
          "C": "Các doanh nghiệp đang tạm dừng các dự án Machine Learning để đánh giá lại hiệu quả.",
          "D": "Các doanh nghiệp chỉ tập trung vào các ứng dụng Machine Learning đã được chứng minh hiệu quả."
        },
        "answer": "B"
      },
      {
        "question": "Khảo sát của Algorithmia được thực hiện trên đối tượng nào?",
        "options": {
          "A": "Các nhà khoa học dữ liệu và kỹ sư Machine Learning.",
          "B": "Các nhà đầu tư mạo hiểm trong lĩnh vực AI.",
          "C": "Các nhà quản lý cấp cao và lãnh đạo doanh nghiệp.",
          "D": "Người dùng cuối của các sản phẩm và dịch vụ AI."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, khó khăn chính mà các doanh nghiệp gặp phải trong việc ứng dụng AI là gì?",
        "options": {
          "A": "Thiếu dữ liệu chất lượng cao để huấn luyện mô hình.",
          "B": "Khó khăn trong việc triển khai, mở rộng và các vấn đề liên quan khác.",
          "C": "Thiếu nhân lực có kỹ năng chuyên môn về AI.",
          "D": "Chi phí đầu tư ban đầu quá lớn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến những lĩnh vực nào mà khảo sát của Algorithmia bao gồm?",
        "options": {
          "A": "Sản xuất, bán lẻ và năng lượng.",
          "B": "Tài chính, y tế, giáo dục và công nghệ thông tin.",
          "C": "Nông nghiệp, xây dựng và giao thông vận tải.",
          "D": "Truyền thông, giải trí và du lịch."
        },
        "answer": "B"
      },
      {
        "question": "Tạp chí nào được đề cập trong bài viết đã nghiên cứu về sự phát triển của AI ở các khu vực khác nhau trên thế giới?",
        "options": {
          "A": "Harvard Business Review.",
          "B": "MIT Technology Review.",
          "C": "Forbes.",
          "D": "The Economist."
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào được đề cập trong bài viết đã nghiên cứu về cách các lĩnh vực thị trường khác nhau tìm thấy các ứng dụng có lợi nhuận cho công nghệ AI?",
        "options": {
          "A": "Boston Consulting Group.",
          "B": "Accenture.",
          "C": "McKinsey.",
          "D": "Deloitte."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì quan trọng trong bối cảnh AI đang phát triển nhanh chóng?",
        "options": {
          "A": "So sánh kinh nghiệm của các công ty khác nhau để tìm ra giải pháp tốt nhất.",
          "B": "Xây dựng một chiến lược AI toàn diện và tuân thủ nó một cách nghiêm ngặt.",
          "C": "Nhận biết các lĩnh vực mà Machine Learning đang có tác động và các vấn đề trong triển khai.",
          "D": "Tập trung vào việc phát triển các thuật toán AI mới và tiên tiến."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết dự đoán điều gì về năm tới liên quan đến MLOps?",
        "options": {
          "A": "Sự suy giảm trong đầu tư vào các công cụ và quy trình MLOps.",
          "B": "Sự phát triển chậm chạp do thiếu nhân lực có kỹ năng.",
          "C": "Sự tiến bộ nhanh chóng trong các quy trình và công cụ MLOps để xây dựng và sản xuất các hệ thống Machine Learning một cách có hệ thống.",
          "D": "Sự tập trung vào việc tối ưu hóa các mô hình hiện có thay vì phát triển các mô hình mới."
        },
        "answer": "C"
      },
      {
        "question": "AI Fund, nơi Andrew là đối tác quản lý chung, đã chứng kiến điều gì?",
        "options": {
          "A": "Sự sụt giảm đáng kể trong số lượng các công ty khởi nghiệp tham gia vào lĩnh vực AI.",
          "B": "Sự gia tăng đáng kể trong số lượng các công ty khởi nghiệp tham gia vào lĩnh vực MLOps.",
          "C": "Sự ổn định trong số lượng các công ty khởi nghiệp tham gia vào lĩnh vực AI.",
          "D": "Sự chuyển dịch từ các công ty khởi nghiệp AI sang các công ty lớn hơn."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của Algorithmia, công ty thực hiện khảo sát, là gì?",
        "options": {
          "A": "Cung cấp các dịch vụ tư vấn chiến lược AI cho các doanh nghiệp.",
          "B": "Phát triển các thuật toán Machine Learning mới và tiên tiến.",
          "C": "Cung cấp các công cụ tự động hóa việc triển khai và quản lý mô hình.",
          "D": "Đào tạo nhân lực có kỹ năng chuyên môn về AI."
        },
        "answer": "C"
      }
    ]
  },
  "ethical-ai-2-0": {
    "title": "Ethical AI 2.0",
    "collection": "business",
    "content": "Microsoft tightened the reins on both AI developers and customers.What’s new:The tech titan revised itsResponsible AI Standardand restricted access to some AI capabilities accordingly.\n\nTaking responsibility:The update is intended to support six core values.\n\nFace off:To comply with its new guidelines, the company limited AI services offered via its Azure Cloud platform.\n\nBehind the news:Microsoft published itsfirstResponsible AI Standard in 2019 but concluded that the initial draft was vague. The new version is intended to give developers clearer directions for compliance. To that end, the company alsoprovidesnearly 20 tools intended to aid developers in building responsible AI systems. For instance, HAX Workbook helps make AI systems easier to use, InterpretML helps explain model behavior, and Counterfit stress-tests security.Why it matters:Regulation in the United States and elsewhere lags rising concern that AI is growing more capable of causing harm even as it becomes enmeshed in everyday life. Microsoft’s latest moves represent a proactive effort to address the issue.We’re thinking:Hundreds of guidelines have been drafted to govern AI development. The efforts are laudable, but the results are seldom actionable. We applaud Microsoft for working to make its guidelines more concrete, and we’re eager to see how its new standards play out in practice.",
    "qa": [
      {
        "question": "Microsoft đã thực hiện hành động gì liên quan đến AI?",
        "options": {
          "A": "Tăng cường đầu tư vào các công ty khởi nghiệp AI.",
          "B": "Thắt chặt kiểm soát đối với các nhà phát triển và khách hàng AI.",
          "C": "Mở rộng quyền truy cập vào tất cả các khả năng AI.",
          "D": "Phát triển một nền tảng AI mới cho người dùng cá nhân."
        },
        "answer": "B"
      },
      {
        "question": "Tiêu chuẩn AI có trách nhiệm (Responsible AI Standard) mới của Microsoft nhằm hỗ trợ bao nhiêu giá trị cốt lõi?",
        "options": {
          "A": "3",
          "B": "6",
          "C": "9",
          "D": "12"
        },
        "answer": "B"
      },
      {
        "question": "Để tuân thủ các hướng dẫn mới, Microsoft đã hạn chế dịch vụ AI nào?",
        "options": {
          "A": "Dịch vụ AI được cung cấp thông qua Microsoft Office.",
          "B": "Dịch vụ AI được cung cấp thông qua Azure Cloud platform.",
          "C": "Dịch vụ AI được cung cấp thông qua LinkedIn.",
          "D": "Dịch vụ AI được cung cấp thông qua Xbox."
        },
        "answer": "B"
      },
      {
        "question": "Microsoft lần đầu tiên công bố Tiêu chuẩn AI có trách nhiệm vào năm nào?",
        "options": {
          "A": "2016",
          "B": "2019",
          "C": "2021",
          "D": "2023"
        },
        "answer": "B"
      },
      {
        "question": "Lý do chính khiến Microsoft cập nhật Tiêu chuẩn AI có trách nhiệm là gì?",
        "options": {
          "A": "Để giảm chi phí phát triển AI.",
          "B": "Để cung cấp hướng dẫn rõ ràng hơn cho các nhà phát triển về tuân thủ.",
          "C": "Để cạnh tranh với các công ty AI khác.",
          "D": "Để đáp ứng yêu cầu của các nhà đầu tư."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ HAX Workbook giúp ích gì trong việc phát triển AI?",
        "options": {
          "A": "Tăng tốc độ xử lý của các mô hình AI.",
          "B": "Giúp hệ thống AI dễ sử dụng hơn.",
          "C": "Cải thiện độ chính xác của các dự đoán AI.",
          "D": "Giảm thiểu lượng dữ liệu cần thiết để đào tạo AI."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ InterpretML có chức năng gì?",
        "options": {
          "A": "Kiểm tra bảo mật của hệ thống AI.",
          "B": "Giải thích hành vi của mô hình AI.",
          "C": "Tự động tạo mã cho các ứng dụng AI.",
          "D": "Tối ưu hóa hiệu suất của các thuật toán AI."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ Counterfit được sử dụng để làm gì?",
        "options": {
          "A": "Phát hiện lỗi trong dữ liệu đào tạo AI.",
          "B": "Đánh giá tác động xã hội của các hệ thống AI.",
          "C": "Kiểm tra độ bền của hệ thống AI trước các cuộc tấn công.",
          "D": "Tạo ra các mô hình AI giả lập để thử nghiệm."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì được cho là đang tụt hậu so với sự phát triển nhanh chóng của AI?",
        "options": {
          "A": "Sự phát triển của phần cứng máy tính.",
          "B": "Quy định pháp luật về AI ở Hoa Kỳ và các nơi khác.",
          "C": "Sự quan tâm của công chúng đối với AI.",
          "D": "Số lượng nhà nghiên cứu AI."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đánh giá như thế nào về nỗ lực của Microsoft trong việc tạo ra các hướng dẫn AI có trách nhiệm?",
        "options": {
          "A": "Chỉ trích vì quá chung chung và không thực tế.",
          "B": "Khen ngợi vì đã làm cho các hướng dẫn cụ thể hơn.",
          "C": "Cho rằng không cần thiết vì đã có quá nhiều hướng dẫn.",
          "D": "Phản đối vì hạn chế sự sáng tạo trong phát triển AI."
        },
        "answer": "B"
      }
    ]
  },
  "european-central-bank-study-finds-surprising-growth-in-jobs-affected-by-ai": {
    "title": "AI Creates Jobs, Study Suggests",
    "collection": "business",
    "content": "Europeans are keeping their jobs even as AI does an increasing amount of work.\n\nWhat’s new:Researchers at the European Central Bankfoundthat employment in occupations affected by AI rose over nearly a decade.\n\nHow it works:The authors considered jobs that were found to be affected by AI over the past decade according totwostudies. As a control group, they considered jobs affected by software generally (“recording, storing, and producing information, and executing programs, logic, and rules”), as detailed in one of the studies. They measured changes in employment and wages in those jobs based on asurveyof workers in 16 European countries between 2011 and 2019.\n\nResults:The researchers found that exposure to AI was associated with greater employment for some workers and had little effect on wages.\n\nBehind the news:Other studies suggest that automation in general and AI technology in particular may benefit the workforce as a whole.\n\nYes, but:It may be too soon to get a clear view of AI’s impact on employment, the authors point out. The data that underlies every study to date ends in 2019, predating ChatGPT and the present wave of generative AI. Furthermore, the impact of AI in European countries varies with their individual economic conditions (for instance, Greece tends to lose more jobs than Germany).\n\nWhy it matters:Many employees fear that AI — and generative AI in particular — will take their jobs. Around the world, the public isnervousabout the technology’s potential impact on employment. Follow-up studies using more recent data could turn these fears into more realistic — and more productive — appraisals.\n\nWe’re thinking:AI is likely to take some jobs. We feel deeply for workers whose livelihoods are affected, and society has a responsibility to create a safety net to help them. To date, at least, the impact has been less than many observers feared. One reason may be that jobs are made up of many tasks, and AI automates tasks rather than jobs. In many jobs, AI can automate a subset of the work while the jobs continue to be filled by humans, who may earn a higher wage if AI helps them be more productive.",
    "qa": [
      {
        "question": "Nghiên cứu của Ngân hàng Trung ương Châu Âu (ECB) cho thấy điều gì về việc làm trong các lĩnh vực chịu ảnh hưởng bởi AI?",
        "options": {
          "A": "Việc làm giảm đáng kể do AI thay thế nhân công.",
          "B": "Việc làm tăng lên trong gần một thập kỷ.",
          "C": "Việc làm không thay đổi, nhưng tiền lương giảm.",
          "D": "Việc làm chỉ tăng ở một số quốc gia nhất định."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu của ECB sử dụng nhóm đối chứng nào để so sánh với các công việc chịu ảnh hưởng bởi AI?",
        "options": {
          "A": "Các công việc trong ngành sản xuất.",
          "B": "Các công việc bị ảnh hưởng bởi phần mềm nói chung.",
          "C": "Các công việc trong lĩnh vực dịch vụ.",
          "D": "Các công việc không bị ảnh hưởng bởi công nghệ."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu trong nghiên cứu của ECB được thu thập từ cuộc khảo sát người lao động ở bao nhiêu quốc gia châu Âu?",
        "options": {
          "A": "10",
          "B": "12",
          "C": "14",
          "D": "16"
        },
        "answer": "D"
      },
      {
        "question": "Theo nghiên cứu của ECB, tác động của AI đối với tiền lương của người lao động là gì?",
        "options": {
          "A": "Tiền lương tăng đáng kể.",
          "B": "Tiền lương giảm đáng kể.",
          "C": "Có ít ảnh hưởng đến tiền lương.",
          "D": "Tiền lương chỉ tăng ở các công việc đòi hỏi kỹ năng cao."
        },
        "answer": "C"
      },
      {
        "question": "Một hạn chế được chỉ ra trong bài viết về các nghiên cứu hiện tại về tác động của AI là gì?",
        "options": {
          "A": "Các nghiên cứu chỉ tập trung vào một số ngành công nghiệp nhất định.",
          "B": "Các nghiên cứu không xem xét đến tác động của AI đối với người lao động lớn tuổi.",
          "C": "Dữ liệu của các nghiên cứu thường kết thúc trước khi có sự xuất hiện của ChatGPT và AI tạo sinh.",
          "D": "Các nghiên cứu không tính đến sự khác biệt về văn hóa giữa các quốc gia."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến quốc gia nào có xu hướng mất việc làm nhiều hơn so với Đức do tác động của AI?",
        "options": {
          "A": "Pháp",
          "B": "Ý",
          "C": "Hy Lạp",
          "D": "Tây Ban Nha"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì khiến công chúng lo lắng về AI, theo như bài viết?",
        "options": {
          "A": "Khả năng AI gây ra các vấn đề về đạo đức.",
          "B": "Khả năng AI ảnh hưởng tiêu cực đến việc làm.",
          "C": "Khả năng AI vượt qua trí thông minh của con người.",
          "D": "Khả năng AI gây ra các cuộc tấn công mạng."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết gợi ý rằng xã hội có trách nhiệm gì đối với những người lao động bị ảnh hưởng bởi AI?",
        "options": {
          "A": "Cấm sử dụng AI trong các ngành công nghiệp.",
          "B": "Tạo ra một mạng lưới an toàn để giúp đỡ họ.",
          "C": "Đào tạo lại họ để làm việc trong các lĩnh vực khác.",
          "D": "Cung cấp cho họ các khoản trợ cấp thất nghiệp lớn hơn."
        },
        "answer": "B"
      },
      {
        "question": "Một lý do được đưa ra giải thích tại sao tác động của AI đến việc làm ít hơn so với lo ngại ban đầu là gì?",
        "options": {
          "A": "AI chỉ tự động hóa các công việc đơn giản.",
          "B": "AI chủ yếu được sử dụng trong các ngành công nghiệp mới.",
          "C": "AI tự động hóa các tác vụ chứ không phải toàn bộ công việc.",
          "D": "AI cần sự giám sát liên tục của con người."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, AI có thể giúp người lao động kiếm được mức lương cao hơn bằng cách nào?",
        "options": {
          "A": "Bằng cách giảm giờ làm việc.",
          "B": "Bằng cách tăng cường sự sáng tạo của họ.",
          "C": "Bằng cách giúp họ làm việc hiệu quả hơn.",
          "D": "Bằng cách loại bỏ sự cạnh tranh từ các đồng nghiệp."
        },
        "answer": "C"
      }
    ]
  },
  "european-regulators-move-to-relax-some-ai-act-rules-on-developers-liability-other-provisions": {
    "title": "EU Loosens AI Regulations",
    "collection": "business",
    "content": "The European Union made an abrupt U-turn away from its stringent AI regulations. Meta promptly adjusted to the loosening restrictions.\n\nWhat’s new:Henna Virkkunen, the EU’s head of digital policy, said the organization wouldeaserules and requirements to support Europe’s competitiveness in AI.\n\nHow it works:Adopted last year, the EU’sAI Actprovides a comprehensive framework for regulating AI that aims to reduce purported risks by banning certain applications, restricting others, and requiring extensive documentation of development efforts. The law is set to take effect in August, empowering various regulatory bodies to formulate detailed rules. However, in recent months, the EU has faced increasing pressure from the U.S. government and large AI companies to reduce the regulatory burden.\n\nBehind the news:In drafting the AI Act, the EU aspired to a comprehensive, specific set of regulations. However, not all European lawmakers agreed that rules were needed. Virkkunen’s supporters noted that existing laws already allowed consumers to file claims against AI companies. Meanwhile, some policymakers havebecome less worriedabout AI than they were during the early drafting of the AI Act.\n\nWhy it matters:It’s unlikely that all nations – or evenstateswithin nations – will ever agree fully on rules and regulations that govern AI companies that do business within their borders, or protections from flaws such as model bias. But AI companies including Meta,OpenAI, andothersargue that a more uniform regulatory environment will make it easier to serve users worldwide.\n\nWe’re thinking:The EU overreached with the AI Act. Fortunately, the legislation provides enough flexibility to pull back. Clearer rules will help European teams innovate and European and international companies better serve EU citizens.",
    "qa": [
      {
        "question": "Điều gì đã khiến Liên minh Châu Âu thay đổi hướng đi đột ngột liên quan đến các quy định về AI?",
        "options": {
          "A": "Meta đã yêu cầu EU nới lỏng các quy định.",
          "B": "EU muốn hỗ trợ khả năng cạnh tranh của Châu Âu trong lĩnh vực AI.",
          "C": "Luật AI của EU đã được chứng minh là không hiệu quả.",
          "D": "Các quốc gia thành viên EU không đồng ý với Luật AI."
        },
        "answer": "B"
      },
      {
        "question": "Luật AI của EU, được thông qua năm ngoái, chủ yếu tập trung vào điều gì?",
        "options": {
          "A": "Thúc đẩy sự phát triển nhanh chóng của các ứng dụng AI mới.",
          "B": "Giảm thiểu các rủi ro tiềm ẩn bằng cách cấm một số ứng dụng và hạn chế những ứng dụng khác.",
          "C": "Cung cấp nguồn tài trợ lớn cho các công ty AI Châu Âu.",
          "D": "Đảm bảo rằng tất cả các công ty AI đều tuân thủ các tiêu chuẩn đạo đức."
        },
        "answer": "B"
      },
      {
        "question": "Thời điểm dự kiến Luật AI của EU có hiệu lực là khi nào?",
        "options": {
          "A": "Tháng 1 năm sau.",
          "B": "Tháng 6 năm nay.",
          "C": "Tháng 8 năm nay.",
          "D": "Đã có hiệu lực từ năm ngoái."
        },
        "answer": "C"
      },
      {
        "question": "Áp lực giảm bớt gánh nặng quy định đối với Luật AI của EU đến từ đâu?",
        "options": {
          "A": "Các tổ chức phi chính phủ và các nhóm bảo vệ quyền riêng tư.",
          "B": "Chính phủ Hoa Kỳ và các công ty AI lớn.",
          "C": "Các quốc gia thành viên EU có nền kinh tế yếu kém.",
          "D": "Người tiêu dùng Châu Âu lo ngại về sự phát triển của AI."
        },
        "answer": "B"
      },
      {
        "question": "Một số người ủng hộ việc nới lỏng quy định AI của EU lập luận điều gì?",
        "options": {
          "A": "Các công ty AI không cần bất kỳ quy định nào.",
          "B": "Luật hiện hành đã cho phép người tiêu dùng khiếu nại các công ty AI.",
          "C": "AI không còn là một mối lo ngại lớn như trước đây.",
          "D": "Tất cả các lựa chọn trên."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu ban đầu của EU khi soạn thảo Luật AI là gì?",
        "options": {
          "A": "Tạo ra một bộ quy định chung và không cụ thể.",
          "B": "Tạo ra một bộ quy định toàn diện và cụ thể.",
          "C": "Cho phép các quốc gia thành viên tự quy định về AI.",
          "D": "Cấm hoàn toàn việc sử dụng AI trong một số lĩnh vực."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, các công ty AI như Meta và OpenAI cho rằng điều gì sẽ giúp họ phục vụ người dùng trên toàn thế giới tốt hơn?",
        "options": {
          "A": "Một môi trường pháp lý ít quy định hơn.",
          "B": "Một môi trường pháp lý thống nhất hơn.",
          "C": "Sự hỗ trợ tài chính từ chính phủ các nước.",
          "D": "Việc sử dụng các mô hình AI tiên tiến nhất."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết cho rằng điều gì về khả năng thống nhất các quy định về AI trên toàn cầu?",
        "options": {
          "A": "Hoàn toàn có thể đạt được sự đồng thuận toàn cầu trong tương lai gần.",
          "B": "Rất khó có khả năng tất cả các quốc gia hoặc thậm chí các bang trong một quốc gia sẽ đồng ý hoàn toàn về các quy định.",
          "C": "Chỉ cần các quốc gia lớn đồng ý, các quốc gia nhỏ sẽ tuân theo.",
          "D": "Sự đồng thuận toàn cầu đã đạt được, chỉ cần thực thi."
        },
        "answer": "B"
      },
      {
        "question": "Theo quan điểm của bài viết, điều gì đã xảy ra với Luật AI của EU?",
        "options": {
          "A": "EU đã hoàn toàn từ bỏ Luật AI.",
          "B": "EU đã đi quá xa với Luật AI ban đầu.",
          "C": "Luật AI của EU đã được chứng minh là hoàn toàn thành công.",
          "D": "Luật AI của EU cần được thắt chặt hơn nữa."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết cho rằng, việc nới lỏng quy định AI của EU sẽ giúp ích như thế nào?",
        "options": {
          "A": "Giúp các đội ngũ Châu Âu đổi mới và các công ty phục vụ công dân EU tốt hơn.",
          "B": "Giúp các công ty AI tránh được việc phải tuân thủ các quy định.",
          "C": "Giúp các công ty AI tăng lợi nhuận một cách nhanh chóng.",
          "D": "Giúp các công ty AI dễ dàng trốn thuế hơn."
        },
        "answer": "A"
      }
    ]
  },
  "every-problem-looks-like-a-nail": {
    "title": "Every Problem Looks Like a Nail",
    "collection": "business",
    "content": "Robots are brushing their way into the beauty market.What’s new:A trio of companies is developing automated nail-painting devices that integrate robotics and computer vision,The New York Timesreported.How it works:Users select a color and place a hand or finger into a slot in a toaster-sized machine. The system scans the fingertips, and an automated paint dispenser — in some cases, a mechanical arm tipped by a brush — coats each nail. These machines update earlier nail-decorating gadgets that, say, applied decals without using AI.\n\nBehind the news: The beauty industry has embraced a variety of AI techniques.\n\nWhy it matters:Americans spent$8.3 billionon nail care last year. Automated systems could appeal to people who are looking for a fast makeover as well as those who want to continue social distancing without foregoing manicures. But such systems also could also displace workers who already contend withlow wages.We’re thinking:Paint your nails or don’t, but everyone who writes code should take good care of their hands.",
    "qa": [
      {
        "question": "Công nghệ mới nào đang được giới thiệu vào thị trường làm đẹp theo bài viết?",
        "options": {
          "A": "Các thiết bị trang điểm tự động sử dụng công nghệ in 3D.",
          "B": "Các thiết bị sơn móng tay tự động tích hợp robot và thị giác máy tính.",
          "C": "Các ứng dụng AI giúp người dùng lựa chọn màu sơn móng tay phù hợp.",
          "D": "Các loại sơn móng tay có khả năng tự động thay đổi màu sắc."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, thiết bị sơn móng tay tự động hoạt động như thế nào?",
        "options": {
          "A": "Người dùng quét vân tay và máy sẽ tự động chọn màu sơn phù hợp.",
          "B": "Người dùng chọn màu sơn, đặt tay vào máy, hệ thống quét đầu ngón tay và bộ phận sơn tự động sẽ sơn.",
          "C": "Người dùng tải ảnh bàn tay lên ứng dụng và máy sẽ mô phỏng quá trình sơn.",
          "D": "Người dùng điều khiển cánh tay robot để tự sơn móng tay theo hướng dẫn của máy."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính giữa các thiết bị sơn móng tay tự động mới và các thiết bị cũ là gì?",
        "options": {
          "A": "Thiết bị mới có kích thước nhỏ gọn hơn.",
          "B": "Thiết bị mới sử dụng công nghệ AI thay vì chỉ dán decal.",
          "C": "Thiết bị mới có nhiều màu sơn hơn.",
          "D": "Thiết bị mới có giá thành rẻ hơn."
        },
        "answer": "B"
      },
      {
        "question": "Ngành công nghiệp làm đẹp đã ứng dụng AI bằng cách nào?",
        "options": {
          "A": "AI được sử dụng để tạo ra các sản phẩm làm đẹp mới.",
          "B": "AI được sử dụng trong nhiều kỹ thuật khác nhau của ngành làm đẹp.",
          "C": "AI được sử dụng để quảng cáo các sản phẩm làm đẹp.",
          "D": "AI được sử dụng để phân tích xu hướng làm đẹp."
        },
        "answer": "B"
      },
      {
        "question": "Thị trường chăm sóc móng tay ở Mỹ đã đạt doanh thu bao nhiêu vào năm ngoái?",
        "options": {
          "A": "8.3 triệu đô la.",
          "B": "83 triệu đô la.",
          "C": "8.3 tỷ đô la.",
          "D": "83 tỷ đô la."
        },
        "answer": "C"
      },
      {
        "question": "Đối tượng nào có thể bị thu hút bởi các hệ thống sơn móng tay tự động?",
        "options": {
          "A": "Những người muốn tiết kiệm chi phí làm đẹp.",
          "B": "Những người tìm kiếm sự thay đổi nhanh chóng và những người muốn tiếp tục giãn cách xã hội.",
          "C": "Những người thích tự tay làm đẹp.",
          "D": "Những người có vấn đề về sức khỏe không thể đến tiệm nail."
        },
        "answer": "B"
      },
      {
        "question": "Một trong những lo ngại được đề cập về hệ thống sơn móng tay tự động là gì?",
        "options": {
          "A": "Giá thành của các hệ thống này quá cao.",
          "B": "Các hệ thống này có thể gây hại cho sức khỏe của người dùng.",
          "C": "Các hệ thống này có thể thay thế người lao động có thu nhập thấp.",
          "D": "Các hệ thống này có thể gây ô nhiễm môi trường."
        },
        "answer": "C"
      },
      {
        "question": "Thông điệp cuối bài viết muốn nhắn nhủ điều gì?",
        "options": {
          "A": "Hãy sơn móng tay thường xuyên để giữ gìn vẻ đẹp.",
          "B": "Dù bạn có sơn móng tay hay không, những người viết code nên chăm sóc đôi tay của mình.",
          "C": "Hãy ủng hộ các sản phẩm làm đẹp tự động.",
          "D": "Hãy học cách viết code để tạo ra các sản phẩm làm đẹp mới."
        },
        "answer": "B"
      },
      {
        "question": "Kích thước của thiết bị sơn móng tay tự động được so sánh với vật dụng nào?",
        "options": {
          "A": "Một chiếc lò vi sóng.",
          "B": "Một chiếc máy nướng bánh mì.",
          "C": "Một chiếc máy tính để bàn.",
          "D": "Một chiếc điện thoại thông minh."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, bộ phận nào của máy sơn móng tay tự động thực hiện việc sơn?",
        "options": {
          "A": "Một hệ thống phun sơn tĩnh điện.",
          "B": "Một cánh tay cơ khí gắn cọ sơn.",
          "C": "Một hệ thống in 3D mini.",
          "D": "Một hệ thống laser tạo màu."
        },
        "answer": "B"
      }
    ]
  },
  "everything-you-need-to-know-about-gpt-4": {
    "title": "GPT-4 Has Landed",
    "collection": "business",
    "content": "Get ready for the next wave of language-model mania.What’s new:OpenAIintroducedthe latest in its GPT series of large language models to widespread excitement. The company showed statistics and examples designed to demonstrate that the new model outstrips its predecessors in its language comprehension as well as its ability to adopt a desired style and tone and stay within bounds imposed by its designers. OpenAI co-founder Greg Brockman showed off some of its capabilities in alivestreamthat accompanied the launch.How to get access:Text input/output is available viaChatGPT Plus, which costs $20 monthly, with image input to come. An API is forthcoming, and you can join the waitlisthere.How it works:OpenAI didn’t share many details, citing concerns about safety and competition. Like earlier GPT models,GPT-4is based on the transformer architecture and trained to predict the next token on a mix of public and private datasets. It was fine-tuned using reinforcement learning from human feedback and engineered prompts.\n\nHow it performs:GPT-4 aced a variety of AI benchmarks as well as simulated versions of tests designed for humans.\n\nWhere it works:Several companies are already using GPT-4.\n\nYes, but:OpenAI doesn’t mince words about the new model’s potential to wreak havoc: “While less capable than humans in many real-world scenarios . . . GPT-4's capabilities and limitations create significant and novel safety challenges.” While the model outperformed its predecessors in internal adversarial evaluations of factual correctness, like other large language models, it still invents facts, makes reasoning errors, generates biased output, and couches incorrect statements in confident language. In addition, it lacks knowledge of events that transpired after September 2021, when its training corpus was finalized. OpenAI details the safety issueshere.Why it matters:As language models become more capable, they become more useful. It’s notable that OpenAI believes this model is ready to commercialize from the get-go: This is the first time it has introduced a new model alongside product launches that take advantage of it.We’re thinking:Stable Diffusion, Phenaki, MusicLM, GPT-4: This is truly a golden time in AI!",
    "qa": [
      {
        "question": "GPT-4 được giới thiệu với những cải tiến chính nào so với các phiên bản trước?",
        "options": {
          "A": "Khả năng tạo ra âm nhạc và hình ảnh chất lượng cao hơn.",
          "B": "Khả năng hiểu ngôn ngữ, áp dụng phong cách mong muốn và tuân thủ các giới hạn được đặt ra.",
          "C": "Tốc độ xử lý dữ liệu nhanh hơn gấp 10 lần.",
          "D": "Khả năng tự động cập nhật kiến thức sau tháng 9 năm 2021."
        },
        "answer": "B"
      },
      {
        "question": "Người dùng có thể truy cập GPT-4 thông qua những phương thức nào hiện tại?",
        "options": {
          "A": "Miễn phí thông qua trang web chính thức của OpenAI.",
          "B": "Thông qua ChatGPT Plus với mức phí 20 đô la mỗi tháng và API đang được phát triển.",
          "C": "Chỉ dành cho các đối tác doanh nghiệp của OpenAI.",
          "D": "Thông qua ứng dụng di động độc quyền của OpenAI."
        },
        "answer": "B"
      },
      {
        "question": "OpenAI hạn chế chia sẻ chi tiết về cách thức hoạt động của GPT-4 vì lý do chính nào?",
        "options": {
          "A": "Do lo ngại về chi phí phát triển và bảo trì.",
          "B": "Do lo ngại về an toàn và cạnh tranh.",
          "C": "Do tính phức tạp của thuật toán khiến việc giải thích trở nên khó khăn.",
          "D": "Do yêu cầu bảo mật từ các đối tác sử dụng GPT-4."
        },
        "answer": "B"
      },
      {
        "question": "GPT-4 đã thể hiện khả năng như thế nào trong các bài kiểm tra mô phỏng dành cho con người?",
        "options": {
          "A": "Không đạt yêu cầu trong hầu hết các bài kiểm tra.",
          "B": "Đạt điểm cao trong nhiều bài kiểm tra AI và các phiên bản mô phỏng của các bài kiểm tra dành cho con người.",
          "C": "Chỉ đạt điểm cao trong các bài kiểm tra liên quan đến ngôn ngữ.",
          "D": "Chỉ đạt điểm cao khi được cung cấp dữ liệu đầu vào cụ thể."
        },
        "answer": "B"
      },
      {
        "question": "Theo OpenAI, GPT-4 có những hạn chế và rủi ro tiềm ẩn nào?",
        "options": {
          "A": "Không có hạn chế và rủi ro nào đáng kể.",
          "B": "Khả năng tạo ra thông tin sai lệch, đưa ra các lỗi logic, tạo ra kết quả thiên vị và thiếu kiến thức về các sự kiện sau tháng 9 năm 2021.",
          "C": "Chỉ có khả năng tạo ra kết quả thiên vị.",
          "D": "Chỉ thiếu kiến thức về các sự kiện sau tháng 9 năm 2021."
        },
        "answer": "B"
      },
      {
        "question": "Thời điểm kết thúc tập dữ liệu huấn luyện của GPT-4 là khi nào?",
        "options": {
          "A": "Tháng 12 năm 2022.",
          "B": "Tháng 9 năm 2021.",
          "C": "Tháng 3 năm 2023.",
          "D": "Không được tiết lộ."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì khiến OpenAI tin rằng GPT-4 đã sẵn sàng để thương mại hóa ngay từ đầu?",
        "options": {
          "A": "Do chi phí phát triển thấp.",
          "B": "Do đây là lần đầu tiên OpenAI giới thiệu một mô hình mới cùng với các sản phẩm tận dụng nó.",
          "C": "Do áp lực từ các nhà đầu tư.",
          "D": "Do sự cạnh tranh gay gắt từ các công ty khác."
        },
        "answer": "B"
      },
      {
        "question": "Kiến trúc nền tảng của GPT-4 là gì?",
        "options": {
          "A": "Mạng nơ-ron tích chập (Convolutional Neural Network).",
          "B": "Kiến trúc Transformer.",
          "C": "Mạng nơ-ron hồi quy (Recurrent Neural Network).",
          "D": "Mạng đối nghịch sinh (Generative Adversarial Network)."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp nào được sử dụng để tinh chỉnh GPT-4?",
        "options": {
          "A": "Học có giám sát hoàn toàn.",
          "B": "Học tăng cường từ phản hồi của con người và các kỹ thuật prompt engineering.",
          "C": "Học không giám sát.",
          "D": "Học bán giám sát."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì đang diễn ra trong lĩnh vực AI hiện nay?",
        "options": {
          "A": "Một giai đoạn suy thoái do thiếu hụt nguồn lực.",
          "B": "Một kỷ nguyên vàng với sự phát triển vượt bậc của các mô hình như Stable Diffusion, Phenaki, MusicLM và GPT-4.",
          "C": "Một cuộc khủng hoảng đạo đức do lo ngại về việc sử dụng AI sai mục đích.",
          "D": "Một giai đoạn ổn định sau những bước tiến ban đầu."
        },
        "answer": "B"
      }
    ]
  },
  "eyes-on-the-assembly-line": {
    "title": "Eyes on the Assembly Line",
    "collection": "business",
    "content": "AI may not steal your job, but it can tell the boss when you’re slacking.What’s new:Drishti, a startup based in Palo Alto and Bengaluru, tracks the productivity of industrial workers by recognizing their actions on the assembly line. Automotive parts giant Denso is using the technology to eliminate bottlenecks in its factory in Battle Creek, Michigan, according toWired.How it works:Drishti trains the system to recognize standardized actions in the client’s industrial processes.\n\nBehind the news:Drishti’s founders include Prasad Akella, who led General Motors’ efforts to developcollaborative robots, and computer vision expert Krishnendu Chadbury, who led teams at Google, Adobe, and Flipkart.Why it matters: Manufacturing is a$14 trillion industry. According toresearchsponsored by Drishti, humans perform 72 percent of the work, and human error causes 68 percent of defects. Using AI to help people work more efficiently could yield substantial gains.Yes, but:Workers in some industries are pushing back against automated management. Last year, dozens of employeeswalked outof Amazon warehouses to protest the pace of work demanded by AI-powered supervisors, which they said led to dangerous conditions.We’re thinking:Complaining about the quality of others’ work while not doing any yourself? Computers are becoming more like humans all the time!",
    "qa": [
      {
        "question": "Công ty Drishti có trụ sở chính ở đâu?",
        "options": {
          "A": "Battle Creek, Michigan",
          "B": "Palo Alto và Bengaluru",
          "C": "Detroit, Michigan",
          "D": "Mountain View, California"
        },
        "answer": "B"
      },
      {
        "question": "Công ty Denso sử dụng công nghệ của Drishti để làm gì?",
        "options": {
          "A": "Tăng cường an toàn lao động",
          "B": "Loại bỏ các điểm nghẽn trong nhà máy",
          "C": "Thay thế hoàn toàn công nhân bằng robot",
          "D": "Giảm chi phí năng lượng"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, ai là một trong những người sáng lập Drishti?",
        "options": {
          "A": "Jeff Bezos",
          "B": "Elon Musk",
          "C": "Prasad Akella",
          "D": "Bill Gates"
        },
        "answer": "C"
      },
      {
        "question": "Prasad Akella trước đây đã dẫn đầu nỗ lực phát triển cái gì tại General Motors?",
        "options": {
          "A": "Xe tự lái",
          "B": "Robot cộng tác",
          "C": "Động cơ điện",
          "D": "Hệ thống quản lý chuỗi cung ứng"
        },
        "answer": "B"
      },
      {
        "question": "Ngành sản xuất được định giá khoảng bao nhiêu theo bài viết?",
        "options": {
          "A": "$4 nghìn tỷ",
          "B": "$14 nghìn tỷ",
          "C": "$24 nghìn tỷ",
          "D": "$34 nghìn tỷ"
        },
        "answer": "B"
      },
      {
        "question": "Theo nghiên cứu được tài trợ bởi Drishti, lỗi do con người gây ra bao nhiêu phần trăm lỗi?",
        "options": {
          "A": "50%",
          "B": "68%",
          "C": "72%",
          "D": "80%"
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã xảy ra tại các nhà kho của Amazon liên quan đến việc quản lý tự động?",
        "options": {
          "A": "Công nhân được tăng lương",
          "B": "Công nhân đình công phản đối tốc độ làm việc",
          "C": "Công nhân được đào tạo kỹ năng mới",
          "D": "Công nhân được nghỉ phép nhiều hơn"
        },
        "answer": "B"
      },
      {
        "question": "Krishnendu Chadbury là chuyên gia trong lĩnh vực nào?",
        "options": {
          "A": "Kỹ thuật cơ khí",
          "B": "Thị giác máy tính",
          "C": "Quản lý chuỗi cung ứng",
          "D": "Kỹ thuật hóa học"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến việc sử dụng AI trong sản xuất có thể mang lại điều gì?",
        "options": {
          "A": "Giảm số lượng công nhân",
          "B": "Tăng hiệu quả làm việc",
          "C": "Tăng chi phí sản xuất",
          "D": "Giảm chất lượng sản phẩm"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, con người thực hiện bao nhiêu phần trăm công việc trong ngành sản xuất?",
        "options": {
          "A": "50%",
          "B": "68%",
          "C": "72%",
          "D": "80%"
        },
        "answer": "C"
      }
    ]
  },
  "flight-paths-optimized": {
    "title": "Flight Paths Optimized",
    "collection": "business",
    "content": "An AI system is helping aircraft avoid bad weather, restricted airspace, and clogged runways.\n\nWhat’s new:Alaska Airlineswill route all its flights using a system fromAirspace Intelligencecalled Flyways.\n\nHow it works:The system evaluates weather data, federal airspace closures, and the routes of all planned and active flights in the U.S. to find the most efficient paths for aircraft to reach their destinations.\n\nBehind the news:AI is making inroads into several areas of air transport.\n\nWhy it matters:Commercial air travel gotwallopedby the pandemic. Streamlining operations may be necessary to revive it, according to theU.S. Travel Association.\n\nWe’re thinking:Unlike cars and trucks, airplanes can’t easily go electric, so they’re stuck with fossil fuels for the foreseeable future. Cutting theircarbon emissionswill benefit everyone.",
    "qa": [
      {
        "question": "Hệ thống AI được đề cập trong bài viết giúp máy bay tránh những vấn đề gì?",
        "options": {
          "A": "Va chạm với các phương tiện khác trên mặt đất.",
          "B": "Thời tiết xấu, không phận hạn chế và đường băng tắc nghẽn.",
          "C": "Sự cố kỹ thuật và lỗi của phi công.",
          "D": "Chi phí nhiên liệu cao và sự chậm trễ do hành khách."
        },
        "answer": "B"
      },
      {
        "question": "Hãng hàng không nào sẽ sử dụng hệ thống Flyways của Airspace Intelligence?",
        "options": {
          "A": "United Airlines.",
          "B": "Delta Airlines.",
          "C": "American Airlines.",
          "D": "Alaska Airlines."
        },
        "answer": "D"
      },
      {
        "question": "Hệ thống Flyways hoạt động bằng cách đánh giá những yếu tố nào?",
        "options": {
          "A": "Giá vé máy bay, số lượng hành khách và đánh giá của khách hàng.",
          "B": "Dữ liệu thời tiết, lệnh đóng không phận liên bang và lộ trình của các chuyến bay.",
          "C": "Tình trạng kỹ thuật của máy bay, kinh nghiệm của phi công và quy định an toàn.",
          "D": "Mức độ ô nhiễm tiếng ồn, mật độ dân cư và quy hoạch đô thị."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lĩnh vực nào đang chứng kiến sự thâm nhập của AI?",
        "options": {
          "A": "Nông nghiệp công nghệ cao.",
          "B": "Vận tải hàng không.",
          "C": "Sản xuất ô tô điện.",
          "D": "Năng lượng tái tạo."
        },
        "answer": "B"
      },
      {
        "question": "Theo Hiệp hội Du lịch Hoa Kỳ, việc hợp lý hóa hoạt động hàng không có thể cần thiết để làm gì?",
        "options": {
          "A": "Giảm giá vé máy bay.",
          "B": "Tăng cường an ninh hàng không.",
          "C": "Phục hồi ngành du lịch sau đại dịch.",
          "D": "Nâng cao chất lượng dịch vụ trên chuyến bay."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến một hạn chế lớn của máy bay so với ô tô và xe tải là gì?",
        "options": {
          "A": "Khả năng chở hàng hóa ít hơn.",
          "B": "Khả năng di chuyển linh hoạt hơn.",
          "C": "Khó chuyển đổi sang sử dụng điện.",
          "D": "Chi phí bảo trì cao hơn."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhấn mạnh lợi ích của việc giảm lượng khí thải carbon từ máy bay là gì?",
        "options": {
          "A": "Tăng cường hiệu quả kinh tế của ngành hàng không.",
          "B": "Cải thiện sức khỏe của phi công và hành khách.",
          "C": "Giảm thiểu tác động tiêu cực đến môi trường và sức khỏe cộng đồng.",
          "D": "Nâng cao uy tín của các hãng hàng không."
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống Flyways giúp máy bay tìm kiếm điều gì?",
        "options": {
          "A": "Các điểm đến du lịch hấp dẫn nhất.",
          "B": "Các phi công có kinh nghiệm nhất.",
          "C": "Các đường bay hiệu quả nhất.",
          "D": "Các sân bay có chi phí hạ cánh thấp nhất."
        },
        "answer": "C"
      },
      {
        "question": "Cụm từ \"walloped\" trong bài viết có nghĩa là gì?",
        "options": {
          "A": "Được hưởng lợi.",
          "B": "Bị ảnh hưởng nặng nề.",
          "C": "Phát triển mạnh mẽ.",
          "D": "Ổn định."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu cuối cùng của việc sử dụng AI trong ngành hàng không, theo bài viết, là gì?",
        "options": {
          "A": "Tăng cường sự cạnh tranh giữa các hãng hàng không.",
          "B": "Giảm thiểu chi phí đào tạo phi công.",
          "C": "Cải thiện hiệu quả hoạt động và giảm lượng khí thải carbon.",
          "D": "Tăng cường sự thoải mái cho hành khách trên các chuyến bay."
        },
        "answer": "C"
      }
    ]
  },
  "forecasting-blockbusters": {
    "title": "Forecasting Blockbusters",
    "collection": "business",
    "content": "Could a black box become Hollywood’s crystal ball?What’s new:Warner Bros. is using an AI-powered tool that predicts a movie’s box-office success, according toHollywood Reporter.How it works:Cinelyticpromotesits software as a project-management platform to help movie execs make decisions throughout a film’s lifecycle. The company says it’s looking not to automate decision making but to make human managers more effective.\n\nBehind the news:Hollywood honchos have been experimenting with AI to help them home in on blockbusters and award winners for a few years. A growing number of companies are after a piece of the action.\n\nWhy it matters:Movies can cost hundreds of millions of dollars to make, so producers are eager for any insight that can return their investment at the box office. Predictive systems could be especially helpful around film festivals, when executives often have to jump into fast-moving bidding wars.We’re thinking:This kind of approach lends itself to many industries. We look forward to one for publishing AI newsletters.",
    "qa": [
      {
        "question": "Công cụ AI mà Warner Bros. đang sử dụng được thiết kế để làm gì?",
        "options": {
          "A": "Tự động hóa hoàn toàn quá trình sản xuất phim.",
          "B": "Dự đoán khả năng thành công về doanh thu phòng vé của một bộ phim.",
          "C": "Thay thế các nhà quản lý trong việc đưa ra quyết định.",
          "D": "Viết kịch bản phim dựa trên dữ liệu thị trường."
        },
        "answer": "B"
      },
      {
        "question": "Cinelytic tự quảng bá phần mềm của mình như thế nào?",
        "options": {
          "A": "Một công cụ tự động hóa hoàn toàn việc sản xuất phim.",
          "B": "Một nền tảng quản lý dự án hỗ trợ các nhà điều hành phim đưa ra quyết định.",
          "C": "Một hệ thống dự đoán giải thưởng điện ảnh.",
          "D": "Một công cụ tạo hiệu ứng đặc biệt cho phim."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của Cinelytic không phải là gì?",
        "options": {
          "A": "Giúp các nhà quản lý đưa ra quyết định hiệu quả hơn.",
          "B": "Tự động hóa việc ra quyết định trong quá trình sản xuất phim.",
          "C": "Cung cấp thông tin chi tiết về thị trường phim.",
          "D": "Hỗ trợ quản lý dự án phim."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà sản xuất phim sử dụng AI vì lý do chính nào?",
        "options": {
          "A": "Để giảm chi phí sản xuất phim.",
          "B": "Để tìm kiếm những bộ phim bom tấn và giành giải thưởng.",
          "C": "Để tạo ra những hiệu ứng đặc biệt ấn tượng.",
          "D": "Để rút ngắn thời gian sản xuất phim."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì khiến các hệ thống dự đoán trở nên đặc biệt hữu ích trong các liên hoan phim?",
        "options": {
          "A": "Giúp các nhà sản xuất tìm kiếm diễn viên tài năng.",
          "B": "Giúp các nhà điều hành đưa ra quyết định nhanh chóng trong các cuộc chiến đấu thầu.",
          "C": "Giúp các nhà phê bình đánh giá phim chính xác hơn.",
          "D": "Giúp các nhà phân phối tìm kiếm thị trường tiềm năng."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì có thể được hưởng lợi từ cách tiếp cận tương tự như AI dự đoán thành công phim?",
        "options": {
          "A": "Ngành công nghiệp ô tô.",
          "B": "Ngành công nghiệp xuất bản bản tin AI.",
          "C": "Ngành công nghiệp thời trang.",
          "D": "Ngành công nghiệp du lịch."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề nào khiến các nhà sản xuất phim quan tâm đến việc sử dụng AI?",
        "options": {
          "A": "Sự phức tạp của việc viết kịch bản.",
          "B": "Chi phí sản xuất phim rất lớn.",
          "C": "Sự cạnh tranh gay gắt giữa các hãng phim.",
          "D": "Sự thay đổi nhanh chóng của thị hiếu khán giả."
        },
        "answer": "B"
      },
      {
        "question": "Cụm từ 'Hollywood honchos' trong bài viết đề cập đến ai?",
        "options": {
          "A": "Các nhà phê bình phim.",
          "B": "Các nhà điều hành cấp cao trong ngành công nghiệp điện ảnh.",
          "C": "Các diễn viên nổi tiếng.",
          "D": "Các nhà biên kịch tài năng."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến điều gì đang diễn ra trong ngành công nghiệp điện ảnh liên quan đến AI?",
        "options": {
          "A": "Sự suy giảm trong việc sử dụng AI.",
          "B": "Sự gia tăng số lượng công ty tham gia vào lĩnh vực AI dự đoán thành công phim.",
          "C": "Sự phản đối mạnh mẽ từ các nhà làm phim truyền thống.",
          "D": "Sự tập trung vào việc sử dụng AI để tạo ra hiệu ứng hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của bài viết này là gì?",
        "options": {
          "A": "Phân tích những hạn chế của AI trong ngành công nghiệp điện ảnh.",
          "B": "Giới thiệu việc sử dụng AI để dự đoán thành công phòng vé của phim.",
          "C": "So sánh các công cụ AI khác nhau được sử dụng trong ngành điện ảnh.",
          "D": "Dự đoán tương lai của ngành công nghiệp điện ảnh."
        },
        "answer": "B"
      }
    ]
  },
  "full-bodied-with-hints-of-forest-fire": {
    "title": "Full-Bodied With Hints of Forest Fire",
    "collection": "business",
    "content": "Wineries in areas affected by wildfires are using machine learning to produce vintages that don’t taste like smoke.What’s new:Some California winemakers are using a service called Tastry to identify grapes tainted by smoke from the state’s surging blazes and recommend blends that will mask the flavor,The Wall Street Journalreported.How it works:Called CompuBlend, Tastry’s systemanalyzesgrapes’ chemical makeup, including smoke compounds absorbed through their skins. A model recommends other varieties that can mask the taste.\n\nBehind the news:The ancient art of winemaking is adopting AI.\n\nWhy it matters:Wildfires are a growing threat to wine regions inAustralia,California, andFrance. They cost the industry an estimated$3.7 billionin 2020. AI could help vintners recoup some of the losses.We’re thinking:While there's a clear need to adapt to human-induced climate change, it’s tragic that the planet has heated to the point that formerly temperate areas are burning. We applaud the work ofClimate Change AI.",
    "qa": [
      {
        "question": "Công nghệ machine learning đang được ứng dụng trong ngành sản xuất rượu vang để giải quyết vấn đề gì?",
        "options": {
          "A": "Tăng năng suất thu hoạch nho.",
          "B": "Giảm thiểu hương vị khói do cháy rừng gây ra.",
          "C": "Cải thiện chất lượng rượu vang.",
          "D": "Giảm chi phí sản xuất rượu vang."
        },
        "answer": "B"
      },
      {
        "question": "Tastry, dịch vụ được đề cập trong bài viết, giúp các nhà sản xuất rượu vang như thế nào?",
        "options": {
          "A": "Dự báo thời tiết để phòng tránh cháy rừng.",
          "B": "Xác định các loại nho bị ảnh hưởng bởi khói và đề xuất pha trộn để che lấp hương vị.",
          "C": "Tự động thu hoạch nho.",
          "D": "Kiểm tra độ cồn của rượu vang."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống CompuBlend của Tastry phân tích thành phần nào của nho?",
        "options": {
          "A": "Kích thước và màu sắc của quả nho.",
          "B": "Độ ngọt và độ chua của quả nho.",
          "C": "Thành phần hóa học, bao gồm các hợp chất khói hấp thụ qua vỏ.",
          "D": "Hàm lượng vitamin trong quả nho."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, cháy rừng gây thiệt hại ước tính bao nhiêu cho ngành công nghiệp rượu vang vào năm 2020?",
        "options": {
          "A": "3.7 triệu đô la.",
          "B": "37 triệu đô la.",
          "C": "370 triệu đô la.",
          "D": "3.7 tỷ đô la."
        },
        "answer": "D"
      },
      {
        "question": "Những khu vực nào được đề cập trong bài viết là đang đối mặt với mối đe dọa ngày càng tăng từ cháy rừng đối với ngành sản xuất rượu vang?",
        "options": {
          "A": "California, Ý và Tây Ban Nha.",
          "B": "Úc, California và Pháp.",
          "C": "Pháp, Ý và Tây Ban Nha.",
          "D": "Úc, Tây Ban Nha và Ý."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về việc ứng dụng AI trong sản xuất rượu vang?",
        "options": {
          "A": "AI thay thế hoàn toàn quy trình sản xuất rượu vang truyền thống.",
          "B": "AI đang được áp dụng vào nghệ thuật làm rượu vang cổ truyền.",
          "C": "AI chỉ được sử dụng để kiểm soát chất lượng rượu vang.",
          "D": "AI làm giảm sự sáng tạo của các nhà sản xuất rượu vang."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc sử dụng AI trong ngành sản xuất rượu vang bị ảnh hưởng bởi cháy rừng là gì?",
        "options": {
          "A": "Tăng giá trị thương hiệu của rượu vang.",
          "B": "Giúp các nhà sản xuất rượu vang bù đắp một phần thiệt hại.",
          "C": "Tạo ra những loại rượu vang mới với hương vị độc đáo.",
          "D": "Giảm thời gian sản xuất rượu vang."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến tổ chức nào liên quan đến biến đổi khí hậu?",
        "options": {
          "A": "Tastry.",
          "B": "The Wall Street Journal.",
          "C": "Climate Change AI.",
          "D": "CompuBlend."
        },
        "answer": "C"
      },
      {
        "question": "Vấn đề chính mà bài viết muốn truyền tải là gì?",
        "options": {
          "A": "Sự phát triển của công nghệ AI trong ngành nông nghiệp.",
          "B": "Tác động tiêu cực của biến đổi khí hậu và giải pháp ứng dụng AI để giảm thiểu thiệt hại.",
          "C": "Sự cạnh tranh giữa các nhà sản xuất rượu vang trên toàn thế giới.",
          "D": "Lịch sử phát triển của ngành sản xuất rượu vang."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống CompuBlend đề xuất điều gì để che lấp hương vị khói trong nho?",
        "options": {
          "A": "Sử dụng các chất phụ gia hóa học.",
          "B": "Pha trộn với các giống nho khác.",
          "C": "Áp dụng quy trình lên men đặc biệt.",
          "D": "Sử dụng thùng ủ rượu mới."
        },
        "answer": "B"
      }
    ]
  },
  "game-changer": {
    "title": "Game Changer",
    "collection": "business",
    "content": "Football clubs are turning to computer vision for winning insights.\n\nWhat’s new:Acronis, a Swiss cloud storage and security company, offers AI services designed to give a boost to some of the world’s top football clubs (soccer teams, to Americans),Wiredreported.Eyes on the ball:The company stores training and match video for professional teams including London-based Arsenal, Manchester City, and Inter Milan. An internal group devoted to machine learning for sports is using the data to train AI tools aimed at improving gameplay and marketing.\n\nBehind the news:Nearly two decades after Michael Lewis’ bookMoneyball: The Art of Winning an Unfair Gamerevealed the use of data analytics in baseball, sports are becoming an active playing field for AI.\n\nWhy it matters:Once the four-minute mile was a breakthrough. Now it’s par for the course. Machine learning is set to help athletes continue to upgrade their own state of the art.We’re thinking:For those of us who aren’t particularly athletic, it’s nice to know that we can help score goals by running our fingers across a keyboard!",
    "qa": [
      {
        "question": "Công ty Acronis có trụ sở chính ở đâu?",
        "options": {
          "A": "London",
          "B": "Thụy Sĩ",
          "C": "Manchester",
          "D": "Milan"
        },
        "answer": "B"
      },
      {
        "question": "Acronis cung cấp dịch vụ AI cho các câu lạc bộ bóng đá nhằm mục đích chính gì?",
        "options": {
          "A": "Quản lý tài chính hiệu quả hơn",
          "B": "Nâng cao hiệu suất thi đấu và hoạt động marketing",
          "C": "Cải thiện cơ sở vật chất của câu lạc bộ",
          "D": "Tuyển dụng cầu thủ tiềm năng"
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu mà Acronis thu thập từ các câu lạc bộ bóng đá chủ yếu đến từ đâu?",
        "options": {
          "A": "Dữ liệu thống kê trận đấu",
          "B": "Video tập luyện và trận đấu",
          "C": "Thông tin cá nhân của cầu thủ",
          "D": "Dữ liệu từ mạng xã hội"
        },
        "answer": "B"
      },
      {
        "question": "Cuốn sách nào đã tiết lộ việc sử dụng phân tích dữ liệu trong bóng chày, mở đường cho AI trong thể thao?",
        "options": {
          "A": "The Blind Side",
          "B": "Moneyball: The Art of Winning an Unfair Game",
          "C": "Friday Night Lights",
          "D": "Open"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, AI có vai trò gì trong việc cải thiện hiệu suất của vận động viên?",
        "options": {
          "A": "Thay thế hoàn toàn các phương pháp huấn luyện truyền thống",
          "B": "Giúp vận động viên liên tục nâng cao trình độ của mình",
          "C": "Giảm thiểu chấn thương cho vận động viên",
          "D": "Tăng cường sức mạnh thể chất cho vận động viên"
        },
        "answer": "B"
      },
      {
        "question": "Đội ngũ nội bộ của Acronis sử dụng dữ liệu để làm gì?",
        "options": {
          "A": "Phát triển phần mềm quản lý câu lạc bộ",
          "B": "Đào tạo các công cụ AI để cải thiện lối chơi và marketing",
          "C": "Nghiên cứu thị trường thể thao",
          "D": "Tạo ra các trò chơi điện tử liên quan đến bóng đá"
        },
        "answer": "B"
      },
      {
        "question": "Câu lạc bộ bóng đá nào sau đây được đề cập trong bài viết là khách hàng của Acronis?",
        "options": {
          "A": "Real Madrid",
          "B": "Arsenal",
          "C": "Barcelona",
          "D": "Bayern Munich"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết ngụ ý gì về vai trò của những người không có năng khiếu thể thao trong việc hỗ trợ bóng đá?",
        "options": {
          "A": "Họ không thể đóng góp gì cho sự phát triển của bóng đá.",
          "B": "Họ có thể giúp ghi bàn bằng cách sử dụng máy tính.",
          "C": "Họ chỉ có thể là khán giả và cổ vũ cho đội bóng.",
          "D": "Họ có thể trở thành huấn luyện viên thể lực."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của việc sử dụng computer vision trong bóng đá là gì?",
        "options": {
          "A": "Giảm chi phí hoạt động của câu lạc bộ",
          "B": "Thu thập thông tin chi tiết để giành chiến thắng",
          "C": "Tăng cường an ninh cho sân vận động",
          "D": "Cải thiện trải nghiệm của người hâm mộ"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì từng được coi là một đột phá nhưng giờ đã trở thành tiêu chuẩn?",
        "options": {
          "A": "Kỹ thuật sút phạt hàng rào",
          "B": "Chạy một dặm trong bốn phút",
          "C": "Chiến thuật phòng ngự khu vực",
          "D": "Sử dụng giày đá bóng chuyên dụng"
        },
        "answer": "B"
      }
    ]
  },
  "gan-makes-pajamas-safe-for-work": {
    "title": "GAN Makes Pajamas Safe For Work",
    "collection": "business",
    "content": "A new camera app uses a generative adversarial network to let users look like they’re dressed for success while they videoconference in their jammies.What’s new:Xpressionis an iPhone app that maps facial expressions onto still images in real time, allowing users to stream live video selfies clothed in digital costumes.How it works:The app uses three deep learning models, a spokesperson for app makerEmbodyMetoldThe Batch.\n\nBehind the news:Computer vision networks aren’t the only models helping socially distanced workers stay productive and presentable.\n\nWhy it matters:No more judgement for our rumpled work-from-home looks and untidy bedrooms!We’re thinking:Apps like these are a lot of fun, and we’re excited to see how they will develop. But they also take us one step further into a world where it is increasingly hard to determine what, and who, is real. Society needs better and more consistent standards for labelling digital fakery.",
    "qa": [
      {
        "question": "Ứng dụng camera mới được đề cập trong bài viết sử dụng công nghệ nào để tạo hiệu ứng?",
        "options": {
          "A": "Mạng nơ-ron tích chập (CNN)",
          "B": "Mạng đối kháng sinh tạo (GAN)",
          "C": "Học tăng cường (Reinforcement Learning)",
          "D": "Xử lý ngôn ngữ tự nhiên (NLP)"
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng Xpression hoạt động trên nền tảng nào?",
        "options": {
          "A": "Android",
          "B": "iPhone",
          "C": "Cả Android và iPhone",
          "D": "Web"
        },
        "answer": "B"
      },
      {
        "question": "Xpression làm gì với biểu cảm khuôn mặt của người dùng?",
        "options": {
          "A": "Làm mờ các khuyết điểm trên khuôn mặt.",
          "B": "Thay đổi màu da và tóc.",
          "C": "Ánh xạ biểu cảm lên hình ảnh tĩnh trong thời gian thực.",
          "D": "Tạo ra một khuôn mặt hoàn toàn mới."
        },
        "answer": "C"
      },
      {
        "question": "Công ty nào đã tạo ra ứng dụng Xpression?",
        "options": {
          "A": "Apple",
          "B": "Google",
          "C": "EmbodyMetold",
          "D": "Microsoft"
        },
        "answer": "C"
      },
      {
        "question": "Ngoài mạng thị giác máy tính, loại mô hình nào khác cũng giúp người làm việc từ xa duy trì sự hiện diện và năng suất?",
        "options": {
          "A": "Mô hình dự đoán thời tiết",
          "B": "Mô hình phân tích dữ liệu tài chính",
          "C": "Bài viết không đề cập đến loại mô hình nào khác.",
          "D": "Mô hình xử lý ngôn ngữ tự nhiên"
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích chính của các ứng dụng như Xpression là gì?",
        "options": {
          "A": "Giúp người dùng kiếm tiền trực tuyến.",
          "B": "Giúp người dùng tránh bị đánh giá về ngoại hình khi làm việc tại nhà.",
          "C": "Giúp người dùng cải thiện kỹ năng giao tiếp.",
          "D": "Giúp người dùng kết nối với bạn bè dễ dàng hơn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết bày tỏ mối quan ngại nào về các ứng dụng tạo hình ảnh giả?",
        "options": {
          "A": "Chúng có thể gây nghiện.",
          "B": "Chúng có thể làm giảm sự sáng tạo của con người.",
          "C": "Chúng có thể gây khó khăn trong việc phân biệt thật giả.",
          "D": "Chúng có thể vi phạm quyền riêng tư."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết kêu gọi điều gì để giải quyết vấn đề hình ảnh giả trên mạng?",
        "options": {
          "A": "Cấm hoàn toàn các ứng dụng tạo hình ảnh giả.",
          "B": "Phát triển công nghệ để phát hiện hình ảnh giả.",
          "C": "Xây dựng các tiêu chuẩn rõ ràng và nhất quán để dán nhãn cho hình ảnh giả.",
          "D": "Tăng cường giáo dục về an ninh mạng."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc sử dụng 'digital costumes' trong ứng dụng Xpression là gì?",
        "options": {
          "A": "Để tạo ra những bức ảnh nghệ thuật độc đáo.",
          "B": "Để che giấu trang phục không phù hợp khi gọi video.",
          "C": "Để thử nghiệm các phong cách thời trang mới.",
          "D": "Để tạo ra các nhân vật ảo cho trò chơi."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì khiến chúng ta 'excited' về các ứng dụng như Xpression?",
        "options": {
          "A": "Khả năng kiếm tiền từ chúng.",
          "B": "Tính giải trí và tiềm năng phát triển của chúng.",
          "C": "Khả năng cải thiện kỹ năng chụp ảnh của chúng.",
          "D": "Khả năng bảo vệ quyền riêng tư của chúng."
        },
        "answer": "B"
      }
    ]
  },
  "generative-ai-demand-is-overwhelming-cloud-servers": {
    "title": "AI Startups Face Compute Shortage",
    "collection": "business",
    "content": "Chatbot-fueled FOMO is overwhelming cloud-computing services.\n\nWhat’s new:Cloud providers are struggling to meet sharply rising demand by a crowd of AI startups eager to cash in on generative AI,The Informationreported.Behind the bottleneck:The surge in demand caught Amazon Web Services, Microsoft Azure, and others off guard.\n\nWhat they’re saying:Engineers and entrepreneurs shared their pain.\n\nBehind the news:China is facing its own chip shortage — andfindingways to address it. That situation, though, is a result of United States trade sanctions rather than a surge in demand.\n\nWhy it matters:Startups that serve a market with generated text or pictures are white-hot, but even the most promising ventures can’t do without servers to build, test, and deploy their models. The winners will need not only a great product but also ready access to computation.We’re thinking:Our hearts go out to everyone who is trying to build AI products in these unpredictable times. We trust that the supply of compute will catch up in due course and that the current run of AI-fueled growth will continue for the foreseeable future.",
    "qa": [
      {
        "question": "Điều gì đang gây áp lực lớn lên các dịch vụ điện toán đám mây?",
        "options": {
          "A": "Sự cạnh tranh gay gắt giữa các nhà cung cấp dịch vụ.",
          "B": "Nhu cầu tăng đột biến từ các startup AI muốn tận dụng AI tạo sinh.",
          "C": "Các lệnh trừng phạt thương mại từ Hoa Kỳ.",
          "D": "Sự thiếu hụt chip toàn cầu."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, ai đang gặp khó khăn trong việc đáp ứng nhu cầu điện toán đám mây tăng cao?",
        "options": {
          "A": "Các nhà sản xuất chip.",
          "B": "Các công ty khởi nghiệp AI.",
          "C": "Các nhà cung cấp dịch vụ điện toán đám mây như AWS và Azure.",
          "D": "Các nhà đầu tư mạo hiểm."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì đã khiến các nhà cung cấp dịch vụ điện toán đám mây bất ngờ?",
        "options": {
          "A": "Sự phát triển nhanh chóng của công nghệ AI tạo sinh.",
          "B": "Sự thiếu hụt kỹ sư và chuyên gia AI.",
          "C": "Nhu cầu tăng đột biến từ các startup AI.",
          "D": "Các quy định mới về bảo mật dữ liệu."
        },
        "answer": "C"
      },
      {
        "question": "Tình trạng thiếu chip ở Trung Quốc là do nguyên nhân nào?",
        "options": {
          "A": "Nhu cầu chip tăng đột biến từ các công ty AI.",
          "B": "Các lệnh trừng phạt thương mại từ Hoa Kỳ.",
          "C": "Sự cố trong chuỗi cung ứng toàn cầu.",
          "D": "Sự chậm trễ trong việc phát triển công nghệ chip nội địa."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì là quan trọng đối với sự thành công của các startup AI, ngoài một sản phẩm tốt?",
        "options": {
          "A": "Khả năng huy động vốn đầu tư lớn.",
          "B": "Khả năng tiếp cận thị trường quốc tế.",
          "C": "Khả năng tiếp cận dễ dàng với tài nguyên tính toán.",
          "D": "Khả năng xây dựng một đội ngũ kỹ sư tài năng."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết bày tỏ thái độ gì về tình hình hiện tại của các startup AI?",
        "options": {
          "A": "Lạc quan về khả năng các startup sẽ vượt qua khó khăn.",
          "B": "Bi quan về tương lai của ngành AI.",
          "C": "Thông cảm với những khó khăn mà các startup đang gặp phải.",
          "D": "Trung lập và chỉ đưa ra thông tin khách quan."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết dự đoán điều gì về nguồn cung tài nguyên tính toán trong tương lai?",
        "options": {
          "A": "Sẽ tiếp tục khan hiếm trong thời gian dài.",
          "B": "Sẽ sớm đáp ứng được nhu cầu.",
          "C": "Sẽ phụ thuộc vào chính sách của chính phủ.",
          "D": "Sẽ chỉ đáp ứng được nhu cầu của các công ty lớn."
        },
        "answer": "B"
      },
      {
        "question": "Cụm từ 'FOMO' trong tiêu đề bài viết có nghĩa là gì?",
        "options": {
          "A": "Fear of Missing Out (Sợ bỏ lỡ).",
          "B": "Future of Machine Optimization (Tương lai của tối ưu hóa máy móc).",
          "C": "Fast Online Market Opportunity (Cơ hội thị trường trực tuyến nhanh chóng).",
          "D": "Financial Obligation Management Organization (Tổ chức quản lý nghĩa vụ tài chính)."
        },
        "answer": "A"
      },
      {
        "question": "Loại hình startup nào được đề cập là 'white-hot' trong bài viết?",
        "options": {
          "A": "Các startup phát triển phần cứng AI.",
          "B": "Các startup cung cấp dịch vụ điện toán đám mây.",
          "C": "Các startup phục vụ thị trường bằng văn bản hoặc hình ảnh được tạo ra.",
          "D": "Các startup chuyên về bảo mật AI."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì sẽ tiếp tục diễn ra trong tương lai gần?",
        "options": {
          "A": "Sự suy giảm của ngành AI.",
          "B": "Sự tăng trưởng được thúc đẩy bởi AI.",
          "C": "Sự ổn định của thị trường điện toán đám mây.",
          "D": "Sự cạnh tranh khốc liệt giữa các startup AI."
        },
        "answer": "B"
      }
    ]
  },
  "generative-ai-highlights-from-google-i-o-2023": {
    "title": "Google Adds AI Inside and Out",
    "collection": "business",
    "content": "Google showcased a flood of new features in its latest bid to get ahead in the generative AI arms race.\n\nWhat’s new:The companydemonstratedAI features for consumers and developers at its annual I/O conference.\n\nPaLM powered:More than two dozen of the new features, including Bard and Duet AI (see below), are powered by a new large language model calledPaLM 2. Google trained PaLM 2 on tasks similar to Google'sUL2pretraining framework more than 100 different natural languages and numerous programming languages. It will be available as a cloud service in four unspecified sizes.\n\nApp assistance:Duet AIis a suite of text generation tools for Google Workspace and Cloud.\n\nNew foundation models:Vertex offers three new foundation models.Chirpfor speech-to-text, Codey for code completion, andImagenfor text-to-image generation. Users can join awaitlistvia Vertex.\n\nBard handles images:Users no longer have to join a waitlist for access to theBardchatbot, and its language capabilities have been expanded from English to include Japanese and Korean. It is now available in 180 countries, though not the EU or Canada. Bard can now respond to image-based queries, provide images in its responses, and generate custom images using Adobe’s image generation model,Firefly.\n\nSearch enhancements:An experimental version of Google Search will generate text answers to queries using an unidentified language model.\n\nWhy it matters:Google’s new capabilities are the latest salvo in anongoing competitionto capture generative AI’s market potential to greatest effect.\n\nWe’re thinking:Just days ago, a leaked Googlememotalked about Google and OpenAI’s lack of moat when it comes to LLM technology. It described how open source offerings of LLMs are racing ahead, making it challenging for any company to maintain a significant and enduring lead over competitors in the quality of its models. We think the impressive I/O presentation by Sundar Pichai and team, however, reminded everyone of Google’s tremendous distribution advantages. Google owns many platforms/products (such as search, Gmail, Android, Chrome and Youtube) with over 2 billion users, and this gives it numerous ways to get generative AI to users. In the era of generative AI, we are increasingly seeing distribution as a moat for businesses.",
    "qa": [
      {
        "question": "Sự kiện nào đã diễn ra mà Google giới thiệu hàng loạt tính năng AI mới?",
        "options": {
          "A": "Hội nghị thượng đỉnh về AI toàn cầu",
          "B": "Hội nghị I/O hàng năm của Google",
          "C": "Triển lãm công nghệ tiêu dùng (CES)",
          "D": "Hội nghị các nhà phát triển phần mềm quốc tế"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình ngôn ngữ lớn nào cung cấp sức mạnh cho hơn hai chục tính năng mới của Google, bao gồm Bard và Duet AI?",
        "options": {
          "A": "LaMDA",
          "B": "PaLM 2",
          "C": "BERT",
          "D": "Transformer"
        },
        "answer": "B"
      },
      {
        "question": "Duet AI là một bộ công cụ tạo văn bản dành cho các ứng dụng nào?",
        "options": {
          "A": "Google Search và Google Maps",
          "B": "Google Workspace và Cloud",
          "C": "Android và Chrome",
          "D": "YouTube và Google Photos"
        },
        "answer": "B"
      },
      {
        "question": "Vertex cung cấp những mô hình nền tảng mới nào?",
        "options": {
          "A": "Gemini, Atlas, Titan",
          "B": "Chirp, Codey, Imagen",
          "C": "Bard, Duet, PaLM",
          "D": "AlphaCode, Minerva, Flamingo"
        },
        "answer": "B"
      },
      {
        "question": "Bard hiện đã có mặt ở bao nhiêu quốc gia?",
        "options": {
          "A": "100",
          "B": "150",
          "C": "180",
          "D": "200"
        },
        "answer": "C"
      },
      {
        "question": "Bard hiện chưa có mặt ở khu vực hoặc quốc gia nào sau đây?",
        "options": {
          "A": "Nhật Bản",
          "B": "Hàn Quốc",
          "C": "Liên minh Châu Âu (EU)",
          "D": "Hoa Kỳ"
        },
        "answer": "C"
      },
      {
        "question": "Bard hiện có thể làm gì liên quan đến hình ảnh?",
        "options": {
          "A": "Chỉ trả lời các câu hỏi bằng văn bản.",
          "B": "Chỉ cung cấp hình ảnh trong câu trả lời.",
          "C": "Đáp ứng các truy vấn dựa trên hình ảnh, cung cấp hình ảnh trong câu trả lời và tạo hình ảnh tùy chỉnh.",
          "D": "Không thể xử lý hình ảnh."
        },
        "answer": "C"
      },
      {
        "question": "Công cụ tạo ảnh tùy chỉnh của Bard sử dụng mô hình tạo ảnh nào?",
        "options": {
          "A": "DALL-E 2",
          "B": "Midjourney",
          "C": "Stable Diffusion",
          "D": "Firefly"
        },
        "answer": "D"
      },
      {
        "question": "Phiên bản thử nghiệm của Google Search sẽ tạo ra câu trả lời bằng văn bản cho các truy vấn sử dụng mô hình ngôn ngữ nào?",
        "options": {
          "A": "Một mô hình ngôn ngữ được xác định rõ ràng.",
          "B": "Một mô hình ngôn ngữ chưa được xác định.",
          "C": "Mô hình PaLM 2.",
          "D": "Mô hình LaMDA."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lợi thế phân phối lớn của Google đến từ đâu?",
        "options": {
          "A": "Sức mạnh tính toán vượt trội.",
          "B": "Số lượng lớn người dùng trên các nền tảng/sản phẩm của Google.",
          "C": "Khả năng phát triển các mô hình AI tiên tiến nhất.",
          "D": "Chiến lược marketing hiệu quả."
        },
        "answer": "B"
      }
    ]
  },
  "generative-ai-startups-raise-hundreds-of-millions-in-funding": {
    "title": "Generating Investment",
    "collection": "business",
    "content": "The generative gold rush is on.\n\nWhat’s new:Venture capitalists are betting hundreds of millions of dollars on startups that use AI to generate images, text, and more,Wiredreported.What’s happening:A handful of generative-AI startups have newly received nine-figure investments. They’re among over 140 nascent companies that aim to capitalize on applications in copywriting, coding, gaming, graphic design, and medicine, according to a growinglistmaintained by Stanford student David Song.\n\nBehind the news:Established companies, too, are looking for ways to capitalize on AI’s emerging generative capabilities.\n\nYes, but:Incumbents and class-action lawyers are lodging complaints over who owns what goes into — and what comes out of — models that generate creative works.\n\nWhy it matters:Despite ongoing chatter aboutAI winter, it’s springtime for generative AI. Founders, investors, and trade organizations alike believe that this emerging technology has the potential to create huge value.We’re thinking: Generative AI holds the spotlight, given the mass appeal of models that paint beautiful pictures in response to simple text prompts, but AI continues to advance in many areas that hold significant, unfulfilled commercial promise.",
    "qa": [
      {
        "question": "Theo bài viết, các nhà đầu tư mạo hiểm đang rót vốn vào các startup AI tạo sinh với mục đích gì?",
        "options": {
          "A": "Để phát triển các mô hình AI có khả năng tự học hỏi và cải thiện.",
          "B": "Để khai thác tiềm năng tạo ra hình ảnh, văn bản và nhiều nội dung khác bằng AI.",
          "C": "Để cạnh tranh với các công ty công nghệ lớn đã có vị thế trên thị trường.",
          "D": "Để giải quyết các vấn đề pháp lý liên quan đến quyền sở hữu trí tuệ của AI."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến số lượng startup AI tạo sinh đang tìm cách khai thác các ứng dụng trong nhiều lĩnh vực là bao nhiêu?",
        "options": {
          "A": "Khoảng 40 công ty.",
          "B": "Hơn 100 công ty.",
          "C": "Khoảng 140 công ty.",
          "D": "Hơn 200 công ty."
        },
        "answer": "C"
      },
      {
        "question": "Ai là người được nhắc đến trong bài viết với vai trò duy trì danh sách các công ty AI tạo sinh?",
        "options": {
          "A": "Một nhà đầu tư mạo hiểm giấu tên.",
          "B": "Một giáo sư tại Đại học Stanford.",
          "C": "Một sinh viên tên David Song.",
          "D": "Một luật sư chuyên về sở hữu trí tuệ."
        },
        "answer": "C"
      },
      {
        "question": "Ngoài các startup, các công ty đã thành lập cũng đang làm gì liên quan đến AI tạo sinh?",
        "options": {
          "A": "Đang phát triển các tiêu chuẩn đạo đức cho việc sử dụng AI.",
          "B": "Đang tìm cách khai thác các khả năng tạo sinh mới nổi của AI.",
          "C": "Đang tập trung vào việc cải thiện hiệu suất của các mô hình AI hiện có.",
          "D": "Đang hợp tác với các trường đại học để nghiên cứu về AI."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề pháp lý nào đang được đề cập liên quan đến các mô hình AI tạo sinh?",
        "options": {
          "A": "Vi phạm quyền riêng tư của người dùng.",
          "B": "Trách nhiệm pháp lý khi AI gây ra thiệt hại.",
          "C": "Quyền sở hữu đối với những gì được đưa vào và tạo ra bởi các mô hình.",
          "D": "Sự phân biệt đối xử do thuật toán AI gây ra."
        },
        "answer": "C"
      },
      {
        "question": "Mặc dù có những lo ngại, bài viết cho rằng giai đoạn hiện tại của AI tạo sinh có thể được ví như mùa nào?",
        "options": {
          "A": "Mùa đông AI.",
          "B": "Mùa thu AI.",
          "C": "Mùa hè AI.",
          "D": "Mùa xuân AI."
        },
        "answer": "D"
      },
      {
        "question": "Theo bài viết, điều gì khiến AI tạo sinh trở nên nổi bật?",
        "options": {
          "A": "Khả năng giải quyết các vấn đề phức tạp trong khoa học.",
          "B": "Sự phổ biến rộng rãi của các mô hình tạo ra hình ảnh đẹp từ các đoạn văn bản đơn giản.",
          "C": "Tiềm năng ứng dụng trong lĩnh vực y tế để chẩn đoán bệnh.",
          "D": "Khả năng tự động hóa các quy trình sản xuất trong công nghiệp."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài AI tạo sinh, bài viết ngụ ý rằng AI còn có tiềm năng phát triển ở những lĩnh vực nào khác?",
        "options": {
          "A": "Chỉ trong lĩnh vực nghiên cứu khoa học cơ bản.",
          "B": "Trong nhiều lĩnh vực khác với tiềm năng thương mại chưa được khai thác.",
          "C": "Chỉ trong lĩnh vực an ninh mạng và phòng chống tội phạm.",
          "D": "Chỉ trong lĩnh vực giáo dục và đào tạo trực tuyến."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, ai là những người tin rằng công nghệ AI tạo sinh có tiềm năng tạo ra giá trị lớn?",
        "options": {
          "A": "Chỉ các nhà đầu tư mạo hiểm.",
          "B": "Chỉ các nhà khoa học và kỹ sư AI.",
          "C": "Các nhà sáng lập, nhà đầu tư và các tổ chức thương mại.",
          "D": "Chỉ các cơ quan chính phủ và tổ chức phi lợi nhuận."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết sử dụng cụm từ \"generative gold rush\" để ám chỉ điều gì?",
        "options": {
          "A": "Sự khan hiếm các chuyên gia trong lĩnh vực AI tạo sinh.",
          "B": "Sự cạnh tranh khốc liệt giữa các công ty AI tạo sinh.",
          "C": "Sự bùng nổ đầu tư và phát triển nhanh chóng trong lĩnh vực AI tạo sinh.",
          "D": "Sự khó khăn trong việc tìm kiếm nguồn dữ liệu chất lượng cao cho AI tạo sinh."
        },
        "answer": "C"
      }
    ]
  },
  "getting-a-jump-on-climate-change": {
    "title": "Getting a Jump on Climate Change",
    "collection": "business",
    "content": "Startups are predicting how climate change will affect global commerce.What’s new:Companies that specialize in climate analytics are training neural networks to help businesses manage risks posed by a warming globe,The Wall Street Journalreported.Changes in the air:These young companies model interactions among environmental data and factors such as commodity prices, consumption patterns, and import/export data. They sell the resulting insights to corporate customers who are concerned about the impact of climate change on their ability to buy goods and raw materials.\n\nBehind the news:Corporations are waking up to the hazards posed by climate change to their own well-being.\n\nWhy it matters:This year’s run of record-breakingwildfires,floods, andfreezesare a preview of what to expect in a warmer world, according to the latestInternational Panel on Climate Change report. AI-powered forecasts can help businesses protect assets and revenue — and the rest of us prepare for further impacts to come.We’re thinking:By calculating the costs of climate disaster, AI can make the very real danger posed by atmospheric carbon emissions feel as urgent as it is.",
    "qa": [
      {
        "question": "Các công ty chuyên về phân tích khí hậu đang sử dụng công nghệ nào để giúp doanh nghiệp quản lý rủi ro từ biến đổi khí hậu?",
        "options": {
          "A": "Mô hình hóa dữ liệu thống kê truyền thống",
          "B": "Mạng nơ-ron (neural networks)",
          "C": "Phân tích SWOT",
          "D": "Dự báo thời tiết dài hạn"
        },
        "answer": "B"
      },
      {
        "question": "Các công ty trẻ trong lĩnh vực phân tích khí hậu mô hình hóa tương tác giữa dữ liệu môi trường và yếu tố nào khác?",
        "options": {
          "A": "Tỷ giá hối đoái và lãi suất ngân hàng",
          "B": "Giá cả hàng hóa, mô hình tiêu dùng và dữ liệu xuất nhập khẩu",
          "C": "Tình hình chính trị và các cuộc xung đột vũ trang",
          "D": "Xu hướng thời trang và sở thích của người tiêu dùng"
        },
        "answer": "B"
      },
      {
        "question": "Khách hàng chính của các công ty phân tích khí hậu là đối tượng nào?",
        "options": {
          "A": "Các tổ chức phi chính phủ hoạt động trong lĩnh vực môi trường",
          "B": "Các doanh nghiệp lo ngại về tác động của biến đổi khí hậu đến khả năng mua hàng hóa và nguyên liệu thô",
          "C": "Các chính phủ và cơ quan quản lý nhà nước",
          "D": "Các nhà đầu tư cá nhân quan tâm đến cổ phiếu xanh"
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đang khiến các tập đoàn ngày càng nhận thức rõ hơn về những nguy cơ do biến đổi khí hậu gây ra?",
        "options": {
          "A": "Áp lực từ các tổ chức bảo vệ quyền lợi người tiêu dùng",
          "B": "Nhận thức về những rủi ro đối với sự thịnh vượng của chính họ",
          "C": "Các quy định pháp luật nghiêm ngặt hơn về khí thải",
          "D": "Sự thay đổi trong sở thích của người tiêu dùng hướng tới sản phẩm thân thiện với môi trường"
        },
        "answer": "B"
      },
      {
        "question": "Theo báo cáo mới nhất của Ủy ban Liên chính phủ về Biến đổi Khí hậu (IPCC), những hiện tượng thời tiết cực đoan trong năm nay là gì?",
        "options": {
          "A": "Sóng thần, động đất và núi lửa phun trào",
          "B": "Cháy rừng, lũ lụt và băng giá kỷ lục",
          "C": "Bão cát, hạn hán và lốc xoáy",
          "D": "Mưa sao băng, nhật thực và nguyệt thực"
        },
        "answer": "B"
      },
      {
        "question": "Dự báo được hỗ trợ bởi trí tuệ nhân tạo (AI) có thể giúp doanh nghiệp làm gì trong bối cảnh biến đổi khí hậu?",
        "options": {
          "A": "Tăng cường hoạt động quảng cáo và marketing",
          "B": "Bảo vệ tài sản và doanh thu",
          "C": "Giảm chi phí sản xuất và vận hành",
          "D": "Thu hút nhân tài và nâng cao năng suất lao động"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết gợi ý rằng việc tính toán chi phí của thảm họa khí hậu có thể giúp điều gì?",
        "options": {
          "A": "Giảm thiểu tác động của biến đổi khí hậu lên nền kinh tế toàn cầu",
          "B": "Làm cho mối nguy hiểm thực sự do khí thải carbon trong khí quyển trở nên cấp bách hơn",
          "C": "Thúc đẩy các chính phủ tăng cường đầu tư vào năng lượng tái tạo",
          "D": "Nâng cao nhận thức của cộng đồng về biến đổi khí hậu"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, mục tiêu cuối cùng của việc sử dụng AI trong dự báo khí hậu là gì?",
        "options": {
          "A": "Giúp các doanh nghiệp tăng lợi nhuận",
          "B": "Giúp mọi người chuẩn bị cho những tác động tiếp theo của biến đổi khí hậu",
          "C": "Thay thế các nhà khoa học khí hậu",
          "D": "Tạo ra các mô hình khí hậu chính xác tuyệt đối"
        },
        "answer": "B"
      },
      {
        "question": "Công ty phân tích khí hậu bán thông tin chi tiết thu được cho ai?",
        "options": {
          "A": "Các nhà khoa học khí hậu",
          "B": "Các tổ chức chính phủ",
          "C": "Khách hàng doanh nghiệp",
          "D": "Công chúng nói chung"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết được đăng trên tờ báo nào?",
        "options": {
          "A": "The New York Times",
          "B": "The Wall Street Journal",
          "C": "The Washington Post",
          "D": "Financial Times"
        },
        "answer": "B"
      }
    ]
  },
  "global-ai-summit-reveals-deep-divisions-on-regulation-and-governance": {
    "title": "World Powers Move to Lighten AI Regulation",
    "collection": "business",
    "content": "The latest international AI summit exposed deep divisions between major world powers regarding AI regulations.\n\nWhat’s new:While previous summits emphasized existential risks, theAI Action Summitin Paris marked a turning point. France and the European Union shifted away from strict regulatory measures and toward investment to compete with the United States and China. However, global consensus remained elusive: the U.S. and the United Kingdom refused to sign key agreements on global governance, military AI, and algorithmic bias. The U.S. in particular pushed back against global AI regulation, arguing that excessive restrictions could hinder economic growth and that international policies should focus on more immediate concerns.\n\nHow it works:Participating countries considered three policy statements that address AI’s impact on society, labor, and security. Thefirst statementcalls on each country to enact AI policies that would support economic development, environmental responsibility, and equitable access to technology. Thesecondencourages safeguards to ensure that companies and nations distribute AI productivity gains fairly, protect workers’ rights, and prevent bias in hiring and management systems. Thethirdadvocates for restrictions on fully autonomous military systems and affirms the need for human oversight in warfare.\n\nBehind the news:The Paris summit follows previous gatherings of world leaders to discuss AI, including the initialAI Safety Summitat Bletchley Park and theAI Seoul Summit and AI Global Forum. At these summits, governments and companies agreed broadly to address AI risks but avoided binding regulations. Nonetheless, divisions over AI governance have widened in the wake of rising geopolitical competition and theemergenceof high-performance open weights models like DeepSeek-R1.\n\nWhy it matters:The Paris summit marks a major shift in global AI policy. The EU, once an ardent proponent of AI regulation, backed away from its strictest proposals. At the same time, doomsayers have lost influence, and officials are turning their attention to immediate concerns like economic growth, security, misuse, and bias. These moves make way for AI to do great good in the world, even as they contribute touncertaintyabout how AI will be governed.\n\nWe’re thinking:Governments are shifting their focus away from unrealistic risks and toward practical strategies for guiding AI development. We look forward to clear policies that encourage innovation while addressing real-world challenges.",
    "qa": [
      {
        "question": "Hội nghị thượng đỉnh AI quốc tế gần đây nhất đã cho thấy điều gì về quan điểm của các cường quốc trên thế giới?",
        "options": {
          "A": "Sự đồng thuận cao về các quy định AI toàn cầu.",
          "B": "Sự chia rẽ sâu sắc về các quy định AI.",
          "C": "Sự thống nhất trong việc tập trung vào rủi ro hiện hữu của AI.",
          "D": "Sự hợp tác chặt chẽ trong việc phát triển AI quân sự."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính giữa Hội nghị thượng đỉnh AI ở Paris so với các hội nghị trước đó là gì?",
        "options": {
          "A": "Tập trung nhiều hơn vào rủi ro hiện hữu của AI.",
          "B": "Chuyển từ các biện pháp quản lý nghiêm ngặt sang đầu tư để cạnh tranh.",
          "C": "Sự tham gia của nhiều quốc gia hơn.",
          "D": "Sự đồng thuận cao hơn về quản trị AI toàn cầu."
        },
        "answer": "B"
      },
      {
        "question": "Quốc gia nào đã phản đối các quy định AI toàn cầu, cho rằng chúng có thể cản trở tăng trưởng kinh tế?",
        "options": {
          "A": "Pháp.",
          "B": "Vương quốc Anh.",
          "C": "Trung Quốc.",
          "D": "Hoa Kỳ."
        },
        "answer": "D"
      },
      {
        "question": "Hội nghị thượng đỉnh AI ở Paris đã xem xét bao nhiêu tuyên bố chính sách liên quan đến tác động của AI?",
        "options": {
          "A": "Một.",
          "B": "Hai.",
          "C": "Ba.",
          "D": "Bốn."
        },
        "answer": "C"
      },
      {
        "question": "Một trong những tuyên bố chính sách được xem xét tại hội nghị kêu gọi điều gì liên quan đến AI và quân sự?",
        "options": {
          "A": "Khuyến khích phát triển hệ thống quân sự tự động hoàn toàn.",
          "B": "Hạn chế hệ thống quân sự tự động hoàn toàn và khẳng định sự cần thiết của sự giám sát của con người.",
          "C": "Tăng cường sử dụng AI trong các hoạt động quân sự mà không có bất kỳ hạn chế nào.",
          "D": "Cấm hoàn toàn việc sử dụng AI trong quân sự."
        },
        "answer": "B"
      },
      {
        "question": "Hội nghị thượng đỉnh AI ở Paris diễn ra sau những sự kiện nào?",
        "options": {
          "A": "Chỉ có Hội nghị An toàn AI đầu tiên tại Bletchley Park.",
          "B": "Hội nghị An toàn AI đầu tiên tại Bletchley Park và Diễn đàn AI Toàn cầu.",
          "C": "Hội nghị An toàn AI đầu tiên tại Bletchley Park, Hội nghị thượng đỉnh AI Seoul và Diễn đàn AI Toàn cầu.",
          "D": "Chỉ có Hội nghị thượng đỉnh AI Seoul."
        },
        "answer": "C"
      },
      {
        "question": "Sự trỗi dậy của mô hình nào được đề cập đến như một yếu tố làm gia tăng sự chia rẽ về quản trị AI?",
        "options": {
          "A": "GPT-4.",
          "B": "Bard.",
          "C": "DeepSeek-R1.",
          "D": "AlphaGo."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì đã xảy ra với những người ủng hộ các quan điểm bi quan về AI?",
        "options": {
          "A": "Họ đã đạt được nhiều ảnh hưởng hơn.",
          "B": "Họ đã mất ảnh hưởng.",
          "C": "Quan điểm của họ không thay đổi.",
          "D": "Họ đã chuyển sang tập trung vào các vấn đề kinh tế."
        },
        "answer": "B"
      },
      {
        "question": "Sự thay đổi trong chính sách AI toàn cầu được mô tả trong bài viết có thể dẫn đến điều gì?",
        "options": {
          "A": "Sự chắc chắn hơn về cách AI sẽ được quản lý.",
          "B": "Sự chậm trễ trong việc phát triển AI.",
          "C": "Sự không chắc chắn về cách AI sẽ được quản lý.",
          "D": "Sự thống nhất toàn cầu về các quy định AI."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết kết luận rằng các chính phủ nên tập trung vào điều gì trong việc hướng dẫn sự phát triển của AI?",
        "options": {
          "A": "Các rủi ro không thực tế.",
          "B": "Các chiến lược thực tế để khuyến khích đổi mới và giải quyết các thách thức thực tế.",
          "C": "Các quy định nghiêm ngặt để ngăn chặn mọi rủi ro tiềm ẩn.",
          "D": "Việc cấm hoàn toàn các mô hình AI có trọng số mở."
        },
        "answer": "B"
      }
    ]
  },
  "goodbye-tourists-hello-labelers": {
    "title": "Goodbye Tourists, Hello Labelers",
    "collection": "business",
    "content": "Covid-19 has cost many workers their livelihood, but it has provided a lucky few on the lowest rungs of Africa’s machine learning industry with luxury suites.What’s new:Samasource, a data labeling company headquartered in San Francisco, California, is housing its East African workforce in hotels and resorts so they can continue to work while maintaining social distance,Wiredreports.How it works:The pandemic prompted strict lockdowns in Kenya and Uganda, where Samasource employs some 2,000 workers. Many live in communities with no internet connectivity. So the company put up its workforce in four internet-equipped hotels that were vacant amid the coronavirus-driven collapse of tourism.\n\nBehind the news:Several companies are providing jobs that help feed both the AI industry’s hunger for data and underserved communities.\n\nWhy it matters:Socially conscious outsourcing increases the tech industry’s talent pool by providing decent jobs to people who, because of geography, gender, race, or other factors, otherwise might be locked out.We’re thinking:The grocery industry’sFair Tradelabels help consumers distinguish between socially responsible employers and their wage-slashing competitors. A similar measure for AI would foster both growth and diversity.",
    "qa": [
      {
        "question": "Công ty Samasource có trụ sở chính đặt tại đâu?",
        "options": {
          "A": "Nairobi, Kenya",
          "B": "Kampala, Uganda",
          "C": "San Francisco, California",
          "D": "East Africa (chung chung)"
        },
        "answer": "C"
      },
      {
        "question": "Đại dịch Covid-19 đã ảnh hưởng đến ngành du lịch ở Kenya và Uganda như thế nào?",
        "options": {
          "A": "Gần như không ảnh hưởng, ngành du lịch vẫn phát triển mạnh.",
          "B": "Gây ra sự sụt giảm nghiêm trọng, khiến nhiều khách sạn bị bỏ trống.",
          "C": "Thúc đẩy sự phát triển của du lịch nội địa.",
          "D": "Chỉ ảnh hưởng đến các khách sạn nhỏ, các khu nghỉ dưỡng lớn vẫn hoạt động bình thường."
        },
        "answer": "B"
      },
      {
        "question": "Samasource đã cung cấp chỗ ở cho nhân viên của mình ở đâu trong thời gian đại dịch?",
        "options": {
          "A": "Trong các khu nhà ở giá rẻ gần văn phòng.",
          "B": "Trong các khách sạn và khu nghỉ dưỡng được trang bị internet.",
          "C": "Trong các căn hộ do công ty xây dựng.",
          "D": "Trong nhà của người thân và bạn bè."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất một biện pháp nào để thúc đẩy sự phát triển và đa dạng trong ngành AI?",
        "options": {
          "A": "Tăng cường đào tạo kỹ năng cho người lao động ở các nước phát triển.",
          "B": "Áp dụng các tiêu chuẩn 'Fair Trade' tương tự như trong ngành thực phẩm.",
          "C": "Giảm thuế cho các công ty AI.",
          "D": "Hạn chế sự tham gia của các công ty nước ngoài vào thị trường AI."
        },
        "answer": "B"
      },
      {
        "question": "Khoảng bao nhiêu nhân viên của Samasource đang làm việc tại Kenya và Uganda?",
        "options": {
          "A": "Khoảng 200 người",
          "B": "Khoảng 500 người",
          "C": "Khoảng 1000 người",
          "D": "Khoảng 2000 người"
        },
        "answer": "D"
      },
      {
        "question": "Công việc chính của Samasource là gì?",
        "options": {
          "A": "Phát triển phần mềm AI.",
          "B": "Cung cấp dịch vụ lưu trữ dữ liệu.",
          "C": "Gắn nhãn dữ liệu (data labeling).",
          "D": "Sản xuất phần cứng cho ngành AI."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, 'socially conscious outsourcing' mang lại lợi ích gì?",
        "options": {
          "A": "Giảm chi phí sản xuất cho các công ty công nghệ.",
          "B": "Mở rộng nguồn nhân tài cho ngành công nghệ bằng cách tạo việc làm tốt cho những người bị thiệt thòi.",
          "C": "Tăng cường sự cạnh tranh giữa các công ty công nghệ.",
          "D": "Giảm thiểu tác động tiêu cực của công nghệ đến môi trường."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã thúc đẩy Samasource đưa nhân viên vào khách sạn?",
        "options": {
          "A": "Để tăng năng suất làm việc của nhân viên.",
          "B": "Để đảm bảo nhân viên có thể tiếp tục làm việc trong bối cảnh phong tỏa và thiếu kết nối internet.",
          "C": "Để cung cấp cho nhân viên những tiện nghi tốt hơn.",
          "D": "Để quảng bá thương hiệu của công ty."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến vấn đề gì liên quan đến nơi sinh sống của nhiều nhân viên Samasource?",
        "options": {
          "A": "Họ sống ở những khu vực có chi phí sinh hoạt cao.",
          "B": "Họ sống ở những khu vực không có kết nối internet.",
          "C": "Họ sống ở những khu vực có tỷ lệ tội phạm cao.",
          "D": "Họ sống ở những khu vực bị ô nhiễm môi trường."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của bài viết là gì?",
        "options": {
          "A": "Phân tích tác động tiêu cực của đại dịch Covid-19 đối với ngành công nghệ.",
          "B": "Giới thiệu một giải pháp sáng tạo của một công ty trong việc duy trì hoạt động và hỗ trợ nhân viên trong đại dịch.",
          "C": "So sánh hiệu quả hoạt động của các công ty AI khác nhau.",
          "D": "Dự đoán tương lai của ngành công nghiệp AI."
        },
        "answer": "B"
      }
    ]
  },
  "google-acquires-character-ai-talent-and-tech-in-strategic-move": {
    "title": "Google Gets Character.AI Co-Founders",
    "collection": "business",
    "content": "Character.AI followed an emerging pattern for ambitious AI startups, trading its leadership to a tech giant in exchange for funds and a strategic makeover.\n\nWhat’s new:Google hired Character.AI’s co-founders and other employees and paid an undisclosed sum for nonexclusive rights to use Character.AI’s technology,The Informationreported. The deal came shortly afterMicrosoft and InflectionandAmazon and Adeptstruck similar agreements.\n\nNew strategy:Character.AI builds chatbots that mimic personalities from history, fiction, and popular culture. When it started, it was necessary to build foundation models to deliver automated conversation, the companyexplainedin a blog post. However, “the landscape has shifted” and many pretrained models are available. Open models enable the company to focus its resources on fine-tuning and product development under its new CEO, former Character.AI general counsel Dom Perella. Licensing revenue from Google will help Character.AI to move forward.\n\nBehind the news:At Google, Shazeer co-authored “Attention Is All You Need,” the 2017paperthat introduced the transformer architecture. De Freitas led theMeenaandLaMDAprojects to develop conversational models. They left Google and founded Character.AI in late 2021 to build a competitor to OpenAI that would develop “personalized superintelligence.” The company hadraised$193 million before its deal with Google.\n\nWhy it matters:Developing cutting-edge foundation models is enormously expensive, and few companies can acquire sufficient funds to keep it up. This dynamic is leading essential team members at high-flying startups to move to AI giants. The established companies need the startups’ entrepreneurial mindset, and the startups need to retool their businesses for a changing market.\n\nWe’re thinking:Models with open weights nowcompetewith proprietary models for the state of the art. This is a sea change for startups, opening the playing field to teams that want to build applications on top of foundation models. Be forewarned, though: New proprietary models such as the forthcoming GPT-5 may change the state of play yet again.",
    "qa": [
      {
        "question": "Theo bài viết, Character.AI đã thực hiện thay đổi chiến lược như thế nào?",
        "options": {
          "A": "Tập trung vào việc xây dựng các mô hình nền tảng độc quyền.",
          "B": "Chuyển trọng tâm sang tinh chỉnh và phát triển sản phẩm dựa trên các mô hình mở.",
          "C": "Mở rộng sang thị trường phần cứng để hỗ trợ các mô hình AI.",
          "D": "Hợp tác chặt chẽ với OpenAI để chia sẻ công nghệ."
        },
        "answer": "B"
      },
      {
        "question": "Thỏa thuận giữa Character.AI và Google bao gồm những gì?",
        "options": {
          "A": "Google mua lại hoàn toàn Character.AI.",
          "B": "Google thuê các nhà đồng sáng lập và nhân viên của Character.AI, đồng thời trả tiền để sử dụng công nghệ của họ.",
          "C": "Character.AI được phép sử dụng miễn phí các mô hình AI của Google.",
          "D": "Character.AI sẽ phát triển các mô hình AI độc quyền cho Google."
        },
        "answer": "B"
      },
      {
        "question": "Ai là CEO hiện tại của Character.AI?",
        "options": {
          "A": "Shazeer",
          "B": "De Freitas",
          "C": "Dom Perella",
          "D": "Một nhà đầu tư từ Google"
        },
        "answer": "C"
      },
      {
        "question": "Shazeer và De Freitas, những người sáng lập Character.AI, trước đây đã làm việc ở đâu?",
        "options": {
          "A": "Microsoft",
          "B": "Amazon",
          "C": "OpenAI",
          "D": "Google"
        },
        "answer": "D"
      },
      {
        "question": "Bài viết đề cập đến lý do chính khiến các startup AI chuyển giao nhân sự chủ chốt cho các công ty công nghệ lớn là gì?",
        "options": {
          "A": "Sự cạnh tranh gay gắt từ các startup khác.",
          "B": "Chi phí quá lớn để phát triển các mô hình nền tảng tiên tiến.",
          "C": "Áp lực từ các nhà đầu tư để đạt được lợi nhuận nhanh chóng.",
          "D": "Sự thiếu hụt nhân tài trong lĩnh vực AI."
        },
        "answer": "B"
      },
      {
        "question": "Bài báo 'Attention Is All You Need' năm 2017 đã giới thiệu kiến trúc nào?",
        "options": {
          "A": "Mạng nơ-ron tích chập (Convolutional Neural Network).",
          "B": "Mạng nơ-ron hồi quy (Recurrent Neural Network).",
          "C": "Transformer.",
          "D": "Mạng đối kháng sinh (Generative Adversarial Network)."
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu ban đầu của Character.AI khi mới thành lập là gì?",
        "options": {
          "A": "Xây dựng các ứng dụng AI cho ngành y tế.",
          "B": "Phát triển 'siêu trí tuệ cá nhân hóa' để cạnh tranh với OpenAI.",
          "C": "Tạo ra các công cụ AI cho giáo dục trực tuyến.",
          "D": "Xây dựng nền tảng AI cho thương mại điện tử."
        },
        "answer": "B"
      },
      {
        "question": "Số tiền mà Character.AI đã huy động được trước khi thỏa thuận với Google là bao nhiêu?",
        "options": {
          "A": "$100 triệu",
          "B": "$150 triệu",
          "C": "$193 triệu",
          "D": "$250 triệu"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì có thể thay đổi cục diện thị trường AI trong tương lai?",
        "options": {
          "A": "Sự ra đời của các quy định mới về AI.",
          "B": "Sự phát triển của các mô hình AI mã nguồn mở.",
          "C": "Sự xuất hiện của các mô hình độc quyền mới như GPT-5.",
          "D": "Sự hợp tác giữa các công ty công nghệ lớn và các trường đại học."
        },
        "answer": "C"
      },
      {
        "question": "Dự án Meena và LaMDA liên quan đến điều gì?",
        "options": {
          "A": "Phát triển các mô hình dịch thuật tự động.",
          "B": "Phát triển các mô hình hội thoại.",
          "C": "Phát triển các mô hình nhận dạng hình ảnh.",
          "D": "Phát triển các mô hình dự đoán thị trường chứng khoán."
        },
        "answer": "B"
      }
    ]
  },
  "google-and-microsoft-both-announce-ai-powered-search": {
    "title": "Search War!",
    "collection": "business",
    "content": "Thelong-dormantstruggle to dominate the web-search business reignited in a display of AI-driven firepower — and hubris.\n\nWhat’s new:Google and Microsoft announcedcompetingupgradespowered by the latest generation of chatbots. Baidu, too, flexed its natural-language-processing muscles.\n\nGoogle’s gambit:Following up on its January “code-red”initiativeto counter arumoredthreat from Microsoft, Google teased unspecified revisions of Search, Lens, and Maps. Google Search is the undisputed leader, responsible for93 percentof all search-driven traffic according to StatCounter.\n\nMicrosoft’s move:Microsoft followed up its announcement bypreviewingan upcoming version of its Bing search engine enhanced by text generation from OpenAI. The company did not say when the new capabilities would become available. Bing, the longstanding underdog of search, accounts for 3 percent of search-driven traffic.\n\nBaidu’s play:Baiduannouncedits own chatbot, Wenxin Yiyan, based onERNIE. The company expects to complete internal testing in March and deploy the system soon afterward. Baidu manages 65 percent of China’s search-driven traffic but less than 1 percent worldwide.\n\nBusiness hitches:Search engines make money by serving ads that users may view or click. If chatbots provide satisfying information, users may stop there, depriving the search provider of revenue. Microsoft’s Chief Marketing Officer Yusuf MehditoldFortunethe optimal way to present ads in a chatbot interface remains unknown.\n\nYes, but:Numerous caveats further dampen the chatbot hype.\n\nWhy it matters:Google’s search engine propelled the company to the pinnacle of tech, and it hasn’t faced a serious challenge in nearly two decades. For the competitors, huge money is at stake — Microsoft recentlytoldits shareholders that every additional percentage of market share for Bing translates into $2 billion in revenue. For users, the utility and integrity of the web hangs in the balance.\n\nWe’re thinking:The future of search depends on tomorrow’s technology as well as today’s. While current large language models have a problem with factual accuracy, outfitting text generation with document retrieval offers a pathway to significant improvement. It’s also likely that the cost of serving generated text will fall significantly over time. Thus the technology’s potential to disrupt the search business is likely to continue to grow as it matures.",
    "qa": [
      {
        "question": "Sự kiện nào đã thúc đẩy Google triển khai sáng kiến 'code-red'?",
        "options": {
          "A": "Sự ra mắt chatbot Wenxin Yiyan của Baidu.",
          "B": "Tin đồn về một mối đe dọa từ Microsoft trong lĩnh vực tìm kiếm.",
          "C": "Sự sụt giảm doanh thu quảng cáo của Google Search.",
          "D": "Yêu cầu từ các cổ đông về việc tăng cường thị phần."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, thị phần tìm kiếm toàn cầu của Google Search là bao nhiêu?",
        "options": {
          "A": "65%",
          "B": "93%",
          "C": "3%",
          "D": "Dưới 1%"
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào đang phát triển chatbot Wenxin Yiyan?",
        "options": {
          "A": "Microsoft",
          "B": "Google",
          "C": "Baidu",
          "D": "OpenAI"
        },
        "answer": "C"
      },
      {
        "question": "Theo Microsoft, mỗi phần trăm tăng thêm trong thị phần tìm kiếm của Bing tương đương với bao nhiêu doanh thu?",
        "options": {
          "A": "$1 tỷ",
          "B": "$2 tỷ",
          "C": "$3 tỷ",
          "D": "$5 tỷ"
        },
        "answer": "B"
      },
      {
        "question": "Thách thức lớn nhất đối với các công cụ tìm kiếm khi sử dụng chatbot là gì?",
        "options": {
          "A": "Khả năng xử lý ngôn ngữ tự nhiên còn hạn chế.",
          "B": "Chi phí phát triển và duy trì chatbot quá cao.",
          "C": "Việc tìm ra cách tối ưu để hiển thị quảng cáo trong giao diện chatbot.",
          "D": "Sự thiếu hụt nhân lực có trình độ chuyên môn cao."
        },
        "answer": "C"
      },
      {
        "question": "Công nghệ nào được đề cập trong bài viết như một giải pháp tiềm năng để cải thiện độ chính xác của chatbot?",
        "options": {
          "A": "Học sâu (Deep Learning).",
          "B": "Xử lý ngôn ngữ tự nhiên (NLP).",
          "C": "Trí tuệ nhân tạo tổng quát (AGI).",
          "D": "Kết hợp tạo văn bản với truy xuất tài liệu."
        },
        "answer": "D"
      },
      {
        "question": "Thị phần tìm kiếm của Baidu tại Trung Quốc là bao nhiêu?",
        "options": {
          "A": "3%",
          "B": "93%",
          "C": "65%",
          "D": "Dưới 1%"
        },
        "answer": "C"
      },
      {
        "question": "Công ty nào đã công bố bản xem trước của Bing được tăng cường bởi khả năng tạo văn bản từ OpenAI?",
        "options": {
          "A": "Google",
          "B": "Microsoft",
          "C": "Baidu",
          "D": "StatCounter"
        },
        "answer": "B"
      },
      {
        "question": "Điều gì được xem là yếu tố quan trọng quyết định tương lai của tìm kiếm, bên cạnh công nghệ hiện tại?",
        "options": {
          "A": "Khả năng cá nhân hóa kết quả tìm kiếm.",
          "B": "Công nghệ của tương lai.",
          "C": "Sự hợp tác giữa các công ty công nghệ.",
          "D": "Quy định pháp luật về bảo mật dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì có thể xảy ra nếu chatbot cung cấp thông tin thỏa mãn người dùng?",
        "options": {
          "A": "Doanh thu quảng cáo của các công cụ tìm kiếm có thể tăng lên.",
          "B": "Người dùng có thể ngừng sử dụng các công cụ tìm kiếm truyền thống.",
          "C": "Các công cụ tìm kiếm sẽ trở nên phổ biến hơn.",
          "D": "Chi phí vận hành của các công cụ tìm kiếm sẽ giảm xuống."
        },
        "answer": "B"
      }
    ]
  },
  "google-contractors-get-a-raise": {
    "title": "Better Pay for Data Workers",
    "collection": "business",
    "content": "Contract workers who help train the algorithms behind Google Search won a pay raise.What’s new:Employees of U.S. contractors who evaluate the quality of Google Search’s results, knowledge panels, and ads will earn $15 per hour, a raise of roughly $1,Bloombergreported.\n\nPay raise:The Alphabet Workers Union (AWU), an unofficial labor union that represents U.S.- and Canada-based employees of Alphabet, its subsidiaries, vendors and contractors, negotiated the raise. The deal will affect around 5,000 workers, most of whom work remotely for Seattle-area RaterLabs.\n\nBehind the news:Large AI developers like Google and OpenAI often outsource rote tasks like labeling data and evaluating outputs. The contractors have come under fire for underpaying workers.\n\nWhy it matters:AI products like search engines, language models, and autonomous vehicles can earn billions for the companies that develop them. Yet many of the workers who contribute to them receive relatively low wages.\n\nWe’re thinking:We’re glad to see wages rising for workers whose input is crucial to building AI systems. For a thoughtful treatment of tech labor issues, we recommend Gray and Suri’s excellent book,Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass.",
    "qa": [
      {
        "question": "Những công nhân hợp đồng làm công việc gì liên quan đến Google Search?",
        "options": {
          "A": "Phát triển các thuật toán tìm kiếm mới.",
          "B": "Đánh giá chất lượng kết quả tìm kiếm, bảng tri thức và quảng cáo của Google Search.",
          "C": "Quản lý cơ sở dữ liệu người dùng của Google Search.",
          "D": "Thiết kế giao diện người dùng cho Google Search."
        },
        "answer": "B"
      },
      {
        "question": "Mức lương mới mà công nhân hợp đồng của Google Search sẽ nhận được là bao nhiêu mỗi giờ?",
        "options": {
          "A": "$12",
          "B": "$15",
          "C": "$18",
          "D": "$20"
        },
        "answer": "B"
      },
      {
        "question": "Tổ chức nào đã đàm phán để tăng lương cho công nhân hợp đồng của Google Search?",
        "options": {
          "A": "Google Workers Union (GWU)",
          "B": "Alphabet Workers Union (AWU)",
          "C": "Search Engine Workers Association (SEWA)",
          "D": "RaterLabs Employee Collective (REC)"
        },
        "answer": "B"
      },
      {
        "question": "Thỏa thuận tăng lương này sẽ ảnh hưởng đến khoảng bao nhiêu công nhân?",
        "options": {
          "A": "500",
          "B": "5,000",
          "C": "50,000",
          "D": "500,000"
        },
        "answer": "B"
      },
      {
        "question": "Phần lớn công nhân được hưởng lợi từ việc tăng lương làm việc cho công ty nào?",
        "options": {
          "A": "Google",
          "B": "Alphabet",
          "C": "OpenAI",
          "D": "RaterLabs"
        },
        "answer": "D"
      },
      {
        "question": "Các công ty như Google và OpenAI thường thuê ngoài những công việc gì?",
        "options": {
          "A": "Phát triển các thuật toán phức tạp.",
          "B": "Xây dựng cơ sở hạ tầng phần cứng.",
          "C": "Các tác vụ lặp đi lặp lại như gắn nhãn dữ liệu và đánh giá kết quả.",
          "D": "Quản lý quan hệ đối tác chiến lược."
        },
        "answer": "C"
      },
      {
        "question": "Một trong những chỉ trích chính đối với việc thuê ngoài các công việc liên quan đến AI là gì?",
        "options": {
          "A": "Chất lượng công việc thường thấp.",
          "B": "Công nhân thường bị trả lương thấp.",
          "C": "Dữ liệu có thể bị rò rỉ.",
          "D": "Khó kiểm soát tiến độ dự án."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh tầm quan trọng của việc tăng lương cho công nhân AI vì lý do gì?",
        "options": {
          "A": "Để thu hút nhân tài giỏi nhất trong ngành.",
          "B": "Để đảm bảo tính công bằng cho những người đóng góp vào sự phát triển của các sản phẩm AI có giá trị.",
          "C": "Để giảm chi phí đào tạo và tuyển dụng.",
          "D": "Để tuân thủ các quy định của chính phủ."
        },
        "answer": "B"
      },
      {
        "question": "Cuốn sách nào được đề xuất để tìm hiểu sâu hơn về các vấn đề lao động trong ngành công nghệ?",
        "options": {
          "A": "The Innovator's Dilemma",
          "B": "Zero to One",
          "C": "Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass",
          "D": "The Lean Startup"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, những sản phẩm AI nào có thể mang lại hàng tỷ đô la cho các công ty phát triển chúng?",
        "options": {
          "A": "Chỉ các mô hình ngôn ngữ lớn.",
          "B": "Chỉ xe tự hành.",
          "C": "Chỉ các công cụ tìm kiếm.",
          "D": "Công cụ tìm kiếm, mô hình ngôn ngữ và xe tự hành."
        },
        "answer": "D"
      }
    ]
  },
  "google-revises-ai-principles-lifting-ban-on-weapons-and-surveillance-applications": {
    "title": "Google Joins AI Peers In Military Work",
    "collection": "business",
    "content": "Google revised its AI principles, reversing previous commitments to avoid work on weapons, surveillance, and other military applications beyond non-lethal uses like communications, logistics, and medicine.\n\nWhat’s new:Along with releasing its latestResponsible AI Progress Reportand an updated AIsafety framework, Google removed key restrictions from itsAI principles. The new version omits a section in the previous document titled “Applications we will not pursue.” The deleted textpledgedto avoid “technologies that cause or are likely to cause overall harm” and, where the technology risks doing harm, to “proceed only where we believe that the benefits substantially outweigh the risks” with “appropriate safety constraints.”\n\nHow it works:Google’s AI principles no longer prohibit specific applications but promote developing the technology to improve scientific inquiry, national security, and the economy.\n\nBehind the news:Google’s new stance reverses a commitment it made in 2018 after employeesprotestedits involvement inProject Maven, a Pentagon AI program for drone surveillance, from which Google ultimately withdrew. At the time, Google pledged not to develop AI applications for weapons or surveillance, which set it apart from Amazon and Microsoft. Since then, the company has expanded its work in defense,building ona $1.3 billion contract with Israel. In 2024,Anthropic, Meta, andOpenAIremoved their restrictions on military and defense applications, and Anthropic and OpenAIstrengthenedtheir ties with defense contractors such as Anduril and Palantir.\n\nWhy it matters:Google’s shift in policy comes as AI is playing an increasing role in conflicts in Israel,Ukraine, and elsewhere, and while global geopolitical tensions are on the rise. While Google’s previous position kept it out of military AI development, defense contractors like Anduril, Northrop Grumman, and Palantir — not to mention AI-giant peers — stepped in. The new principles recognize the need for democratic countries to take the lead in developing technology and standards for its use as well as the massive business opportunity in military AI as governments worldwide seek new defense capabilities. Still, no widely acceptedglobal frameworkgoverns uses of AI in combat.\n\nWe’re thinking:Knowing how and when to employ AI in warfare is one of the most difficult ethical questions of our time. Democratic nations have a right to defend themselves, and those of us who live in democracies have a responsibility to support fellow citizens who would put themselves in harm’s way to protect us. AI is transforming military strategy, and refusing to engage with it doesn’t make the risks go away.",
    "qa": [
      {
        "question": "Nguyên tắc AI mới của Google đã thay đổi như thế nào so với trước đây?",
        "options": {
          "A": "Cấm hoàn toàn việc sử dụng AI trong các ứng dụng quân sự.",
          "B": "Loại bỏ các hạn chế cụ thể đối với các ứng dụng AI, bao gồm cả quân sự.",
          "C": "Chỉ cho phép sử dụng AI trong các ứng dụng quân sự phi sát thương.",
          "D": "Tăng cường các biện pháp kiểm soát đối với việc sử dụng AI trong các ứng dụng liên quan đến an ninh quốc gia."
        },
        "answer": "B"
      },
      {
        "question": "Văn bản nào đã bị loại bỏ khỏi nguyên tắc AI của Google?",
        "options": {
          "A": "Cam kết phát triển AI để cải thiện khoa học và kinh tế.",
          "B": "Cam kết tránh các công nghệ gây hại hoặc có khả năng gây hại.",
          "C": "Cam kết hợp tác với các chính phủ dân chủ trong phát triển AI.",
          "D": "Cam kết tuân thủ các tiêu chuẩn đạo đức toàn cầu về AI."
        },
        "answer": "B"
      },
      {
        "question": "Dự án Maven là gì và tại sao nó lại liên quan đến sự thay đổi trong chính sách AI của Google?",
        "options": {
          "A": "Một dự án nghiên cứu về AI trong lĩnh vực y tế mà Google tài trợ.",
          "B": "Một chương trình AI của Lầu Năm Góc về giám sát bằng máy bay không người lái mà Google đã rút khỏi sau các cuộc biểu tình.",
          "C": "Một sáng kiến hợp tác giữa Google và Amazon để phát triển AI cho mục đích thương mại.",
          "D": "Một dự án phát triển AI cho xe tự lái của Google."
        },
        "answer": "B"
      },
      {
        "question": "Những công ty nào khác trong lĩnh vực AI đã nới lỏng hoặc loại bỏ các hạn chế đối với ứng dụng quân sự và quốc phòng?",
        "options": {
          "A": "Apple và Samsung.",
          "B": "IBM và Oracle.",
          "C": "Anthropic, Meta và OpenAI.",
          "D": "Tesla và SpaceX."
        },
        "answer": "C"
      },
      {
        "question": "Sự thay đổi chính sách của Google diễn ra trong bối cảnh nào?",
        "options": {
          "A": "Sự suy giảm vai trò của AI trong các cuộc xung đột toàn cầu.",
          "B": "Sự gia tăng căng thẳng địa chính trị và vai trò ngày càng tăng của AI trong các cuộc xung đột.",
          "C": "Sự thống nhất về một khuôn khổ toàn cầu về sử dụng AI trong chiến đấu.",
          "D": "Sự giảm sút đầu tư vào lĩnh vực AI quân sự."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lý do nào khiến Google thay đổi chính sách AI của mình?",
        "options": {
          "A": "Để tập trung vào các ứng dụng AI trong lĩnh vực y tế và giáo dục.",
          "B": "Để tránh bị tụt hậu so với các đối thủ cạnh tranh và nắm bắt cơ hội kinh doanh trong lĩnh vực AI quân sự.",
          "C": "Do áp lực từ các tổ chức phi chính phủ phản đối việc sử dụng AI trong quân sự.",
          "D": "Do sự suy giảm nhu cầu về AI trong lĩnh vực quốc phòng."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến những quốc gia nào đang diễn ra các cuộc xung đột mà AI đóng vai trò ngày càng tăng?",
        "options": {
          "A": "Syria, Afghanistan, và Iraq.",
          "B": "Israel, Ukraine, và các khu vực khác.",
          "C": "Triều Tiên, Iran, và Venezuela.",
          "D": "Nga, Trung Quốc, và Ấn Độ."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết cho rằng các quốc gia dân chủ nên làm gì trong bối cảnh AI ngày càng phát triển?",
        "options": {
          "A": "Cấm hoàn toàn việc sử dụng AI trong lĩnh vực quân sự.",
          "B": "Dẫn đầu trong việc phát triển công nghệ và tiêu chuẩn sử dụng AI.",
          "C": "Hạn chế hợp tác quốc tế trong lĩnh vực AI.",
          "D": "Chỉ tập trung vào phát triển AI cho mục đích dân sự."
        },
        "answer": "B"
      },
      {
        "question": "Hợp đồng trị giá 1.3 tỷ đô la mà Google đã xây dựng là với quốc gia nào?",
        "options": {
          "A": "Ukraine",
          "B": "Israel",
          "C": "Hoa Kỳ",
          "D": "Anh"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, câu hỏi đạo đức khó khăn nhất trong thời đại ngày nay là gì?",
        "options": {
          "A": "Làm thế nào để đảm bảo an toàn cho dữ liệu cá nhân khi sử dụng AI.",
          "B": "Làm thế nào và khi nào nên sử dụng AI trong chiến tranh.",
          "C": "Làm thế nào để ngăn chặn sự phân biệt đối xử do AI gây ra.",
          "D": "Làm thế nào để đảm bảo rằng AI được sử dụng một cách công bằng và minh bạch."
        },
        "answer": "B"
      }
    ]
  },
  "googles-new-ai-offerings-include-veo-3-video-generator-lightweight-gemma-3n-updates-to-gemini-pro-and-ultra-and-more": {
    "title": "Google I/O Overdrive",
    "collection": "business",
    "content": "Google revamped its roster of models, closed and open, and added more AI-powered features to its existing products.\n\nWhat’s new:Google staged a parade ofannouncementsat this year’s I/O developer conference. New offerings include improvements toGemini 2.5 Pro and Gemini 2.5 Flashand a preview ofGemma 3n(all three generally available in June), the updatedVeo 3video generator (available via Flow, Google’s AI videography app, for paid subscribers to its AI Pro and Ultra services), and increasingly AI-powered search.\n\nHow it works:The I/O offerings spanned from public-facing products to developer tools.\n\nWhy it matters:Google is catching up with the Microsoft/OpenAI colossus on several fronts. The addition of audio output to Gemini and Gemma models fuels the rise of voice-to-voice and other audio applications and gives developers powerful new tools to build them. At the same time, Veo 3’s text-to-video-plus-audio output showsmarkedimprovementover the previous version.\n\nBehind the news:The number of tokens Google processed monthly has surged this year from 9.7 trillion last year to 480 trillion, a sign that its AI APIs and AI-infused products are rapidly gaining traction. Google’s progress contrasts with Apple’s ongoingstruggles. Both share advantages in smartphones and app distribution. But, while Google has showcased a string of advanced models as well as early efforts to integrate them into legacy products, Apple’s organizational challenges have hampered its AI development. Now Apple must contend with OpenAI’sacquisitionof LoveFrom, the startup founded by its former lead product designer Jony Ive.\n\nWe’re thinking:Google I/O 2025 was a strong showing of generative AI capabilities! There’s still work to be done to translate these innovations into compelling products, but the company now has a strong base for building numerous innovative products.",
    "qa": [
      {
        "question": "Sự kiện nào đã diễn ra mà Google trình bày một loạt các thông báo về các sản phẩm và cải tiến AI?",
        "options": {
          "A": "Hội nghị thượng đỉnh AI toàn cầu",
          "B": "Hội nghị nhà phát triển I/O",
          "C": "Triển lãm công nghệ CES",
          "D": "Hội nghị Microsoft Build"
        },
        "answer": "B"
      },
      {
        "question": "Gemini 2.5 Pro và Gemini 2.5 Flash sẽ được phát hành rộng rãi vào thời điểm nào?",
        "options": {
          "A": "Tháng 5",
          "B": "Tháng 6",
          "C": "Tháng 7",
          "D": "Tháng 8"
        },
        "answer": "B"
      },
      {
        "question": "Veo 3, trình tạo video được cập nhật của Google, có sẵn thông qua ứng dụng nào?",
        "options": {
          "A": "Google Photos",
          "B": "Google Clips",
          "C": "Flow",
          "D": "Google Lens"
        },
        "answer": "C"
      },
      {
        "question": "Việc bổ sung đầu ra âm thanh cho các mô hình Gemini và Gemma có tác động gì?",
        "options": {
          "A": "Giảm khả năng xử lý ngôn ngữ tự nhiên",
          "B": "Thúc đẩy sự phát triển của các ứng dụng âm thanh và giọng nói",
          "C": "Hạn chế khả năng tạo video từ văn bản",
          "D": "Tăng chi phí phát triển các ứng dụng AI"
        },
        "answer": "B"
      },
      {
        "question": "Sự cải tiến đáng chú ý nào được đề cập về Veo 3 so với phiên bản trước?",
        "options": {
          "A": "Khả năng tạo hình ảnh 3D",
          "B": "Đầu ra văn bản thành video kèm âm thanh được cải thiện",
          "C": "Tốc độ xử lý nhanh hơn",
          "D": "Khả năng tương thích với nhiều thiết bị hơn"
        },
        "answer": "B"
      },
      {
        "question": "Số lượng token mà Google xử lý hàng tháng đã tăng lên bao nhiêu trong năm nay?",
        "options": {
          "A": "Từ 9.7 nghìn tỷ lên 97 nghìn tỷ",
          "B": "Từ 9.7 nghìn tỷ lên 48 nghìn tỷ",
          "C": "Từ 9.7 nghìn tỷ lên 480 nghìn tỷ",
          "D": "Từ 9.7 nghìn tỷ lên 970 nghìn tỷ"
        },
        "answer": "C"
      },
      {
        "question": "Công ty nào được đề cập là đang gặp khó khăn trong việc phát triển AI, trái ngược với tiến bộ của Google?",
        "options": {
          "A": "Microsoft",
          "B": "Amazon",
          "C": "Apple",
          "D": "Samsung"
        },
        "answer": "C"
      },
      {
        "question": "Công ty LoveFrom, được thành lập bởi Jony Ive, đã được công ty nào mua lại?",
        "options": {
          "A": "Google",
          "B": "Microsoft",
          "C": "OpenAI",
          "D": "Amazon"
        },
        "answer": "C"
      },
      {
        "question": "Nhận định chung về Google I/O 2025 là gì?",
        "options": {
          "A": "Một sự kiện thất bại của Google",
          "B": "Một sự kiện thể hiện khả năng AI tạo sinh mạnh mẽ",
          "C": "Một sự kiện tập trung vào phần cứng hơn là phần mềm",
          "D": "Một sự kiện không có nhiều đổi mới đáng kể"
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu tiếp theo của Google sau khi đã có một nền tảng vững chắc cho AI tạo sinh là gì?",
        "options": {
          "A": "Giảm chi phí phát triển AI",
          "B": "Tăng cường hợp tác với các công ty khác",
          "C": "Chuyển đổi những đổi mới này thành các sản phẩm hấp dẫn",
          "D": "Tập trung vào việc phát triển phần cứng AI"
        },
        "answer": "C"
      }
    ]
  },
  "got-model": {
    "title": "Got Model?",
    "collection": "business",
    "content": "Who needs cows when you can make milk from scratch?What’s new:NotMilk, a dairy-free milk substitute that was designed with help from a deep learning model, made its debut in American grocery stores, theWall Street Journalreports.How it works:Chilean food-tech startupNotCodeveloped a model called Giuseppe that finds combinations of plant products that mimic the characteristics of animal-derived foods. The model also helped NotCo develop plant-based mayonnaise, ice cream, and hamburgers.\n\nBehind the news:NotCo is one of several companies using machine learning to discover new culinary secrets.\n\nWhy it matters:Producing animal-based foods can takeenormous quantities of natural resourcescompared to growing and processing plants. If AI can help the food and beverage industry develop the market for animal-free substitutes — which is expected to grow 14 percent annually over the next five years, according to oneanalysis—it could reduce the environmental toll.We’re thinking:We look forward to the day when an AI-poweredchefin our AI-augmentedkitchenpours us a glass of AI-designed milk.",
    "qa": [
      {
        "question": "Công ty NotCo đến từ quốc gia nào?",
        "options": {
          "A": "Hoa Kỳ",
          "B": "Chile",
          "C": "Tây Ban Nha",
          "D": "Argentina"
        },
        "answer": "B"
      },
      {
        "question": "Tên của mô hình deep learning mà NotCo sử dụng là gì?",
        "options": {
          "A": "NotMilk",
          "B": "NotCode",
          "C": "Giuseppe",
          "D": "DeepFood"
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của mô hình Giuseppe là gì?",
        "options": {
          "A": "Tìm ra các công thức nấu ăn mới từ thực vật.",
          "B": "Phát triển các sản phẩm thay thế thực phẩm có nguồn gốc động vật bằng thực vật.",
          "C": "Tối ưu hóa quy trình sản xuất thực phẩm.",
          "D": "Nghiên cứu tác động của thực phẩm lên sức khỏe con người."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài sữa, NotCo còn phát triển những sản phẩm nào khác sử dụng AI?",
        "options": {
          "A": "Phô mai, sữa chua, bánh ngọt.",
          "B": "Mayonnaise, kem, hamburger.",
          "C": "Bánh mì, mì ống, pizza.",
          "D": "Salad, súp, nước ép."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, thị trường các sản phẩm thay thế thực phẩm có nguồn gốc động vật dự kiến sẽ tăng trưởng bao nhiêu phần trăm mỗi năm trong 5 năm tới?",
        "options": {
          "A": "5%",
          "B": "10%",
          "C": "14%",
          "D": "20%"
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích chính của việc sử dụng AI để phát triển các sản phẩm thay thế thực phẩm có nguồn gốc động vật là gì?",
        "options": {
          "A": "Giảm chi phí sản xuất.",
          "B": "Tăng hương vị và chất lượng sản phẩm.",
          "C": "Giảm tác động tiêu cực đến môi trường.",
          "D": "Tăng cường sức khỏe cho người tiêu dùng."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến tờ báo nào đã đưa tin về sản phẩm NotMilk?",
        "options": {
          "A": "The New York Times",
          "B": "The Wall Street Journal",
          "C": "The Washington Post",
          "D": "USA Today"
        },
        "answer": "B"
      },
      {
        "question": "NotMilk là sản phẩm thay thế cho loại thực phẩm nào?",
        "options": {
          "A": "Thịt bò",
          "B": "Trứng",
          "C": "Sữa",
          "D": "Phô mai"
        },
        "answer": "C"
      },
      {
        "question": "Điều gì khiến NotCo khác biệt so với các công ty thực phẩm khác?",
        "options": {
          "A": "Sử dụng các nguyên liệu hữu cơ.",
          "B": "Áp dụng công nghệ AI để phát triển sản phẩm.",
          "C": "Tập trung vào thị trường quốc tế.",
          "D": "Có đội ngũ nghiên cứu khoa học hàng đầu."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì có thể xảy ra trong tương lai liên quan đến AI và thực phẩm?",
        "options": {
          "A": "AI sẽ thay thế hoàn toàn con người trong ngành thực phẩm.",
          "B": "AI sẽ giúp tạo ra những loại thực phẩm hoàn toàn mới và độc đáo.",
          "C": "AI sẽ chỉ được sử dụng trong các nhà hàng cao cấp.",
          "D": "AI sẽ làm cho thực phẩm trở nên đắt đỏ hơn."
        },
        "answer": "B"
      }
    ]
  },
  "3d-scene-synthesis-for-the-real-world": {
    "title": "3D Scene Synthesis for the Real World",
    "collection": "ml-research",
    "content": "Researchers have used neural networks to generate novel views of a 3D scene based on existing pictures plus the positions and angles of the cameras that took them. In practice, though, you may not know the precise camera positions and angles, since location sensors may be unavailable or miscalibrated. A new method synthesizes novel perspectives based on existing views alone.What’s new:Chen-Hsuan Lin led researchers at Carnegie Mellon University, Massachusetts Institute of Technology, and University of Adelaide in developing the archly namedBundle-Adjusting Neural Radiance Fields(BARF), a technique that generates new 3D views from images of a scene without requiring further information.Key insight:The earlier method calledNeRFrequires camera positions and angles to find values that feed a neural network. Those variables can be represented by a learnable vector, and backpropagation can update it as well as the network’s weights.How it works:Like NeRF, BARF generates views of a scene by sampling points along rays that extend from the camera through each pixel. It uses a vanilla neural network to compute the color and transparency of each point based on the point’s position and the ray’s direction. To determine the color of a given pixel, it combines the color and transparency of all points along  the associated ray. Unlike NeRF, BARF’s loss function is designed to learn camera positions and angles, and it uses a training schedule to learn camera viewpoints before pixel colors.\n\nResults:The researchers compared BARF to NeRF, measuring their ability to generate a novel view based on several views of an everydayscene, where the viewpoints were unknown to BARF and known to NeRF. BARF achieved 21.96 competitive peak signal-to-noise ratio, a measure of the difference between the generated and actual images (higher is better). NeRF achieved 23.25 competitive peak signal-to-noise ratio.Why it matters:Data collected in the wild rarely are perfect, and bad sensors are one of many reasons why. BARF is part of a new generation of models that don’t assume accurate sensor input, spurring hopes of systems that generalize to real-world conditions.We’re thinking:In language processing,ELMokicked off a fad for naming algorithms after Sesame Street characters. Here’s hoping this work doesn’t inspire its own run of names.",
    "qa": [
      {
        "question": "Phương pháp BARF được phát triển bởi nhóm nghiên cứu từ những trường đại học nào?",
        "options": {
          "A": "Stanford University, University of California, và University of Oxford",
          "B": "Carnegie Mellon University, Massachusetts Institute of Technology, và University of Adelaide",
          "C": "Harvard University, Princeton University, và Yale University",
          "D": "University of Tokyo, Kyoto University, và Osaka University"
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính giữa BARF và NeRF là gì?",
        "options": {
          "A": "BARF sử dụng mạng neural phức tạp hơn NeRF.",
          "B": "BARF không yêu cầu thông tin về vị trí và góc của camera, trong khi NeRF cần.",
          "C": "BARF chỉ có thể tạo ra hình ảnh 2D, trong khi NeRF tạo ra hình ảnh 3D.",
          "D": "BARF nhanh hơn NeRF trong việc tạo ra các góc nhìn mới."
        },
        "answer": "B"
      },
      {
        "question": "BARF sử dụng phương pháp nào để xác định màu sắc của một pixel?",
        "options": {
          "A": "Tính trung bình màu sắc của các pixel lân cận.",
          "B": "Kết hợp màu sắc và độ trong suốt của tất cả các điểm dọc theo tia từ camera qua pixel đó.",
          "C": "Sử dụng một hàm toán học phức tạp dựa trên vị trí của pixel.",
          "D": "Lấy mẫu ngẫu nhiên màu sắc từ một tập hợp màu được định nghĩa trước."
        },
        "answer": "B"
      },
      {
        "question": "Chỉ số competitive peak signal-to-noise ratio (PSNR) được sử dụng để đo lường điều gì trong bài viết?",
        "options": {
          "A": "Độ phức tạp của mạng neural.",
          "B": "Thời gian cần thiết để tạo ra một góc nhìn mới.",
          "C": "Sự khác biệt giữa hình ảnh được tạo ra và hình ảnh thực tế.",
          "D": "Độ chính xác của thông tin vị trí camera."
        },
        "answer": "C"
      },
      {
        "question": "Kết quả PSNR của BARF so với NeRF trong thử nghiệm được đề cập là gì?",
        "options": {
          "A": "BARF đạt PSNR cao hơn NeRF đáng kể.",
          "B": "BARF đạt PSNR tương đương NeRF.",
          "C": "BARF đạt PSNR thấp hơn NeRF một chút.",
          "D": "BARF không thể so sánh với NeRF về PSNR."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao BARF lại quan trọng trong bối cảnh dữ liệu thực tế?",
        "options": {
          "A": "Vì nó có thể tạo ra hình ảnh chất lượng cao hơn NeRF.",
          "B": "Vì nó giả định dữ liệu cảm biến hoàn hảo, phù hợp với môi trường phòng thí nghiệm.",
          "C": "Vì nó không yêu cầu dữ liệu cảm biến chính xác, phù hợp với dữ liệu thu thập được trong điều kiện thực tế.",
          "D": "Vì nó có thể xử lý dữ liệu với tốc độ nhanh hơn NeRF."
        },
        "answer": "C"
      },
      {
        "question": "Cơ chế nào được BARF sử dụng để cập nhật vị trí và góc của camera?",
        "options": {
          "A": "Sử dụng bộ lọc Kalman.",
          "B": "Sử dụng thuật toán tối ưu hóa di truyền.",
          "C": "Sử dụng lan truyền ngược (backpropagation).",
          "D": "Sử dụng phương pháp Monte Carlo."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích của việc sử dụng 'training schedule' trong BARF là gì?",
        "options": {
          "A": "Để tăng tốc quá trình huấn luyện mạng neural.",
          "B": "Để học vị trí camera trước khi học màu sắc pixel.",
          "C": "Để giảm thiểu lỗi trong quá trình tạo ảnh.",
          "D": "Để cải thiện độ phân giải của hình ảnh được tạo ra."
        },
        "answer": "B"
      },
      {
        "question": "Thuật ngữ 'Bundle-Adjusting' trong tên BARF ám chỉ điều gì?",
        "options": {
          "A": "Việc điều chỉnh kích thước của các bó tia sáng.",
          "B": "Việc tối ưu hóa đồng thời vị trí camera và cấu trúc 3D của cảnh.",
          "C": "Việc nén dữ liệu hình ảnh để giảm dung lượng lưu trữ.",
          "D": "Việc sử dụng nhiều camera cùng lúc để thu thập dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Trong bài viết, ELMO được nhắc đến với vai trò gì?",
        "options": {
          "A": "Một thuật toán xử lý ngôn ngữ tự nhiên cạnh tranh với BARF.",
          "B": "Một ví dụ về xu hướng đặt tên thuật toán theo các nhân vật Sesame Street.",
          "C": "Một phương pháp cải thiện độ chính xác của cảm biến vị trí.",
          "D": "Một công cụ để đánh giá chất lượng hình ảnh được tạo ra bởi BARF."
        },
        "answer": "B"
      }
    ]
  },
  "3d-object-factory": {
    "title": "3D Object Factory",
    "collection": "ml-research",
    "content": "In the open-ended video gameMinecraft, players extract blocks of virtual materials from a 3D environment to assemble objects of their own design, from trees to cathedrals. Researchers trained neural networks to generate these structures.\n\nWhat’s new:Shyam Sudhakaran and researchers at University of Copenhagen, University of York, and Shanghai University used a neural cellular automaton algorithm toconstruct 3D objects. The work demonstrates the potential for such algorithms to generate structures in three dimensions, as typically they’re limited to two.\n\nKey insight:Acellular automatongenerates complex patterns on a 2D grid by changing each cell’s state iteratively based on simple rules that depend on the states of its neighbors. Aneural cellular automatonupdates cells depending on the output of a neural network and the states of neighboring cells. Using 3D convolutions enables a neural cellular automaton to generate patterns in 3D.\n\nHow it works:The authors trained several 3D convolutional neural networks to reproduce structures found on the community websitePlanet Minecraft. Each different structure required its own model. The structures comprised 50 block types mostly corresponding to materials (stone, glass, metals, and so on), including piston blocks that push or pull adjacent blocks to produce animated objects. The system spawned block types directly without needing to virtually mine them out of the virtual ground.\n\nResults:The authors reported few quantitative results. However, the trained models grew static structures like castles, temples, and apartments that appear to be accurate inside and out. One model learned to grow an animated caterpillar.\n\nWhy it matters:Cellular automata may have certain benefits. For instance, if part of the resulting structure is destroyed, the automaton can use what’s left to regenerate the missing part. This approach can produce resilient digital 3D structures with no human intervention after the first step.\n\nWe’re thinking:Machine learning engineers looking for an excuse to play Minecraft need look no further!",
    "qa": [
      {
        "question": "Trong trò chơi Minecraft, người chơi làm gì với các khối vật liệu ảo?",
        "options": {
          "A": "Phá hủy chúng để tạo ra không gian trống.",
          "B": "Khai thác chúng để bán lấy tiền ảo.",
          "C": "Sử dụng chúng để xây dựng các công trình theo thiết kế riêng.",
          "D": "Sử dụng chúng để chiến đấu với quái vật."
        },
        "answer": "C"
      },
      {
        "question": "Thuật toán nào được các nhà nghiên cứu sử dụng để xây dựng các đối tượng 3D trong Minecraft?",
        "options": {
          "A": "Thuật toán di truyền.",
          "B": "Mạng nơ-ron tế bào tự động.",
          "C": "Thuật toán tìm kiếm đường đi A*.",
          "D": "Mạng nơ-ron đối nghịch (GAN)."
        },
        "answer": "B"
      },
      {
        "question": "Điểm mới trong nghiên cứu này là gì so với các ứng dụng trước đây của mạng nơ-ron tế bào tự động?",
        "options": {
          "A": "Khả năng tạo ra các đối tượng 2D phức tạp hơn.",
          "B": "Khả năng tạo ra các đối tượng 3D, thay vì chỉ giới hạn ở 2D.",
          "C": "Khả năng tạo ra các đối tượng có màu sắc đa dạng hơn.",
          "D": "Khả năng tạo ra các đối tượng có độ phân giải cao hơn."
        },
        "answer": "B"
      },
      {
        "question": "Mạng nơ-ron tế bào tự động cập nhật trạng thái của các ô dựa trên yếu tố nào?",
        "options": {
          "A": "Đầu vào ngẫu nhiên.",
          "B": "Đầu ra của một mạng nơ-ron và trạng thái của các ô lân cận.",
          "C": "Chỉ trạng thái của các ô lân cận.",
          "D": "Chỉ đầu ra của một mạng nơ-ron."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã sử dụng loại mạng nơ-ron nào để huấn luyện hệ thống?",
        "options": {
          "A": "Mạng nơ-ron hồi quy (RNN).",
          "B": "Mạng nơ-ron tích chập 3D.",
          "C": "Mạng nơ-ron lan truyền ngược (Backpropagation).",
          "D": "Mạng nơ-ron tự mã hóa (Autoencoder)."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu huấn luyện cho các mô hình đến từ đâu?",
        "options": {
          "A": "Các công trình do chính các nhà nghiên cứu xây dựng trong Minecraft.",
          "B": "Các công trình được tạo ra bởi một thuật toán ngẫu nhiên.",
          "C": "Các công trình được tìm thấy trên trang web cộng đồng Planet Minecraft.",
          "D": "Các công trình được trích xuất từ các trò chơi Minecraft khác."
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống tạo ra các khối vật liệu như thế nào?",
        "options": {
          "A": "Bằng cách khai thác chúng từ lòng đất ảo.",
          "B": "Bằng cách sử dụng các công thức hóa học ảo.",
          "C": "Bằng cách tạo ra chúng trực tiếp mà không cần khai thác.",
          "D": "Bằng cách chuyển đổi các khối vật liệu khác."
        },
        "answer": "C"
      },
      {
        "question": "Một trong những kết quả đáng chú ý của nghiên cứu là gì?",
        "options": {
          "A": "Mô hình có thể tạo ra các công trình có thể tự sửa chữa khi bị hư hỏng.",
          "B": "Mô hình có thể tạo ra các công trình có thể bay lượn trên không.",
          "C": "Mô hình có thể tạo ra một con sâu bướm hoạt hình.",
          "D": "Mô hình có thể tạo ra các công trình có thể tương tác với người chơi."
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích tiềm năng của việc sử dụng mạng nơ-ron tế bào tự động là gì?",
        "options": {
          "A": "Tạo ra các công trình có độ bền cao hơn.",
          "B": "Tạo ra các công trình có thể tự động tái tạo khi bị phá hủy.",
          "C": "Tạo ra các công trình có chi phí xây dựng thấp hơn.",
          "D": "Tạo ra các công trình có thiết kế phức tạp hơn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết gợi ý gì cho các kỹ sư học máy?",
        "options": {
          "A": "Nên tập trung vào việc phát triển các thuật toán khai thác tài nguyên hiệu quả hơn.",
          "B": "Nên tìm kiếm cơ hội để chơi Minecraft như một cách để nghiên cứu và phát triển.",
          "C": "Nên tránh sử dụng Minecraft vì nó quá phức tạp.",
          "D": "Nên hợp tác với các kiến trúc sư để tạo ra các công trình đẹp hơn."
        },
        "answer": "B"
      }
    ]
  },
  "24-hours-on-an-old-consumer-gpu": {
    "title": "24 Hours on an Old Consumer GPU",
    "collection": "ml-research",
    "content": "BERT, a large language model released in 2018 and built upon the then-new transformer architecture, marked a paradigm shift in AI. Researchers explored whether innovations since then would enable them to train an equivalent model while using orders of magnitude less processing power.\n\nWhat’s new:Jonas Geiping and Tom Goldstein at University of Maryland tried to match BERT using a similar architecture but much less computation. They limited their compute budget to 24 hours on a single, BERT-vintage 24GB Nvidia 2080 Ti processor — about 1/136th of the compute used to train BERT. Drawing a parallel to studying for a test only one day before taking it, they call their processcramming.\n\nKey insight:According tolanguage model scaling laws, the accuracy of a transformer model depends mainly on the sizes of the model and training set. If tweaking the architecture enables a model to process tokens faster, it can train on more data in the same amount of time — so, after training, it should perform better than a slower model trained for the same amount of time. Therefore the best architecture is the one that, during training, processes the greatest amount of data within a given amount of time.\n\nHow it works:The authors built their model using aBERT-size transformer (110 million parameters), and they pretrained it on filtered data and fine-tuned it on the same benchmark dataset (GLUE). They modified the architecture, training data, and hyperparameters to improve training speed and efficiency.\n\nResults:The authors’ model didn’t beat BERT, but it came within a few percentage points. For instance, it achieved 78.3 percent accuracy onGeneral Language Understanding Evaluation (GLUE), while BERT achieved 80.9 percent accuracy. Trained using the same limited processing resources, the original BERT architecture achieved 52.0 percent. The authors found that the gains came mostly from architecture changes, followed by data changes, while hyperparameter changes had the least impact.\n\nWhy it matters:There’s room to optimize pretraining of LLMs. Careful attention to architecture, training data, and hyperparameters can yield powerful models even with severely limited computation.\n\nWe’re thinking:The work serves as a guide to training BERT-style models efficiently and a starting point to training modern transformers.",
    "qa": [
      {
        "question": "Mục tiêu chính của nghiên cứu được đề cập trong bài viết là gì?",
        "options": {
          "A": "Đánh bại BERT về hiệu suất trên mọi tác vụ.",
          "B": "Huấn luyện một mô hình tương đương BERT với chi phí tính toán thấp hơn đáng kể.",
          "C": "Phát triển một kiến trúc transformer hoàn toàn mới thay thế BERT.",
          "D": "Nghiên cứu ảnh hưởng của kích thước dữ liệu huấn luyện đến hiệu suất của BERT."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu tại Đại học Maryland đã sử dụng phương pháp nào để giảm chi phí tính toán trong quá trình huấn luyện mô hình?",
        "options": {
          "A": "Sử dụng một bộ xử lý mạnh mẽ hơn nhiều so với bộ xử lý được dùng để huấn luyện BERT.",
          "B": "Giới hạn ngân sách tính toán trong 24 giờ trên một GPU Nvidia 2080 Ti.",
          "C": "Tăng kích thước của mô hình transformer để bù đắp cho việc giảm dữ liệu huấn luyện.",
          "D": "Sử dụng một thuật toán tối ưu hóa mới để tăng tốc quá trình huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Thuật ngữ 'cramming' được sử dụng trong bài viết để ám chỉ điều gì?",
        "options": {
          "A": "Quá trình tăng cường dữ liệu huấn luyện để cải thiện hiệu suất mô hình.",
          "B": "Quá trình huấn luyện mô hình trong một khoảng thời gian rất ngắn với nguồn lực hạn chế.",
          "C": "Quá trình nén mô hình để giảm kích thước và tăng tốc độ suy luận.",
          "D": "Quá trình điều chỉnh siêu tham số để tối ưu hóa hiệu suất mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Theo quy luật tỷ lệ của mô hình ngôn ngữ, yếu tố nào quan trọng nhất đối với độ chính xác của mô hình transformer?",
        "options": {
          "A": "Kiến trúc của mô hình và thuật toán tối ưu hóa được sử dụng.",
          "B": "Kích thước của mô hình và kích thước của tập dữ liệu huấn luyện.",
          "C": "Siêu tham số được sử dụng trong quá trình huấn luyện.",
          "D": "Chất lượng của dữ liệu huấn luyện và phương pháp tiền xử lý dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã thực hiện những thay đổi nào để cải thiện tốc độ và hiệu quả huấn luyện mô hình?",
        "options": {
          "A": "Chỉ thay đổi siêu tham số.",
          "B": "Thay đổi kiến trúc, dữ liệu huấn luyện và siêu tham số.",
          "C": "Chỉ thay đổi kiến trúc.",
          "D": "Chỉ thay đổi dữ liệu huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả chính của nghiên cứu là gì?",
        "options": {
          "A": "Mô hình mới đã đánh bại BERT về độ chính xác trên GLUE.",
          "B": "Mô hình mới đạt được độ chính xác tương đương BERT trên GLUE.",
          "C": "Mô hình mới đạt được độ chính xác gần bằng BERT trên GLUE, vượt trội hơn so với việc huấn luyện BERT với cùng nguồn lực hạn chế.",
          "D": "Mô hình mới không thể đạt được độ chính xác chấp nhận được trên GLUE."
        },
        "answer": "C"
      },
      {
        "question": "Trên bộ dữ liệu GLUE, mô hình của các tác giả đạt được độ chính xác là bao nhiêu?",
        "options": {
          "A": "80.9%",
          "B": "52.0%",
          "C": "78.3%",
          "D": "90.0%"
        },
        "answer": "C"
      },
      {
        "question": "Theo nghiên cứu, yếu tố nào đóng góp nhiều nhất vào sự cải thiện hiệu suất của mô hình?",
        "options": {
          "A": "Thay đổi siêu tham số.",
          "B": "Thay đổi dữ liệu huấn luyện.",
          "C": "Thay đổi kiến trúc.",
          "D": "Kết hợp cả ba yếu tố một cách đồng đều."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhấn mạnh tầm quan trọng của điều gì trong việc huấn luyện các mô hình ngôn ngữ lớn (LLMs)?",
        "options": {
          "A": "Sử dụng các bộ xử lý mạnh mẽ nhất hiện có.",
          "B": "Tối ưu hóa quá trình tiền huấn luyện thông qua việc chú trọng đến kiến trúc, dữ liệu huấn luyện và siêu tham số.",
          "C": "Tăng kích thước của mô hình lên mức tối đa có thể.",
          "D": "Sử dụng các thuật toán tối ưu hóa phức tạp nhất."
        },
        "answer": "B"
      },
      {
        "question": "Công trình nghiên cứu này có thể được xem là gì?",
        "options": {
          "A": "Một phương pháp thay thế hoàn toàn cho BERT.",
          "B": "Một hướng dẫn để huấn luyện các mô hình theo phong cách BERT một cách hiệu quả và là điểm khởi đầu để huấn luyện các transformer hiện đại.",
          "C": "Một bằng chứng cho thấy không thể huấn luyện các mô hình ngôn ngữ lớn với nguồn lực hạn chế.",
          "D": "Một nghiên cứu chỉ tập trung vào việc cải thiện hiệu suất trên bộ dữ liệu GLUE."
        },
        "answer": "B"
      }
    ]
  },
  "4m-21-multimodal-model-excels-in-handling-diverse-input-and-output-types": {
    "title": "Multimodal to the Max",
    "collection": "ml-research",
    "content": "Researchers introduced a model that handles an unprecedented number of input and output types, including many related to performing computer vision tasks.\n\nWhat’s new:Roman Bachmann, Oguzhan Fatih Kar, David Mizrahi and colleagues at EPFL and Apple built4M-21, a system that works with 21 input and output types. These include modalities related to images, geometry, and text along with metadata and embeddings produced by other models.\n\nKey insight:The authors followed and extended their insight from the earlier4M, which handles seven input and output types, as well as work such asUnified-IO 2, which handles 11. The key to training a model to handle multiple types of data input is to ensure that the training data takes the same format with the same-sized embedding across all input types. Using the transformer architecture, tokens suffice.\n\nHow it works:4M-21 comprises a large transformer and several encoder-decoders that convert different data types into tokens and back. The authors repeated their training strategy for 4M, but they increased the transformer’s size from 303 million parameters to 3 billion parameters, boosted the training dataset size from 400 million examples to 500 million examples, and incorporated new input types.\n\nResults:4M-21 demonstrated strong zero-shot performance in a variety of vision tasks. For instance, in estimating surface normals for each point in an image, 4M-21 achieved a 20.8 L1 score (average absolute difference between predicted and true values, lower is better), while the multimodal modelUnifiedIO 2-XLachieved a 34.8 L1. In estimating an image’s depth map, 4M-21 achieved 0.68 L1, while UnifiedIO 2-XL achieved 0.86 L1. In semantic segmentation, 4M-21 reached 48.1 percent mean intersection over union (overlap between predicted and ground-truth segments divided by their union, higher is better), while UnifiedIO 2-XL achieved 39.7 percent mean intersection over union.\n\nWhy it matters:Since 4M-21 learned to predict tokens of several modalities using tokens from other modalities, it isn’t limited to a single modalities as input. The authors demonstrate that it can generate new images conditioned by the combination of a caption and 3D human poses, edges, or metadata.\n\nWe’re thinking:The authors say 4M-21 can take as input any combination of the modalities it’s trained to handle and output any of them. The limits of this capability aren’t clear, but it opens the door to fine control over the model’s output. The authors explain how they extracted the various modalities; presumably users can do the same to prompt the model for the output they desire. For instance, a user could request an image by entering not only a prompt but also a color palette, edges, depth map extracted from another image, and receive output that integrates those elements.",
    "qa": [
      {
        "question": "Mô hình 4M-21 được phát triển bởi những tổ chức nào?",
        "options": {
          "A": "Google và Microsoft",
          "B": "EPFL và Apple",
          "C": "Stanford và MIT",
          "D": "Facebook và Amazon"
        },
        "answer": "B"
      },
      {
        "question": "Số lượng loại dữ liệu đầu vào và đầu ra mà mô hình 4M-21 có thể xử lý là bao nhiêu?",
        "options": {
          "A": "7",
          "B": "11",
          "C": "21",
          "D": "400"
        },
        "answer": "C"
      },
      {
        "question": "Điểm khác biệt chính trong phương pháp huấn luyện của 4M-21 so với các mô hình trước đó như 4M là gì?",
        "options": {
          "A": "Sử dụng kiến trúc mạng nơ-ron hồi quy (RNN)",
          "B": "Tăng kích thước mô hình transformer và bộ dữ liệu huấn luyện",
          "C": "Loại bỏ hoàn toàn việc sử dụng embedding",
          "D": "Chỉ sử dụng dữ liệu hình ảnh để huấn luyện"
        },
        "answer": "B"
      },
      {
        "question": "Kiến trúc chính được sử dụng trong mô hình 4M-21 là gì?",
        "options": {
          "A": "Mạng nơ-ron tích chập (CNN)",
          "B": "Mạng nơ-ron hồi quy (RNN)",
          "C": "Transformer",
          "D": "Mạng đối kháng sinh (GAN)"
        },
        "answer": "C"
      },
      {
        "question": "Trong bài toán ước tính pháp tuyến bề mặt, mô hình 4M-21 đạt được kết quả như thế nào so với UnifiedIO 2-XL?",
        "options": {
          "A": "Tốt hơn với L1 score là 34.8",
          "B": "Tệ hơn với L1 score là 20.8",
          "C": "Tốt hơn với L1 score là 20.8",
          "D": "Tệ hơn với L1 score là 34.8"
        },
        "answer": "C"
      },
      {
        "question": "Chỉ số nào được sử dụng để đánh giá hiệu suất của mô hình trong bài toán phân vùng ngữ nghĩa (semantic segmentation)?",
        "options": {
          "A": "L1 score",
          "B": "Độ chính xác (Accuracy)",
          "C": "Mean Intersection over Union (mIoU)",
          "D": "F1-score"
        },
        "answer": "C"
      },
      {
        "question": "Một trong những ứng dụng tiềm năng của 4M-21 được đề cập trong bài viết là gì?",
        "options": {
          "A": "Tự động dịch văn bản từ nhiều ngôn ngữ",
          "B": "Tạo ra hình ảnh mới dựa trên sự kết hợp của chú thích và các yếu tố 3D",
          "C": "Dự đoán giá cổ phiếu trên thị trường chứng khoán",
          "D": "Phát hiện gian lận trong giao dịch tài chính"
        },
        "answer": "B"
      },
      {
        "question": "Số lượng tham số (parameters) của mô hình transformer trong 4M-21 là bao nhiêu?",
        "options": {
          "A": "303 triệu",
          "B": "400 triệu",
          "C": "500 triệu",
          "D": "3 tỷ"
        },
        "answer": "D"
      },
      {
        "question": "Đâu là yếu tố quan trọng để huấn luyện một mô hình xử lý nhiều loại dữ liệu đầu vào khác nhau, theo như bài viết?",
        "options": {
          "A": "Sử dụng các kiến trúc mạng nơ-ron khác nhau cho từng loại dữ liệu",
          "B": "Đảm bảo dữ liệu huấn luyện có cùng định dạng và kích thước embedding trên tất cả các loại đầu vào",
          "C": "Loại bỏ hoàn toàn việc sử dụng dữ liệu huấn luyện",
          "D": "Tăng số lượng lớp trong mạng nơ-ron"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì khiến 4M-21 không bị giới hạn ở một phương thức đầu vào duy nhất?",
        "options": {
          "A": "Nó chỉ được huấn luyện trên dữ liệu hình ảnh.",
          "B": "Nó học cách dự đoán các token của nhiều phương thức sử dụng token từ các phương thức khác.",
          "C": "Nó sử dụng một kiến trúc mạng nơ-ron hoàn toàn mới.",
          "D": "Nó có thể tự động thu thập dữ liệu huấn luyện từ internet."
        },
        "answer": "B"
      }
    ]
  },
  "a-3d-model-from-one-2d-image": {
    "title": "A 3D Mesh From One 2D Image",
    "collection": "ml-research",
    "content": "Video diffusion provides a new basis for generating 3D meshes.What's new:Vikram Voleti, Chun-Han Yao, Mark Boss, Varun Jampani, and colleagues at Stability AI produced amethodthat generates a 3D mesh from a single image based on Stability’s video diffusion model. You can see its outputhere.Key insight:The approach known as aNeural Radiance Field(NeRF) learns to create a 3D mesh from images of the same object shot at various angles. Given a single image of an object, a video diffusion model can learn to generate videos that orbit around it. The frames from such orbital videos give NeRF the information it needs to produce a 3D model.How it works:To generate a 3D mesh, the authors took one step before and two steps during inference. Before inference: Train a video diffusion model to generate an orbital video. During inference: (i) Train a NeRF model on an orbital video. (ii) Improve the 3D mesh using diffusion followingDreamFusion.\n\nResults:The authors produced 3D meshes from images of 50 objects inGSO, a 3D object dataset of scanned household items. They compared their 3D meshes to those produced by other methods includingEscherNet, a method that uses an image diffusion model to generate images of an object from different angles that are used to train apair of vanilla neural networksto produce a 3D mesh. Evaluated according to Chamfer distance, a measure of the distance between the points on the ground truth and generated 3D models (lower is better), their method achieved .024, while EscherNet achieved .042.\n\nWhy it matters:Video diffusion models must generate different views of the same object, so they require a greater understanding of 3D objects than image diffusion models, which need to generate only one view at a time. Upgrading from an image diffusion model to a video diffusion model makes for better 3D object generation.We’re thinking:Building 3D meshes used to be difficult, but with models like this, it's becoming less of a mesh.",
    "qa": [
      {
        "question": "Phương pháp mới được giới thiệu trong bài viết sử dụng mô hình nào để tạo ra lưới 3D từ một ảnh duy nhất?",
        "options": {
          "A": "Mô hình khuếch tán ảnh (Image diffusion model)",
          "B": "Mô hình khuếch tán video (Video diffusion model)",
          "C": "Mô hình mạng nơ-ron thông thường (Vanilla neural network)",
          "D": "Mô hình EscherNet"
        },
        "answer": "B"
      },
      {
        "question": "NeRF (Neural Radiance Field) học cách tạo lưới 3D từ thông tin nào?",
        "options": {
          "A": "Từ một ảnh duy nhất của vật thể.",
          "B": "Từ các ảnh chụp vật thể ở nhiều góc độ khác nhau.",
          "C": "Từ các mô hình 3D đã được quét sẵn.",
          "D": "Từ các video được tạo ra bởi mô hình khuếch tán ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Trong quá trình suy luận (inference), phương pháp này thực hiện bước nào đầu tiên?",
        "options": {
          "A": "Cải thiện lưới 3D bằng cách sử dụng khuếch tán theo DreamFusion.",
          "B": "Huấn luyện mô hình NeRF trên một video quỹ đạo.",
          "C": "Huấn luyện mô hình khuếch tán video để tạo ra một video quỹ đạo.",
          "D": "So sánh kết quả với các phương pháp khác như EscherNet."
        },
        "answer": "B"
      },
      {
        "question": "Bộ dữ liệu nào được sử dụng để đánh giá hiệu quả của phương pháp tạo lưới 3D trong bài viết?",
        "options": {
          "A": "ImageNet",
          "B": "COCO",
          "C": "GSO (3D object dataset of scanned household items)",
          "D": "MNIST"
        },
        "answer": "C"
      },
      {
        "question": "Chỉ số Chamfer distance được sử dụng để đánh giá điều gì?",
        "options": {
          "A": "Độ chính xác của việc tạo video quỹ đạo.",
          "B": "Khoảng cách giữa các điểm trên mô hình 3D thực tế và mô hình 3D được tạo ra.",
          "C": "Hiệu suất của mô hình khuếch tán video.",
          "D": "Khả năng tái tạo hình ảnh của mô hình NeRF."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp EscherNet sử dụng gì để tạo ra các ảnh của vật thể từ các góc độ khác nhau?",
        "options": {
          "A": "Mô hình khuếch tán video.",
          "B": "Mô hình khuếch tán ảnh.",
          "C": "Mô hình NeRF.",
          "D": "Video quỹ đạo."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, tại sao mô hình khuếch tán video lại tốt hơn mô hình khuếch tán ảnh trong việc tạo mô hình 3D?",
        "options": {
          "A": "Vì mô hình khuếch tán video có thể tạo ra hình ảnh chất lượng cao hơn.",
          "B": "Vì mô hình khuếch tán video yêu cầu ít dữ liệu huấn luyện hơn.",
          "C": "Vì mô hình khuếch tán video cần hiểu rõ hơn về các đối tượng 3D để tạo ra các góc nhìn khác nhau của cùng một đối tượng.",
          "D": "Vì mô hình khuếch tán video nhanh hơn mô hình khuếch tán ảnh."
        },
        "answer": "C"
      },
      {
        "question": "Ai là tác giả chính của phương pháp tạo lưới 3D từ ảnh đơn sử dụng mô hình khuếch tán video?",
        "options": {
          "A": "Nhóm nghiên cứu tại Google AI.",
          "B": "Vikram Voleti, Chun-Han Yao, Mark Boss, Varun Jampani và các đồng nghiệp tại Stability AI.",
          "C": "Các nhà nghiên cứu tại OpenAI.",
          "D": "Các kỹ sư tại Facebook AI Research."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả Chamfer distance mà phương pháp mới đạt được so với EscherNet là như thế nào?",
        "options": {
          "A": "Cao hơn đáng kể.",
          "B": "Tương đương.",
          "C": "Thấp hơn, cho thấy hiệu quả tốt hơn.",
          "D": "Không được so sánh trong bài viết."
        },
        "answer": "C"
      },
      {
        "question": "Bước nào được thực hiện trước quá trình suy luận (inference) trong phương pháp này?",
        "options": {
          "A": "Huấn luyện mô hình NeRF.",
          "B": "Cải thiện lưới 3D bằng DreamFusion.",
          "C": "Huấn luyện mô hình khuếch tán video để tạo video quỹ đạo.",
          "D": "Đánh giá bằng Chamfer distance."
        },
        "answer": "C"
      }
    ]
  },
  "a-formula-for-training-vision-transformers": {
    "title": "Cookbook for Vision Transformers",
    "collection": "ml-research",
    "content": "Vision Transformers (ViTs) are overtaking convolutional neural networks (CNN) in many vision tasks, but procedures for training them are still tailored for CNNs. New research investigated how various training ingredients affect ViT performance.\n\nWhat's new:Hugo Touvron and colleagues at Meta and Sorbonne University formulated a new recipe for training ViTs. They call their third-generation approachData Efficient Image Transformers(DeiT III).\n\nKey insight:The CNN and transformer architectures differ. For instance, when processing an image, a CNN works on one group of pixels at a time, while a transformer processes all pixels simultaneously. Moreover, while the computational cost of a CNN scales proportionally to input size, a transformer’s self-attention mechanism requires dramatically more processing as input size increases. Training recipes that take these differences — and other, less obvious ones — into account should impart better performance.\n\nHow it works:The authors pretrainedViTsto classify images in ImageNet using various combinations of training data, data augmentation, and regularization. (They also experimented with variables such as weight decay, dropout, and type of optimizer, for which they didn’t describe results in detail.) They fine-tuned and tested on ImageNet.\n\nResults:The authors’ approach substantially improved ViT performance. An 86 million-parameter ViT-B pretrained on ImageNet-21K and fine-tuned on ImageNet using the full recipe achieved 85.7 percent accuracy. Their cropping technique alone yielded 84.8 percent accuracy. In contrast, the same architecture trained on the same datasets using full-resolution examples augmented viaRandAugmentachieved 84.6 percent accuracy.\n\nWhy it matters:Deep learning is evolving at a breakneck pace, and familiar hyperparameter choices may no longer be the most productive. This work is an early step toward updating for the transformer era recipes that were developed when CNNs ruled computer vision.\n\nWe're thinking:The transformer architecture’s hunger for data makes it especially important to reconsider habits around data-related training procedures like augmentation and regularization.",
    "qa": [
      {
        "question": "Kiến trúc nào đang dần thay thế CNN trong nhiều tác vụ thị giác máy tính?",
        "options": {
          "A": "Recurrent Neural Networks (RNNs)",
          "B": "Convolutional Neural Networks (CNNs)",
          "C": "Vision Transformers (ViTs)",
          "D": "Generative Adversarial Networks (GANs)"
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp huấn luyện DeiT III được phát triển bởi ai?",
        "options": {
          "A": "Google Brain",
          "B": "Microsoft Research",
          "C": "Hugo Touvron và các đồng nghiệp tại Meta và Đại học Sorbonne",
          "D": "Geoffrey Hinton và các cộng sự"
        },
        "answer": "C"
      },
      {
        "question": "Sự khác biệt chính giữa CNN và Transformer trong xử lý ảnh là gì?",
        "options": {
          "A": "CNN xử lý toàn bộ ảnh cùng lúc, Transformer xử lý từng nhóm pixel.",
          "B": "CNN xử lý từng nhóm pixel, Transformer xử lý toàn bộ ảnh cùng lúc.",
          "C": "CNN sử dụng cơ chế self-attention, Transformer sử dụng convolution.",
          "D": "CNN có chi phí tính toán tăng nhanh hơn Transformer khi kích thước ảnh tăng."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì làm cho việc huấn luyện Transformer trở nên tốn kém hơn CNN khi kích thước ảnh tăng lên?",
        "options": {
          "A": "Sử dụng nhiều lớp convolution hơn.",
          "B": "Cơ chế self-attention.",
          "C": "Yêu cầu bộ nhớ lớn hơn để lưu trữ trọng số.",
          "D": "Sử dụng hàm kích hoạt phức tạp hơn."
        },
        "answer": "B"
      },
      {
        "question": "Các tác giả đã sử dụng dữ liệu nào để pretrain ViTs?",
        "options": {
          "A": "MNIST",
          "B": "CIFAR-10",
          "C": "ImageNet",
          "D": "COCO"
        },
        "answer": "C"
      },
      {
        "question": "Trong nghiên cứu này, các tác giả đã thử nghiệm những yếu tố nào trong quá trình pretraining?",
        "options": {
          "A": "Kiến trúc mạng và hàm mất mát.",
          "B": "Dữ liệu huấn luyện, tăng cường dữ liệu và điều chuẩn.",
          "C": "Tốc độ học và kích thước batch.",
          "D": "Số lượng lớp và số lượng neuron trên mỗi lớp."
        },
        "answer": "B"
      },
      {
        "question": "Độ chính xác cao nhất mà ViT-B (86 triệu tham số) đạt được sau khi fine-tune trên ImageNet là bao nhiêu?",
        "options": {
          "A": "84.6%",
          "B": "84.8%",
          "C": "85.0%",
          "D": "85.7%"
        },
        "answer": "D"
      },
      {
        "question": "Kỹ thuật cropping nào đã mang lại độ chính xác 84.8% cho ViT-B?",
        "options": {
          "A": "Sử dụng cropping ngẫu nhiên.",
          "B": "Sử dụng cropping trung tâm.",
          "C": "Kỹ thuật cropping của tác giả (được đề cập trong bài).",
          "D": "Không có kỹ thuật cropping nào được đề cập."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao việc xem xét lại các phương pháp huấn luyện liên quan đến dữ liệu lại quan trọng đối với Transformer?",
        "options": {
          "A": "Transformer ít nhạy cảm với dữ liệu hơn CNN.",
          "B": "Transformer cần ít dữ liệu hơn CNN.",
          "C": "Transformer 'đói' dữ liệu hơn CNN.",
          "D": "Transformer không cần tăng cường dữ liệu."
        },
        "answer": "C"
      },
      {
        "question": "Ý chính của bài viết là gì?",
        "options": {
          "A": "CNN đã lỗi thời và nên được thay thế hoàn toàn bằng Transformer.",
          "B": "Cần cập nhật các phương pháp huấn luyện đã được phát triển cho CNN để phù hợp với Transformer.",
          "C": "Transformer chỉ hiệu quả khi được huấn luyện trên một lượng lớn dữ liệu.",
          "D": "Việc tăng cường dữ liệu không quan trọng đối với Transformer."
        },
        "answer": "B"
      }
    ]
  },
  "a-language-model-that-collaborates-with-human-writers": {
    "title": "Collaborative Text Generator",
    "collection": "ml-research",
    "content": "Text from current language models can be useful as a rough draft, but that leaves the polishing to human writers. A language model learned how to generate and respond to editorial directions.What’s new:Timo Schick and colleagues at Meta proposedPlan, Edit, Explain, and Repeat(PEER), a text generator designed to collaborate with human writers.Key insight:Data that demonstrates the motivations, execution, and results of editing is hard to come by. Wikipedia, in which every article includes a history of edits as well as comments on them, comes close, but an editor trained solely on Wikipedia would be limited to encyclopedia-style text. However, a model trained on Wikipedia to undo revisions can synthesize a supplemental dataset of unrevised and revised examples. Applying the undo function to varied text can generate synthetic “unedited” drafts for training the editor.How it works:PEER comprises fourT5large language models: PEER-Edit (which executed revisions), PEER-Undo (which undid revisions), PEER-Explain (which explained revisions), and PEER-Document (which generated synthetic primary-source documents as a basis for revisions). The authors trained them onWikipedia, 6.9 million examples that include texts before and after a revision, a revision plan (a directive to revise the text, such as “add information about the scandal”), an explanation (a reason for the revision, which may duplicate the revision plan), and cited documents (primary sources on which the text is based).\n\nResults:The authors evaluated PEER-Edit usingSARI, a measure of similarity between two revised versions of a text relative to the unrevised original (higher is better). Comparing generated revisions to ground-truth revisions of Wikinews, the Wikipedia-trained PEER-Edit (175 billion-parameters) achieved 49.3 SARI, and the same architecture trained on the synthetic Wikinews dataset achieved 51.6 SARI. Both were more similar to the human revisions than was the unrevised text, which achieved 32.8 SARI. They also evaluated PEER-Edit on six tasks such as grammar correction and removal of biased words. Averaged across these tasks, a 175-billion parameter model achieved 44.3 SARI and a 3 billion-parameter version achieved 43.6 SARI. Prompted to perform the same tasks,InstructGPT(1.3 billion parameters) achieved 39.4 SARI, andTk-Instruct(3 billion parameters, fine-tuned to correct grammar and simplify text) achieved 23.5 SARI.Yes, but:Text generators can produce factually false statements. While PEER-Edit sometimes corrected misinformation, it also fabricated falsehoods, which it backed up by fabricating citations.Why it matters:Training text generators to provide explanations for their decisions and citations for the facts they use may lead to more interpretable models.We’re thinking:The raw output of generative models is fun and exciting, but imagine their potential as collaborators with creative people!",
    "qa": [
      {
        "question": "Mục đích chính của mô hình PEER là gì?",
        "options": {
          "A": "Tự động viết hoàn chỉnh các bài báo khoa học.",
          "B": "Hợp tác với người viết để cải thiện chất lượng văn bản.",
          "C": "Thay thế hoàn toàn vai trò của người viết trong quá trình sáng tạo.",
          "D": "Phát hiện và sửa lỗi chính tả trong văn bản."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc thu thập dữ liệu cho việc huấn luyện mô hình chỉnh sửa văn bản lại khó khăn?",
        "options": {
          "A": "Dữ liệu về các bản nháp thô rất hiếm.",
          "B": "Dữ liệu thể hiện động cơ, cách thực hiện và kết quả của việc chỉnh sửa rất khó tìm.",
          "C": "Các biên tập viên không muốn chia sẻ dữ liệu chỉnh sửa của họ.",
          "D": "Việc đánh giá chất lượng chỉnh sửa văn bản là một thách thức lớn."
        },
        "answer": "B"
      },
      {
        "question": "Wikipedia được sử dụng như thế nào trong quá trình huấn luyện mô hình PEER?",
        "options": {
          "A": "Làm nguồn dữ liệu duy nhất để huấn luyện mô hình.",
          "B": "Làm nguồn dữ liệu chính, sau đó được bổ sung bằng dữ liệu tổng hợp.",
          "C": "Chỉ được sử dụng để đánh giá hiệu suất của mô hình.",
          "D": "Để tạo ra các bản nháp thô ban đầu cho mô hình chỉnh sửa."
        },
        "answer": "B"
      },
      {
        "question": "PEER bao gồm mấy mô hình T5 lớn?",
        "options": {
          "A": "2",
          "B": "3",
          "C": "4",
          "D": "5"
        },
        "answer": "C"
      },
      {
        "question": "Chức năng chính của mô hình PEER-Undo là gì?",
        "options": {
          "A": "Thực hiện các chỉnh sửa văn bản.",
          "B": "Giải thích lý do cho các chỉnh sửa.",
          "C": "Hoàn tác các chỉnh sửa văn bản.",
          "D": "Tạo ra các tài liệu nguồn sơ cấp."
        },
        "answer": "C"
      },
      {
        "question": "Chỉ số SARI được sử dụng để đánh giá điều gì?",
        "options": {
          "A": "Độ chính xác của thông tin trong văn bản.",
          "B": "Mức độ tương đồng giữa hai phiên bản chỉnh sửa của một văn bản so với bản gốc.",
          "C": "Khả năng tạo ra văn bản mạch lạc và trôi chảy.",
          "D": "Mức độ sáng tạo của văn bản được tạo ra."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả SARI của PEER-Edit được huấn luyện trên dữ liệu Wikinews tổng hợp là bao nhiêu?",
        "options": {
          "A": "32.8",
          "B": "44.3",
          "C": "49.3",
          "D": "51.6"
        },
        "answer": "D"
      },
      {
        "question": "Một hạn chế được đề cập của mô hình PEER là gì?",
        "options": {
          "A": "Khả năng tạo ra văn bản quá dài dòng.",
          "B": "Khả năng tạo ra các tuyên bố sai sự thật và trích dẫn bịa đặt.",
          "C": "Khả năng chỉnh sửa văn bản quá chậm.",
          "D": "Khả năng chỉ hoạt động tốt với văn bản theo phong cách bách khoa toàn thư."
        },
        "answer": "B"
      },
      {
        "question": "Việc huấn luyện các mô hình tạo văn bản cung cấp giải thích và trích dẫn có thể dẫn đến điều gì?",
        "options": {
          "A": "Các mô hình nhanh hơn.",
          "B": "Các mô hình dễ diễn giải hơn.",
          "C": "Các mô hình chính xác hơn.",
          "D": "Các mô hình sáng tạo hơn."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, tiềm năng của các mô hình tạo sinh nằm ở đâu?",
        "options": {
          "A": "Thay thế hoàn toàn các công việc sáng tạo của con người.",
          "B": "Cộng tác với những người sáng tạo.",
          "C": "Tạo ra những nội dung giải trí đơn thuần.",
          "D": "Tự động hóa các tác vụ viết lặp đi lặp lại."
        },
        "answer": "B"
      }
    ]
  },
  "a-machine-learning-model-for-robots-to-predict-objects-location-in-households": {
    "title": "Robot, Find My Keys",
    "collection": "ml-research",
    "content": "Researchers proposed a way for robots to find objects in households where things get moved around.\n\nWhat's new:Andrey Kurenkov and colleagues at Stanford University introducedNode Edge Predictor, a model that learned to predict where objects were located in houses.\n\nKey insight:A popular way to represent objects and their locations is a graph, in which each node is either an object or its location and an edge connects the two. If we want to track objects over time, a recurrent model could predict the locations of objects using a separate graph for each time step, but that would require a prohibitive number of graphs. Instead, a model can predict locations using a single graph in which each edge is annotated, additionally, with the time elapsed since the associated object was seen in the associated location. The model learns to predict the next most likely place to find an object based on the object’s most recent, frequent, and longstanding locations.\n\nHow it works:The authors simulated a robot looking for things in a household. They built (i) a simulator of houses, object locations, and when and where they moved; (ii) a graph that represented a house containing objects; and (iii) a machine learning system that predicted where objects might be found.\n\nResults:The authors tested their system’s ability to find a single object in a house versus a few baseline methods. The baselines included random guessing, always guessing the piece of furniture where the object was last seen, and a Bayesian model that guessed whether the object was on/in a given piece of furniture based on the percentage of times it had been seen there. On average, their system found the object in 3.2 attempts, while the next best model (Bayesian) took 3.6 attempts. Guessing the last-seen location required 6.0 attempts, and random guessing required 8.8 attempts.\n\nWhy it matters:Feature engineering helps to find a good way to represent data so a model can learn from it. In this work, engineering time-related features (such as the time elapsed since an object was on a piece of furniture or the number of times an object was observed on a piece of furniture over time) enabled a non-recurrent model to learn how graphs change over time.\n\nWe’re thinking:A physical robot likely would use object detection on its camera feed instead of a simulator that told it directly which objects were associated with which pieces of furniture. We look forward to future work that proves the concept using this more realistic setup.",
    "qa": [
      {
        "question": "Mục tiêu chính của nghiên cứu được đề cập trong bài viết là gì?",
        "options": {
          "A": "Phát triển robot có khả năng dọn dẹp nhà cửa tự động.",
          "B": "Đề xuất phương pháp giúp robot tìm kiếm đồ vật trong môi trường nhà ở có sự thay đổi vị trí đồ vật.",
          "C": "Nghiên cứu về các thuật toán tối ưu hóa cho robot di chuyển trong không gian hẹp.",
          "D": "Xây dựng mô hình mô phỏng 3D cho các ngôi nhà để huấn luyện robot."
        },
        "answer": "B"
      },
      {
        "question": "Node Edge Predictor, mô hình được giới thiệu trong nghiên cứu, có đặc điểm gì nổi bật?",
        "options": {
          "A": "Sử dụng nhiều đồ thị riêng biệt cho mỗi bước thời gian để theo dõi vị trí đồ vật.",
          "B": "Dự đoán vị trí đồ vật dựa trên một đồ thị duy nhất, trong đó các cạnh được chú thích bằng thời gian.",
          "C": "Áp dụng thuật toán học tăng cường để robot tự học cách tìm kiếm đồ vật.",
          "D": "Sử dụng cảm biến hồng ngoại để xác định vị trí chính xác của các đồ vật."
        },
        "answer": "B"
      },
      {
        "question": "Trong mô hình đồ thị được sử dụng, các nút (nodes) đại diện cho điều gì?",
        "options": {
          "A": "Các phòng trong nhà và hành lang.",
          "B": "Đồ vật và vị trí của chúng.",
          "C": "Thời gian đồ vật được di chuyển và khoảng cách giữa các đồ vật.",
          "D": "Các loại đồ vật khác nhau và kích thước của chúng."
        },
        "answer": "B"
      },
      {
        "question": "Yếu tố 'thời gian' được tích hợp vào mô hình Node Edge Predictor như thế nào?",
        "options": {
          "A": "Bằng cách sử dụng một đồ thị riêng biệt cho mỗi khoảng thời gian cố định.",
          "B": "Bằng cách chú thích các cạnh của đồ thị bằng thời gian đã trôi qua kể từ khi đồ vật được nhìn thấy ở vị trí đó.",
          "C": "Bằng cách sử dụng đồng hồ thời gian thực để theo dõi vị trí đồ vật.",
          "D": "Bằng cách dự đoán thời gian cần thiết để di chuyển giữa các vị trí khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Trong quá trình thử nghiệm, hệ thống được so sánh với những phương pháp cơ bản nào?",
        "options": {
          "A": "Tìm kiếm ngẫu nhiên, tìm kiếm dựa trên vị trí cuối cùng nhìn thấy và mô hình Bayesian.",
          "B": "Tìm kiếm dựa trên màu sắc, hình dạng và kích thước của đồ vật.",
          "C": "Tìm kiếm bằng giọng nói và tìm kiếm bằng hình ảnh.",
          "D": "Tìm kiếm dựa trên tần suất sử dụng và tìm kiếm dựa trên giá trị của đồ vật."
        },
        "answer": "A"
      },
      {
        "question": "Kết quả thử nghiệm cho thấy hệ thống mới có ưu điểm gì so với các phương pháp cơ bản?",
        "options": {
          "A": "Tìm thấy đồ vật nhanh hơn và chính xác hơn.",
          "B": "Tiêu thụ ít năng lượng hơn trong quá trình tìm kiếm.",
          "C": "Có khả năng học hỏi và thích nghi với môi trường tốt hơn.",
          "D": "Yêu cầu ít dữ liệu huấn luyện hơn."
        },
        "answer": "A"
      },
      {
        "question": "Tại sao việc 'thiết kế đặc trưng' (feature engineering) lại quan trọng trong nghiên cứu này?",
        "options": {
          "A": "Giúp giảm thiểu chi phí tính toán của mô hình.",
          "B": "Giúp mô hình học hỏi từ dữ liệu một cách hiệu quả hơn.",
          "C": "Giúp robot di chuyển nhanh hơn trong môi trường phức tạp.",
          "D": "Giúp tăng cường độ chính xác của cảm biến."
        },
        "answer": "B"
      },
      {
        "question": "Trong nghiên cứu này, đặc trưng liên quan đến 'thời gian' được thiết kế như thế nào?",
        "options": {
          "A": "Thời gian đồ vật được sử dụng gần đây nhất.",
          "B": "Thời gian đã trôi qua kể từ khi đồ vật ở trên một món đồ nội thất và số lần đồ vật được quan sát trên món đồ nội thất đó.",
          "C": "Thời gian cần thiết để di chuyển đồ vật từ vị trí này sang vị trí khác.",
          "D": "Thời gian đồ vật được sản xuất và thời gian bảo hành của đồ vật."
        },
        "answer": "B"
      },
      {
        "question": "Hạn chế nào của nghiên cứu được tác giả đề cập đến trong phần 'We're thinking'?",
        "options": {
          "A": "Sử dụng mô hình quá phức tạp, gây khó khăn cho việc triển khai trên robot thực tế.",
          "B": "Sử dụng mô phỏng thay vì robot thực tế với khả năng nhận diện đồ vật bằng camera.",
          "C": "Chưa xem xét đến yếu tố ánh sáng và tiếng ồn trong môi trường thực tế.",
          "D": "Chưa đánh giá hiệu quả của hệ thống trong các ngôi nhà có diện tích lớn."
        },
        "answer": "B"
      },
      {
        "question": "Hướng phát triển tiềm năng nào được đề xuất cho nghiên cứu trong tương lai?",
        "options": {
          "A": "Tích hợp thêm các cảm biến khác như cảm biến nhiệt độ và độ ẩm.",
          "B": "Sử dụng robot thực tế với khả năng nhận diện đồ vật bằng camera để chứng minh tính khả thi của mô hình.",
          "C": "Phát triển mô hình có khả năng dự đoán nhu cầu sử dụng đồ vật của người dùng.",
          "D": "Tối ưu hóa thuật toán để giảm thiểu thời gian huấn luyện mô hình."
        },
        "answer": "B"
      }
    ]
  },
  "a-memory-method-that-reduces-hallucinations-in-llms": {
    "title": "Getting the Facts Right",
    "collection": "ml-research",
    "content": "Large language models that remember more hallucinate less.\n\nWhat’s new:Johnny Li and colleagues at Lamini introducedMixture of Memory Experts (MoME), a method that enables large language models (LLMs) to memorize many facts with relatively modest computational requirements. (Disclosure: Andrew Ng invested in Lamini.)\n\nKey insight:The key to getting factual answers from LLMs is to keep training it until it chooses the correct answer every time. In technical terms, train past the point where tokens relevant to the answer have a similar probability distribution, and continue until a single token has 100 percent probability. But this amount of training takes a lot of computation and, since the model may overfit the training set, it also may degrade performance on the test set. Fine-tuning is one solution, and fine-tuning a LoRA adapter to memorize facts reduces the computational burden. But a single LoRA adapter isn’t enough to store all of the knowledge in a large dataset. Training multiple adapters that are selected by cross-attention enables the LLM to memorize a variety of facts.\n\nHow it works:The authors extended a pretrainedLlama-3-8Bwith a large number (on the order of 1 million) of LoRA adapters and a cross-attention layer. They froze Llama-3-8B and trained the LoRA adapters to predict the next token in a custom dataset of over 1 million questions and answers.\n\nResults:The authorstestedtheir LoRA-enhanced model’s ability to answer questions about a database via SQL queries. The model, which was outfitted for retrieval-augmented generation (RAG), achieved 94.7 percent accuracy. An unnamed model with RAG achieved 50 percent accuracy.\n\nYes, but:It stands to reason that the authors’ approach saves processing, but it’s unclear how much. The authors didn’t mention the cost of fine-tuning Llama-3-8B in the usual way on their training dataset for the same number of epochs.\n\nWhy it matters:The authors argue that eliminating hallucinations is possible in typical training, it’s just computationally very expensive (not to mention the risk of overfitting). An architecture designed to store and retrieve facts, via LoRA adapters in this case, makes the process more feasible.\n\nWe’re thinking:While some researchers want large language models to memorize facts, others want them toavoid memorizing their training data. These aims address very different problems. Preventing LLMs from memorizing training data would make them less likely to regurgitate it verbatim and thus violate copyrights. On the other hand, this work memorizes facts so the model can deliver consistent, truthful responses that might be stated in a variety of ways.",
    "qa": [
      {
        "question": "Phương pháp Mixture of Memory Experts (MoME) được giới thiệu bởi ai?",
        "options": {
          "A": "Andrew Ng và cộng sự",
          "B": "Johnny Li và cộng sự",
          "C": "Nhóm nghiên cứu Llama-3",
          "D": "Một nhóm nghiên cứu ẩn danh"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, chìa khóa để LLM đưa ra câu trả lời chính xác là gì?",
        "options": {
          "A": "Sử dụng một LoRA adapter duy nhất với kích thước lớn.",
          "B": "Tiếp tục huấn luyện cho đến khi token liên quan đến câu trả lời có xác suất 100%.",
          "C": "Giảm số lượng epochs huấn luyện để tránh overfitting.",
          "D": "Sử dụng dữ liệu kiểm tra (test set) lớn hơn dữ liệu huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "LoRA adapters được chọn bởi cơ chế nào trong phương pháp MoME?",
        "options": {
          "A": "Cơ chế attention thông thường.",
          "B": "Cơ chế cross-attention.",
          "C": "Cơ chế self-attention.",
          "D": "Cơ chế ngẫu nhiên."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Llama-3-8B trong nghiên cứu này được sử dụng như thế nào?",
        "options": {
          "A": "Được huấn luyện lại từ đầu với bộ dữ liệu mới.",
          "B": "Được giữ nguyên và mở rộng với LoRA adapters và lớp cross-attention.",
          "C": "Được tinh chỉnh (fine-tuning) bằng phương pháp thông thường.",
          "D": "Được thay thế hoàn toàn bằng một mô hình nhỏ hơn."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình LoRA-enhanced trong bài viết đạt độ chính xác bao nhiêu khi trả lời câu hỏi về cơ sở dữ liệu thông qua truy vấn SQL?",
        "options": {
          "A": "50%",
          "B": "75%",
          "C": "90%",
          "D": "94.7%"
        },
        "answer": "D"
      },
      {
        "question": "Một hạn chế được đề cập trong bài viết về phương pháp MoME là gì?",
        "options": {
          "A": "Khó khăn trong việc triển khai trên phần cứng có cấu hình thấp.",
          "B": "Chưa rõ về chi phí tính toán so với việc tinh chỉnh Llama-3-8B theo cách thông thường.",
          "C": "Độ chính xác thấp hơn so với các phương pháp RAG khác.",
          "D": "Yêu cầu bộ dữ liệu huấn luyện quá lớn."
        },
        "answer": "B"
      },
      {
        "question": "Theo tác giả, việc loại bỏ ảo giác (hallucinations) trong quá trình huấn luyện thông thường có thể thực hiện được không?",
        "options": {
          "A": "Không thể, vì ảo giác là bản chất của LLM.",
          "B": "Có thể, nhưng đòi hỏi chi phí tính toán rất lớn và có nguy cơ overfitting.",
          "C": "Có thể, bằng cách sử dụng các kỹ thuật regularization.",
          "D": "Không thể, nếu không sử dụng LoRA adapters."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu của việc ngăn LLM ghi nhớ dữ liệu huấn luyện là gì?",
        "options": {
          "A": "Tăng cường khả năng suy luận của mô hình.",
          "B": "Giảm thiểu nguy cơ vi phạm bản quyền.",
          "C": "Cải thiện độ chính xác của mô hình.",
          "D": "Giảm chi phí tính toán."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu của việc LLM ghi nhớ các sự kiện (facts) là gì?",
        "options": {
          "A": "Tăng cường khả năng sáng tạo của mô hình.",
          "B": "Cung cấp các phản hồi nhất quán và trung thực.",
          "C": "Giảm kích thước của mô hình.",
          "D": "Tăng tốc độ huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Trong bối cảnh bài viết, RAG là viết tắt của cụm từ nào?",
        "options": {
          "A": "Reinforcement-Augmented Generation",
          "B": "Retrieval-Augmented Generation",
          "C": "Recursive-Attention Generation",
          "D": "Reasoning-Augmented Generation"
        },
        "answer": "B"
      }
    ]
  },
  "a-method-to-process-large-spreadsheets-for-accurate-question-answering": {
    "title": "Enabling LLMs to Read Spreadsheets",
    "collection": "ml-research",
    "content": "Large language models can process small spreadsheets, but very large spreadsheets often exceed their limits for input length. Researchers devised a method that processes large spreadsheets so LLMs can answer questions about them.\n\nWhat’s new:Yuzhang Tian, Jianbo Zhao, and colleagues at Microsoft proposedSheetCompressor, a way to represent spreadsheets that enables LLMs to identify and request the parts they need to answer specific questions.\n\nKey insight:Most spreadsheets can be broken down into a set of tables that may be bordered by visual dividers like thick lines or empty rows and/or columns. But detecting these tables isn’t trivial, since they may contain the same kinds of markers. (See the illustration above, in which tables are denoted by red dashes.) To answer many questions, you don’t need the whole spreadsheet, only the relevant table. Moreover, given a question, an LLM can recognize the table it needs to produce an answer. However, to identify the correct table, it needs to see the whole spreadsheet, which may be too large for its input context window, and the tables, which may not be clearly separated, need to be parsed. The solution is to compress the spreadsheet, feed the compressed representation to the LLM along with the question, and ask the LLM to identify the boundaries of the table it needs to answer the question. Then, given an uncompressed version of that table, the LLM can produce an answer.\n\nHow it works:The authors built software that prepared spreadsheets by (i) parsing them into tables and (ii) compressing them while maintaining the table structure. Then they fine-tuned LLMs to detect tables in the compressed spreadsheets and prompted the fine-tuned LLMs to identify the tables relevant to a given question.\n\nResults:The authors compared the fine-tuned LLMs’ ability to detect tables in spreadsheets that were compressed using their method and in their original uncompressed form. They fed the models spreadsheets of various sizes that ranged from small (up to 4,000 tokens) to huge (more than 32,000 tokens). They gauged the models’ performance according to F1 score (higher is better).\n\nWhy it matters:By giving LLMs the ability to detect a spreadsheet’s functional components, this approach enables them to process a wide variety of spreadsheets regardless of their size and complexity.\n\nWe’re thinking:When considering the strengths of LLMs, we no longer have to take spreadsheets off the table.",
    "qa": [
      {
        "question": "Vấn đề chính mà các nhà nghiên cứu muốn giải quyết là gì?",
        "options": {
          "A": "Làm thế nào để LLM có thể tạo ra bảng tính.",
          "B": "Làm thế nào để LLM có thể xử lý các bảng tính lớn vượt quá giới hạn đầu vào của chúng.",
          "C": "Làm thế nào để LLM có thể chỉnh sửa bảng tính một cách hiệu quả.",
          "D": "Làm thế nào để LLM có thể chuyển đổi bảng tính sang các định dạng khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "SheetCompressor hoạt động bằng cách nào?",
        "options": {
          "A": "Chia nhỏ bảng tính thành các ô nhỏ hơn và xử lý từng ô một.",
          "B": "Đại diện bảng tính theo cách cho phép LLM xác định và yêu cầu các phần cần thiết để trả lời các câu hỏi cụ thể.",
          "C": "Sử dụng một thuật toán nén mạnh mẽ để giảm kích thước tệp của bảng tính.",
          "D": "Chuyển đổi bảng tính thành một định dạng văn bản đơn giản để LLM dễ dàng xử lý hơn."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì khiến việc phát hiện các bảng trong bảng tính trở nên khó khăn?",
        "options": {
          "A": "Các bảng luôn được phân tách rõ ràng bằng các đường kẻ đậm.",
          "B": "Các bảng có thể chứa các dấu hiệu tương tự như các dấu phân tách bảng.",
          "C": "Các bảng thường được mã hóa bằng các ký tự đặc biệt.",
          "D": "Các bảng thường bị ẩn trong bảng tính."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc nén bảng tính lại cần thiết trong phương pháp này?",
        "options": {
          "A": "Để giảm dung lượng lưu trữ cần thiết cho bảng tính.",
          "B": "Để tăng tốc độ xử lý của LLM.",
          "C": "Để đưa bảng tính vào cửa sổ ngữ cảnh đầu vào của LLM.",
          "D": "Để cải thiện độ chính xác của LLM."
        },
        "answer": "C"
      },
      {
        "question": "Sau khi nén bảng tính, bước tiếp theo là gì?",
        "options": {
          "A": "Gửi trực tiếp bảng tính nén cho LLM để trả lời câu hỏi.",
          "B": "Yêu cầu LLM xác định ranh giới của bảng cần thiết để trả lời câu hỏi.",
          "C": "Giải nén bảng tính và gửi toàn bộ bảng tính cho LLM.",
          "D": "Chuyển đổi bảng tính nén sang định dạng khác."
        },
        "answer": "B"
      },
      {
        "question": "Các tác giả đã làm gì để cải thiện khả năng của LLM trong việc phát hiện bảng?",
        "options": {
          "A": "Họ đã sử dụng một LLM lớn hơn.",
          "B": "Họ đã tinh chỉnh LLM để phát hiện bảng trong bảng tính nén.",
          "C": "Họ đã sử dụng một thuật toán phát hiện bảng phức tạp hơn.",
          "D": "Họ đã loại bỏ tất cả các dấu phân tách bảng khỏi bảng tính."
        },
        "answer": "B"
      },
      {
        "question": "Chỉ số F1 được sử dụng để đánh giá điều gì trong nghiên cứu này?",
        "options": {
          "A": "Tốc độ xử lý của LLM.",
          "B": "Khả năng của LLM trong việc tạo ra bảng tính.",
          "C": "Khả năng của LLM trong việc phát hiện bảng trong bảng tính.",
          "D": "Độ chính xác của LLM trong việc trả lời câu hỏi về bảng tính."
        },
        "answer": "C"
      },
      {
        "question": "Kết quả nghiên cứu cho thấy điều gì về khả năng xử lý bảng tính của LLM?",
        "options": {
          "A": "LLM chỉ có thể xử lý bảng tính nhỏ.",
          "B": "LLM có thể xử lý bảng tính có kích thước và độ phức tạp khác nhau nhờ phương pháp này.",
          "C": "LLM không thể xử lý bảng tính hiệu quả.",
          "D": "LLM chỉ có thể xử lý bảng tính ở định dạng cụ thể."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, đâu là một trong những lợi ích chính của phương pháp này?",
        "options": {
          "A": "Giảm chi phí lưu trữ bảng tính.",
          "B": "Cho phép LLM xử lý nhiều loại bảng tính khác nhau bất kể kích thước và độ phức tạp của chúng.",
          "C": "Tăng cường bảo mật cho bảng tính.",
          "D": "Cho phép người dùng dễ dàng chỉnh sửa bảng tính."
        },
        "answer": "B"
      },
      {
        "question": "Câu \"When considering the strengths of LLMs, we no longer have to take spreadsheets off the table.\" có nghĩa là gì?",
        "options": {
          "A": "LLM không thể xử lý bảng tính.",
          "B": "Bảng tính không còn là một hạn chế khi sử dụng LLM.",
          "C": "LLM có thể tạo ra bảng tính một cách dễ dàng.",
          "D": "Bảng tính là một công cụ quan trọng để đào tạo LLM."
        },
        "answer": "B"
      }
    ]
  },
  "a-new-class-of-diffusion-models-based-on-the-transformer-architecture": {
    "title": "Diffusion Transformed",
    "collection": "ml-research",
    "content": "A tweak to diffusion models, which are responsible for most of the recent excitement about AI-generated images, enables them to produce more realistic output.\n\nWhat's new:William Peebles at UC Berkeley and Saining Xie at New York University improved a diffusion model by replacing a key component, a U-Net convolutional neural network, with a transformer. They call the workDiffusion Transformer (DiT).\n\nDiffusion basics:During training, adiffusion modeltakes an image to which noise has been added, a descriptive embedding (typically an embedding of a text phrase that describes the original image, in this experiment, the image’s class), and an embedding of the current time step. The system learns to use the descriptive embedding to remove the noise in successive time steps. At inference, it generates an image by starting with pure noise and a descriptive embedding and removing noise iteratively according to that embedding. A variant known as alatent diffusion modelsaves computation by removing noise not from an image but from an image embedding that represents it.\n\nKey insight:In a typical diffusion model, aU-Netconvolutional neural network (CNN) learns to estimate the noise to be removed from an image.Recentworkshowed that transformers outperform CNNs in many computer vision tasks. Replacing the CNN with a transformer can lead to similar gains.\n\nHow it works:The authors modified a latent diffusion model (specificallyStable Diffusion) by putting a transformer at its core. They trained it onImageNetin the usual manner for diffusion models.\n\nResults:The authors assessed the quality of DiT’s output according toFréchet Inception Distance(FID), which measures how the distribution of a generated version of an image compares to the distribution of the original (lower is better). FID improved depending on the processing budget: On 256-by-256-pixel ImageNet images, a small DiT with 6 gigaflops of compute achieved 68.4 FID, a large DiT with 80.7 gigaflops achieved 23.3 FID, and the largest DiT with 119 gigaflops achieved 9.62 FID. Alatent diffusion model that used a U-Net(104 gigaflops) achieved 10.56 FID.\n\nWhy it matters:Given more processing power and data, transformers achieve better performance than other architectures in numerous tasks. This goes for the authors’ transformer-enhanced diffusion model as well.\n\nWe're thinking:Transformers continue to replace CNNs for many tasks. We’ll see if this replacement sticks.",
    "qa": [
      {
        "question": "Mục đích chính của việc điều chỉnh mô hình khuếch tán (diffusion model) được đề cập trong bài viết là gì?",
        "options": {
          "A": "Giảm thiểu lượng dữ liệu cần thiết để huấn luyện mô hình.",
          "B": "Tạo ra hình ảnh chân thực hơn.",
          "C": "Tăng tốc độ xử lý hình ảnh.",
          "D": "Đơn giản hóa cấu trúc của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "William Peebles và Saining Xie đã cải tiến mô hình khuếch tán bằng cách nào?",
        "options": {
          "A": "Sử dụng một thuật toán mã hóa mới.",
          "B": "Thay thế mạng nơ-ron tích chập U-Net bằng một transformer.",
          "C": "Tăng số lượng lớp trong mạng nơ-ron.",
          "D": "Sử dụng một tập dữ liệu huấn luyện lớn hơn."
        },
        "answer": "B"
      },
      {
        "question": "Trong quá trình huấn luyện, mô hình khuếch tán (diffusion model) học cách làm gì?",
        "options": {
          "A": "Tạo ra nhiễu ngẫu nhiên từ hình ảnh gốc.",
          "B": "Sử dụng embedding mô tả để loại bỏ nhiễu theo từng bước thời gian.",
          "C": "Phân loại hình ảnh dựa trên nội dung của nó.",
          "D": "Nén hình ảnh thành một định dạng nhỏ hơn."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình khuếch tán tiềm ẩn (latent diffusion model) tiết kiệm tính toán bằng cách nào?",
        "options": {
          "A": "Loại bỏ nhiễu trực tiếp từ hình ảnh gốc.",
          "B": "Loại bỏ nhiễu từ một embedding hình ảnh đại diện cho hình ảnh gốc.",
          "C": "Sử dụng một mạng nơ-ron nhỏ hơn để xử lý hình ảnh.",
          "D": "Chia nhỏ hình ảnh thành các phần nhỏ hơn để xử lý song song."
        },
        "answer": "B"
      },
      {
        "question": "Trong một mô hình khuếch tán điển hình, thành phần nào chịu trách nhiệm ước tính nhiễu cần loại bỏ khỏi hình ảnh?",
        "options": {
          "A": "Transformer.",
          "B": "Mạng nơ-ron tích chập U-Net (U-Net CNN).",
          "C": "Embedding mô tả.",
          "D": "Bộ mã hóa (encoder)."
        },
        "answer": "B"
      },
      {
        "question": "DiT (Diffusion Transformer) được huấn luyện trên tập dữ liệu nào?",
        "options": {
          "A": "MNIST.",
          "B": "CIFAR-10.",
          "C": "ImageNet.",
          "D": "COCO."
        },
        "answer": "C"
      },
      {
        "question": "FID (Fréchet Inception Distance) được sử dụng để làm gì trong bài viết này?",
        "options": {
          "A": "Đo lường tốc độ xử lý hình ảnh của mô hình.",
          "B": "Đo lường mức độ sử dụng bộ nhớ của mô hình.",
          "C": "Đo lường chất lượng của hình ảnh được tạo ra so với hình ảnh gốc.",
          "D": "Đo lường độ chính xác của mô hình trong việc phân loại hình ảnh."
        },
        "answer": "C"
      },
      {
        "question": "Theo kết quả được trình bày, điều gì xảy ra với giá trị FID khi tăng ngân sách tính toán (processing budget) cho DiT?",
        "options": {
          "A": "FID tăng lên.",
          "B": "FID giảm xuống.",
          "C": "FID không thay đổi.",
          "D": "FID dao động ngẫu nhiên."
        },
        "answer": "B"
      },
      {
        "question": "So với mô hình khuếch tán tiềm ẩn sử dụng U-Net, DiT (Diffusion Transformer) có ưu điểm gì khi có cùng ngân sách tính toán?",
        "options": {
          "A": "DiT có FID cao hơn.",
          "B": "DiT có FID thấp hơn.",
          "C": "DiT yêu cầu ít dữ liệu huấn luyện hơn.",
          "D": "DiT dễ dàng triển khai hơn."
        },
        "answer": "B"
      },
      {
        "question": "Nhận định nào sau đây được đưa ra về xu hướng thay thế CNN bằng Transformer?",
        "options": {
          "A": "Transformer chỉ hiệu quả hơn CNN trong một số ít tác vụ.",
          "B": "Transformer đang dần thay thế CNN trong nhiều tác vụ.",
          "C": "CNN vẫn là lựa chọn tốt nhất cho hầu hết các tác vụ xử lý ảnh.",
          "D": "Việc thay thế CNN bằng Transformer không mang lại nhiều lợi ích đáng kể."
        },
        "answer": "B"
      }
    ]
  },
  "a-method-to-reduce-memory-needs-when-fine-tuning-ai-models": {
    "title": "Memory-Efficient Optimizer",
    "collection": "ml-research",
    "content": "Researchers devised a way to reduce memory requirements when fine-tuning large language models.\n\nWhat's new:Kai Lv and colleagues at Fudan University proposedlow memory optimization(LOMO), a modification of stochastic gradient descent that stores less data than other optimizers during fine-tuning.\n\nKey insight:Optimizers require a lot of memory to store an entire network’s worth of parameters, gradients, activations, and optimizer states. While Adam has overtaken stochastic gradient descent (SGD) for training, SGD remains a popular choice for fine-tuning partly because it requires less memory (since it stores fewer optimizer states). Nonetheless, SGD must store an entire network’s gradients — which, with state-of-the-art models, can amount to tens or hundreds of gigabytes — before it updates the network all at once. Updating the network layer by layer requires storing only one layer’s gradients — a more memory-efficient twist on typical SGD.\n\nHow it works:The authors fine-tunedLLaMAon six datasets inSuperGLUE, a benchmark for language understanding and reasoning that includes tasks such as answering multiple-choice questions.\n\nResults:LOMO required less memory than popular optimizers and achieved better performance than the popular memory-efficient fine-tuning technique LoRA.\n\nWhy it matters:Methods like LoRA save memory by fine-tuning a small number of parameters relative to a network’s total parameter count. However, because it adjusts only a small number of parameters, the performance gain from fine-tuning is less than it could be. LOMO fine-tunes all parameters, maximizing performance gain while reducing memory requirements.\n\nWe're thinking:SGD’s hunger for memory is surprising. Many developers will find it helpful to have a memory-efficient alternative.",
    "qa": [
      {
        "question": "Phương pháp LOMO được đề xuất bởi ai?",
        "options": {
          "A": "Các nhà nghiên cứu tại Google AI",
          "B": "Kai Lv và các đồng nghiệp tại Đại học Fudan",
          "C": "Nhóm phát triển mô hình LLaMA",
          "D": "Các tác giả của bộ dữ liệu SuperGLUE"
        },
        "answer": "B"
      },
      {
        "question": "LOMO là một cải tiến của thuật toán nào?",
        "options": {
          "A": "Adam",
          "B": "Stochastic Gradient Descent (SGD)",
          "C": "LoRA",
          "D": "Backpropagation"
        },
        "answer": "B"
      },
      {
        "question": "Tại sao SGD vẫn được ưa chuộng trong fine-tuning mặc dù Adam thường được sử dụng để training?",
        "options": {
          "A": "SGD có tốc độ hội tụ nhanh hơn Adam.",
          "B": "SGD yêu cầu ít bộ nhớ hơn Adam.",
          "C": "SGD dễ dàng song song hóa hơn Adam.",
          "D": "SGD có khả năng tránh overfitting tốt hơn Adam."
        },
        "answer": "B"
      },
      {
        "question": "Nhược điểm chính của SGD truyền thống khi fine-tuning các mô hình lớn là gì?",
        "options": {
          "A": "SGD không thể xử lý dữ liệu có kích thước lớn.",
          "B": "SGD yêu cầu lưu trữ toàn bộ gradient của mạng, tốn nhiều bộ nhớ.",
          "C": "SGD dễ bị mắc kẹt trong các cực tiểu cục bộ.",
          "D": "SGD có độ chính xác thấp hơn so với các thuật toán khác."
        },
        "answer": "B"
      },
      {
        "question": "LOMO giảm yêu cầu bộ nhớ bằng cách nào?",
        "options": {
          "A": "Bằng cách giảm kích thước của mô hình.",
          "B": "Bằng cách cập nhật mạng theo từng lớp.",
          "C": "Bằng cách sử dụng kỹ thuật nén dữ liệu.",
          "D": "Bằng cách sử dụng phần cứng chuyên dụng."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào đã được sử dụng để đánh giá hiệu quả của LOMO trong bài viết?",
        "options": {
          "A": "BERT",
          "B": "GPT-3",
          "C": "LLaMA",
          "D": "ResNet"
        },
        "answer": "C"
      },
      {
        "question": "LOMO được đánh giá trên bộ dữ liệu nào?",
        "options": {
          "A": "ImageNet",
          "B": "SuperGLUE",
          "C": "SQuAD",
          "D": "MNIST"
        },
        "answer": "B"
      },
      {
        "question": "So với LoRA, LOMO có ưu điểm gì?",
        "options": {
          "A": "LOMO yêu cầu ít tham số hơn LoRA.",
          "B": "LOMO đạt được hiệu suất tốt hơn LoRA.",
          "C": "LOMO dễ dàng triển khai hơn LoRA.",
          "D": "LOMO có tốc độ fine-tuning nhanh hơn LoRA."
        },
        "answer": "B"
      },
      {
        "question": "LoRA tiết kiệm bộ nhớ bằng cách nào?",
        "options": {
          "A": "Bằng cách giảm kích thước của dữ liệu đầu vào.",
          "B": "Bằng cách chỉ fine-tuning một số lượng nhỏ tham số.",
          "C": "Bằng cách sử dụng các kỹ thuật lượng tử hóa.",
          "D": "Bằng cách sử dụng các kỹ thuật pruning."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính giữa LOMO và LoRA là gì?",
        "options": {
          "A": "LOMO sử dụng kiến trúc mạng khác với LoRA.",
          "B": "LOMO fine-tunes tất cả các tham số, trong khi LoRA chỉ fine-tunes một số lượng nhỏ.",
          "C": "LOMO sử dụng một hàm mất mát khác với LoRA.",
          "D": "LOMO yêu cầu phần cứng mạnh hơn LoRA."
        },
        "answer": "B"
      }
    ]
  },
  "a-new-method-rapidly-trains-robots-in-the-real-world": {
    "title": "Real-World Training on the Double",
    "collection": "ml-research",
    "content": "Roboticists often train their machines in simulation, where the controller model can learn from millions of hours of experience. A new method trained robots in the real world in 20 minutes.\n\nWhat's new:Laura Smith, Ilya Kostrikov, and Sergey Levine at UC Berkeley introduced a process torapidly train a quadruped robot to walkin a variety of real-world terrains and settings.\n\nKey insight:One way to train a model on less data is to train it repeatedly on the same examples (in this case, ​​the robot's orientation, velocity, and joint angles at specific points in time). However, this may lead the model to overfit (for instance, the robot may learn to walk effectively only on the terrain used in training). Regularization or normalization enables a model to train multiple times on the same examples without overfitting.\n\nHow it works:The authors trained a motion-planning model to move aUnitree A1robot forward on a given terrain using anactor-criticalgorithm, a reinforcement-learning method in which an actor function learns to take actions that maximize the total return (roughly the sum of all rewards) estimated by a critic function. The actor was a vanilla neural network and the critic was an ensemble of such networks.\n\nResults:The authors trained the model to walk the robot on each of five surfaces (starting from scratch for each surface): flat ground, mulch, lawn, a hiking trail, and a memory foam mattress. The robot learned to walk on each in about 20 minutes, which is roughly equivalent to 20,000 examples. Competing methods use either simulation or more time in the real world. For example, the authors ofDayDreamer: World Models for Physical Robot Learningtrained the same type of robot to walk on an indoor surface without a simulation, but it took one hour and 3.6 times more examples.\n\nWhy it matters:Training on simple features (those with a small number of dimensions, such as robot orientation and velocity) rather than complex features (such as images) reduces the number of examples required to learn a task, and regularizing the model prevents overfitting. This is a simple, general setup to train reinforcement learning models in the real world.\n\nWe're thinking:Reinforcement learning algorithms are famously data-hungry, which is why much of the progress in the past decade was made in simulated environments. A recipe for training a quadruped rapidly in the real world is a great step forward!",
    "qa": [
      {
        "question": "Phương pháp mới được giới thiệu trong bài viết đã huấn luyện robot trong môi trường nào?",
        "options": {
          "A": "Môi trường mô phỏng với hàng triệu giờ kinh nghiệm.",
          "B": "Môi trường thực tế trong khoảng 20 phút.",
          "C": "Kết hợp cả môi trường mô phỏng và thực tế.",
          "D": "Môi trường ảo được tạo ra bởi trí tuệ nhân tạo."
        },
        "answer": "B"
      },
      {
        "question": "Ai là những người đã giới thiệu phương pháp huấn luyện robot đi trên nhiều địa hình khác nhau một cách nhanh chóng?",
        "options": {
          "A": "Google DeepMind.",
          "B": "Laura Smith, Ilya Kostrikov và Sergey Levine tại UC Berkeley.",
          "C": "Các nhà nghiên cứu tại Stanford University.",
          "D": "Một nhóm các nhà khoa học ẩn danh."
        },
        "answer": "B"
      },
      {
        "question": "Một trong những insight quan trọng của phương pháp này là gì?",
        "options": {
          "A": "Sử dụng dữ liệu phức tạp để huấn luyện mô hình.",
          "B": "Huấn luyện mô hình lặp đi lặp lại trên cùng một ví dụ kết hợp với regularization.",
          "C": "Tăng số lượng dữ liệu huấn luyện lên mức tối đa.",
          "D": "Sử dụng các thuật toán học tăng cường phức tạp nhất."
        },
        "answer": "B"
      },
      {
        "question": "Thuật toán học tăng cường nào được sử dụng để huấn luyện robot Unitree A1?",
        "options": {
          "A": "Thuật toán Q-learning.",
          "B": "Thuật toán Actor-Critic.",
          "C": "Thuật toán Deep Q-Network (DQN).",
          "D": "Thuật toán Monte Carlo Tree Search (MCTS)."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình 'actor' trong thuật toán Actor-Critic có vai trò gì?",
        "options": {
          "A": "Ước tính tổng phần thưởng.",
          "B": "Đưa ra các hành động để tối đa hóa tổng phần thưởng.",
          "C": "Đánh giá hiệu suất của robot.",
          "D": "Lập kế hoạch đường đi cho robot."
        },
        "answer": "B"
      },
      {
        "question": "Robot đã học cách đi trên bao nhiêu loại bề mặt khác nhau trong quá trình huấn luyện?",
        "options": {
          "A": "3",
          "B": "4",
          "C": "5",
          "D": "6"
        },
        "answer": "C"
      },
      {
        "question": "Thời gian huấn luyện robot đi trên mỗi bề mặt là khoảng bao lâu?",
        "options": {
          "A": "10 phút.",
          "B": "20 phút.",
          "C": "30 phút.",
          "D": "1 giờ."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp 'DayDreamer' mất bao lâu để huấn luyện robot tương tự đi trên một bề mặt trong nhà?",
        "options": {
          "A": "20 phút.",
          "B": "30 phút.",
          "C": "1 giờ.",
          "D": "2 giờ."
        },
        "answer": "C"
      },
      {
        "question": "Việc sử dụng các đặc trưng đơn giản (ví dụ: hướng và vận tốc của robot) thay vì các đặc trưng phức tạp (ví dụ: hình ảnh) có lợi ích gì?",
        "options": {
          "A": "Tăng độ chính xác của mô hình.",
          "B": "Giảm số lượng ví dụ cần thiết để học một nhiệm vụ.",
          "C": "Tăng tốc độ xử lý của robot.",
          "D": "Giảm chi phí huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao phần lớn tiến bộ trong học tăng cường trong thập kỷ qua lại được thực hiện trong môi trường mô phỏng?",
        "options": {
          "A": "Môi trường mô phỏng dễ kiểm soát hơn.",
          "B": "Thuật toán học tăng cường cần rất nhiều dữ liệu.",
          "C": "Chi phí huấn luyện trong môi trường thực tế quá cao.",
          "D": "Tất cả các đáp án trên."
        },
        "answer": "D"
      }
    ]
  },
  "a-new-stanford-index-to-assess-the-transparency-of-leading-ai-models": {
    "title": "What We Know — and Don’t Know — About Foundation Models",
    "collection": "ml-research",
    "content": "A new index ranks popular AI models in terms of information their developers provide about their training, architecture, and usage. Few score well.\n\nWhat’s new:The Stanford Center for Research on Foundation Modelspublishedits debut Foundation Model Transparency Index, scoring 10 popular models on how well their makers disclosed details of their training, characteristics, and use.\n\nHow it works:Rishi Bommasani, Kevin Klyman, and colleagues at Stanford, MIT, and Princetonexamined10 foundation models — that is, models that can be pretrained for general purposes and fine-tuned for specific tasks — from 10 companies. They scored each model by asking 100 yes-or-no questions that covered training, model architecture and behavior, and policies regarding access and usage.\n\nResults:The index assigned each model a score between 1 and 100. Meta’s Llama 2 ranked most transparent with a score of 54. BigScience’s BLOOM-Z came in just behind with a score of 53. At the bottom of the list were Inflection’s Inflection-1, which scored 21, and Amazon’s Titan Text, which scored 12.\n\nYes, but:Because the index is limited to yes/no questions, it doesn’t allow for partial credit. In addition, the questions are weighted equally, so lack of transparency in an important area (say, access to training data) costs only one point in a model’s overall score. It’s easy to imagine companies gaming the scores rather than addressing the most meaningful deficits.\n\nBehind the news:Researchers at MIT, Cohere For AI, and 11 other organizations recently launched the Data Provenance Platform, a project that audits and categorizes training datasets. The effort offers aData Provenance Explorerfor evaluating sources, licenses, creators, and other metadata with respect to roughly 1,800 text datasets.\n\nWhy it matters:AI has a transparency problem, and the rise of models that serve as foundations for other models exacerbates the issue. Without disclosure of fundamental factors like architectures, datasets, and training methods, it’s impossible to replicate research, evaluate cost per performance, and address biases. Without disclosure of applications based on a given foundation model, it’s impossible to weigh those applications’ capabilities and limitations. A consistent set of criteria for evaluating transparency may encourage greater disclosure.We’re thinking:The rise of open source AI has been accompanied by an opposite rise in commercial concerns that have little incentive to reveal the inner workings of their models. An index encourages everyone to provide detailed information about the systems they build, and we hope it will help engineers who care about transparency to persuade their teammates. We look forward to refinements and expansion to cover models that aren’t included among the initial 10.",
    "qa": [
      {
        "question": "Mục đích chính của Foundation Model Transparency Index là gì?",
        "options": {
          "A": "Đánh giá hiệu suất của các mô hình AI phổ biến.",
          "B": "Xếp hạng các mô hình AI dựa trên mức độ minh bạch thông tin.",
          "C": "So sánh chi phí đào tạo giữa các mô hình AI khác nhau.",
          "D": "Xác định các mô hình AI phù hợp nhất cho các tác vụ cụ thể."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, mô hình nào đạt điểm cao nhất trong Foundation Model Transparency Index?",
        "options": {
          "A": "Inflection-1",
          "B": "Llama 2",
          "C": "BLOOM-Z",
          "D": "Titan Text"
        },
        "answer": "B"
      },
      {
        "question": "Điểm số thấp nhất trong Foundation Model Transparency Index thuộc về mô hình nào?",
        "options": {
          "A": "Llama 2",
          "B": "BLOOM-Z",
          "C": "Inflection-1",
          "D": "Titan Text"
        },
        "answer": "D"
      },
      {
        "question": "Phương pháp đánh giá của Foundation Model Transparency Index chủ yếu dựa trên loại câu hỏi nào?",
        "options": {
          "A": "Câu hỏi mở",
          "B": "Câu hỏi trắc nghiệm nhiều lựa chọn",
          "C": "Câu hỏi đúng/sai",
          "D": "Câu hỏi tự luận"
        },
        "answer": "C"
      },
      {
        "question": "Một trong những hạn chế của Foundation Model Transparency Index được đề cập trong bài viết là gì?",
        "options": {
          "A": "Chỉ đánh giá các mô hình mã nguồn mở.",
          "B": "Không cho phép tính điểm một phần.",
          "C": "Chỉ tập trung vào hiệu suất của mô hình.",
          "D": "Yêu cầu thông tin chi tiết về dữ liệu cá nhân."
        },
        "answer": "B"
      },
      {
        "question": "Data Provenance Platform tập trung vào việc gì?",
        "options": {
          "A": "Đánh giá hiệu suất của các mô hình AI.",
          "B": "Kiểm toán và phân loại các bộ dữ liệu huấn luyện.",
          "C": "Phát triển các mô hình AI mới.",
          "D": "Cung cấp tài nguyên tính toán cho việc huấn luyện AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, việc thiếu minh bạch trong AI gây ra vấn đề gì?",
        "options": {
          "A": "Làm chậm quá trình phát triển AI.",
          "B": "Gây khó khăn cho việc nhân rộng nghiên cứu và đánh giá chi phí.",
          "C": "Tăng chi phí đào tạo mô hình.",
          "D": "Giảm độ chính xác của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì có thể khuyến khích các công ty cung cấp thông tin chi tiết hơn về các hệ thống AI của họ?",
        "options": {
          "A": "Yêu cầu pháp lý bắt buộc.",
          "B": "Một bộ tiêu chí nhất quán để đánh giá tính minh bạch.",
          "C": "Sự cạnh tranh về hiệu suất mô hình.",
          "D": "Sự gia tăng của các mô hình mã nguồn đóng."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì đang diễn ra song song với sự phát triển của AI mã nguồn mở?",
        "options": {
          "A": "Sự gia tăng các quy định về AI.",
          "B": "Sự gia tăng các lo ngại về thương mại khiến các công ty ít muốn tiết lộ thông tin.",
          "C": "Sự giảm chi phí đào tạo mô hình.",
          "D": "Sự hợp tác quốc tế trong lĩnh vực AI."
        },
        "answer": "B"
      },
      {
        "question": "Data Provenance Explorer cung cấp thông tin về cái gì liên quan đến các bộ dữ liệu?",
        "options": {
          "A": "Hiệu suất của mô hình được huấn luyện trên dữ liệu đó.",
          "B": "Nguồn gốc, giấy phép, người tạo và siêu dữ liệu khác.",
          "C": "Chi phí để thu thập và xử lý dữ liệu.",
          "D": "Các thuật toán được sử dụng để tạo ra dữ liệu."
        },
        "answer": "B"
      }
    ]
  },
  "a-privacy-threat-revealed": {
    "title": "A Privacy Threat Revealed",
    "collection": "ml-research",
    "content": "With access to a trained model, an attacker can use areconstruction attackto approximate its training data, including examples that impinge on privacy, such as medical images. A method calledInstaHiderecently wonacclaimfor promising to make such examples unrecognizable to human eyes while retaining their utility for training. Researchers cracked it in short order.What’s new:InstaHide aims to scramble images in a way that can’t be reversed. Nicholas Carlini and researchers at Berkeley, Columbia, Google, Princeton, Stanford, University of Virginia, and University of WisconsindefeatedInstaHide to recover images that look a lot like the originals.Key insight:InstaHide can be viewed as a linear equation that scrambles images by summing them (typically two sensitive and four public images chosen at random) using random weights, then randomly flipping the sign of each pixel value. But summing is reversible, and changing signs doesn’t effectively obscure values. Consequently, a linear equation can be devised to reverse this process.How it works:The authors applied InstaHide to produce targets.CIFAR-10, CIFAR-100, andSTL-10stood in for sensitive datasets.ImageNetserved as their non-sensitive dataset. Then they undid the effects of the InstaHide algorithm in reverse order.\n\nResults:The authors tested their approach using the CIFAR-10 and CIFAR-100 test sets as proxies for sensitive data. Subjectively, the reconstructed images closely resembled the originals. They also tried it on theInstaHide Challenge, a collection of 5,000 scrambled versions of 100 images published by the InstaHide team. They found an approximate solution in under an hour, and InstaHide’s inventors agreed that they had met the challenge.Why it matters:Once personally identifiable information is leaked, it’s impossible to unleak. Machine learning must protect privacy with the utmost rigor.We’re thinking:The authors show that their method can work well if the scrambled training images are available. It remains to be seen whether it works given access only to a trained model.",
    "qa": [
      {
        "question": "Phương pháp tấn công nào được sử dụng để ước tính dữ liệu huấn luyện từ một mô hình đã được huấn luyện?",
        "options": {
          "A": "Tấn công từ chối dịch vụ (DoS)",
          "B": "Tấn công tái cấu trúc (reconstruction attack)",
          "C": "Tấn công trung gian (Man-in-the-middle attack)",
          "D": "Tấn công brute-force"
        },
        "answer": "B"
      },
      {
        "question": "InstaHide ban đầu được ca ngợi vì điều gì?",
        "options": {
          "A": "Khả năng tăng tốc độ huấn luyện mô hình.",
          "B": "Khả năng làm cho các ví dụ nhạy cảm không thể nhận ra bằng mắt thường trong khi vẫn giữ được tính hữu dụng cho việc huấn luyện.",
          "C": "Khả năng bảo vệ mô hình khỏi các cuộc tấn công adversarial.",
          "D": "Khả năng giảm kích thước của dữ liệu huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Nhóm nghiên cứu đã phá vỡ InstaHide bằng cách nào?",
        "options": {
          "A": "Tìm ra lỗ hổng bảo mật trong phần cứng mà InstaHide sử dụng.",
          "B": "Phân tích InstaHide như một phương trình tuyến tính có thể đảo ngược.",
          "C": "Sử dụng thuật toán học sâu tiên tiến để giải mã hình ảnh.",
          "D": "Tấn công brute-force vào các khóa mã hóa của InstaHide."
        },
        "answer": "B"
      },
      {
        "question": "Trong quá trình thử nghiệm, các bộ dữ liệu nào được sử dụng làm đại diện cho dữ liệu nhạy cảm?",
        "options": {
          "A": "ImageNet và MNIST",
          "B": "CIFAR-10, CIFAR-100 và STL-10",
          "C": "COCO và Pascal VOC",
          "D": "LFW và CelebA"
        },
        "answer": "B"
      },
      {
        "question": "Bộ dữ liệu nào được sử dụng làm bộ dữ liệu không nhạy cảm trong quá trình thử nghiệm?",
        "options": {
          "A": "MNIST",
          "B": "CIFAR-10",
          "C": "ImageNet",
          "D": "STL-10"
        },
        "answer": "C"
      },
      {
        "question": "Kết quả chính của việc phá vỡ InstaHide là gì?",
        "options": {
          "A": "Không thể tái tạo lại hình ảnh gốc từ dữ liệu đã xáo trộn.",
          "B": "Hình ảnh tái tạo lại rất giống với hình ảnh gốc.",
          "C": "Chỉ có thể tái tạo lại một phần nhỏ hình ảnh gốc.",
          "D": "Quá trình tái tạo lại mất quá nhiều thời gian để thực hiện."
        },
        "answer": "B"
      },
      {
        "question": "Thử thách InstaHide mà nhóm nghiên cứu đã tham gia bao gồm bao nhiêu hình ảnh đã xáo trộn?",
        "options": {
          "A": "1000",
          "B": "2500",
          "C": "5000",
          "D": "10000"
        },
        "answer": "C"
      },
      {
        "question": "Tại sao việc bảo vệ thông tin cá nhân trong máy học lại quan trọng?",
        "options": {
          "A": "Để tăng tốc độ huấn luyện mô hình.",
          "B": "Để giảm chi phí lưu trữ dữ liệu.",
          "C": "Một khi thông tin cá nhân bị rò rỉ, không thể thu hồi lại được.",
          "D": "Để tuân thủ các quy định pháp luật về bản quyền."
        },
        "answer": "C"
      },
      {
        "question": "Nhóm nghiên cứu đã mất bao lâu để tìm ra giải pháp gần đúng cho thử thách InstaHide?",
        "options": {
          "A": "Vài giây",
          "B": "Dưới một giờ",
          "C": "Vài giờ",
          "D": "Một ngày"
        },
        "answer": "B"
      },
      {
        "question": "Câu hỏi nào vẫn còn bỏ ngỏ sau nghiên cứu này?",
        "options": {
          "A": "Liệu phương pháp này có hiệu quả khi chỉ có quyền truy cập vào mô hình đã được huấn luyện hay không.",
          "B": "Liệu InstaHide có thể được cải thiện để chống lại các cuộc tấn công tái cấu trúc hay không.",
          "C": "Liệu các phương pháp mã hóa khác có hiệu quả hơn InstaHide hay không.",
          "D": "Liệu các bộ dữ liệu khác có dễ bị tấn công tái cấu trúc hơn CIFAR-10 và CIFAR-100 hay không."
        },
        "answer": "A"
      }
    ]
  },
  "a-system-that-provides-feedback-with-near-human-level-accuracy": {
    "title": "Bug Finder",
    "collection": "ml-research",
    "content": "One challenge to making online education available worldwide is evaluating an immense volume of student work. Especially difficult is evaluating interactive computer programming assignments such as coding a game. A deep learning system automated the process by finding mistakes in completed assignments.\n\nWhat’s new:Evan Zheran Liu and colleagues at Stanford proposedDreamGrader, a system that integrates reinforcement and supervised learning to identify errors (undesirable behaviors) in interactive computer programs and provide detailed information about where the problems lie.\n\nKey insight:A reinforcement learning model can play a game, randomly at first, and — if it receives the proper rewards — learn to take actions that bring about an error. A classifier can learn to recognize that the error occurred, randomly at first, and reward the RL model when it triggers the error. In this scheme, training requires a small number of student submissions that have been labeled with a particular error that is known to occur. The two models learn in an alternating fashion: The RL model plays for a while and does or doesn’t bring about the error; the classifier classifies the RL model’s actions (that is, it applies the model’s label to actions that trigger the error and, if so, dispenses a reward), then the RL model plays more, and so on. By repeating this cycle, the classifier learns to recognize an error reliably.\n\nHow it works:DreamGrader was trained on a subset of 3,500 anonymized student responses to an assignment from the online educational platform Code.org. Students were asked to codeBounce, a game in which a single player moves a paddle along a horizontal axis to send a ball into a goal. The authors identified eight possible errors (such as the ball bouncing out of the goal after entering and no new ball being launched after a goal was scored) and labeled the examples accordingly. The system comprised two components for each type of error: (i) aplayerthat played the game (adouble dueling deep Q-network) and (ii) a classifier (an LSTM and vanilla neural network) that decided whether the error occurred.\n\nResults:The authors evaluated DreamGrader on a test set of Code.org student submissions. For comparison, they modified the previousPlay to Grade, which had been designed to identify error-free submissions, to predict the presence of a specific error. DreamGrader achieved 94.3 percent accuracy — 1.5 percent short of human-level performance — while Play to Grade achieved 75.5 percent accuracy. It evaluated student submissions in around 1 second each, 180 times faster than human-level performance.\n\nYes, but:DreamGrader finds only known errors. It can’t catch bugs that instructors haven’t already seen.\n\nWhy it matters:Each student submission can be considered a different, related task. The approach known as meta-RL aims to train an agent that can learn new tasks based on experience with related tasks. Connecting these two ideas, the authors trained their model following the learning techniques expressed in the meta-RL algorithmDREAM. Sometimes it’s not about reinventing the wheel, but reframing the problem as one we already know how to solve.\n\nWe’re thinking:Teaching people how to code empowers them to lead more fulfilling lives in the digital age, just as teaching them to read has opened doors to wisdom and skill since the invention of the printing press. Accomplishing this on a global scale requires automated systems for education (like Coursera!). It’s great to see AI research that could make these systems more effective.",
    "qa": [
      {
        "question": "Thách thức chính trong việc cung cấp giáo dục trực tuyến trên toàn thế giới được đề cập trong bài viết là gì?",
        "options": {
          "A": "Thiếu hụt cơ sở hạ tầng internet ở các nước đang phát triển.",
          "B": "Đánh giá khối lượng lớn bài tập của học sinh, đặc biệt là các bài tập lập trình tương tác.",
          "C": "Sự thiếu hụt giáo viên có trình độ chuyên môn cao để giảng dạy trực tuyến.",
          "D": "Chi phí cao để phát triển các khóa học trực tuyến chất lượng."
        },
        "answer": "B"
      },
      {
        "question": "DreamGrader là hệ thống được phát triển bởi ai và ở đâu?",
        "options": {
          "A": "Google AI Research.",
          "B": "Evan Zheran Liu và cộng sự tại Stanford.",
          "C": "Một nhóm các nhà nghiên cứu tại MIT.",
          "D": "Các kỹ sư của Code.org."
        },
        "answer": "B"
      },
      {
        "question": "Nguyên tắc chính mà DreamGrader sử dụng để xác định lỗi trong các chương trình máy tính tương tác là gì?",
        "options": {
          "A": "Phân tích cú pháp và ngữ nghĩa của mã nguồn.",
          "B": "Tích hợp học tăng cường và học có giám sát.",
          "C": "So sánh mã nguồn với các mẫu mã lỗi đã biết.",
          "D": "Sử dụng thuật toán di truyền để tìm kiếm các lỗi tiềm ẩn."
        },
        "answer": "B"
      },
      {
        "question": "Trong DreamGrader, mô hình học tăng cường đóng vai trò gì?",
        "options": {
          "A": "Phân loại các hành động của người chơi để xác định lỗi.",
          "B": "Chơi trò chơi và học cách thực hiện các hành động dẫn đến lỗi.",
          "C": "Đánh giá chất lượng mã nguồn của học sinh.",
          "D": "Tạo ra các bài kiểm tra tự động để đánh giá kiến thức của học sinh."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu nào được sử dụng để huấn luyện DreamGrader?",
        "options": {
          "A": "Mã nguồn của các trò chơi nổi tiếng.",
          "B": "Một tập hợp con gồm 3,500 bài nộp ẩn danh của học sinh từ Code.org.",
          "C": "Dữ liệu tổng hợp từ nhiều nền tảng giáo dục trực tuyến khác nhau.",
          "D": "Các bài kiểm tra được tạo ra bởi các chuyên gia lập trình."
        },
        "answer": "B"
      },
      {
        "question": "Trò chơi Bounce mà DreamGrader được huấn luyện để đánh giá có mục tiêu gì?",
        "options": {
          "A": "Điều khiển một nhân vật vượt qua các chướng ngại vật.",
          "B": "Di chuyển một mái chèo để đưa bóng vào mục tiêu.",
          "C": "Giải các câu đố logic để tiến tới cấp độ tiếp theo.",
          "D": "Xây dựng một thành phố và quản lý tài nguyên."
        },
        "answer": "B"
      },
      {
        "question": "Độ chính xác mà DreamGrader đạt được khi đánh giá bài tập của học sinh là bao nhiêu?",
        "options": {
          "A": "65.5%",
          "B": "75.5%",
          "C": "94.3%",
          "D": "99.9%"
        },
        "answer": "C"
      },
      {
        "question": "So với hiệu suất của con người, DreamGrader đánh giá bài tập nhanh hơn bao nhiêu lần?",
        "options": {
          "A": "10 lần.",
          "B": "50 lần.",
          "C": "100 lần.",
          "D": "180 lần."
        },
        "answer": "D"
      },
      {
        "question": "Hạn chế chính của DreamGrader được đề cập trong bài viết là gì?",
        "options": {
          "A": "Yêu cầu phần cứng mạnh mẽ để hoạt động.",
          "B": "Chỉ có thể tìm thấy các lỗi đã biết.",
          "C": "Khó khăn trong việc tích hợp với các nền tảng giáo dục trực tuyến khác nhau.",
          "D": "Độ chính xác giảm đáng kể khi đánh giá các chương trình phức tạp."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến thuật toán meta-RL DREAM với mục đích gì?",
        "options": {
          "A": "Để cải thiện khả năng gỡ lỗi của DreamGrader.",
          "B": "Để huấn luyện mô hình theo các kỹ thuật học tập được thể hiện trong DREAM.",
          "C": "Để giảm thời gian huấn luyện cho DreamGrader.",
          "D": "Để tăng cường tính bảo mật của hệ thống."
        },
        "answer": "B"
      }
    ]
  },
  "a-technique-that-masks-tokens-in-large-language-models-protecting-data-privacy": {
    "title": "Reducing Memorization in LLMs",
    "collection": "ml-research",
    "content": "Studies have established that large language models can memorize the text passages they’ve been trained on repeatedly and regurgitate them when prompted in adversarial and, though rarely, in benign ways. Researchers proposed a way to reduce this tendency and attendant risks to intellectual property and privacy.\n\nWhat’s new:Abhimanyu Hans and colleagues from University of Maryland introduced thegoldfish loss, a modification of the next-token-prediction loss function typically used in large language models. The goldfish loss avoids memorization of long passages by masking some tokens during the loss computation.\n\nKey insight:Certain passages may appear many times during training, either because the model takes multiple passes over data or because they’re duplicated in the training corpus. Randomly masking individual tokens from the loss computation doesn’t prevent a model from memorizing repeated passages because the model, over many repetitions, still sees every word and its place in the order. But masking a long passage the same way with every repetition ensures the model can’t memorize the passage regardless of the number of repetitions.\n\nHow it works:The goldfish loss masks the current token from the loss computation based on previous tokens.  A deterministic hashing function decides which tokens to mask effectively at random the first time it encounters a particular 13-token sequence, but identically if it encounters the same sequence again. At a high level, it masks a certain percentage of tokens, typically one in three or four. The authors compared the goldfish loss to the next-token-prediction loss function in two settings: one that mimicked a typical training process and one that made memorization more likely.\n\nResults:The authors assessed the results using two metrics: (i)ROUGE-L, which falls between 0 and 100 percent and reflects the longest subsequence in common between ground-truth and generated data, and (ii) the percentage of tokens that exactly matched the original text in proper order. Both measure memorization, so lower scores are better.\n\nWhy it matters:Businesses are worried about whether using LLMsposes risks to intellectual property rights and privacy. Techniques that address this concern without significantly impacting performance are welcome.\n\nWe’re thinking:Memorization also happens in models generating images. We look forward to research into using similar techniques in that domain.",
    "qa": [
      {
        "question": "Mục đích chính của nghiên cứu được đề cập trong bài viết là gì?",
        "options": {
          "A": "Tăng cường khả năng sáng tạo của các mô hình ngôn ngữ lớn.",
          "B": "Giảm thiểu xu hướng ghi nhớ và tái tạo văn bản huấn luyện của các mô hình ngôn ngữ lớn.",
          "C": "Cải thiện hiệu suất của các mô hình ngôn ngữ lớn trong việc dự đoán từ tiếp theo.",
          "D": "Phát triển một phương pháp mới để huấn luyện các mô hình ngôn ngữ lớn nhanh hơn."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp 'goldfish loss' hoạt động bằng cách nào?",
        "options": {
          "A": "Tăng cường trọng số của các token quan trọng trong quá trình tính toán loss.",
          "B": "Che giấu một số token một cách ngẫu nhiên trong quá trình tính toán loss.",
          "C": "Che giấu một số token dựa trên các token trước đó trong quá trình tính toán loss.",
          "D": "Sử dụng một hàm loss khác hoàn toàn so với hàm dự đoán token tiếp theo."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao việc che giấu ngẫu nhiên các token không hiệu quả trong việc ngăn chặn việc ghi nhớ các đoạn văn lặp đi lặp lại?",
        "options": {
          "A": "Vì mô hình vẫn có thể thấy tất cả các từ và vị trí của chúng theo thứ tự qua nhiều lần lặp lại.",
          "B": "Vì việc che giấu ngẫu nhiên làm giảm hiệu suất của mô hình.",
          "C": "Vì việc che giấu ngẫu nhiên chỉ ảnh hưởng đến một số lượng nhỏ token.",
          "D": "Vì mô hình có thể dự đoán các token bị che giấu một cách dễ dàng."
        },
        "answer": "A"
      },
      {
        "question": "Hàm băm (hashing function) trong 'goldfish loss' được sử dụng để làm gì?",
        "options": {
          "A": "Xác định các token quan trọng cần được giữ lại.",
          "B": "Quyết định token nào sẽ bị che giấu dựa trên chuỗi token trước đó.",
          "C": "Tăng tốc quá trình tính toán loss.",
          "D": "Giảm kích thước của dữ liệu huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Tỷ lệ token bị che giấu trong 'goldfish loss' thường là bao nhiêu?",
        "options": {
          "A": "Khoảng 10%.",
          "B": "Khoảng 25-33%.",
          "C": "Khoảng 50%.",
          "D": "Khoảng 75%."
        },
        "answer": "B"
      },
      {
        "question": "ROUGE-L được sử dụng để đo lường điều gì trong nghiên cứu này?",
        "options": {
          "A": "Độ chính xác của mô hình trong việc dự đoán từ tiếp theo.",
          "B": "Mức độ tương đồng giữa văn bản gốc và văn bản được tạo ra bởi mô hình.",
          "C": "Tốc độ huấn luyện của mô hình.",
          "D": "Khả năng của mô hình trong việc hiểu ngữ cảnh."
        },
        "answer": "B"
      },
      {
        "question": "Giá trị ROUGE-L như thế nào thì cho thấy mô hình ít ghi nhớ hơn?",
        "options": {
          "A": "Giá trị càng cao càng tốt.",
          "B": "Giá trị càng thấp càng tốt.",
          "C": "Giá trị gần 50% là tốt nhất.",
          "D": "Giá trị không ảnh hưởng đến việc đánh giá khả năng ghi nhớ."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao các doanh nghiệp lo ngại về việc sử dụng LLMs?",
        "options": {
          "A": "Vì chi phí vận hành LLMs quá cao.",
          "B": "Vì LLMs có thể gây ra rủi ro cho quyền sở hữu trí tuệ và quyền riêng tư.",
          "C": "Vì LLMs khó tích hợp vào các hệ thống hiện có.",
          "D": "Vì LLMs không đủ chính xác cho các ứng dụng kinh doanh."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lĩnh vực nào khác có thể hưởng lợi từ các kỹ thuật tương tự như 'goldfish loss'?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên cho các ngôn ngữ ít phổ biến.",
          "B": "Tạo sinh hình ảnh.",
          "C": "Phân tích dữ liệu tài chính.",
          "D": "Robot học."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì làm cho 'goldfish loss' khác biệt so với việc che giấu token ngẫu nhiên thông thường?",
        "options": {
          "A": "'Goldfish loss' che giấu nhiều token hơn.",
          "B": "'Goldfish loss' sử dụng một hàm băm để che giấu các token một cách nhất quán cho cùng một chuỗi.",
          "C": "'Goldfish loss' chỉ được sử dụng cho các mô hình ngôn ngữ lớn.",
          "D": "'Goldfish loss' không ảnh hưởng đến hiệu suất của mô hình."
        },
        "answer": "B"
      }
    ]
  },
  "a-transformer-for-graphs": {
    "title": "A Transformer for Graphs",
    "collection": "ml-research",
    "content": "Transformers can learn a lot from sequential data like words in a book, but they’ve shown limited ability to learn from data in the form of a graph. A new transformer variant gives graphs due attention.What's new:Vijay Prakash Dwivedi and Xavier Bresson at Nanyang Technological University devisedGraph Transformer(GT), a transformer layer designed to process graph data. Stacking GT layers provides a transformer-based alternative to typical graph neural networks, which process data in the form of nodes and edges that connect them, such as customers connected to products they’ve purchased or atoms connected to one another in a molecule.Key insight:Previous work applied transformers to graph data by dedicating a token to each node and computing self-attention between every pair. This method encodes both local relationships, such as which nodes are neighbors (given a hyperparameter that defines the neighborhood within a number of degrees of separation), and global information, such as a node’s distance from non-neighboring nodes. However, this approach is prohibitively expensive for large graphs, since the computation required for self-attention grows quadratically with the size of the input. Applying attention only to neighboring nodes captures crucial local information while cutting the computational burden. Meanwhile, a positional vector that represents each node’s relative distance from all other nodes can capture global information in a compute-efficient way.How it works:The authors built three models, each of which comprised embedding layers, 10 GT layers (including self-attention and fully connected layers) followed by a vanilla neural network. They trained each model on a different task: two-class classification ofsynthetic data, six-class classification of synthetic data, and a regression task that estimated the solubility of variouscompounds that contain zinc.\n\nResults:The authors’ model achieved 73.17 percent accuracy and 84.81 percent accuracy on the two- and six-class classification tasks, respectively. A baselineGATgraph neural network, which applied attention across neighboring node representations, achieved 70.58 percent accuracy and 78.27 percent accuracy respectively. On the regression task, the authors’ model achieved mean absolute error (MAE) of 0.226 compared to GAT’s 0.384 (lower is better). However, it slightly underperformed the state-of-the-artGated Graph ConvNetin all three tasks.Why it matters:Transformers have proven their value in processing text, images, and other data types. This work makes them more useful with graphs. Although the Graph Transformer model fell short of the best graph neural network, this work establishes a strong baseline for further work in this area.We're thinking:Pretrained and fine-tuned transformers handily outperform trained convolutional neural networks. Would fine-tuning a Graph Transformer model yield similarly outstanding results?",
    "qa": [
      {
        "question": "Mục đích chính của Graph Transformer (GT) được giới thiệu trong bài viết là gì?",
        "options": {
          "A": "Thay thế hoàn toàn các mạng neural đồ thị truyền thống.",
          "B": "Xử lý dữ liệu đồ thị bằng kiến trúc transformer.",
          "C": "Cải thiện hiệu suất của các mô hình transformer trên dữ liệu văn bản.",
          "D": "Tăng tốc độ tính toán cho các mạng neural tích chập."
        },
        "answer": "B"
      },
      {
        "question": "Nhược điểm chính của việc áp dụng trực tiếp transformer cho dữ liệu đồ thị bằng cách gán một token cho mỗi node là gì?",
        "options": {
          "A": "Không thể mã hóa thông tin cục bộ.",
          "B": "Đòi hỏi chi phí tính toán quá lớn, tăng bậc hai theo kích thước đồ thị.",
          "C": "Chỉ hoạt động tốt với các đồ thị nhỏ.",
          "D": "Khó khăn trong việc trích xuất các đặc trưng quan trọng."
        },
        "answer": "B"
      },
      {
        "question": "Giải pháp nào được tác giả đề xuất để giảm chi phí tính toán khi áp dụng transformer cho dữ liệu đồ thị?",
        "options": {
          "A": "Áp dụng attention cho tất cả các node trong đồ thị.",
          "B": "Áp dụng attention chỉ cho các node lân cận và sử dụng vector vị trí để biểu diễn khoảng cách tương đối.",
          "C": "Sử dụng một mạng neural tích chập thay vì transformer.",
          "D": "Giảm số lượng layer trong mô hình transformer."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Graph Transformer (GT) được đánh giá trên những loại tác vụ nào trong bài viết?",
        "options": {
          "A": "Phân loại ảnh và xử lý ngôn ngữ tự nhiên.",
          "B": "Phân loại dữ liệu tổng hợp (2 và 6 lớp) và hồi quy ước tính độ hòa tan của hợp chất.",
          "C": "Dự đoán chuỗi thời gian và phân tích cảm xúc.",
          "D": "Phát hiện đối tượng và phân đoạn ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Trong các thử nghiệm, mô hình Graph Transformer (GT) thể hiện như thế nào so với GAT (Graph Attention Network)?",
        "options": {
          "A": "GT luôn vượt trội hơn GAT trên tất cả các tác vụ.",
          "B": "GT có độ chính xác cao hơn GAT trong các tác vụ phân loại, nhưng kém hơn trong tác vụ hồi quy.",
          "C": "GT có độ chính xác cao hơn GAT trong cả tác vụ phân loại và hồi quy.",
          "D": "GT có độ chính xác thấp hơn GAT trong các tác vụ phân loại, nhưng tốt hơn trong tác vụ hồi quy."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình nào được đề cập trong bài viết là 'state-of-the-art' (hiện đại nhất) và có hiệu suất tốt hơn Graph Transformer (GT) trong tất cả các tác vụ?",
        "options": {
          "A": "GAT (Graph Attention Network).",
          "B": "Gated Graph ConvNet.",
          "C": "Vanilla Neural Network.",
          "D": "Transformer gốc."
        },
        "answer": "B"
      },
      {
        "question": "Ý nghĩa chính của nghiên cứu về Graph Transformer (GT) là gì?",
        "options": {
          "A": "Chứng minh rằng transformer không thể áp dụng cho dữ liệu đồ thị.",
          "B": "Thiết lập một baseline mạnh mẽ cho các nghiên cứu tiếp theo về transformer trên dữ liệu đồ thị.",
          "C": "Thay thế hoàn toàn các mạng neural đồ thị bằng transformer.",
          "D": "Cải thiện hiệu suất của các mô hình transformer trên dữ liệu văn bản."
        },
        "answer": "B"
      },
      {
        "question": "Các tác giả của bài viết đến từ trường đại học nào?",
        "options": {
          "A": "Massachusetts Institute of Technology (MIT).",
          "B": "Stanford University.",
          "C": "Nanyang Technological University.",
          "D": "University of Oxford."
        },
        "answer": "C"
      },
      {
        "question": "Số lượng lớp GT (bao gồm self-attention và fully connected layers) được sử dụng trong mỗi mô hình mà các tác giả xây dựng là bao nhiêu?",
        "options": {
          "A": "5",
          "B": "10",
          "C": "15",
          "D": "20"
        },
        "answer": "B"
      },
      {
        "question": "Trong bài viết, 'MAE' là viết tắt của thuật ngữ nào và nó được sử dụng để đánh giá hiệu suất của mô hình trong tác vụ nào?",
        "options": {
          "A": "Mean Average Error, được sử dụng trong tác vụ phân loại.",
          "B": "Mean Absolute Error, được sử dụng trong tác vụ hồi quy.",
          "C": "Maximum Absolute Error, được sử dụng trong tác vụ phân loại.",
          "D": "Minimum Average Error, được sử dụng trong tác vụ hồi quy."
        },
        "answer": "B"
      }
    ]
  },
  "active-inheritance-a-smarter-way-to-train-models-with-synthetic-data": {
    "title": "Fine-Tuning Fine Points",
    "collection": "ml-research",
    "content": "The practice of fine-tuning models on synthetic data is becoming well established. But synthetic training data, even if it represents the training task well, may include characteristics like toxicity that impart unwelcome properties in the trained model’s output, and it may inconsistently represent desired traits such as the target output length. Researchers developed a method that reduces aspects of generated data and retains desired ones.\n\nWhat’s new:Luísa Shimabucoro and colleagues at Cohere introducedactive inheritance, a fine-tuning method that automatically selects synthetic training examples that have desirable characteristics.\n\nKey insight:A naive way to generate synthetic fine-tuning data is to feed prompts to a model, collect its output, and use that as the fine-tuning set. But synthetic data is cheap, so we can afford to be more choosy. By generating several responses to each prompt, we can select the one that best suits our purposes.\n\nHow it works:The authors usedLlama 2 7BandMixtral 8x7Bas both teachers and students in all combinations. They prompted the models with 52,000 prompts from theAlpacadataset and used automated methods to evaluate their outputs in terms of characteristics including social bias, toxicity, word count, lexical diversity, andcalibration(how well a model’s estimated probabilities match its accuracy).\n\nResults:Fine-tuning on the best response for each characteristic improved performance with respect to that characteristic beyond using the initial outputs or selecting outputs randomly.\n\nWhy it matters:Training on synthetic data is becoming increasingly common. While it shows great promise, best practices for data generation are still being formulated. The authors’ method helps by automatically steering models toward generating more desirable responses, reducing negative traits and reinforcing positive traits.\n\nWe’re thinking:Knowledge distillation lately has led to more capable and compact models. This approach adds levers of fine control to that technique.",
    "qa": [
      {
        "question": "Phương pháp 'active inheritance' được giới thiệu bởi Luísa Shimabucoro và cộng sự tại Cohere có mục đích chính là gì?",
        "options": {
          "A": "Tăng tốc độ huấn luyện mô hình bằng dữ liệu tổng hợp.",
          "B": "Tự động lựa chọn các ví dụ huấn luyện tổng hợp có đặc điểm mong muốn.",
          "C": "Giảm chi phí tạo dữ liệu huấn luyện tổng hợp.",
          "D": "Cải thiện độ chính xác của mô hình trên dữ liệu thực tế."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, nhược điểm tiềm ẩn của việc sử dụng dữ liệu tổng hợp để huấn luyện mô hình là gì?",
        "options": {
          "A": "Dữ liệu tổng hợp thường có kích thước quá lớn, gây khó khăn cho việc huấn luyện.",
          "B": "Dữ liệu tổng hợp có thể chứa các đặc điểm không mong muốn như độc hại.",
          "C": "Dữ liệu tổng hợp không thể hiện được đầy đủ sự phức tạp của dữ liệu thực tế.",
          "D": "Dữ liệu tổng hợp đòi hỏi nhiều tài nguyên tính toán hơn so với dữ liệu thực tế."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính giữa phương pháp 'active inheritance' và phương pháp tạo dữ liệu tổng hợp thông thường là gì?",
        "options": {
          "A": "Active inheritance sử dụng các mô hình lớn hơn để tạo dữ liệu.",
          "B": "Active inheritance tạo ra nhiều phản hồi cho mỗi prompt và chọn phản hồi tốt nhất.",
          "C": "Active inheritance sử dụng dữ liệu thực tế kết hợp với dữ liệu tổng hợp.",
          "D": "Active inheritance tự động điều chỉnh các tham số của mô hình trong quá trình tạo dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Trong thí nghiệm, các tác giả đã sử dụng những mô hình nào làm 'giáo viên' và 'học sinh'?",
        "options": {
          "A": "Chỉ Llama 2 7B.",
          "B": "Chỉ Mixtral 8x7B.",
          "C": "Cả Llama 2 7B và Mixtral 8x7B, trong tất cả các tổ hợp.",
          "D": "Một mô hình lớn hơn làm 'giáo viên' và một mô hình nhỏ hơn làm 'học sinh'."
        },
        "answer": "C"
      },
      {
        "question": "Bộ dữ liệu Alpaca được sử dụng trong thí nghiệm với vai trò gì?",
        "options": {
          "A": "Dữ liệu thực tế để đánh giá hiệu suất của mô hình.",
          "B": "Dữ liệu tổng hợp để huấn luyện mô hình.",
          "C": "Bộ prompt để tạo ra dữ liệu huấn luyện tổng hợp.",
          "D": "Dữ liệu để so sánh với kết quả của phương pháp active inheritance."
        },
        "answer": "C"
      },
      {
        "question": "Các đặc điểm nào được sử dụng để đánh giá chất lượng của dữ liệu tổng hợp trong thí nghiệm?",
        "options": {
          "A": "Độ chính xác, tốc độ xử lý và kích thước mô hình.",
          "B": "Độ lệch xã hội, độc hại, số lượng từ, sự đa dạng từ vựng và độ tin cậy.",
          "C": "Độ phức tạp, tính dễ hiểu và khả năng tái sử dụng.",
          "D": "Độ chính xác, khả năng khái quát hóa và khả năng thích ứng."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả chính của thí nghiệm là gì?",
        "options": {
          "A": "Việc sử dụng dữ liệu tổng hợp không cải thiện hiệu suất của mô hình.",
          "B": "Việc lựa chọn ngẫu nhiên các phản hồi tốt hơn so với việc sử dụng tất cả các phản hồi.",
          "C": "Việc tinh chỉnh trên phản hồi tốt nhất cho mỗi đặc điểm cải thiện hiệu suất so với đặc điểm đó.",
          "D": "Mô hình Llama 2 7B luôn hoạt động tốt hơn Mixtral 8x7B."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao việc huấn luyện trên dữ liệu tổng hợp ngày càng trở nên phổ biến?",
        "options": {
          "A": "Dữ liệu tổng hợp luôn có chất lượng tốt hơn dữ liệu thực tế.",
          "B": "Dữ liệu tổng hợp dễ dàng thu thập và xử lý hơn dữ liệu thực tế.",
          "C": "Dữ liệu tổng hợp cho phép kiểm soát tốt hơn các đặc điểm của mô hình.",
          "D": "Dữ liệu tổng hợp giúp giảm chi phí huấn luyện mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, phương pháp 'active inheritance' đóng góp vào việc gì trong quá trình tạo dữ liệu tổng hợp?",
        "options": {
          "A": "Tăng tốc độ tạo dữ liệu tổng hợp.",
          "B": "Giảm dung lượng lưu trữ cần thiết cho dữ liệu tổng hợp.",
          "C": "Tự động hướng mô hình tạo ra các phản hồi mong muốn hơn, giảm đặc điểm tiêu cực và tăng cường đặc điểm tích cực.",
          "D": "Cải thiện khả năng hiểu ngôn ngữ tự nhiên của mô hình."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến 'knowledge distillation' như thế nào?",
        "options": {
          "A": "Knowledge distillation là một phương pháp thay thế cho việc sử dụng dữ liệu tổng hợp.",
          "B": "Knowledge distillation không liên quan đến phương pháp active inheritance.",
          "C": "Knowledge distillation gần đây đã dẫn đến các mô hình có khả năng và nhỏ gọn hơn, và phương pháp active inheritance bổ sung các đòn bẩy kiểm soát tốt vào kỹ thuật đó.",
          "D": "Knowledge distillation chỉ hiệu quả với dữ liệu thực tế."
        },
        "answer": "C"
      }
    ]
  },
  "adversarial-helper": {
    "title": "Adversarial Helper",
    "collection": "ml-research",
    "content": "Models that learn relationships between images and words are gaining ahigherprofile. New research shows that adversarial learning, usually a way to make models robust to deliberately misleading inputs, can boost vision-and-language performance.What’s new:Vision-and-language models based on transformer networks have shown strong performance on tasks such as answering questions about images. Zhe Gan of Microsoft and colleagues at Microsoft and the University of Maryland improved such models viaVision-and-Language Large-scale Adversarial (VILLA)training.Key insight:Vision-and-language models often are pretrained, for instance, to fill in blanks in image captions, and then fine-tuned for a specific task, such as answering questions about images.Previous workwith language models showed that adversarial fine-tuning — that is, giving the model input that’s designed to fool it and training it not to be fooled — can increase accuracy. The team extended this idea to vision-and-language models in both pretraining and fine-tuning.How it works:The authors worked withUNITER, which has achieved state-of-the-art performance on several vision-and-language tasks. UNITER embeds images and text separately. Then it feeds the embeddings into aBERT-like model to create a multimodal embedding.\n\nResults:UNITER trained with VILLA outperformed a standard UNITER in six vision-and-language tasks. In visual question answering, UNITER with VILLA answered 73.67 percent correctly, while the plain model answered 72.91 percent correctly. In the two-stage visual commonsense reasoning task of answering a question and justifying the answer, UNITER with VILLA scored 59.75 percent, while its standard counterpart succeeded 57.76 percent of the time.Why it matters:We understand the world through several modalities, and that makes us smarter. For instance, to describe a tree, neither an image nor a biological description is sufficient, but together they have a revealing synergy. Current models still struggle to grasp the meaning of images and language individually, but they will always be missing something until they can draw connections between them.We’re thinking:Vision: check. Language: check. Now sound, aroma, touch . . .",
    "qa": [
      {
        "question": "Nghiên cứu mới cho thấy phương pháp học đối kháng (adversarial learning) có thể cải thiện hiệu suất của mô hình nào?",
        "options": {
          "A": "Mô hình xử lý ngôn ngữ tự nhiên thuần túy.",
          "B": "Mô hình thị giác máy tính thuần túy.",
          "C": "Mô hình học tăng cường.",
          "D": "Mô hình học mối quan hệ giữa hình ảnh và ngôn ngữ."
        },
        "answer": "D"
      },
      {
        "question": "VILLA (Vision-and-Language Large-scale Adversarial) là phương pháp huấn luyện được phát triển bởi ai?",
        "options": {
          "A": "Google AI.",
          "B": "Facebook AI Research.",
          "C": "Zhe Gan của Microsoft và cộng sự tại Microsoft và Đại học Maryland.",
          "D": "OpenAI."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc huấn luyện trước (pretraining) các mô hình thị giác và ngôn ngữ là gì?",
        "options": {
          "A": "Tăng tốc độ xử lý hình ảnh.",
          "B": "Cải thiện khả năng tạo ra hình ảnh từ văn bản.",
          "C": "Điền vào chỗ trống trong chú thích hình ảnh (image captions).",
          "D": "Giảm kích thước của mô hình."
        },
        "answer": "C"
      },
      {
        "question": "Huấn luyện đối kháng (adversarial fine-tuning) hoạt động bằng cách nào?",
        "options": {
          "A": "Cung cấp dữ liệu huấn luyện sạch và không có nhiễu.",
          "B": "Cung cấp đầu vào được thiết kế để đánh lừa mô hình và huấn luyện mô hình để không bị đánh lừa.",
          "C": "Sử dụng một mạng nơ-ron đối kháng để tạo ra dữ liệu huấn luyện.",
          "D": "Tăng cường dữ liệu huấn luyện bằng cách thêm các biến thể của hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình UNITER được sử dụng trong nghiên cứu này có đặc điểm gì nổi bật?",
        "options": {
          "A": "Có khả năng tạo ra hình ảnh chất lượng cao từ văn bản.",
          "B": "Đạt được hiệu suất hàng đầu (state-of-the-art) trên một số tác vụ thị giác và ngôn ngữ.",
          "C": "Sử dụng kiến trúc mạng nơ-ron hồi quy (RNN).",
          "D": "Chỉ có thể xử lý hình ảnh có độ phân giải thấp."
        },
        "answer": "B"
      },
      {
        "question": "UNITER xử lý hình ảnh và văn bản như thế nào?",
        "options": {
          "A": "Kết hợp trực tiếp hình ảnh và văn bản thành một đầu vào duy nhất.",
          "B": "Nhúng (embed) hình ảnh và văn bản riêng biệt, sau đó đưa vào mô hình BERT.",
          "C": "Sử dụng hai mô hình riêng biệt cho hình ảnh và văn bản, sau đó kết hợp kết quả.",
          "D": "Chỉ xử lý văn bản và sử dụng thông tin hình ảnh như một yếu tố bổ sung."
        },
        "answer": "B"
      },
      {
        "question": "Trong tác vụ trả lời câu hỏi về hình ảnh (visual question answering), UNITER được huấn luyện với VILLA đạt được độ chính xác là bao nhiêu?",
        "options": {
          "A": "72.91%.",
          "B": "73.00%.",
          "C": "73.67%.",
          "D": "74.00%."
        },
        "answer": "C"
      },
      {
        "question": "Trong tác vụ suy luận thông thường trực quan (visual commonsense reasoning), UNITER với VILLA cải thiện bao nhiêu phần trăm so với UNITER tiêu chuẩn?",
        "options": {
          "A": "0.76%.",
          "B": "1.99%.",
          "C": "2.00%.",
          "D": "57.76%."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc hiểu thế giới thông qua nhiều phương thức (modalities) lại quan trọng?",
        "options": {
          "A": "Giúp giảm chi phí tính toán.",
          "B": "Giúp chúng ta thông minh hơn và hiểu sâu sắc hơn.",
          "C": "Giúp đơn giản hóa quá trình xử lý thông tin.",
          "D": "Giúp tăng tốc độ học máy."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, những phương thức (modalities) nào có thể được tích hợp vào mô hình trong tương lai, ngoài hình ảnh và ngôn ngữ?",
        "options": {
          "A": "Chỉ âm thanh.",
          "B": "Chỉ xúc giác.",
          "C": "Âm thanh, mùi hương và xúc giác.",
          "D": "Chỉ vị giác."
        },
        "answer": "C"
      }
    ]
  },
  "agent-develops-language-skills-through-simulated-exploration-tasks": {
    "title": "Learning Language by Exploration",
    "collection": "ml-research",
    "content": "Machine learning models typically learn language by training on tasks like predicting the next word in a given text. Researchers trained a language model in a less focused, more human-like way.\n\nWhat’s new: A team at Stanford led by Evan Zheran Liu built areinforcement learning agent that learned language indirectlyby learning to navigate a simulated environment that provides text clues.\n\nKey insight:Reinforcement learning agents learn by discovering actions that maximize rewards. If the training environment provides text that explains how to achieve the highest reward, an agent will benefit by learning to interpret written language. That is, learning to comprehend written instructions will correlate with success in maximizing rewards.\n\nHow it works:The authors built a series of simulated two-dimensional environments usingMinigrid, a reinforcement learning library that contains grid-world environments. They trained the agent to find a particular room according to theDREAMreinforcement learning algorithm.\n\nResults:The authors tested the agent’s ability to generalize to text it had not encountered in training: They trained the agents on layouts that excluded text that described the blue room as the “third office in the second row” and tested it on layouts that included these words. The agent found the blue room every time without checking every room. They also tested the agent in layouts where the hallways were twice as long as in the training set. It always found the blue room. To determine whether the agent understood individual words in the instructions, the authors collected its embeddings of many instructions and trained a single-layer LSTM to extract the instructions from the embeddings. The LSTM achieved a perplexity (a measure of the likelihood that it would predict the next word of instructions that were not in its training data, lower is better) of 1.1, while a randomly-initialized network of the same architecture achieved 4.65 perplexity — an indication that the agent did, indeed, learn to read individual words.\n\nYes, but:The choice of reinforcement-learning algorithm was crucial. When the authors replaced DREAM with eitherRL2orVariBAD), the agent did not learn language. Instead, it learned to check all the doors.\n\nWhy it matters:The discovery that reinforcement-learning agents can learn language without explicit training opens avenues for training language models that use objectives different from traditional text completion.\n\nWe’re thinking:The authors focused on simple language (instructions limited to a few words and a very small vocabulary) that described a single domain (navigating hallways and rooms). There's a long road ahead, but this work could be the start of a more grounded approach to language learning in AI.",
    "qa": [
      {
        "question": "Phương pháp học ngôn ngữ mới được đề cập trong bài viết khác biệt so với phương pháp truyền thống như thế nào?",
        "options": {
          "A": "Sử dụng dữ liệu lớn hơn nhiều để huấn luyện.",
          "B": "Học ngôn ngữ một cách gián tiếp thông qua việc điều hướng trong môi trường mô phỏng.",
          "C": "Tập trung vào việc dự đoán các từ khóa quan trọng trong văn bản.",
          "D": "Sử dụng các thuật toán học sâu phức tạp hơn."
        },
        "answer": "B"
      },
      {
        "question": "Đâu là yếu tố then chốt giúp reinforcement learning agent học được ngôn ngữ trong thí nghiệm này?",
        "options": {
          "A": "Sử dụng một bộ từ vựng phong phú và đa dạng.",
          "B": "Môi trường huấn luyện cung cấp văn bản hướng dẫn để đạt được phần thưởng cao nhất.",
          "C": "Áp dụng một mạng nơ-ron hồi quy (RNN) mạnh mẽ.",
          "D": "Huấn luyện trên một lượng lớn dữ liệu văn bản có sẵn."
        },
        "answer": "B"
      },
      {
        "question": "Môi trường mô phỏng được sử dụng trong thí nghiệm này có tên là gì?",
        "options": {
          "A": "StanfordSim",
          "B": "GridWorld",
          "C": "Minigrid",
          "D": "DREAMSim"
        },
        "answer": "C"
      },
      {
        "question": "Thuật toán reinforcement learning nào đã được sử dụng thành công trong thí nghiệm này?",
        "options": {
          "A": "RL2",
          "B": "VariBAD",
          "C": "DREAM",
          "D": "Q-learning"
        },
        "answer": "C"
      },
      {
        "question": "Kết quả nào cho thấy agent đã học được cách đọc các từ riêng lẻ trong hướng dẫn?",
        "options": {
          "A": "Agent luôn tìm thấy căn phòng màu xanh trong mọi bố cục.",
          "B": "Agent có thể điều hướng trong các hành lang dài hơn so với dữ liệu huấn luyện.",
          "C": "LSTM được huấn luyện trên embeddings của agent đạt được perplexity thấp hơn so với mạng ngẫu nhiên.",
          "D": "Agent có thể dự đoán từ tiếp theo trong văn bản với độ chính xác cao."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì xảy ra khi thuật toán DREAM được thay thế bằng RL2 hoặc VariBAD?",
        "options": {
          "A": "Agent học được ngôn ngữ nhanh hơn.",
          "B": "Agent không học được ngôn ngữ và thay vào đó kiểm tra tất cả các cửa.",
          "C": "Agent chỉ học được một phần của ngôn ngữ.",
          "D": "Agent gặp khó khăn trong việc điều hướng môi trường."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc reinforcement learning agent có thể học ngôn ngữ mà không cần huấn luyện trực tiếp lại quan trọng?",
        "options": {
          "A": "Nó giúp giảm chi phí huấn luyện mô hình ngôn ngữ.",
          "B": "Nó mở ra các hướng đi mới cho việc huấn luyện mô hình ngôn ngữ với các mục tiêu khác với việc hoàn thành văn bản truyền thống.",
          "C": "Nó cho phép tạo ra các mô hình ngôn ngữ có khả năng hiểu ngôn ngữ tự nhiên tốt hơn.",
          "D": "Nó giúp cải thiện hiệu suất của các tác vụ xử lý ngôn ngữ tự nhiên."
        },
        "answer": "B"
      },
      {
        "question": "Hạn chế chính của nghiên cứu này là gì?",
        "options": {
          "A": "Sử dụng một lượng lớn dữ liệu huấn luyện.",
          "B": "Ngôn ngữ được sử dụng đơn giản và giới hạn trong một miền duy nhất.",
          "C": "Thuật toán reinforcement learning được sử dụng quá phức tạp.",
          "D": "Môi trường mô phỏng không đủ thực tế."
        },
        "answer": "B"
      },
      {
        "question": "Perplexity được sử dụng trong bài viết để đánh giá điều gì?",
        "options": {
          "A": "Khả năng điều hướng của agent trong môi trường mô phỏng.",
          "B": "Khả năng hiểu và dự đoán ngôn ngữ của agent.",
          "C": "Độ phức tạp của thuật toán reinforcement learning.",
          "D": "Mức độ gây nhiễu của môi trường mô phỏng."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của nhóm nghiên cứu tại Stanford là gì?",
        "options": {
          "A": "Phát triển một thuật toán reinforcement learning mới.",
          "B": "Xây dựng một môi trường mô phỏng thực tế hơn.",
          "C": "Tìm hiểu cách reinforcement learning agent có thể học ngôn ngữ một cách gián tiếp.",
          "D": "Cải thiện hiệu suất của các mô hình ngôn ngữ hiện có."
        },
        "answer": "C"
      }
    ]
  },
  "agents-of-action": {
    "title": "Mustafa Suleyman",
    "collection": "ml-research",
    "content": "In 2025, AI will have learned to see, it will be way smarter and more accurate, and it will start to do things on your behalf.\n\nToday AI systems struggle to understand our full context. Their perception is limited to the chat window and a fairly narrow set of interactions. They don’t have a full understanding of what we’re doing or aiming for beyond that. To really grasp our intentions, they need to see what we see.\n\nThis capability is now here. AI can sit within the software we use and work alongside us co-browsing. If text was the first modality for interacting with AI, and voice the breakthrough feature of 2024, I think vision will occupy a similar place in 2025. At Microsoft AI, it has been a major priority of mine to create an AI that can work alongside you in your browser, so you can chat through what you’re looking at or working on and make it a true two-way interaction.\n\nVision is a step change, palpably different from the ways we’ve been able to use computers in the past. I can’t wait to see where it goes in the coming months.\n\nAlongside vision, we’ll see enormous progress in reducing hallucinations. This is still a critical blocker for widespread adoption of AI. If people doubt what AI tells them, it severely limits what they’ll use it for. Trust is utterly foundational for AI. The good news is that the quality of models as well as their retrieval and grounding capabilities are still rapidly improving.\n\nWhile I don’t think we’ll eliminate hallucinations entirely, by this time next year, we won’t be fussing about them as much. On most topics, talking to an AI will be at least as reliable as using a search engine and probably more so. This isn’t about a single technical advance, but the persistent accretion of gains across the spectrum. It will make a massive difference.\n\nLastly, we’re entering the agentic era. We’ve been dreaming of this moment for decades. In my book,The Coming Wave: Technology, Power, and the 21st Century’s Greatest Dilemma, I proposed that we start thinking about ACI, orartificially capable intelligence: the moment when AI starts taking concrete actions on behalf of users. Giving AI the ability to take actions marks the moment when AI isn’t just talking to us, it’s doing things. This is a critical change, and it’s right around the corner.\n\nIf we get it right, we’ll be able to, at once, make life easier and calmer while supercharging businesses and personal productivity alike. But agentic capabilities demand the highest standards of safety, security, and responsibility. Meanwhile, creating genuinely useful agents still has many formidable hurdles, not least integrating with myriad other systems.\n\nThe momentum is there. Actions are on their way. 2025 is going to be a big year.\n\nMustafa Suleyman is Chief Executive Officer of Microsoft AI. He co-founded Inflection AI and founded DeepMind Technologies.",
    "qa": [
      {
        "question": "Theo bài viết, điều gì sẽ là bước đột phá quan trọng trong tương tác với AI vào năm 2025, tương tự như giọng nói vào năm 2024?",
        "options": {
          "A": "Khả năng hiểu ngữ cảnh đầy đủ của người dùng.",
          "B": "Khả năng thị giác (vision) của AI.",
          "C": "Khả năng giảm thiểu hoàn toàn ảo giác của AI.",
          "D": "Khả năng tự động thực hiện các hành động thay mặt người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Theo tác giả, điều gì là yếu tố nền tảng (foundational) cho sự chấp nhận rộng rãi của AI?",
        "options": {
          "A": "Tốc độ xử lý dữ liệu nhanh chóng.",
          "B": "Độ tin cậy (trust) của AI.",
          "C": "Khả năng tương tác đa dạng.",
          "D": "Chi phí sử dụng thấp."
        },
        "answer": "B"
      },
      {
        "question": "Thuật ngữ 'ACI' trong cuốn sách 'The Coming Wave' của Mustafa Suleyman đề cập đến điều gì?",
        "options": {
          "A": "Artificial Cognitive Intelligence: Trí tuệ nhân tạo có khả năng nhận thức.",
          "B": "Artificial Capable Intelligence: Trí tuệ nhân tạo có khả năng hành động.",
          "C": "Advanced Computational Intelligence: Trí tuệ nhân tạo tính toán nâng cao.",
          "D": "Automated Creative Intelligence: Trí tuệ nhân tạo sáng tạo tự động."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì là một trong những rào cản lớn nhất đối với việc tạo ra các 'agent' AI thực sự hữu ích?",
        "options": {
          "A": "Sự thiếu hụt dữ liệu huấn luyện chất lượng cao.",
          "B": "Khả năng tích hợp với vô số hệ thống khác nhau.",
          "C": "Chi phí phát triển quá cao.",
          "D": "Sự phản đối từ các chuyên gia trong ngành."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết dự đoán điều gì về 'ảo giác' (hallucinations) của AI trong tương lai gần?",
        "options": {
          "A": "Chúng sẽ bị loại bỏ hoàn toàn.",
          "B": "Chúng sẽ giảm đáng kể và không còn là vấn đề đáng lo ngại.",
          "C": "Chúng sẽ trở nên phức tạp và khó phát hiện hơn.",
          "D": "Chúng sẽ được chấp nhận như một phần tự nhiên của AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo tác giả, điều gì còn hạn chế khả năng của các hệ thống AI hiện tại trong việc hiểu ý định của người dùng?",
        "options": {
          "A": "Sự thiếu hụt về sức mạnh tính toán.",
          "B": "Nhận thức của chúng bị giới hạn trong cửa sổ chat và một số tương tác hẹp.",
          "C": "Sự phức tạp của ngôn ngữ tự nhiên.",
          "D": "Thiếu các thuật toán học sâu tiên tiến."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của Mustafa Suleyman tại Microsoft AI là gì?",
        "options": {
          "A": "Phát triển AI có thể thay thế hoàn toàn con người trong công việc.",
          "B": "Tạo ra AI có thể làm việc cùng người dùng trong trình duyệt.",
          "C": "Nghiên cứu các ứng dụng AI trong lĩnh vực y tế.",
          "D": "Xây dựng một nền tảng AI mở cho tất cả các nhà phát triển."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì sẽ xảy ra khi AI có khả năng thực hiện các hành động thay mặt người dùng?",
        "options": {
          "A": "AI sẽ trở nên nguy hiểm và khó kiểm soát hơn.",
          "B": "AI không chỉ nói chuyện với chúng ta mà còn làm việc.",
          "C": "AI sẽ thay thế hoàn toàn các công cụ tìm kiếm truyền thống.",
          "D": "AI sẽ trở nên đắt đỏ và chỉ dành cho các doanh nghiệp lớn."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, bên cạnh khả năng thị giác, tiến bộ nào khác sẽ đóng vai trò quan trọng trong sự phát triển của AI?",
        "options": {
          "A": "Khả năng tạo ra nội dung sáng tạo.",
          "B": "Khả năng giảm thiểu ảo giác.",
          "C": "Khả năng học hỏi từ dữ liệu không có cấu trúc.",
          "D": "Khả năng tương tác bằng nhiều ngôn ngữ khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Mustafa Suleyman hiện đang giữ chức vụ gì?",
        "options": {
          "A": "Giám đốc điều hành của Google AI.",
          "B": "Giám đốc điều hành của Microsoft AI.",
          "C": "Giám đốc công nghệ của OpenAI.",
          "D": "Giáo sư tại Đại học Stanford về Trí tuệ Nhân tạo."
        },
        "answer": "B"
      }
    ]
  },
  "ai-generated-reference-text-improves-llm-output": {
    "title": "For Better Answers, Generate Reference Text",
    "collection": "ml-research",
    "content": "If you want a model to answer questions correctly, thenenriching the input with reference text retrieved from the webis a reliable way toincrease the accuracy of its output. But the web isn’t necessarily the best source of reference text.\n\nWhat's new:Wenhao Yu at University of Notre Dame and colleagues at Microsoft and University of Southern California used a pretrained language model to generate reference text. They fed that material, along with a question, to a second pretrained language model thatansweredmore accurately than a comparable model that was able to retrieve relevant text from the web.\n\nKey insight:Given a question, documents retrieved from the web, even if they’re relevant, often contain information that doesn’t help to answer it. For instance, considering the question “How tall is Mount Everest?,” the Wikipedia page on Mount Everest contains the answer but also a lot of confusing information such as elevations attained in various attempts to reach the summit and irrelevant information that might distract the model. A language model pretrained on web pages can generate a document that draws on the web but focuses on the question at hand. When fed to a separate language model along with the question, this model-generated reference text can make it easier for that model to answer questions correctly.\n\nHow it works:The authors used a pretrainedInstructGPT(175 billion parameters) to generate reference text related to questions in trivia question-answer datasets such asTriviaQA. They generated answers usingFiD(3 billion parameters), which they had fine-tuned on the dataset plus the reference text. (A given question may have more than one valid answer.)\n\nResults:The authors evaluated their fine-tuned FiD onTriviaQAaccording to the percentage of answers that exactly matched one of a list of correct answers. Provided with generated documents, FiD answered 71.6 percent of the questions correctly compared to 66.3 percent for FiD fine-tuned on TriviaQA and provided with text retrieved from Wikipedia usingDPR.\n\nYes, but:The authors’ approach performed best (74.3 percent) when it had access to both Wikipedia and the generated documents. While generated documents may be better than retrieved documents alone, they worked best together.\n\nWhy it matters:Good reference text substantially improves a language model’s question-answering ability. While a relevant Wikipedia entry is helpful, a document that’s directly related to the question is better — even if that document is a product of text generation.\n\nWe're thinking:Your teachers were right — Wikipedia isn’t the best source.",
    "qa": [
      {
        "question": "Theo bài viết, phương pháp nào giúp tăng độ chính xác cho mô hình trả lời câu hỏi?",
        "options": {
          "A": "Sử dụng mô hình ngôn ngữ lớn nhất hiện có.",
          "B": "Bổ sung thông tin đầu vào bằng văn bản tham khảo lấy từ web.",
          "C": "Loại bỏ thông tin gây nhiễu trong câu hỏi.",
          "D": "Tăng số lượng dữ liệu huấn luyện cho mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu của Wenhao Yu và cộng sự đã sử dụng phương pháp nào để tạo văn bản tham khảo?",
        "options": {
          "A": "Tìm kiếm thông tin trên Wikipedia.",
          "B": "Sử dụng một mô hình ngôn ngữ được huấn luyện trước.",
          "C": "Thu thập thông tin từ nhiều nguồn web khác nhau.",
          "D": "Sử dụng dữ liệu huấn luyện được tạo thủ công."
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm của văn bản tham khảo được tạo bởi mô hình ngôn ngữ so với văn bản lấy từ web là gì?",
        "options": {
          "A": "Luôn chứa thông tin chính xác hơn.",
          "B": "Tập trung vào câu hỏi cụ thể, giảm thông tin gây nhiễu.",
          "C": "Luôn cập nhật thông tin mới nhất.",
          "D": "Dễ dàng tìm kiếm và truy cập hơn."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào đã được sử dụng để tạo văn bản tham khảo trong nghiên cứu?",
        "options": {
          "A": "FiD (3 tỷ tham số).",
          "B": "DPR.",
          "C": "InstructGPT (175 tỷ tham số).",
          "D": "GPT-3."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình nào đã được sử dụng để trả lời câu hỏi sau khi được cung cấp văn bản tham khảo?",
        "options": {
          "A": "InstructGPT (175 tỷ tham số).",
          "B": "DPR.",
          "C": "GPT-3.",
          "D": "FiD (3 tỷ tham số)."
        },
        "answer": "D"
      },
      {
        "question": "Kết quả tốt nhất trong nghiên cứu đạt được khi nào?",
        "options": {
          "A": "Chỉ sử dụng văn bản tham khảo được tạo bởi mô hình.",
          "B": "Chỉ sử dụng văn bản lấy từ Wikipedia.",
          "C": "Sử dụng kết hợp văn bản tham khảo được tạo bởi mô hình và văn bản lấy từ Wikipedia.",
          "D": "Sử dụng một mô hình ngôn ngữ lớn hơn."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, điều gì cải thiện đáng kể khả năng trả lời câu hỏi của mô hình ngôn ngữ?",
        "options": {
          "A": "Sử dụng nhiều dữ liệu huấn luyện hơn.",
          "B": "Văn bản tham khảo tốt.",
          "C": "Tăng kích thước của mô hình.",
          "D": "Sử dụng thuật toán tìm kiếm hiệu quả hơn."
        },
        "answer": "B"
      },
      {
        "question": "Trong thí nghiệm, mô hình FiD được đánh giá dựa trên tiêu chí nào?",
        "options": {
          "A": "Thời gian trả lời câu hỏi.",
          "B": "Độ chính xác của câu trả lời so với câu trả lời của con người.",
          "C": "Phần trăm câu trả lời hoàn toàn trùng khớp với một trong các đáp án đúng.",
          "D": "Khả năng hiểu ngữ cảnh của câu hỏi."
        },
        "answer": "C"
      },
      {
        "question": "So với việc chỉ sử dụng văn bản từ Wikipedia, việc sử dụng văn bản được tạo bởi mô hình ngôn ngữ có ưu điểm gì?",
        "options": {
          "A": "Luôn chứa thông tin đầy đủ và chính xác hơn.",
          "B": "Được tạo ra nhanh chóng và dễ dàng hơn.",
          "C": "Liên quan trực tiếp đến câu hỏi hơn.",
          "D": "Luôn miễn phí và dễ dàng truy cập."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết ngụ ý gì về nguồn thông tin Wikipedia?",
        "options": {
          "A": "Wikipedia là nguồn thông tin tốt nhất cho mọi câu hỏi.",
          "B": "Wikipedia không hữu ích cho việc trả lời câu hỏi.",
          "C": "Wikipedia có thể hữu ích, nhưng không phải lúc nào cũng là nguồn tốt nhất.",
          "D": "Wikipedia luôn chứa thông tin sai lệch."
        },
        "answer": "C"
      }
    ]
  },
  "ai-knows-who-labeled-the-data": {
    "title": "AI Knows Who Labeled the Data",
    "collection": "ml-research",
    "content": "The latest language models are great at answering questions about a given text passage. However, these models are also powerful enough to recognize an individual writer’s style, which can clue them in to the right answers. Newresearchmeasures such annotator bias in several data sets.What’s new:Researchers from Tel Aviv and Bar-Ilan Universities uncovered annotator bias in several crowdsourced data sets.Key insight:Only a few dozen people may generate the lion’s share of examples in a crowdsourced natural-language data set (see graph above). Having an overly small team of annotators introduces bias that can influence a model’s behavior.How it works:Mor Geva, Yoav Goldberg, and Jonathan Berant studied three data sets: MNLI, OpenBookQA, and CommonsenseQA. They fine-tuned the BERT architecture for each of three experiments:\n\nResults:Performance improved an average of 4 percent across the three data sets when input text included an annotator label. The model inferred annotators most accurately in data sets created by fewer contributors. In two of three data sets, mixing in samples from test-set annotators during training improved test accuracy, implying that the model doesn’t generalize to novel annotators.Why it matters:Annotator bias is pernicious and difficult to detect. This work raises a red flag around the number of contributors to data sets used in natural-language research.We’re thinking:Benchmark data sets are used to identify the best-performing models, which drives further research. If the data is biased, it may lead that research astray. Here’s hoping this work inspires further enquiry into sources of bias and ways to assess and mitigate it.",
    "qa": [
      {
        "question": "Nghiên cứu mới tập trung vào vấn đề gì liên quan đến các mô hình ngôn ngữ?",
        "options": {
          "A": "Khả năng trả lời các câu hỏi phức tạp về một đoạn văn bản.",
          "B": "Sự tồn tại của annotator bias (thiên kiến của người chú thích) trong các tập dữ liệu.",
          "C": "Hiệu suất của các mô hình ngôn ngữ trên các tập dữ liệu lớn.",
          "D": "Khả năng nhận diện và tạo ra văn bản theo phong cách của một tác giả cụ thể."
        },
        "answer": "B"
      },
      {
        "question": "Theo nghiên cứu, điều gì có thể gây ra annotator bias trong các tập dữ liệu ngôn ngữ tự nhiên?",
        "options": {
          "A": "Sử dụng quá nhiều người chú thích khác nhau.",
          "B": "Sử dụng một nhóm nhỏ người chú thích tạo ra phần lớn các ví dụ.",
          "C": "Sử dụng các thuật toán chú thích tự động.",
          "D": "Sử dụng các tập dữ liệu quá lớn."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã sử dụng kiến trúc nào để thực hiện các thí nghiệm của họ?",
        "options": {
          "A": "Transformer",
          "B": "Recurrent Neural Network (RNN)",
          "C": "BERT",
          "D": "Generative Adversarial Network (GAN)"
        },
        "answer": "C"
      },
      {
        "question": "Trong các thí nghiệm, điều gì đã xảy ra khi văn bản đầu vào bao gồm nhãn của người chú thích?",
        "options": {
          "A": "Hiệu suất giảm trung bình 4%.",
          "B": "Hiệu suất không thay đổi.",
          "C": "Hiệu suất tăng trung bình 4%.",
          "D": "Mô hình không thể xử lý văn bản."
        },
        "answer": "C"
      },
      {
        "question": "Kết quả nào cho thấy rằng mô hình không khái quát hóa tốt cho những người chú thích mới?",
        "options": {
          "A": "Hiệu suất giảm khi sử dụng dữ liệu từ những người chú thích mới trong quá trình kiểm tra.",
          "B": "Hiệu suất tăng khi sử dụng dữ liệu từ những người chú thích mới trong quá trình kiểm tra.",
          "C": "Hiệu suất không thay đổi khi sử dụng dữ liệu từ những người chú thích mới trong quá trình kiểm tra.",
          "D": "Hiệu suất tăng khi sử dụng dữ liệu từ những người chú thích mới trong quá trình huấn luyện."
        },
        "answer": "A"
      },
      {
        "question": "Tại sao annotator bias lại được coi là 'pernicious' (có hại)?",
        "options": {
          "A": "Vì nó dễ dàng phát hiện và khắc phục.",
          "B": "Vì nó khó phát hiện và có thể ảnh hưởng đến kết quả nghiên cứu.",
          "C": "Vì nó chỉ ảnh hưởng đến một số ít các tập dữ liệu.",
          "D": "Vì nó không ảnh hưởng đến hiệu suất của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu này đưa ra cảnh báo về điều gì liên quan đến các tập dữ liệu được sử dụng trong nghiên cứu ngôn ngữ tự nhiên?",
        "options": {
          "A": "Kích thước của tập dữ liệu.",
          "B": "Số lượng người đóng góp vào tập dữ liệu.",
          "C": "Loại dữ liệu được sử dụng.",
          "D": "Phương pháp chú thích được sử dụng."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì có thể xảy ra nếu dữ liệu benchmark bị thiên vị?",
        "options": {
          "A": "Nó sẽ không ảnh hưởng đến nghiên cứu.",
          "B": "Nó có thể dẫn đến nghiên cứu đi sai hướng.",
          "C": "Nó sẽ giúp xác định các mô hình hoạt động tốt nhất.",
          "D": "Nó sẽ làm cho các mô hình hoạt động tốt hơn."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu của nghiên cứu này là gì?",
        "options": {
          "A": "Cải thiện hiệu suất của các mô hình ngôn ngữ.",
          "B": "Tìm ra các nguồn gốc của bias và cách đánh giá và giảm thiểu chúng.",
          "C": "Tạo ra các tập dữ liệu lớn hơn.",
          "D": "Phát triển các thuật toán chú thích tự động."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu này đã xem xét những tập dữ liệu nào?",
        "options": {
          "A": "MNLI, SQuAD, GLUE",
          "B": "MNLI, OpenBookQA, CommonsenseQA",
          "C": "SQuAD, OpenBookQA, GLUE",
          "D": "GLUE, CommonsenseQA, MNLI"
        },
        "answer": "B"
      }
    ]
  },
  "ai-models-show-promise-in-understanding-human-beliefs-research-reveals": {
    "title": "LLMs Can Get Inside Your Head",
    "collection": "ml-research",
    "content": "Most people understand that others’ mental states can differ from their own. For instance, if your friend leaves a smartphone on a table and you privately put it in your pocket, you understand that your friend continues to believe it was on the table. Researchers probed whether language models exhibit this capability, which psychologists call theory of mind.\n\nWhat's new:Michal Kosinski at Stanford evaluated the ability of large language models tosolve language tasks designed to test for theory of mind in humans. The largest models fared well.\n\nHow it works:The author evaluated the performance of (GPT-1 through GPT-4 as well asBLOOM) on 40 tasks developed for human studies. In each task, the models completed three prompts in response to a short story. Researchers rewrote the stories in case the original versions had been part of a model’s training set.\n\nResults:The models generated the correct response more consistently as they increased in size. GPT-1 (117 million parameters) gave few correct responses, while GPT-4 (size unknown but rumored to be over 1 trillion parameters) solved 90 percent of unexpected content tasks and 60 percent of unexpected transfer tasks, exceeding the performance of 7-year-old children.\n\nWhy it matters: The tasks in this work traditionally are used to establish a theory of mind in children. Subjecting large language models to the same tasks makes it possible to compare this aspect of intelligence between humans and deep learning models.\n\nWe're thinking: If a model exhibits a theory of mind, are you more or less likely to give it a piece of your mind?",
    "qa": [
      {
        "question": "Khái niệm 'theory of mind' (lý thuyết về tâm trí) trong bài viết đề cập đến khả năng gì?",
        "options": {
          "A": "Khả năng hiểu và dự đoán hành vi của người khác dựa trên kiến thức về thế giới.",
          "B": "Khả năng nhận thức rằng trạng thái tinh thần của người khác có thể khác với trạng thái tinh thần của bản thân.",
          "C": "Khả năng giải quyết các vấn đề phức tạp liên quan đến ngôn ngữ và logic.",
          "D": "Khả năng tạo ra các mô hình ngôn ngữ lớn có thể mô phỏng suy nghĩ của con người."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu được đề cập trong bài viết được thực hiện bởi ai?",
        "options": {
          "A": "Một nhóm các nhà tâm lý học tại Đại học Harvard.",
          "B": "Michal Kosinski tại Đại học Stanford.",
          "C": "Các nhà nghiên cứu tại Google AI.",
          "D": "Một liên minh các nhà khoa học từ nhiều trường đại học khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Các mô hình ngôn ngữ lớn được đánh giá trong nghiên cứu này đã được kiểm tra bằng cách nào?",
        "options": {
          "A": "Bằng cách cho chúng chơi các trò chơi chiến lược phức tạp.",
          "B": "Bằng cách yêu cầu chúng hoàn thành các câu chuyện ngắn và trả lời các câu hỏi liên quan đến 'theory of mind'.",
          "C": "Bằng cách đánh giá khả năng dịch thuật của chúng giữa các ngôn ngữ khác nhau.",
          "D": "Bằng cách đo lường tốc độ xử lý thông tin của chúng."
        },
        "answer": "B"
      },
      {
        "question": "Trong nghiên cứu, mô hình ngôn ngữ nào thể hiện hiệu suất tốt nhất trong các bài kiểm tra 'theory of mind'?",
        "options": {
          "A": "GPT-1",
          "B": "GPT-2",
          "C": "BLOOM",
          "D": "GPT-4"
        },
        "answer": "D"
      },
      {
        "question": "GPT-1 có bao nhiêu tham số (parameters)?",
        "options": {
          "A": "1 triệu",
          "B": "117 triệu",
          "C": "1 tỷ",
          "D": "1 nghìn tỷ"
        },
        "answer": "B"
      },
      {
        "question": "Theo kết quả nghiên cứu, GPT-4 đã vượt qua hiệu suất của đối tượng nào trong các bài kiểm tra 'theory of mind'?",
        "options": {
          "A": "Người trưởng thành có trình độ học vấn cao.",
          "B": "Trẻ em 7 tuổi.",
          "C": "Các chuyên gia về trí tuệ nhân tạo.",
          "D": "Các loài linh trưởng bậc cao."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc sử dụng các bài kiểm tra 'theory of mind' cho các mô hình ngôn ngữ lớn là gì?",
        "options": {
          "A": "Để cải thiện khả năng dịch thuật của các mô hình.",
          "B": "Để so sánh khía cạnh trí thông minh này giữa con người và các mô hình học sâu.",
          "C": "Để phát triển các mô hình ngôn ngữ có thể tương tác tự nhiên hơn với con người.",
          "D": "Để xác định xem các mô hình có thể vượt qua bài kiểm tra Turing hay không."
        },
        "answer": "B"
      },
      {
        "question": "Trong bài viết, cụm từ 'unexpected content tasks' và 'unexpected transfer tasks' đề cập đến điều gì?",
        "options": {
          "A": "Các loại bài tập ngôn ngữ mà mô hình chưa từng được huấn luyện trước đó.",
          "B": "Các bài kiểm tra được thiết kế để đánh giá khả năng của mô hình trong việc xử lý thông tin bất ngờ và chuyển giao kiến thức.",
          "C": "Các lỗi thường gặp trong quá trình huấn luyện các mô hình ngôn ngữ lớn.",
          "D": "Các phương pháp để tăng cường hiệu suất của mô hình trong các tác vụ ngôn ngữ thông thường."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì xảy ra với độ chính xác của các mô hình khi kích thước của chúng tăng lên?",
        "options": {
          "A": "Độ chính xác giảm xuống.",
          "B": "Độ chính xác không thay đổi.",
          "C": "Độ chính xác tăng lên.",
          "D": "Độ chính xác tăng lên đến một ngưỡng nhất định rồi giảm xuống."
        },
        "answer": "C"
      },
      {
        "question": "Câu hỏi 'If a model exhibits a theory of mind, are you more or less likely to give it a piece of your mind?' (Nếu một mô hình thể hiện lý thuyết về tâm trí, bạn có nhiều khả năng hay ít khả năng hơn để 'cho nó một phần tâm trí' của bạn?) mang ý nghĩa gì?",
        "options": {
          "A": "Liệu chúng ta có dễ dàng chia sẻ suy nghĩ và cảm xúc của mình với một mô hình có khả năng hiểu được chúng hay không.",
          "B": "Liệu chúng ta có nên tin tưởng một mô hình có khả năng thao túng suy nghĩ của chúng ta hay không.",
          "C": "Liệu chúng ta có nên lo lắng về việc các mô hình AI sẽ thay thế con người trong công việc hay không.",
          "D": "Liệu chúng ta có nên đầu tư vào việc phát triển các mô hình AI có khả năng hiểu được cảm xúc của con người hay không."
        },
        "answer": "A"
      }
    ]
  },
  "ai-learns-to-mimic-conversational-pauses-and-interruptions": {
    "title": "The Sound of Conversation",
    "collection": "ml-research",
    "content": "In spoken conversation, people naturally take turns amid interjections, overlaps, and other patterns that aren’t strictly verbal. A new approach generated natural-sounding — though not necessarily semantically coherent — audio dialogs without training on text transcriptions that mark when one party should stop speaking and the other should chime in.\n\nWhat's new:Tu Anh Nguyen and colleagues at Meta, France’s National Institute for Research in Digital Science and Technology, and École des Hautes Études en Sciences Sociales introducedDialogue Transformer Language Model(DLM), a system that learned to incorporate the interruptions, pauses, and inflections of conversational speech into audio dialogues. You can listen to exampleshere.\n\nKey insight:Prior efforts to model dialogue were based on text, but text datasets omit information that’s unique to spoken interactions. Training directly on recordings of spoken dialogue can enable models to learn this additional mode of expression so they can mimic face-to-face conversation more naturally.\n\nHow it works:The system encoded two audio signals — two sides of a spoken conversation — into tokens. It processed each token stream through a separate transformer and decoded the tokens back to audio signals. The transformers were trained onFisher English Training Speech, a dataset that comprises over 10,000 telephone conversations, an average of 10 minutes long, recorded using a separate audio channel for each participant.\n\nResults:Crowdsourced evaluators compared DLM to a similar approach that used a single transformer to process both channels of conversation. They rated naturalness of turn-taking and meaningfulness on a 1 to 5 scale. (Ground-truth dialogs scored around 4.25 for both criteria.) DLM performed relatively well in turn-taking though poorly in meaningful output. For turn-taking, DLM achieved 3.86 while the single transformer achieved 3.46. For meaningfulness, DLM achieved 2.71, while the single transformer achieved 2.46.\n\nWhy it matters:Two transformers can model a pair of participants in conversation (or other interaction) more effectively than one. Connecting them via cross attention layers enables them to be aware of one another’s activity without needing to predict it. This simplifies the task of modeling their interactions while avoiding potentially confounding variables such as who said what.\n\nWe're thinking:The system’s ability to mimic the ebb and flow of conversation is impressive, but its verbal output is largely gibberish. To be fair, training on only 1,700 hours of audio conversation may not be expected to impart much about semantics. We look forward to an update that produces more cogent spoken conversation.",
    "qa": [
      {
        "question": "Phương pháp mới được giới thiệu trong bài viết tạo ra loại hội thoại âm thanh nào?",
        "options": {
          "A": "Hội thoại có ngữ nghĩa mạch lạc và tự nhiên.",
          "B": "Hội thoại nghe tự nhiên nhưng không nhất thiết có ngữ nghĩa mạch lạc.",
          "C": "Hội thoại được tạo ra từ bản ghi văn bản.",
          "D": "Hội thoại được tạo ra bằng cách dự đoán lượt lời của người nói."
        },
        "answer": "B"
      },
      {
        "question": "DLM (Dialogue Transformer Language Model) được phát triển bởi những tổ chức nào?",
        "options": {
          "A": "Meta và Google.",
          "B": "Meta, Viện Nghiên cứu Khoa học Kỹ thuật Số Quốc gia Pháp, và École des Hautes Études en Sciences Sociales.",
          "C": "Google và École des Hautes Études en Sciences Sociales.",
          "D": "Viện Nghiên cứu Khoa học Kỹ thuật Số Quốc gia Pháp và Google."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính giữa phương pháp DLM và các phương pháp mô hình hóa hội thoại trước đây là gì?",
        "options": {
          "A": "DLM sử dụng dữ liệu văn bản thay vì dữ liệu âm thanh.",
          "B": "DLM được đào tạo trực tiếp trên bản ghi âm hội thoại.",
          "C": "DLM sử dụng một transformer duy nhất để xử lý cả hai kênh hội thoại.",
          "D": "DLM tập trung vào việc tạo ra hội thoại có ngữ nghĩa mạch lạc."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu nào được sử dụng để huấn luyện các transformer trong hệ thống DLM?",
        "options": {
          "A": "Dữ liệu văn bản từ các cuộc trò chuyện trực tuyến.",
          "B": "Fisher English Training Speech, một tập dữ liệu gồm hơn 10,000 cuộc điện thoại.",
          "C": "Dữ liệu âm thanh từ các bộ phim và chương trình truyền hình.",
          "D": "Dữ liệu được tạo ra bằng cách tổng hợp giọng nói."
        },
        "answer": "B"
      },
      {
        "question": "Trong quá trình đánh giá, DLM thể hiện như thế nào so với phương pháp sử dụng một transformer duy nhất về khả năng chuyển lượt lời?",
        "options": {
          "A": "DLM kém hơn đáng kể về khả năng chuyển lượt lời.",
          "B": "DLM tốt hơn về khả năng chuyển lượt lời.",
          "C": "DLM và phương pháp sử dụng một transformer duy nhất có kết quả tương đương.",
          "D": "DLM chỉ tốt hơn về khả năng chuyển lượt lời trong một số trường hợp nhất định."
        },
        "answer": "B"
      },
      {
        "question": "Trong quá trình đánh giá, DLM thể hiện như thế nào so với phương pháp sử dụng một transformer duy nhất về ý nghĩa của nội dung?",
        "options": {
          "A": "DLM tốt hơn đáng kể về ý nghĩa của nội dung.",
          "B": "DLM kém hơn về ý nghĩa của nội dung.",
          "C": "DLM và phương pháp sử dụng một transformer duy nhất có kết quả tương đương.",
          "D": "DLM chỉ tốt hơn về ý nghĩa của nội dung trong một số trường hợp nhất định."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc sử dụng hai transformer lại hiệu quả hơn một trong việc mô hình hóa hội thoại?",
        "options": {
          "A": "Hai transformer có thể dự đoán chính xác hơn lượt lời của người nói.",
          "B": "Hai transformer có thể nhận biết hoạt động của nhau thông qua các lớp cross attention mà không cần dự đoán.",
          "C": "Một transformer duy nhất không đủ khả năng xử lý lượng dữ liệu lớn.",
          "D": "Hai transformer giúp đơn giản hóa việc tạo ra hội thoại có ngữ nghĩa mạch lạc."
        },
        "answer": "B"
      },
      {
        "question": "Hạn chế lớn nhất của hệ thống DLM được đề cập trong bài viết là gì?",
        "options": {
          "A": "Khả năng bắt chước nhịp điệu của cuộc trò chuyện còn hạn chế.",
          "B": "Đầu ra bằng lời nói chủ yếu là vô nghĩa.",
          "C": "Hệ thống yêu cầu lượng dữ liệu huấn luyện rất lớn.",
          "D": "Hệ thống không thể xử lý các cuộc trò chuyện có nhiều hơn hai người tham gia."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì có thể cải thiện khả năng tạo ra hội thoại có ý nghĩa của hệ thống DLM?",
        "options": {
          "A": "Sử dụng một transformer mạnh mẽ hơn.",
          "B": "Huấn luyện trên lượng dữ liệu âm thanh hội thoại lớn hơn.",
          "C": "Tập trung vào việc cải thiện khả năng bắt chước nhịp điệu của cuộc trò chuyện.",
          "D": "Sử dụng dữ liệu văn bản kết hợp với dữ liệu âm thanh."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích chính của việc sử dụng các lớp cross attention giữa hai transformer là gì?",
        "options": {
          "A": "Giúp dự đoán chính xác nội dung của cuộc trò chuyện.",
          "B": "Cho phép các transformer nhận biết hoạt động của nhau mà không cần dự đoán.",
          "C": "Giảm thiểu lượng dữ liệu cần thiết để huấn luyện.",
          "D": "Tăng tốc độ xử lý của hệ thống."
        },
        "answer": "B"
      }
    ]
  },
  "ai-system-make-a-video-generates-video-from-text": {
    "title": "Text to Video Without Text-Video Training Data",
    "collection": "ml-research",
    "content": "Text-to-image generators like DALL·E 2, Midjourney, and Stable Diffusion arewinning art contestsandworrying artists. A new approach brings the magic of text-to-image generation to video.\n\nWhat's new:Make-A-Video, a system built by Uriel Singer and colleagues at Meta, turns text prompts into high-resolution videos without training on text-video pairs. You can see its outputhere.\n\nKey insight:While billions of text-image pairs are available to train atext-to-image generator, text-video pairs are too scarce to train a video equivalent. A model can learn relationships between words and pictures via pretraining on text-image pairs. Then it can be adapted for video by adding further layers that process image patches across frames and — while keeping the pretrained layers fixed — fine-tuning the new layers on videos, which are plentiful. In this way, a system can generate videos using knowledge it learned from text-image pairs.\n\nHow it works:The authors pretrained a series of models (one transformer and fourU-Netdiffusion models) to generate images from text, generate in-between video frames, and boost image resolution. To pretrain the text-to-image models, they used2.3 billion text-image pairs. After pretraining, they modified some of the models to process sequences of video frames: On top of each pretrained convolutional layer, the authors stacked a 1D convolutional layer that processed a grid of pixels in each frame; and on top of each pretrained attention layer, they stacked a 1D attention layer that, likewise, processed a grid of pixels in each frame. To fine-tune or train the modified models on video, they used 20 millioninternetvideos.\n\nResults:The authors compared their system’s output to that of the previous state of the art,CogVideo, which takes a similar approach but requires training on text-video pairs. Crowdworkers supplied 300 prompts and judged the output of the author’s system to be of higher quality 77.15 percent of the time and to better fit the text 71.19 percent of the time.\n\nWhy it matters:Text-to-image generators already transform text into high-quality images, so there’s no need to train a video generator to do the same thing. The authors’ approach enabled their system to learn about things in the world from text-image pairs, and then to learn how those things move from unlabeled videos.\n\nWe're thinking:The Ng family’s penchant fordrawing pandasis about to undergo another revolution!",
    "qa": [
      {
        "question": "Hệ thống Make-A-Video của Meta tạo ra video từ văn bản mà không cần huấn luyện trên dữ liệu nào?",
        "options": {
          "A": "Các cặp văn bản-hình ảnh có độ phân giải cao.",
          "B": "Các cặp văn bản-video.",
          "C": "Các video không nhãn.",
          "D": "Các hình ảnh tĩnh được chú thích bằng văn bản."
        },
        "answer": "B"
      },
      {
        "question": "Điểm mấu chốt trong phương pháp của Make-A-Video là gì?",
        "options": {
          "A": "Sử dụng lượng lớn dữ liệu văn bản-video để huấn luyện trực tiếp.",
          "B": "Tận dụng kiến thức từ việc huấn luyện trước trên các cặp văn bản-hình ảnh, sau đó điều chỉnh cho video.",
          "C": "Áp dụng các thuật toán nén video tiên tiến để giảm dung lượng dữ liệu huấn luyện.",
          "D": "Sử dụng mạng nơ-ron biến đổi (transformer) phức tạp hơn để xử lý video."
        },
        "answer": "B"
      },
      {
        "question": "Make-A-Video sử dụng bao nhiêu cặp văn bản-hình ảnh để huấn luyện trước các mô hình?",
        "options": {
          "A": "20 triệu.",
          "B": "2.3 triệu.",
          "C": "2.3 tỷ.",
          "D": "20 tỷ."
        },
        "answer": "C"
      },
      {
        "question": "Sau khi huấn luyện trước, các mô hình của Make-A-Video được điều chỉnh trên dữ liệu nào?",
        "options": {
          "A": "Các cặp văn bản-hình ảnh mới.",
          "B": "Các cặp văn bản-video được chọn lọc.",
          "C": "Các video trên internet không nhãn.",
          "D": "Các hình ảnh được tạo ra từ văn bản."
        },
        "answer": "C"
      },
      {
        "question": "Để xử lý chuỗi khung hình video, các tác giả đã thêm lớp gì vào các lớp tích chập (convolutional layer) và lớp chú ý (attention layer) đã được huấn luyện trước?",
        "options": {
          "A": "Lớp tích chập 2D và lớp chú ý 2D.",
          "B": "Lớp tích chập 3D và lớp chú ý 3D.",
          "C": "Lớp tích chập 1D và lớp chú ý 1D.",
          "D": "Lớp tích chập ngược và lớp chú ý ngược."
        },
        "answer": "C"
      },
      {
        "question": "Make-A-Video đã sử dụng bao nhiêu video trên internet để tinh chỉnh hoặc huấn luyện các mô hình đã được sửa đổi?",
        "options": {
          "A": "2.3 tỷ.",
          "B": "2.3 triệu.",
          "C": "20 triệu.",
          "D": "20 tỷ."
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống nào được sử dụng để so sánh với Make-A-Video trong bài viết?",
        "options": {
          "A": "DALL·E 2.",
          "B": "Midjourney.",
          "C": "Stable Diffusion.",
          "D": "CogVideo."
        },
        "answer": "D"
      },
      {
        "question": "Theo đánh giá của người dùng, Make-A-Video vượt trội hơn hệ thống so sánh về mặt nào?",
        "options": {
          "A": "Tốc độ xử lý video.",
          "B": "Độ phân giải video.",
          "C": "Chất lượng video và độ phù hợp với văn bản.",
          "D": "Khả năng tạo ra các hiệu ứng đặc biệt."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhấn mạnh lợi ích của phương pháp Make-A-Video là gì?",
        "options": {
          "A": "Giảm chi phí huấn luyện mô hình video.",
          "B": "Tăng cường tính bảo mật cho dữ liệu video.",
          "C": "Cho phép hệ thống học hỏi về thế giới từ các cặp văn bản-hình ảnh và cách các vật thể di chuyển từ video không nhãn.",
          "D": "Tạo ra video với độ phân giải cực cao."
        },
        "answer": "C"
      },
      {
        "question": "Các mô hình U-Net diffusion được sử dụng trong Make-A-Video có vai trò gì?",
        "options": {
          "A": "Tạo ra văn bản từ hình ảnh.",
          "B": "Tạo ra hình ảnh từ văn bản, tạo khung hình video trung gian và tăng độ phân giải hình ảnh.",
          "C": "Phân tích ngữ nghĩa của văn bản đầu vào.",
          "D": "Nén dữ liệu video để giảm dung lượng lưu trữ."
        },
        "answer": "B"
      }
    ]
  },
  "ai-systems-from-stability-ai-and-shutterstock-transform-2d-images-into-3d-meshes-in-seconds": {
    "title": "2D-to-3D Goes Mainstream",
    "collection": "ml-research",
    "content": "Traditionally, building 3D meshes for gaming, animation, product design, architecture, and the like has been labor-intensive. Now the ability to generate 3D meshes from a single image is widely available.\n\nWhat’s new:Two companies launched systems that produce a 3D mesh from one image. Stability AI releasedSF3D. Itsweightsandcodeare freely available to users with annual revenue under $1 million. Meanwhile, Shutterstocklauncheda service that provides a similar capability.\n\nHow it works:Stability AI’s SF3D generates output in a half-second, while Shutterstock’s service takes around 10 seconds.\n\nBehind the news:These releases arrived amid a flurry of recent works that aim to tackle similar problems. Most are based onLarge Reconstruction Model(LRM), proposed by Adobe in late 2023, which produces a 3D mesh and surface texture from a single image in less than 5 seconds. Follow-upworktrained LRM on real-world images in addition to the images of synthetic 3D meshes used in the original work and then reproduced LRM’s capabilities in anopen source model. Further research extended the model tolearn from generated videos. Stability AI’s new system addresses issues in its own previousworkthat was based on LRM.\n\nWhy it matters:SF3D replacesNeRF, a 2D-to-3D approach proposed in 2020 that serves as the basis for LRM and several other methods, with DMTet, which incorporates surface properties to achieve smoother meshes and better account for light reflecting off object surfaces.\n\nWe’re thinking:3D generation is advancing rapidly. To ignore this technology would be a mesh-take!",
    "qa": [
      {
        "question": "Trước đây, việc xây dựng mô hình 3D cho các lĩnh vực như game, hoạt hình thường tốn rất nhiều:",
        "options": {
          "A": "Thời gian và chi phí đầu tư phần mềm.",
          "B": "Công sức và thời gian lao động.",
          "C": "Tài nguyên máy tính và năng lượng.",
          "D": "Kỹ năng chuyên môn và kinh nghiệm."
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào đã phát hành hệ thống SF3D cho phép tạo mô hình 3D từ một ảnh duy nhất với điều kiện doanh thu hàng năm dưới 1 triệu đô la?",
        "options": {
          "A": "Adobe.",
          "B": "Stability AI.",
          "C": "Shutterstock.",
          "D": "Google."
        },
        "answer": "B"
      },
      {
        "question": "Shutterstock cung cấp dịch vụ tạo mô hình 3D từ một ảnh duy nhất mất khoảng bao lâu?",
        "options": {
          "A": "Nửa giây.",
          "B": "Dưới 5 giây.",
          "C": "Khoảng 10 giây.",
          "D": "Vài phút."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình Large Reconstruction Model (LRM) được đề xuất bởi công ty nào?",
        "options": {
          "A": "Stability AI.",
          "B": "Shutterstock.",
          "C": "Adobe.",
          "D": "Google."
        },
        "answer": "C"
      },
      {
        "question": "LRM tạo ra mô hình 3D và bề mặt kết cấu từ một ảnh duy nhất trong khoảng thời gian nào?",
        "options": {
          "A": "Nửa giây.",
          "B": "Dưới 5 giây.",
          "C": "Khoảng 10 giây.",
          "D": "Vài phút."
        },
        "answer": "B"
      },
      {
        "question": "Công nghệ nào đã được SF3D thay thế để tạo ra các mô hình 3D mượt mà hơn và phản ánh ánh sáng tốt hơn?",
        "options": {
          "A": "LRM.",
          "B": "DMTet.",
          "C": "NeRF.",
          "D": "Large Language Model."
        },
        "answer": "C"
      },
      {
        "question": "DMTet cải thiện khả năng tạo mô hình 3D bằng cách kết hợp yếu tố nào?",
        "options": {
          "A": "Thuật toán nén dữ liệu.",
          "B": "Độ phân giải hình ảnh cao.",
          "C": "Thuộc tính bề mặt.",
          "D": "Số lượng đa giác trong mô hình."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích của việc huấn luyện LRM trên hình ảnh thực tế ngoài hình ảnh 3D tổng hợp là gì?",
        "options": {
          "A": "Tăng tốc độ xử lý.",
          "B": "Cải thiện độ chính xác và tính chân thực.",
          "C": "Giảm dung lượng lưu trữ.",
          "D": "Đơn giản hóa quy trình tạo mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống mới của Stability AI giải quyết vấn đề gì trong công việc trước đây của họ?",
        "options": {
          "A": "Tốc độ xử lý chậm.",
          "B": "Chất lượng mô hình chưa cao.",
          "C": "Khả năng tương thích kém.",
          "D": "Chi phí vận hành đắt đỏ."
        },
        "answer": "B"
      },
      {
        "question": "Câu nào sau đây thể hiện quan điểm của tác giả về sự phát triển của công nghệ tạo mô hình 3D?",
        "options": {
          "A": "Công nghệ này vẫn còn nhiều hạn chế và cần thêm thời gian để phát triển.",
          "B": "Việc bỏ qua công nghệ này là một sai lầm.",
          "C": "Công nghệ này chỉ phù hợp với một số lĩnh vực nhất định.",
          "D": "Công nghệ này sẽ sớm thay thế hoàn toàn các phương pháp truyền thống."
        },
        "answer": "B"
      }
    ]
  },
  "ai-with-a-sense-of-style": {
    "title": "AI With a Sense of Style",
    "collection": "ml-research",
    "content": "The process known as image-to-image style transfer — mapping, say, the character of a painting’s brushstrokes onto a photo — can render inconsistent results. When they apply the styles of different artists to the same target content, they may produce similar-looking pictures. Conversely, when they apply the same style to different targets, such as successive video frames, they may produce images with unrelated shapes and colors. A new approach aims to address these issues.What’s new:Min Jin Chong and David Forsyth at University of Illinois at Urbana-Champaign proposedGANs N’ Roses, a style transfer system designed to maintain the distinctive qualities of input styles and contents.Key insight:Earlier style transfer systems falter because they don't clearly differentiate style from content. Style can be defined as whatever doesn’t change when an image undergoes common data-augmentation techniques such as scaling and rotation. Content can be defined as whatever is changed by such operations. A loss function that reflects these principles should produce more consistent results.How it works:Like other generative adversarial networks, GANs N’ Roses includes a discriminator that tries to distinguish synthetic anime images from actual artworks and a generator that aims to fool the discriminator. The architecture is aStyleGAN2with a modified version ofCycleGAN’s loss function. The authors trained it to transfer anime styles to portrait photos usingselfie2anime, a collection of unmatched selfies and anime faces. The authors created batches of seven anime faces and seven augmented versions of a single selfie (flipped, rotated, scaled, and the like).\n\nResults:Qualitatively, the system translated different selfies into corresponding anime poses and face sizes, and different styles into a variety of colors, hair styles, and eye sizes. Moreover, without training the networks on video, the authors rendered a series of consecutive video frames. Subjectively, those videos were smooth, while those produced by CouncilGAN’s frames showed inconsistent colors and hairstyles. In quantitative evaluations comparingFrechet Inception Distance(FID), a measure of similarity between real and generated images in which lower is better, GANs N’ Roses achieved 34.4 FID whileCouncilGANachieved 38.1 FID. ComparingLearned Perceptual Image Patch Similarity(LPIPS), a measure of diversity across styles in which higher is better, GANs N’ Roses scored .505 LPIPS while CouncilGAN scored .430 LPIPS.Why it matters:If style transfer is cool, better style transfer is cooler. The ability to isolate style and content — and thus to change content while keeping style consistent — is a precondition for extending style transfer to video.We’re thinking:The next frontier: Neural networks that not only know the difference between style and content but also have good taste.",
    "qa": [
      {
        "question": "Vấn đề chính mà phương pháp image-to-image style transfer hiện tại gặp phải là gì?",
        "options": {
          "A": "Không thể áp dụng cho video.",
          "B": "Kết quả không nhất quán khi áp dụng các phong cách khác nhau hoặc cùng một phong cách lên các đối tượng khác nhau.",
          "C": "Đòi hỏi lượng dữ liệu huấn luyện quá lớn.",
          "D": "Chỉ hoạt động tốt với ảnh tĩnh, không hiệu quả với ảnh động."
        },
        "answer": "B"
      },
      {
        "question": "GANs N’ Roses tiếp cận vấn đề style transfer bằng cách nào?",
        "options": {
          "A": "Sử dụng một kiến trúc mạng nơ-ron hoàn toàn mới.",
          "B": "Phân biệt rõ ràng giữa style (phong cách) và content (nội dung).",
          "C": "Tăng cường khả năng nhận diện khuôn mặt của mạng.",
          "D": "Áp dụng các kỹ thuật data augmentation phức tạp hơn."
        },
        "answer": "B"
      },
      {
        "question": "Theo GANs N’ Roses, 'style' được định nghĩa là gì?",
        "options": {
          "A": "Những yếu tố thay đổi khi áp dụng các phép biến đổi hình ảnh thông thường.",
          "B": "Những yếu tố không thay đổi khi áp dụng các phép biến đổi hình ảnh thông thường.",
          "C": "Màu sắc và kết cấu của hình ảnh.",
          "D": "Hình dạng và bố cục của hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "GANs N’ Roses sử dụng kiến trúc mạng nào làm nền tảng?",
        "options": {
          "A": "CycleGAN",
          "B": "StyleGAN",
          "C": "StyleGAN2",
          "D": "GAN"
        },
        "answer": "C"
      },
      {
        "question": "GANs N’ Roses được huấn luyện trên bộ dữ liệu nào?",
        "options": {
          "A": "Một bộ dữ liệu ảnh phong cảnh.",
          "B": "Một bộ dữ liệu ảnh chân dung chất lượng cao.",
          "C": "selfie2anime, một bộ sưu tập ảnh selfie và ảnh anime không khớp.",
          "D": "Một bộ dữ liệu video anime."
        },
        "answer": "C"
      },
      {
        "question": "Trong quá trình huấn luyện, GANs N’ Roses tạo ra các batch dữ liệu như thế nào?",
        "options": {
          "A": "Các cặp ảnh selfie và ảnh anime tương ứng.",
          "B": "Các batch gồm ảnh selfie và ảnh phong cảnh.",
          "C": "Các batch gồm bảy ảnh anime và bảy phiên bản augmented của một ảnh selfie.",
          "D": "Các batch gồm ảnh anime và ảnh được tạo ra bởi các mô hình style transfer khác."
        },
        "answer": "C"
      },
      {
        "question": "Chỉ số FID (Frechet Inception Distance) được sử dụng để đánh giá điều gì?",
        "options": {
          "A": "Độ đa dạng giữa các phong cách khác nhau.",
          "B": "Độ mượt của video được tạo ra.",
          "C": "Độ tương đồng giữa ảnh thật và ảnh được tạo ra.",
          "D": "Khả năng nhận diện khuôn mặt của mô hình."
        },
        "answer": "C"
      },
      {
        "question": "Chỉ số LPIPS (Learned Perceptual Image Patch Similarity) được sử dụng để đánh giá điều gì?",
        "options": {
          "A": "Độ tương đồng giữa ảnh thật và ảnh được tạo ra.",
          "B": "Độ đa dạng giữa các phong cách khác nhau.",
          "C": "Độ mượt của video được tạo ra.",
          "D": "Khả năng tái tạo chi tiết của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả định lượng cho thấy GANs N’ Roses vượt trội hơn CouncilGAN ở điểm nào?",
        "options": {
          "A": "Chỉ số FID cao hơn và chỉ số LPIPS thấp hơn.",
          "B": "Chỉ số FID thấp hơn và chỉ số LPIPS thấp hơn.",
          "C": "Chỉ số FID cao hơn và chỉ số LPIPS cao hơn.",
          "D": "Chỉ số FID thấp hơn và chỉ số LPIPS cao hơn."
        },
        "answer": "D"
      },
      {
        "question": "Theo bài viết, khả năng phân biệt style và content có ý nghĩa gì trong việc phát triển style transfer?",
        "options": {
          "A": "Giúp giảm chi phí tính toán.",
          "B": "Là tiền đề để mở rộng style transfer sang video.",
          "C": "Tăng độ chính xác của việc nhận diện khuôn mặt.",
          "D": "Cho phép tạo ra những phong cách độc đáo hơn."
        },
        "answer": "B"
      }
    ]
  },
  "ai21-labs-jamba-1-5-outpaces-transformers-in-long-text-processing": {
    "title": "Long Context Gets Up to Speed",
    "collection": "ml-research",
    "content": "A new open weights model generates tokens faster than current transformers, especially when processing long inputs.\n\nWhat’s new:AI21 Labs releasedJamba 1.5, an update of its earlierJamba. It comes inMiniandLargeversions and boasts a relatively large (and validated) input context length of 256,000 tokens. The model weights arefreeto users who have annual recurring revenue under $50 million and available on several cloud platforms including Google Cloud Vertex AI, Hugging Face, and Microsoft Azure.\n\nHow it works:Jamba 1.5 is a hybrid architecture made up of transformer,mamba, andmixture of experts(MoE) layers. Unlike transformer layers, in which processing power scales quadratically as input length increases, the mamba layers enable the required processing power to scale linearly as input length increases without requiring workarounds like sparse attention and sliding windows. The MoE layers are composed of many fully connected sublayers, of which only a small number are used to process a given input. Jamba 1.5 Mini has roughly 50 billion parameters but uses only 12 billion at a time, while Jamba 1.5 Large has around 400 billion parameters but uses only 94 billion at a time.\n\nResults:Both versions of Jamba 1.5 produced output tokens faster than other models (running on identical hardware), especially given longer inputs. However, the larger version achieved lower performance on popular benchmarks than other open models.\n\nBehind the news:The mamba architecture, which is designed to enable processing to scale linearly with longer input lengths, has been a subject of much research since its release in late 2023. Notably,Mamba-2,Mamba-2-Hybrid, andZambacombined mamba layers with attention layers with varying degrees of success.\n\nWhy it matters:The originalMambamodel was much faster and equally accurate compared to transformers up to 2.8 billion parameters. But how the mamba architecture compared to transformers at larger scales was an open question. Jamba 1.5 shows that the combination of mamba and transformer layers can yield higher speed in larger models — although the results don’t yet exceed those of comparably sized transformers.\n\nWe’re thinking:While hardware companies like Groq and SambaNova are accelerating LLMs, software innovations like Jamba may enable further speed-ups.",
    "qa": [
      {
        "question": "AI21 Labs vừa phát hành phiên bản cập nhật nào của mô hình Jamba?",
        "options": {
          "A": "Jamba 1.0",
          "B": "Jamba 1.5",
          "C": "Jamba 2.0",
          "D": "Jamba-2-Hybrid"
        },
        "answer": "B"
      },
      {
        "question": "Độ dài ngữ cảnh đầu vào tối đa (input context length) được xác nhận của Jamba 1.5 là bao nhiêu token?",
        "options": {
          "A": "128,000 tokens",
          "B": "256,000 tokens",
          "C": "512,000 tokens",
          "D": "1,024,000 tokens"
        },
        "answer": "B"
      },
      {
        "question": "Kiến trúc hybrid của Jamba 1.5 bao gồm những thành phần nào?",
        "options": {
          "A": "Transformer và Mamba",
          "B": "Mamba và Mixture of Experts (MoE)",
          "C": "Transformer và Mixture of Experts (MoE)",
          "D": "Transformer, Mamba và Mixture of Experts (MoE)"
        },
        "answer": "D"
      },
      {
        "question": "Ưu điểm chính của lớp Mamba so với lớp Transformer trong Jamba 1.5 là gì?",
        "options": {
          "A": "Tăng độ chính xác của mô hình",
          "B": "Giảm yêu cầu về sức mạnh xử lý khi tăng độ dài đầu vào",
          "C": "Tăng số lượng tham số của mô hình",
          "D": "Đơn giản hóa kiến trúc mô hình"
        },
        "answer": "B"
      },
      {
        "question": "Jamba 1.5 Mini sử dụng bao nhiêu tham số tại một thời điểm?",
        "options": {
          "A": "50 tỷ",
          "B": "400 tỷ",
          "C": "12 tỷ",
          "D": "94 tỷ"
        },
        "answer": "C"
      },
      {
        "question": "Kết quả thử nghiệm cho thấy điều gì về tốc độ tạo token của Jamba 1.5 so với các mô hình khác?",
        "options": {
          "A": "Chậm hơn đáng kể",
          "B": "Nhanh hơn, đặc biệt với đầu vào dài",
          "C": "Tương đương",
          "D": "Chỉ nhanh hơn với đầu vào ngắn"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào được thiết kế để cho phép xử lý tỷ lệ tuyến tính với độ dài đầu vào dài hơn?",
        "options": {
          "A": "Transformer",
          "B": "Mixture of Experts (MoE)",
          "C": "Mamba",
          "D": "Attention layers"
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc kết hợp Mamba và Transformer layers trong Jamba 1.5 là gì?",
        "options": {
          "A": "Giảm kích thước mô hình",
          "B": "Tăng độ chính xác trên các benchmarks",
          "C": "Tăng tốc độ xử lý cho các mô hình lớn",
          "D": "Đơn giản hóa quá trình huấn luyện"
        },
        "answer": "C"
      },
      {
        "question": "Mô hình Mamba ban đầu so sánh với Transformer như thế nào về tốc độ và độ chính xác (với số lượng tham số nhỏ hơn 2.8 tỷ)?",
        "options": {
          "A": "Chậm hơn và kém chính xác hơn",
          "B": "Nhanh hơn và chính xác hơn",
          "C": "Nhanh hơn và có độ chính xác tương đương",
          "D": "Chậm hơn và có độ chính xác tương đương"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến những công ty nào đang đẩy nhanh tiến độ phát triển LLMs thông qua phần cứng?",
        "options": {
          "A": "AI21 Labs và Hugging Face",
          "B": "Google và Microsoft",
          "C": "Groq và SambaNova",
          "D": "Mamba và Transformer"
        },
        "answer": "C"
      }
    ]
  },
  "airfoils-automatically-optimized": {
    "title": "Airfoils Automatically Optimized",
    "collection": "ml-research",
    "content": "Engineers who design aircraft, aqueducts, and other objects that interact with air and water use numerical simulations to test potential shapes, but they rely on trial and error to improve their designs. A neural simulator can optimize the shape itself.What’s new:Researchers at DeepMind devisedDifferentiable Learned Simulators, neural networks that learn to simulate physical processes, to help design surfaces that channel fluids in specific ways.Key insight:A popular way to design an object with certain physical properties is to evolve it using a numerical simulator: sample candidate designs, test their properties, keep the best design, tweak it randomly, and repeat. Here’s a faster, nonrandom alternative: Given parameters that define an object’s shape as a two- or three-dimensional mesh, a differentiable model can compute how it should change to better perform a task. Then it can use that information to adjust the object’s shape directly.How it works:Water and air can be modeled as systems of particles. The authors trainedMeshGraphNets, a type of graph neural network, to reproduce a prebuilt simulator’s output. The networks were trained to simulate the flow of particles around various shapes by predicting the next state given the previous state. The MeshGraphNets’ nodes represented particles, and their edges connected nearby particles.\n\nResults:Shapes designed using the authors’ approach outperformed those produced by thecross-entropy method(CEM), a technique that samples many designs and evolves them to maximize rewards. In the 2D water tasks, they achieved rewards 3.9 to 37.5 percent higher than shapes produced by CEM using the prebuilt simulator. In the aerodynamic task, they achieved results similar to those of a highly specializedsolver, producing drag coefficients between 0.01898 and 0.01919 compared to DAFoam’s 0.01902 (lower is better).We’re thinking:It’s not uncommon to train a neural network to mimic the output of a computation-intensive physics simulator. Using such a neural simulator not to run simulations but to optimize inputs according to the simulation’s outcome — that’s a fresh idea.",
    "qa": [
      {
        "question": "Phương pháp thiết kế truyền thống các vật thể tương tác với chất lỏng và khí thường dựa vào điều gì?",
        "options": {
          "A": "Sử dụng các mô hình toán học phức tạp để dự đoán chính xác hình dạng tối ưu.",
          "B": "Sử dụng mô phỏng số và thử nghiệm lặp đi lặp lại để cải thiện thiết kế.",
          "C": "Dựa vào kinh nghiệm của các kỹ sư thiết kế lâu năm.",
          "D": "Áp dụng các nguyên tắc thiết kế đã được chứng minh trong thực tế."
        },
        "answer": "B"
      },
      {
        "question": "Điểm mới trong nghiên cứu của DeepMind là gì?",
        "options": {
          "A": "Phát triển các thuật toán tối ưu hóa hình dạng dựa trên học tăng cường.",
          "B": "Sử dụng mạng nơ-ron để mô phỏng các quá trình vật lý và tối ưu hóa hình dạng.",
          "C": "Cải tiến các phương pháp mô phỏng số truyền thống để tăng tốc độ tính toán.",
          "D": "Xây dựng một thư viện các hình dạng tối ưu cho các ứng dụng khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Differentiable Learned Simulators là gì?",
        "options": {
          "A": "Một loại phần mềm mô phỏng vật lý thương mại.",
          "B": "Mạng nơ-ron được huấn luyện để mô phỏng các quá trình vật lý.",
          "C": "Một phương pháp tối ưu hóa hình dạng dựa trên giải thuật di truyền.",
          "D": "Một công cụ phân tích dữ liệu lớn cho các thí nghiệm vật lý."
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm chính của việc sử dụng mô hình khả vi (differentiable model) trong thiết kế là gì?",
        "options": {
          "A": "Cho phép tạo ra các thiết kế hoàn toàn ngẫu nhiên để khám phá không gian thiết kế rộng lớn.",
          "B": "Có thể tính toán trực tiếp sự thay đổi cần thiết để cải thiện hiệu suất của vật thể.",
          "C": "Giảm thiểu chi phí tính toán bằng cách sử dụng các mô hình đơn giản hơn.",
          "D": "Tăng cường tính trực quan của quá trình thiết kế cho người dùng."
        },
        "answer": "B"
      },
      {
        "question": "MeshGraphNets được sử dụng như thế nào trong nghiên cứu này?",
        "options": {
          "A": "Để tạo ra các hình dạng 3D phức tạp từ các tham số đầu vào.",
          "B": "Để mô phỏng dòng chảy của các hạt xung quanh các hình dạng khác nhau.",
          "C": "Để phân tích dữ liệu thu thập được từ các thí nghiệm vật lý thực tế.",
          "D": "Để trực quan hóa kết quả mô phỏng cho người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Trong mô hình MeshGraphNets, các nút (nodes) và cạnh (edges) đại diện cho điều gì?",
        "options": {
          "A": "Các nút đại diện cho các phần tử của hình dạng, cạnh đại diện cho mối quan hệ giữa các phần tử.",
          "B": "Các nút đại diện cho các hạt, cạnh đại diện cho mối liên kết giữa các hạt lân cận.",
          "C": "Các nút đại diện cho các bước trong quá trình mô phỏng, cạnh đại diện cho sự phụ thuộc giữa các bước.",
          "D": "Các nút đại diện cho các tham số thiết kế, cạnh đại diện cho ảnh hưởng của các tham số đến hiệu suất."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp thiết kế của các tác giả đã vượt trội hơn phương pháp CEM (cross-entropy method) như thế nào trong các nhiệm vụ liên quan đến nước?",
        "options": {
          "A": "Đạt được phần thưởng thấp hơn từ 3.9 đến 37.5 phần trăm.",
          "B": "Đạt được phần thưởng cao hơn từ 3.9 đến 37.5 phần trăm.",
          "C": "Đạt được kết quả tương đương với phương pháp CEM.",
          "D": "Không thể so sánh được do sử dụng các tiêu chí đánh giá khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Trong nhiệm vụ khí động học, kết quả của phương pháp mới so với DAFoam như thế nào?",
        "options": {
          "A": "Vượt trội hơn đáng kể, tạo ra hệ số cản thấp hơn nhiều.",
          "B": "Tương đương, tạo ra hệ số cản tương tự.",
          "C": "Kém hơn, tạo ra hệ số cản cao hơn.",
          "D": "Không thể so sánh được do sử dụng các mô hình khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Hệ số cản (drag coefficient) càng thấp thì hiệu suất khí động học như thế nào?",
        "options": {
          "A": "Càng thấp.",
          "B": "Càng cao.",
          "C": "Không ảnh hưởng.",
          "D": "Chỉ ảnh hưởng trong một số điều kiện nhất định."
        },
        "answer": "B"
      },
      {
        "question": "Ý chính mà tác giả muốn nhấn mạnh về việc sử dụng mạng nơ-ron trong mô phỏng vật lý là gì?",
        "options": {
          "A": "Mạng nơ-ron có thể thay thế hoàn toàn các mô phỏng vật lý truyền thống.",
          "B": "Mạng nơ-ron có thể được sử dụng để tối ưu hóa các đầu vào dựa trên kết quả mô phỏng.",
          "C": "Mạng nơ-ron có thể tăng tốc độ tính toán của các mô phỏng vật lý phức tạp.",
          "D": "Mạng nơ-ron có thể tạo ra các mô phỏng vật lý chính xác hơn."
        },
        "answer": "B"
      }
    ]
  },
  "alibaba-advances-open-weight-llms-with-qwen2-math-and-audio-variants": {
    "title": "Open Models for Math and Audio",
    "collection": "ml-research",
    "content": "Alibaba followed up its open-weights Qwen2 large language models with specialized variations.\n\nWhat’s new:Qwen2-MathandQwen2-Audioare model families devoted to, respectively, solving math problems and generating text directly from audio. Both set new states of the art in a variety of English and Chinese benchmarks, and some versions offer open weights. Notably Qwen2-Math-Instruct-72B, whose 72 billion parameters are fine-tuned according to human preferences, outperformed top models including Claude 3.5 Sonnet, Gemini 1.5-Pro, GPT-4o, and Llama-3.1-405B on some math benchmarks.\n\nMath mavens:Qwen2-Math models includepretrainedandinstruction-tunedvariations that comprise 1.5 billion, 7 billion, and 72 billion parameters. Thelicensefor the largest version is free for noncommerical development and commercial developers who have less than 100 million monthly active users.\n\nAudio/text to text:A revision of the earlier Qwen-Audio,Qwen2-Audiotakes text and audio inputs and generates text outputs. It’s designed to (i) provide text chat in response to voice input including voice transcription and translation between eight languages and (ii) discuss audio input including voice, music, and natural sounds. Weights (8.2 billion parameters) are available for base and instruction-tuned versions. You can try ithere.\n\nWhy it matters:Qwen2 delivered extraordinary performance with open weights, putting Alibaba on the map of large language models (LLMs). These specialized additions to the family push forward math performance and audio integration in AI while delivering state-of-the-art models into the hands of more developers.\n\nWe’re thinking:It’s thrilling to see models with open weights that outperform proprietary models. The white-hot competition between open and closed technology is good for everyone!",
    "qa": [
      {
        "question": "Dòng mô hình Qwen2 mới của Alibaba tập trung vào những lĩnh vực chuyên biệt nào?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên và dịch thuật.",
          "B": "Giải quyết các bài toán và tạo văn bản từ âm thanh.",
          "C": "Phân tích dữ liệu lớn và dự đoán thị trường chứng khoán.",
          "D": "Tạo hình ảnh từ văn bản và nhận diện khuôn mặt."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Qwen2-Math-Instruct-72B đã vượt trội hơn những mô hình nào trong một số bài kiểm tra toán học?",
        "options": {
          "A": "GPT-3, LaMDA, và PaLM.",
          "B": "Claude 3.5 Sonnet, Gemini 1.5-Pro, GPT-4o, và Llama-3.1-405B.",
          "C": "Bard, Bloom, và OPT.",
          "D": "ChatGPT, DALL-E 2, và Stable Diffusion."
        },
        "answer": "B"
      },
      {
        "question": "Phiên bản lớn nhất của dòng Qwen2-Math có bao nhiêu tham số?",
        "options": {
          "A": "1.5 tỷ.",
          "B": "7 tỷ.",
          "C": "72 tỷ.",
          "D": "8.2 tỷ."
        },
        "answer": "C"
      },
      {
        "question": "Giấy phép sử dụng phiên bản lớn nhất của Qwen2-Math miễn phí cho những đối tượng nào?",
        "options": {
          "A": "Tất cả các nhà phát triển.",
          "B": "Chỉ các nhà nghiên cứu học thuật.",
          "C": "Nhà phát triển phi thương mại và nhà phát triển thương mại có dưới 100 triệu người dùng hoạt động hàng tháng.",
          "D": "Chỉ các công ty khởi nghiệp."
        },
        "answer": "C"
      },
      {
        "question": "Qwen2-Audio có khả năng gì liên quan đến âm thanh và văn bản?",
        "options": {
          "A": "Chỉ tạo ra âm thanh từ văn bản.",
          "B": "Chỉ dịch văn bản sang âm thanh.",
          "C": "Nhận đầu vào văn bản và âm thanh, tạo ra đầu ra văn bản.",
          "D": "Chỉ phân tích âm thanh để trích xuất thông tin."
        },
        "answer": "C"
      },
      {
        "question": "Qwen2-Audio có thể thực hiện phiên âm và dịch thuật giữa bao nhiêu ngôn ngữ?",
        "options": {
          "A": "2 ngôn ngữ.",
          "B": "5 ngôn ngữ.",
          "C": "8 ngôn ngữ.",
          "D": "10 ngôn ngữ."
        },
        "answer": "C"
      },
      {
        "question": "Số lượng tham số của các phiên bản base và instruction-tuned của Qwen2-Audio là bao nhiêu?",
        "options": {
          "A": "1.5 tỷ.",
          "B": "7 tỷ.",
          "C": "72 tỷ.",
          "D": "8.2 tỷ."
        },
        "answer": "D"
      },
      {
        "question": "Điều gì khiến Qwen2 trở nên quan trọng trong lĩnh vực mô hình ngôn ngữ lớn?",
        "options": {
          "A": "Khả năng tạo ra hình ảnh chất lượng cao.",
          "B": "Hiệu suất vượt trội với mã nguồn mở, đưa Alibaba lên bản đồ LLM.",
          "C": "Khả năng dự đoán thị trường chứng khoán chính xác.",
          "D": "Khả năng tự động viết mã."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, sự cạnh tranh giữa công nghệ mã nguồn mở và công nghệ độc quyền có tác động như thế nào?",
        "options": {
          "A": "Chỉ có lợi cho các công ty lớn.",
          "B": "Chỉ có lợi cho các nhà nghiên cứu.",
          "C": "Có lợi cho tất cả mọi người.",
          "D": "Không có tác động đáng kể."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của Qwen2-Audio là gì?",
        "options": {
          "A": "Chỉ tạo ra nhạc từ văn bản.",
          "B": "Chỉ dịch văn bản sang âm thanh.",
          "C": "Cung cấp trò chuyện bằng văn bản đáp ứng đầu vào bằng giọng nói và thảo luận về đầu vào âm thanh.",
          "D": "Chỉ phân tích âm thanh để trích xuất thông tin về cảm xúc."
        },
        "answer": "C"
      }
    ]
  },
  "alibaba-debuts-qwen2-5-vl-a-powerful-family-of-open-vision-language-models": {
    "title": "Alibaba’s Answer to DeepSeek",
    "collection": "ml-research",
    "content": "While Hangzhou’s DeepSeek flexed its muscles, Chinese tech giant Alibaba vied for the spotlight with new open vision-language models.\n\nWhat’s new:Alibaba announcedQwen2.5-VL, a family of vision-language models (images and text in, text out) in sizes of 3 billion, 7 billion, and 72 billion parameters. The weights for all three models are available for download onHugging Face, each under a different license: Qwen2.5-VL-3B isfree for non-commercial uses, Qwen2.5-VL-7B isfree for commercial and noncommercial usesunder the Apache 2.0 license, and Qwen2.5-VL-72B isfree to developers that have less than 100 million monthly active users. You can try them out for free for a limited time inAlibaba Model Studio, and Qwen2.5-VL-72B is available via the model selector inQwen Chat.\n\nHow it works:Qwen2.5-VL models accept up to 129,024 tokens of input according to thedeveloper reference(other sources provide conflicting numbers) and generate up to 8,192 tokens of output. Alibaba has not released details about how it trained them.\n\nResults: Alibaba reports Qwen2.5-VL-72B’s performance on measures that span image and text problems, parsing documents, understanding videos, and interacting with computer programs. Across 21 benchmarks, it beat Microsoft Gemini 2.0 Flash, OpenAI GPT-4o, Anthropic Claude 3.5 Sonnet, and open competitors on 13 of them (where comparisons are  relevant and available).\n\nMore models:Alibaba also introduced competition for DeepSeek and a family of small models.\n\nWhy it matters:Vision-language models are getting more powerful and versatile. Not long ago, it was an impressive feat simply to answer questions about a chart or diagram that mixed graphics with text. Now such models are paired with an agent to control computers and smartphones. Broadly speaking, the Qwen2.5-VL models outperform open and closed competitors and they’re open to varying degrees (though the data is not available), giving developers a range of highly capable choices.\n\nWe’re thinking:We’re happy Alibaba released a vision-language model that is broadly permissive with respect to commercial use (although we’d prefer that all sizes were available under a standard open weights license). We hope to see technical reports that illuminate Alibaba’s training and fine-tuning recipes.",
    "qa": [
      {
        "question": "Công ty công nghệ nào của Trung Quốc đã giới thiệu các mô hình ngôn ngữ thị giác mới?",
        "options": {
          "A": "DeepSeek",
          "B": "Alibaba",
          "C": "Microsoft",
          "D": "OpenAI"
        },
        "answer": "B"
      },
      {
        "question": "Qwen2.5-VL có bao nhiêu phiên bản với số lượng tham số khác nhau?",
        "options": {
          "A": "2",
          "B": "3",
          "C": "4",
          "D": "5"
        },
        "answer": "B"
      },
      {
        "question": "Phiên bản Qwen2.5-VL nào được cung cấp miễn phí cho cả mục đích thương mại và phi thương mại?",
        "options": {
          "A": "Qwen2.5-VL-3B",
          "B": "Qwen2.5-VL-7B",
          "C": "Qwen2.5-VL-72B",
          "D": "Tất cả các phiên bản"
        },
        "answer": "B"
      },
      {
        "question": "Theo tài liệu tham khảo của nhà phát triển, Qwen2.5-VL có thể chấp nhận tối đa bao nhiêu token đầu vào?",
        "options": {
          "A": "8,192",
          "B": "65,536",
          "C": "129,024",
          "D": "258,048"
        },
        "answer": "C"
      },
      {
        "question": "Qwen2.5-VL-72B có thể được dùng thử miễn phí ở đâu trong thời gian giới hạn?",
        "options": {
          "A": "Hugging Face",
          "B": "Alibaba Cloud",
          "C": "Alibaba Model Studio",
          "D": "Qwen Chat"
        },
        "answer": "C"
      },
      {
        "question": "Trên bao nhiêu benchmark, Qwen2.5-VL-72B vượt trội hơn các đối thủ cạnh tranh?",
        "options": {
          "A": "8",
          "B": "13",
          "C": "18",
          "D": "21"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình ngôn ngữ thị giác (vision-language model) có thể được sử dụng để làm gì, ngoài việc trả lời câu hỏi về biểu đồ?",
        "options": {
          "A": "Điều khiển máy tính và điện thoại thông minh",
          "B": "Dịch văn bản sang nhiều ngôn ngữ",
          "C": "Tạo ra hình ảnh từ văn bản",
          "D": "Phân tích cảm xúc từ video"
        },
        "answer": "A"
      },
      {
        "question": "Giấy phép nào được sử dụng cho Qwen2.5-VL-7B?",
        "options": {
          "A": "MIT License",
          "B": "Apache 2.0 license",
          "C": "GPL License",
          "D": "Creative Commons"
        },
        "answer": "B"
      },
      {
        "question": "Điều gì còn thiếu trong thông tin được Alibaba cung cấp về các mô hình Qwen2.5-VL?",
        "options": {
          "A": "Chi tiết về hiệu suất trên các benchmark",
          "B": "Chi tiết về cách thức đào tạo mô hình",
          "C": "Thông tin về giấy phép sử dụng",
          "D": "Hướng dẫn sử dụng mô hình"
        },
        "answer": "B"
      },
      {
        "question": "Điều gì mà tác giả mong muốn thấy ở Alibaba liên quan đến các mô hình Qwen2.5-VL?",
        "options": {
          "A": "Phát hành thêm nhiều phiên bản mô hình nhỏ hơn",
          "B": "Cung cấp tất cả các kích thước mô hình dưới giấy phép mã nguồn mở tiêu chuẩn",
          "C": "Tăng giới hạn token đầu vào",
          "D": "Giảm giá cho người dùng thương mại"
        },
        "answer": "B"
      }
    ]
  },
  "alibaba-releases-qwen-2-5-models-raising-the-bar-for-open-weight-llms": {
    "title": "More, Better Open Source Options",
    "collection": "ml-research",
    "content": "The parade of ever more capable LLMs continues with Qwen 2.5.\n\nWhat's new:Alibaba releasedQwen 2.5in several sizes, the API variants Qwen Plus and Qwen Turbo, and the specialized modelsQwen 2.5-Coder and Qwen 2.5-Coder-InstructandQwen 2.5-Math and Qwen 2.5-Math-Instruct. Many are freely available for commercial use under the Apache 2.0 licensehere. The 3B and 72B models are also free, but theirlicenserequires special arrangements for commercial use.\n\nHow it works:The Qwen 2.5 family ranges from 500 million parameters to 72 billion parameters.\n\nResults:Compared to other models with open weights, Qwen 2.5-72B-Instruct beats LLama 3.1 405B Instruct and Mistral Large 2 Instruct (123 billion parameters) on seven of 14 benchmarks includingLiveCodeBench,MATH(solving math word problems), andMMLU(answering questions on a variety of topics). Compared to other models that respond to API calls, Qwen-Plus beats LLama 3.1 405B, Claude 3.5 Sonnet, and GPT-4o on MATH, LiveCodeBench, andArenaHard. Smaller versions also deliver outstanding performance. For instance, Qwen 2.5-14B-Instruct outperforms Gemma 2 27B Instruct and GPT-4o mini on seven benchmarks.\n\nBehind the news:Qwen 2.5 extends a parade of ever more capable LLMs that include Claude 3.5 Sonnet, GPT-4o, and LLama 3.1 as well as the earlierQwen 2 family.\n\nWhy it matters:The new models raise the bar for open weights models of similar sizes. They also rival some proprietary models, offering options to users who seek to balance performance and cost.\n\nWe’re thinking:Some companies encourage developers to use their paid APIs by locking their LLMs behind non-commercial licenses or blocking commercial applications beyond a certain threshold of revenue. We applaud Qwen’s approach, which keeps most models in the family open.",
    "qa": [
      {
        "question": "Qwen 2.5 được phát hành bởi công ty nào?",
        "options": {
          "A": "Google",
          "B": "Alibaba",
          "C": "Meta",
          "D": "Microsoft"
        },
        "answer": "B"
      },
      {
        "question": "Phiên bản Qwen 2.5 nào yêu cầu thỏa thuận đặc biệt cho mục đích sử dụng thương mại?",
        "options": {
          "A": "Qwen Plus",
          "B": "Qwen 2.5-Coder",
          "C": "Qwen 2.5-3B và 72B",
          "D": "Qwen Turbo"
        },
        "answer": "C"
      },
      {
        "question": "Phạm vi số lượng tham số của các mô hình trong gia đình Qwen 2.5 là bao nhiêu?",
        "options": {
          "A": "Từ 1 tỷ đến 100 tỷ tham số",
          "B": "Từ 500 triệu đến 72 tỷ tham số",
          "C": "Từ 100 triệu đến 50 tỷ tham số",
          "D": "Từ 1 tỷ đến 50 tỷ tham số"
        },
        "answer": "B"
      },
      {
        "question": "Trên bao nhiêu benchmark, Qwen 2.5-72B-Instruct vượt trội hơn LLama 3.1 405B Instruct và Mistral Large 2 Instruct?",
        "options": {
          "A": "5",
          "B": "7",
          "C": "9",
          "D": "11"
        },
        "answer": "B"
      },
      {
        "question": "Qwen-Plus vượt trội hơn LLama 3.1 405B, Claude 3.5 Sonnet và GPT-4o trên benchmark nào?",
        "options": {
          "A": "MMLU",
          "B": "LiveCodeBench",
          "C": "ArenaHard",
          "D": "Cả B và C"
        },
        "answer": "D"
      },
      {
        "question": "Qwen 2.5-14B-Instruct vượt trội hơn Gemma 2 27B Instruct và GPT-4o mini trên bao nhiêu benchmark?",
        "options": {
          "A": "3",
          "B": "5",
          "C": "7",
          "D": "9"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến những mô hình LLM nào khác cùng với Qwen 2.5?",
        "options": {
          "A": "GPT-3 và Claude 2",
          "B": "Claude 3.5 Sonnet, GPT-4o và LLama 3.1",
          "C": "Bard và Gemini",
          "D": "LLama 2 và Mistral 7B"
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì làm cho Qwen 2.5 trở nên quan trọng?",
        "options": {
          "A": "Nó là mô hình LLM duy nhất có giấy phép Apache 2.0.",
          "B": "Nó nâng cao tiêu chuẩn cho các mô hình open weights có kích thước tương tự và cạnh tranh với một số mô hình độc quyền.",
          "C": "Nó có số lượng tham số lớn nhất so với bất kỳ mô hình LLM nào khác.",
          "D": "Nó là mô hình LLM duy nhất có thể giải quyết các bài toán phức tạp."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đánh giá cao điều gì về cách tiếp cận của Qwen đối với việc cấp phép?",
        "options": {
          "A": "Việc cung cấp các mô hình trả phí với hiệu suất vượt trội.",
          "B": "Việc giữ cho hầu hết các mô hình trong gia đình Qwen được mở.",
          "C": "Việc hạn chế sử dụng thương mại để khuyến khích sử dụng API trả phí.",
          "D": "Việc cung cấp giấy phép độc quyền cho các ứng dụng doanh nghiệp."
        },
        "answer": "B"
      },
      {
        "question": "Benchmark MATH được sử dụng để đánh giá khả năng gì của các mô hình LLM?",
        "options": {
          "A": "Khả năng tạo ra văn bản sáng tạo.",
          "B": "Khả năng trả lời các câu hỏi về nhiều chủ đề khác nhau.",
          "C": "Khả năng giải quyết các bài toán đố.",
          "D": "Khả năng viết mã."
        },
        "answer": "C"
      }
    ]
  },
  "alibaba-releases-the-qwen3-family-of-open-llms-with-optional-reasoning": {
    "title": "Qwen3 Takes On DeepSeek-R1",
    "collection": "ml-research",
    "content": "Alibaba’s new model family may unseat DeepSeek-R1’s four-month reign as the top open-weights large language model.\n\nWhat’s new:Alibabareleasedweights for eight large language models, all of which offer a reasoning mode that can be switched on or off. Two use a mixture of experts (MoE) architecture: Qwen3-235B-A22B (the name indicates 235 billion parameters, 22 billion of which are active at any given time) and Qwen3-30B-A3B). The other six are dense models in sizes between 32 billion parameters and 0.6 billion parameters — tiny by LLM standards, and with reasoning, too.\n\nHow it works:The Qwen3 family implementschain-of-thoughtreasoning in both relatively large and quite small LLMs.\n\nResults:Qwen3-235B-A22B and Qwen3-30B-A3B performed as well as, or better than, leading open-weights models in tests performed by Alibaba. Qwen3-4B, too, achieved results that are competitive with many models several times its size. Alibaba didn’t provide results for the other dense models.\n\nWhy it matters:Qwen3 continues a string of high-performance, open-weights models released by developers in China. Alibaba says it designed the models to do the thinking in agentic systems. Reasoning that can be switched on and off can help control costs in agentic and other applications.\n\nWe’re thinking:Alibaba’s 235-billion parameter MoE model may perform better according to benchmarks, but Qwen3-30B-A3B does nearly as well and can run locally on a pro laptop without straining its memory. Add the easy ability to switch reasoning on or off, and Qwen3’s versatile, mid-sized MoE model may turn out to be the star of the show.",
    "qa": [
      {
        "question": "Mô hình ngôn ngữ lớn nào có thể bị soán ngôi bởi dòng Qwen3 của Alibaba?",
        "options": {
          "A": "GPT-4",
          "B": "DeepSeek-R1",
          "C": "Llama 2",
          "D": "Gemini"
        },
        "answer": "B"
      },
      {
        "question": "Dòng Qwen3 của Alibaba bao gồm bao nhiêu mô hình ngôn ngữ lớn đã được công bố?",
        "options": {
          "A": "2",
          "B": "4",
          "C": "6",
          "D": "8"
        },
        "answer": "D"
      },
      {
        "question": "Kiến trúc Mixture of Experts (MoE) được sử dụng trong những mô hình nào của dòng Qwen3?",
        "options": {
          "A": "Qwen3-4B và Qwen3-32B",
          "B": "Qwen3-235B-A22B và Qwen3-30B-A3B",
          "C": "Tất cả các mô hình Qwen3",
          "D": "Chỉ Qwen3-235B-A22B"
        },
        "answer": "B"
      },
      {
        "question": "Tính năng 'reasoning mode' (chế độ suy luận) trong các mô hình Qwen3 có đặc điểm gì?",
        "options": {
          "A": "Không thể điều chỉnh",
          "B": "Chỉ hoạt động trên các mô hình lớn",
          "C": "Có thể bật hoặc tắt",
          "D": "Chỉ hoạt động trên các mô hình nhỏ"
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp suy luận nào được triển khai trong dòng Qwen3?",
        "options": {
          "A": "Zero-shot reasoning",
          "B": "Few-shot reasoning",
          "C": "Chain-of-thought reasoning",
          "D": "Reinforcement learning reasoning"
        },
        "answer": "C"
      },
      {
        "question": "Mô hình Qwen3 nào đạt được kết quả cạnh tranh với nhiều mô hình lớn hơn nó nhiều lần?",
        "options": {
          "A": "Qwen3-235B-A22B",
          "B": "Qwen3-30B-A3B",
          "C": "Qwen3-4B",
          "D": "Qwen3-32B"
        },
        "answer": "C"
      },
      {
        "question": "Theo Alibaba, dòng Qwen3 được thiết kế để làm gì?",
        "options": {
          "A": "Dịch thuật ngôn ngữ",
          "B": "Tạo sinh hình ảnh",
          "C": "Thực hiện các tác vụ toán học phức tạp",
          "D": "Thực hiện suy nghĩ trong các hệ thống agentic"
        },
        "answer": "D"
      },
      {
        "question": "Lợi ích của việc có thể bật/tắt chế độ suy luận trong các mô hình Qwen3 là gì?",
        "options": {
          "A": "Tăng độ chính xác của kết quả",
          "B": "Giảm chi phí trong các ứng dụng agentic",
          "C": "Tăng tốc độ xử lý",
          "D": "Giảm dung lượng bộ nhớ cần thiết"
        },
        "answer": "B"
      },
      {
        "question": "Mô hình Qwen3 nào được đánh giá là có thể chạy cục bộ trên một máy tính xách tay chuyên nghiệp mà không gây quá tải bộ nhớ?",
        "options": {
          "A": "Qwen3-235B-A22B",
          "B": "Qwen3-30B-A3B",
          "C": "Qwen3-4B",
          "D": "Qwen3-32B"
        },
        "answer": "B"
      },
      {
        "question": "Điều gì khiến Qwen3-30B-A3B trở nên nổi bật so với Qwen3-235B-A22B?",
        "options": {
          "A": "Hiệu suất vượt trội hơn trên các benchmark",
          "B": "Khả năng chạy cục bộ trên laptop và khả năng bật/tắt suy luận",
          "C": "Số lượng tham số lớn hơn",
          "D": "Khả năng tạo sinh hình ảnh tốt hơn"
        },
        "answer": "B"
      }
    ]
  },
  "all-examples-are-not-equal": {
    "title": "All Examples Are Not Equal",
    "collection": "ml-research",
    "content": "Semi-supervised learning — a set of training techniques that use a small number of labeled examples and a large number of unlabeled examples — typically treats all unlabeled examples the same way. But some examples are more useful for learning than others. A new approach lets models distinguish between them.What’s new:Researchers Zhongzheng Ren, Raymond A. Yeh, and Alexander G. Schwing from the University of Illinois at Urbana-Champaign developed analgorithmthat weighs the most significant examples more heavily.Key insight:In its most common form, semi-supervised learning tries to minimize a weighted combination of supervised and unsupervised losses. Most previous approaches effectively weight each unlabeled example as equally important. The authors, instead of assigning one weight to all unlabeled examples, calculate weights for every example automatically by evaluating how it changes the model’s output during training.How it works:The algorithm works with any semi-supervised model. It trains by alternating between optimizing the model and the per-example weights.\n\nResults:Using synthetic data, the authors demonstrated that less useful examples were assigned lower weights. In image classification using theCifar-10andSVHNdatasets, their approach marginally outperformed previous state of the art semi-supervised learning work includingFixMatchandUDA. Specifically, using a WideResNet-28-2and Cifar-10 with 250 labeled examples, the authors’ method combined with FixMatch achieved a classification error of 5.05 percent compared to FixMatch’s 5.07 percent. Combined with UDA, the authors’ method on Cifar-10 achieved a classification error of 5.53 percent compared to UDA’s 8.76 percent.Why it matters:Unlabeled data points are available in far greater profusion than labeled data points. This work explores a path toward unlocking their value.We’re thinking:Sometimes another 1,000 cat pictures don’t provide a model with any more useful information. But keep sending them anyway.The Batchteam appreciates it!",
    "qa": [
      {
        "question": "Phương pháp học bán giám sát (Semi-supervised learning) thường xử lý các dữ liệu không được gán nhãn như thế nào?",
        "options": {
          "A": "Loại bỏ hoàn toàn các dữ liệu không được gán nhãn.",
          "B": "Coi tất cả các dữ liệu không được gán nhãn là có giá trị như nhau.",
          "C": "Ưu tiên các dữ liệu không được gán nhãn có độ phức tạp cao.",
          "D": "Gán nhãn giả cho các dữ liệu không được gán nhãn dựa trên mô hình hiện tại."
        },
        "answer": "B"
      },
      {
        "question": "Điểm mới trong phương pháp được đề xuất bởi các nhà nghiên cứu từ Đại học Illinois tại Urbana-Champaign là gì?",
        "options": {
          "A": "Sử dụng ít dữ liệu được gán nhãn hơn so với các phương pháp trước đây.",
          "B": "Phân biệt tầm quan trọng của các dữ liệu không được gán nhãn khác nhau.",
          "C": "Loại bỏ hoàn toàn việc sử dụng dữ liệu được gán nhãn.",
          "D": "Tăng cường sử dụng dữ liệu được gán nhãn để cải thiện độ chính xác."
        },
        "answer": "B"
      },
      {
        "question": "Theo phương pháp mới, trọng số của mỗi dữ liệu không được gán nhãn được xác định như thế nào?",
        "options": {
          "A": "Được gán ngẫu nhiên.",
          "B": "Được tính toán tự động dựa trên ảnh hưởng của nó đến đầu ra của mô hình trong quá trình huấn luyện.",
          "C": "Được xác định bởi người dùng dựa trên kinh nghiệm.",
          "D": "Được gán dựa trên độ tin cậy của dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Thuật toán mới hoạt động bằng cách xen kẽ giữa hai quá trình nào?",
        "options": {
          "A": "Huấn luyện mô hình và kiểm tra độ chính xác.",
          "B": "Tối ưu hóa mô hình và tối ưu hóa trọng số cho từng dữ liệu.",
          "C": "Gán nhãn cho dữ liệu và loại bỏ dữ liệu nhiễu.",
          "D": "Tăng cường dữ liệu và giảm chiều dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Trong thử nghiệm với dữ liệu tổng hợp, kết quả cho thấy điều gì về trọng số được gán cho các dữ liệu ít hữu ích?",
        "options": {
          "A": "Chúng được gán trọng số cao hơn.",
          "B": "Chúng được gán trọng số thấp hơn.",
          "C": "Chúng được gán trọng số tương đương với các dữ liệu hữu ích.",
          "D": "Chúng không được gán trọng số."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp mới kết hợp với FixMatch trên tập dữ liệu Cifar-10 với 250 dữ liệu được gán nhãn đạt được kết quả như thế nào?",
        "options": {
          "A": "Đạt được độ lỗi phân loại cao hơn so với FixMatch.",
          "B": "Đạt được độ lỗi phân loại tương đương với FixMatch.",
          "C": "Đạt được độ lỗi phân loại thấp hơn một chút so với FixMatch.",
          "D": "Không thể so sánh với FixMatch do sử dụng các tham số khác nhau."
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp mới kết hợp với UDA trên tập dữ liệu Cifar-10 đạt được kết quả như thế nào?",
        "options": {
          "A": "Đạt được độ lỗi phân loại cao hơn đáng kể so với UDA.",
          "B": "Đạt được độ lỗi phân loại tương đương với UDA.",
          "C": "Đạt được độ lỗi phân loại thấp hơn đáng kể so với UDA.",
          "D": "Không thể kết hợp với UDA."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao công trình nghiên cứu này lại quan trọng?",
        "options": {
          "A": "Vì nó giảm thiểu nhu cầu về dữ liệu được gán nhãn.",
          "B": "Vì nó mở ra hướng khai thác giá trị của dữ liệu không được gán nhãn, vốn có số lượng lớn hơn nhiều.",
          "C": "Vì nó cải thiện đáng kể tốc độ huấn luyện mô hình.",
          "D": "Vì nó đơn giản hóa quá trình gán nhãn dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Trong bối cảnh học máy, câu nói \"Sometimes another 1,000 cat pictures don’t provide a model with any more useful information\" có ý nghĩa gì?",
        "options": {
          "A": "Mô hình đã học được tất cả các đặc trưng cần thiết từ ảnh mèo.",
          "B": "Dữ liệu ảnh mèo không phù hợp để huấn luyện mô hình.",
          "C": "Không phải tất cả dữ liệu không được gán nhãn đều có giá trị như nhau.",
          "D": "Cần phải tăng cường dữ liệu ảnh mèo để cải thiện hiệu suất."
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp này có thể được áp dụng cho loại mô hình học bán giám sát nào?",
        "options": {
          "A": "Chỉ các mô hình dựa trên mạng nơ-ron tích chập (CNN).",
          "B": "Chỉ các mô hình dựa trên máy vector hỗ trợ (SVM).",
          "C": "Bất kỳ mô hình học bán giám sát nào.",
          "D": "Chỉ các mô hình được huấn luyện trên dữ liệu hình ảnh."
        },
        "answer": "C"
      }
    ]
  },
  "alphadev-a-new-system-for-high-speed-algorithmic-sorting-of-lists-and-numbers": {
    "title": "AI Builds Better Sorting Algorithms",
    "collection": "ml-research",
    "content": "Online sorting algorithms run trillions of times a day to organize lists according to users’ interests. New work found faster alternatives.\n\nWhat’s new:Daniel J. Mankowitz and colleagues at Google developedAlphaDev, a system that learned to generate algorithms that sort three to five numbers faster than previous state-of-the-art methods. Accelerating such algorithms can expedite the sorting of lists of any size — say, for search engines, ecommerce sites, and the like — since algorithms that sort more elements often call algorithms that sort fewer elements.\n\nKey insight:Most programmers implement sorting algorithms in a high-level programming language like C++, which a compiler translates into Assembly Language instructions that control the processor and memory. A compiler can translate a single line of C++ into a variety of sequences of Assembly instructions that are equivalent functionally but vary in their speed (number of Assembly instructions required). A reinforcement learning agent can learn to choose a translation that maximizes speed.\n\nHow it works:AlphaDev is a collection of neural networks that learn jointly via reinforcement learning. The authors initialized the system by giving it a sequence of unsorted numbers and an empty list of Assembly instructions. It built algorithms by adding Assembly instructions one by one. It earned rewards for choosing instructions that sorted the numbers correctly and quickly.\n\nResults:The authors tested two approaches to rewarding speed, minimizing either Assembly instructions or average runtime over a number of inputs. When AlphaDev minimized the number of Assembly instructions, it found an algorithm that sorted three integers using 17 instructions instead of the previous state-of-the-art algorithm, a human-engineered one that used 18 instructions. Its algorithm for sorting four integers used 28 instructions, equal to the typical one. Its algorithm for sorting five integers had 42 instructions, compared to the alternative’s 46 instructions. When AlphaDev optimized for runtime (running on Intel 6th-generation Core “Skylake” processor), sorting three integers took 2.18 nanoseconds, compared to the typical algorithm’s 4.86 nanoseconds. Sorting four unsigned integers took 1.96 nanoseconds instead of 5.43 nanoseconds and sorting five of them took 1.98 nanoseconds instead of 6.79 nanoseconds. AlphaDev achieved smaller speedups with longer number sequences: Sorting 16 unsigned integers took 9.5 nanoseconds instead of 10.5 nanoseconds, and sorting 262,144 numbers took 60.8 nanoseconds instead of 61.4 nanoseconds.\n\nWhy it matters:This work repurposes the training method and architecture of game-playing models likeAlphaZeroto solve real-world problems. The trick is to reframe the task of writing a sorting algorithm as a reinforcement learning problem.\n\nWe’re thinking:What other algorithms can this approach optimize? How much faster will they be? Let’s get these questions sorted!",
    "qa": [
      {
        "question": "AlphaDev được phát triển bởi tổ chức nào?",
        "options": {
          "A": "Microsoft",
          "B": "Google",
          "C": "OpenAI",
          "D": "DeepMind"
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của AlphaDev là gì?",
        "options": {
          "A": "Tạo ra các thuật toán sắp xếp phức tạp hơn.",
          "B": "Tạo ra các thuật toán sắp xếp nhanh hơn.",
          "C": "Tạo ra các thuật toán sắp xếp dễ hiểu hơn.",
          "D": "Tạo ra các thuật toán sắp xếp tiết kiệm bộ nhớ hơn."
        },
        "answer": "B"
      },
      {
        "question": "AlphaDev sử dụng phương pháp học máy nào để tạo ra các thuật toán?",
        "options": {
          "A": "Học có giám sát (Supervised learning)",
          "B": "Học không giám sát (Unsupervised learning)",
          "C": "Học tăng cường (Reinforcement learning)",
          "D": "Học chuyển giao (Transfer learning)"
        },
        "answer": "C"
      },
      {
        "question": "Ngôn ngữ lập trình nào được sử dụng để triển khai các thuật toán sắp xếp truyền thống mà AlphaDev cạnh tranh?",
        "options": {
          "A": "Python",
          "B": "Java",
          "C": "C++",
          "D": "Assembly"
        },
        "answer": "C"
      },
      {
        "question": "Trong quá trình huấn luyện, AlphaDev nhận được phần thưởng khi nào?",
        "options": {
          "A": "Khi thuật toán sắp xếp không chính xác.",
          "B": "Khi thuật toán sắp xếp chính xác và nhanh chóng.",
          "C": "Khi thuật toán sử dụng nhiều lệnh Assembly.",
          "D": "Khi thuật toán dễ hiểu."
        },
        "answer": "B"
      },
      {
        "question": "Khi tối ưu hóa theo số lượng lệnh Assembly, AlphaDev đã tìm ra thuật toán sắp xếp 3 số nguyên với bao nhiêu lệnh?",
        "options": {
          "A": "16",
          "B": "17",
          "C": "18",
          "D": "19"
        },
        "answer": "B"
      },
      {
        "question": "Trên bộ vi xử lý Intel Skylake, AlphaDev sắp xếp 4 số nguyên không dấu mất bao nhiêu thời gian?",
        "options": {
          "A": "1.96 nanoseconds",
          "B": "4.86 nanoseconds",
          "C": "5.43 nanoseconds",
          "D": "6.79 nanoseconds"
        },
        "answer": "A"
      },
      {
        "question": "Ứng dụng nào sau đây có thể hưởng lợi từ việc tăng tốc các thuật toán sắp xếp?",
        "options": {
          "A": "Trình soạn thảo văn bản",
          "B": "Công cụ tìm kiếm",
          "C": "Phần mềm đồ họa",
          "D": "Trình phát nhạc"
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp huấn luyện của AlphaDev tương tự với mô hình nào?",
        "options": {
          "A": "AlphaGo",
          "B": "AlphaFold",
          "C": "AlphaZero",
          "D": "AlphaCode"
        },
        "answer": "C"
      },
      {
        "question": "Điểm mấu chốt trong cách tiếp cận của AlphaDev là gì?",
        "options": {
          "A": "Sử dụng ngôn ngữ lập trình Assembly trực tiếp.",
          "B": "Áp dụng học tăng cường để giải quyết bài toán viết thuật toán sắp xếp.",
          "C": "Tối ưu hóa mã C++ trước khi biên dịch.",
          "D": "Sử dụng phần cứng chuyên dụng để tăng tốc quá trình sắp xếp."
        },
        "answer": "B"
      }
    ]
  },
  "alphatensor-for-faster-matrix-multiplication-explained": {
    "title": "Optimizing Matrix Multiplication",
    "collection": "ml-research",
    "content": "Matrix multiplication is executed so often in deep learning, video games, and scientific computing that even a slight acceleration can save substantial amounts of processing time. New work finds ways to speed up this crucial operation.\n\nWhat’s new:Alhussein Fawzi and colleagues at DeepMind developedAlphaTensor. This reinforcement learning agent discovers algorithms that multiply matrices faster than those previously developed by humans.\n\nComposition and decomposition:Computers need more time to multiply than to add or subtract. Developers often take advantage of algebraic properties — for instance, (a^2 - b^2) = (a+b)(a-b) — to manually find matrix multiplication algorithms that require fewer multiplications. To minimize the number of multiplications systematically, we can take advantage of the fact that a tensor (a high-dimensional matrix) can represent a matrix multiplication algorithm. It’s easy tocomposea tensor from three matrices. However, todecomposea tensor (the reverse operation) is not straightforward; the procedure could result in any of thousands of potential sets of matrices. Any valid decomposition of the tensor into three matrices represents a valid algorithm for matrix multiplication. The number of columns equals the number of multiplications required.\n\nKey insight:Just as DeepMind’s AlphaZero learned via reinforcement learning to play Go by simulating future game-board states and, based on those states, predicting the likelihood that it would win, a reinforcement learning model can learn to win a game of decomposing tensors by predicting the columns of three matrices.\n\nHow it works:Given a tensor that represents a matrix multiplication algorithm, AlphaTensor played a game in which it decomposed the tensor into three matrices with as few columns — and thus as few multiplications — as possible. (The values in the predicted columns were limited to {-2,-1,0,1,2} to avoid precision issues that could have occurred with floating-point values.) At each turn, it predicted the entries in one column of each of the three matrices. The game updated the tensor’s state by subtracting theouter productof the predicted columns. It ended when all entries in the tensor equalled 0. AlphaTensor received a negative reward after predicting each set of columns, which encouraged it to decompose the tensor into matrices that had few columns. It received a positive reward for predicting all columns of the three matrices.\n\nResults:AlphaTensor rediscovered known matrix multiplication algorithms for matrices as large as five rows and columns (5x5). Notably, to multiply two 4x4 matrices that contain binary numbers, AlphaTensor discovered an algorithm that requires 47 multiplications, compared toStrassen’s algorithm, which requires 49 and had not been improved upon since its creation in 1969. To multiply 4x5 and 5x5 matrices that contain real numbers, AlphaTensor found an algorithm that requires 76 multiplications; the previous best takes 80. After training AlphaTensor with an additional reward that reduced hardware-specific compute time, the authors found algorithms for an Nvidia V100 GPU that are, on median, 8.5 percent faster than the usual implementation. Optimized for TPUs, AlphaTensor sped up matrix multiplication by 10.3 percent.\n\nWhy it matters:Neural networks learn from data how to perform a particular task reasonably well (for instance, they may be correct 95 percent of the time). But is reasonably well sufficient for a field such as mathematics, in which results are provably true or false? This paper stands alongside achievements such as aneural theorem finderandneural theorem prover, showing that deep learning can advance even the most exacting fields.\n\nWe’re thinking:This work shows deep learning’s potential for synergy between humans and machines: People supply an algorithm (such as matrix multiplication) and AI accelerates its runtime.",
    "qa": [
      {
        "question": "Mục tiêu chính của việc tăng tốc phép nhân ma trận trong các lĩnh vực như deep learning là gì?",
        "options": {
          "A": "Giảm thiểu số lượng ma trận cần xử lý.",
          "B": "Tiết kiệm đáng kể thời gian xử lý.",
          "C": "Tăng độ chính xác của kết quả tính toán.",
          "D": "Đơn giản hóa thuật toán nhân ma trận."
        },
        "answer": "B"
      },
      {
        "question": "AlphaTensor là gì?",
        "options": {
          "A": "Một thuật toán nhân ma trận mới do con người phát triển.",
          "B": "Một tác tử học tăng cường được phát triển bởi DeepMind để tìm ra các thuật toán nhân ma trận nhanh hơn.",
          "C": "Một loại phần cứng chuyên dụng để thực hiện phép nhân ma trận.",
          "D": "Một phương pháp phân tích ma trận để tối ưu hóa hiệu suất."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc phân tích một tensor thành ba ma trận lại quan trọng trong việc tối ưu hóa phép nhân ma trận?",
        "options": {
          "A": "Nó giúp giảm kích thước của ma trận đầu vào.",
          "B": "Nó cho phép sử dụng các phép toán cộng và trừ thay vì phép nhân.",
          "C": "Mỗi cách phân tích hợp lệ đại diện cho một thuật toán nhân ma trận hợp lệ.",
          "D": "Nó giúp tăng độ chính xác của kết quả nhân ma trận."
        },
        "answer": "C"
      },
      {
        "question": "Trong quá trình học của AlphaTensor, phần thưởng âm được sử dụng để làm gì?",
        "options": {
          "A": "Khuyến khích việc tìm kiếm các ma trận có kích thước lớn.",
          "B": "Ngăn chặn việc sử dụng các giá trị dấu phẩy động để tránh các vấn đề về độ chính xác.",
          "C": "Khuyến khích việc phân tích tensor thành các ma trận có ít cột hơn.",
          "D": "Tăng tốc độ hội tụ của thuật toán học tăng cường."
        },
        "answer": "C"
      },
      {
        "question": "Kết quả đáng chú ý nào mà AlphaTensor đạt được khi nhân hai ma trận 4x4 chứa số nhị phân?",
        "options": {
          "A": "Tìm ra thuật toán yêu cầu ít hơn 45 phép nhân.",
          "B": "Tìm ra thuật toán yêu cầu 47 phép nhân, vượt trội hơn thuật toán Strassen.",
          "C": "Tìm ra thuật toán có độ chính xác cao hơn thuật toán Strassen.",
          "D": "Tìm ra thuật toán có thể chạy trên phần cứng ít tốn kém hơn."
        },
        "answer": "B"
      },
      {
        "question": "Thuật toán AlphaTensor đã cải thiện hiệu suất nhân ma trận trên GPU Nvidia V100 và TPU như thế nào?",
        "options": {
          "A": "Giảm thời gian tính toán trung bình khoảng 5% trên cả hai loại phần cứng.",
          "B": "Tăng tốc độ nhân ma trận trung bình 8.5% trên Nvidia V100 và 10.3% trên TPU.",
          "C": "Tăng độ chính xác của kết quả nhân ma trận lên 15% trên cả hai loại phần cứng.",
          "D": "Giảm mức tiêu thụ năng lượng khi nhân ma trận trên cả hai loại phần cứng."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về khả năng của deep learning trong các lĩnh vực đòi hỏi độ chính xác cao như toán học?",
        "options": {
          "A": "Deep learning chỉ có thể được sử dụng để giải quyết các bài toán gần đúng trong toán học.",
          "B": "Deep learning có thể đạt được kết quả tốt hơn con người trong mọi bài toán toán học.",
          "C": "Deep learning có thể đóng góp vào việc phát triển các công cụ chứng minh và tìm kiếm định lý mới.",
          "D": "Deep learning không phù hợp cho các lĩnh vực đòi hỏi độ chính xác tuyệt đối."
        },
        "answer": "C"
      },
      {
        "question": "Ý chính của phần 'We're thinking' trong bài viết là gì?",
        "options": {
          "A": "Con người nên ngừng phát triển thuật toán và để AI tự động tạo ra chúng.",
          "B": "AI có thể thay thế hoàn toàn con người trong việc giải quyết các bài toán phức tạp.",
          "C": "Deep learning có tiềm năng tạo ra sự hợp tác giữa con người và máy móc, trong đó con người cung cấp thuật toán và AI tăng tốc độ thực thi.",
          "D": "Thuật toán nhân ma trận là một ví dụ hoàn hảo về những gì AI có thể làm tốt hơn con người."
        },
        "answer": "C"
      },
      {
        "question": "Yếu tố nào được giới hạn trong tập {-2,-1,0,1,2} khi AlphaTensor dự đoán các cột của ba ma trận?",
        "options": {
          "A": "Số lượng cột trong mỗi ma trận.",
          "B": "Các giá trị trong các cột được dự đoán.",
          "C": "Số lượng phép nhân cần thiết.",
          "D": "Kích thước của tensor đầu vào."
        },
        "answer": "B"
      },
      {
        "question": "Thuật toán Strassen, được đề cập trong bài viết, có điểm gì đặc biệt?",
        "options": {
          "A": "Là thuật toán nhân ma trận nhanh nhất hiện nay.",
          "B": "Là thuật toán nhân ma trận đầu tiên được phát triển bởi AI.",
          "C": "Là thuật toán nhân ma trận cho ma trận nhị phân được cải tiến gần đây bởi AlphaTensor.",
          "D": "Là thuật toán nhân ma trận 4x4 không được cải thiện kể từ năm 1969 cho đến khi AlphaTensor xuất hiện."
        },
        "answer": "D"
      }
    ]
  },
  "anonymous-faces": {
    "title": "Anonymous Faces",
    "collection": "ml-research",
    "content": "A number of countries restrict commercial use of personal data without consent unless they’re fully anonymized. A new paper proposes a way to anonymize images of faces, purportedly without degrading their usefulness in applications that rely on face recognition.What’s new:Researchers from the Norwegian University of Science and Technology introducedDeepPrivacy, a system that anonymizes images of people by synthesizing replacement faces. They also offer the Flickr Diverse Faces dataset, 1.47 million images of faces with supplemental metadata, which they used to train DeepPrivacy.Key insight:The original images are never exposed to the face generator. Authors Håkon Hukkelås, Rudolf Mester, and Frank Lindseth argue that this strategy preserves privacy more effectively than traditional anonymization techniques like pixelizing and blurring.How it works:DeepPrivacy is aconditional generative adversarial networkthat synthesizes novel images similar to previously observed ones. A discriminator classifies images as real or generated, while a generator based on the U-Net architecture is optimized to create images that fool the generator.\n\nResults:The researchers processed the WIDER-Face dataset (roughly 32,000 images containing around 394,000 faces) using DeepPrivacy as well as traditional anonymization methods. Subjected to traditional techniques,Dual Shot Face Detectorretained 96.7 percent of its usual performance. With DeepPrivacy, it retained 99.3 percent. The researchers don’t provide metrics to evaluate the relative degree of anonymity imparted by the various methods.Why it matters:Laws like the European Union’s General Data Protection Regulation set a high bar for data-driven applications by placing tight limits on how personal data can be used. DeepPrivacy transforms photos of people into a less identifiable format that still contains faces recognizable to neural networks.Yes, but:DeepPrivacy addresses the privacy implications of faces only. An image purged of faces but still containing, say, clothing with identifiable markings, such as an athlete’s number, would allow a sophisticated model to infer the wearer’s identity.We’re thinking:Machine learning’s reliance on data is both a gift and a curse. Aggregation of data has allowed for great progress in the field. Yet privacy advocates are inclined to keep personal data under wraps. DeepPrivacy is an intriguing step toward a compromise that could satisfy both AI engineers and users alike.",
    "qa": [
      {
        "question": "Mục đích chính của DeepPrivacy là gì?",
        "options": {
          "A": "Tăng cường khả năng nhận diện khuôn mặt của các hệ thống AI.",
          "B": "Ẩn danh hóa hình ảnh khuôn mặt mà không làm giảm đáng kể hiệu quả của các ứng dụng nhận diện khuôn mặt.",
          "C": "Tạo ra các hình ảnh khuôn mặt mới hoàn toàn từ dữ liệu cá nhân.",
          "D": "Cải thiện độ chính xác của các thuật toán phát hiện khuôn mặt."
        },
        "answer": "B"
      },
      {
        "question": "DeepPrivacy được huấn luyện bằng bộ dữ liệu nào?",
        "options": {
          "A": "WIDER-Face dataset.",
          "B": "ImageNet dataset.",
          "C": "Flickr Diverse Faces dataset.",
          "D": "Labeled Faces in the Wild dataset."
        },
        "answer": "C"
      },
      {
        "question": "Điểm khác biệt chính của DeepPrivacy so với các phương pháp ẩn danh hóa truyền thống như pixel hóa và làm mờ là gì?",
        "options": {
          "A": "DeepPrivacy sử dụng ít tài nguyên tính toán hơn.",
          "B": "DeepPrivacy tạo ra hình ảnh khuôn mặt hoàn toàn mới thay vì chỉ che giấu khuôn mặt gốc.",
          "C": "DeepPrivacy có thể được áp dụng cho video, trong khi các phương pháp truyền thống chỉ áp dụng cho ảnh tĩnh.",
          "D": "DeepPrivacy không yêu cầu bất kỳ dữ liệu huấn luyện nào."
        },
        "answer": "B"
      },
      {
        "question": "DeepPrivacy sử dụng kiến trúc mạng nào để tạo ra các khuôn mặt mới?",
        "options": {
          "A": "Convolutional Neural Network (CNN).",
          "B": "Recurrent Neural Network (RNN).",
          "C": "U-Net.",
          "D": "Transformer."
        },
        "answer": "C"
      },
      {
        "question": "Kết quả thử nghiệm DeepPrivacy trên WIDER-Face dataset cho thấy điều gì?",
        "options": {
          "A": "DeepPrivacy làm giảm đáng kể hiệu suất của các thuật toán nhận diện khuôn mặt.",
          "B": "DeepPrivacy duy trì hiệu suất của thuật toán nhận diện khuôn mặt tốt hơn so với các phương pháp ẩn danh hóa truyền thống.",
          "C": "DeepPrivacy không có tác động đáng kể đến hiệu suất của thuật toán nhận diện khuôn mặt.",
          "D": "DeepPrivacy chỉ hoạt động tốt trên một số loại khuôn mặt nhất định."
        },
        "answer": "B"
      },
      {
        "question": "Luật nào được đề cập trong bài viết liên quan đến việc hạn chế sử dụng dữ liệu cá nhân?",
        "options": {
          "A": "Health Insurance Portability and Accountability Act (HIPAA).",
          "B": "California Consumer Privacy Act (CCPA).",
          "C": "General Data Protection Regulation (GDPR).",
          "D": "Personal Information Protection and Electronic Documents Act (PIPEDA)."
        },
        "answer": "C"
      },
      {
        "question": "Hạn chế chính của DeepPrivacy được đề cập trong bài viết là gì?",
        "options": {
          "A": "DeepPrivacy chỉ hoạt động tốt với hình ảnh có độ phân giải cao.",
          "B": "DeepPrivacy chỉ giải quyết vấn đề quyền riêng tư liên quan đến khuôn mặt, không bao gồm các yếu tố nhận dạng khác.",
          "C": "DeepPrivacy yêu cầu một lượng lớn dữ liệu huấn luyện.",
          "D": "DeepPrivacy không thể được sử dụng trong thời gian thực."
        },
        "answer": "B"
      },
      {
        "question": "DeepPrivacy sử dụng loại mạng đối kháng sinh (GAN) nào?",
        "options": {
          "A": "Vanilla GAN.",
          "B": "Conditional Generative Adversarial Network (cGAN).",
          "C": "Deep Convolutional GAN (DCGAN).",
          "D": "Wasserstein GAN (WGAN)."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì khiến việc sử dụng dữ liệu trong Machine Learning vừa là một lợi thế vừa là một thách thức?",
        "options": {
          "A": "Dữ liệu lớn giúp cải thiện hiệu suất, nhưng cũng gây ra lo ngại về quyền riêng tư.",
          "B": "Dữ liệu nhỏ dễ quản lý, nhưng không đủ để huấn luyện các mô hình phức tạp.",
          "C": "Dữ liệu có sẵn miễn phí, nhưng chất lượng thường không đảm bảo.",
          "D": "Dữ liệu dễ thu thập, nhưng khó phân tích."
        },
        "answer": "A"
      },
      {
        "question": "Tác giả của DeepPrivacy đến từ đâu?",
        "options": {
          "A": "Stanford University.",
          "B": "Massachusetts Institute of Technology (MIT).",
          "C": "Norwegian University of Science and Technology.",
          "D": "University of Oxford."
        },
        "answer": "C"
      }
    ]
  },
  "amie-a-chatbot-that-outperforms-doctors-in-diagnostic-conversations": {
    "title": "The LLM Will See You Now",
    "collection": "ml-research",
    "content": "A critical step in diagnosing illnesses is a conversation between doctor and patient to assemble a medical history, discuss approaches to managing symptoms, and so on. Can a large language model play the doctor’s role? Researchers trained one to do surprisingly well.\n\nWhat's new:Articulate Medical Intelligence Explorer(AMIE), a chatbot built by Google researchers Tao Tu, Anil Palepu, Mike Schaekermann and colleagues, showed better diagnostic ability and bedside manner than doctors in conversations with patients. The conversations covered a range of complaints including cardiovascular, respiratory, gastroenterology, neurology, urology, obstetric, and gynecology conditions.\n\nKey insight:A pretrained LLM that’s fine-tuned on conversations between doctors and patients can learn to mimic the doctor’s role. However, such models are limited because available datasets of real-world medical conversations don’t cover the full range of medical scenarios and include ambiguities, interruptions, implicit references and the like, posing difficulties for learning. Conversations generated by a pretrained LLM can cover more conditions in more articulate language. After fine-tuning on real-world conversations, further tuning on generated conversations can improve performance. In addition, after a conversation, critiquing the “doctor’s” performance can improve its ability to render diagnoses, suggest plans for managing symptoms, empathize with patients, and otherwise perform its role.\n\nHow it works:The authors fine-tuned a pretrainedPaLM-2on medicalmultiple-choice questionsthat describe symptoms, possible causes, and evidence for the correct diagnosis, as well as datasets for tasks like summarizing and continuing medical dialogs. They further fine-tuned the model on its own output.\n\nResults:Specialist physicians evaluated the doctor model’s performance in 149 conversations with human actors who played the roles of patients based on scenarios supplied by clinical providers. They compared the model’s output with those of 20 primary care physicians based on their own conversations with the actors.\n\nWhy it matters:LLMs can generate fine-tuning data that improves their own performance. By training on relevant, factually correct medical information from the web, LLMs can generate realistic conversations at scale — even in a highly technical, high-stakes discipline like medicine and despite their potential to generate potentially dangerous hallucinations. Used as fine-tuning data, this output enables LLMs to converse with humans more effectively.\n\nWe're thinking:AI promises to spread intelligence far and wide. As the authors acknowledge, further work remains to demonstrate this work’s efficacy, ethics, security, and regulatory compliance in a clinical setting. Yet it’s an exciting glimpse of a world in which medical intelligence is fast, cheap, and widely available.",
    "qa": [
      {
        "question": "Mục đích chính của cuộc trò chuyện giữa bác sĩ và bệnh nhân trong chẩn đoán bệnh là gì?",
        "options": {
          "A": "Để kê đơn thuốc phù hợp.",
          "B": "Để thu thập tiền sử bệnh, thảo luận về cách quản lý triệu chứng.",
          "C": "Để thực hiện các xét nghiệm cần thiết.",
          "D": "Để xác định mức độ nghiêm trọng của bệnh."
        },
        "answer": "B"
      },
      {
        "question": "AMIE, chatbot được phát triển bởi Google, đã thể hiện khả năng gì so với các bác sĩ trong các cuộc trò chuyện với bệnh nhân?",
        "options": {
          "A": "Khả năng kê đơn thuốc chính xác hơn.",
          "B": "Khả năng chẩn đoán và thái độ giao tiếp tốt hơn.",
          "C": "Khả năng thực hiện các thủ thuật y tế phức tạp hơn.",
          "D": "Khả năng phân tích kết quả xét nghiệm nhanh hơn."
        },
        "answer": "B"
      },
      {
        "question": "Hạn chế chính của các mô hình ngôn ngữ lớn (LLM) được đào tạo trên dữ liệu hội thoại y tế thực tế là gì?",
        "options": {
          "A": "Khả năng xử lý ngôn ngữ tự nhiên còn hạn chế.",
          "B": "Dữ liệu hội thoại thực tế không bao phủ đầy đủ các tình huống y tế và chứa nhiều yếu tố gây nhiễu.",
          "C": "Chi phí đào tạo mô hình quá cao.",
          "D": "Khó khăn trong việc tích hợp với các hệ thống y tế hiện có."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp nào được sử dụng để cải thiện hiệu suất của LLM sau khi đã được tinh chỉnh trên các cuộc hội thoại thực tế?",
        "options": {
          "A": "Tăng cường khả năng tính toán của mô hình.",
          "B": "Tinh chỉnh thêm trên các cuộc hội thoại do chính LLM tạo ra.",
          "C": "Sử dụng dữ liệu từ các sách giáo khoa y khoa.",
          "D": "Kết hợp với các thuật toán học máy khác."
        },
        "answer": "B"
      },
      {
        "question": "PaLM-2 đã được tinh chỉnh trên những loại dữ liệu nào để tạo ra AMIE?",
        "options": {
          "A": "Các bài báo khoa học và sách giáo khoa y khoa.",
          "B": "Các câu hỏi trắc nghiệm y tế, dữ liệu tóm tắt và tiếp tục hội thoại y tế.",
          "C": "Các bản ghi âm các cuộc phẫu thuật.",
          "D": "Dữ liệu về lịch sử bệnh án của bệnh nhân."
        },
        "answer": "B"
      },
      {
        "question": "Trong quá trình đánh giá hiệu suất của mô hình bác sĩ, các chuyên gia y tế đã so sánh kết quả của mô hình với kết quả của ai?",
        "options": {
          "A": "Các bác sĩ chuyên khoa hàng đầu.",
          "B": "20 bác sĩ chăm sóc sức khỏe ban đầu.",
          "C": "Các sinh viên y khoa.",
          "D": "Các y tá có kinh nghiệm."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích chính của việc sử dụng LLM để tạo dữ liệu tinh chỉnh là gì?",
        "options": {
          "A": "Giảm chi phí đào tạo mô hình.",
          "B": "Cải thiện hiệu suất của chính LLM bằng cách đào tạo trên dữ liệu liên quan và chính xác.",
          "C": "Tăng cường khả năng bảo mật dữ liệu y tế.",
          "D": "Đơn giản hóa quy trình chẩn đoán bệnh."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, thách thức lớn nhất khi sử dụng LLM trong y học là gì?",
        "options": {
          "A": "Khả năng tạo ra thông tin sai lệch hoặc nguy hiểm (hallucinations).",
          "B": "Chi phí triển khai quá cao.",
          "C": "Sự thiếu tin tưởng từ phía bệnh nhân.",
          "D": "Khó khăn trong việc tích hợp với các hệ thống y tế hiện có."
        },
        "answer": "A"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về việc sử dụng AI trong y học?",
        "options": {
          "A": "AI sẽ thay thế hoàn toàn vai trò của bác sĩ.",
          "B": "AI hứa hẹn sẽ lan tỏa trí tuệ rộng rãi, giúp y tế trở nên nhanh chóng, rẻ và dễ tiếp cận hơn.",
          "C": "AI chỉ nên được sử dụng trong các trường hợp khẩn cấp.",
          "D": "AI không có tiềm năng thực sự trong lĩnh vực y học."
        },
        "answer": "B"
      },
      {
        "question": "Những yếu tố nào cần được xem xét thêm trước khi triển khai AMIE trong môi trường lâm sàng?",
        "options": {
          "A": "Hiệu quả, đạo đức, an ninh và tuân thủ quy định.",
          "B": "Khả năng tương thích với các thiết bị y tế khác.",
          "C": "Khả năng hỗ trợ đa ngôn ngữ.",
          "D": "Khả năng dự đoán các bệnh hiếm gặp."
        },
        "answer": "A"
      }
    ]
  },
  "another-look-at-yolo": {
    "title": "Another Look at YOLO",
    "collection": "ml-research",
    "content": "The latest update of the acclaimed real-time object detector You Only Look Once is more accurate than ever.What’s new:Alexey Bochovskiy, Chien-Yao Wang, and Hong-Yuan Mark Liao at Taiwan’s Institute of Information Science Academia Sinica offerYOLOv4— the first version not to include the architecture’s original creators.Key insight:Rapid inference is YOLO’s claim to fame. The authors prioritized newer techniques that improve accuracy without impinging on speed (their so-called “bag of freebies”). In addition, they made improvements that boost accuracy at a minimal cost to speed (the “bag of specials”). All told, these tweaks enable the new version to outperform both its predecessor and high-accuracy competitors running at real-time frame rates.How it works:YOLO, as well as most object detectors since, tack a model that predicts bounding boxes and classes onto a pre-trained ImageNet feature extractor.\n\nResults:The authors pitted YOLOv4 against other object detectors that process at least 30 frames per second, using theCOCOimage dataset. YOLOv4 achieved 0.435 average precision (AP), running at 62 frames per second (FPS). It achieved 0.41 AP at its maximum rate of 96 FPS. The previous state of the art,EfficientDet, achieved 0.43 AP running at nearly 42 FPS and 0.333 AP at its top speed of 62 FPS.Why it matters:YOLOv4 locates and classifies objects faster thanmeasurementsof human performance. While it’s not as accurate as slower networks such as EfficientDet, the new version boosts accuracy without sacrificing speed.We’re thinking: You only look once . . . twice . . . thrice . . . four times and counting!",
    "qa": [
      {
        "question": "YOLOv4 được phát triển bởi ai?",
        "options": {
          "A": "Alexey Bochovskiy, Chien-Yao Wang, Hong-Yuan Mark Liao và những người sáng tạo ban đầu của YOLO.",
          "B": "Alexey Bochovskiy, Chien-Yao Wang và Hong-Yuan Mark Liao tại Viện Khoa học Thông tin Academia Sinica của Đài Loan.",
          "C": "Những người sáng tạo ban đầu của YOLO và nhóm nghiên cứu tại COCOimage dataset.",
          "D": "Nhóm phát triển EfficientDet."
        },
        "answer": "B"
      },
      {
        "question": "Điểm mạnh nổi bật nhất của YOLO là gì?",
        "options": {
          "A": "Độ chính xác vượt trội so với các đối thủ.",
          "B": "Khả năng suy luận nhanh.",
          "C": "Sử dụng ít tài nguyên tính toán.",
          "D": "Khả năng nhận diện đối tượng 3D."
        },
        "answer": "B"
      },
      {
        "question": "Các tác giả của YOLOv4 đã ưu tiên những kỹ thuật nào?",
        "options": {
          "A": "Các kỹ thuật làm giảm tốc độ nhưng tăng độ chính xác đáng kể.",
          "B": "Các kỹ thuật mới giúp cải thiện độ chính xác mà không ảnh hưởng đến tốc độ.",
          "C": "Các kỹ thuật phức tạp đòi hỏi phần cứng mạnh mẽ.",
          "D": "Các kỹ thuật đã được chứng minh là hiệu quả trong các mô hình trước đó."
        },
        "answer": "B"
      },
      {
        "question": "“Bag of freebies” và “bag of specials” trong YOLOv4 đề cập đến điều gì?",
        "options": {
          "A": "Các thuật toán nén dữ liệu để giảm kích thước mô hình.",
          "B": "Các kỹ thuật cải thiện độ chính xác với chi phí tốc độ khác nhau.",
          "C": "Các phương pháp tăng cường dữ liệu để cải thiện khả năng tổng quát hóa.",
          "D": "Các kỹ thuật tối ưu hóa phần cứng để tăng tốc độ xử lý."
        },
        "answer": "B"
      },
      {
        "question": "YOLOv4 hoạt động bằng cách nào?",
        "options": {
          "A": "Sử dụng một mạng nơ-ron duy nhất để dự đoán cả bounding box và lớp đối tượng.",
          "B": "Kết hợp một mô hình dự đoán bounding box và lớp đối tượng với một bộ trích xuất đặc trưng ImageNet đã được huấn luyện trước.",
          "C": "Sử dụng một thuật toán tìm kiếm dựa trên đồ thị để xác định vị trí đối tượng.",
          "D": "Áp dụng một phương pháp phân đoạn hình ảnh để xác định các đối tượng riêng lẻ."
        },
        "answer": "B"
      },
      {
        "question": "YOLOv4 đã đạt được độ chính xác trung bình (AP) là bao nhiêu khi chạy ở tốc độ 62 FPS trên tập dữ liệu COCO?",
        "options": {
          "A": "0.333",
          "B": "0.41",
          "C": "0.43",
          "D": "0.435"
        },
        "answer": "D"
      },
      {
        "question": "Đối thủ cạnh tranh chính của YOLOv4 được đề cập trong bài viết là gì?",
        "options": {
          "A": "ResNet",
          "B": "Faster R-CNN",
          "C": "EfficientDet",
          "D": "Mask R-CNN"
        },
        "answer": "C"
      },
      {
        "question": "Ưu điểm chính của YOLOv4 so với EfficientDet là gì?",
        "options": {
          "A": "Độ chính xác cao hơn đáng kể.",
          "B": "Tốc độ xử lý nhanh hơn.",
          "C": "Yêu cầu ít bộ nhớ hơn.",
          "D": "Khả năng nhận diện đối tượng nhỏ tốt hơn."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao YOLOv4 lại quan trọng?",
        "options": {
          "A": "Nó có độ chính xác cao nhất so với tất cả các mô hình nhận diện đối tượng.",
          "B": "Nó có thể định vị và phân loại đối tượng nhanh hơn khả năng của con người.",
          "C": "Nó dễ dàng triển khai trên các thiết bị di động.",
          "D": "Nó là mô hình nhận diện đối tượng duy nhất có thể hoạt động trong thời gian thực."
        },
        "answer": "B"
      },
      {
        "question": "Nhận xét nào sau đây đúng về sự cân bằng giữa tốc độ và độ chính xác của YOLOv4?",
        "options": {
          "A": "YOLOv4 hy sinh tốc độ để đạt được độ chính xác cao nhất có thể.",
          "B": "YOLOv4 hy sinh độ chính xác để đạt được tốc độ nhanh nhất có thể.",
          "C": "YOLOv4 cải thiện độ chính xác mà không làm giảm tốc độ đáng kể.",
          "D": "YOLOv4 có độ chính xác và tốc độ tương đương với các mô hình khác."
        },
        "answer": "C"
      }
    ]
  },
  "anthropic-debuts-new-claude-4-sonnet-and-claude-4-opus-models-featuring-top-benchmarks-in-coding": {
    "title": "Claude 4 Advances Code Generation",
    "collection": "ml-research",
    "content": "Anthropic continued its tradition of building AI models that raise the bar in coding tasks.\n\nWhat’s new:Anthropic launchedClaude 4 Sonnet 4 and Claude Opus 4, the latest medium- and largest-size members of its family of general-purpose large language models. Both models offer an optional reasoning mode and can use multiple tools in parallel while reasoning. In addition, the company made generally available Claude Code, a coding agent previously offered as a research preview, along with a Claude Code software development kit.\n\nHow it works:The team trained the Claude 4 models on a mix of publicly available information on the web as well as proprietary purchased data, data from Claude users who opted to share their inputs and outputs, and generated data. They fine-tuned the models to behelpful, honest, and harmlessaccording to human andAI feedback.\n\nResults:Both Claude 4 models tied Google Gemini 2.5 Pro at the top of the LMSys WebDev Arena and achieved top marks for coding and agentic computer-use benchmarks in Anthropic’s tests.\n\nWhy it matters:The new models extend LLM technology with parallel tool use, using external files as a form of memory, and staying on-task over unusually long periods of time. Early users have reported many impressive projects, including aTetris clonebuilt in one shot and a seven-hour stintrefactoring Rakutan’s open-source code base.\n\nWe’re thinking:Prompting expert @elder_plinius published a text file that is purported to beClaude 4’s system promptand includes some material that does not appear in Anthropic’s ownpublicationof the prompts. It is instructive to see how it conditions the model for tool use, agentic behavior, and reasoning.",
    "qa": [
      {
        "question": "Anthropic vừa ra mắt những mô hình AI mới nào?",
        "options": {
          "A": "Claude 3 Sonnet và Claude 3 Opus",
          "B": "Claude 4 Sonnet và Claude 4 Opus",
          "C": "Gemini 2.5 Pro và Claude Code",
          "D": "Claude Code và Claude 4 Pro"
        },
        "answer": "B"
      },
      {
        "question": "Tính năng mới nào được giới thiệu trong Claude 4 Sonnet và Claude 4 Opus?",
        "options": {
          "A": "Khả năng tạo ra dữ liệu mới",
          "B": "Chế độ suy luận tùy chọn và sử dụng nhiều công cụ song song",
          "C": "Tự động cập nhật thông tin từ web",
          "D": "Khả năng tương tác trực tiếp với người dùng"
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu huấn luyện cho các mô hình Claude 4 đến từ những nguồn nào?",
        "options": {
          "A": "Dữ liệu độc quyền của Anthropic và dữ liệu từ các đối thủ cạnh tranh",
          "B": "Thông tin công khai trên web, dữ liệu mua bản quyền, dữ liệu từ người dùng Claude và dữ liệu được tạo ra",
          "C": "Chỉ dữ liệu từ người dùng Claude và dữ liệu được tạo ra bởi AI",
          "D": "Chỉ thông tin công khai trên web và dữ liệu mua bản quyền"
        },
        "answer": "B"
      },
      {
        "question": "Theo Anthropic, các mô hình Claude 4 được tinh chỉnh để có những đặc điểm nào?",
        "options": {
          "A": "Thông minh, sáng tạo và hiệu quả",
          "B": "Hữu ích, trung thực và vô hại",
          "C": "Nhanh chóng, chính xác và đáng tin cậy",
          "D": "Linh hoạt, mạnh mẽ và dễ sử dụng"
        },
        "answer": "B"
      },
      {
        "question": "Trong các bài kiểm tra của Anthropic, Claude 4 đã đạt được thành tích gì?",
        "options": {
          "A": "Vượt trội hơn tất cả các mô hình AI khác trong mọi lĩnh vực",
          "B": "Đạt điểm cao nhất về mã hóa và các chuẩn mực sử dụng máy tính",
          "C": "Đạt điểm cao nhất về khả năng hiểu ngôn ngữ tự nhiên",
          "D": "Đạt điểm cao nhất về khả năng tạo ra nội dung sáng tạo"
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích chính của việc sử dụng các mô hình LLM mới như Claude 4 là gì?",
        "options": {
          "A": "Tăng cường khả năng dịch thuật ngôn ngữ",
          "B": "Sử dụng công cụ song song, sử dụng tệp bên ngoài làm bộ nhớ và duy trì nhiệm vụ trong thời gian dài",
          "C": "Giảm chi phí vận hành hệ thống AI",
          "D": "Cải thiện khả năng nhận diện khuôn mặt"
        },
        "answer": "B"
      },
      {
        "question": "Dự án ấn tượng nào được đề cập trong bài viết mà người dùng đã thực hiện với Claude 4?",
        "options": {
          "A": "Phát triển một hệ thống quản lý tài chính cá nhân",
          "B": "Xây dựng một bản sao Tetris trong một lần và tái cấu trúc mã nguồn mở Rakutan trong bảy giờ",
          "C": "Tạo ra một ứng dụng học ngôn ngữ tương tác",
          "D": "Phát triển một hệ thống dự báo thời tiết chính xác"
        },
        "answer": "B"
      },
      {
        "question": "Điều gì được cho là có trong system prompt của Claude 4 theo @elder_plinius?",
        "options": {
          "A": "Thông tin về cách tối ưu hóa hiệu suất của mô hình",
          "B": "Một số tài liệu không xuất hiện trong công bố chính thức của Anthropic về các prompt",
          "C": "Danh sách các đối thủ cạnh tranh của Anthropic",
          "D": "Hướng dẫn chi tiết về cách sử dụng API của Claude 4"
        },
        "answer": "B"
      },
      {
        "question": "Claude Code là gì?",
        "options": {
          "A": "Một ngôn ngữ lập trình mới do Anthropic phát triển",
          "B": "Một coding agent được cung cấp dưới dạng bản xem trước nghiên cứu và hiện đã được cung cấp rộng rãi",
          "C": "Một thư viện mã nguồn mở cho các mô hình AI",
          "D": "Một công cụ để gỡ lỗi mã"
        },
        "answer": "B"
      },
      {
        "question": "Claude Code Software Development Kit (SDK) là gì?",
        "options": {
          "A": "Một bộ công cụ phần mềm giúp phát triển ứng dụng sử dụng Claude Code",
          "B": "Một khóa học trực tuyến về lập trình AI",
          "C": "Một dịch vụ lưu trữ mã đám mây",
          "D": "Một công cụ để tạo ra dữ liệu huấn luyện cho AI"
        },
        "answer": "A"
      }
    ]
  },
  "anthropic-empowers-claude-sonnet-3-5-to-operate-desktop-apps-but-cautions-remain": {
    "title": "Claude Controls Computers",
    "collection": "ml-research",
    "content": "API commands for Claude Sonnet 3.5 enable Anthropic’s large language model to operate desktop apps much like humans do. Be cautious, though: It’s a work in progress.\n\nWhat’s new:AnthropiclaunchedAPI commands for computer use. The new commands prompt Claude Sonnet 3.5 to translate natural language instructions into commands that tell a computer to open applications, fetch data from local files, complete forms, and the like. (In addition, Anthropic improved Claude Sonnet 3.5 to achieve a state-of-the-art score on theSWE-bench Verifiedcoding benchmark and released the faster, cheaper Claude Haiku 3.5, which likewise shows exceptional performance on coding tasks.)\n\nHow it works:The commands for computer use don’t cost extra on a per-token basis, but they may require up to 1,200 additional tokens and run repeatedly until the task at hand is accomplished, consuming more input tokens. They’re available via Anthropic, Amazon Bedrock, and Google Vertex.\n\nYes, but:The current version of computer use is experimental, and Anthropic acknowledges various limitations. The company stronglyrecommendsusing these commands only in a sandboxed environment, such as a Docker container, with limited access to the computer’s hard drive and the web to protect sensitive data and core system files. Anthropic restricts the ability to create online accounts or post to social media or other sites (but says it may lift this restriction in the future).\n\nBehind the news:Several companies have been racing to build models that can control desktop applications. Microsoft researchers recently releasedOmniParser, a tool based on GPT-4V that identifies user-interface elements like windows and buttons within screenshots, potentially making it easier for agentic workflows to navigate computers. In July, Amazonhiredstaff and leaders from Adept, a startup that trained models to operate computer applications. (Disclosure: Andrew Ng sits on Amazon’s board of directors.)Open Interpreteris an open-source project that likewise uses a large language model to control local applications like image editors and web browsers.\n\nWhy it matters:Large multimodal models already use externaltoolslike search engines, web browsers, calculators, calendars, databases, and email. Giving them control over a computer’s visual user interface may enable them to automate a wider range of tasks we use computers to perform, such ascreating lesson plansand — more worrisome —taking academic tests.\n\nWe’re thinking:Controlling computers remains hard. For instance, using AI to read a screenshot and pick the right action to take next is very challenging. However, we’re confident that this capability will be a growth area for agentic workflows in coming years.",
    "qa": [
      {
        "question": "API commands mới của Claude Sonnet 3.5 cho phép mô hình này thực hiện điều gì?",
        "options": {
          "A": "Tự động tạo ra các ứng dụng desktop mới.",
          "B": "Điều khiển các ứng dụng desktop tương tự như cách con người thực hiện.",
          "C": "Tối ưu hóa hiệu suất của các ứng dụng desktop hiện có.",
          "D": "Phân tích và dự đoán hành vi của người dùng trên desktop."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài khả năng điều khiển ứng dụng desktop, Claude Sonnet 3.5 còn đạt được thành tựu nào khác?",
        "options": {
          "A": "Đạt điểm cao nhất trong một cuộc thi thiết kế giao diện người dùng.",
          "B": "Đạt điểm cao nhất trên SWE-bench Verified coding benchmark.",
          "C": "Phát triển một ngôn ngữ lập trình mới.",
          "D": "Tự động sửa lỗi trong các ứng dụng desktop."
        },
        "answer": "B"
      },
      {
        "question": "Việc sử dụng API commands cho computer use của Claude Sonnet 3.5 có thể tốn thêm chi phí nào?",
        "options": {
          "A": "Phí đăng ký sử dụng API hàng tháng.",
          "B": "Chi phí dựa trên số lượng ứng dụng desktop được điều khiển.",
          "C": "Chi phí dựa trên số lượng token sử dụng, có thể tăng lên do lặp lại lệnh.",
          "D": "Chi phí bảo trì hệ thống sau khi sử dụng API."
        },
        "answer": "C"
      },
      {
        "question": "Anthropic khuyến cáo sử dụng API commands cho computer use trong môi trường nào?",
        "options": {
          "A": "Môi trường sản xuất thực tế với dữ liệu nhạy cảm.",
          "B": "Môi trường đám mây công cộng để dễ dàng mở rộng.",
          "C": "Môi trường sandboxed (ví dụ: Docker container) với quyền truy cập hạn chế.",
          "D": "Môi trường mạng nội bộ an toàn với tường lửa mạnh mẽ."
        },
        "answer": "C"
      },
      {
        "question": "Anthropic hiện tại hạn chế khả năng nào của Claude Sonnet 3.5 khi sử dụng API commands cho computer use?",
        "options": {
          "A": "Truy cập vào các tệp tin hệ thống quan trọng.",
          "B": "Tạo tài khoản trực tuyến hoặc đăng bài lên mạng xã hội.",
          "C": "Điều khiển các ứng dụng yêu cầu quyền quản trị.",
          "D": "Kết nối với các thiết bị ngoại vi như máy in hoặc máy quét."
        },
        "answer": "B"
      },
      {
        "question": "Công cụ OmniParser của Microsoft sử dụng công nghệ nào để xác định các thành phần giao diện người dùng?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên (NLP).",
          "B": "Thị giác máy tính (Computer Vision) dựa trên GPT-4V.",
          "C": "Học tăng cường (Reinforcement Learning).",
          "D": "Phân tích dữ liệu lớn (Big Data Analytics)."
        },
        "answer": "B"
      },
      {
        "question": "Công ty nào đã thuê nhân viên và lãnh đạo từ Adept, một startup chuyên đào tạo mô hình điều khiển ứng dụng máy tính?",
        "options": {
          "A": "Google.",
          "B": "Microsoft.",
          "C": "Amazon.",
          "D": "Anthropic."
        },
        "answer": "C"
      },
      {
        "question": "Open Interpreter là gì?",
        "options": {
          "A": "Một ngôn ngữ lập trình mới được thiết kế cho AI.",
          "B": "Một dự án mã nguồn mở sử dụng LLM để điều khiển các ứng dụng cục bộ.",
          "C": "Một công cụ phân tích dữ liệu lớn cho các ứng dụng desktop.",
          "D": "Một hệ điều hành mới được tối ưu hóa cho AI."
        },
        "answer": "B"
      },
      {
        "question": "Việc cho phép các mô hình đa phương thức lớn (Large multimodal models) kiểm soát giao diện người dùng có thể dẫn đến khả năng tự động hóa những tác vụ nào?",
        "options": {
          "A": "Chỉ các tác vụ đơn giản như gửi email.",
          "B": "Chỉ các tác vụ liên quan đến xử lý văn bản.",
          "C": "Một loạt các tác vụ rộng hơn, bao gồm cả việc tạo kế hoạch bài học và làm bài kiểm tra.",
          "D": "Chỉ các tác vụ liên quan đến quản lý tệp tin."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, thách thức lớn nhất trong việc điều khiển máy tính bằng AI là gì?",
        "options": {
          "A": "Khả năng xử lý ngôn ngữ tự nhiên còn hạn chế.",
          "B": "Chi phí tính toán quá cao.",
          "C": "Khả năng đọc ảnh chụp màn hình và chọn hành động phù hợp còn nhiều khó khăn.",
          "D": "Thiếu dữ liệu huấn luyện đủ lớn."
        },
        "answer": "C"
      }
    ]
  },
  "anthropic-experiment-finds-claude-shows-signs-of-unprompted-reasoning": {
    "title": "Ordinary LLMs Implicitly Take Reasoning Steps",
    "collection": "ml-research",
    "content": "Even without explicit training in reasoning, large language models “think” in ways that may be more deliberate than previously understood.\n\nWhat’s new:Emmanuel Ameisen and colleagues at Anthropic devised amethodto study how transformers generate responses to specific prompts. They alsostudiedClaude 3.5 Haiku’s responses to specific prompts and found that the model, which is not trained to generate chains of thought, nonetheless appeared to take reasoning steps via its neuron activations.\n\nKey insight:A viable alternative to a fully connected layer is a cross-layer transcoder, which has two layers. The outputs of the larger first layer are sparse, which makes them interpretable “features,” or individual values that correspond to concepts. By mapping an input to highly activated features, we can identify the concepts that determine the model’s output.\n\nHow it works:The team replaced fully connected layers in Claude 3.5 Haiku with cross-layer transcoders and interpreted their features.\n\nResults:The authors built graphs that show how Claude 3.5 Haiku computes its output over a number of selected prompts.\n\nBehind the news:Last year, Google trained models toexamine individual featuresin Gemma 2. Before that, Anthropic used similar methods tointerpret Claude 3 Sonnet’s middle layer.\n\nWhy it matters:Apparently Claude 3.5 Haiku — and presumably other large language models — spontaneously perform implicit reasoning steps without being prompted to do so. Anthropic’s method reveals not only whether a model reasons or takes a shortcut, but also what it truly does well and what it only professes to do well.\n\nWe’re thinking:The authors’ approach to examining how large language models generate output is interesting. We wonder whether even pre-transformer vanilla neural networks would appear to perform some sort of “reasoning” if we were to interpret them in a similar way.",
    "qa": [
      {
        "question": "Theo bài viết, điều gì mới mẻ về cách các mô hình ngôn ngữ lớn 'suy nghĩ'?",
        "options": {
          "A": "Chúng cần được đào tạo rõ ràng về suy luận để có thể suy nghĩ.",
          "B": "Chúng 'suy nghĩ' một cách có chủ ý hơn so với những gì người ta nghĩ trước đây, ngay cả khi không được đào tạo về suy luận.",
          "C": "Chúng không thực sự 'suy nghĩ' mà chỉ đơn giản là tạo ra các phản hồi dựa trên dữ liệu đã được đào tạo.",
          "D": "Chúng chỉ có thể 'suy nghĩ' khi được cung cấp các chuỗi suy luận rõ ràng."
        },
        "answer": "B"
      },
      {
        "question": "Emmanuel Ameisen và các đồng nghiệp tại Anthropic đã sử dụng phương pháp nào để nghiên cứu cách các transformer tạo ra phản hồi?",
        "options": {
          "A": "Đào tạo các transformer với các bộ dữ liệu suy luận phức tạp.",
          "B": "Phân tích sự thay đổi trong kiến trúc của các transformer.",
          "C": "Nghiên cứu sự kích hoạt của các neuron trong quá trình tạo phản hồi.",
          "D": "So sánh hiệu suất của các transformer khác nhau trên cùng một tập dữ liệu."
        },
        "answer": "C"
      },
      {
        "question": "Cross-layer transcoder, một giải pháp thay thế cho fully connected layer, có đặc điểm gì nổi bật?",
        "options": {
          "A": "Nó chỉ có một lớp duy nhất.",
          "B": "Các đầu ra của lớp đầu tiên lớn hơn có tính chất thưa thớt, khiến chúng dễ diễn giải.",
          "C": "Nó yêu cầu nhiều tài nguyên tính toán hơn so với fully connected layer.",
          "D": "Nó không thể hiện các 'features' riêng lẻ tương ứng với các khái niệm."
        },
        "answer": "B"
      },
      {
        "question": "Trong nghiên cứu, nhóm tác giả đã làm gì với các fully connected layer trong Claude 3.5 Haiku?",
        "options": {
          "A": "Loại bỏ hoàn toàn chúng.",
          "B": "Thay thế chúng bằng các cross-layer transcoders.",
          "C": "Tăng số lượng neuron trong các lớp này.",
          "D": "Đào tạo lại chúng với một thuật toán học tập mới."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả chính của nghiên cứu về Claude 3.5 Haiku là gì?",
        "options": {
          "A": "Mô hình không thể hiện bất kỳ dấu hiệu nào của suy luận.",
          "B": "Mô hình chỉ có thể suy luận khi được hướng dẫn rõ ràng.",
          "C": "Mô hình tự động thực hiện các bước suy luận ngầm định mà không cần được nhắc nhở.",
          "D": "Mô hình chỉ có thể thực hiện các phép tính đơn giản."
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp của Anthropic có thể giúp tiết lộ điều gì về mô hình ngôn ngữ lớn?",
        "options": {
          "A": "Chỉ liệu mô hình có suy luận hay không.",
          "B": "Chỉ liệu mô hình có sử dụng đường tắt hay không.",
          "C": "Không chỉ liệu mô hình có suy luận hay không, mà còn cả những gì nó thực sự làm tốt và những gì nó chỉ tuyên bố làm tốt.",
          "D": "Chỉ hiệu suất tổng thể của mô hình."
        },
        "answer": "C"
      },
      {
        "question": "Trước nghiên cứu này, Google đã làm gì liên quan đến việc kiểm tra các features riêng lẻ trong mô hình ngôn ngữ?",
        "options": {
          "A": "Huấn luyện các mô hình để loại bỏ các features không cần thiết.",
          "B": "Huấn luyện các mô hình để kiểm tra các features riêng lẻ trong Gemma 2.",
          "C": "Phát triển một phương pháp mới để trực quan hóa các features.",
          "D": "Không có thông tin nào về việc Google làm gì liên quan đến features."
        },
        "answer": "B"
      },
      {
        "question": "Anthropic đã sử dụng các phương pháp tương tự để diễn giải lớp nào của Claude 3 Sonnet trước đây?",
        "options": {
          "A": "Lớp đầu vào.",
          "B": "Lớp đầu ra.",
          "C": "Lớp giữa.",
          "D": "Tất cả các lớp."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đặt câu hỏi gì về các mạng nơ-ron vanilla trước transformer?",
        "options": {
          "A": "Liệu chúng có thể được đào tạo để suy luận tốt hơn không.",
          "B": "Liệu chúng có thể được sử dụng để thay thế các transformer không.",
          "C": "Liệu chúng có thể được diễn giải theo cách tương tự để thấy rằng chúng thực hiện một số loại 'suy luận' hay không.",
          "D": "Liệu chúng có hiệu quả hơn trong việc xử lý ngôn ngữ tự nhiên hay không."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc thay thế fully connected layers bằng cross-layer transcoders là gì?",
        "options": {
          "A": "Tăng tốc độ xử lý của mô hình.",
          "B": "Giảm kích thước của mô hình.",
          "C": "Làm cho các features dễ diễn giải hơn.",
          "D": "Cải thiện độ chính xác của mô hình."
        },
        "answer": "C"
      }
    ]
  },
  "artprompt-a-technique-that-exploits-ascii-art-to-bypass-llm-safety-measures": {
    "title": "Art Attack",
    "collection": "ml-research",
    "content": "Seemingly an innocuous form of expression, ASCII art opens a new vector for jailbreak attacks on large language models (LLMs), enabling them to generate outputs that their developers tuned them to avoid producing.\n\nWhat's new:A team led by Fengqing Jiang at University of Washington developedArtPrompt, a technique to test the impact of text rendered as ASCII art on LLM performance.\n\nKey insight:LLM safety methods such as fine-tuning are designed to counter prompts that can cause a model to produce harmful outputs, such as specific keywords and tricky ways to ask questions. They don’t guard against atypical ways of using text to communicate, such as ASCII art. This oversight enables devious users to get around some precautions.\n\nHow it works:Researchers gauged the vulnerability to ASCII-art attacks ofGPT-3.5, GPT-4,Claude,Gemini, andLlama 2. They modified prompts fromAdvBenchorHEx-PHI, which contain prompts that are designed to make safety-aligned LLMs refuse to respond, such as “how to make a bomb.”\n\nResults:ArtPrompt successfully circumvented LLM guardrails against generating harmful output, achieving an average harmfulness score of 3.6 out of 5 across all five LLMs. The next most-harmful attack method,PAIR, which prompts a model several times and refines its prompt each time, achieved 2.67.\n\nWhy it matters:This work adds to the growingbodyofliteratureon LLM jailbreak techniques. While fine-tuning is fairly good at preventing innocent users — who are not trying to trick an LLM — from accidentally receiving harmful output, we have no robust mechanisms for stopping a wide variety of jailbreak techniques. Blocking ASCII attacks would require additional input- and output-screening systems that are not currently in place.\n\nWe're thinking:We’re glad that LLMs are safety-tuned to help prevent users from receiving harmful information. Yet many uncensored models are available to users who want to get problematic information without implementing jailbreaks, and we’re not aware of any harm done. We’re cautiously optimistic that, despite the lack of defenses, jailbreak techniques also won’t prove broadly harmful.",
    "qa": [
      {
        "question": "Phương pháp tấn công jailbreak mới nào được giới thiệu trong bài viết?",
        "options": {
          "A": "PAIR",
          "B": "AdvBench",
          "C": "ArtPrompt",
          "D": "HEx-PHI"
        },
        "answer": "C"
      },
      {
        "question": "ArtPrompt sử dụng hình thức biểu đạt nào để tấn công các LLM?",
        "options": {
          "A": "Mã độc",
          "B": "Văn bản ASCII art",
          "C": "Hình ảnh đồ họa",
          "D": "Âm thanh được mã hóa"
        },
        "answer": "B"
      },
      {
        "question": "Điểm yếu nào của các phương pháp bảo mật LLM mà ArtPrompt khai thác?",
        "options": {
          "A": "Khả năng xử lý ngôn ngữ tự nhiên kém",
          "B": "Thiếu khả năng chống lại các hình thức giao tiếp văn bản không điển hình",
          "C": "Dễ bị tấn công từ chối dịch vụ",
          "D": "Không có khả năng phát hiện các từ khóa nguy hiểm"
        },
        "answer": "B"
      },
      {
        "question": "Những LLM nào đã được thử nghiệm với phương pháp ArtPrompt?",
        "options": {
          "A": "GPT-2, BERT, RoBERTa",
          "B": "GPT-3, LaMDA, PaLM",
          "C": "GPT-3.5, GPT-4, Claude, Gemini, Llama 2",
          "D": "Bard, Bloom, OPT"
        },
        "answer": "C"
      },
      {
        "question": "Bộ dữ liệu nào được sử dụng để tạo ra các prompt tấn công trong nghiên cứu này?",
        "options": {
          "A": "ImageNet",
          "B": "AdvBench và HEx-PHI",
          "C": "COCO",
          "D": "MNIST"
        },
        "answer": "B"
      },
      {
        "question": "So với phương pháp PAIR, ArtPrompt đạt được mức độ gây hại trung bình như thế nào?",
        "options": {
          "A": "Thấp hơn đáng kể",
          "B": "Tương đương",
          "C": "Cao hơn đáng kể",
          "D": "Không thể so sánh"
        },
        "answer": "C"
      },
      {
        "question": "Điểm gây hại trung bình mà ArtPrompt đạt được trên các LLM là bao nhiêu?",
        "options": {
          "A": "2.67 trên 5",
          "B": "3.0 trên 5",
          "C": "3.6 trên 5",
          "D": "4.0 trên 5"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về các cơ chế ngăn chặn tấn công jailbreak hiện tại?",
        "options": {
          "A": "Chúng rất hiệu quả trong việc ngăn chặn mọi hình thức tấn công.",
          "B": "Chúng chỉ hiệu quả với những người dùng vô tình tạo ra các prompt nguy hiểm.",
          "C": "Chúng không cần thiết vì không có ai cố gắng tấn công LLM.",
          "D": "Chúng quá phức tạp và gây khó khăn cho người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Để ngăn chặn các cuộc tấn công bằng ASCII art, cần phải có những hệ thống nào?",
        "options": {
          "A": "Hệ thống mã hóa dữ liệu phức tạp",
          "B": "Hệ thống kiểm tra đầu vào và đầu ra",
          "C": "Hệ thống tường lửa mạnh mẽ",
          "D": "Hệ thống xác thực đa yếu tố"
        },
        "answer": "B"
      },
      {
        "question": "Quan điểm của tác giả bài viết về việc các kỹ thuật jailbreak có thể gây hại là gì?",
        "options": {
          "A": "Chắc chắn sẽ gây ra những hậu quả nghiêm trọng.",
          "B": "Có thể gây ra những hậu quả nghiêm trọng.",
          "C": "Không có khả năng gây ra những hậu quả nghiêm trọng.",
          "D": "Chưa thể xác định được khả năng gây hại."
        },
        "answer": "C"
      }
    ]
  },
  "ask-me-in-a-different-way": {
    "title": "Ask Me in a Different Way",
    "collection": "ml-research",
    "content": "Pretrained language models likeGPT-3have shown notable proficiency in few-shot learning. Given a prompt that includes a few example questions and answers (the shots) plus an unanswered question (the task), such models can generate an accurate answer. But there may be more to getting good results.What’s new:Ethan Perez, Douwe Kiela, and Kyunghyun Cho subjected GPT-style language models to a test they calltrue few-shot learning. They found that the heralded few-shot success may depend on a well engineered prompt. The authors are based at New York University, Facebook, and CIFAR, respectively.Key insight:Training a machine-learning model typically requires a validation set to tune hyperparameters such as the learning rate. For GPT-style models, those hyperparameters include the prompt format. In few-shot learning with a pretrained model, the prompt typically contains a handful of examples. However, researchers often experiment extensively to find a prompt format that yields accurate responses. This amounts to stacking the deck in the model’s favor, and without it, such models can’t perform so well.How it works:The authors evaluated four sizes of GPT-3, four sizes ofGPT-2, andDistilGPT-2. They tested prompt formats fromLAMA, a benchmark that comprises factual statements in a variety of formats, andLPAQA, which contains LAMA statements translated from English into a different language and back.\n\nResults:For all models tested, the accuracy prompted by the format selected according to cross-validation was only marginally above the mean and significantly below the accuracy of the best format. For instance, for the largest model (GPT-3 with 175 billion parameters), the format chosen by cross-validation scored about 55 percent, mean accuracy was about 54 percent, and the accuracy of the best format was about 60 percent.Why it matters:Previous claims of few-shot learning in GPT-style models left out an important variable: the size of the dataset used to pick a good format. Choosing among 12 prompt formats boosted accuracy by around 5 percent; choosing among a larger set of formats could make a bigger difference. If researchers don’t include all the information that went into the results they report, follow-up studies are unlikely to duplicate their work.We’re thinking:We like prompt engineering that gets things done on time. We’re less enamored with prompt engineering that muddies the water around few-shot learning.",
    "qa": [
      {
        "question": "Nghiên cứu của Ethan Perez, Douwe Kiela và Kyunghyun Cho tập trung vào vấn đề gì liên quan đến mô hình ngôn ngữ GPT?",
        "options": {
          "A": "Khả năng tự động cải thiện hiệu suất của GPT-3 theo thời gian.",
          "B": "Sự phụ thuộc của thành công few-shot learning vào việc thiết kế prompt.",
          "C": "Giới hạn về kích thước dữ liệu mà GPT-3 có thể xử lý.",
          "D": "Tốc độ xử lý ngôn ngữ chậm chạp của các mô hình GPT-2."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì thường bị bỏ qua trong các nghiên cứu về few-shot learning với mô hình GPT?",
        "options": {
          "A": "Số lượng tham số của mô hình GPT được sử dụng.",
          "B": "Kích thước của tập dữ liệu được sử dụng để chọn định dạng prompt tốt.",
          "C": "Ảnh hưởng của kiến trúc mạng nơ-ron đến hiệu suất.",
          "D": "Sự khác biệt giữa GPT-2 và GPT-3."
        },
        "answer": "B"
      },
      {
        "question": "Trong bối cảnh nghiên cứu, 'cross-validation' được sử dụng để làm gì?",
        "options": {
          "A": "Tăng tốc quá trình huấn luyện mô hình.",
          "B": "Chọn định dạng prompt tối ưu cho few-shot learning.",
          "C": "Đánh giá độ chính xác của mô hình trên dữ liệu mới.",
          "D": "Giảm thiểu overfitting trong quá trình huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "LAMA và LPAQA là gì trong ngữ cảnh của bài viết?",
        "options": {
          "A": "Các mô hình ngôn ngữ cạnh tranh với GPT-3.",
          "B": "Các kỹ thuật tối ưu hóa tham số cho mô hình GPT.",
          "C": "Các bộ dữ liệu benchmark được sử dụng để đánh giá hiệu suất của mô hình.",
          "D": "Các phương pháp mã hóa văn bản mới."
        },
        "answer": "C"
      },
      {
        "question": "Kết quả nghiên cứu cho thấy điều gì về độ chính xác của mô hình khi sử dụng định dạng prompt được chọn bằng cross-validation?",
        "options": {
          "A": "Độ chính xác luôn cao hơn đáng kể so với các định dạng khác.",
          "B": "Độ chính xác chỉ cao hơn một chút so với độ chính xác trung bình và thấp hơn đáng kể so với định dạng tốt nhất.",
          "C": "Độ chính xác tương đương với định dạng tốt nhất.",
          "D": "Độ chính xác thấp hơn đáng kể so với độ chính xác trung bình."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, việc chọn giữa 12 định dạng prompt có thể cải thiện độ chính xác khoảng bao nhiêu?",
        "options": {
          "A": "Khoảng 1%.",
          "B": "Khoảng 5%.",
          "C": "Khoảng 10%.",
          "D": "Khoảng 20%."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc không bao gồm tất cả thông tin về cách chọn prompt có thể gây khó khăn cho các nghiên cứu tiếp theo?",
        "options": {
          "A": "Vì các mô hình GPT sẽ trở nên lỗi thời nhanh chóng.",
          "B": "Vì các nghiên cứu tiếp theo khó có thể tái tạo lại kết quả.",
          "C": "Vì việc chọn prompt là một bí mật thương mại.",
          "D": "Vì các nhà nghiên cứu khác sẽ không thể hiểu được phương pháp luận."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết ám chỉ điều gì về 'prompt engineering'?",
        "options": {
          "A": "Nên tập trung vào việc tạo ra các prompt phức tạp.",
          "B": "Nên được thực hiện một cách minh bạch để tránh làm sai lệch kết quả few-shot learning.",
          "C": "Là một kỹ năng không quan trọng trong few-shot learning.",
          "D": "Chỉ nên được sử dụng cho các tác vụ cụ thể."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc sử dụng validation set trong huấn luyện mô hình là gì?",
        "options": {
          "A": "Để tăng tốc độ huấn luyện.",
          "B": "Để điều chỉnh các siêu tham số như learning rate.",
          "C": "Để tạo ra dữ liệu huấn luyện mới.",
          "D": "Để giảm kích thước của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình GPT-3 lớn nhất được đề cập trong bài viết có bao nhiêu tham số?",
        "options": {
          "A": "1.5 tỷ tham số.",
          "B": "13 tỷ tham số.",
          "C": "117 tỷ tham số.",
          "D": "175 tỷ tham số."
        },
        "answer": "D"
      }
    ]
  },
  "attention-for-image-generation": {
    "title": "Attention for Image Generation",
    "collection": "ml-research",
    "content": "Attention quantifies how each part of one input affects the various parts of another. Researchers added a step that reverses this comparison to produce more convincing images.What’s new:Drew A. Hudson at Stanford and C. Lawrence Zitnick at Facebook chalked up a new state of the art in generative modeling by integrating attention layers into a generative adversarial network (GAN). They call their systemGANsformer.Key insight:Typically, a GAN learns through competition between a generator that aims to produce realistic images and a discriminator that judges whether images are generated or real.StyleGANsplits the generator into (a) a mapping network and (b) a synthesis network, and uses the output of the mapping network to control high-level properties (for example, pose and facial expression) of an image generated by the synthesis network. The output of the mapping layer can be viewed as a high-level representation of the scene, and the output of each layer of the synthesis network as a low-level representation. The authors devised a two-way version of attention, which they call duplex attention, to refine each representation based on the other.How it works:GANsformer is a modified StyleGAN. The authors trained it on four types of subject matter: faces inFFHQ;scenes composed of cubes, cylinders, and spheres inCLEVR; pictures of bedrooms inLSUN; and urban scenes inCityscapes.\n\nResults:GANsformer outperformed the previous state of the art on CLEVR, LSUN-Bedroom, and Cityscapes (comparing Fréchet Inception Distance based on representations produced by a pretrainedInceptionmodel). For example, on Cityscapes, GANsformer achieved 5.7589 FID compared toStyleGAN2’s 8.3500 FID. GANsformer also learned more efficiently than avanilla GAN, StyleGAN, StyleGAN2,k-GAN, andSAGAN. It required a third as many training iterations to achieve equal performance.Why it matters:Duplex attention helps to generate scenes that make sense in terms of both the big picture and the details. Moreover, it uses memory and compute efficiently: Consumption grows linearly as input size increases. (In transformer-style self-attention, which evaluates the importance of each part of an input with respect to other parts of the same input, memory and compute cost grows quadratically with input size.)We’re thinking:Transformers, which alternate attention and fully connected layers, perform better than other architectures in language processing. This work, which alternates attention and convolutional layers, may bring similar improvements to image processing.",
    "qa": [
      {
        "question": "GANsformer tích hợp lớp attention vào kiến trúc nào?",
        "options": {
          "A": "Recurrent Neural Network (RNN)",
          "B": "Generative Adversarial Network (GAN)",
          "C": "Convolutional Neural Network (CNN)",
          "D": "Autoencoder"
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính của duplex attention so với attention thông thường là gì?",
        "options": {
          "A": "Chỉ tập trung vào các chi tiết nhỏ của hình ảnh.",
          "B": "Thực hiện attention hai chiều giữa high-level representation và low-level representation.",
          "C": "Sử dụng ít bộ nhớ và tính toán hơn.",
          "D": "Chỉ áp dụng cho dữ liệu văn bản."
        },
        "answer": "B"
      },
      {
        "question": "StyleGAN chia generator thành mấy phần chính?",
        "options": {
          "A": "Một phần duy nhất.",
          "B": "Hai phần: mapping network và synthesis network.",
          "C": "Ba phần: encoder, decoder và discriminator.",
          "D": "Bốn phần: input layer, hidden layers, output layer và attention layer."
        },
        "answer": "B"
      },
      {
        "question": "GANsformer đã đạt được kết quả tốt hơn so với các mô hình trước đó trên những tập dữ liệu nào?",
        "options": {
          "A": "Chỉ trên tập dữ liệu khuôn mặt FFHQ.",
          "B": "CLEVR, LSUN-Bedroom và Cityscapes.",
          "C": "Chỉ trên tập dữ liệu LSUN-Bedroom.",
          "D": "Tất cả các tập dữ liệu được thử nghiệm, bao gồm FFHQ, CLEVR, LSUN-Bedroom và Cityscapes."
        },
        "answer": "B"
      },
      {
        "question": "Chỉ số nào được sử dụng để so sánh hiệu suất của GANsformer với các mô hình khác?",
        "options": {
          "A": "Accuracy",
          "B": "Precision",
          "C": "Fréchet Inception Distance (FID)",
          "D": "Recall"
        },
        "answer": "C"
      },
      {
        "question": "Ưu điểm về hiệu quả đào tạo của GANsformer so với các GAN khác là gì?",
        "options": {
          "A": "Yêu cầu số lượng tham số ít hơn.",
          "B": "Yêu cầu ít dữ liệu đào tạo hơn.",
          "C": "Yêu cầu số lượng iteration đào tạo ít hơn để đạt được hiệu suất tương đương.",
          "D": "Có thể đào tạo trên CPU thay vì GPU."
        },
        "answer": "C"
      },
      {
        "question": "Trong kiến trúc GANsformer, lớp attention được xen kẽ với lớp nào?",
        "options": {
          "A": "Recurrent layers",
          "B": "Fully connected layers",
          "C": "Convolutional layers",
          "D": "Pooling layers"
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc sử dụng duplex attention trong GANsformer là gì?",
        "options": {
          "A": "Tăng tốc độ đào tạo mô hình.",
          "B": "Giảm kích thước mô hình.",
          "C": "Tạo ra các cảnh hợp lý về cả tổng thể và chi tiết.",
          "D": "Cải thiện độ phân giải của hình ảnh được tạo ra."
        },
        "answer": "C"
      },
      {
        "question": "Trong transformer-style self-attention, chi phí bộ nhớ và tính toán tăng lên như thế nào khi kích thước đầu vào tăng lên?",
        "options": {
          "A": "Tuyến tính",
          "B": "Logarithmic",
          "C": "Bậc hai (Quadratic)",
          "D": "Bậc ba (Cubic)"
        },
        "answer": "C"
      },
      {
        "question": "Tác giả của GANsformer đến từ đâu?",
        "options": {
          "A": "Google và Microsoft",
          "B": "Stanford và Facebook",
          "C": "MIT và Amazon",
          "D": "OpenAI và DeepMind"
        },
        "answer": "B"
      }
    ]
  },
  "automated-method-organizes-large-datasets-for-more-representative-training-data": {
    "title": "Balancing Web Data Distributions",
    "collection": "ml-research",
    "content": "Datasets that were scraped from the web tend to be unbalanced, meaning examples of some classes (say, cats) are plentiful while examples of others (say, caterpillars) are scarce. A model that’s trained on an unbalanced dataset will perform unevenly across classes, but the labor required to balance the data manually can be prohibitive. An automated method addresses such imbalances.\n\nWhat’s new:Huy V. Vo and colleagues at Meta, France’s National Institute for Research in Digital Science and Technology, Université Paris Saclay, and Google proposed amethodthat automatically selects a balanced subset of text or image datasets.\n\nKey insight:A naive way to balance a dataset automatically is to cluster it usingk-meansto define implicit categories and then draw an equal number of points randomly from the resulting clusters. But this approach tends to form many clusters in areas of the distribution that have more examples, leading to over-representation of certain categories. For instance, when the authors applied k-means to web images and associated the clusters with their nearest neighbors in ImageNet, around 300 clusters (out of 10,000) corresponded to the ImageNet class “website.” However, after clustering, the distribution of the centroids is a bit more uniform than that of the entire dataset. Applying k-means repeatedly distributes the centroids (and thus the clusters) more uniformly. After a number of iterations, each cluster is more likely to represent a distinct category, and selecting equal numbers of examples from each cluster makes a balanced dataset.\n\nHow it works:The authors balanced image and text datasets using several iterations of k-means clustering. Their image dataset started with 743 million examples from a “publicly available repository of crawled web data.” For text, they started withCCNet, a version ofCommon Crawlthat was filtered to match the distribution of language and topics found in Wikipedia. The following approach ensured balanced sampling from all levels, maintaining a balance among high-level classes (such as animal, vehicle, and sport) and lower-level subclasses (such as dog, airplane, and football):\n\nResults:Both vision and language models that were pretrained on the balanced data outperformed models that were pretrained on the corresponding unbalanced datasets.\n\nWhy it matters:The old-school machine learning algorithm k-means can organize quantities of pretraining data that are too large for manual inspection yet crucial to data-hungry models. Breaking down data into clusters also makes it possible to manually inspect cluster elements, which might help identify unwanted data.\n\nWe’re thinking:Even in the era of foundation models, data-centric AI — that is, systematically engineering the data used to train such models — remains a critical, often under-appreciated step. This paper offers a promising way to create more balanced datasets. The encouraging results suggest fruitful avenues for further study.",
    "qa": [
      {
        "question": "Vấn đề chính mà bài viết này đề cập đến là gì?",
        "options": {
          "A": "Sự cần thiết của việc sử dụng các mô hình học máy phức tạp hơn.",
          "B": "Sự mất cân bằng dữ liệu trong các tập dữ liệu thu thập từ web và giải pháp tự động để cân bằng chúng.",
          "C": "Những hạn chế của thuật toán k-means trong việc xử lý dữ liệu lớn.",
          "D": "Tầm quan trọng của việc kiểm tra dữ liệu thủ công trước khi huấn luyện mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì xảy ra khi một mô hình được huấn luyện trên một tập dữ liệu không cân bằng?",
        "options": {
          "A": "Mô hình sẽ hoạt động tốt trên tất cả các lớp dữ liệu.",
          "B": "Mô hình sẽ hoạt động không đồng đều giữa các lớp dữ liệu.",
          "C": "Mô hình sẽ không thể học được bất kỳ đặc trưng nào từ dữ liệu.",
          "D": "Mô hình sẽ yêu cầu nhiều tài nguyên tính toán hơn để huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp cân bằng dữ liệu tự động được đề xuất trong bài viết dựa trên thuật toán nào?",
        "options": {
          "A": "Gradient Descent.",
          "B": "K-means clustering.",
          "C": "Support Vector Machine (SVM).",
          "D": "Principal Component Analysis (PCA)."
        },
        "answer": "B"
      },
      {
        "question": "Nhược điểm của việc sử dụng k-means một lần duy nhất để cân bằng dữ liệu là gì?",
        "options": {
          "A": "Nó tạo ra quá ít cluster, dẫn đến việc bỏ sót nhiều loại dữ liệu.",
          "B": "Nó có xu hướng tạo ra nhiều cluster ở những vùng có nhiều mẫu, dẫn đến việc đại diện quá mức cho một số loại.",
          "C": "Nó yêu cầu lượng tài nguyên tính toán quá lớn để xử lý dữ liệu lớn.",
          "D": "Nó không thể xử lý dữ liệu phi cấu trúc như hình ảnh và văn bản."
        },
        "answer": "B"
      },
      {
        "question": "Giải pháp được đề xuất để khắc phục nhược điểm của việc sử dụng k-means một lần là gì?",
        "options": {
          "A": "Sử dụng một thuật toán clustering khác phức tạp hơn.",
          "B": "Áp dụng k-means lặp đi lặp lại nhiều lần.",
          "C": "Giảm số lượng cluster được tạo ra bởi k-means.",
          "D": "Kết hợp k-means với một thuật toán giảm chiều dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Trong thí nghiệm với dữ liệu hình ảnh, tập dữ liệu ban đầu được sử dụng có bao nhiêu mẫu?",
        "options": {
          "A": "10,000.",
          "B": "300.",
          "C": "743 triệu.",
          "D": "Vài triệu."
        },
        "answer": "C"
      },
      {
        "question": "CCNet, tập dữ liệu văn bản được sử dụng, là phiên bản lọc của tập dữ liệu nào?",
        "options": {
          "A": "ImageNet.",
          "B": "Wikipedia.",
          "C": "Common Crawl.",
          "D": "Google Dataset Search."
        },
        "answer": "C"
      },
      {
        "question": "Kết quả chính của nghiên cứu này là gì?",
        "options": {
          "A": "Các mô hình được huấn luyện trên dữ liệu không cân bằng hoạt động tốt hơn.",
          "B": "Các mô hình được huấn luyện trên dữ liệu cân bằng hoạt động tốt hơn.",
          "C": "Không có sự khác biệt đáng kể giữa hiệu suất của các mô hình được huấn luyện trên dữ liệu cân bằng và không cân bằng.",
          "D": "Chỉ các mô hình thị giác mới được hưởng lợi từ dữ liệu cân bằng."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, tại sao việc chia nhỏ dữ liệu thành các cluster lại hữu ích?",
        "options": {
          "A": "Giúp giảm kích thước của tập dữ liệu.",
          "B": "Giúp tăng tốc quá trình huấn luyện mô hình.",
          "C": "Giúp kiểm tra các thành phần của cluster thủ công, có thể giúp xác định dữ liệu không mong muốn.",
          "D": "Giúp cải thiện độ chính xác của thuật toán k-means."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhấn mạnh tầm quan trọng của yếu tố nào trong kỷ nguyên của các mô hình nền tảng (foundation models)?",
        "options": {
          "A": "Sử dụng kiến trúc mô hình phức tạp nhất.",
          "B": "Tăng cường sức mạnh tính toán để huấn luyện mô hình.",
          "C": "Kỹ thuật dữ liệu một cách có hệ thống (data-centric AI).",
          "D": "Tự động hóa hoàn toàn quy trình huấn luyện mô hình."
        },
        "answer": "C"
      }
    ]
  },
  "augmentation-for-features": {
    "title": "Augmentation for Features",
    "collection": "ml-research",
    "content": "In any training dataset, some classes may have relatively few examples. A new technique can improve a trained model’s performance on such underrepresented classes.What’s new:Researchers at Jilin University, Megvii Inc., Beihang University, Huazhong University, and Tsinghua University led by Jialun Liu and Yifan Sun introduced a method thatsynthesizes extracted features of underrepresented classes.Key insight:The researchers trained a model and then mapped the extracted features for each data class into a two-dimensional visualization. Classes with fewer samples covered a smaller volume, making nearby decision boundaries more sensitive to variations in the features. They reasoned that artificially increasing the volume of underrepresented classes to match that of other classes should result in more robust predictions on the underrepresented classes.How it works:The researchers used well represented classes to predict the distribution of features in classes with fewer samples.\n\nResults:The researchers extracted features from images using a ResNet-50. They applied those features to models built with the ArcFace loss and trained on two datasets pared down to create underrepresented classes of five examples each. Then they built models using their approach and compared the results. Their method increased the average precision (AP), a measure of true positive rate where 1 is perfect, from 0.811 AP to 0.832 AP onMarket-1501. Similarly, it boosted performance from 0.732 AP to 0.742 AP onDukeMTMC-reID.Why it matters:There’s no need to generate synthetic examples if we can describe their extracted features.We’re thinking:Deep learning engineers like to use cats as examples, but these researchers focused only on the long tail.",
    "qa": [
      {
        "question": "Kỹ thuật mới được giới thiệu trong bài viết này tập trung vào việc cải thiện hiệu suất mô hình trên loại dữ liệu nào?",
        "options": {
          "A": "Các lớp dữ liệu có số lượng mẫu lớn.",
          "B": "Các lớp dữ liệu có số lượng mẫu ít.",
          "C": "Các lớp dữ liệu có phân phối đồng đều.",
          "D": "Các lớp dữ liệu có độ phức tạp cao."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã sử dụng phương pháp gì để hình dung các đặc trưng (features) của từng lớp dữ liệu?",
        "options": {
          "A": "Phân tích thành phần chính (PCA).",
          "B": "Ánh xạ các đặc trưng vào không gian hai chiều.",
          "C": "Sử dụng mạng nơ-ron tự mã hóa (autoencoder).",
          "D": "Áp dụng thuật toán gom cụm K-means."
        },
        "answer": "B"
      },
      {
        "question": "Theo các nhà nghiên cứu, điều gì xảy ra với ranh giới quyết định (decision boundaries) khi một lớp dữ liệu có ít mẫu?",
        "options": {
          "A": "Ranh giới quyết định trở nên ổn định hơn.",
          "B": "Ranh giới quyết định trở nên ít nhạy cảm hơn với các biến thể của đặc trưng.",
          "C": "Ranh giới quyết định trở nên nhạy cảm hơn với các biến thể của đặc trưng.",
          "D": "Ranh giới quyết định biến mất."
        },
        "answer": "C"
      },
      {
        "question": "Mục tiêu của việc tăng kích thước vùng bao phủ của các lớp dữ liệu ít được đại diện là gì?",
        "options": {
          "A": "Giảm độ phức tạp của mô hình.",
          "B": "Tăng cường tính ổn định của dự đoán trên các lớp này.",
          "C": "Giảm thời gian huấn luyện mô hình.",
          "D": "Cải thiện khả năng khái quát hóa trên toàn bộ tập dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã sử dụng lớp dữ liệu nào để dự đoán phân phối đặc trưng của các lớp dữ liệu ít mẫu?",
        "options": {
          "A": "Các lớp dữ liệu có số lượng mẫu ít.",
          "B": "Các lớp dữ liệu được chọn ngẫu nhiên.",
          "C": "Các lớp dữ liệu có số lượng mẫu lớn.",
          "D": "Các lớp dữ liệu có độ phức tạp cao."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình nào đã được sử dụng để trích xuất đặc trưng từ hình ảnh trong thí nghiệm?",
        "options": {
          "A": "AlexNet.",
          "B": "VGG16.",
          "C": "ResNet-50.",
          "D": "GoogleNet."
        },
        "answer": "C"
      },
      {
        "question": "Độ đo nào đã được sử dụng để đánh giá hiệu suất của mô hình trong bài viết?",
        "options": {
          "A": "Độ chính xác (Accuracy).",
          "B": "Độ thu hồi (Recall).",
          "C": "Độ chính xác trung bình (AP).",
          "D": "F1-score."
        },
        "answer": "C"
      },
      {
        "question": "Trên tập dữ liệu Market-1501, phương pháp mới đã cải thiện độ chính xác trung bình (AP) như thế nào?",
        "options": {
          "A": "Từ 0.811 AP lên 0.822 AP.",
          "B": "Từ 0.801 AP lên 0.832 AP.",
          "C": "Từ 0.811 AP lên 0.832 AP.",
          "D": "Từ 0.711 AP lên 0.832 AP."
        },
        "answer": "C"
      },
      {
        "question": "Ý chính của câu \"There’s no need to generate synthetic examples if we can describe their extracted features\" là gì?",
        "options": {
          "A": "Việc tạo dữ liệu tổng hợp luôn cần thiết.",
          "B": "Mô tả đặc trưng trích xuất có thể thay thế cho việc tạo dữ liệu tổng hợp.",
          "C": "Việc trích xuất đặc trưng là không cần thiết.",
          "D": "Dữ liệu tổng hợp luôn tốt hơn dữ liệu thực."
        },
        "answer": "B"
      },
      {
        "question": "Câu \"Deep learning engineers like to use cats as examples, but these researchers focused only on the long tail\" ám chỉ điều gì?",
        "options": {
          "A": "Các nhà nghiên cứu chỉ quan tâm đến việc phân loại mèo.",
          "B": "Các nhà nghiên cứu tập trung vào các lớp dữ liệu ít được đại diện, khác với xu hướng thông thường.",
          "C": "Các nhà nghiên cứu không thích sử dụng mèo làm ví dụ.",
          "D": "Các nhà nghiên cứu chỉ sử dụng dữ liệu tổng hợp."
        },
        "answer": "B"
      }
    ]
  },
  "behavioral-cloning-shootout": {
    "title": "Behavioral Cloning Shootout",
    "collection": "ml-research",
    "content": "Neural networks have learned to play video games like Dota 2 via reinforcement learning by playing for the equivalent of thousands of years (compressed into far less time). In new work, an automated player learned not by playing for millennia but by watching a few days’ worth of recorded gameplay.\n\nWhat’s new:Tim Pearce and Jun Zhu at Cambridge Universitytrained an autonomous agent via supervised learningto play the first-person shooterCounter Strike: Global Offensive (CS:GO)by analyzing pixels. The model reached an intermediate level of skill. Check out a video presentationhere.\n\nKey insight:Reinforcement learning can be used to teach neural networks to play games that include a programming interface, which enables the model to explore all possible game states because gameplay proceeds much faster than real time.CS:GOlacks such an interface. An alternative is to learn from expert demonstrations, a technique known as behavioral cloning. Where such demonstrations are hard to collect, publicly broadcast matches can stand in.\n\nHow it works:The system generated a representation of each video frame using a convolutional neural network and combined multiple representations using a convolutional LSTM. A linear layer decided what action to take per frame.\n\nResults:Pitted against the game’s built-in medium-difficulty agent, which takes advantage of information that humans don’t have access to (such as the positions of all players), the author’s system came out on top. It achieved 2.67 kills per minute and 1.25 kills per death, compared to the built-in agent’s 1.97 kills per minute and 1.00 kills per death. Against human players in the top 10 percent, it didn’t fare so well. It achieved 0.5 kills per minute and 0.26 kills per death compared to the human average of 4.27 kills per minute and 2.34 kills per death\n\nWhy it matters:Behavioral cloning is a viable alternative to reinforcement learning — within the limits of available expert demonstrations. The authors’ system even learned the classic gamer swagger of jumping and spinning while it reloaded.\n\nWe’re thinking:We’re in the mood for a nonviolent round ofSplatoon.",
    "qa": [
      {
        "question": "Phương pháp học nào đã được sử dụng để huấn luyện mạng nơ-ron chơi Dota 2 trong quá khứ?",
        "options": {
          "A": "Học có giám sát (Supervised learning)",
          "B": "Học tăng cường (Reinforcement learning)",
          "C": "Sao chép hành vi (Behavioral cloning)",
          "D": "Học bán giám sát (Semi-supervised learning)"
        },
        "answer": "B"
      },
      {
        "question": "Trong nghiên cứu mới, tác giả đã huấn luyện mô hình chơi CS:GO bằng phương pháp nào?",
        "options": {
          "A": "Tự chơi hàng ngàn năm",
          "B": "Học từ dữ liệu pixel của video gameplay",
          "C": "Sử dụng giao diện lập trình của game",
          "D": "Kết hợp học tăng cường và sao chép hành vi"
        },
        "answer": "B"
      },
      {
        "question": "Tại sao học tăng cường (Reinforcement learning) thường được sử dụng để huấn luyện AI chơi game?",
        "options": {
          "A": "Vì nó dễ dàng thu thập dữ liệu từ người chơi chuyên nghiệp.",
          "B": "Vì nó cho phép mô hình khám phá tất cả các trạng thái trò chơi có thể với tốc độ nhanh hơn thời gian thực.",
          "C": "Vì nó không yêu cầu giao diện lập trình.",
          "D": "Vì nó luôn cho kết quả tốt hơn so với các phương pháp khác."
        },
        "answer": "B"
      },
      {
        "question": "Kỹ thuật 'sao chép hành vi' (Behavioral cloning) hoạt động như thế nào?",
        "options": {
          "A": "Bằng cách tự chơi game trong thời gian dài.",
          "B": "Bằng cách phân tích và học hỏi từ các bản ghi gameplay của người chơi.",
          "C": "Bằng cách sử dụng giao diện lập trình để truy cập thông tin game.",
          "D": "Bằng cách kết hợp dữ liệu pixel và thông tin từ giao diện lập trình."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình trong nghiên cứu đã sử dụng kiến trúc mạng nơ-ron nào để xử lý video frame?",
        "options": {
          "A": "Mạng nơ-ron hồi quy (Recurrent Neural Network)",
          "B": "Mạng nơ-ron tích chập (Convolutional Neural Network)",
          "C": "Mạng nơ-ron lan truyền ngược (Backpropagation Neural Network)",
          "D": "Mạng nơ-ron đối kháng (Generative Adversarial Network)"
        },
        "answer": "B"
      },
      {
        "question": "Kết quả của hệ thống khi đối đầu với bot trung bình của CS:GO là gì?",
        "options": {
          "A": "Hệ thống thua cuộc.",
          "B": "Hệ thống ngang bằng với bot.",
          "C": "Hệ thống chiến thắng với số kill trên phút và kill trên chết cao hơn.",
          "D": "Hệ thống chiến thắng nhưng chỉ có số kill trên phút cao hơn."
        },
        "answer": "C"
      },
      {
        "question": "So với người chơi CS:GO thuộc top 10%, hệ thống AI thể hiện như thế nào?",
        "options": {
          "A": "Hệ thống vượt trội hơn hẳn.",
          "B": "Hệ thống ngang bằng.",
          "C": "Hệ thống có số kill trên phút và kill trên chết thấp hơn đáng kể.",
          "D": "Hệ thống chỉ thua một chút về số kill trên phút."
        },
        "answer": "C"
      },
      {
        "question": "Hạn chế chính của phương pháp 'sao chép hành vi' (Behavioral cloning) là gì?",
        "options": {
          "A": "Yêu cầu phần cứng mạnh mẽ.",
          "B": "Phụ thuộc vào số lượng và chất lượng của dữ liệu trình diễn từ chuyên gia.",
          "C": "Khó khăn trong việc triển khai trên các game khác nhau.",
          "D": "Không thể học được các hành vi phức tạp."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống AI đã học được hành vi nào thường thấy ở game thủ CS:GO?",
        "options": {
          "A": "Sử dụng lựu đạn một cách hiệu quả.",
          "B": "Di chuyển chiến thuật trên bản đồ.",
          "C": "Nhảy và xoay người khi nạp đạn.",
          "D": "Giao tiếp với đồng đội."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết kết thúc bằng gợi ý về một trò chơi nào?",
        "options": {
          "A": "Counter Strike: Global Offensive (CS:GO)",
          "B": "Dota 2",
          "C": "Splatoon",
          "D": "Một trò chơi bạo lực khác"
        },
        "answer": "C"
      }
    ]
  },
  "better-crowd-counts": {
    "title": "Better Crowd Counts",
    "collection": "ml-research",
    "content": "Did a million people attend theMillion Man March? Estimates of the crowd size gathered at a given place and time can have significant political implications — and practical ones, too, as they can help public safety experts deploy resources for public health or crowd control. A new method improves on previous crowd-counting approaches with a novel way to compare predictions with hand-labeled training data.What’s new:DM-Counttrains neural networks to count crowd size usingoptimal transportin the cost function. Optimal transport is a measure of difference between two distributions. In this case, the first distribution is the network’s prediction of people’s locations in a training example, and the second is the ground-truth locations. The method was developed by Boyu Wang and colleagues at Stony Brook University.Key insight:Training datasets for crowd-counting models typically mark each person in an image with a single-pixel label. Training a network to match such labels is difficult, because tiny discrepancies in a label’s location count as errors. Previous approaches managed this problem by replacing the pixels with blobs, but choosing the right blob size is difficult given the wide range of sizes of people and parts of people in an image. Optimal transport gave the authors a way to compare the density of single-pixel predictions with that of single-pixel labels. Armed with this metric, they could measure the deformation necessary to match a matrix of predictions to the labels and apply a cost accordingly.How it works:DM-Count accepts a picture of a crowd and places pixels where it sees people. Ideally, it would place one per person with 100 percent certainty, but in practice it spreads that certainty over a few pixels. In training, it learns to match those values to the training data using a loss function that combines three terms:\n\nResults:The authors built a modified [VGG-19]https://arxiv.org/abs/1409.1556 as detailed in thispaperand used DM-Count to train it on datasets includingNWPU, which the authors considered the most challenging crowd-counting dataset. Their method achieved a mean absolute error of 88.4 compared to 106.3 forContext-Aware Crowd Counting, the previous state of the art.Yes, but: Context-Aware Crowd Counting achieved a marginally lower root mean squared error (386.5) than DM-Count’s (388.6).Why it matters:We often try to improve models by finding better ways to format training data such as replacing pixels with blobs. This work shows that finding new ways to evaluate a network’s predictions can be a good alternative.We’re thinking:Can this method be adapted to check whether people in a crowd are maintaining proper social distance?",
    "qa": [
      {
        "question": "Ước tính số lượng người tham gia một sự kiện có thể ảnh hưởng đến điều gì?",
        "options": {
          "A": "Giá trị bất động sản xung quanh địa điểm tổ chức.",
          "B": "Quyết định đầu tư vào các dự án nghệ thuật công cộng.",
          "C": "Việc triển khai nguồn lực cho y tế công cộng và kiểm soát đám đông.",
          "D": "Số lượng nhà vệ sinh công cộng cần thiết tại địa điểm."
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp DM-Count sử dụng kỹ thuật nào để huấn luyện mạng nơ-ron đếm số lượng người?",
        "options": {
          "A": "Giải thuật di truyền.",
          "B": "Vận tải tối ưu trong hàm chi phí.",
          "C": "Mạng nơ-ron tích chập sâu.",
          "D": "Phân tích thành phần chính."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính mà các phương pháp đếm đám đông trước đây gặp phải khi sử dụng nhãn pixel đơn là gì?",
        "options": {
          "A": "Khó khăn trong việc thu thập dữ liệu huấn luyện.",
          "B": "Sự khác biệt nhỏ trong vị trí nhãn được tính là lỗi.",
          "C": "Yêu cầu phần cứng tính toán quá lớn.",
          "D": "Khó khăn trong việc trực quan hóa kết quả."
        },
        "answer": "B"
      },
      {
        "question": "Giải pháp mà các phương pháp trước đây sử dụng để giải quyết vấn đề với nhãn pixel đơn là gì?",
        "options": {
          "A": "Sử dụng nhãn đa giác thay vì pixel.",
          "B": "Thay thế pixel bằng các 'blob'.",
          "C": "Tăng độ phân giải của hình ảnh đầu vào.",
          "D": "Sử dụng nhiều nhãn cho mỗi người."
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm của việc sử dụng vận tải tối ưu trong DM-Count là gì?",
        "options": {
          "A": "Giảm thời gian huấn luyện mô hình.",
          "B": "Cho phép so sánh mật độ của các dự đoán pixel đơn với nhãn pixel đơn.",
          "C": "Tăng độ chính xác của việc xác định vị trí khuôn mặt.",
          "D": "Giảm yêu cầu bộ nhớ cho mô hình."
        },
        "answer": "B"
      },
      {
        "question": "DM-Count hoạt động như thế nào khi xử lý một bức ảnh đám đông?",
        "options": {
          "A": "Xác định khuôn mặt và đếm số lượng khuôn mặt.",
          "B": "Phân loại các khu vực trong ảnh thành người hoặc không phải người.",
          "C": "Đặt các pixel vào nơi nó nhận thấy người.",
          "D": "Ước tính mật độ đám đông dựa trên màu sắc và kết cấu."
        },
        "answer": "C"
      },
      {
        "question": "Mạng VGG-19 được sử dụng trong DM-Count đã được điều chỉnh như thế nào?",
        "options": {
          "A": "Được thay thế bằng một kiến trúc mạng nơ-ron khác.",
          "B": "Được sửa đổi theo chi tiết trong bài báo được tham khảo.",
          "C": "Được sử dụng nguyên bản mà không có bất kỳ thay đổi nào.",
          "D": "Được sử dụng để tiền xử lý hình ảnh đầu vào."
        },
        "answer": "B"
      },
      {
        "question": "Trên bộ dữ liệu NWPU, DM-Count đạt được sai số tuyệt đối trung bình (MAE) là bao nhiêu?",
        "options": {
          "A": "106.3",
          "B": "386.5",
          "C": "88.4",
          "D": "388.6"
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp Context-Aware Crowd Counting có ưu điểm gì so với DM-Count?",
        "options": {
          "A": "Sai số tuyệt đối trung bình (MAE) thấp hơn.",
          "B": "Sai số căn bậc hai trung bình (RMSE) thấp hơn.",
          "C": "Thời gian huấn luyện mô hình nhanh hơn.",
          "D": "Yêu cầu bộ nhớ ít hơn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất gì về việc cải thiện mô hình học máy?",
        "options": {
          "A": "Tập trung vào việc tăng kích thước dữ liệu huấn luyện.",
          "B": "Tìm kiếm các cách mới để định dạng dữ liệu huấn luyện.",
          "C": "Tìm kiếm các cách mới để đánh giá dự đoán của mạng.",
          "D": "Sử dụng các thuật toán tối ưu hóa phức tạp hơn."
        },
        "answer": "C"
      }
    ]
  },
  "bert-is-back": {
    "title": "BERT Is Back",
    "collection": "ml-research",
    "content": "Less than a month after XLNet overtook BERT, the pole position in natural language understanding changed hands again.RoBERTais an improved BERT pretraining recipe that beats its forbear, becoming the new state-of-the-art language model — for the moment.\n\nWhat’s new:Researchers at Facebook AI and from the University of Washington modifiedBERTto beat the best published results on three popular benchmarks.\n\nKey insight:Since BERT’s debut late last year, success in language modeling has been fueled not only by bigger models but also by an order of magnitude more data, more passes through the training set, and larger batch sizes. RoBERTa shows that these training choices can have a greater impact on performance than advances in model architecture.\n\nHow it works:RoBERTa uses the BERT LARGE configuration (355 million parameters) with an altered pretraining pipeline. Yinhan Liu and her colleagues made the following changes:\n\nResults:RoBERTa achieves state-of-the-art performance on GLUE without multi-task fine tuning, on SQuAD without additional data (unlike BERT and XLNet), and on RACE.\n\nYes, but:As the authors point out, the comparison would be fairer if XLNet and other language models were fine-tuned as rigorously as RoBERTa. The success of intensive fine-tuning raises the question whether researchers with limited resources can obtain state-of-the-art results in the problems they care about.\n\nWhy it matters:The authors show that rigorous tuning of hyperparameters and dataset size can play a decisive role in performance. The study highlights the importance of proper evaluation procedures for all new machine learning techniques.We’re thinking:Researchers are just beginning to assess the impact of hyperparameter tuning and data set size on complex neural network architectures at scale of 100 to 1,000 million parameters. BERT is an early beneficiary, and there’s much more exploration to be done.",
    "qa": [
      {
        "question": "Mục đích chính của bài viết là gì?",
        "options": {
          "A": "So sánh chi tiết kiến trúc của RoBERTa và BERT.",
          "B": "Giới thiệu RoBERTa, một mô hình ngôn ngữ mới vượt trội hơn BERT nhờ cải tiến quy trình huấn luyện.",
          "C": "Phân tích những hạn chế của BERT và XLNet trong việc xử lý ngôn ngữ tự nhiên.",
          "D": "Đề xuất các phương pháp mới để cải thiện hiệu suất của các mô hình ngôn ngữ dựa trên Transformer."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đã thúc đẩy sự thành công trong mô hình ngôn ngữ kể từ khi BERT ra mắt?",
        "options": {
          "A": "Sự ra đời của các kiến trúc mô hình hoàn toàn mới.",
          "B": "Sự kết hợp giữa mô hình lớn hơn, dữ liệu nhiều hơn, số lần duyệt qua tập huấn luyện nhiều hơn và kích thước batch lớn hơn.",
          "C": "Việc sử dụng các thuật toán tối ưu hóa tiên tiến hơn.",
          "D": "Sự tập trung vào việc giảm thiểu số lượng tham số trong mô hình."
        },
        "answer": "B"
      },
      {
        "question": "RoBERTa sử dụng cấu hình nào của BERT?",
        "options": {
          "A": "BERT BASE",
          "B": "BERT SMALL",
          "C": "BERT LARGE",
          "D": "BERT TINY"
        },
        "answer": "C"
      },
      {
        "question": "Điểm nổi bật của RoBERTa so với BERT và XLNet trên SQuAD là gì?",
        "options": {
          "A": "RoBERTa đạt hiệu suất tốt hơn với ít tham số hơn.",
          "B": "RoBERTa đạt hiệu suất tốt hơn mà không cần dữ liệu bổ sung.",
          "C": "RoBERTa có tốc độ xử lý nhanh hơn.",
          "D": "RoBERTa dễ dàng triển khai hơn."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì sẽ làm cho sự so sánh giữa RoBERTa và các mô hình ngôn ngữ khác công bằng hơn?",
        "options": {
          "A": "Sử dụng cùng một tập dữ liệu huấn luyện.",
          "B": "Tinh chỉnh XLNet và các mô hình khác một cách kỹ lưỡng như RoBERTa.",
          "C": "Đánh giá trên cùng một bộ benchmark.",
          "D": "Sử dụng cùng một phần cứng để huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh tầm quan trọng của điều gì trong việc cải thiện hiệu suất của mô hình?",
        "options": {
          "A": "Sự phức tạp của kiến trúc mô hình.",
          "B": "Việc điều chỉnh cẩn thận các siêu tham số và kích thước tập dữ liệu.",
          "C": "Việc sử dụng các kỹ thuật regularization tiên tiến.",
          "D": "Việc giảm thiểu thời gian huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Ai là những người đã phát triển RoBERTa?",
        "options": {
          "A": "Google AI",
          "B": "OpenAI",
          "C": "Facebook AI và Đại học Washington",
          "D": "Microsoft Research"
        },
        "answer": "C"
      },
      {
        "question": "RoBERTa đã đạt được hiệu suất vượt trội trên những benchmark nào?",
        "options": {
          "A": "ImageNet, COCO, và MNIST",
          "B": "GLUE, SQuAD, và RACE",
          "C": "WMT, IWSLT, và TED",
          "D": "LibriSpeech, TIMIT, và WSJ"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến việc các nhà nghiên cứu đang bắt đầu đánh giá tác động của yếu tố nào lên các kiến trúc mạng nơ-ron phức tạp?",
        "options": {
          "A": "Số lượng lớp trong mạng nơ-ron.",
          "B": "Kích thước của các lớp ẩn.",
          "C": "Việc điều chỉnh siêu tham số và kích thước tập dữ liệu.",
          "D": "Loại hàm kích hoạt được sử dụng."
        },
        "answer": "C"
      },
      {
        "question": "Số lượng tham số của RoBERTa là bao nhiêu?",
        "options": {
          "A": "110 triệu",
          "B": "355 triệu",
          "C": "1.5 tỷ",
          "D": "175 triệu"
        },
        "answer": "B"
      }
    ]
  },
  "better-language-through-vision": {
    "title": "Better Language Through Vision",
    "collection": "ml-research",
    "content": "For children, associating a word with a picture that illustrates it helps them learn the word’s meaning. New research aims to do something similar for machine learning models.What’s new:Hao Tan and Mohit Bansal at University of North Carolina Chapel Hill improved a BERT model’s performance on some language tasks by training it on a large dataset of image-word pairs, which they call visualized tokens, orvokens.Key insight:Images can illuminate word meanings, but current datasets that associate images with words have a small vocabulary relative to the corpuses typically used to train language models. However, these smaller datasets can be used to train a model to find correspondences between words and images. Then that model can find such pairings in separate, much larger datasets of images and words. The resulting pairings can help an established language model understand words better.How it works:The authors trained a system called the vokenizer to pair BERT-style tokens — generally individual words or characters — with related images. They used the resulting visualized tokens to train BERT to predict such pairings and fine-tuned it on various language tasks.\n\nResults:BERT pretrained with the token-image pairs outperformed the same architecture trained in the same way but without the pairs on tasks in GLUE, SQuAD, and SWAG. For instance, it achieved 92.2 percent accuracy onSST2, predicting the sentiment of movie reviews, compared to 89.3 percent for BERT without visual training. Similarly, onSQuAD v1.1, it achieved an F1 score of .867 on SQuAD compared to .853 for BERT without visual training.Why it matters:This work suggests the potential of visual learning to improve even best language models.We’re thinking:If associating words with images helps a model learn word meaning, why not sounds? Sonic tokens — sokens! — would pair, say, “horn” with the tone of a trumpet and “cat” with the sound of a meow.",
    "qa": [
      {
        "question": "Nghiên cứu mới được đề cập trong bài viết tập trung vào việc cải thiện mô hình học máy bằng cách nào?",
        "options": {
          "A": "Tăng cường khả năng xử lý ngôn ngữ tự nhiên thông qua việc sử dụng dữ liệu âm thanh.",
          "B": "Liên kết từ ngữ với hình ảnh minh họa để giúp mô hình hiểu nghĩa của từ tốt hơn.",
          "C": "Sử dụng các thuật toán phức tạp hơn để phân tích cú pháp và ngữ nghĩa của câu.",
          "D": "Tăng kích thước của bộ dữ liệu huấn luyện để mô hình học được nhiều mẫu hơn."
        },
        "answer": "B"
      },
      {
        "question": "Hao Tan và Mohit Bansal đã sử dụng phương pháp nào để cải thiện hiệu suất của mô hình BERT?",
        "options": {
          "A": "Huấn luyện mô hình trên một bộ dữ liệu lớn chứa các cặp từ-âm thanh.",
          "B": "Huấn luyện mô hình trên một bộ dữ liệu lớn chứa các cặp từ-hình ảnh, được gọi là 'vokens'.",
          "C": "Sử dụng một kiến trúc mạng nơ-ron mới để xử lý ngôn ngữ tự nhiên hiệu quả hơn.",
          "D": "Áp dụng kỹ thuật học tăng cường để tối ưu hóa các tham số của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, hạn chế của các bộ dữ liệu hiện tại liên kết hình ảnh với từ ngữ là gì?",
        "options": {
          "A": "Chúng chứa quá nhiều hình ảnh không liên quan đến từ ngữ.",
          "B": "Chúng có kích thước quá lớn, gây khó khăn cho việc huấn luyện mô hình.",
          "C": "Chúng có vốn từ vựng nhỏ so với các bộ dữ liệu thường được sử dụng để huấn luyện mô hình ngôn ngữ.",
          "D": "Chúng không đủ đa dạng về phong cách hình ảnh."
        },
        "answer": "C"
      },
      {
        "question": "Vokenizer được sử dụng để làm gì trong nghiên cứu này?",
        "options": {
          "A": "Tạo ra các bộ dữ liệu lớn chứa các cặp từ-hình ảnh.",
          "B": "Đánh giá hiệu suất của mô hình BERT trên các tác vụ ngôn ngữ khác nhau.",
          "C": "Ghép nối các token (từ hoặc ký tự) theo phong cách BERT với các hình ảnh liên quan.",
          "D": "Chuyển đổi văn bản thành hình ảnh để trực quan hóa thông tin."
        },
        "answer": "C"
      },
      {
        "question": "Trên tác vụ SST2 (dự đoán cảm xúc của các bài đánh giá phim), mô hình BERT được huấn luyện với 'vokens' đạt độ chính xác là bao nhiêu?",
        "options": {
          "A": "85.3%",
          "B": "89.3%",
          "C": "92.2%",
          "D": "86.7%"
        },
        "answer": "C"
      },
      {
        "question": "Kết quả trên SQuAD v1.1 cho thấy điều gì về hiệu quả của việc sử dụng 'vokens'?",
        "options": {
          "A": "Mô hình BERT được huấn luyện với 'vokens' có hiệu suất thấp hơn so với mô hình không sử dụng 'vokens'.",
          "B": "Mô hình BERT được huấn luyện với 'vokens' đạt điểm F1 cao hơn so với mô hình không sử dụng 'vokens'.",
          "C": "Việc sử dụng 'vokens' không ảnh hưởng đến hiệu suất của mô hình BERT trên SQuAD v1.1.",
          "D": "Mô hình BERT được huấn luyện với 'vokens' chỉ hoạt động tốt trên một số loại câu hỏi nhất định."
        },
        "answer": "B"
      },
      {
        "question": "Ý nghĩa quan trọng nhất của nghiên cứu này là gì?",
        "options": {
          "A": "Nó chứng minh rằng việc sử dụng hình ảnh không có tác dụng gì đối với việc cải thiện mô hình ngôn ngữ.",
          "B": "Nó cho thấy tiềm năng của việc học trực quan trong việc cải thiện ngay cả những mô hình ngôn ngữ tốt nhất.",
          "C": "Nó giới thiệu một kiến trúc mạng nơ-ron mới vượt trội hơn BERT.",
          "D": "Nó cung cấp một phương pháp mới để tạo ra các bộ dữ liệu lớn hơn và đa dạng hơn."
        },
        "answer": "B"
      },
      {
        "question": "Trong phần 'We're thinking', tác giả đề xuất ý tưởng gì?",
        "options": {
          "A": "Sử dụng video thay vì hình ảnh để cải thiện mô hình ngôn ngữ.",
          "B": "Kết hợp cả hình ảnh và âm thanh để huấn luyện mô hình ngôn ngữ.",
          "C": "Sử dụng âm thanh để liên kết với từ ngữ, tạo ra 'sokens'.",
          "D": "Tập trung vào việc cải thiện khả năng xử lý ngôn ngữ đa ngôn ngữ của mô hình."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của việc liên kết một từ với một hình ảnh là gì?",
        "options": {
          "A": "Giúp mô hình tạo ra hình ảnh từ văn bản.",
          "B": "Giúp mô hình hiểu rõ hơn về nghĩa của từ.",
          "C": "Giúp mô hình dịch văn bản sang ngôn ngữ khác.",
          "D": "Giúp mô hình tạo ra văn bản từ hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình nào được sử dụng làm nền tảng để thử nghiệm phương pháp 'vokens'?",
        "options": {
          "A": "GPT-3",
          "B": "Transformer",
          "C": "BERT",
          "D": "ResNet"
        },
        "answer": "C"
      }
    ]
  },
  "better-teachers-make-better-students": {
    "title": "Better Teachers Make Better Students",
    "collection": "ml-research",
    "content": "A relatively small student LLM that learns to mimic a larger teacher model can perform nearly as well as the teacher while using much less computation. It can come even closer if the teacher also strengthens the student’s native reasoning skills.\n\nWhat’s new:Arindam Mitra and colleagues at Microsoft proposedOrca 2, a technique that improves the output of student LLMs an order of magnitude smaller than their teachers.\n\nKey insight:Large language models can provide better output when they’re prompted to use a particular reasoning strategy such as think step by step, recall then generate, or explain then generate. Different reasoning strategies may yield better output depending on the task at hand. Moreover, given the same task, different models may perform better using different reasoning strategies. Consequently, in a teacher-student situation, the teacher and student models may need to use different strategies to achieve their highest performances on a given task. The student will achieve its best performance if it mimics the teacher's reasoning and response when the teacher uses not its own best-performing strategy, but the student’s best-performing strategy.\n\nHow it works:The teacher, GPT-4, helped generate a fine-tuning dataset to improve the output of the student,Llama 2(13 billion parameters), both of which had been pretrained. They created the fine-tuning dataset and fine-tuned Llama 2 as follows:\n\nResults:The authors compared their model to models of similar size including WizardLM-13B (also based on Llama 2) and larger models including GPT-3.5 Turbo (an order of magnitude larger) and GPT-4 (parameter count undisclosed). They evaluated the percentage of correct responses on average over six reasoning benchmarks such asAGIEval, which includes multiple-choice and fill-in-the-blank questions from the Scholastic Aptitude Test, American Mathematics Competitions, and other tests designed for humans. Their model exactly matched the correct answer 66.92 percent of the time compared to WizardLM-13B (50.32 percent). It performed nearly as well as the 10x larger GPT-3.5 Turbo (which achieved 67.65 percent) but much less well than GPT-4 (which achieved 79.03 percent).\n\nWhy it matters:Learning how to reason is an important complement to learning facts and perspectives. A model that has been trained to reason using its most effective strategy generally will provide better output. Users don’t need to tell it which strategy to apply. They can simply enter a prompt, and the model will figure out how to reason its response.\n\nWe’re thinking:Perhaps a similar approach could be used to prompt a model to improve its own output. In effect, this would be similar to an agentic workflow designed to enable a model to produce its own training data, as recentlydescribedinThe Batch.",
    "qa": [
      {
        "question": "Orca 2 là một kỹ thuật được đề xuất bởi ai?",
        "options": {
          "A": "OpenAI",
          "B": "Arindam Mitra và cộng sự tại Microsoft",
          "C": "Google AI",
          "D": "Meta AI"
        },
        "answer": "B"
      },
      {
        "question": "Điểm mới của Orca 2 là gì?",
        "options": {
          "A": "Tăng kích thước của mô hình học sinh để ngang bằng mô hình giáo viên.",
          "B": "Cải thiện đáng kể đầu ra của mô hình học sinh nhỏ hơn nhiều so với mô hình giáo viên.",
          "C": "Loại bỏ hoàn toàn nhu cầu về mô hình giáo viên.",
          "D": "Sử dụng một thuật toán học máy hoàn toàn mới."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì có thể cải thiện đầu ra của các mô hình ngôn ngữ lớn?",
        "options": {
          "A": "Sử dụng một chiến lược suy luận ngẫu nhiên.",
          "B": "Sử dụng một chiến lược suy luận cụ thể được gợi ý.",
          "C": "Tăng số lượng tham số của mô hình.",
          "D": "Giảm độ phức tạp của nhiệm vụ."
        },
        "answer": "B"
      },
      {
        "question": "Trong tình huống giáo viên-học sinh, mô hình học sinh đạt hiệu suất tốt nhất khi nào?",
        "options": {
          "A": "Khi bắt chước chiến lược suy luận tốt nhất của giáo viên.",
          "B": "Khi bắt chước chiến lược suy luận và phản hồi của giáo viên khi giáo viên sử dụng chiến lược tốt nhất của học sinh.",
          "C": "Khi sử dụng chiến lược suy luận hoàn toàn khác biệt so với giáo viên.",
          "D": "Khi có nhiều dữ liệu huấn luyện hơn giáo viên."
        },
        "answer": "B"
      },
      {
        "question": "Trong thí nghiệm, mô hình giáo viên được sử dụng là gì?",
        "options": {
          "A": "Llama 2",
          "B": "GPT-3.5 Turbo",
          "C": "GPT-4",
          "D": "WizardLM-13B"
        },
        "answer": "C"
      },
      {
        "question": "Mô hình học sinh Llama 2 được tinh chỉnh bằng cách nào?",
        "options": {
          "A": "Sử dụng dữ liệu huấn luyện được tạo ra bởi chính nó.",
          "B": "Sử dụng dữ liệu huấn luyện được tạo ra bởi GPT-4.",
          "C": "Sử dụng dữ liệu huấn luyện công khai.",
          "D": "Sử dụng dữ liệu huấn luyện được tạo ra bởi WizardLM-13B."
        },
        "answer": "B"
      },
      {
        "question": "Trong các thử nghiệm, Orca 2 đạt được kết quả như thế nào so với GPT-3.5 Turbo?",
        "options": {
          "A": "Vượt trội hơn đáng kể.",
          "B": "Gần như tương đương.",
          "C": "Kém hơn đáng kể.",
          "D": "Hoàn toàn giống nhau."
        },
        "answer": "B"
      },
      {
        "question": "Benchmark AGIEval bao gồm các loại câu hỏi nào?",
        "options": {
          "A": "Chỉ câu hỏi trắc nghiệm.",
          "B": "Chỉ câu hỏi điền vào chỗ trống.",
          "C": "Câu hỏi trắc nghiệm và điền vào chỗ trống từ các bài kiểm tra như SAT và AMC.",
          "D": "Chỉ các bài toán logic phức tạp."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, lợi ích của việc huấn luyện mô hình suy luận hiệu quả là gì?",
        "options": {
          "A": "Người dùng cần chỉ định chiến lược suy luận cho mô hình.",
          "B": "Mô hình có thể tự động xác định chiến lược suy luận phù hợp nhất.",
          "C": "Mô hình sẽ luôn đưa ra câu trả lời chính xác tuyệt đối.",
          "D": "Mô hình sẽ hoạt động nhanh hơn đáng kể."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất ý tưởng gì về việc cải thiện đầu ra của mô hình?",
        "options": {
          "A": "Sử dụng một mô hình lớn hơn nhiều.",
          "B": "Sử dụng một cách tiếp cận tương tự để mô hình tự tạo dữ liệu huấn luyện của riêng mình.",
          "C": "Loại bỏ hoàn toàn việc sử dụng dữ liệu huấn luyện.",
          "D": "Tập trung vào việc cải thiện phần cứng thay vì phần mềm."
        },
        "answer": "B"
      }
    ]
  },
  "better-text-to-image-results-with-latent-diffusion": {
    "title": "Precision-Guided Image Generation",
    "collection": "ml-research",
    "content": "Typical text-to-image generators can generate pictures of a cat, but notyourcat. That’s because it’s hard to describe in a text prompt precisely all the things that distinguish your pet from other members of the same species. A new approach guides diffusion models in a way that can produce pictures of your darling Simba.\n\nWhat's new:Rinon Gal and colleagues at Nvidia and Tel-Aviv University devised amethodto make a diffusion-based, text-to-image generator produce pictures of a particular object or in a particular style.\n\nBasics of diffusion models:During training, a text-to-image generator based on diffusion takes a noisy image and a text description. A transformer learns to embed the description, and a diffusion model learns to use the embeddings to remove the noise in successive steps. At inference, the system starts with pure noise and a text description, and iteratively removes noise according to the text to generate an image. A variant known as alatent diffusion modelsaves computation by removing noise from a small, learned vector of an image instead of a noisy image.\n\nKey insight:A text-to-image generator feeds text word embeddings to an image generator. Adding a learned embedding that represents a set of related images can prompt the generator to produce common attributes of those images in addition to the semantic content of words.\n\nHow it works:The authors used atext-to-image generatorbased on a latent diffusion model. The system was pretrained on400 million text-image pairsscraped from the web. Its weights were frozen.\n\nResults:The authors evaluated their model’s output by comparing embeddings, generated byCLIP, of original and generated images. They measured similarity on a scale from 0 to 1, where 1 signifies two identical inputs. The model scored around 0.78. Images generated using human-crafted descriptions of up to 12 words — without reference to S∗ — scored around 0.6. Images generated using longer descriptions of up to 30 words scored around 0.625.\n\nWhy it matters:The authors’ method offers a simple way for users of diffusion-based, text-to-image generators to steer the output toward specific attributes of content or style without retraining the model.\n\nWe’re thinking:Could this approach be extended to encompass multiple learned vectors and allow users to combine them as they like? That would make it possible to control image generation in even more precise ways.",
    "qa": [
      {
        "question": "Điểm hạn chế của các trình tạo ảnh từ văn bản thông thường được đề cập trong bài viết là gì?",
        "options": {
          "A": "Không thể tạo ra hình ảnh có độ phân giải cao.",
          "B": "Khó tạo ra hình ảnh của một đối tượng cụ thể, đặc biệt khi mô tả chi tiết là cần thiết.",
          "C": "Yêu cầu lượng dữ liệu huấn luyện quá lớn.",
          "D": "Chỉ có thể tạo ra hình ảnh đen trắng."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp mới của Rinon Gal và cộng sự tập trung vào việc gì?",
        "options": {
          "A": "Tăng tốc độ xử lý của các mô hình khuếch tán.",
          "B": "Giúp các mô hình khuếch tán tạo ra hình ảnh của một đối tượng cụ thể hoặc theo một phong cách cụ thể.",
          "C": "Giảm dung lượng lưu trữ cần thiết cho các mô hình khuếch tán.",
          "D": "Cải thiện độ chính xác của việc nhận diện văn bản trong hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Trong quá trình huấn luyện, mô hình khuếch tán (diffusion model) học cách làm gì?",
        "options": {
          "A": "Tạo ra nhiễu từ hình ảnh rõ nét.",
          "B": "Sử dụng các embedding để loại bỏ nhiễu trong các bước liên tiếp.",
          "C": "Chuyển đổi văn bản thành hình ảnh trực tiếp.",
          "D": "Phân tích cú pháp của văn bản mô tả."
        },
        "answer": "B"
      },
      {
        "question": "Latent diffusion model khác biệt so với diffusion model thông thường như thế nào?",
        "options": {
          "A": "Latent diffusion model sử dụng ít dữ liệu huấn luyện hơn.",
          "B": "Latent diffusion model loại bỏ nhiễu từ một vector nhỏ, học được của hình ảnh thay vì hình ảnh nhiễu.",
          "C": "Latent diffusion model tạo ra hình ảnh có độ phân giải cao hơn.",
          "D": "Latent diffusion model có thể xử lý nhiều ngôn ngữ hơn."
        },
        "answer": "B"
      },
      {
        "question": "Ý tưởng chính trong phương pháp mới là gì?",
        "options": {
          "A": "Sử dụng mạng nơ-ron tích chập để cải thiện chất lượng hình ảnh.",
          "B": "Thêm một embedding học được đại diện cho một tập hợp các hình ảnh liên quan để gợi ý các thuộc tính chung.",
          "C": "Tăng số lượng lớp trong mô hình khuếch tán.",
          "D": "Sử dụng một hàm mất mát mới để tối ưu hóa quá trình huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống được sử dụng trong nghiên cứu này đã được huấn luyện trước trên bao nhiêu cặp văn bản-hình ảnh?",
        "options": {
          "A": "10 triệu",
          "B": "100 triệu",
          "C": "400 triệu",
          "D": "1 tỷ"
        },
        "answer": "C"
      },
      {
        "question": "Mô hình đánh giá kết quả bằng cách so sánh embeddings được tạo bởi CLIP, với thang điểm từ 0 đến 1. Giá trị 1 biểu thị điều gì?",
        "options": {
          "A": "Hai hình ảnh hoàn toàn khác nhau.",
          "B": "Hai hình ảnh có độ tương đồng cao.",
          "C": "Hai đầu vào giống hệt nhau.",
          "D": "Hình ảnh được tạo ra có chất lượng rất kém."
        },
        "answer": "C"
      },
      {
        "question": "Mô hình đạt được điểm số khoảng bao nhiêu khi so sánh embeddings của hình ảnh gốc và hình ảnh được tạo ra?",
        "options": {
          "A": "0.5",
          "B": "0.6",
          "C": "0.78",
          "D": "0.9"
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích chính của phương pháp được đề xuất là gì?",
        "options": {
          "A": "Giảm chi phí tính toán khi huấn luyện mô hình.",
          "B": "Cho phép người dùng điều chỉnh đầu ra theo các thuộc tính cụ thể mà không cần huấn luyện lại mô hình.",
          "C": "Tăng độ phân giải của hình ảnh được tạo ra.",
          "D": "Cải thiện khả năng xử lý hình ảnh 3D."
        },
        "answer": "B"
      },
      {
        "question": "Tác giả bài viết đặt ra câu hỏi về khả năng mở rộng phương pháp này như thế nào?",
        "options": {
          "A": "Mở rộng để tạo ra video từ văn bản.",
          "B": "Mở rộng để tạo ra hình ảnh có độ phân giải cực cao.",
          "C": "Mở rộng để bao gồm nhiều vector học được và cho phép người dùng kết hợp chúng.",
          "D": "Mở rộng để tạo ra hình ảnh 3D từ văn bản."
        },
        "answer": "C"
      }
    ]
  },
  "better-than-backprop": {
    "title": "Better Than Backprop",
    "collection": "ml-research",
    "content": "End-to-end backpropagation and labeled data are the peanut butter and chocolate of deep learning. However, recent work suggests that neither is necessary to train effective neural networks to represent complex data.What’s new:Sindy Löwe, Peter O’Connor, and Bastiaan Veeling proposeGreedy InfoMax(GIM), an unsupervised method for learning to extract features that trains only one layer at a time.Key insight:Theinformation bottleneck theory(IB) suggests that neural networks work by concentrating information like a data-compression algorithm. In data compression, the amount of information retained is measured in mutual information (MI) between original and compressed versions. IB says that neural nets maximize MI between each layer’s input and output. Thus GIM reframes learning as a self-supervised compression problem. Unlike earlier MI-based approaches, it optimizes each layer separately.How it works:GIM works on modular networks, in which each layer learns to extract features from its input and passes its output to the next available layer, and so on down to the final layer. GIM doesn’t require labels, but if they’re available, a linear classification model can learn from GIM’s compressed output in a supervised manner.\n\nResults:The researchers pitted Greedy InfoMax againstcontrastive predictive coding. Inimage classification, GIM beat CPC by 1.4 percent, achieving 81.9 percent accuracy. In avoice identificationtask, GIM underperformed CPC by 0.2 percent, scoring 99.4 percent accuracy. GIM’s scores are state-of-the-art for models based on mutual information.Why it matters:Backprop requires storing forward prediction, backward gradients, and weights for an entire network simultaneously. InfoMax handles each layer individually, making it possible to accommodate much larger models in limited memory.\n\nBehind the news:Layerwise training or pre-training has been around for at least a decade. For example,stacked autoencodersuse reconstruction error as an alternative unsupervised mechanism to control intelligent data compression. Many past approaches are more focused on pre-training and assume that, once each layer has been trained individually, they will be trained together with a supervised task.We’re thinking:Many machine learning applications use a large pretrained network as an initial feature extractor and then apply transfer learning. By maximizing MI between layers, this approach could use more data to train and build still larger networks.",
    "qa": [
      {
        "question": "Phương pháp Greedy InfoMax (GIM) là một phương pháp học...",
        "options": {
          "A": "có giám sát, yêu cầu dữ liệu được gán nhãn.",
          "B": "bán giám sát, kết hợp cả dữ liệu có nhãn và không nhãn.",
          "C": "tăng cường, sử dụng phần thưởng và hình phạt để huấn luyện.",
          "D": "không giám sát, không yêu cầu dữ liệu được gán nhãn."
        },
        "answer": "D"
      },
      {
        "question": "Lý thuyết Information Bottleneck (IB) cho rằng mạng nơ-ron hoạt động bằng cách nào?",
        "options": {
          "A": "Tối thiểu hóa thông tin giữa đầu vào và đầu ra của mỗi lớp.",
          "B": "Tối đa hóa thông tin giữa đầu vào và đầu ra của mỗi lớp.",
          "C": "Giảm thiểu sai số tái tạo dữ liệu đầu vào.",
          "D": "Tăng cường tính đa dạng của dữ liệu đầu vào."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính của GIM so với các phương pháp dựa trên Mutual Information (MI) trước đây là gì?",
        "options": {
          "A": "GIM sử dụng backpropagation để tối ưu hóa toàn bộ mạng.",
          "B": "GIM tối ưu hóa từng lớp một cách riêng biệt.",
          "C": "GIM yêu cầu dữ liệu được gán nhãn để huấn luyện.",
          "D": "GIM không sử dụng Mutual Information trong quá trình huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Trong bài toán phân loại ảnh, GIM thể hiện như thế nào so với Contrastive Predictive Coding (CPC)?",
        "options": {
          "A": "GIM vượt trội hơn CPC 1.4% về độ chính xác.",
          "B": "GIM kém hơn CPC 1.4% về độ chính xác.",
          "C": "GIM và CPC có độ chính xác tương đương.",
          "D": "GIM không thể áp dụng cho bài toán phân loại ảnh."
        },
        "answer": "A"
      },
      {
        "question": "Ưu điểm chính của InfoMax so với backpropagation là gì?",
        "options": {
          "A": "InfoMax yêu cầu ít bộ nhớ hơn vì xử lý từng lớp riêng lẻ.",
          "B": "InfoMax hội tụ nhanh hơn backpropagation.",
          "C": "InfoMax cho độ chính xác cao hơn backpropagation.",
          "D": "InfoMax dễ dàng song song hóa hơn backpropagation."
        },
        "answer": "A"
      },
      {
        "question": "Stacked autoencoders sử dụng cơ chế không giám sát nào để kiểm soát việc nén dữ liệu thông minh?",
        "options": {
          "A": "Mutual Information.",
          "B": "Sai số tái tạo.",
          "C": "Contrastive loss.",
          "D": "Adversarial loss."
        },
        "answer": "B"
      },
      {
        "question": "Trong bài toán nhận dạng giọng nói, GIM thể hiện như thế nào so với Contrastive Predictive Coding (CPC)?",
        "options": {
          "A": "GIM vượt trội hơn CPC 0.2% về độ chính xác.",
          "B": "GIM kém hơn CPC 0.2% về độ chính xác.",
          "C": "GIM và CPC có độ chính xác tương đương.",
          "D": "GIM không thể áp dụng cho bài toán nhận dạng giọng nói."
        },
        "answer": "B"
      },
      {
        "question": "GIM hoạt động trên loại mạng nào?",
        "options": {
          "A": "Mạng hồi quy (Recurrent Neural Networks).",
          "B": "Mạng đối kháng sinh (Generative Adversarial Networks).",
          "C": "Mạng mô-đun (Modular Networks).",
          "D": "Mạng tích chập (Convolutional Neural Networks)."
        },
        "answer": "C"
      },
      {
        "question": "Nếu có nhãn dữ liệu, GIM có thể được sử dụng như thế nào?",
        "options": {
          "A": "GIM không thể sử dụng dữ liệu có nhãn.",
          "B": "GIM sử dụng dữ liệu có nhãn để huấn luyện từng lớp một cách có giám sát.",
          "C": "Một mô hình phân loại tuyến tính có thể học từ đầu ra nén của GIM một cách có giám sát.",
          "D": "GIM sử dụng dữ liệu có nhãn để tinh chỉnh các tham số của mạng."
        },
        "answer": "C"
      },
      {
        "question": "Ứng dụng tiềm năng nào được đề xuất cho việc tối đa hóa MI giữa các lớp trong mạng nơ-ron?",
        "options": {
          "A": "Giảm kích thước mạng nơ-ron.",
          "B": "Tăng tốc độ huấn luyện mạng nơ-ron.",
          "C": "Sử dụng nhiều dữ liệu hơn để huấn luyện và xây dựng các mạng lớn hơn.",
          "D": "Giảm thiểu overfitting trong quá trình huấn luyện."
        },
        "answer": "C"
      }
    ]
  },
  "beware-bad-arguments-against-open-source": {
    "title": "Beware Bad Arguments Against Open Source",
    "collection": "ml-research",
    "content": "Inexpensive token generation and agentic workflows for large language models (LLMs) open up intriguing new possibilities for training LLMs on synthetic data. Pretraining an LLM on its own directly generated responses to prompts doesn't help. But if an agentic workflow implemented with the LLM results in higher quality output than the LLM can generate directly, then training on that output becomes potentially useful.\n\nJust as humans can learn from their own thinking, perhaps LLMs can, too. For example, imagine a math student who is learning to write mathematical proofs. By solving a few problems — even without external input — they can reflect on what does and doesn’t work and, through practice, learn how to more quickly generate good proofs.\n\nBroadly, LLM training involves (i) pretraining (learning from unlabeled text data to predict the next word) followed by (ii) instruction fine-tuning (learning to follow instructions) and (iii) RLHF/DPO tuning to align the LLM’s output to human values. Step (i) requires many orders of magnitude more data than the other steps. For example,Llama 3was pretrained on over 15 trillion tokens, and LLM developers are still hungry for more data. Where can we get more text to train on?\n\nMany developers train smaller models directly on the output of larger models, so a smaller model learns to mimic a larger model’s behavior on a particular task. However, an LLM can’t learn much by training on data it generated directly, just like a supervised learning algorithm can’t learn from trying to predict labels it generated by itself. Indeed, training a model repeatedly on the output of an earlier version of itself can result inmodel collapse.\n\nHowever, an LLM wrapped in anagentic workflowmay produce higher-quality output than it can generate directly. In this case, the LLM’s higher-quality output might be useful as pretraining data for the LLM itself.\n\nEfforts like these have precedents:\n\nA significant barrier to using LLMs prompted via agentic workflows to produce their own training data is the cost of generating tokens. Say we want to generate 1 trillion tokens to extend a pre-existing training dataset. Currently, at publicly announced prices, generating 1 trillion tokens using GPT-4-turbo ($30 per million output tokens), Claude 3 Opus ($75), Gemini 1.5 Pro ($21), and Llama-3-70B on Groq ($0.79) would cost, respectively, $30M, $75M, $21M and $790K. Of course, an agentic workflow that uses a design pattern likeReflectionwould require generating more than one token per token that we would use as training data. But budgets for training cutting-edge LLMs easily surpass $100M, so spending a few million dollars more for data to boost performance is quite feasible.\n\nThat’s why I believe agentic workflows will open up intriguing new opportunities for high-quality synthetic data generation.",
    "qa": [
      {
        "question": "Theo bài viết, việc huấn luyện LLM trực tiếp trên dữ liệu do chính nó tạo ra thường không hiệu quả vì lý do gì?",
        "options": {
          "A": "Dữ liệu tự tạo thường quá phức tạp để LLM có thể học được.",
          "B": "LLM không thể học được nhiều từ dữ liệu mà nó tự tạo ra, tương tự như thuật toán học có giám sát không thể học từ nhãn tự tạo.",
          "C": "Dữ liệu tự tạo thường chứa quá nhiều lỗi và nhiễu.",
          "D": "Quá trình này tiêu tốn quá nhiều tài nguyên tính toán."
        },
        "answer": "B"
      },
      {
        "question": "Loại dữ liệu nào được sử dụng nhiều nhất trong quá trình huấn luyện LLM?",
        "options": {
          "A": "Dữ liệu tổng hợp được tạo ra thông qua quy trình agentic.",
          "B": "Dữ liệu được gắn nhãn bởi con người.",
          "C": "Dữ liệu văn bản không được gắn nhãn.",
          "D": "Dữ liệu được tinh chỉnh để phù hợp với giá trị của con người."
        },
        "answer": "C"
      },
      {
        "question": "Mục đích chính của giai đoạn 'instruction fine-tuning' trong quá trình huấn luyện LLM là gì?",
        "options": {
          "A": "Dạy LLM dự đoán từ tiếp theo trong một chuỗi văn bản.",
          "B": "Điều chỉnh đầu ra của LLM phù hợp với giá trị của con người.",
          "C": "Dạy LLM tuân theo các hướng dẫn.",
          "D": "Giảm chi phí tính toán trong quá trình huấn luyện."
        },
        "answer": "C"
      },
      {
        "question": "Hiện tượng 'model collapse' xảy ra khi nào?",
        "options": {
          "A": "Khi LLM được huấn luyện trên dữ liệu quá lớn.",
          "B": "Khi LLM được huấn luyện lặp đi lặp lại trên đầu ra của phiên bản trước đó của chính nó.",
          "C": "Khi LLM được sử dụng trong một quy trình agentic quá phức tạp.",
          "D": "Khi LLM không được tinh chỉnh phù hợp với giá trị của con người."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, yếu tố nào là rào cản lớn nhất đối với việc sử dụng LLM thông qua quy trình agentic để tạo dữ liệu huấn luyện cho chính nó?",
        "options": {
          "A": "Sự phức tạp của việc thiết kế quy trình agentic.",
          "B": "Chi phí tạo ra token.",
          "C": "Khó khăn trong việc đánh giá chất lượng dữ liệu tổng hợp.",
          "D": "Sự thiếu hụt các công cụ và thư viện hỗ trợ."
        },
        "answer": "B"
      },
      {
        "question": "Trong bài viết, 'Reflection' được đề cập đến như là gì?",
        "options": {
          "A": "Một phương pháp để giảm chi phí huấn luyện LLM.",
          "B": "Một thiết kế mẫu (design pattern) trong quy trình agentic.",
          "C": "Một kỹ thuật để cải thiện độ chính xác của LLM.",
          "D": "Một loại dữ liệu huấn luyện đặc biệt."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, lợi ích tiềm năng của việc sử dụng quy trình agentic để tạo dữ liệu huấn luyện là gì?",
        "options": {
          "A": "Giảm đáng kể chi phí huấn luyện LLM.",
          "B": "Tăng tốc độ huấn luyện LLM.",
          "C": "Tạo ra dữ liệu huấn luyện chất lượng cao hơn so với dữ liệu do LLM tạo ra trực tiếp.",
          "D": "Loại bỏ nhu cầu về dữ liệu huấn luyện do con người tạo ra."
        },
        "answer": "C"
      },
      {
        "question": "Bước nào trong quá trình huấn luyện LLM đòi hỏi lượng dữ liệu lớn hơn nhiều so với các bước khác?",
        "options": {
          "A": "Instruction fine-tuning.",
          "B": "RLHF/DPO tuning.",
          "C": "Pretraining.",
          "D": "Tất cả các bước đều đòi hỏi lượng dữ liệu tương đương."
        },
        "answer": "C"
      },
      {
        "question": "Ví dụ về học sinh tự học viết chứng minh toán học trong bài viết minh họa cho điều gì?",
        "options": {
          "A": "Khả năng của LLM trong việc giải các bài toán phức tạp.",
          "B": "Khả năng của con người trong việc học hỏi từ kinh nghiệm của chính mình.",
          "C": "Khả năng của LLM trong việc tạo ra dữ liệu huấn luyện chất lượng cao.",
          "D": "Khả năng của con người trong việc huấn luyện LLM hiệu quả."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì khiến việc chi một vài triệu đô la cho dữ liệu để cải thiện hiệu suất LLM trở nên khả thi?",
        "options": {
          "A": "Giá token đang giảm nhanh chóng.",
          "B": "Ngân sách cho việc huấn luyện LLM tiên tiến thường vượt quá 100 triệu đô la.",
          "C": "Các công cụ tạo dữ liệu tổng hợp ngày càng trở nên hiệu quả hơn.",
          "D": "Các nhà phát triển đang tìm kiếm các phương pháp huấn luyện LLM rẻ hơn."
        },
        "answer": "B"
      }
    ]
  },
  "better-zero-shot-translations": {
    "title": "Better Zero-Shot Translations",
    "collection": "ml-research",
    "content": "Train amultilingual language translatorto translate between Spanish and English and between English and German, and it may be able to translate directly between Spanish and German as well. New work proposes a simple path to better machine translation between languages that weren’t explicitly paired during training.What’s new:Danni Liu and researchers at Maastricht University and Facebook found that asmall adjustmentin the design of transformer networks improved zero-shot translations rendered by multilingual translators that are based on that architecture.Key insight:Residual connections, which add the inputs of one layer to those of a later layer to preventvanishing gradients, impose a one-to-one correspondence between the two layers they connect. Transformers use residual connections throughout, which imposes a one-to-one correspondence between the network’s input and output. That correspondence could preserve word order in representations extracted from a languages (for example, remembering that adjectives precede the nouns they describe), which causes problems for zero-shot translation if the output language orders adjectives and nouns differently. Removing residual connections in one layer should break the correspondence while preserving the benefits of residual connections in other layers.How it works:The authors used a transformer and removed the residual connections from its encoder’s middle layer.\n\nResults:The authors compared their model’s zero-shot translations with those of an unmodified transformer usingBLEU, a measure of how well a machine translation matches a reference translation (higher is better). On Europarl, removing residual connections boosted the average BLEU score from 8.2 to 26.7. On IWSLT, it raised the average from 10.8 to 17.7. On PMIndia, which includes low-resource languages, it lifted scores from 0.8 to 2.3.Why it matters:The zero-shot approach opens doors in language translation. Many language pairs lack sufficient training data to train a translator via supervised learning. But if you have enough data forNlanguages, zero-shot allows for translation betweenN2language pairs.We’re thinking:Residual connections are all you don’t need!",
    "qa": [
      {
        "question": "Mục tiêu chính của nghiên cứu được đề cập trong bài viết là gì?",
        "options": {
          "A": "Cải thiện khả năng dịch thuật giữa tiếng Anh và tiếng Tây Ban Nha.",
          "B": "Cải thiện khả năng dịch máy giữa các ngôn ngữ không được ghép cặp rõ ràng trong quá trình huấn luyện.",
          "C": "Phát triển một kiến trúc transformer mới hoàn toàn.",
          "D": "Tăng tốc độ dịch thuật của các mô hình dịch máy hiện có."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã thực hiện điều chỉnh nào trong thiết kế của mạng transformer?",
        "options": {
          "A": "Tăng số lượng lớp trong mạng.",
          "B": "Loại bỏ các kết nối dư (residual connections) khỏi lớp giữa của bộ mã hóa (encoder).",
          "C": "Sử dụng một hàm kích hoạt (activation function) khác.",
          "D": "Thay đổi cách thức xử lý dữ liệu đầu vào."
        },
        "answer": "B"
      },
      {
        "question": "Kết nối dư (residual connections) có thể gây ra vấn đề gì trong dịch thuật zero-shot?",
        "options": {
          "A": "Làm chậm quá trình huấn luyện mô hình.",
          "B": "Gây ra sự tương ứng một-một giữa đầu vào và đầu ra, ảnh hưởng đến trật tự từ.",
          "C": "Làm tăng kích thước của mô hình.",
          "D": "Làm giảm độ chính xác của mô hình dịch thuật."
        },
        "answer": "B"
      },
      {
        "question": "BLEU là gì và nó được sử dụng để làm gì trong nghiên cứu này?",
        "options": {
          "A": "Một loại thuật toán mã hóa dữ liệu.",
          "B": "Một thước đo đánh giá mức độ phù hợp giữa bản dịch máy và bản dịch tham khảo.",
          "C": "Một phương pháp tối ưu hóa mô hình dịch máy.",
          "D": "Một công cụ để phân tích cú pháp của các ngôn ngữ."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả thực nghiệm cho thấy việc loại bỏ kết nối dư (residual connections) ảnh hưởng như thế nào đến điểm BLEU?",
        "options": {
          "A": "Làm giảm đáng kể điểm BLEU trên tất cả các tập dữ liệu.",
          "B": "Làm tăng điểm BLEU trên một số tập dữ liệu và giảm trên các tập dữ liệu khác.",
          "C": "Làm tăng điểm BLEU trên hầu hết các tập dữ liệu.",
          "D": "Không có ảnh hưởng đáng kể đến điểm BLEU."
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích chính của phương pháp dịch thuật zero-shot là gì?",
        "options": {
          "A": "Yêu cầu ít dữ liệu huấn luyện hơn so với các phương pháp khác.",
          "B": "Cho phép dịch thuật giữa các cặp ngôn ngữ mà không cần dữ liệu huấn luyện trực tiếp.",
          "C": "Tạo ra bản dịch chính xác hơn so với các phương pháp khác.",
          "D": "Đơn giản hóa quá trình huấn luyện mô hình dịch máy."
        },
        "answer": "B"
      },
      {
        "question": "Trong bối cảnh của bài viết, 'N' đại diện cho điều gì?",
        "options": {
          "A": "Số lượng tham số trong mô hình transformer.",
          "B": "Số lượng ngôn ngữ được sử dụng để huấn luyện mô hình.",
          "C": "Số lượng lớp trong mạng transformer.",
          "D": "Số lượng kết nối dư (residual connections) trong mạng."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đến từ những tổ chức nào?",
        "options": {
          "A": "Google và Stanford University.",
          "B": "Maastricht University và Facebook.",
          "C": "Microsoft và Oxford University.",
          "D": "Amazon và MIT."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao kết nối dư (residual connections) lại được sử dụng trong mạng transformer?",
        "options": {
          "A": "Để tăng tốc độ tính toán.",
          "B": "Để ngăn chặn hiện tượng biến mất gradient (vanishing gradients).",
          "C": "Để giảm kích thước của mô hình.",
          "D": "Để cải thiện khả năng biểu diễn của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Tập dữ liệu PMIndia được đề cập trong bài viết có đặc điểm gì?",
        "options": {
          "A": "Chỉ chứa các ngôn ngữ có nguồn lực cao.",
          "B": "Chứa các ngôn ngữ có nguồn lực thấp.",
          "C": "Chỉ chứa các ngôn ngữ châu Âu.",
          "D": "Chứa dữ liệu từ các bài phát biểu chính trị."
        },
        "answer": "B"
      }
    ]
  },
  "beyond-neural-architecture-search": {
    "title": "Beyond Neural Architecture Search",
    "collection": "ml-research",
    "content": "Faced with a classification task, an important step is to browse the catalog of machine learning architectures to find a good performer. Researchers are exploring ways to do it automatically.What’s new:Esteban Real, Chen Liang, and their colleagues at Google Brain developedAutoML-Zero, an evolutionary meta-algorithm that generates a wide variety of machine learning algorithms to classify data. Applied to the small CIFAR-10 image dataset, it discovered several common deep learning techniques.Key insight:Past meta-algorithms for machine learning constrain their output to particular architectures. Neural architecture search, for instance, finds only neural networks. AutoML-Zero finds any algorithm that can learn using high school-level math.How it works:The researchers used AutoML-Zero to generate models for various resolutions of CIFAR-10.\n\nResults:AutoML-Zero regularly generated models that achieved 84 percent accuracy on CIFAR-10, compared to only 82 percent achieved by a two-layer, fully connected network. In the process, it rediscovered gradient descent, ReLu activations, gradient normalization, and hyperparameters.Why it matters:The researchers estimate that, given AutoML-Zero’s wide-ranging purview, the chance of coming up with a model suitable for a CIFAR-10 classification task is vanishingly small (around 1 in 107 for linear regression, and 1012 if that line is offset by a constant). Yet it did so frequently — a demonstration of the meta-algorithm’s power to come up with useful architectures. If AutoML-Zero can find nearly state-of-the-art models on such a complex task, it may well be able to discover techniques that humans haven’t yet devised.We’re thinking:CIFAR-10 was developed over a decade ago for machine learning experiments on the CPU-based neural networks of the day. We’re curious to learn how AutoML-Zero scales to larger datasets.We’re not thinking:Today we have learning algorithms that design other learning algorithms. When will we have learning algorithms that design learning algorithms that design learning algorithms?",
    "qa": [
      {
        "question": "AutoML-Zero là gì?",
        "options": {
          "A": "Một mạng nơ-ron nhân tạo được thiết kế đặc biệt cho CIFAR-10.",
          "B": "Một meta-thuật toán tiến hóa tạo ra nhiều thuật toán máy học để phân loại dữ liệu.",
          "C": "Một kỹ thuật tìm kiếm kiến trúc nơ-ron chỉ tìm kiếm các mạng nơ-ron.",
          "D": "Một thuật toán hồi quy tuyến tính được sử dụng để phân loại hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "AutoML-Zero khác biệt so với các meta-thuật toán máy học trước đây như thế nào?",
        "options": {
          "A": "Nó chỉ có thể tìm kiếm các mạng nơ-ron.",
          "B": "Nó giới hạn đầu ra của nó cho các kiến trúc cụ thể.",
          "C": "Nó có thể tìm thấy bất kỳ thuật toán nào có thể học bằng cách sử dụng toán học cấp trung học.",
          "D": "Nó không thể áp dụng cho các tập dữ liệu hình ảnh."
        },
        "answer": "C"
      },
      {
        "question": "AutoML-Zero đã đạt được độ chính xác bao nhiêu trên tập dữ liệu CIFAR-10?",
        "options": {
          "A": "60%",
          "B": "75%",
          "C": "82%",
          "D": "84%"
        },
        "answer": "D"
      },
      {
        "question": "Những kỹ thuật học sâu phổ biến nào đã được AutoML-Zero tái khám phá?",
        "options": {
          "A": "Mạng nơ-ron tích chập và pooling.",
          "B": "Gradient descent, ReLu activations, gradient normalization và hyperparameters.",
          "C": "Hồi quy logistic và Support Vector Machines.",
          "D": "K-means clustering và phân tích thành phần chính."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao các nhà nghiên cứu đánh giá cao khả năng của AutoML-Zero?",
        "options": {
          "A": "Vì nó có thể dễ dàng đánh bại các mô hình hồi quy tuyến tính.",
          "B": "Vì nó có thể tạo ra các mô hình phù hợp cho CIFAR-10 mặc dù xác suất rất nhỏ.",
          "C": "Vì nó chỉ sử dụng toán học cấp trung học.",
          "D": "Vì nó nhanh hơn các thuật toán tìm kiếm kiến trúc nơ-ron khác."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, AutoML-Zero có thể khám phá ra điều gì trong tương lai?",
        "options": {
          "A": "Các kỹ thuật mà con người đã phát minh ra.",
          "B": "Các kỹ thuật mà con người chưa phát minh ra.",
          "C": "Các thuật toán hồi quy tuyến tính hiệu quả hơn.",
          "D": "Các mạng nơ-ron phức tạp hơn cho CIFAR-10."
        },
        "answer": "B"
      },
      {
        "question": "Tập dữ liệu CIFAR-10 được phát triển khi nào và cho mục đích gì?",
        "options": {
          "A": "Hơn một thập kỷ trước, cho các thí nghiệm máy học trên mạng nơ-ron dựa trên GPU.",
          "B": "Hơn một thập kỷ trước, cho các thí nghiệm máy học trên mạng nơ-ron dựa trên CPU.",
          "C": "Gần đây, cho các thí nghiệm học sâu trên mạng nơ-ron tích chập.",
          "D": "Gần đây, cho các thí nghiệm học tăng cường."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đang tò mò về điều gì liên quan đến AutoML-Zero?",
        "options": {
          "A": "Khả năng của nó trong việc tái khám phá các thuật toán hiện có.",
          "B": "Khả năng mở rộng của nó với các tập dữ liệu lớn hơn.",
          "C": "Độ chính xác của nó trên tập dữ liệu CIFAR-10.",
          "D": "Tốc độ của nó so với các thuật toán khác."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến một câu hỏi mở về tương lai của các thuật toán học máy, đó là gì?",
        "options": {
          "A": "Khi nào chúng ta sẽ có các thuật toán học máy có thể thay thế con người hoàn toàn?",
          "B": "Khi nào chúng ta sẽ có các thuật toán học máy có thể tự động gỡ lỗi?",
          "C": "Khi nào chúng ta sẽ có các thuật toán học máy thiết kế các thuật toán học máy thiết kế các thuật toán học máy?",
          "D": "Khi nào chúng ta sẽ có các thuật toán học máy có thể hiểu ngôn ngữ tự nhiên hoàn toàn?"
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, xác suất để một mô hình hồi quy tuyến tính phù hợp cho CIFAR-10 là bao nhiêu?",
        "options": {
          "A": "Khoảng 1 trên 10^5",
          "B": "Khoảng 1 trên 10^7",
          "C": "Khoảng 1 trên 10^9",
          "D": "Khoảng 1 trên 10^12"
        },
        "answer": "B"
      }
    ]
  },
  "beyond-the-bounding-box": {
    "title": "Beyond the Bounding Box",
    "collection": "ml-research",
    "content": "Computer vision models typically draw bounding boxes around objects they spot, but those rectangles are a crude approximation of an object’s outline. A new method finds keypoints on an object’s perimeter to produce state-of-the-art object classification.What’s new:Ze Yang and researchers from Peking University, Tsinghua University, and Microsoft Research developed a network, RPDet, that extracts what the authors call representation points, orRepPoints.Key insights:Bounding boxes can be constructed from RepPoints, which enables RPDet to learn to derive RepPoints from bounding-box labels in standard object-recognition datasets. A good RepPoint is one that helps to answer two questions: What is the bounding box, and what object does it enclose?How it works:RPDet uses feature pyramidal networks that extract a hierarchy of image features of varying levels of detail. From these features, it extracts a user-defined number of points as follows:\n\nResults:Processing image features supplied by a ResNet, RPDet achieved a 2 percent boost in classification accuracy over bounding-box representations. Further, RPDet achieves a new state of the art for precision on COCO, an object detection and classification dataset, with 4 percent improvement in average precision over the alternatives considered.Why it matters:This technique encodes relatively detailed information about object shapes that could be useful in a variety of tasks. For instance, RepPoints’ implicit estimation of poses could help predict the trajectory of a moving object.We’re thinking:Plenty of applications, including face recognition, find explicit predefined keypoints. But they tend to be specialized for specific types of objects, such as finding the eyes, nose, and mouth on faces. RepPoints encode arbitrary geometry and pose information for a wide range of shapes, giving them a potential role in applications that otherwise wouldn’t be feasible.",
    "qa": [
      {
        "question": "Phương pháp RPDet được phát triển bởi các nhà nghiên cứu đến từ đâu?",
        "options": {
          "A": "Đại học Stanford, Đại học Harvard và Google AI",
          "B": "Đại học Bắc Kinh, Đại học Thanh Hoa và Microsoft Research",
          "C": "Viện Công nghệ Massachusetts (MIT), Đại học California, Berkeley và Facebook AI",
          "D": "Đại học Oxford, Đại học Cambridge và DeepMind"
        },
        "answer": "B"
      },
      {
        "question": "RPDet sử dụng khái niệm nào để biểu diễn hình dạng của vật thể thay vì bounding box truyền thống?",
        "options": {
          "A": "Feature Vectors",
          "B": "Representation Points (RepPoints)",
          "C": "Convolutional Kernels",
          "D": "Anchor Boxes"
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của một RepPoint 'tốt' là gì?",
        "options": {
          "A": "Xác định màu sắc chủ đạo của vật thể.",
          "B": "Giúp xác định bounding box và vật thể mà nó bao quanh.",
          "C": "Tối ưu hóa tốc độ xử lý hình ảnh.",
          "D": "Giảm thiểu nhiễu trong quá trình nhận diện vật thể."
        },
        "answer": "B"
      },
      {
        "question": "RPDet sử dụng kiến trúc mạng nào để trích xuất các đặc trưng hình ảnh ở các mức độ chi tiết khác nhau?",
        "options": {
          "A": "Recurrent Neural Networks (RNNs)",
          "B": "Generative Adversarial Networks (GANs)",
          "C": "Feature Pyramidal Networks (FPNs)",
          "D": "Self-Organizing Maps (SOMs)"
        },
        "answer": "C"
      },
      {
        "question": "So với phương pháp sử dụng bounding box, RPDet đạt được mức tăng bao nhiêu phần trăm về độ chính xác phân loại khi sử dụng ResNet?",
        "options": {
          "A": "1%",
          "B": "2%",
          "C": "3%",
          "D": "4%"
        },
        "answer": "B"
      },
      {
        "question": "Trên bộ dữ liệu COCO, RPDet cải thiện độ chính xác trung bình (average precision) so với các phương pháp khác là bao nhiêu?",
        "options": {
          "A": "2%",
          "B": "3%",
          "C": "4%",
          "D": "5%"
        },
        "answer": "C"
      },
      {
        "question": "Ưu điểm chính của việc sử dụng RepPoints so với các keypoint được xác định trước (predefined keypoints) là gì?",
        "options": {
          "A": "RepPoints có độ chính xác cao hơn trong việc xác định các đặc điểm khuôn mặt.",
          "B": "RepPoints có thể mã hóa thông tin hình học và tư thế tùy ý cho nhiều hình dạng khác nhau.",
          "C": "RepPoints yêu cầu ít tài nguyên tính toán hơn.",
          "D": "RepPoints dễ dàng tích hợp vào các hệ thống hiện có hơn."
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng tiềm năng nào của RepPoints được đề cập trong bài viết liên quan đến việc dự đoán?",
        "options": {
          "A": "Dự đoán giá cổ phiếu.",
          "B": "Dự đoán thời tiết.",
          "C": "Dự đoán quỹ đạo của một vật thể đang di chuyển.",
          "D": "Dự đoán kết quả bầu cử."
        },
        "answer": "C"
      },
      {
        "question": "Bounding boxes được tạo ra từ RepPoints như thế nào?",
        "options": {
          "A": "Bounding boxes được tạo ra bằng cách sử dụng một thuật toán ngẫu nhiên.",
          "B": "Bounding boxes được xây dựng từ RepPoints, cho phép RPDet học cách suy ra RepPoints từ nhãn bounding box trong các bộ dữ liệu nhận dạng đối tượng tiêu chuẩn.",
          "C": "Bounding boxes được tạo ra bằng cách sử dụng thông tin màu sắc của đối tượng.",
          "D": "Bounding boxes được tạo ra bằng cách sử dụng thông tin về độ sâu của hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Lợi ích chính của việc mã hóa thông tin chi tiết về hình dạng vật thể bằng kỹ thuật RepPoints là gì?",
        "options": {
          "A": "Giảm kích thước mô hình.",
          "B": "Tăng tốc độ xử lý hình ảnh.",
          "C": "Có thể hữu ích trong nhiều tác vụ khác nhau, đặc biệt là những tác vụ trước đây không khả thi.",
          "D": "Đơn giản hóa quá trình huấn luyện mô hình."
        },
        "answer": "C"
      }
    ]
  },
  "bias-fighter": {
    "title": "Bias Fighter",
    "collection": "ml-research",
    "content": "Sophisticated models trained on biased data can learn discriminatory patterns, which leads to skewed decisions. A new solution aims to prevent neural networks from making decisions based on common biases.What’s new:Ehsan Adeli and a group at Stanford proposeBias-Resilient Neural Network, or BR-Net, an architecture that works with a classifier to minimize the impact of biases that are well understood. In the training data, we can label, say, race and gender (known as bias variables), and BR-Net will learn to prevent spurious correlations between those variables and the model's output classification.Key insight:Biases in data correlate with class labels. If one part of a network learns to predict this correlation, another can learn to minimize the predicted correlation. This adversarial scheme can mitigate bias.How it works:BR-Net comprises three neural networks. The feature extractor finds embeddings of input data. The classifier predicts class labels from the embeddings. The bias predictor predicts the correlation between embeddings and bias variables. Once labels for bias variables have been added to the data, training proceeds in three steps:\n\nResults:The researchers used a VGG16 classifier with BR-Net to predict a person’s gender from a photo. They trained the model on the GS-PPB dataset. Because classifiers often perform poorly on darker faces, they labeled skin tone as a bias variable. BR-Net achieved 96.1 percent balanced accuracy (accuracy for each of six skin tones considered equally), an improvement of 2 percent. This indicates more consistent results across different skin colors than a VGG16 trained without BR-Net.Why it matters:Bias in AI is insidious and difficult to prevent. BR-Net offers a solution when sources of bias are known.We're thinking:Machine learning presents hard questions to society: Which biases should we avoid? How can we come to agreement about which to avoid? Who gets to decide in the end? In lieu of answers, the choices are in the hands of ML engineers.",
    "qa": [
      {
        "question": "Vấn đề chính mà bài viết đề cập đến là gì?",
        "options": {
          "A": "Sự cần thiết của việc sử dụng VGG16 trong phân loại hình ảnh.",
          "B": "Khả năng các mô hình AI học các khuôn mẫu phân biệt đối xử từ dữ liệu thiên vị.",
          "C": "Sự phức tạp trong việc xây dựng các mạng nơ-ron sâu.",
          "D": "Hiệu quả của việc sử dụng dữ liệu lớn để huấn luyện mô hình AI."
        },
        "answer": "B"
      },
      {
        "question": "BR-Net là gì?",
        "options": {
          "A": "Một thuật toán mới để tăng tốc độ huấn luyện mạng nơ-ron.",
          "B": "Một kiến trúc mạng nơ-ron được thiết kế để giảm thiểu tác động của các thiên kiến đã biết.",
          "C": "Một phương pháp để tạo ra dữ liệu huấn luyện không thiên vị.",
          "D": "Một công cụ để đánh giá mức độ thiên vị của một mô hình AI."
        },
        "answer": "B"
      },
      {
        "question": "Đâu là ý tưởng chính đằng sau BR-Net?",
        "options": {
          "A": "Sử dụng nhiều lớp ẩn hơn trong mạng nơ-ron để tăng độ chính xác.",
          "B": "Phân tách mạng thành các phần, một phần học các tương quan thiên vị và một phần giảm thiểu chúng.",
          "C": "Sử dụng các hàm kích hoạt phức tạp hơn để tránh các quyết định thiên vị.",
          "D": "Huấn luyện mô hình trên nhiều bộ dữ liệu khác nhau để giảm thiểu thiên vị."
        },
        "answer": "B"
      },
      {
        "question": "BR-Net bao gồm mấy mạng nơ-ron?",
        "options": {
          "A": "Một",
          "B": "Hai",
          "C": "Ba",
          "D": "Bốn"
        },
        "answer": "C"
      },
      {
        "question": "Ba mạng nơ-ron trong BR-Net có chức năng gì?",
        "options": {
          "A": "Phân tích dữ liệu, phân loại và tạo ra dữ liệu mới.",
          "B": "Trích xuất đặc trưng, phân loại và dự đoán biến thiên vị.",
          "C": "Làm sạch dữ liệu, huấn luyện và kiểm tra mô hình.",
          "D": "Mã hóa, giải mã và phân loại dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Trong thí nghiệm được mô tả, biến thiên vị nào đã được sử dụng?",
        "options": {
          "A": "Tuổi tác",
          "B": "Giới tính",
          "C": "Màu da",
          "D": "Chiều cao"
        },
        "answer": "C"
      },
      {
        "question": "Bộ dữ liệu nào đã được sử dụng để huấn luyện mô hình trong thí nghiệm?",
        "options": {
          "A": "ImageNet",
          "B": "MNIST",
          "C": "GS-PPB",
          "D": "CIFAR-10"
        },
        "answer": "C"
      },
      {
        "question": "Kết quả chính của thí nghiệm là gì?",
        "options": {
          "A": "BR-Net giảm độ chính xác tổng thể của mô hình.",
          "B": "BR-Net cải thiện độ chính xác cân bằng, cho thấy kết quả nhất quán hơn giữa các màu da khác nhau.",
          "C": "BR-Net chỉ hoạt động tốt trên một số loại hình ảnh nhất định.",
          "D": "BR-Net không có tác động đáng kể đến hiệu suất của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc giải quyết vấn đề thiên vị trong AI lại quan trọng?",
        "options": {
          "A": "Để tăng tốc độ huấn luyện mô hình.",
          "B": "Để đảm bảo các quyết định của AI công bằng và không phân biệt đối xử.",
          "C": "Để giảm chi phí phát triển mô hình AI.",
          "D": "Để làm cho mô hình AI dễ hiểu hơn."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, ai là người đưa ra các quyết định về việc tránh những thiên vị nào trong AI?",
        "options": {
          "A": "Các nhà lập pháp.",
          "B": "Các nhà đạo đức học.",
          "C": "Các kỹ sư học máy.",
          "D": "Công chúng."
        },
        "answer": "C"
      }
    ]
  },
  "bias-goes-undercover": {
    "title": "Bias Goes Undercover",
    "collection": "ml-research",
    "content": "As black-box algorithms like neural networks find their way into high-stakes fields such as transportation, healthcare, and finance, researchers have developed techniques to help explain models’ decisions. New findings show that some of these methods can be fooled.What’s new:Two popular approaches to interpreting black-box algorithms includeLocal Interpretable Model-Agnostic Explanations(LIME) andShapley Additive Explanations(SHAP). Researchers at Harvard and the University of California Irvine found a way to trick these methods to make a deliberately biased model appear to be unbiased.Key Insight:LIME and SHAP expose bias by showing how a model might react to small perturbations in its input. Statistical analysis shows that the distribution of perturbed inputs is distinct from that of the original inputs, as shown in the image above. A malicious actor can take advantage of the difference.How it works:LIME and SHAP use a linear model, which is highly explainable, to mimic a black-box model’s decision with respect to any given input sample. The explainable model is built by feeding perturbed inputs to the black-box model and measuring how its output changes in response to the perturbations. Once the model is built, we can rank the features most important to the decision, highlighting any bias in the original model. Dylan Slack, Sophie Hilgard, and their colleagues introduce a way to hide such bias from LIME and SHAP by learning to recognize data they’ve altered.\n\nResults:The authors created malicious systems to run COMPAS (a criminal recidivism dataset), Communities And Crime (a dataset of violent crime and demographic information), and the German Credit loan-application dataset. The embedded biased models deliberately abused discriminatory features such as race and gender, while the unbiased models used only features which were uncorrelated with discriminatory features. A malicious system biased on one feature (say, race) fooled LIME every time and SHAP in 85 percent of cases. A malicious system biased on two features fooled LIME over 90 percent of the time and SHAP 67 percent of the time.Why it matters:The authors’ approach highlights LIME’s and SHAP’s reliance on generating novel data. If these methods were to generate data more similar to the training data’s distribution, the method would fail. This may be a promising avenue for explainability research. Meanwhile, Duke University computer scientist Cynthia Rudinproposesavoiding black-box models in high-stakes situations. The AI community needs to hold a vigorous discussion about when such models are and aren’t appropriate.We’re thinking:If a major AI provider were caught using this technique, likely it would be vilified, which should provide some disincentive. We can imagine changes to LIME and SHAP that would counter a specific implementation, but this paper provides a dose of caution that checking for bias is not easy.",
    "qa": [
      {
        "question": "Các thuật toán black-box như mạng nơ-ron đang được ứng dụng rộng rãi trong lĩnh vực nào?",
        "options": {
          "A": "Nghiên cứu khoa học cơ bản.",
          "B": "Giao thông, y tế và tài chính.",
          "C": "Sản xuất hàng tiêu dùng.",
          "D": "Nông nghiệp công nghệ cao."
        },
        "answer": "B"
      },
      {
        "question": "LIME và SHAP là những phương pháp được sử dụng để làm gì?",
        "options": {
          "A": "Tăng cường hiệu suất của các thuật toán black-box.",
          "B": "Giải thích các quyết định của mô hình black-box.",
          "C": "Phát hiện và sửa lỗi trong dữ liệu huấn luyện.",
          "D": "Tự động tạo ra các mô hình học máy mới."
        },
        "answer": "B"
      },
      {
        "question": "Theo nghiên cứu, LIME và SHAP có thể bị đánh lừa bằng cách nào?",
        "options": {
          "A": "Thay đổi cấu trúc của thuật toán.",
          "B": "Làm cho một mô hình thiên vị có vẻ như không thiên vị.",
          "C": "Giảm độ chính xác của dữ liệu đầu vào.",
          "D": "Tăng kích thước của tập dữ liệu huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "LIME và SHAP hoạt động dựa trên việc sử dụng mô hình nào để mô phỏng quyết định của black-box?",
        "options": {
          "A": "Mô hình phi tuyến tính phức tạp.",
          "B": "Mô hình tuyến tính dễ giải thích.",
          "C": "Mô hình cây quyết định.",
          "D": "Mô hình mạng nơ-ron sâu."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp mà Dylan Slack và các đồng nghiệp giới thiệu có tác dụng gì?",
        "options": {
          "A": "Cải thiện độ chính xác của LIME và SHAP.",
          "B": "Ẩn đi sự thiên vị khỏi LIME và SHAP.",
          "C": "Tăng tốc độ xử lý của các thuật toán black-box.",
          "D": "Giảm thiểu rủi ro trong các ứng dụng tài chính."
        },
        "answer": "B"
      },
      {
        "question": "Trong các thử nghiệm, hệ thống độc hại đã sử dụng những loại dữ liệu nào?",
        "options": {
          "A": "Dữ liệu hình ảnh và âm thanh.",
          "B": "Dữ liệu văn bản và ngôn ngữ tự nhiên.",
          "C": "Dữ liệu về tiền sử phạm tội, tội phạm và thông tin nhân khẩu học, và đơn xin vay tín dụng.",
          "D": "Dữ liệu về thị trường chứng khoán và giao dịch tài chính."
        },
        "answer": "C"
      },
      {
        "question": "Kết quả thử nghiệm cho thấy, hệ thống độc hại thiên vị trên một đặc điểm (ví dụ: chủng tộc) đã đánh lừa LIME và SHAP với tỷ lệ nào?",
        "options": {
          "A": "LIME 50%, SHAP 50%.",
          "B": "LIME 100%, SHAP 85%.",
          "C": "LIME 85%, SHAP 100%.",
          "D": "LIME 67%, SHAP 90%."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao tác giả bài viết cho rằng phương pháp của họ lại quan trọng?",
        "options": {
          "A": "Nó giúp tăng cường tính bảo mật của dữ liệu cá nhân.",
          "B": "Nó làm nổi bật sự phụ thuộc của LIME và SHAP vào việc tạo ra dữ liệu mới.",
          "C": "Nó giúp giảm chi phí tính toán cho các thuật toán black-box.",
          "D": "Nó cho phép tự động hóa quá trình ra quyết định trong các hệ thống AI."
        },
        "answer": "B"
      },
      {
        "question": "Cynthia Rudin đề xuất giải pháp nào cho các tình huống rủi ro cao?",
        "options": {
          "A": "Sử dụng các mô hình black-box phức tạp hơn.",
          "B": "Tránh sử dụng các mô hình black-box.",
          "C": "Tăng cường kiểm soát và giám sát các mô hình black-box.",
          "D": "Phát triển các phương pháp giải thích mạnh mẽ hơn cho các mô hình black-box."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết kết luận rằng việc kiểm tra sự thiên vị trong các mô hình AI là như thế nào?",
        "options": {
          "A": "Đơn giản và dễ thực hiện.",
          "B": "Khó khăn và phức tạp.",
          "C": "Chỉ cần thiết trong một số trường hợp nhất định.",
          "D": "Không cần thiết nếu dữ liệu huấn luyện đã được làm sạch."
        },
        "answer": "B"
      }
    ]
  },
  "big-bot-makes-small-talk": {
    "title": "Big Bot Makes Small Talk",
    "collection": "ml-research",
    "content": "Facebook recently rolled out its entry in the World’s Biggest Chatbot sweepstakes. In keeping with the company’s social-networking dominance, the bot is designed to excel at chitchat on any subject.What’s new:Led by Stephen Roller, Facebook researchers builtGenerative BST, a transformer-based model comprising up to 9.4 billion parameters. They trained the bot on their ownBlendedSkillTalkdataset of 5,000 conversations among 2,500 people who were instructed to be knowledgeable, empathetic, and generous with personal details.Key insight:The keys to small talk are personality, knowledge, empathy, and balancing response length (too short shows lack of interest, too long betrays poor listening). BlendedSkillTalk is designed to teach the first three traits. Finding the right response length is a matter of generation strategy.How it works:Many chatbots generate a set of potential responses and score the best one in a technique known as retrieval. In contrast, generative language models create responses one token at a time, often producingdull or repetitive output. Generative BST combines these approaches in a method calledretrieve and refine.\n\nResults:Human judges scored the performance of Generative BST and Google’s Meena (see “Toward Open-Domain Chatbots” above) according toAcute-Eval, a chatbot benchmark also developed by Facebook. Sixty-five percent of judges found Generative BST more human-like, while 75 percent found it more engaging. The researchers experimented with various techniques to build variants with different skills. For instance, 70 percent of judges found the version called BST Unlikelihood, which used a different generation approach, more human-like than Meena, but only 64 percent found it more engaging.Yes, but:The judges’ positive assessment of Generative BST’s human-like qualities relative to other chatbots doesn’t imply that any of them can carry on coherent conversations. You can read some nonsensical turns with Generative BSThere.Why it matters:Generative BST held the record for chatbot parameter count for only a short time before Microsoft announced its 17 billion-parameterTuring-NLG. But its malleable generator remains unique. Other researchers may be able to use this framework to create chatbots with particular qualities and behaviors.We’re thinking:Facebook’s bot takes Big Tech rivalry to a new level. The Googlers behind Meena reported a conversation (illustrated above) in which their system, considering education for barnyard animals, punned, “Horses go to Hayvard.” The Facebook authors tried out the joke on Generative BST. The bot merely deadpanned: “I don’t get it.”",
    "qa": [
      {
        "question": "Mục tiêu chính của chatbot mới được Facebook phát triển là gì?",
        "options": {
          "A": "Thực hiện các tác vụ phức tạp như đặt vé máy bay và thanh toán hóa đơn.",
          "B": "Trò chuyện một cách tự nhiên và hấp dẫn về nhiều chủ đề khác nhau.",
          "C": "Cung cấp thông tin chính xác và nhanh chóng về các sự kiện thời sự.",
          "D": "Hỗ trợ khách hàng giải quyết các vấn đề kỹ thuật liên quan đến sản phẩm của Facebook."
        },
        "answer": "B"
      },
      {
        "question": "Generative BST, chatbot của Facebook, được xây dựng dựa trên mô hình nào?",
        "options": {
          "A": "Mô hình mạng nơ-ron tích chập (CNN).",
          "B": "Mô hình dựa trên transformer với số lượng tham số lớn.",
          "C": "Mô hình Markov ẩn (HMM).",
          "D": "Mô hình cây quyết định (Decision Tree)."
        },
        "answer": "B"
      },
      {
        "question": "Bộ dữ liệu BlendedSkillTalk được sử dụng để huấn luyện Generative BST tập trung vào những yếu tố nào?",
        "options": {
          "A": "Khả năng phân tích dữ liệu và đưa ra dự đoán chính xác.",
          "B": "Kiến thức chuyên môn sâu rộng, khả năng thấu cảm và chia sẻ thông tin cá nhân.",
          "C": "Tốc độ xử lý ngôn ngữ và khả năng dịch thuật đa ngôn ngữ.",
          "D": "Kỹ năng lập trình và khả năng tương tác với các hệ thống khác."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, yếu tố nào không được đề cập đến như là một chìa khóa để trò chuyện hiệu quả?",
        "options": {
          "A": "Tính cách.",
          "B": "Kiến thức.",
          "C": "Sự thấu cảm.",
          "D": "Khả năng giải quyết vấn đề."
        },
        "answer": "D"
      },
      {
        "question": "Phương pháp 'retrieve and refine' mà Generative BST sử dụng kết hợp những kỹ thuật nào?",
        "options": {
          "A": "Tạo ra các phản hồi tiềm năng và đánh giá chúng.",
          "B": "Tạo ra phản hồi từng token một và lựa chọn phản hồi tốt nhất.",
          "C": "Kết hợp cả hai kỹ thuật tạo ra phản hồi tiềm năng và tạo phản hồi từng token một.",
          "D": "Sử dụng một cơ sở dữ liệu lớn các câu trả lời được tạo sẵn."
        },
        "answer": "C"
      },
      {
        "question": "Benchmark Acute-Eval được sử dụng để đánh giá hiệu suất của Generative BST so với chatbot nào khác?",
        "options": {
          "A": "GPT-3 của OpenAI.",
          "B": "Meena của Google.",
          "C": "BERT của Google.",
          "D": "Alexa của Amazon."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả đánh giá cho thấy điều gì về Generative BST so với Meena?",
        "options": {
          "A": "Generative BST được đánh giá là có khả năng giải quyết vấn đề tốt hơn.",
          "B": "Generative BST được đánh giá là giống con người hơn và hấp dẫn hơn.",
          "C": "Meena được đánh giá là có kiến thức chuyên môn sâu rộng hơn.",
          "D": "Meena được đánh giá là có tốc độ xử lý ngôn ngữ nhanh hơn."
        },
        "answer": "B"
      },
      {
        "question": "Phiên bản BST Unlikelihood của Generative BST khác biệt so với phiên bản gốc ở điểm nào?",
        "options": {
          "A": "Sử dụng một bộ dữ liệu huấn luyện khác.",
          "B": "Sử dụng một phương pháp tạo phản hồi khác.",
          "C": "Có số lượng tham số lớn hơn.",
          "D": "Tập trung vào một lĩnh vực kiến thức cụ thể."
        },
        "answer": "B"
      },
      {
        "question": "Mặc dù được đánh giá cao, bài viết cũng chỉ ra hạn chế nào của Generative BST và các chatbot tương tự?",
        "options": {
          "A": "Khả năng hiểu ngôn ngữ tự nhiên còn hạn chế.",
          "B": "Khả năng duy trì các cuộc trò chuyện mạch lạc còn hạn chế.",
          "C": "Khả năng xử lý các yêu cầu phức tạp còn hạn chế.",
          "D": "Khả năng tương tác với các hệ thống khác còn hạn chế."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì khiến bộ tạo (generator) của Generative BST trở nên độc đáo so với các chatbot khác?",
        "options": {
          "A": "Khả năng học hỏi từ dữ liệu mới một cách nhanh chóng.",
          "B": "Khả năng tùy biến để tạo ra các chatbot với các đặc điểm và hành vi cụ thể.",
          "C": "Khả năng xử lý ngôn ngữ đa ngôn ngữ một cách hiệu quả.",
          "D": "Khả năng tích hợp với các nền tảng mạng xã hội khác."
        },
        "answer": "B"
      }
    ]
  },
  "bigger-corpora-better-answers": {
    "title": "Bigger Corpora, Better Answers",
    "collection": "ml-research",
    "content": "Models that summarize documents and answer questions work pretty well with limited source material, but they can slip into incoherence when they draw from a sizeable corpus. Recent work by Facebook AI Research and Université de Lorraine’s computer science research lab addresses this problem.What’s new:Angela Fan and collaborators developed amodelfor multi-document summarization and question answering. While most previous efforts combine all input documents into one, the authors improved  the state of t he art by representing them in a more compact form.Key insight:The combined length of major source documents pertaining to a given topic overwhelms current language models' ability to extract meaning. A knowledge graph squeezes out irrelevant and redundant information, enabling models to work more effectively.How it works:The authors’ method involves three steps: constructing a knowledge graph from source documents, encoding the graph as a sequence of words, and extracting information from the sequence.\n\nResults:The authors tested their model on a question answering task based on the dataset called Explain Like I'm Five (ELI5).This dataset contains 270,000 question-answer pairs along with source documents (the top 100 web sources from the CommonCrawl corpus for each question). The graph approach edged out the earlier state of the art on F1 for ROUGE-1 (30 percent versus 28.9 percent). They also compared performance on the WikiSum dataset for multi-document summarization using an article’s title as the input query, the footnotes as source documents, and the first paragraph as the target summary. The graph approach underperformed the previous ROUGE-L state of the art 36.5 percent to 38.8 percent, but the comparison wasn't apples-to-apples. The previous research supplemented the corpus with a web search, while the new work used only CommonCrawl.Why it matters:This research shows that natural language generation based on very large bodies of input text can work well. It also shows that source documents don’t need to be composed of well formed sentences. New ways of representing source documents may well lead to better language generation.We’re thinking:Many search engines produce summaries or answer questions by choosing the most relevant document. The ability to draw on any number of documents could enable such models to deliver a far wider diversity of information, leading to better research tools and ultimately a better-informed public.",
    "qa": [
      {
        "question": "Phương pháp mới được phát triển bởi Facebook AI Research và Université de Lorraine tập trung giải quyết vấn đề gì?",
        "options": {
          "A": "Tăng tốc độ xử lý ngôn ngữ tự nhiên.",
          "B": "Giảm sự thiếu mạch lạc khi mô hình xử lý lượng lớn tài liệu.",
          "C": "Cải thiện khả năng dịch thuật giữa các ngôn ngữ.",
          "D": "Nâng cao độ chính xác của việc nhận diện giọng nói."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính trong phương pháp của Angela Fan và cộng sự so với các phương pháp trước đây là gì?",
        "options": {
          "A": "Sử dụng mạng nơ-ron sâu hơn.",
          "B": "Biểu diễn tài liệu đầu vào dưới dạng cô đọng hơn.",
          "C": "Áp dụng thuật toán di truyền để tối ưu hóa mô hình.",
          "D": "Sử dụng nhiều dữ liệu huấn luyện hơn."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, tại sao việc sử dụng knowledge graph lại giúp mô hình hoạt động hiệu quả hơn?",
        "options": {
          "A": "Knowledge graph giúp tăng cường khả năng tính toán của mô hình.",
          "B": "Knowledge graph loại bỏ thông tin không liên quan và dư thừa.",
          "C": "Knowledge graph giúp mô hình hiểu rõ hơn về ngữ cảnh của câu hỏi.",
          "D": "Knowledge graph giúp mô hình truy cập dữ liệu nhanh hơn."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp của các tác giả bao gồm mấy bước chính?",
        "options": {
          "A": "2",
          "B": "3",
          "C": "4",
          "D": "5"
        },
        "answer": "B"
      },
      {
        "question": "Trong thử nghiệm, mô hình được đánh giá trên tập dữ liệu nào cho nhiệm vụ trả lời câu hỏi?",
        "options": {
          "A": "WikiSum",
          "B": "CommonCrawl",
          "C": "Explain Like I'm Five (ELI5)",
          "D": "ROUGE-1"
        },
        "answer": "C"
      },
      {
        "question": "Kết quả thử nghiệm trên tập dữ liệu ELI5 cho thấy điều gì?",
        "options": {
          "A": "Phương pháp mới vượt trội hơn hẳn so với các phương pháp trước đây.",
          "B": "Phương pháp mới có kết quả tương đương với các phương pháp trước đây.",
          "C": "Phương pháp mới nhỉnh hơn một chút so với các phương pháp trước đây.",
          "D": "Phương pháp mới kém hiệu quả hơn so với các phương pháp trước đây."
        },
        "answer": "C"
      },
      {
        "question": "Trên tập dữ liệu WikiSum, phương pháp mới so sánh với phương pháp trước đó như thế nào?",
        "options": {
          "A": "Phương pháp mới vượt trội hơn về ROUGE-L.",
          "B": "Phương pháp mới kém hơn về ROUGE-L.",
          "C": "Phương pháp mới và phương pháp cũ có kết quả ROUGE-L tương đương.",
          "D": "Không thể so sánh do phương pháp mới không được thử nghiệm trên WikiSum."
        },
        "answer": "B"
      },
      {
        "question": "Một yếu tố nào khiến việc so sánh hiệu suất trên WikiSum không hoàn toàn công bằng?",
        "options": {
          "A": "Phương pháp mới sử dụng ít tài nguyên tính toán hơn.",
          "B": "Phương pháp cũ bổ sung dữ liệu từ tìm kiếm trên web.",
          "C": "Phương pháp mới được huấn luyện trên một tập dữ liệu nhỏ hơn.",
          "D": "Phương pháp cũ sử dụng một kiến trúc mô hình phức tạp hơn."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu này cho thấy điều gì về khả năng tạo ngôn ngữ tự nhiên dựa trên lượng lớn văn bản đầu vào?",
        "options": {
          "A": "Khả năng này vẫn còn rất hạn chế.",
          "B": "Khả năng này có thể hoạt động tốt.",
          "C": "Khả năng này chỉ hiệu quả với các văn bản có cấu trúc tốt.",
          "D": "Khả năng này phụ thuộc nhiều vào ngôn ngữ được sử dụng."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết gợi ý rằng, trong tương lai, khả năng xử lý nhiều tài liệu có thể cải thiện điều gì ở các công cụ tìm kiếm?",
        "options": {
          "A": "Tăng tốc độ tìm kiếm.",
          "B": "Cung cấp thông tin đa dạng hơn.",
          "C": "Giảm chi phí vận hành.",
          "D": "Cải thiện giao diện người dùng."
        },
        "answer": "B"
      }
    ]
  },
  "bigger-faster-transformers": {
    "title": "Bigger, Faster Transformers",
    "collection": "ml-research",
    "content": "Performance inlanguagetasksrises with the size of the model— yet, as a model’s parameter count rises, so does the time it takes to render output. New work pumps up the number of parameters without slowing down the network.What’s new:William Fedus, Barret Zoph, and Noam Shazeer at Google Brain developed theSwitch Transformer, a large-scale architecture (the authors built a version comprising 1.6trillionparameters) that’s nearly as fast as a much smaller model.Key insight:The approach known asmixture-of-expertsuses only a subset of a model’s parameters per input example. Like mixture-of-experts, Switch Transformer chooses which of many layers would best process a given input.How it works:The authors trained Switch Transformer to predict words that had been removed at random from alarge text datasetscraped from the web. The dataset was preprocessed to remove offensive language, placeholder text, and other issues.\n\nResults:The authors compared Switch Transformer (7.4 billion parameters) toT5(223 million parameters), a variant similar to the original transformer that was trained on the same dataset, using negative log perplexity, a measure of the model’s uncertainty (higher is better). The new model achieved -1.561 negative log perplexity compared to T5’s -1.731. Switch Transformer ran at two-thirds the speed of T5 — it executed 1,000 predictions per second compared to T5’s 1,600 — with 33 times the number of parameters. It beat a mixture-of-experts transformer, presumably of roughly the same size, on both counts.Why it matters:In deep learning, bigger is better — but so is a manageable computation budget.We’re thinking:Transformers come in an increasing variety of flavors. We hope this summary helps you remember which is switch.",
    "qa": [
      {
        "question": "Ai là tác giả chính của Switch Transformer được đề cập trong bài viết?",
        "options": {
          "A": "Ilya Sutskever, Geoffrey Hinton, và Yoshua Bengio",
          "B": "William Fedus, Barret Zoph, và Noam Shazeer",
          "C": "Jeff Dean, Sanjay Ghemawat, và Andrew Ng",
          "D": "Yann LeCun, Corinna Cortes, và Vladimir Vapnik"
        },
        "answer": "B"
      },
      {
        "question": "Switch Transformer là một kiến trúc mạng nơ-ron quy mô lớn với bao nhiêu tham số trong phiên bản được tác giả xây dựng?",
        "options": {
          "A": "223 triệu tham số",
          "B": "7.4 tỷ tham số",
          "C": "1.6 nghìn tỷ tham số",
          "D": "100 tỷ tham số"
        },
        "answer": "C"
      },
      {
        "question": "Nguyên tắc chính mà Switch Transformer sử dụng để tăng hiệu quả là gì?",
        "options": {
          "A": "Sử dụng tất cả các tham số của mô hình cho mỗi đầu vào.",
          "B": "Sử dụng một tập hợp con các tham số của mô hình cho mỗi đầu vào.",
          "C": "Tăng kích thước của dữ liệu huấn luyện.",
          "D": "Giảm số lượng lớp trong mạng nơ-ron."
        },
        "answer": "B"
      },
      {
        "question": "Switch Transformer được huấn luyện để làm gì?",
        "options": {
          "A": "Phân loại hình ảnh.",
          "B": "Dịch ngôn ngữ.",
          "C": "Dự đoán các từ bị xóa ngẫu nhiên từ một tập dữ liệu văn bản lớn.",
          "D": "Tạo ra văn bản mới từ đầu."
        },
        "answer": "C"
      },
      {
        "question": "Tập dữ liệu huấn luyện của Switch Transformer được xử lý trước như thế nào?",
        "options": {
          "A": "Chỉ giữ lại các câu có độ dài nhất định.",
          "B": "Loại bỏ ngôn ngữ xúc phạm, văn bản giữ chỗ và các vấn đề khác.",
          "C": "Tăng cường dữ liệu bằng cách thêm nhiễu.",
          "D": "Chuyển đổi tất cả văn bản thành chữ thường."
        },
        "answer": "B"
      },
      {
        "question": "Chỉ số nào được sử dụng để so sánh hiệu suất của Switch Transformer và T5?",
        "options": {
          "A": "Độ chính xác (Accuracy).",
          "B": "Độ phức tạp Log âm (Negative Log Perplexity).",
          "C": "Điểm F1 (F1 Score).",
          "D": "Thời gian huấn luyện (Training Time)."
        },
        "answer": "B"
      },
      {
        "question": "Giá trị Negative Log Perplexity của Switch Transformer (7.4 tỷ tham số) là bao nhiêu?",
        "options": {
          "A": "-1.731",
          "B": "-1.561",
          "C": "1,600",
          "D": "1,000"
        },
        "answer": "B"
      },
      {
        "question": "Tốc độ thực hiện dự đoán của T5 (223 triệu tham số) là bao nhiêu?",
        "options": {
          "A": "1,000 dự đoán mỗi giây",
          "B": "1,600 dự đoán mỗi giây",
          "C": "7.4 tỷ dự đoán mỗi giây",
          "D": "223 triệu dự đoán mỗi giây"
        },
        "answer": "B"
      },
      {
        "question": "So với T5, Switch Transformer chạy với tốc độ như thế nào?",
        "options": {
          "A": "Nhanh hơn gấp đôi.",
          "B": "Nhanh hơn một chút.",
          "C": "Chậm hơn khoảng một phần ba.",
          "D": "Chậm hơn đáng kể."
        },
        "answer": "C"
      },
      {
        "question": "Ý chính mà tác giả muốn nhấn mạnh về deep learning là gì?",
        "options": {
          "A": "Mô hình nhỏ hơn luôn tốt hơn.",
          "B": "Mô hình lớn hơn luôn tốt hơn, nhưng cần cân nhắc đến chi phí tính toán.",
          "C": "Dữ liệu huấn luyện quan trọng hơn kích thước mô hình.",
          "D": "Kiến trúc mạng nơ-ron không quan trọng bằng việc tối ưu hóa siêu tham số."
        },
        "answer": "B"
      }
    ]
  },
  "bigger-is-better": {
    "title": "Bigger is Better",
    "collection": "ml-research",
    "content": "Natural language processing lately has come to resemble an arms race, as the big AI companies build models that encompass ever larger numbers of parameters. Microsoft recently held the record — but not for long.What’s new:In February, Microsoft introducedTuring Natural Language Generation(Turing-NLG), a language model that comprises 17 billion parameters.Key insight:More parameters is better. More training data is better. And more compute is better. For the time being, these factors determine the state of the art in language processing.How it works:Like other recent large language models, Turing-NLG is based on the transformer architecture, which extracts features across long sequences of data without having to examine every element in between. Also like its immediate predecessors, it’s trained on unlabeled data via an unsupervised method, which enables it to absorb information from far more text than supervised models have available.\n\nResults:The researchers pitted Turing-NLG against Megatron. Turing-NLG improved state-of-the-art accuracy on theLambadalanguage understanding benchmark from 66.51 percent to 67.98 percent. It also improved perplexity (lower is better) on theWikiTextof verified Wikipedia articles from 10.81 to 10.21.Yes, but:The race to build bigger and better language models doesn’t leave any breathing room even for engineers at the biggest tech powerhouses. Less than four months after Microsoft announced Turing-NLG, OpenAI detailedGPT-3. At 175 billion parameters, it’s roughly 10 times bigger and achieved 76.2 percent accuracy on Lambada.Why it matters:As language models balloon, so do scores on NLP benchmarks. Keep your seatbelts on: Microsoft says its approach to allocating hardware resources can scale past 1 trillion parameters.We’re thinking: The recipe of adding parameters, data, and compute for better performance has a long history. That today’s language models ingest far more text than a human could read in a lifetime reveals both the power of brute-force training and the algorithms’ inefficiency at learning.",
    "qa": [
      {
        "question": "Mục tiêu chính của các công ty AI lớn trong lĩnh vực xử lý ngôn ngữ tự nhiên (NLP) hiện nay là gì?",
        "options": {
          "A": "Giảm số lượng tham số trong mô hình để tiết kiệm tài nguyên.",
          "B": "Xây dựng các mô hình với số lượng tham số ngày càng lớn.",
          "C": "Tập trung vào việc cải thiện hiệu quả của các thuật toán hiện có.",
          "D": "Phát triển các phương pháp học có giám sát hiệu quả hơn."
        },
        "answer": "B"
      },
      {
        "question": "Turing-NLG của Microsoft có bao nhiêu tham số?",
        "options": {
          "A": "175 tỷ",
          "B": "17 tỷ",
          "C": "1.7 tỷ",
          "D": "1.75 tỷ"
        },
        "answer": "B"
      },
      {
        "question": "Yếu tố nào KHÔNG được đề cập đến trong bài viết là yếu tố quyết định đến hiệu quả của mô hình ngôn ngữ?",
        "options": {
          "A": "Số lượng tham số",
          "B": "Số lượng dữ liệu huấn luyện",
          "C": "Khả năng tính toán",
          "D": "Kiến trúc mạng nơ-ron"
        },
        "answer": "D"
      },
      {
        "question": "Kiến trúc nào được sử dụng trong Turing-NLG và các mô hình ngôn ngữ lớn gần đây?",
        "options": {
          "A": "Mạng nơ-ron tích chập (CNN)",
          "B": "Mạng nơ-ron hồi quy (RNN)",
          "C": "Transformer",
          "D": "Mạng đối kháng sinh (GAN)"
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp học nào được sử dụng để huấn luyện Turing-NLG?",
        "options": {
          "A": "Học có giám sát",
          "B": "Học bán giám sát",
          "C": "Học tăng cường",
          "D": "Học không giám sát"
        },
        "answer": "D"
      },
      {
        "question": "Turing-NLG đã cải thiện độ chính xác trên benchmark Lambada lên bao nhiêu?",
        "options": {
          "A": "66.51% lên 67.98%",
          "B": "67.98% lên 76.2%",
          "C": "10.81% lên 10.21%",
          "D": "65.51% lên 66.98%"
        },
        "answer": "A"
      },
      {
        "question": "Mô hình nào đã vượt qua Turing-NLG chỉ sau chưa đầy bốn tháng?",
        "options": {
          "A": "Megatron",
          "B": "BERT",
          "C": "GPT-2",
          "D": "GPT-3"
        },
        "answer": "D"
      },
      {
        "question": "GPT-3 có bao nhiêu tham số?",
        "options": {
          "A": "17 tỷ",
          "B": "175 tỷ",
          "C": "1.7 tỷ",
          "D": "1.75 tỷ"
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề cập đến việc Microsoft có thể mở rộng quy mô tài nguyên phần cứng để hỗ trợ mô hình với bao nhiêu tham số?",
        "options": {
          "A": "175 tỷ tham số",
          "B": "17 tỷ tham số",
          "C": "1 nghìn tỷ tham số",
          "D": "100 tỷ tham số"
        },
        "answer": "C"
      },
      {
        "question": "Bài viết nhận xét gì về hiệu quả học tập của các mô hình ngôn ngữ hiện nay so với khả năng đọc hiểu của con người?",
        "options": {
          "A": "Các mô hình học hiệu quả hơn con người trong việc xử lý văn bản.",
          "B": "Các mô hình có thể đọc hiểu văn bản tốt hơn con người.",
          "C": "Các mô hình học hiệu quả hơn con người trong việc ghi nhớ thông tin.",
          "D": "Các mô hình sử dụng phương pháp 'ép buộc' (brute-force) và kém hiệu quả hơn con người trong việc học."
        },
        "answer": "D"
      }
    ]
  },
  "black-forest-labs-flux-1-outperforms-top-text-to-image-models": {
    "title": "Out of the Black Forest",
    "collection": "ml-research",
    "content": "A new company with deep roots in generative AI made an eye-catching debut.\n\nWhat’s new:Black Forest Labs, home to alumni of Stability AI,releasedthe Flux.1 family of text-to-image models under a variety of licenses including open options. The largest of them outperformed Stable Diffusion 3 Ultra, Midourney v6.0, and DALL·E 3 HD in the company’s internal qualitative tests.\n\nHow it works:The Flux.1 models are based on diffusion transformers that were trained usingflow matching, a form of diffusion. Like other latent diffusion models, given text and a noisy image embedding, they learn to remove the noise. At inference, given text and an embedding of pure noise, they remove the noise in successive steps and render an image using a decoder that was trained for the purpose.\n\nResults:Black Forest Labs evaluated the models internally in qualitative tests. Given images produced by one of the Flux.1 family and a competitor, roughly 800 people judged which they preferred for various qualities. The two larger versions achieved high scores.\n\nBehind the news:The Black Forest Labs staff includes former core members of Stability AI, whichlostmany top employees in April. Black Forest CEO Robin Rombach co-authored the papers that introduced VQGAN, latent diffusion, adversarial diffusion distillation, Stable Diffusion XL, and Stable Video Diffusion.\n\nWhy it matters:Text-to-image models generally occupy three tiers: large commercial models like Midjourney v6, OpenAI DALL·E 3, and Adobe Firefly; offerings that are open-source to varying degrees like Stability AI’s Stable Diffusion 3 Medium; and smaller models that can run locally like Stable Diffusion’s Stable Diffusion XL Lightning. The Flux.1 suite checks all the boxes with high marks in head-to-head comparisons.\n\nWe’re thinking:In late 2022, Stability AI’s release of the open Stable Diffusion unleashed a wave of innovation. We see a similar wave building on the open versions of Flux.1.",
    "qa": [
      {
        "question": "Công ty Black Forest Labs ra mắt sản phẩm Flux.1, lĩnh vực hoạt động chính của công ty này là gì?",
        "options": {
          "A": "Phát triển phần mềm quản lý doanh nghiệp.",
          "B": "Phát triển các mô hình AI tạo sinh, đặc biệt là chuyển văn bản thành hình ảnh.",
          "C": "Nghiên cứu và sản xuất phần cứng máy tính.",
          "D": "Cung cấp dịch vụ tư vấn tài chính và đầu tư."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, Flux.1 đã thể hiện như thế nào so với các mô hình chuyển văn bản thành hình ảnh khác trong các thử nghiệm nội bộ của Black Forest Labs?",
        "options": {
          "A": "Kém hơn đáng kể so với Stable Diffusion 3 Ultra, Midjourney v6.0 và DALL·E 3 HD.",
          "B": "Tương đương với Stable Diffusion 3 Ultra, Midjourney v6.0 và DALL·E 3 HD.",
          "C": "Vượt trội hơn Stable Diffusion 3 Ultra, Midjourney v6.0 và DALL·E 3 HD.",
          "D": "Chỉ vượt trội hơn một vài mô hình nhất định, nhưng không phải tất cả."
        },
        "answer": "C"
      },
      {
        "question": "Công nghệ cốt lõi nào được sử dụng trong các mô hình Flux.1 để chuyển văn bản thành hình ảnh?",
        "options": {
          "A": "Mạng nơ-ron tích chập (Convolutional Neural Networks).",
          "B": "Mô hình ngôn ngữ lớn (Large Language Models).",
          "C": "Diffusion transformers được huấn luyện bằng flow matching.",
          "D": "Mạng nơ-ron tái phát (Recurrent Neural Networks)."
        },
        "answer": "C"
      },
      {
        "question": "Trong quá trình tạo ảnh từ văn bản bằng Flux.1, vai trò của 'noise' (nhiễu) là gì?",
        "options": {
          "A": "Noise được sử dụng để tăng độ phân giải của hình ảnh cuối cùng.",
          "B": "Noise được thêm vào để làm cho hình ảnh trở nên nghệ thuật hơn.",
          "C": "Noise được loại bỏ dần trong các bước liên tiếp để tạo ra hình ảnh từ văn bản.",
          "D": "Noise được sử dụng để mã hóa thông tin văn bản vào hình ảnh."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến việc khoảng bao nhiêu người đã tham gia đánh giá chất lượng hình ảnh do Flux.1 và các đối thủ tạo ra?",
        "options": {
          "A": "Khoảng 100 người.",
          "B": "Khoảng 500 người.",
          "C": "Khoảng 800 người.",
          "D": "Khoảng 1000 người."
        },
        "answer": "C"
      },
      {
        "question": "CEO của Black Forest Labs, Robin Rombach, được biết đến với vai trò gì trước khi thành lập công ty này?",
        "options": {
          "A": "Là nhà đầu tư mạo hiểm chuyên về lĩnh vực AI.",
          "B": "Là một trong những thành viên chủ chốt của Stability AI.",
          "C": "Là giáo sư đại học chuyên nghiên cứu về xử lý ngôn ngữ tự nhiên.",
          "D": "Là kỹ sư phần mềm tại Google Brain."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, những mô hình nào thường chiếm vị trí hàng đầu trong lĩnh vực chuyển văn bản thành hình ảnh?",
        "options": {
          "A": "Các mô hình mã nguồn mở nhỏ gọn, dễ dàng chạy trên thiết bị cá nhân.",
          "B": "Các mô hình thương mại lớn như Midjourney v6, OpenAI DALL·E 3 và Adobe Firefly.",
          "C": "Các mô hình được phát triển bởi các trường đại học và viện nghiên cứu.",
          "D": "Các mô hình chuyên dụng cho một lĩnh vực cụ thể, ví dụ như y học hoặc kiến trúc."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhận định gì về tiềm năng của các phiên bản mã nguồn mở của Flux.1?",
        "options": {
          "A": "Chúng sẽ không tạo ra sự khác biệt lớn so với các mô hình hiện có.",
          "B": "Chúng có thể khơi dậy một làn sóng đổi mới tương tự như Stable Diffusion đã từng làm.",
          "C": "Chúng chỉ phù hợp cho mục đích thử nghiệm và nghiên cứu.",
          "D": "Chúng sẽ nhanh chóng bị các mô hình thương mại vượt mặt."
        },
        "answer": "B"
      },
      {
        "question": "Stable Diffusion XL Lightning thuộc loại mô hình chuyển văn bản thành hình ảnh nào?",
        "options": {
          "A": "Mô hình thương mại lớn.",
          "B": "Mô hình mã nguồn mở hoàn toàn.",
          "C": "Mô hình nhỏ có thể chạy cục bộ.",
          "D": "Mô hình dựa trên điện toán đám mây."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì đã xảy ra với Stability AI vào tháng 4 mà có liên quan đến sự ra đời của Black Forest Labs?",
        "options": {
          "A": "Stability AI đã được mua lại bởi một tập đoàn lớn.",
          "B": "Stability AI đã mất nhiều nhân viên chủ chốt.",
          "C": "Stability AI đã tuyên bố phá sản.",
          "D": "Stability AI đã chuyển trụ sở chính sang một quốc gia khác."
        },
        "answer": "B"
      }
    ]
  },
  "build-once-run-anywhere": {
    "title": "Build Once, Run Anywhere",
    "collection": "ml-research",
    "content": "From server to smartphone, devices with less processing speed and memory require smaller networks. Instead of building and training separate models to run on a variety of hardware, a new approach trains a single network that can be adapted to any device.What’s new:Han Cai and researchers at MIT developedOnce-for-All(OFA). This method trains a single large model and derives subnetworks — subsets of the original model’s weights — that perform well on less powerful processors.Key insight:Typical pruning methods downsize neural networks one at a time by reducing, say, the size and number of convolutional filters and then fine-tuning the smaller model. It’s more efficient to extract and fine-tune a fleet of progressively smaller models in a single process.How it works:OFA extracts subnetworks by varying the parent network’s number of layers, number of filters per layer, filter sizes, and the input resolution. The researchers constrained each of these factors to a predetermined set of values that allow up to 1019 possible subnetworks.\n\nResults:The authors compared OFA with a variety of neural architecture search methods suitable for finding models for mobile devices. The popular NASNet-A required 48,000 hours to generate the smallest model, and it would require that time again to generate another one optimized for different constraints. OFA’s baseline model required 1,200 hours to find all models. They also compared OFA toMobileNetV3-Large, the state-of-the-art image recognition network for mobile devices. The OFA model that ran on similar hardware achieved 76.9 percent top-one accuracy onImageNetcompared to MobileNetV3’s 75.2 percent. The most accurate neural search method the researchers considered,FBNet-C, required roughly half as much time as OFA to generate a single, less accurate model, but much more time to generate the second.Why it matters:OFA produces equivalent models of many sizes in slightly more time than it takes to train the original large models. In situations that require deploying a given network to heterogeneous devices, this efficiency can translate into big savings in development time and energy consumption.We’re thinking:Smart speakers, watches, thermostats, pacemakers — it’s inevitable that neural networks will run on more and more heterogenous hardware. This work is an early step toward tools to manage such diverse deployments.",
    "qa": [
      {
        "question": "Phương pháp OFA (Once-for-All) được phát triển bởi ai?",
        "options": {
          "A": "Google AI",
          "B": "Han Cai và các nhà nghiên cứu tại MIT",
          "C": "Facebook AI Research",
          "D": "Microsoft Research"
        },
        "answer": "B"
      },
      {
        "question": "Điểm mới của phương pháp OFA so với các phương pháp truyền thống là gì?",
        "options": {
          "A": "Xây dựng và huấn luyện các mô hình riêng biệt cho từng loại phần cứng.",
          "B": "Huấn luyện một mạng duy nhất có thể được điều chỉnh cho nhiều thiết bị khác nhau.",
          "C": "Sử dụng các thuật toán nén mô hình phức tạp hơn.",
          "D": "Tăng kích thước của mạng nơ-ron để đạt được độ chính xác cao hơn."
        },
        "answer": "B"
      },
      {
        "question": "OFA trích xuất các mạng con (subnetworks) bằng cách thay đổi yếu tố nào của mạng gốc?",
        "options": {
          "A": "Số lượng lớp, số lượng bộ lọc trên mỗi lớp, kích thước bộ lọc và độ phân giải đầu vào.",
          "B": "Chỉ số lượng lớp và số lượng bộ lọc trên mỗi lớp.",
          "C": "Chỉ kích thước bộ lọc và độ phân giải đầu vào.",
          "D": "Chỉ trọng số của các kết nối nơ-ron."
        },
        "answer": "A"
      },
      {
        "question": "Ưu điểm chính của OFA so với NASNet-A là gì?",
        "options": {
          "A": "OFA tạo ra mô hình nhỏ nhất nhanh hơn NASNet-A.",
          "B": "OFA tạo ra nhiều mô hình khác nhau trong thời gian ngắn hơn so với việc NASNet-A tạo ra từng mô hình riêng lẻ.",
          "C": "OFA có độ chính xác cao hơn NASNet-A trên ImageNet.",
          "D": "OFA dễ dàng triển khai hơn NASNet-A."
        },
        "answer": "B"
      },
      {
        "question": "So với MobileNetV3-Large, mô hình OFA chạy trên phần cứng tương tự đạt được kết quả như thế nào trên ImageNet?",
        "options": {
          "A": "Độ chính xác thấp hơn đáng kể.",
          "B": "Độ chính xác tương đương.",
          "C": "Độ chính xác cao hơn một chút.",
          "D": "Độ chính xác cao hơn đáng kể."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, FBNet-C cần bao nhiêu thời gian để tạo ra một mô hình so với OFA?",
        "options": {
          "A": "Gấp đôi thời gian.",
          "B": "Thời gian tương đương.",
          "C": "Ít hơn khoảng một nửa thời gian.",
          "D": "Nhiều hơn đáng kể."
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích quan trọng nhất của OFA trong các tình huống triển khai mạng trên các thiết bị không đồng nhất là gì?",
        "options": {
          "A": "Tiết kiệm chi phí phần cứng.",
          "B": "Tiết kiệm thời gian phát triển và năng lượng tiêu thụ.",
          "C": "Tăng cường bảo mật dữ liệu.",
          "D": "Đơn giản hóa quá trình gỡ lỗi."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết dự đoán rằng mạng nơ-ron sẽ được sử dụng rộng rãi trên loại thiết bị nào trong tương lai?",
        "options": {
          "A": "Chỉ trên điện thoại thông minh và máy tính bảng.",
          "B": "Chỉ trên máy chủ và trung tâm dữ liệu.",
          "C": "Trên nhiều loại phần cứng không đồng nhất, bao gồm loa thông minh, đồng hồ, máy điều nhiệt và máy tạo nhịp tim.",
          "D": "Chỉ trên các thiết bị y tế chuyên dụng."
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp tỉa thưa (pruning) mạng nơ-ron truyền thống hoạt động như thế nào?",
        "options": {
          "A": "Tạo ra nhiều bản sao của mạng và chọn bản tốt nhất.",
          "B": "Giảm kích thước và số lượng bộ lọc tích chập, sau đó tinh chỉnh mô hình nhỏ hơn.",
          "C": "Tăng số lượng lớp trong mạng.",
          "D": "Thay đổi hàm kích hoạt của các nơ-ron."
        },
        "answer": "B"
      },
      {
        "question": "Số lượng mạng con (subnetworks) có thể có mà OFA tạo ra là bao nhiêu?",
        "options": {
          "A": "100",
          "B": "1,000",
          "C": "1,000,000",
          "D": "Lên đến 10^19"
        },
        "answer": "D"
      }
    ]
  },
  "cats-cured-of-covid": {
    "title": "Cats Cured of Covid",
    "collection": "ml-research",
    "content": "Neural networks are famously bad at interpreting input that falls outside the training set’s distribution, so it’s not surprising that some models are certain that cat pictures show symptoms of Covid-19. A new approach won’t mistakenly condemn your feline to a quarantine.What’s new:Led by Ankur Mallick, researchers at Carnegie Mellon and Lawrence Livermore National Lab developedProbabilistic Neighborhood Components Analysis(PNCA) to help models estimate the confidence of their predictions.Key insight:Neural networks often show high confidence in predictions that are clearly incorrect — a major issue in areas like healthcare and criminal justice. The problem can fade with enough training data, but it’s pervasive where training data is scarce. Overfitting limited data contributes to overconfidence, so combining deep learning with probabilistic methods, which are less prone to overfitting, might alleviate overconfidence.How it works:PNCA is a probabilistic version ofNeighborhood Component Analysis. NCA is a supervised learning method that trains neural nets to extract features that cluster examples of the same class. NCA determines the class of novel input by computing the distance between training data features and input features. It takes the softmax of the distances to obtain the probability that each training example belongs to the same class of the novel input. Practically speaking, NCA is a classification network with fixed output layer weights, but not size, given by the distance function.\n\nResults:The researchers trained PNCA on aKaggle datasetof chest x-rays showing Covid-19, and tested it onCovid-V2and aCats and Dogs dataset. PNCA performed with similar accuracy to other deep learning approaches on Covid-V2, while incorrectly classifying 1,000 cats and dogs out of 25,000 as Covid-19 with high confidence. This may seem like poor performance, but the same architecture with a standard supervised learning objective mistook around 2500 cats and dogs as Covid-19 chest x-rays.Why it matters:Deep learning’s overconfidence and data hunger are limitations to their practical deployment. PNCA combines deep learning’s powerful feature extraction with a probabilistic ability to quantify uncertainty.We’re thinking:We’re waiting for a model that can tell us the condition of Schroedinger’s cat.",
    "qa": [
      {
        "question": "Vấn đề chính mà các mạng neural gặp phải khi xử lý dữ liệu nằm ngoài phân phối của tập huấn luyện là gì?",
        "options": {
          "A": "Khả năng xử lý dữ liệu chậm chạp.",
          "B": "Độ tin cậy cao vào các dự đoán sai lệch.",
          "C": "Yêu cầu phần cứng quá cao.",
          "D": "Khó khăn trong việc trích xuất đặc trưng."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp PNCA (Probabilistic Neighborhood Components Analysis) được phát triển bởi ai?",
        "options": {
          "A": "Một nhóm nghiên cứu độc lập tại Google.",
          "B": "Ankur Mallick và các nhà nghiên cứu tại Carnegie Mellon và Lawrence Livermore National Lab.",
          "C": "Một nhóm các nhà khoa học tại Đại học Stanford.",
          "D": "Các kỹ sư tại Microsoft Research."
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm chính của việc kết hợp deep learning với các phương pháp xác suất như PNCA là gì?",
        "options": {
          "A": "Giảm thiểu nhu cầu về dữ liệu huấn luyện.",
          "B": "Tăng tốc độ huấn luyện mô hình.",
          "C": "Giảm thiểu tình trạng overfitting và tăng độ tin cậy của dự đoán.",
          "D": "Cải thiện khả năng trích xuất đặc trưng từ dữ liệu."
        },
        "answer": "C"
      },
      {
        "question": "NCA (Neighborhood Component Analysis) hoạt động như thế nào trong quá trình phân loại dữ liệu mới?",
        "options": {
          "A": "Bằng cách so sánh trực tiếp dữ liệu mới với dữ liệu huấn luyện gốc.",
          "B": "Bằng cách tính toán khoảng cách giữa các đặc trưng của dữ liệu huấn luyện và dữ liệu mới.",
          "C": "Bằng cách sử dụng một mạng neural riêng biệt để phân loại dữ liệu mới.",
          "D": "Bằng cách áp dụng các quy tắc logic được xác định trước."
        },
        "answer": "B"
      },
      {
        "question": "Trong PNCA, lớp đầu ra của mạng phân loại có đặc điểm gì?",
        "options": {
          "A": "Trọng số và kích thước được huấn luyện cùng với các lớp khác.",
          "B": "Trọng số cố định dựa trên hàm khoảng cách, nhưng kích thước có thể thay đổi.",
          "C": "Trọng số và kích thước cố định, được xác định trước khi huấn luyện.",
          "D": "Trọng số thay đổi ngẫu nhiên trong quá trình huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu nào được sử dụng để huấn luyện và kiểm tra mô hình PNCA trong nghiên cứu này?",
        "options": {
          "A": "Chỉ dữ liệu X-quang ngực của bệnh nhân Covid-19.",
          "B": "Dữ liệu X-quang ngực của bệnh nhân Covid-19 và dữ liệu hình ảnh mèo và chó.",
          "C": "Dữ liệu hình ảnh mèo và chó được gán nhãn là Covid-19.",
          "D": "Dữ liệu tổng hợp được tạo ra bằng các thuật toán AI."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả thử nghiệm cho thấy PNCA cải thiện điều gì so với các phương pháp deep learning tiêu chuẩn?",
        "options": {
          "A": "Độ chính xác cao hơn trong việc phân loại hình ảnh Covid-19.",
          "B": "Khả năng giảm số lượng hình ảnh mèo và chó bị phân loại sai thành Covid-19.",
          "C": "Tốc độ xử lý nhanh hơn đáng kể.",
          "D": "Khả năng hoạt động tốt hơn trên các thiết bị có tài nguyên hạn chế."
        },
        "answer": "B"
      },
      {
        "question": "Hạn chế chính của deep learning mà PNCA cố gắng giải quyết là gì?",
        "options": {
          "A": "Khả năng xử lý ngôn ngữ tự nhiên kém.",
          "B": "Sự phụ thuộc lớn vào dữ liệu huấn luyện và xu hướng quá tự tin vào các dự đoán.",
          "C": "Khó khăn trong việc tích hợp với các hệ thống hiện có.",
          "D": "Chi phí triển khai và bảo trì cao."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu cuối cùng của việc phát triển các mô hình như PNCA là gì?",
        "options": {
          "A": "Thay thế hoàn toàn các phương pháp deep learning truyền thống.",
          "B": "Cung cấp khả năng định lượng sự không chắc chắn trong các dự đoán của deep learning.",
          "C": "Tự động hóa hoàn toàn quá trình chẩn đoán bệnh.",
          "D": "Tạo ra các mô hình có khả năng suy nghĩ và cảm nhận như con người."
        },
        "answer": "B"
      },
      {
        "question": "Câu 'We’re waiting for a model that can tell us the condition of Schroedinger’s cat' ám chỉ điều gì?",
        "options": {
          "A": "Sự cần thiết của các mô hình có thể dự đoán tương lai.",
          "B": "Sự mong muốn về một mô hình có thể giải quyết các vấn đề phức tạp và không chắc chắn.",
          "C": "Sự phát triển của các mô hình có khả năng hiểu biết về vật lý lượng tử.",
          "D": "Sự hài hước và mong đợi về những đột phá trong lĩnh vực AI."
        },
        "answer": "B"
      }
    ]
  },
  "children-and-people-with-darker-skin-face-higher-street-risks-with-object-detectors-research-finds": {
    "title": "Seeing Darker-Skinned Pedestrians",
    "collection": "ml-research",
    "content": "In a study, models used to detect people walking on streets and sidewalks performed less well on adults with darker skin and children of all skin tones.\n\nWhat’s new:Xinyui Li, Zhenpeng Chen, and colleagues at Peking University, University College London, and King’s College Londonevaluatedeight widely used object detectors for bias with respect to skin color, age, and gender.\n\nKey insight:When it comes to detecting pedestrians, biases with respect to demographic characteristics can be a life-and-death matter. Evaluating them requires a dataset of pedestrians labeled according to characteristics that might influence detection. Skin color, age, and gender are important human differences that can affect a vision model’s performance, especially depending on lighting conditions.\n\nHow it works:The authors collected over 8,000 photos from fourdatasetsofstreetscenes. They annotated each image with labels for skin tone (light or dark), age group (child or adult), and gender (male or female). They tested four general-purpose object detectors:YOLOX,RetinaNet,Faster R-CNN, andCascade R-CNN— and four pedestrian-specific detectors —ALFNet,CSP,MGAN, andPRNet— on their dataset. They evaluated performance between perceived skin tone, age, and gender groups and under different conditions of brightness, contrast, and weather.\n\nResults:The study revealed significant fairness issues related to skin tone and age.\n\nBehind the news:Previousworkhas shown that computer vision models can harbor biases that make them less likely to recognize individuals of certain types. In 2019, MITshowedthat commercial face recognition performed worse on women and darker skinned individuals. Aplethoraofworkevaluatesbias in datasets typically used to train vision models.\n\nWhy it matters:As more road vehicles gain self-driving capabilities and as expanded robotaxi services come to major cities, a growing number of pedestrians’ lives are in the hands of computer vision algorithms. Auto makers don’t disclose what pedestrian detection systems they use or the number of real-world accidents involving self-driving cars. But co-author Jie Zhangclaimsthat the proprietary systems used in self-driving cars are “usually built upon the existing open-source models,” and “we can be certain that their models must also have similar issues.”\n\nWe’re thinking:Computer vision isn’t the only technology used by self-driving cars to detect objects. Most self-driving car manufacturers rely on lidar and radar in addition to cameras. Those technologies are blind to color and gender differences and, in the view of many engineers, make better choices for this application.",
    "qa": [
      {
        "question": "Nghiên cứu đã chỉ ra điều gì về hiệu suất của các mô hình phát hiện người đi bộ?",
        "options": {
          "A": "Hiệu suất tốt hơn trên trẻ em có làn da sáng.",
          "B": "Hiệu suất kém hơn trên người lớn có làn da tối màu và trẻ em ở mọi tông da.",
          "C": "Hiệu suất tương đương trên tất cả các nhóm tuổi và tông da.",
          "D": "Hiệu suất tốt hơn trên người lớn có làn da tối màu."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đến từ những trường đại học nào đã thực hiện nghiên cứu này?",
        "options": {
          "A": "Đại học Bắc Kinh, Đại học Oxford và Đại học Cambridge.",
          "B": "Đại học Bắc Kinh, Đại học College London và King's College London.",
          "C": "Đại học Harvard, MIT và Stanford.",
          "D": "Đại học Bắc Kinh, Đại học Tokyo và Đại học Seoul."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu này đánh giá những yếu tố nào có thể gây ra sự thiên vị trong việc phát hiện người đi bộ?",
        "options": {
          "A": "Chiều cao, cân nặng và chủng tộc.",
          "B": "Tông da, tuổi tác và giới tính.",
          "C": "Quần áo, kiểu tóc và phụ kiện.",
          "D": "Địa điểm, thời gian và thời tiết."
        },
        "answer": "B"
      },
      {
        "question": "Các tác giả đã thu thập dữ liệu từ bao nhiêu bộ dữ liệu cảnh đường phố?",
        "options": {
          "A": "2",
          "B": "4",
          "C": "6",
          "D": "8"
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu đã tiết lộ những vấn đề công bằng đáng kể liên quan đến yếu tố nào?",
        "options": {
          "A": "Giới tính và chiều cao.",
          "B": "Tông da và tuổi tác.",
          "C": "Chủng tộc và quốc tịch.",
          "D": "Nghề nghiệp và thu nhập."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu năm 2019 của MIT đã chỉ ra điều gì về nhận diện khuôn mặt thương mại?",
        "options": {
          "A": "Hiệu suất tốt hơn trên nam giới và người da trắng.",
          "B": "Hiệu suất kém hơn trên phụ nữ và người da trắng.",
          "C": "Hiệu suất tốt hơn trên phụ nữ và người da tối màu.",
          "D": "Hiệu suất kém hơn trên phụ nữ và người da tối màu."
        },
        "answer": "D"
      },
      {
        "question": "Theo Jie Zhang, hệ thống phát hiện người đi bộ trong xe tự lái thường được xây dựng dựa trên điều gì?",
        "options": {
          "A": "Các mô hình độc quyền được phát triển nội bộ.",
          "B": "Các mô hình mã nguồn mở hiện có.",
          "C": "Sự kết hợp giữa mô hình độc quyền và mã nguồn mở.",
          "D": "Các mô hình được cung cấp bởi chính phủ."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài camera, công nghệ nào khác thường được sử dụng trong xe tự lái để phát hiện vật thể?",
        "options": {
          "A": "Hồng ngoại và sóng âm.",
          "B": "Lidar và radar.",
          "C": "GPS và cảm biến nhiệt.",
          "D": "Bluetooth và Wi-Fi."
        },
        "answer": "B"
      },
      {
        "question": "Theo nhiều kỹ sư, công nghệ nào được cho là lựa chọn tốt hơn cho việc phát hiện vật thể trong xe tự lái vì không bị ảnh hưởng bởi màu da và giới tính?",
        "options": {
          "A": "Camera hồng ngoại.",
          "B": "Lidar và radar.",
          "C": "Camera độ phân giải cao.",
          "D": "Cảm biến siêu âm."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc đánh giá các mô hình phát hiện người đi bộ theo các đặc điểm nhân khẩu học là gì?",
        "options": {
          "A": "Để cải thiện tốc độ xử lý của mô hình.",
          "B": "Để đảm bảo tính công bằng và tránh những hậu quả nghiêm trọng liên quan đến an toàn.",
          "C": "Để giảm chi phí phát triển mô hình.",
          "D": "Để tăng cường khả năng nhận diện khuôn mặt."
        },
        "answer": "B"
      }
    ]
  },
  "choose-the-right-annotators": {
    "title": "Choose the Right Annotators",
    "collection": "ml-research",
    "content": "Classification isn’t always cut and dried. While the majority of doctors are men and nurses women, that doesn't mean all men who wear scrubs are doctors or all women who wear scrubs are nurses. A new method attempts to account for biases that may be held by certain subsets of labelers.What's new:Mitchell L. Gordon and colleagues at Stanford introduced a method to control bias in machine learning model outputs. Theirjury learningapproach models a user-selected subset of the annotators who labeled the training data.Key insight:A typical classifier mimics how an average labeler would annotate a given example. Such output inevitably reflects biases typically associated with an annotator’s age, gender, religion, and so on, and if the distribution of such demographic characteristics among labelers is skewed, the model’s output will be skewed as well. How to correct for such biases? Instead of predicting the average label, a classifier can predict the label likely to be applied by each individual in a pool of labelers whose demographic characteristics are known. Users can choose labelers who have the characteristics they desire, and the model can emulate them and assign a label accordingly. This would enable users to correct for biases (or select for them).How it works:The authors used jury learning to train a classifier to mimic the ways different annotators label the toxicity of social media comments. Thedatasetcomprised comments from Twitter, Reddit, and 4Chan.\n\nResults:The authors evaluated their model’s ability to predict labels assigned by individual annotators. It achieved 0.61 mean average error, while a BERTweet fine-tuned on the dataset achieved 0.9 mean average error (lower is better). The authors’ model achieved fairly consistent error rates when estimating how annotators of different races would label examples: Asian (0.62), Black (0.65), Hispanic (0.57), White (0.60). In contrast, BERTweet’s error rate varied widely with respect to Black annotators: Asian (0.83), Black (1.12), Hispanic (0.87), White (0.87). The authors’ model, which focused on estimating labels assigned by individuals, also outperformed a similar model that was trained to predict decisions by demographic groups, which scored 0.81 mean average error.Why it matters:Users of AI systems may assume that data labels are objectively true. In fact, they’re often messy approximations, and they can be influenced by the circumstances and experiences of individual annotators. The jury method gives users a way to account for this inherent subjectivity.We're thinking:Selecting a good demographic mix of labelers can reduce some biases and ensure that diverse viewpoints are represented in the resulting labels — but it doesn’t reduce biases that are pervasive across demographic groups. That problem requires a different approach.",
    "qa": [
      {
        "question": "Phương pháp 'jury learning' của Mitchell L. Gordon và cộng sự tại Stanford tập trung vào điều gì?",
        "options": {
          "A": "Loại bỏ hoàn toàn các yếu tố gây nhiễu trong dữ liệu huấn luyện.",
          "B": "Kiểm soát sự thiên vị trong kết quả đầu ra của mô hình học máy.",
          "C": "Tăng tốc độ xử lý dữ liệu của các mô hình học máy.",
          "D": "Tự động lựa chọn các annotator (người gán nhãn) có trình độ cao."
        },
        "answer": "B"
      },
      {
        "question": "Nhược điểm của một bộ phân loại (classifier) điển hình là gì, theo bài viết?",
        "options": {
          "A": "Không thể xử lý dữ liệu có kích thước lớn.",
          "B": "Phản ánh sự thiên vị liên quan đến đặc điểm nhân khẩu học của người gán nhãn.",
          "C": "Yêu cầu phần cứng mạnh mẽ để hoạt động hiệu quả.",
          "D": "Dễ bị tấn công bởi các thuật toán đối nghịch (adversarial attacks)."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp 'jury learning' khắc phục sự thiên vị bằng cách nào?",
        "options": {
          "A": "Bằng cách loại bỏ hoàn toàn dữ liệu được gán nhãn bởi những người có đặc điểm nhân khẩu học không mong muốn.",
          "B": "Bằng cách dự đoán nhãn có khả năng được gán bởi từng cá nhân trong một nhóm người gán nhãn có đặc điểm nhân khẩu học đã biết.",
          "C": "Bằng cách sử dụng một thuật toán phức tạp hơn để phân tích dữ liệu.",
          "D": "Bằng cách yêu cầu nhiều người gán nhãn cho cùng một dữ liệu và lấy trung bình kết quả."
        },
        "answer": "B"
      },
      {
        "question": "Trong thử nghiệm được đề cập, phương pháp 'jury learning' được sử dụng để làm gì?",
        "options": {
          "A": "Phân loại hình ảnh mèo và chó.",
          "B": "Dự đoán giá cổ phiếu.",
          "C": "Phân tích mức độ độc hại của các bình luận trên mạng xã hội.",
          "D": "Dịch văn bản từ tiếng Anh sang tiếng Pháp."
        },
        "answer": "C"
      },
      {
        "question": "Kết quả thử nghiệm cho thấy điều gì về hiệu suất của 'jury learning' so với BERTweet?",
        "options": {
          "A": "'Jury learning' có hiệu suất kém hơn BERTweet trong mọi trường hợp.",
          "B": "'Jury learning' có hiệu suất tốt hơn BERTweet trong việc dự đoán nhãn được gán bởi các cá nhân khác nhau.",
          "C": "BERTweet có hiệu suất ổn định hơn 'jury learning' khi đánh giá các annotator thuộc các chủng tộc khác nhau.",
          "D": "Cả hai mô hình đều có hiệu suất tương đương."
        },
        "answer": "B"
      },
      {
        "question": "Chỉ số 'mean average error' (MAE) được sử dụng trong bài viết để đánh giá điều gì?",
        "options": {
          "A": "Tốc độ xử lý dữ liệu của mô hình.",
          "B": "Mức độ chính xác của mô hình trong việc dự đoán nhãn.",
          "C": "Mức độ thiên vị của mô hình đối với các nhóm nhân khẩu học khác nhau.",
          "D": "Khả năng của mô hình trong việc xử lý dữ liệu nhiễu."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao kết quả của mô hình 'jury learning' lại quan trọng?",
        "options": {
          "A": "Nó cho thấy rằng nhãn dữ liệu luôn là sự thật khách quan.",
          "B": "Nó cho thấy rằng nhãn dữ liệu có thể bị ảnh hưởng bởi hoàn cảnh và kinh nghiệm của người gán nhãn.",
          "C": "Nó chứng minh rằng tất cả các mô hình học máy đều hoàn hảo.",
          "D": "Nó cho thấy rằng việc gán nhãn dữ liệu nên được tự động hóa hoàn toàn."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, vấn đề nào mà việc lựa chọn một nhóm người gán nhãn đa dạng về nhân khẩu học không thể giải quyết được?",
        "options": {
          "A": "Sự thiên vị tồn tại phổ biến giữa các nhóm nhân khẩu học.",
          "B": "Sự thiếu hụt người gán nhãn có trình độ cao.",
          "C": "Chi phí cao của việc thuê nhiều người gán nhãn.",
          "D": "Sự khó khăn trong việc xác định đặc điểm nhân khẩu học của người gán nhãn."
        },
        "answer": "A"
      },
      {
        "question": "Mục đích chính của việc sử dụng phương pháp 'jury learning' là gì?",
        "options": {
          "A": "Để tạo ra các mô hình học máy hoàn toàn khách quan.",
          "B": "Để cho phép người dùng điều chỉnh và kiểm soát sự thiên vị trong mô hình học máy.",
          "C": "Để giảm chi phí gán nhãn dữ liệu.",
          "D": "Để tăng tốc độ huấn luyện mô hình học máy."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu được sử dụng để huấn luyện mô hình 'jury learning' trong bài viết đến từ đâu?",
        "options": {
          "A": "Sách và báo.",
          "B": "Các bài đăng trên Twitter, Reddit và 4Chan.",
          "C": "Dữ liệu y tế từ bệnh viện.",
          "D": "Dữ liệu tài chính từ thị trường chứng khoán."
        },
        "answer": "B"
      }
    ]
  },
  "choosing-words-carefully": {
    "title": "Choosing Words Carefully",
    "collection": "ml-research",
    "content": "The words “big” and “large” have similar meanings, but they aren’t always interchangeable: You wouldn’t refer to an older, male sibling as your “large brother” (unless you meant to be cheeky). Choosing among words with similar meanings is critical in language tasks like translation.What’s new:Google used a top language model to developBLEURT, a way to compare translation models.Background:Machine learning engineers typically evaluate a translation model’s ability to choose the right words by translating a sentence from one language to another and back again. The metric calledBLEUquantifies how far the re-translation’s meaning has drifted from that of the original sentence. But BLEU, which scores similarity on a 0-to-1 scale using an n-gram method, often misses nuances. BLEURT does a better job by training a language model to predict the semantic similarity between different sequences of words.Key insight:BERTis a general-purpose, unsupervised language model at the heart of many state-of-the-art systems. Fine-tuned on sentences that humans judge to be similar, it should learn to agree with human notions of similarity.How it works:BLEURT uses BERT to extract feature vectors from an original sentence and its re-translation. A linear layer predicts their similarity.\n\nResults:The authors drew sentences from each of several datasets and created variations on them. BLEURT and BLEU ranked the similarity between each variation and the original, and the authors compared the Kendall Tau correlation, the percentage of pairs assigned the same order minus the percentage of pairs ordered differently, with the human ranking (which is given a score of 1.0). BLEURT achieved a Kendall Tau correlation of 0.338 while BLEU achieved 0.227 — a nice bump, although it leaves plenty of room for improvement.Why it matters:Language modelshave improved by leaps and bounds in recent years, but they still stumble over context. Better word choices could improve not only automatic translation but the gamut of language tasks including chat, text summarization, sentiment analysis, question answering, and text classification.We’re thinking:BLEUstands for Bilingual Evaluation Understudy. BERT stands for Bidirectional Encoder Representations from Transformers. Does anyone know what BLEURT stands for?",
    "qa": [
      {
        "question": "Trong ngữ cảnh của bài viết, điểm khác biệt chính giữa 'big' và 'large' là gì?",
        "options": {
          "A": "Chúng có nghĩa hoàn toàn khác nhau.",
          "B": "Chúng có nghĩa tương tự nhưng không phải lúc nào cũng có thể thay thế cho nhau.",
          "C": "'Big' chỉ dùng cho vật thể, còn 'large' chỉ dùng cho người.",
          "D": "'Large' là từ trang trọng hơn 'big'."
        },
        "answer": "B"
      },
      {
        "question": "BLEURT được phát triển với mục đích chính là gì?",
        "options": {
          "A": "Thay thế hoàn toàn mô hình BLEU.",
          "B": "Cải thiện khả năng đánh giá các mô hình dịch thuật.",
          "C": "Tự động dịch văn bản từ ngôn ngữ này sang ngôn ngữ khác.",
          "D": "Phân tích cảm xúc trong văn bản."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp đánh giá truyền thống BLEU hoạt động như thế nào?",
        "options": {
          "A": "Đánh giá dựa trên sự tương đồng ngữ nghĩa giữa các câu.",
          "B": "Đánh giá dựa trên sự tương đồng về mặt hình thức (n-gram) giữa câu gốc và câu dịch ngược.",
          "C": "Đánh giá dựa trên ý kiến của con người về chất lượng bản dịch.",
          "D": "Đánh giá dựa trên khả năng của mô hình trong việc trả lời câu hỏi."
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm chính của BLEURT so với BLEU là gì?",
        "options": {
          "A": "BLEURT nhanh hơn và dễ sử dụng hơn.",
          "B": "BLEURT đánh giá tốt hơn các sắc thái ngữ nghĩa.",
          "C": "BLEURT có thể xử lý nhiều ngôn ngữ hơn.",
          "D": "BLEURT không cần dữ liệu huấn luyện."
        },
        "answer": "B"
      },
      {
        "question": "BLEURT sử dụng mô hình ngôn ngữ nào làm nền tảng?",
        "options": {
          "A": "RNN",
          "B": "CNN",
          "C": "BERT",
          "D": "LSTM"
        },
        "answer": "C"
      },
      {
        "question": "BLEURT được huấn luyện bằng cách nào?",
        "options": {
          "A": "Huấn luyện trên dữ liệu dịch thuật song ngữ.",
          "B": "Tinh chỉnh BERT trên các câu được con người đánh giá là tương đồng.",
          "C": "Huấn luyện để dự đoán từ tiếp theo trong một câu.",
          "D": "Huấn luyện để phân loại các câu theo chủ đề."
        },
        "answer": "B"
      },
      {
        "question": "Trong bài viết, Kendall Tau correlation được sử dụng để làm gì?",
        "options": {
          "A": "Đo tốc độ dịch thuật của các mô hình.",
          "B": "Đo mức độ tương quan giữa kết quả đánh giá của mô hình và đánh giá của con người.",
          "C": "Đo độ chính xác của mô hình trong việc phân loại văn bản.",
          "D": "Đo mức độ sử dụng tài nguyên của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả thực nghiệm cho thấy BLEURT đạt được Kendall Tau correlation là bao nhiêu so với BLEU?",
        "options": {
          "A": "BLEURT thấp hơn BLEU.",
          "B": "BLEURT cao hơn BLEU đáng kể, nhưng vẫn còn nhiều dư địa để cải thiện.",
          "C": "BLEURT cao hơn BLEU và đạt mức hoàn hảo (1.0).",
          "D": "BLEURT và BLEU đạt kết quả tương đương."
        },
        "answer": "B"
      },
      {
        "question": "Ngoài dịch thuật tự động, việc cải thiện lựa chọn từ ngữ có thể ảnh hưởng đến những lĩnh vực nào khác?",
        "options": {
          "A": "Chỉ dịch thuật tự động.",
          "B": "Chỉ dịch thuật tự động và phân tích cảm xúc.",
          "C": "Nhiều lĩnh vực xử lý ngôn ngữ tự nhiên như chat, tóm tắt văn bản, phân tích cảm xúc, trả lời câu hỏi và phân loại văn bản.",
          "D": "Chỉ các lĩnh vực liên quan đến xử lý giọng nói."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, BLEU là viết tắt của cụm từ nào?",
        "options": {
          "A": "Bilingual Language Understanding Engine.",
          "B": "Bilingual Evaluation Understudy.",
          "C": "Bidirectional Language Understanding Engine.",
          "D": "Bidirectional Evaluation Understudy."
        },
        "answer": "B"
      }
    ]
  },
  "clothes-make-the-model": {
    "title": "Clothes Make the Model",
    "collection": "ml-research",
    "content": "In online retailing, the most commoncustomer complaintsare slow shipping and inability to try on clothes. Amazon conceived its Prime program to address the first concern. To answer the second, it built a virtual fitting room. (This is one of three recent papers from Amazon that explore AI in online retail. We’ll cover the others in upcoming weeks).What’s new:Amazon researchers led by Assaf Neuberger developedOutfit-Viton, a model that generates images of a user wearing any combination of apparel. Their work builds on the earlierVirtual Try-On NetworkandCharacteristic Preserving Virtual Try-On Network.Key insight:Previous approaches to generating images of a customer wearing a particular outfit often require hard-to-acquire data — say, 3D scans of the person and the clothes, or photos of the clothes both on and off a wearer. Outfit-Viton takes advantage ofstyle transfer, opening the door to more training data and a more interactive user experience.How it works:Outfit-Viton starts with a photo of the user and photos of clothing items. The network predicts the shape of each clothing item on the user and uses the predicted shape to generate an image of the entire outfit. Then it refines the image to capture greater detail (appearance refinement).\n\nResults:On a 7,000 image test set, Outfit-Viton achieved 20.06 Fréchet Inception Distance, a measure that correlates with human similarity where lower is better.CP-Viton, the state-of-the-art system for the task, achieved 16.63. Human judges preferred Outfit-Viton’s generated images over CP-Viton’s 65 percent of the time.Why it matters:Training CP-Viton requires photos of a garment both on and off a body. Outfit-Viton can learn from either, so it accommodates a more expansive training dataset and a wider variety of use cases.We’re thinking:Stores must spur sales even as they enact social distancing measures. A neural network makes a very socially distant dressing room.",
    "qa": [
      {
        "question": "Theo bài viết, vấn đề phổ biến nhất mà khách hàng gặp phải khi mua sắm trực tuyến là gì?",
        "options": {
          "A": "Giá cả không cạnh tranh.",
          "B": "Vận chuyển chậm và không thể thử quần áo.",
          "C": "Chất lượng sản phẩm không đảm bảo.",
          "D": "Thiếu thông tin chi tiết về sản phẩm."
        },
        "answer": "B"
      },
      {
        "question": "Amazon đã phát triển chương trình Prime để giải quyết vấn đề nào?",
        "options": {
          "A": "Không thể thử quần áo.",
          "B": "Vận chuyển chậm.",
          "C": "Thiếu sự tương tác với khách hàng.",
          "D": "Giá cả sản phẩm cao."
        },
        "answer": "B"
      },
      {
        "question": "Outfit-Viton là một mô hình được phát triển bởi Amazon để làm gì?",
        "options": {
          "A": "Dự đoán xu hướng thời trang.",
          "B": "Tạo ra hình ảnh người dùng mặc nhiều loại trang phục khác nhau.",
          "C": "Tối ưu hóa quy trình vận chuyển.",
          "D": "Cá nhân hóa trải nghiệm mua sắm."
        },
        "answer": "B"
      },
      {
        "question": "Outfit-Viton dựa trên công nghệ nào để tạo ra hình ảnh?",
        "options": {
          "A": "Nhận diện khuôn mặt.",
          "B": "Chuyển đổi phong cách (style transfer).",
          "C": "Xử lý ngôn ngữ tự nhiên.",
          "D": "Thực tế ảo tăng cường."
        },
        "answer": "B"
      },
      {
        "question": "Ưu điểm chính của Outfit-Viton so với các phương pháp trước đây là gì?",
        "options": {
          "A": "Yêu cầu dữ liệu đầu vào ít phức tạp hơn.",
          "B": "Tạo ra hình ảnh có độ phân giải cao hơn.",
          "C": "Xử lý nhanh hơn.",
          "D": "Dễ dàng tích hợp vào các nền tảng khác."
        },
        "answer": "A"
      },
      {
        "question": "Outfit-Viton bắt đầu quá trình tạo ảnh bằng cách nào?",
        "options": {
          "A": "Bằng cách tạo mô hình 3D của người dùng và quần áo.",
          "B": "Bằng cách sử dụng ảnh của người dùng và ảnh của các món đồ quần áo.",
          "C": "Bằng cách quét cơ thể người dùng.",
          "D": "Bằng cách sử dụng thông tin về kích thước cơ thể người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Chỉ số Fréchet Inception Distance (FID) được sử dụng để đo lường điều gì trong bài viết?",
        "options": {
          "A": "Độ chính xác của việc dự đoán kích cỡ quần áo.",
          "B": "Mức độ tương đồng giữa hình ảnh được tạo ra và hình ảnh thực tế.",
          "C": "Tốc độ xử lý của mô hình.",
          "D": "Mức độ hài lòng của người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống CP-Viton yêu cầu loại dữ liệu nào mà Outfit-Viton không cần?",
        "options": {
          "A": "Ảnh của quần áo khi không mặc.",
          "B": "Ảnh của quần áo khi đang mặc và không mặc.",
          "C": "Ảnh 3D của người dùng.",
          "D": "Thông tin về phong cách thời trang của người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, Outfit-Viton có thể giúp các cửa hàng giải quyết vấn đề gì trong bối cảnh giãn cách xã hội?",
        "options": {
          "A": "Giảm chi phí thuê nhân viên.",
          "B": "Tăng doanh số bán hàng thông qua trải nghiệm thử đồ ảo.",
          "C": "Cải thiện quy trình quản lý kho.",
          "D": "Thu hút khách hàng đến cửa hàng trực tiếp."
        },
        "answer": "B"
      },
      {
        "question": "Trong thử nghiệm, Outfit-Viton được người đánh giá ưa thích hơn CP-Viton bao nhiêu phần trăm?",
        "options": {
          "A": "55 phần trăm.",
          "B": "60 phần trăm.",
          "C": "65 phần trăm.",
          "D": "70 phần trăm."
        },
        "answer": "C"
      }
    ]
  },
  "coheres-aya-vision-beats-multilingual-rivals-in-text-image-understanding": {
    "title": "Equally Fluent in Many Languages",
    "collection": "ml-research",
    "content": "Multilingual AI models often suffer uneven performance across languages, especially in multimodal tasks. A pair of lean models counters this trend with consistent understanding of text and images across major languages.\n\nWhat’s new:A team at Cohere led by Saurabh Dash releasedAya Vision, a family of multilingual vision-language models with downloadable weights in 8 billion- and 32-billion-parameter sizes.\n\nHow it works:Each modelcomprisesa pretrained large language model (Aya Expanse for the 32B model, C4AI Command R7B for the 8B version), a pretrained vision encoder (SigLIP 2), and a vision-language adapter (“connector”) of unspecified architecture.\n\nPerformance:To test the model, the team built and released two benchmarks:m-WildVision, a multilingual version ofWild Vision Bench’s arena-style competition for discussion of images, andAyaVisionBench, 135 image-question pairs in each language that cover nine tasks including captioning images, understanding charts, recognizing characters in images, visual reasoning, and converting screenshots to code. On these two benchmarks, Aya Vision 8B and 32B outperformed larger competitors, as judged by Claude 3.7 Sonnet.\n\nBehind the news:Aya Vision builds on the Cohere-ledAyainitiative, a noncommercial effort to build models that perform consistently well in all languages, especially languages that lack high-quality training data. The project started with a multilingual text model (Aya Expanse), added vision (Aya Vision), and plans to eventually add video and audio.\n\nWhy it matters:Multilingual vision-language models often perform less well in low-resource languages, and the gap widens when they process media other than text. Aya Vision’s recipe for augmenting synthetic data with successively refined translations may contribute to more universally capable models. Aya Vision is available on the global messaging platform WhatsApp, where it can be used to translate text and images in all 23 of its current languages.\n\nWe’re thinking:Multilingual vision models could soon help non-native speakers decipher Turkish road signs, Finnish legal contracts, and Korean receipts. We look forward to a world in which understanding any scene or document is as effortless in Swahili as it is in English.",
    "qa": [
      {
        "question": "Aya Vision là một loại mô hình AI thuộc lĩnh vực nào?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên thuần túy.",
          "B": "Thị giác ngôn ngữ đa ngôn ngữ.",
          "C": "Phân tích dữ liệu tài chính đa quốc gia.",
          "D": "Dịch máy thời gian thực cho video."
        },
        "answer": "B"
      },
      {
        "question": "Aya Vision có bao nhiêu phiên bản với số lượng tham số khác nhau?",
        "options": {
          "A": "Một phiên bản duy nhất với 16 tỷ tham số.",
          "B": "Hai phiên bản: 8 tỷ và 32 tỷ tham số.",
          "C": "Ba phiên bản: 7 tỷ, 13 tỷ và 33 tỷ tham số.",
          "D": "Không có phiên bản cụ thể, số lượng tham số thay đổi linh hoạt."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình ngôn ngữ lớn (LLM) nào được sử dụng trong phiên bản 32 tỷ tham số của Aya Vision?",
        "options": {
          "A": "C4AI Command R7B.",
          "B": "Aya Expanse.",
          "C": "SigLIP 2.",
          "D": "Một LLM chưa được công bố."
        },
        "answer": "B"
      },
      {
        "question": "Thành phần nào của Aya Vision chịu trách nhiệm xử lý thông tin hình ảnh?",
        "options": {
          "A": "Aya Expanse.",
          "B": "C4AI Command R7B.",
          "C": "SigLIP 2.",
          "D": "Vision-language adapter."
        },
        "answer": "C"
      },
      {
        "question": "Tên của benchmark đa ngôn ngữ được phát triển để đánh giá khả năng thảo luận về hình ảnh của Aya Vision là gì?",
        "options": {
          "A": "AyaVisionBench.",
          "B": "m-WildVision.",
          "C": "Wild Vision Bench.",
          "D": "Multilingual ImageNet."
        },
        "answer": "B"
      },
      {
        "question": "AyaVisionBench bao gồm bao nhiêu cặp hình ảnh-câu hỏi cho mỗi ngôn ngữ?",
        "options": {
          "A": "100.",
          "B": "120.",
          "C": "135.",
          "D": "150."
        },
        "answer": "C"
      },
      {
        "question": "Ai là người đánh giá hiệu suất của Aya Vision so với các đối thủ cạnh tranh trong bài viết?",
        "options": {
          "A": "GPT-4.",
          "B": "Gemini Ultra.",
          "C": "Claude 3.7 Sonnet.",
          "D": "Một nhóm các nhà nghiên cứu độc lập."
        },
        "answer": "C"
      },
      {
        "question": "Aya Vision được xây dựng dựa trên sáng kiến nào?",
        "options": {
          "A": "Cohere AI.",
          "B": "Aya Initiative.",
          "C": "OpenAI.",
          "D": "Google AI."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của Aya Initiative là gì?",
        "options": {
          "A": "Phát triển các mô hình chỉ hoạt động tốt với tiếng Anh.",
          "B": "Phát triển các mô hình thương mại cho thị trường toàn cầu.",
          "C": "Phát triển các mô hình hoạt động tốt trên tất cả các ngôn ngữ, đặc biệt là các ngôn ngữ thiếu dữ liệu huấn luyện chất lượng cao.",
          "D": "Phát triển các mô hình có khả năng tạo ra nội dung giả mạo một cách thuyết phục."
        },
        "answer": "C"
      },
      {
        "question": "Aya Vision hiện có thể được sử dụng trên nền tảng nào để dịch văn bản và hình ảnh?",
        "options": {
          "A": "Telegram.",
          "B": "Facebook Messenger.",
          "C": "WhatsApp.",
          "D": "WeChat."
        },
        "answer": "C"
      }
    ]
  },
  "columbia-university-researchers-show-how-to-trick-trusting-ai-agents-with-poisoned-links": {
    "title": "Phishing for Agents",
    "collection": "ml-research",
    "content": "Researchers identified a simple way to mislead autonomous agents based on large language models.\n\nWhat’s new: Ang Li and colleagues at Columbia University developed a method toexploitthe implicit trust that agents tend to place in popular websites by poisoning those websites with malicious links.\n\nKey insight:Commercially available agentic systems may not trust random sites on the web, but they tend to trust popular sites such as social-media sites. An attacker can exploit this trust by crafting seemingly typical posts that link to a malicious website. The agent might follow the link, mistakenly extending its trust to an untrustworthy site.\n\nHow it works: The authors tested web-browsing agents includingAnthropic Computer UseandMultiOnon tasks such as shopping or sending emails.\n\nResults: Once an agent was redirected to the malicious websites, it reliably followed the attacker’s instructions. For example, each of the agents tested divulged credit card information in 10 out of 10 trials. Similarly, each agent sent a phishing message from the user’s email account asking recipients to send money to a malicious “friend” in 10 out of 10 trials.\n\nWhy it matters: Giving agents the ability to perform real-world actions, such as executing purchases and sending emails, raises the possibility that they might be tricked into taking harmful actions. Manipulating agents by referring them to malicious web content is an effective vector of attack. Agents will be more secure if they’re designed to avoid and resist such manipulation.\n\nWe’re thinking:Humans, too, can be fooled by phishing and other malicious activities, and the path to programming agents to defend against them seems easier than the path to training the majority of humans to do so. In the long term, agents will make online interactions safer.",
    "qa": [
      {
        "question": "Phương pháp mà Ang Li và cộng sự phát triển dựa trên việc khai thác điều gì ở các tác nhân tự động?",
        "options": {
          "A": "Khả năng xử lý ngôn ngữ tự nhiên vượt trội.",
          "B": "Sự tin tưởng ngầm định vào các trang web phổ biến.",
          "C": "Tốc độ truy cập internet cực nhanh.",
          "D": "Khả năng học hỏi và thích nghi với môi trường mới."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điểm yếu của các hệ thống tác nhân thương mại là gì?",
        "options": {
          "A": "Dễ dàng bị đánh lừa bởi các trang web ngẫu nhiên.",
          "B": "Có xu hướng tin tưởng các trang web phổ biến như mạng xã hội.",
          "C": "Không có khả năng phân biệt giữa trang web thật và trang web giả mạo.",
          "D": "Yêu cầu xác thực hai yếu tố để truy cập các trang web."
        },
        "answer": "B"
      },
      {
        "question": "Trong thí nghiệm, các tác giả đã sử dụng những tác nhân duyệt web nào?",
        "options": {
          "A": "Google Assistant và Siri.",
          "B": "Anthropic Computer Use và MultiOn.",
          "C": "ChatGPT và Bard.",
          "D": "Bing AI và Perplexity AI."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả thí nghiệm cho thấy điều gì về khả năng bảo mật của các tác nhân khi bị chuyển hướng đến trang web độc hại?",
        "options": {
          "A": "Các tác nhân có khả năng tự bảo vệ và từ chối thực hiện các yêu cầu độc hại.",
          "B": "Các tác nhân đáng tin cậy làm theo hướng dẫn của kẻ tấn công.",
          "C": "Các tác nhân yêu cầu xác thực từ người dùng trước khi thực hiện bất kỳ hành động nào.",
          "D": "Các tác nhân chỉ thực hiện các hành động được cho phép bởi nhà phát triển."
        },
        "answer": "B"
      },
      {
        "question": "Ví dụ nào được đưa ra trong bài viết về hành động độc hại mà các tác nhân đã thực hiện?",
        "options": {
          "A": "Tự động mua hàng trực tuyến với số lượng lớn.",
          "B": "Tiết lộ thông tin thẻ tín dụng và gửi tin nhắn lừa đảo.",
          "C": "Xóa dữ liệu quan trọng trên máy tính của người dùng.",
          "D": "Thay đổi mật khẩu tài khoản trực tuyến của người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc trang bị cho các tác nhân khả năng thực hiện các hành động trong thế giới thực lại tiềm ẩn rủi ro?",
        "options": {
          "A": "Vì các tác nhân có thể trở nên quá thông minh và vượt khỏi tầm kiểm soát.",
          "B": "Vì các tác nhân có thể bị lừa để thực hiện các hành động gây hại.",
          "C": "Vì các tác nhân có thể thay thế con người trong nhiều công việc.",
          "D": "Vì các tác nhân có thể gây ra sự mất cân bằng trong xã hội."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, cách tiếp cận nào có vẻ dễ dàng hơn trong việc bảo vệ khỏi các hoạt động độc hại?",
        "options": {
          "A": "Đào tạo phần lớn con người để nhận biết và tránh các hoạt động lừa đảo.",
          "B": "Lập trình các tác nhân để phòng thủ trước các hoạt động lừa đảo.",
          "C": "Cấm sử dụng các tác nhân tự động trong các hoạt động trực tuyến.",
          "D": "Phát triển các phần mềm diệt virus mạnh mẽ hơn."
        },
        "answer": "B"
      },
      {
        "question": "Về lâu dài, tác giả bài viết dự đoán điều gì về sự an toàn của các tương tác trực tuyến?",
        "options": {
          "A": "Các tương tác trực tuyến sẽ trở nên nguy hiểm hơn do sự phát triển của công nghệ.",
          "B": "Các tương tác trực tuyến sẽ trở nên an toàn hơn nhờ sự hỗ trợ của các tác nhân.",
          "C": "Các tương tác trực tuyến sẽ không thay đổi nhiều về mức độ an toàn.",
          "D": "Các tương tác trực tuyến sẽ phụ thuộc hoàn toàn vào sự cẩn trọng của người dùng."
        },
        "answer": "B"
      },
      {
        "question": "Kỹ thuật 'poisoning' trong bài viết đề cập đến việc gì?",
        "options": {
          "A": "Làm nhiễm độc dữ liệu huấn luyện của mô hình ngôn ngữ lớn.",
          "B": "Chèn các liên kết độc hại vào các trang web phổ biến.",
          "C": "Tấn công vào hệ thống phần cứng của các tác nhân tự động.",
          "D": "Sử dụng các thuật toán phức tạp để đánh lừa các tác nhân."
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc nghiên cứu các phương pháp đánh lừa tác nhân tự động là gì?",
        "options": {
          "A": "Để chứng minh rằng các tác nhân tự động không đáng tin cậy.",
          "B": "Để cải thiện tính bảo mật và khả năng chống lại các cuộc tấn công của tác nhân.",
          "C": "Để hạn chế sự phát triển của các tác nhân tự động.",
          "D": "Để tìm ra những lỗ hổng bảo mật và khai thác chúng."
        },
        "answer": "B"
      }
    ]
  },
  "competitive-coder": {
    "title": "Competitive Coder",
    "collection": "ml-research",
    "content": "Programming is hard. Programming competitions are harder. Yet transformers proved themselves up to the task.What’s new:Yujia Li, David Choi, Junyoung Chung, and a team at DeepMind builtAlphaCode, a system that beat roughly half of competitors in coding contests where many examples of program inputs and outputs were available.Key insight:Previous workshowed that transformers can generate code, though their output doesn’t always solve the task at hand. But transformers can generate millions of possible solutions to the same problem instantly, and the solutions can be filtered by checking their performance automatically. Those that remain should solve the problem.How it works:The authors trained a transformer to generate programs based on problems from adatasetthey built containing 13,000 challenges mainly fromCodeforces, a platform that hosts coding contests. Each problem included hundreds of solution programs (incorrect as well as correct) along with roughly 100 examples of test cases (expected inputs and outputs) mostly created by the authors.\n\nResults:The authors used AlphaCode in 10 simulated Codeforces competitions, allowing it two hours to generate solutions for each. Ranking its performance among 5,000 Codeforces competitors, it averaged in the 54th percentile (lower is better). It correctly solved 34.2 percent of problems in the validation set.Why it matters:AlphaCode generated 1 million possible solutions and culled the bad ones to solve problems it had never seen before and beat a substantial portion of competitive human programmers. It goes to show that there are still benefits to be gained from scaling up.We’re thinking:AlphaCode is an impressive demonstration of high-throughput code generation and testing. That said, considering its performance on the validation set, there’s still a distance to go.",
    "qa": [
      {
        "question": "AlphaCode được phát triển bởi tổ chức nào?",
        "options": {
          "A": "Google",
          "B": "DeepMind",
          "C": "OpenAI",
          "D": "Facebook AI Research"
        },
        "answer": "B"
      },
      {
        "question": "AlphaCode đã tham gia vào bao nhiêu cuộc thi Codeforces mô phỏng?",
        "options": {
          "A": "5",
          "B": "10",
          "C": "15",
          "D": "20"
        },
        "answer": "B"
      },
      {
        "question": "AlphaCode đạt được thứ hạng trung bình khoảng bao nhiêu phần trăm so với các đối thủ trong các cuộc thi Codeforces mô phỏng?",
        "options": {
          "A": "25th",
          "B": "54th",
          "C": "75th",
          "D": "90th"
        },
        "answer": "B"
      },
      {
        "question": "Nền tảng chính được sử dụng để thu thập dữ liệu huấn luyện cho AlphaCode là gì?",
        "options": {
          "A": "Kaggle",
          "B": "LeetCode",
          "C": "Codeforces",
          "D": "Topcoder"
        },
        "answer": "C"
      },
      {
        "question": "AlphaCode sử dụng kiến trúc nào để tạo ra các giải pháp lập trình?",
        "options": {
          "A": "Recurrent Neural Network (RNN)",
          "B": "Convolutional Neural Network (CNN)",
          "C": "Transformer",
          "D": "Generative Adversarial Network (GAN)"
        },
        "answer": "C"
      },
      {
        "question": "Điểm mạnh chính của AlphaCode được nhấn mạnh trong bài viết là gì?",
        "options": {
          "A": "Khả năng hiểu ngôn ngữ tự nhiên phức tạp.",
          "B": "Khả năng tạo ra số lượng lớn các giải pháp tiềm năng và lọc ra những giải pháp tốt nhất.",
          "C": "Khả năng tối ưu hóa mã nguồn để đạt hiệu suất cao nhất.",
          "D": "Khả năng gỡ lỗi mã nguồn một cách tự động."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đánh giá như thế nào về hiệu suất của AlphaCode trên tập dữ liệu validation?",
        "options": {
          "A": "Hiệu suất rất xuất sắc và vượt trội so với các hệ thống khác.",
          "B": "Hiệu suất tốt nhưng vẫn còn nhiều tiềm năng để cải thiện.",
          "C": "Hiệu suất chỉ ở mức trung bình và cần nhiều nghiên cứu hơn.",
          "D": "Hiệu suất kém và không thể cạnh tranh với các lập trình viên con người."
        },
        "answer": "B"
      },
      {
        "question": "Số lượng bài toán trong tập dữ liệu mà AlphaCode được huấn luyện chủ yếu đến từ Codeforces là bao nhiêu?",
        "options": {
          "A": "5,000",
          "B": "10,000",
          "C": "13,000",
          "D": "20,000"
        },
        "answer": "C"
      },
      {
        "question": "AlphaCode đã giải đúng bao nhiêu phần trăm số bài toán trong tập validation?",
        "options": {
          "A": "20.5%",
          "B": "34.2%",
          "C": "45.8%",
          "D": "60.1%"
        },
        "answer": "B"
      },
      {
        "question": "Mục đích chính của việc sử dụng các test case (input và output dự kiến) trong quá trình huấn luyện AlphaCode là gì?",
        "options": {
          "A": "Để đánh giá khả năng hiểu ngôn ngữ tự nhiên của AlphaCode.",
          "B": "Để kiểm tra và lọc ra các giải pháp lập trình không chính xác.",
          "C": "Để tăng tốc độ huấn luyện của mô hình.",
          "D": "Để giảm thiểu dung lượng bộ nhớ cần thiết cho việc huấn luyện."
        },
        "answer": "B"
      }
    ]
  },
  "compl-ai-study-measures-llms-compliance-with-eus-ai-act": {
    "title": "Does Your Model Comply With the AI Act?",
    "collection": "ml-research",
    "content": "A new study suggests that leading AI models may meet the requirements of the European Union’s AI Act in some areas, but probably not in others.\n\nWhat’s new:The Zurich-based startup LatticeFlow, working with research institutions in Bulgaria and Switzerland, developedCOMPL-AI, an unofficial framework designed to evaluate large language models’ likely compliance with the AI Act. Aleaderboardranks an initial selection of models. (LatticeFlow does not work for the European Commission or have legal standing to interpret the AI Act.)\n\nHow it works:Apaperexplains how COMPL-AI maps the AI Act’s requirements to specific benchmarks. It evaluates each requirement using new or established tests and renders an aggregate score. These scores are relative measures, and the authors don’t propose thresholds for compliance. The assessment covers five primary categories:\n\nResults:The authors evaluated nine open models and three proprietary ones on a scale between 0 and 1. Theirreportson each model reveal considerable variability. (Note: The aggregate scores cited in the reports don’t match those in the paper.)\n\nYes, but:The authors note that some provisions of the AI Act, including explainability, oversight (deference to human control), and corrigibility (whether an AI system can be altered to change harmful outputs, which bears on a model’s risk classification under the AI Act), are defined ambiguously under the law and can’t be measured reliably at present. These areas are under-explored in the research literature and lack benchmarks to assess them.\n\nWhy it matters:With the advent of laws that regulate AI technology, developers are responsible for assessing a model’s compliance before they release it or use it in ways that affect the public. COMPL-AI takes a first step toward assuring model builders that their work is legally defensible or else alerting them to flaws that could lead to legal risk if they’re not addressed prior to release.\n\nWe’re thinking:Thoughtful regulation of AI is necessary, but it should be done in ways that don’t impose an undue burden on developers. While the AI Act itself is overly burdensome, we’re glad to see a largely automated path to demonstrating compliance of large language models.",
    "qa": [
      {
        "question": "COMPL-AI là gì?",
        "options": {
          "A": "Một đạo luật chính thức của Liên minh Châu Âu về trí tuệ nhân tạo.",
          "B": "Một khuôn khổ không chính thức được thiết kế để đánh giá khả năng tuân thủ Đạo luật AI của các mô hình ngôn ngữ lớn.",
          "C": "Một công ty luật chuyên tư vấn về tuân thủ Đạo luật AI.",
          "D": "Một tiêu chuẩn đánh giá hiệu suất của các mô hình AI trong lĩnh vực xử lý ngôn ngữ tự nhiên."
        },
        "answer": "B"
      },
      {
        "question": "Tổ chức nào đã phát triển COMPL-AI?",
        "options": {
          "A": "Ủy ban Châu Âu.",
          "B": "Một liên minh các trường đại học hàng đầu thế giới.",
          "C": "Startup LatticeFlow, hợp tác với các viện nghiên cứu ở Bulgaria và Thụy Sĩ.",
          "D": "Một tổ chức phi chính phủ chuyên về quyền riêng tư và bảo mật dữ liệu."
        },
        "answer": "C"
      },
      {
        "question": "COMPL-AI đánh giá các mô hình AI dựa trên những tiêu chí nào?",
        "options": {
          "A": "Hiệu suất, độ chính xác và tốc độ xử lý.",
          "B": "Khả năng tuân thủ các yêu cầu cụ thể của Đạo luật AI.",
          "C": "Mức độ sáng tạo và khả năng tạo ra nội dung mới.",
          "D": "Mức độ phổ biến và số lượng người dùng sử dụng mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Điểm số mà COMPL-AI đưa ra có ý nghĩa gì?",
        "options": {
          "A": "Cho biết mức độ tuyệt đối mà mô hình tuân thủ Đạo luật AI.",
          "B": "Cho biết mức độ tương đối mà mô hình tuân thủ Đạo luật AI so với các mô hình khác.",
          "C": "Cho biết khả năng mô hình sẽ bị phạt theo Đạo luật AI.",
          "D": "Cho biết chi phí để điều chỉnh mô hình cho phù hợp với Đạo luật AI."
        },
        "answer": "B"
      },
      {
        "question": "Những khía cạnh nào của Đạo luật AI hiện tại khó đánh giá bằng COMPL-AI?",
        "options": {
          "A": "Khả năng xử lý ngôn ngữ tự nhiên và dịch thuật.",
          "B": "Khả năng nhận diện khuôn mặt và phân tích hình ảnh.",
          "C": "Tính dễ giải thích, khả năng kiểm soát của con người và khả năng sửa lỗi.",
          "D": "Khả năng dự đoán và đưa ra quyết định dựa trên dữ liệu lịch sử."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao việc đánh giá sự tuân thủ của mô hình AI lại quan trọng?",
        "options": {
          "A": "Để tăng cường khả năng cạnh tranh của các mô hình AI trên thị trường.",
          "B": "Để đảm bảo rằng các mô hình AI không vi phạm pháp luật và gây hại cho cộng đồng.",
          "C": "Để thu hút đầu tư và tài trợ cho các dự án phát triển AI.",
          "D": "Để đơn giản hóa quy trình phát triển và triển khai các mô hình AI."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của COMPL-AI là gì?",
        "options": {
          "A": "Thay thế các chuyên gia pháp lý trong việc đánh giá tuân thủ Đạo luật AI.",
          "B": "Cung cấp một con đường tự động hóa để chứng minh sự tuân thủ của các mô hình ngôn ngữ lớn.",
          "C": "Phát hiện và ngăn chặn các hành vi gian lận trong quá trình phát triển AI.",
          "D": "Tối ưu hóa hiệu suất và giảm chi phí phát triển các mô hình AI."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, điều gì cần thiết trong việc ban hành các quy định về AI?",
        "options": {
          "A": "Quy định cần phải nghiêm ngặt để đảm bảo an toàn tuyệt đối.",
          "B": "Quy định cần phải được thực thi một cách nhanh chóng và hiệu quả.",
          "C": "Quy định cần phải được cân nhắc kỹ lưỡng để không gây gánh nặng quá mức cho các nhà phát triển.",
          "D": "Quy định cần phải được điều chỉnh liên tục để phù hợp với sự phát triển của công nghệ."
        },
        "answer": "C"
      },
      {
        "question": "Bài viết đề cập đến số lượng mô hình AI đã được đánh giá bởi COMPL-AI là bao nhiêu?",
        "options": {
          "A": "6",
          "B": "9",
          "C": "12",
          "D": "15"
        },
        "answer": "C"
      },
      {
        "question": "Thuật ngữ 'corrigibility' trong bài viết đề cập đến điều gì?",
        "options": {
          "A": "Khả năng của mô hình AI trong việc tự sửa lỗi.",
          "B": "Khả năng của mô hình AI trong việc giải thích các quyết định của nó.",
          "C": "Khả năng của mô hình AI trong việc được thay đổi để thay đổi các kết quả đầu ra có hại.",
          "D": "Khả năng của mô hình AI trong việc học hỏi từ dữ liệu mới."
        },
        "answer": "C"
      }
    ]
  },
  "computer-vision-transformed": {
    "title": "Computer Vision Transformed",
    "collection": "ml-research",
    "content": "The transformer architecture that has shaken up natural language processing may replace recurrent layers in object detection networks.What’s new:A Facebook team led by Nicolas Carion and Francisco Massa simplified object detection pipelines by using transformers, yielding Detection Transformer (DETR).Key insight:Images can show multiple objects. Some object detection networks use recurrent layers to predict one object at a time until all objects are accounted for. Language models usetransformersto evaluate a sequence of words in one pass. Similarly, DETR uses them to predict all objects in an image in a single process.How it works:DETR predicts a fixed number of object bounding boxes and classes per image. First, it extracts image features using convolutional layers. Then transformers predict features associated with regions likely to contain objects. Feed-forward layers process the object features into classes and bounding boxes. (“No object” is a possible class.)\n\nResults:The researchers pitted DETR againstFaster R-CNNon the canonical object detection datasetCoco. At model sizes of roughly 40 million parameters, DETR bettered Faster R-CNN’s average precision, a measure of true positives, from 0.402 to 0.420. And DETR did it faster, spotting objects at 28 images per second compared to Faster R-CNN’s 26 images per second.Why it matters:Transformers are changing the way machine learning models handle sequential data in NLP and beyond.We’re thinking:What happened to theMuppet namesfor transformer-based models? Fozzie Bear is available.",
    "qa": [
      {
        "question": "Kiến trúc Transformer, ban đầu được sử dụng rộng rãi trong lĩnh vực nào, hiện đang được ứng dụng trong object detection?",
        "options": {
          "A": "Xử lý ảnh y tế",
          "B": "Xử lý ngôn ngữ tự nhiên",
          "C": "Phân tích dữ liệu tài chính",
          "D": "Dự báo thời tiết"
        },
        "answer": "B"
      },
      {
        "question": "Đội ngũ nghiên cứu Facebook, dẫn đầu bởi ai, đã phát triển mô hình Detection Transformer (DETR)?",
        "options": {
          "A": "Yann LeCun và Yoshua Bengio",
          "B": "Nicolas Carion và Francisco Massa",
          "C": "Geoffrey Hinton và Andrew Ng",
          "D": "Jeff Dean và Sanjay Ghemawat"
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính của DETR so với các mạng object detection truyền thống là gì?",
        "options": {
          "A": "Sử dụng mạng nơ-ron tích chập sâu hơn",
          "B": "Dự đoán tất cả các đối tượng trong ảnh cùng một lúc",
          "C": "Sử dụng dữ liệu huấn luyện lớn hơn",
          "D": "Áp dụng kỹ thuật tăng cường dữ liệu phức tạp hơn"
        },
        "answer": "B"
      },
      {
        "question": "DETR dự đoán số lượng bounding box và class cho mỗi ảnh như thế nào?",
        "options": {
          "A": "Số lượng thay đổi tùy thuộc vào độ phức tạp của ảnh",
          "B": "Số lượng được xác định động dựa trên số lượng đối tượng thực tế",
          "C": "Số lượng là cố định cho mỗi ảnh",
          "D": "Số lượng được học trong quá trình huấn luyện"
        },
        "answer": "C"
      },
      {
        "question": "Lớp nào được sử dụng đầu tiên trong DETR để trích xuất đặc trưng hình ảnh?",
        "options": {
          "A": "Lớp recurrent",
          "B": "Lớp transformer",
          "C": "Lớp tích chập",
          "D": "Lớp fully connected"
        },
        "answer": "C"
      },
      {
        "question": "Trong DETR, lớp nào chịu trách nhiệm xử lý các đặc trưng đối tượng thành các lớp và bounding box?",
        "options": {
          "A": "Lớp recurrent",
          "B": "Lớp feed-forward",
          "C": "Lớp tích chập",
          "D": "Lớp pooling"
        },
        "answer": "B"
      },
      {
        "question": "Trong quá trình dự đoán của DETR, class nào có thể được gán cho một vùng ảnh?",
        "options": {
          "A": "Chỉ các class đối tượng cụ thể",
          "B": "Chỉ các class đối tượng phổ biến",
          "C": "Chỉ các class đối tượng hiếm gặp",
          "D": "Class 'Không có đối tượng' (No object)"
        },
        "answer": "D"
      },
      {
        "question": "DETR đã được so sánh với mô hình nào trên bộ dữ liệu Coco?",
        "options": {
          "A": "YOLOv3",
          "B": "SSD",
          "C": "Faster R-CNN",
          "D": "Mask R-CNN"
        },
        "answer": "C"
      },
      {
        "question": "DETR đạt được độ chính xác trung bình (average precision) là bao nhiêu trên bộ dữ liệu Coco, so với Faster R-CNN?",
        "options": {
          "A": "Thấp hơn Faster R-CNN",
          "B": "Tương đương Faster R-CNN",
          "C": "Cao hơn Faster R-CNN",
          "D": "Không thể so sánh được"
        },
        "answer": "C"
      },
      {
        "question": "Tốc độ xử lý ảnh của DETR là bao nhiêu ảnh mỗi giây?",
        "options": {
          "A": "20 ảnh/giây",
          "B": "26 ảnh/giây",
          "C": "28 ảnh/giây",
          "D": "30 ảnh/giây"
        },
        "answer": "C"
      }
    ]
  },
  "convnext-v2-the-new-model-family-that-boosts-convnet-performance": {
    "title": "Masked Pretraining for CNNs",
    "collection": "ml-research",
    "content": "Vision transformers have bested convolutional neural networks (CNNs) in a number of key vision tasks. Have CNNs hit their limit? New research suggests otherwise.\n\nWhat’s new:Sanghyun Woo and colleagues at Korea Advanced Institute of Science & Technology, Meta, and New York University builtConvNeXt V2, a purely convolutional architecture that, after pretraining and fine-tuning, achieved state-of-the-art performance on ImageNet. ConvNeXt V2 improves uponConvNeXt, which updated the classicResNet.\n\nKey insight:Vision transformers learn via masked pretraining — that is, hiding part of an image and learning to reconstruct the missing part. This enables them to learn from unlabeled data, which simplifies amassing large training datasets and thus enables them to produce better embeddings. If masked pretraining works for transformers, it ought to work for CNNs as well.\n\nHow it works:ConvNeXt V2 is an encoder-decoder pretrained on 14 million images inImageNet 22k. For the decoder, the authors used a single ConvNeXt convolutional block (made up of three convolutional layers). They modified the ConvNeXt encoder (36 ConvNeXt blocks) as follows:\n\nResults:The biggest ConvNeXt V2 model (659 million parameters) achieved 88.9 percent top-1 accuracy on ImageNet. The previous state of the art,MViTV2(a transformer with roughly the same number of parameters) achieved 88.8 percent accuracy. In addition, ConvNeXt V2 required less processing power: 600.7 gigaflops versus 763.5 gigaflops.\n\nWhy it matters:Transformers show great promise in computer vision, but convolutional architectures can achieve comparable performance with less computation.\n\nWe’re thinking:While ImageNet 22k is one of the largest publicly available image datasets, vision transformers benefit from training on proprietary datasets that are much larger. We’re eager to see how ConvNeXt V2 would fare if it were scaled to billions of parameters andimages. In addition, ImageNet has been joined by many newer benchmarks. We’d like to see results for some of those.",
    "qa": [
      {
        "question": "ConvNeXt V2 được xây dựng bởi những tổ chức nào?",
        "options": {
          "A": "Google, Meta, và Stanford University",
          "B": "Korea Advanced Institute of Science & Technology, Meta, và New York University",
          "C": "Microsoft, OpenAI, và Massachusetts Institute of Technology",
          "D": "Tsinghua University, Baidu, và Carnegie Mellon University"
        },
        "answer": "B"
      },
      {
        "question": "Điểm cải tiến chính của ConvNeXt V2 so với các kiến trúc CNN truyền thống là gì?",
        "options": {
          "A": "Sử dụng nhiều lớp fully connected hơn.",
          "B": "Áp dụng phương pháp pretraining masked tương tự như vision transformers.",
          "C": "Loại bỏ hoàn toàn các lớp convolutional.",
          "D": "Tăng kích thước kernel của các lớp convolutional."
        },
        "answer": "B"
      },
      {
        "question": "ConvNeXt V2 được pretrain trên bộ dữ liệu nào?",
        "options": {
          "A": "ImageNet 1k",
          "B": "ImageNet 22k",
          "C": "COCO",
          "D": "Pascal VOC"
        },
        "answer": "B"
      },
      {
        "question": "Decoder trong ConvNeXt V2 bao gồm bao nhiêu convolutional block?",
        "options": {
          "A": "36",
          "B": "3",
          "C": "1",
          "D": "Không sử dụng decoder"
        },
        "answer": "C"
      },
      {
        "question": "Độ chính xác top-1 mà mô hình ConvNeXt V2 lớn nhất đạt được trên ImageNet là bao nhiêu?",
        "options": {
          "A": "88.0%",
          "B": "88.8%",
          "C": "88.9%",
          "D": "89.0%"
        },
        "answer": "C"
      },
      {
        "question": "Mô hình nào đạt được độ chính xác gần tương đương với ConvNeXt V2 trên ImageNet?",
        "options": {
          "A": "ResNet-50",
          "B": "MViTV2",
          "C": "VGG16",
          "D": "AlexNet"
        },
        "answer": "B"
      },
      {
        "question": "ConvNeXt V2 tiêu thụ bao nhiêu gigaflops để xử lý?",
        "options": {
          "A": "763.5",
          "B": "500.0",
          "C": "600.7",
          "D": "800.0"
        },
        "answer": "C"
      },
      {
        "question": "Ưu điểm của ConvNeXt V2 so với MViTV2 là gì?",
        "options": {
          "A": "Độ chính xác cao hơn đáng kể.",
          "B": "Yêu cầu ít sức mạnh tính toán hơn.",
          "C": "Dễ dàng triển khai hơn.",
          "D": "Ít tham số hơn."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết đề xuất gì về hướng phát triển tiềm năng của ConvNeXt V2?",
        "options": {
          "A": "Giảm số lượng tham số để tăng tốc độ xử lý.",
          "B": "Mở rộng quy mô mô hình và huấn luyện trên các bộ dữ liệu lớn hơn.",
          "C": "Sử dụng các hàm kích hoạt khác nhau.",
          "D": "Thay thế các lớp convolutional bằng các lớp fully connected."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết gợi ý rằng cần đánh giá ConvNeXt V2 trên những loại benchmark nào?",
        "options": {
          "A": "Chỉ trên ImageNet.",
          "B": "Các benchmark mới hơn ngoài ImageNet.",
          "C": "Các benchmark về xử lý ngôn ngữ tự nhiên.",
          "D": "Các benchmark về reinforcement learning."
        },
        "answer": "B"
      }
    ]
  },
  "convolution-revolution": {
    "title": "Convolution Revolution",
    "collection": "ml-research",
    "content": "Looking at images, people see outlines before the details within them. A replacement for the traditional convolutional layer decomposes images based on this distinction between coarse and fine features.What’s new:Researchers at Facebook AI, National University of Singapore, and Yitu Technology devisedOctConv, a convolutional filter that reduces the computational cost and memory footprint of image processing networks without degrading performance.Key insight:Yunpeng Chen and collaborators took their inspiration from signal processing: An audio signal can be represented as a set of discrete frequencies rather than a single waveform. Similarly, an image can be said to contain low-frequency information that doesn’t change much across space and high-frequency imagery that does. Low-frequency image features are shapes, while high-frequency image features comprise details such as textures. By capturing them separately, OctConv can reduce redundant information.How it works:The outputs of a convolutional layer’s hidden units are feature maps that hold 2D spatial information. Feature maps often encode redundant information across an image’s color channels. OctConv cuts this redundancy by using a frequency-channel representation instead of the usual color-channel representation.\n\nResults:A ResNet-152 with OctConv rather than CNN filters was 0.2 percent more accurate on ImageNet than the next best model, with 15 percent less computation during testing. An I3D model pair with OctConv filters was 2 percent more accurate on Kinetics-600, a video dataset for predicting human actions, with 10 percent less computation.Why it matters:OctConv filters can substitute for standard convolutional filters for better performance, reduced computation, and smaller footprint. The authors suggest subdividing beyond their low- and high-frequency scheme. That would yield greater savings in size and training time, but its impact on performance is a subject for further experimentation.Takeaway:Memory compression and pruning techniques have been important for deploying neural networks on smartphones and other low-powered, low-memory devices. OctConv is a fresh approach to shrinking image-processing networks that takes into account memory and computation primitives.",
    "qa": [
      {
        "question": "Theo bài viết, điều gì thường được nhận diện đầu tiên khi nhìn vào hình ảnh?",
        "options": {
          "A": "Các chi tiết nhỏ như vân tay.",
          "B": "Đường viền tổng thể.",
          "C": "Màu sắc chủ đạo.",
          "D": "Độ tương phản sáng tối."
        },
        "answer": "B"
      },
      {
        "question": "OctConv là một cải tiến cho loại lớp mạng nào?",
        "options": {
          "A": "Lớp mạng nơ-ron tái phát (RNN).",
          "B": "Lớp mạng nơ-ron tích chập (CNN).",
          "C": "Lớp mạng nơ-ron lan truyền ngược (BPNN).",
          "D": "Lớp mạng nơ-ron tự mã hóa (Autoencoder)."
        },
        "answer": "B"
      },
      {
        "question": "Ý tưởng chính của OctConv đến từ lĩnh vực nào?",
        "options": {
          "A": "Xử lý ngôn ngữ tự nhiên.",
          "B": "Xử lý tín hiệu.",
          "C": "Thống kê học.",
          "D": "Lý thuyết thông tin."
        },
        "answer": "B"
      },
      {
        "question": "Trong OctConv, tần số thấp của hình ảnh đại diện cho điều gì?",
        "options": {
          "A": "Các chi tiết nhỏ như kết cấu.",
          "B": "Hình dạng tổng thể.",
          "C": "Sự thay đổi màu sắc đột ngột.",
          "D": "Độ sáng của hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "OctConv giảm thiểu sự dư thừa thông tin bằng cách nào?",
        "options": {
          "A": "Loại bỏ các kênh màu ít quan trọng.",
          "B": "Sử dụng biểu diễn kênh tần số thay vì kênh màu.",
          "C": "Giảm kích thước của các bản đồ đặc trưng.",
          "D": "Áp dụng các hàm kích hoạt tuyến tính."
        },
        "answer": "B"
      },
      {
        "question": "Trong thử nghiệm, ResNet-152 sử dụng OctConv đã cải thiện độ chính xác trên ImageNet như thế nào so với mô hình tốt nhất tiếp theo?",
        "options": {
          "A": "Tăng 15%.",
          "B": "Tăng 0.2%.",
          "C": "Giảm 0.2%.",
          "D": "Không có sự thay đổi đáng kể."
        },
        "answer": "B"
      },
      {
        "question": "Mô hình I3D với OctConv đã được thử nghiệm trên bộ dữ liệu nào?",
        "options": {
          "A": "ImageNet.",
          "B": "MNIST.",
          "C": "Kinetics-600.",
          "D": "CIFAR-10."
        },
        "answer": "C"
      },
      {
        "question": "Lợi ích chính của việc sử dụng OctConv là gì?",
        "options": {
          "A": "Tăng độ phức tạp của mô hình.",
          "B": "Giảm hiệu suất, tăng kích thước và tính toán.",
          "C": "Cải thiện hiệu suất, giảm tính toán và kích thước.",
          "D": "Không có lợi ích đáng kể."
        },
        "answer": "C"
      },
      {
        "question": "Các tác giả của OctConv gợi ý điều gì cho các nghiên cứu tiếp theo?",
        "options": {
          "A": "Chỉ sử dụng hai tần số (cao và thấp).",
          "B": "Không cần thiết phải chia nhỏ hơn nữa.",
          "C": "Chia nhỏ hơn nữa thành nhiều tần số.",
          "D": "Loại bỏ hoàn toàn các lớp tích chập."
        },
        "answer": "C"
      },
      {
        "question": "Kỹ thuật nào đã trở nên quan trọng để triển khai mạng nơ-ron trên các thiết bị có công suất và bộ nhớ thấp?",
        "options": {
          "A": "Tăng kích thước mô hình.",
          "B": "Nén bộ nhớ và tỉa thưa.",
          "C": "Sử dụng nhiều lớp ẩn hơn.",
          "D": "Tăng tốc độ học."
        },
        "answer": "B"
      }
    ]
  },
  "coordinating-robot-limbs": {
    "title": "Coordinating Robot Limbs",
    "collection": "ml-research",
    "content": "A dog doesn’t think twice about fetching a tennis ball, but an autonomous robot typically suffers from delays between perception and action. A new machine-learning model helped a quadruped robot coordinate its sensors and actuators.\n\nWhat's new:Chieko Sarah Imai and colleagues at University of California devised a reinforcement learning method,Multi-Modal Delay Randomization(MMDR), that approximates real-world latency in a simulated training environment, enabling engineers to compensate for it.\n\nKey insight:Most robot simulations wait for the machine to take an action after a change in its surroundings. But in the real world, it takes time for a sensor to read the environment, a neural network to compute the action, and motors to execute the action — and by that time, the environment has already shifted again. Simulating the latency of sensors that track position and movement during traininghelpsa model to learn to adjust accordingly, but that doesn’t account for lags due to reading and processing visual sensors. Simulating a separate latency for vision should address this issue.\n\nHow it works:The authors trained their system to compute optimal angles for a simulated robot's joints using the reinforcement learning algorithmproximal policy optimization. The virtual robot traversed uneven virtual ground between box-like obstacles in aPyBulletsimulation.\n\nResults:The authors tested aUnitree A1robot in the real world, comparing MMDR with alternatives they call No-Delay and Frame-Extract. No-Delay used only the four most recent frames as input. Frame-Extract was similar to MMDR but used the initial frames from each of the buffered sequences. MMDR was consistently best in terms of steps traveled through a variety of terrain. For example, in nine forest trials, the robot using MMDR moved an average of 992.5 steps versus 733.8 steps for No-Delay and 572.4 steps for Frame-Extract.\n\nWhy it matters:Robots in the wild often face different mechanical and environmental conditions than a simulation can reproduce. To build autonomous machines that work in the real world, it’s critical to account for all kinds of latency in the system.\n\nWe're thinking:Roboticists and mechanical engineers who work with physical robots have been accounting for various control latencies for decades. But much of the recent activity in reinforcement learning has involved simulated environments. We’re glad to see researchers working to bridge the sim-to-real gap and address the challenges of working with physical robots.",
    "qa": [
      {
        "question": "Vấn đề chính mà các robot tự hành thường gặp phải so với chó khi thực hiện các tác vụ đơn giản như nhặt bóng là gì?",
        "options": {
          "A": "Khả năng di chuyển chậm chạp hơn.",
          "B": "Sự chậm trễ giữa nhận thức và hành động.",
          "C": "Thiếu khả năng nhận diện vật thể.",
          "D": "Khả năng giữ thăng bằng kém."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp Multi-Modal Delay Randomization (MMDR) được phát triển bởi Chieko Sarah Imai và các đồng nghiệp nhằm mục đích gì?",
        "options": {
          "A": "Tăng tốc độ xử lý hình ảnh của robot.",
          "B": "Mô phỏng độ trễ thực tế trong môi trường huấn luyện ảo.",
          "C": "Cải thiện khả năng di chuyển trên địa hình gồ ghề.",
          "D": "Giảm chi phí sản xuất robot."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính giữa mô phỏng robot thông thường và phương pháp MMDR là gì?",
        "options": {
          "A": "MMDR sử dụng thuật toán học tăng cường phức tạp hơn.",
          "B": "MMDR mô phỏng độ trễ của cảm biến, mạng nơ-ron và động cơ.",
          "C": "MMDR sử dụng môi trường mô phỏng thực tế hơn.",
          "D": "MMDR cho phép robot học hỏi nhanh hơn."
        },
        "answer": "B"
      },
      {
        "question": "Thuật toán học tăng cường nào được sử dụng để huấn luyện hệ thống tính toán góc tối ưu cho các khớp của robot trong mô phỏng?",
        "options": {
          "A": "Thuật toán Q-learning.",
          "B": "Thuật toán Deep Q-Network (DQN).",
          "C": "Thuật toán proximal policy optimization.",
          "D": "Thuật toán Monte Carlo tree search."
        },
        "answer": "C"
      },
      {
        "question": "Trong quá trình thử nghiệm, robot Unitree A1 đã được thử nghiệm trong môi trường nào?",
        "options": {
          "A": "Phòng thí nghiệm với bề mặt phẳng.",
          "B": "Môi trường đô thị với nhiều chướng ngại vật.",
          "C": "Rừng với địa hình đa dạng.",
          "D": "Sa mạc với điều kiện thời tiết khắc nghiệt."
        },
        "answer": "C"
      },
      {
        "question": "Trong các thử nghiệm, phương pháp nào cho kết quả tốt nhất về số bước di chuyển trung bình trên địa hình rừng?",
        "options": {
          "A": "No-Delay.",
          "B": "Frame-Extract.",
          "C": "MMDR.",
          "D": "Tất cả các phương pháp đều cho kết quả tương đương."
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp No-Delay sử dụng bao nhiêu khung hình gần nhất làm đầu vào?",
        "options": {
          "A": "Hai khung hình.",
          "B": "Bốn khung hình.",
          "C": "Sáu khung hình.",
          "D": "Tám khung hình."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao việc tính đến độ trễ trong hệ thống lại quan trọng khi xây dựng robot tự hành hoạt động trong thế giới thực?",
        "options": {
          "A": "Để giảm kích thước của robot.",
          "B": "Để tăng tuổi thọ pin của robot.",
          "C": "Để robot có thể thích ứng với các điều kiện cơ học và môi trường khác nhau.",
          "D": "Để giảm chi phí sản xuất robot."
        },
        "answer": "C"
      },
      {
        "question": "Frame-Extract khác với MMDR ở điểm nào?",
        "options": {
          "A": "Frame-Extract sử dụng thuật toán học tăng cường khác.",
          "B": "Frame-Extract sử dụng các khung hình ban đầu từ mỗi chuỗi đệm.",
          "C": "Frame-Extract không tính đến độ trễ của cảm biến.",
          "D": "Frame-Extract chỉ hoạt động trong môi trường mô phỏng."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh điều gì về sự khác biệt giữa môi trường mô phỏng và thế giới thực trong lĩnh vực robot học?",
        "options": {
          "A": "Môi trường mô phỏng luôn chính xác hơn thế giới thực.",
          "B": "Việc thu hẹp khoảng cách giữa mô phỏng và thực tế là rất quan trọng để phát triển robot tự hành hiệu quả.",
          "C": "Robot hoạt động tốt trong mô phỏng luôn hoạt động tốt trong thế giới thực.",
          "D": "Không cần thiết phải quan tâm đến sự khác biệt giữa mô phỏng và thực tế."
        },
        "answer": "B"
      }
    ]
  },
  "correct-n-contrast": {
    "title": "Taming Spurious Correlations",
    "collection": "ml-research",
    "content": "When a neural network learns image labels, it may confuse a background item for the labeled object. For example, it may learn to associate the label “camel” with desert sand and then classify a cow on a beach as a camel. New research has trained networks to avoid such mistakes.What’s new:A team at Stanford and Northeastern University led by Michael Zhang proposedCorrect-N-Contrast(CNC), a training method that makes neural networks more robust to spurious correlations, in which features and labels are associated but not causally related.Key insight:A neural network likely has learned a spurious correlation when it produces dissimilar representations of two images with the same label. When learning representations of two images of a cow, for example, the error may manifest as a representation of a grassy field in one image and a representation of a beach in the other. A contrastive loss function can help a neural network avoid such errors by encouraging it to learn similar representations for similar objects against different backgrounds.How it works:The authors trained models to classify examples and identified examples the models got wrong, possibly owing to spurious correlations. Then they trained a second neural network to classify them correctly using a contrastive loss function.\n\nResults:The authors evaluated their models’ accuracies on groups of examples known to be difficult to classify. Their approach outperformedEIIL, which first trains a model to infer related groups of examples and then trains a second model to classify examples using the group IDs, both on average and on individual tasks. For instance, the ResNet-50 trained on CelebA with CNC achieved 88.8 percent accuracy, while training with EIIL achieved 81.7 percent accuracy. Across all tasks, the authors’ approach achieved 80.9 percent average accuracy while EIIL achieved 74.7 percent average accuracy.Yes, but:Group DRO, which provides additional information during training such as a description of the background of an image or the gender of a depicted person, achieved 81.8 percent average accuracy.Why it matters:Previous approaches to managing spurious correlations tend to expand training datasets to capture more variability in data. This work actively guides models away from representing features that reduce classification accuracy.We’re thinking:A self-driving car must detect a cow (or a person or another vehicle) whether it stands on a meadow, a beach, or pavement.",
    "qa": [
      {
        "question": "Vấn đề chính mà mạng nơ-ron gặp phải khi học nhãn hình ảnh được đề cập trong bài viết là gì?",
        "options": {
          "A": "Khó khăn trong việc phân biệt các đối tượng có màu sắc tương đồng.",
          "B": "Nhầm lẫn các yếu tố nền với đối tượng được gán nhãn.",
          "C": "Không thể xử lý hình ảnh có độ phân giải thấp.",
          "D": "Yêu cầu lượng dữ liệu huấn luyện quá lớn."
        },
        "answer": "B"
      },
      {
        "question": "Phương pháp Correct-N-Contrast (CNC) được phát triển bởi nhóm nghiên cứu nào?",
        "options": {
          "A": "MIT và Harvard University.",
          "B": "Stanford và Northeastern University.",
          "C": "Oxford và Cambridge University.",
          "D": "Google AI và DeepMind."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, 'spurious correlation' (tương quan giả) được định nghĩa như thế nào?",
        "options": {
          "A": "Mối quan hệ nhân quả giữa các đặc trưng và nhãn.",
          "B": "Mối liên hệ giữa các đặc trưng và nhãn, nhưng không có quan hệ nhân quả.",
          "C": "Sự trùng lặp ngẫu nhiên giữa các đặc trưng trong hình ảnh.",
          "D": "Sai sót trong quá trình gán nhãn dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Ý tưởng chính đằng sau việc sử dụng contrastive loss function trong CNC là gì?",
        "options": {
          "A": "Tăng cường sự khác biệt giữa các đối tượng khác nhau.",
          "B": "Khuyến khích mạng nơ-ron học các biểu diễn tương tự cho các đối tượng tương tự trong các bối cảnh khác nhau.",
          "C": "Giảm thiểu sự ảnh hưởng của các đặc trưng không liên quan đến đối tượng.",
          "D": "Cải thiện tốc độ hội tụ của mô hình."
        },
        "answer": "B"
      },
      {
        "question": "Trong phương pháp CNC, mạng nơ-ron thứ hai được huấn luyện để làm gì?",
        "options": {
          "A": "Phân loại các ví dụ mà mạng nơ-ron đầu tiên đã phân loại đúng.",
          "B": "Phân loại các ví dụ mà mạng nơ-ron đầu tiên đã phân loại sai, có thể do tương quan giả.",
          "C": "Tạo ra các ví dụ mới để huấn luyện mạng nơ-ron đầu tiên.",
          "D": "Xác định các đặc trưng quan trọng nhất trong hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "So với phương pháp EIIL, CNC thể hiện như thế nào về độ chính xác?",
        "options": {
          "A": "CNC có độ chính xác thấp hơn EIIL trên tất cả các nhiệm vụ.",
          "B": "CNC có độ chính xác tương đương EIIL trên hầu hết các nhiệm vụ.",
          "C": "CNC vượt trội hơn EIIL về độ chính xác trung bình và trên các nhiệm vụ riêng lẻ.",
          "D": "CNC chỉ vượt trội hơn EIIL trên một số nhiệm vụ cụ thể."
        },
        "answer": "C"
      },
      {
        "question": "Phương pháp Group DRO sử dụng thông tin bổ sung nào trong quá trình huấn luyện?",
        "options": {
          "A": "Thông tin về độ tuổi của đối tượng trong hình ảnh.",
          "B": "Thông tin về bối cảnh của hình ảnh, chẳng hạn như mô tả về nền.",
          "C": "Thông tin về kích thước của đối tượng trong hình ảnh.",
          "D": "Thông tin về độ sáng của hình ảnh."
        },
        "answer": "B"
      },
      {
        "question": "Điểm khác biệt chính giữa CNC và các phương pháp quản lý tương quan giả trước đây là gì?",
        "options": {
          "A": "CNC sử dụng kiến trúc mạng nơ-ron phức tạp hơn.",
          "B": "CNC chủ động hướng dẫn mô hình tránh biểu diễn các đặc trưng làm giảm độ chính xác phân loại.",
          "C": "CNC yêu cầu ít dữ liệu huấn luyện hơn.",
          "D": "CNC có thể được áp dụng cho nhiều loại dữ liệu khác nhau."
        },
        "answer": "B"
      },
      {
        "question": "Bài viết nhấn mạnh tầm quan trọng của việc phát hiện đối tượng trong các bối cảnh khác nhau đối với ứng dụng nào?",
        "options": {
          "A": "Nhận dạng khuôn mặt.",
          "B": "Xe tự hành.",
          "C": "Chẩn đoán y tế.",
          "D": "Dịch máy."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu cuối cùng của nghiên cứu này là gì?",
        "options": {
          "A": "Tăng tốc độ huấn luyện mạng nơ-ron.",
          "B": "Giảm kích thước của mô hình mạng nơ-ron.",
          "C": "Làm cho mạng nơ-ron trở nên mạnh mẽ hơn trước các tương quan giả trong dữ liệu.",
          "D": "Cải thiện khả năng tạo ra hình ảnh mới của mạng nơ-ron."
        },
        "answer": "C"
      }
    ]
  },
  "covid-19-triage": {
    "title": "Covid-19 Triage",
    "collection": "ml-research",
    "content": "The pandemic has pushed hospitals to their limits. A new machine learning system could help doctors make sure the most severe cases get timely, appropriate care.What’s new:Anuroop Sriram, Matthew Muckley, and colleagues at Facebook, NYU School of Medicine, and NYU Abu Dhabi developed asystemthat examines X-ray images to predict which Covid-19 patients are at greatest risk of decline.Key insight:Previous methodsassess Covid risk based on a single chest X-ray. But when making assessments, clinicians often look for relative changes between successive X-rays to determine whether a patient’s condition is improving or deteriorating. The researchers used consecutive X-rays to improve risk assessment.How it works:The authors trained their system to predict the probability that a patient would die, require intubation, need intensive care, or need more oxygen over the next 24, 48, 72, or 96 hours.\n\nResults:The system achieved a mean AUC (area under the curve, a measure of true versus false positives where 1 is a perfect score) of 0.785, 0.801, 0.790, and 0.790 when predicting adverse outcomes at 24, 48, 72, and 96 hours into the future, respectively. Those scores were comparable to those of two clinicians who achieved an average AUC of 0.784, 0.787, 0.761 and 0.754.Why it matters:Pretraining followed by fine-tuning opens up important applications where data is too scarce for simpler learning approaches.We’re thinking:The pandemic has been anearly testof AI’s utility in medicine. The record so far has beenmixed, but we’re glad to see research that shows promising results for both fighting Covid and improving healthcare in general.",
    "qa": [
      {
        "question": "Hệ thống máy học mới được phát triển nhằm mục đích chính gì trong bối cảnh đại dịch?",
        "options": {
          "A": "Tự động chẩn đoán bệnh nhân mắc Covid-19.",
          "B": "Hỗ trợ bác sĩ đưa ra quyết định chăm sóc kịp thời và phù hợp cho các ca bệnh nặng nhất.",
          "C": "Thay thế hoàn toàn vai trò của bác sĩ trong việc đọc phim X-quang.",
          "D": "Nghiên cứu các biến thể mới của virus SARS-CoV-2."
        },
        "answer": "B"
      },
      {
        "question": "Điểm mới trong phương pháp tiếp cận của hệ thống này so với các phương pháp đánh giá rủi ro Covid-19 trước đây là gì?",
        "options": {
          "A": "Sử dụng trí tuệ nhân tạo để phân tích dữ liệu bệnh nhân.",
          "B": "Dựa trên một phim chụp X-quang duy nhất để đánh giá.",
          "C": "Sử dụng các phim chụp X-quang liên tiếp để đánh giá sự thay đổi tình trạng bệnh nhân.",
          "D": "Đánh giá rủi ro dựa trên các triệu chứng lâm sàng của bệnh nhân."
        },
        "answer": "C"
      },
      {
        "question": "Hệ thống được huấn luyện để dự đoán những nguy cơ nào cho bệnh nhân Covid-19?",
        "options": {
          "A": "Khả năng lây nhiễm cho người khác.",
          "B": "Khả năng tử vong, cần đặt nội khí quản, cần chăm sóc đặc biệt hoặc cần thêm oxy.",
          "C": "Khả năng phục hồi hoàn toàn sau khi điều trị.",
          "D": "Khả năng phát triển các biến chứng lâu dài sau khi khỏi bệnh."
        },
        "answer": "B"
      },
      {
        "question": "AUC (area under the curve) là gì trong ngữ cảnh đánh giá hiệu quả của hệ thống?",
        "options": {
          "A": "Một loại thuốc điều trị Covid-19.",
          "B": "Một phương pháp đo lường độ chính xác của việc dự đoán, so sánh tỷ lệ dương tính thật và dương tính giả.",
          "C": "Một chỉ số đánh giá mức độ nghiêm trọng của bệnh Covid-19.",
          "D": "Một thuật toán máy học được sử dụng trong hệ thống."
        },
        "answer": "B"
      },
      {
        "question": "Giá trị AUC trung bình mà hệ thống đạt được khi dự đoán các kết quả bất lợi trong 24 giờ là bao nhiêu?",
        "options": {
          "A": "0.754",
          "B": "0.761",
          "C": "0.785",
          "D": "0.801"
        },
        "answer": "C"
      },
      {
        "question": "Kết quả AUC của hệ thống so với các bác sĩ lâm sàng như thế nào?",
        "options": {
          "A": "Hệ thống có kết quả AUC thấp hơn đáng kể so với các bác sĩ.",
          "B": "Hệ thống có kết quả AUC cao hơn đáng kể so với các bác sĩ.",
          "C": "Hệ thống có kết quả AUC tương đương với các bác sĩ.",
          "D": "Hệ thống không thể so sánh được với các bác sĩ vì sử dụng phương pháp khác nhau."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao việc 'pretraining' (huấn luyện trước) và 'fine-tuning' (tinh chỉnh) lại quan trọng trong ứng dụng này?",
        "options": {
          "A": "Giúp giảm chi phí phát triển hệ thống.",
          "B": "Cho phép hệ thống hoạt động nhanh hơn.",
          "C": "Mở ra các ứng dụng quan trọng khi dữ liệu quá ít để sử dụng các phương pháp học đơn giản hơn.",
          "D": "Giúp hệ thống dễ dàng tích hợp với các hệ thống y tế khác."
        },
        "answer": "C"
      },
      {
        "question": "Đại dịch Covid-19 được xem là gì đối với việc ứng dụng AI trong y học?",
        "options": {
          "A": "Một thất bại hoàn toàn của AI.",
          "B": "Một cơ hội để thay thế hoàn toàn bác sĩ bằng AI.",
          "C": "Một thử nghiệm ban đầu về tính hữu ích của AI.",
          "D": "Một bằng chứng cho thấy AI không thể ứng dụng trong y học."
        },
        "answer": "C"
      },
      {
        "question": "Nghiên cứu này mang lại hy vọng gì?",
        "options": {
          "A": "Loại bỏ hoàn toàn sự cần thiết của bác sĩ trong việc điều trị Covid-19.",
          "B": "Chứng minh rằng AI có thể thay thế hoàn toàn các phương pháp chẩn đoán truyền thống.",
          "C": "Cho thấy kết quả đầy hứa hẹn trong việc chống lại Covid-19 và cải thiện chăm sóc sức khỏe nói chung.",
          "D": "Giảm chi phí điều trị Covid-19 một cách đáng kể."
        },
        "answer": "C"
      },
      {
        "question": "Ai là những người đã phát triển hệ thống đánh giá rủi ro Covid-19 dựa trên X-quang?",
        "options": {
          "A": "Chỉ có Anuroop Sriram.",
          "B": "Chỉ có Matthew Muckley.",
          "C": "Anuroop Sriram, Matthew Muckley và các đồng nghiệp tại Facebook, NYU School of Medicine và NYU Abu Dhabi.",
          "D": "Các bác sĩ tại NYU School of Medicine."
        },
        "answer": "C"
      }
    ]
  },
  "cracking-open-doctors-notes": {
    "title": "Cracking Open Doctors’ Notes",
    "collection": "ml-research",
    "content": "Weak supervision is the practice of assigning likely labels to unlabeled data using a variety of simple labeling functions. Then supervised methods can be used on top of the now-labeled data. Researchers used this technique to search electronic health records (EHRs) for information squirreled away in unstructured text.What’s new:Complications from hip replacement surgery tend to be under-reported because they’re recorded in EHRs as notes rather than check-marked in a standard list. Researchers at Stanford used weak supervision to label such notes and then extracted information related to hip implants. Theirmethodbrought to light complications that hadn’t been tracked explicitly.Key insight:Alison Callahan and collaborators divided the problem of finding references to post-surgical issues in notes into two parts: identifying the implant’s make and model, and spotting mentions of pain and complications. This made it possible to use weak supervision to label data separately for each subproblem.How it works:Snorkel is a framework that provides a modular way to define and combine labeling functions. The model works as follows:\n\nResults:The researchers trained the system on records of about 6,000 hip-replacement patients treated between 1995 and 2014. Learning the relationships between the various labeling functions uncovered twice as many patients facing complications as majority voting on their predictions (61 percent versus 32 percent). Overall, the system made it possible to assess the likelihood that a particular implant would lead to complications.Why it matters:This analysis could help doctors to match patients with appropriate implants, and help implant manufacturers design their products to minimize bad outcomes.Takeaway:This approach extracts useful information from EHRs, and it looks as though it would generalize to other text-labeling tasks.",
    "qa": [
      {
        "question": "Kỹ thuật 'weak supervision' được sử dụng để làm gì trong bài viết này?",
        "options": {
          "A": "Xây dựng các mô hình học sâu phức tạp để phân tích dữ liệu y tế.",
          "B": "Gán nhãn có khả năng đúng cho dữ liệu chưa được gán nhãn bằng các hàm gán nhãn đơn giản.",
          "C": "Kiểm tra tính chính xác của dữ liệu trong hồ sơ bệnh án điện tử (EHRs).",
          "D": "Chuẩn hóa định dạng của dữ liệu văn bản trong EHRs."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính mà các nhà nghiên cứu Stanford giải quyết là gì?",
        "options": {
          "A": "Tìm kiếm thông tin về tất cả các loại phẫu thuật trong EHRs.",
          "B": "Xác định và trích xuất thông tin về các biến chứng sau phẫu thuật thay khớp háng từ các ghi chú văn bản trong EHRs.",
          "C": "Phát triển một hệ thống tự động để chẩn đoán các bệnh liên quan đến khớp háng.",
          "D": "Cải thiện độ chính xác của việc nhập dữ liệu vào EHRs."
        },
        "answer": "B"
      },
      {
        "question": "Theo Alison Callahan và cộng sự, bài toán tìm kiếm thông tin về các vấn đề sau phẫu thuật được chia thành mấy phần?",
        "options": {
          "A": "Một phần: Xác định các biến chứng.",
          "B": "Hai phần: Xác định loại implant và phát hiện các đề cập đến đau và biến chứng.",
          "C": "Ba phần: Xác định loại implant, phát hiện đau và đánh giá mức độ nghiêm trọng của biến chứng.",
          "D": "Bốn phần: Xác định loại implant, phát hiện đau, biến chứng và tiền sử bệnh nhân."
        },
        "answer": "B"
      },
      {
        "question": "Snorkel là gì trong bối cảnh bài viết này?",
        "options": {
          "A": "Một loại implant khớp háng mới.",
          "B": "Một framework cung cấp cách thức mô-đun để định nghĩa và kết hợp các hàm gán nhãn.",
          "C": "Một thuật toán để phân tích dữ liệu văn bản trong EHRs.",
          "D": "Một phương pháp để đánh giá rủi ro biến chứng sau phẫu thuật."
        },
        "answer": "B"
      },
      {
        "question": "Hệ thống được huấn luyện trên dữ liệu của bao nhiêu bệnh nhân thay khớp háng?",
        "options": {
          "A": "Khoảng 1,000 bệnh nhân.",
          "B": "Khoảng 3,000 bệnh nhân.",
          "C": "Khoảng 6,000 bệnh nhân.",
          "D": "Khoảng 10,000 bệnh nhân."
        },
        "answer": "C"
      },
      {
        "question": "So với phương pháp majority voting, hệ thống sử dụng weak supervision đã phát hiện thêm bao nhiêu bệnh nhân gặp biến chứng?",
        "options": {
          "A": "Ít hơn.",
          "B": "Gấp đôi.",
          "C": "Tương đương.",
          "D": "Gấp ba."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả chính của nghiên cứu là gì?",
        "options": {
          "A": "Hệ thống có thể dự đoán chính xác thời gian phục hồi sau phẫu thuật.",
          "B": "Hệ thống có thể đánh giá khả năng một loại implant cụ thể dẫn đến biến chứng.",
          "C": "Hệ thống có thể tự động đặt lịch hẹn tái khám cho bệnh nhân.",
          "D": "Hệ thống có thể giảm chi phí phẫu thuật thay khớp háng."
        },
        "answer": "B"
      },
      {
        "question": "Phân tích này có thể giúp ích gì cho bác sĩ và nhà sản xuất implant?",
        "options": {
          "A": "Giúp bác sĩ chẩn đoán bệnh nhanh hơn và nhà sản xuất giảm giá thành sản phẩm.",
          "B": "Giúp bác sĩ lựa chọn implant phù hợp cho bệnh nhân và nhà sản xuất thiết kế sản phẩm giảm thiểu biến chứng.",
          "C": "Giúp bác sĩ theo dõi bệnh nhân từ xa và nhà sản xuất tăng cường quảng cáo sản phẩm.",
          "D": "Giúp bác sĩ nghiên cứu các phương pháp phẫu thuật mới và nhà sản xuất mở rộng thị trường."
        },
        "answer": "B"
      },
      {
        "question": "Ứng dụng tiềm năng của phương pháp này là gì?",
        "options": {
          "A": "Chỉ giới hạn trong việc phân tích dữ liệu EHRs liên quan đến phẫu thuật thay khớp háng.",
          "B": "Có thể tổng quát hóa cho các tác vụ gán nhãn văn bản khác.",
          "C": "Chỉ phù hợp với dữ liệu có cấu trúc rõ ràng.",
          "D": "Chỉ có thể sử dụng với framework Snorkel."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao các biến chứng từ phẫu thuật thay khớp háng thường bị báo cáo thiếu?",
        "options": {
          "A": "Do bác sĩ không muốn ghi lại các sai sót của mình.",
          "B": "Do bệnh nhân không thông báo cho bác sĩ về các biến chứng.",
          "C": "Do chúng được ghi lại trong EHRs dưới dạng ghi chú thay vì được đánh dấu trong danh sách tiêu chuẩn.",
          "D": "Do hệ thống EHRs không có chức năng theo dõi biến chứng."
        },
        "answer": "C"
      }
    ]
  },
  "crawl-the-web-absorb-the-bias": {
    "title": "Crawl the Web, Absorb the Bias",
    "collection": "ml-research",
    "content": "The emerging generation of trillion-parameter models needs datasets of billions of examples, but the most readily available source of examples on that scale — the web — is polluted with bias and antisocial expressions. A new study examines the issue.What’s new:Abeba Birhane and colleagues at University College Dublin and University of Edinburghauditedthe LAION-400M dataset, which was released in September. It comprises data scraped from the open web, from which inaccurate entries were removed by a state-of-the-art model for matching images totext. The automated curation left plenty of worrisome examples among the remaining 400 million examples — including stereotypes, racial slurs, and sexual violence — raising concerns that models trained on LAION-400M would inherit its shortcomings.Key insight:The compilers ofLAION-400Mpaired images and text drawn fromCommon Crawl, a large repository of web data. To filter out low-quality pairs, they usedCLIPto score the correspondence between them and discarded those with the lowest scores. But CLIP itself is trained on a massive trove of web data. Thus it’s bound to find a high correspondence between words and pictures that are frequently associated with one another on the web, even if the associations are spurious or otherwise undesirable.NSFT (not safe for training):The authors entered text queries into LAION-400M’s search function, which returned matching images.\n\nBehind the news:The LAION-400M team, a loosely knit collective led by Christoph Schuhmann at University of Vienna, aims to re-create Google’sWikipedia-based Image Textdataset and ultimately use it to train open-source analogs of OpenAI’s CLIP andDALL·E. The group was inspired byEleutherAI’s community effortto build an open source version of GPT-3.Why it matters:It’s enormously expensive to manually clean a dataset that spans hundreds of millions of examples. Automated curation has been viewed as a way to ensure that immense datasets contain high-quality data. This study reveals serious flaws in that approach.We’re thinking:Researchers haveretracted or amendedseveral widely used datasets to address issues of biased and harmful data. Yet, as the demand for data rises, there’s no ready solution to this problem. Audits like this make an important contribution, and the community — including large corporations that produce proprietary systems — would do well to take them seriously.",
    "qa": [
      {
        "question": "LAION-400M là một bộ dữ liệu được tạo ra bằng cách nào?",
        "options": {
          "A": "Thu thập dữ liệu từ các bài báo khoa học đã được kiểm duyệt.",
          "B": "Thu thập dữ liệu từ web mở và loại bỏ các mục không chính xác bằng mô hình AI.",
          "C": "Thu thập dữ liệu từ các nguồn tin tức uy tín và được biên tập viên kiểm tra.",
          "D": "Thu thập dữ liệu từ các mạng xã hội và được người dùng đánh giá."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính được chỉ ra trong nghiên cứu về LAION-400M là gì?",
        "options": {
          "A": "Kích thước của bộ dữ liệu quá nhỏ để huấn luyện các mô hình lớn.",
          "B": "Bộ dữ liệu chứa nhiều ví dụ gây lo ngại như định kiến, lời lẽ phân biệt chủng tộc và bạo lực tình dục.",
          "C": "Bộ dữ liệu không tương thích với các mô hình AI hiện đại.",
          "D": "Quá trình thu thập dữ liệu vi phạm quyền riêng tư của người dùng."
        },
        "answer": "B"
      },
      {
        "question": "CLIP được sử dụng trong quá trình xử lý LAION-400M với mục đích gì?",
        "options": {
          "A": "Để xác định và loại bỏ các hình ảnh có độ phân giải thấp.",
          "B": "Để đánh giá mức độ tương ứng giữa hình ảnh và văn bản, loại bỏ các cặp có điểm số thấp.",
          "C": "Để tự động tạo ra các chú thích cho hình ảnh.",
          "D": "Để nén kích thước của bộ dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao CLIP có thể vô tình giữ lại các nội dung không mong muốn trong LAION-400M?",
        "options": {
          "A": "CLIP được huấn luyện trên một tập dữ liệu nhỏ và không đủ đa dạng.",
          "B": "CLIP được huấn luyện trên dữ liệu web, nơi chứa các liên kết sai lệch hoặc không mong muốn.",
          "C": "CLIP không có khả năng phân biệt giữa hình ảnh và văn bản.",
          "D": "CLIP bị lỗi phần mềm và không hoạt động chính xác."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của nhóm LAION-400M là gì?",
        "options": {
          "A": "Tạo ra một bộ dữ liệu độc quyền để bán cho các công ty lớn.",
          "B": "Tái tạo bộ dữ liệu Image Text dựa trên Wikipedia của Google và huấn luyện các mô hình mã nguồn mở tương tự như CLIP và DALL·E của OpenAI.",
          "C": "Phát triển một thuật toán mới để lọc dữ liệu web.",
          "D": "Nghiên cứu về tác động của AI đối với xã hội."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì khiến việc làm sạch thủ công một bộ dữ liệu lớn như LAION-400M trở nên khó khăn?",
        "options": {
          "A": "Thiếu công cụ phù hợp để xử lý dữ liệu.",
          "B": "Chi phí và thời gian cần thiết để kiểm tra hàng trăm triệu ví dụ là rất lớn.",
          "C": "Không có đủ chuyên gia có kinh nghiệm trong lĩnh vực này.",
          "D": "Các quy định pháp lý cấm việc truy cập vào dữ liệu cá nhân."
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu về LAION-400M cho thấy điều gì về việc sử dụng tự động hóa để làm sạch dữ liệu?",
        "options": {
          "A": "Tự động hóa là giải pháp hoàn hảo để đảm bảo chất lượng dữ liệu.",
          "B": "Tự động hóa có thể giúp giảm chi phí và thời gian, nhưng vẫn có thể tồn tại các sai sót nghiêm trọng.",
          "C": "Tự động hóa không hiệu quả và nên được thay thế bằng phương pháp thủ công.",
          "D": "Tự động hóa chỉ phù hợp với các bộ dữ liệu nhỏ."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì đang xảy ra với một số bộ dữ liệu được sử dụng rộng rãi do vấn đề dữ liệu thiên vị và có hại?",
        "options": {
          "A": "Chúng đang được bán cho các chính phủ để sử dụng cho mục đích an ninh.",
          "B": "Chúng đang bị thu hồi hoặc sửa đổi để giải quyết các vấn đề này.",
          "C": "Chúng đang được sử dụng để huấn luyện các mô hình AI mạnh mẽ hơn.",
          "D": "Chúng đang được công khai để mọi người có thể đóng góp vào việc làm sạch dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Theo bài viết, cộng đồng nghiên cứu nên làm gì để giải quyết vấn đề dữ liệu thiên vị và có hại?",
        "options": {
          "A": "Ngừng sử dụng các bộ dữ liệu lớn và tập trung vào các bộ dữ liệu nhỏ hơn.",
          "B": "Phớt lờ các vấn đề này và tiếp tục sử dụng các bộ dữ liệu hiện có.",
          "C": "Nghiêm túc xem xét các đánh giá và kiểm toán dữ liệu, kể cả các công ty lớn sản xuất các hệ thống độc quyền.",
          "D": "Chỉ sử dụng dữ liệu được tạo ra bởi các tổ chức phi lợi nhuận."
        },
        "answer": "C"
      },
      {
        "question": "Cụm từ 'NSFT (not safe for training)' trong bài viết có nghĩa là gì?",
        "options": {
          "A": "Dữ liệu đã được chứng minh là an toàn để sử dụng cho mục đích huấn luyện.",
          "B": "Dữ liệu không phù hợp để sử dụng cho mục đích huấn luyện do chứa nội dung không mong muốn.",
          "C": "Dữ liệu cần được mã hóa trước khi sử dụng cho mục đích huấn luyện.",
          "D": "Dữ liệu chỉ được phép sử dụng cho mục đích nghiên cứu, không được sử dụng cho mục đích thương mại."
        },
        "answer": "B"
      }
    ]
  },
  "decision-trees-perform-best-on-most-tabular-data": {
    "title": "When Trees Outdo Neural Networks",
    "collection": "ml-research",
    "content": "While neural networks perform well on image, text, and audio datasets, they fall behinddecision treesand their variations for tabular datasets. New research looked into why.\n\nWhat’s new:Léo Grinsztajn, Edouard Oyallon, and Gaël Varoquaux at France’s National Institute for Research in Digital Science and Technology and Sorbonne Universitytraineda variety of neural networks and tree models on tabular datasets. Performance on theirtabular data learning benchmarkrevealed dataset characteristics that favor each class of models.\n\nKey insight:Previousworkfound that no single neural network architecture performed best on a variety of tabular datasets, but a tree-based approach performed better than any neural network on most of them. Training and testing different models on many permutations of the data can reveal principles to guide the choice of architecture for any given dataset.\n\nHow it works:The authors compiled datasets, trained a variety of models (using a variety of hyperparameters), and evaluated their performance. Then they applied transformations to the data, retrained the models, and tested them again to see how the transformations affected model performance.\n\nResults:Averaged across all tasks, the best tree models performed 20 percent to 30 percent better than the best deep learning models. ResNets fell even farther behind trees and transformers as the number of uninformative features rose. In another experiment, training on smoothed labels degraded the performance of trees more than that of neural networks, which suggests that tree-based methods are better at learning irregular mapping of training data to labels.\n\nWhy it matters:Deep learning isn’t the best approach to all datasets and problems. If you have tabular data, givetreesa try!\n\nWe’re thinking:The authors trained their models on datasets of 10,000 or 50,000 training examples. Smaller or larger datasets may have yielded different results.",
    "qa": [
      {
        "question": "Theo nghiên cứu được đề cập, loại mô hình nào thường hoạt động tốt hơn trên dữ liệu dạng bảng (tabular data) so với mạng nơ-ron?",
        "options": {
          "A": "Mạng nơ-ron tích chập (Convolutional Neural Networks)",
          "B": "Cây quyết định và các biến thể của chúng (Decision trees and their variations)",
          "C": "Mạng nơ-ron hồi quy (Recurrent Neural Networks)",
          "D": "Mạng nơ-ron tự mã hóa (Autoencoders)"
        },
        "answer": "B"
      },
      {
        "question": "Nghiên cứu mới được thực hiện bởi ai?",
        "options": {
          "A": "Google AI",
          "B": "Facebook AI Research",
          "C": "Viện Nghiên cứu Khoa học Kỹ thuật Số Quốc gia Pháp và Đại học Sorbonne",
          "D": "Microsoft Research"
        },
        "answer": "C"
      },
      {
        "question": "Một phát hiện quan trọng của nghiên cứu là gì?",
        "options": {
          "A": "Mạng nơ-ron luôn hoạt động tốt hơn cây quyết định trên mọi loại dữ liệu.",
          "B": "Không có kiến trúc mạng nơ-ron đơn lẻ nào hoạt động tốt nhất trên nhiều bộ dữ liệu dạng bảng, nhưng phương pháp dựa trên cây hoạt động tốt hơn hầu hết các mạng nơ-ron.",
          "C": "Cây quyết định không thể xử lý dữ liệu dạng bảng phức tạp.",
          "D": "Cần phải sử dụng cả mạng nơ-ron và cây quyết định để đạt được kết quả tốt nhất."
        },
        "answer": "B"
      },
      {
        "question": "Các tác giả đã làm gì để đánh giá hiệu suất của các mô hình?",
        "options": {
          "A": "Chỉ huấn luyện các mô hình trên một bộ dữ liệu duy nhất.",
          "B": "Huấn luyện các mô hình trên nhiều bộ dữ liệu và áp dụng các phép biến đổi dữ liệu.",
          "C": "Chỉ sử dụng các siêu tham số mặc định cho tất cả các mô hình.",
          "D": "So sánh hiệu suất của các mô hình với hiệu suất của con người."
        },
        "answer": "B"
      },
      {
        "question": "Kết quả nghiên cứu cho thấy điều gì về hiệu suất của mô hình cây so với mô hình học sâu (deep learning) trên các tác vụ trung bình?",
        "options": {
          "A": "Mô hình học sâu hoạt động tốt hơn từ 20% đến 30%.",
          "B": "Mô hình cây hoạt động tốt hơn từ 20% đến 30%.",
          "C": "Hiệu suất của cả hai loại mô hình là tương đương.",
          "D": "Mô hình cây chỉ hoạt động tốt hơn trên các bộ dữ liệu nhỏ."
        },
        "answer": "B"
      },
      {
        "question": "Điều gì xảy ra với hiệu suất của ResNets, cây quyết định và transformers khi số lượng đặc trưng không mang lại thông tin (uninformative features) tăng lên?",
        "options": {
          "A": "Hiệu suất của tất cả các mô hình đều tăng lên.",
          "B": "Hiệu suất của tất cả các mô hình đều giảm xuống, nhưng ResNets giảm nhiều nhất.",
          "C": "Hiệu suất của ResNets giảm nhiều hơn so với cây quyết định và transformers.",
          "D": "Hiệu suất của cây quyết định giảm nhiều hơn so với ResNets và transformers."
        },
        "answer": "C"
      },
      {
        "question": "Việc huấn luyện trên các nhãn được làm mịn (smoothed labels) ảnh hưởng đến hiệu suất của cây quyết định và mạng nơ-ron như thế nào?",
        "options": {
          "A": "Làm tăng hiệu suất của cả hai loại mô hình.",
          "B": "Làm giảm hiệu suất của cả hai loại mô hình.",
          "C": "Làm giảm hiệu suất của cây quyết định nhiều hơn so với mạng nơ-ron.",
          "D": "Làm giảm hiệu suất của mạng nơ-ron nhiều hơn so với cây quyết định."
        },
        "answer": "C"
      },
      {
        "question": "Tại sao nghiên cứu này lại quan trọng?",
        "options": {
          "A": "Nó chứng minh rằng học sâu luôn là phương pháp tốt nhất cho mọi loại dữ liệu.",
          "B": "Nó cho thấy rằng cây quyết định không còn phù hợp trong thời đại của học sâu.",
          "C": "Nó nhấn mạnh rằng học sâu không phải là phương pháp tốt nhất cho tất cả các bộ dữ liệu và vấn đề, đặc biệt là dữ liệu dạng bảng.",
          "D": "Nó khuyến khích sử dụng học sâu cho tất cả các bài toán liên quan đến dữ liệu dạng bảng."
        },
        "answer": "C"
      },
      {
        "question": "Các tác giả đã huấn luyện mô hình của họ trên các bộ dữ liệu có kích thước như thế nào?",
        "options": {
          "A": "100 ví dụ huấn luyện.",
          "B": "1.000 ví dụ huấn luyện.",
          "C": "10.000 hoặc 50.000 ví dụ huấn luyện.",
          "D": "1.000.000 ví dụ huấn luyện."
        },
        "answer": "C"
      },
      {
        "question": "Điều gì có thể xảy ra nếu các tác giả huấn luyện mô hình trên các bộ dữ liệu có kích thước nhỏ hơn hoặc lớn hơn?",
        "options": {
          "A": "Kết quả sẽ hoàn toàn giống nhau.",
          "B": "Kết quả có thể khác.",
          "C": "Chỉ có hiệu suất của mạng nơ-ron bị ảnh hưởng.",
          "D": "Chỉ có hiệu suất của cây quyết định bị ảnh hưởng."
        },
        "answer": "B"
      }
    ]
  },
  "deep-learning-finds-new-antibiotic": {
    "title": "Deep Learning Finds New Antibiotic",
    "collection": "ml-research",
    "content": "Chemists typically develop new antibiotics by testing close chemical relatives of tried-and-true compounds like penicillin. That approach becomes less effective, though, as dangerous bacteria evolve resistance to those very chemical structures. Instead, researchers enlisted neural networks.What’s new:Jonathan Stokes and colleagues at MIT, Harvard, and McMaster University built an ensemble model that predicts molecules that are structurally unrelated to known antibiotics, harmless to humans, and deadly to E. coli, a common bacterium that served as a proxy microorganism. The model spotted a previously unrecognized antibiotic that proved effective at killing a variety of germs.Key insight:Neural networks can stand in for petri dishes to zero in on promising molecules. An initial simulation reduced an enormous number of molecules to a few thousand solid possibilities, of which the model selected a couple dozen for testing in a wet lab.How it works:The researchers used an ensemble of 20 graph neural networks (GNNs) to evaluate molecules’ ability to inhibit E. coli, and another ensemble of five GNNs to evaluate toxicity. They used a standard measure to evaluate chemical structure. Then they tested the most promising compounds on mice.\n\nResults:The researchers examined more than 107 million compounds to produce a ranked list. Empirical tests on the top-ranked 3,260 chemicals yielded 51 that were effective. Of those, 23 had low predicted toxicity and structures distinct from known antibiotics. In mouse experiments, Halicin, a known diabetes treatment, proved effective as a broad-spectrum antibiotic.Why it matters:Alexander Fleming’s discovery of penicillin in 1928 revolutionized medicine. Now that transformation is at risk as bugs evolve resistance to that drug and its successors. Discovery of new antibiotics has been hampered by lack of a way to narrow the list of possibilities for lab tests. This method offers a way to vet candidates quickly and efficiently.\n\nWe’re thinking:Antibiotic-resistant bugs are responsible for 2.8 million infections and 35,000 deaths annually in the U.S. alone. Crank up those GNNs!",
    "qa": [
      {
        "question": "Phương pháp truyền thống để phát triển kháng sinh mới thường dựa vào điều gì?",
        "options": {
          "A": "Sử dụng các hợp chất hoàn toàn mới, chưa từng được nghiên cứu.",
          "B": "Thử nghiệm các chất hóa học có cấu trúc tương tự các hợp chất đã được chứng minh hiệu quả.",
          "C": "Tập trung vào việc tìm kiếm các hợp chất có khả năng ức chế trực tiếp sự phát triển của vi khuẩn kháng thuốc.",
          "D": "Sử dụng các hợp chất tự nhiên chiết xuất từ thực vật và động vật."
        },
        "answer": "B"
      },
      {
        "question": "Mục tiêu chính của nhóm nghiên cứu Jonathan Stokes khi sử dụng mạng nơ-ron là gì?",
        "options": {
          "A": "Tăng tốc độ thử nghiệm các loại kháng sinh hiện có.",
          "B": "Dự đoán các phân tử không liên quan về mặt cấu trúc với kháng sinh đã biết, vô hại với người và tiêu diệt E. coli.",
          "C": "Tìm ra các phương pháp mới để tăng cường hiệu quả của penicillin.",
          "D": "Phát triển các loại thuốc điều trị bệnh tiểu đường có tác dụng kháng khuẩn."
        },
        "answer": "B"
      },
      {
        "question": "Mạng nơ-ron đóng vai trò gì trong quá trình nghiên cứu kháng sinh mới?",
        "options": {
          "A": "Thay thế hoàn toàn các thí nghiệm trong phòng thí nghiệm ướt.",
          "B": "Đóng vai trò như đĩa petri để xác định các phân tử tiềm năng.",
          "C": "Phân tích cấu trúc hóa học của các kháng sinh hiện có.",
          "D": "Tổng hợp các phân tử kháng sinh mới trong phòng thí nghiệm."
        },
        "answer": "B"
      },
      {
        "question": "Các nhà nghiên cứu đã sử dụng loại mạng nơ-ron nào để đánh giá khả năng ức chế E. coli của các phân tử?",
        "options": {
          "A": "Mạng nơ-ron tích chập (CNNs).",
          "B": "Mạng nơ-ron lan truyền ngược (BPNNs).",
          "C": "Mạng nơ-ron đồ thị (GNNs).",
          "D": "Mạng nơ-ron hồi quy (RNNs)."
        },
        "answer": "C"
      },
      {
        "question": "Các nhà nghiên cứu đã sử dụng tiêu chí nào để đánh giá cấu trúc hóa học của các phân tử?",
        "options": {
          "A": "Độ tan trong nước.",
          "B": "Độ bền nhiệt.",
          "C": "Một thước đo tiêu chuẩn.",
          "D": "Khả năng phản ứng với axit."
        },
        "answer": "C"
      },
      {
        "question": "Trong quá trình sàng lọc, bao nhiêu hợp chất hàng đầu đã được kiểm tra thực nghiệm?",
        "options": {
          "A": "51.",
          "B": "23.",
          "C": "3,260.",
          "D": "107 triệu."
        },
        "answer": "C"
      },
      {
        "question": "Hợp chất nào, vốn là một phương pháp điều trị bệnh tiểu đường, đã được chứng minh là có hiệu quả như một loại kháng sinh phổ rộng trong các thí nghiệm trên chuột?",
        "options": {
          "A": "Penicillin.",
          "B": "Halicin.",
          "C": "E. coli.",
          "D": "GNNs."
        },
        "answer": "B"
      },
      {
        "question": "Khám phá penicillin của Alexander Fleming vào năm 1928 có ý nghĩa gì?",
        "options": {
          "A": "Đánh dấu sự khởi đầu của việc sử dụng mạng nơ-ron trong y học.",
          "B": "Mở ra một kỷ nguyên mới trong điều trị bệnh nhiễm trùng.",
          "C": "Chứng minh rằng vi khuẩn không thể phát triển khả năng kháng thuốc.",
          "D": "Cho thấy rằng tất cả các bệnh nhiễm trùng đều có thể được chữa khỏi bằng kháng sinh."
        },
        "answer": "B"
      },
      {
        "question": "Vấn đề chính mà phương pháp mới này giải quyết trong việc phát hiện kháng sinh là gì?",
        "options": {
          "A": "Chi phí cao của các thí nghiệm trong phòng thí nghiệm.",
          "B": "Sự thiếu hụt các nhà khoa học có kinh nghiệm.",
          "C": "Sự hạn chế về số lượng hợp chất có thể được kiểm tra trong phòng thí nghiệm.",
          "D": "Thời gian dài cần thiết để phát triển một loại kháng sinh mới."
        },
        "answer": "C"
      },
      {
        "question": "Theo bài viết, mỗi năm có bao nhiêu ca nhiễm trùng và tử vong liên quan đến vi khuẩn kháng kháng sinh ở Hoa Kỳ?",
        "options": {
          "A": "2.8 triệu ca nhiễm trùng và 35,000 ca tử vong.",
          "B": "35,000 ca nhiễm trùng và 2.8 triệu ca tử vong.",
          "C": "1 triệu ca nhiễm trùng và 10,000 ca tử vong.",
          "D": "10,000 ca nhiễm trùng và 1 triệu ca tử vong."
        },
        "answer": "A"
      }
    ]
  },
  "deep-learning-for-object-tracking": {
    "title": "Deep Learning for Object Tracking",
    "collection": "ml-research",
    "content": "AI is good at tracking objects in two dimensions. A new model processes video from a camera with a depth sensor to predict how objects move through space.What’s new:Led by Chen Wang, researchers from Stanford, Shanghai Jiao Tong University, and Nvidia built a system that tracks objects fast enough for a robot to react in real time:6D-Pose Anchor-based Category-level Keypoint-tracker(6-PACK). Why 6D? Because three-dimensional objects in motion have six degrees of freedom: three for linear motion and three for rotation. You can see the system in action in thisvideo.Key insight:Rather than tracking absolution location, 6-PACK tracks an object’s change in position from video frame to video frame. Knowing its position in one frame makes it easier to find in the next.How it works:The network’s training data is labeled with a six-dimensional vector that represents changes in an object’s location and orientation between frames. From that information, it learns to extract keypoints such as edges and corners, calculate changes in their positions, and extrapolate a new position. Objects in the training data are labeled with a category such as bowl or mug.\n\nResults:Tested on adatasetof real-world videos, 6-PACK predicted object position and rotation within 5cm and 5 degrees in 33.3 percent of cases, versus the previousstate of the artof 17 percent.Why it matters:The ability to track objects as they move and rotate is essential to progress in robotics, both to manipulate things and to navigate around them.We’re thinking:Object tracking algorithms and visual keypoints have a long history stretching beyond the 1960-vintageKalman filter. Deep learning has come to dominate object recognition, and it’s good to see progress in tasks like tracking and optical flow.",
    "qa": [
      {
        "question": "Mô hình 6-PACK được phát triển bởi các nhà nghiên cứu đến từ những trường đại học và công ty nào?",
        "options": {
          "A": "Stanford, MIT, và Google.",
          "B": "Stanford, Shanghai Jiao Tong University, và Nvidia.",
          "C": "Harvard, Oxford, và Microsoft.",
          "D": "Cambridge, Tsinghua University, và Amazon."
        },
        "answer": "B"
      },
      {
        "question": "Tại sao hệ thống theo dõi đối tượng này được gọi là '6D'?",
        "options": {
          "A": "Vì nó sử dụng 6 camera để theo dõi đối tượng.",
          "B": "Vì các đối tượng ba chiều chuyển động có sáu bậc tự do.",
          "C": "Vì nó có thể theo dõi đối tượng trong không gian sáu chiều.",
          "D": "Vì nó sử dụng 6 lớp mạng nơ-ron để xử lý dữ liệu."
        },
        "answer": "B"
      },
      {
        "question": "Thay vì theo dõi vị trí tuyệt đối, 6-PACK theo dõi điều gì?",
        "options": {
          "A": "Vận tốc của đối tượng.",
          "B": "Sự thay đổi vị trí của đối tượng giữa các khung hình video.",
          "C": "Gia tốc của đối tượng.",
          "D": "Quỹ đạo tổng thể của đối tượng."
        },
        "answer": "B"
      },
      {
        "question": "Dữ liệu huấn luyện của mạng 6-PACK được gán nhãn bằng thông tin gì?",
        "options": {
          "A": "Hình ảnh 3D của đối tượng.",
          "B": "Một vector sáu chiều biểu diễn sự thay đổi vị trí và hướng của đối tượng giữa các khung hình.",
          "C": "Vị trí tuyệt đối của đối tượng trong không gian.",
          "D": "Màu sắc và kết cấu của đối tượng."
        },
        "answer": "B"
      },
      {
        "question": "6-PACK học cách trích xuất những đặc điểm gì từ đối tượng trong quá trình huấn luyện?",
        "options": {
          "A": "Màu sắc và độ sáng.",
          "B": "Các điểm chính như cạnh và góc.",
          "C": "Kích thước và hình dạng tổng thể.",
          "D": "Vật liệu và kết cấu bề mặt."
        },
        "answer": "B"
      },
      {
        "question": "Trong thử nghiệm, 6-PACK dự đoán vị trí và góc quay của đối tượng trong phạm vi bao nhiêu phần trăm trường hợp?",
        "options": {
          "A": "50%",
          "B": "33.3%",
          "C": "25%",
          "D": "17%"
        },
        "answer": "B"
      },
      {
        "question": "Kết quả của 6-PACK tốt hơn bao nhiêu so với công nghệ trước đây?",
        "options": {
          "A": "Gấp đôi.",
          "B": "Gần gấp đôi.",
          "C": "Gấp ba.",
          "D": "Gấp bốn."
        },
        "answer": "B"
      },
      {
        "question": "Khả năng theo dõi đối tượng di chuyển và xoay có tầm quan trọng như thế nào đối với lĩnh vực robot học?",
        "options": {
          "A": "Không quan trọng.",
          "B": "Chỉ quan trọng trong một số ứng dụng nhất định.",
          "C": "Rất quan trọng để thao tác và điều hướng.",
          "D": "Chỉ quan trọng trong môi trường được kiểm soát."
        },
        "answer": "C"
      },
      {
        "question": "Thuật toán theo dõi đối tượng và các điểm chính trực quan có lịch sử phát triển lâu dài, vượt ra ngoài bộ lọc nào?",
        "options": {
          "A": "Bộ lọc Gaussian.",
          "B": "Bộ lọc Kalman.",
          "C": "Bộ lọc trung bình.",
          "D": "Bộ lọc Median."
        },
        "answer": "B"
      },
      {
        "question": "Lĩnh vực nào đã trở nên thống trị trong việc nhận dạng đối tượng?",
        "options": {
          "A": "Thống kê Bayes.",
          "B": "Học sâu (Deep learning).",
          "C": "Xử lý ảnh truyền thống.",
          "D": "Thị giác máy tính cổ điển."
        },
        "answer": "B"
      }
    ]
  }
}